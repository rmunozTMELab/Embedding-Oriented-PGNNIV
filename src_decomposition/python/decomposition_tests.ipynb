{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from models.non_constant_diffusivity import NonConstantDiffusivityNeuralNetwork\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'C:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data\\non_linear\\non_linear_fft_tests.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results\\non_linear')\n",
    "# MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results\\non_linear\\model_paper')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "# create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.Tensor(dataset['y_train'])\n",
    "image = u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hayo los coeficientes de fourier mas energeticos\n",
    "fft_img = torch.fft.fft2(image)\n",
    "fft_img_shifted = torch.fft.fftshift(fft_img)\n",
    "magnitude = torch.abs(fft_img_shifted)\n",
    "magnitude_flattened = magnitude.flatten(1, 2)\n",
    "\n",
    "# Me quedo con los 10 mas energeticos\n",
    "k=50\n",
    "top = torch.topk(magnitude_flattened, k).indices\n",
    "values, counts = zip(*Counter(top.flatten()).most_common(k))\n",
    "\n",
    "values_list = list(map(int, values))\n",
    "counts_list = list(counts)\n",
    "\n",
    "top_indices = values_list\n",
    "\n",
    "nuevo_tensor = torch.zeros_like(magnitude_flattened, dtype=torch.complex64)\n",
    "nuevo_tensor[:, top_indices] = fft_img_shifted.flatten(1, 2)[:, top_indices]\n",
    "\n",
    "new_base_fft = nuevo_tensor.reshape(image.shape)\n",
    "\n",
    "fft_filtered_shifted_back = torch.fft.ifftshift(new_base_fft)\n",
    "\n",
    "img_filtered = torch.fft.ifft2(fft_filtered_shifted_back)\n",
    "\n",
    "img_filtered = torch.real(img_filtered)\n",
    "\n",
    "plt.imshow(img_filtered[0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "error = torch.trapz(torch.trapz(torch.abs(img_filtered - image), dx=dx, dim=-1), dx=dx, dim=-1)/torch.trapz(torch.trapz(torch.abs(image), dx=dx, dim=-1), dx=dx, dim=-1)\n",
    "\n",
    "print(torch.sum(error)/len(error))\n",
    "\n",
    "plt.hist(error)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para conservar solo las 5 frecuencias más energéticas\n",
    "def keep_top_k_frequencies(image, k=10):\n",
    "    # Convertir la imagen a tensor de PyTorch\n",
    "    img_tensor = image\n",
    "    \n",
    "    # Aplicar la transformada de Fourier 2D\n",
    "    fft_img = torch.fft.fft2(img_tensor)\n",
    "    \n",
    "    # Desplazar el espectro de Fourier para centrar las frecuencias bajas\n",
    "    fft_img_shifted = torch.fft.fftshift(fft_img)\n",
    "\n",
    "    # Calcular la magnitud (energía) de las frecuencias\n",
    "    magnitude = torch.abs(fft_img_shifted)\n",
    "    \n",
    "    # Aplanar la magnitud y obtener los índices de las top-k frecuencias más energéticas\n",
    "    flat_magnitude = magnitude.flatten()\n",
    "    top_k_indices = torch.topk(flat_magnitude, k).indices\n",
    "\n",
    "    # Crear una máscara con ceros\n",
    "    mask = torch.zeros_like(fft_img_shifted, dtype=torch.complex64)\n",
    "    \n",
    "    # Usar los índices para mantener solo las 5 frecuencias más energéticas\n",
    "    for idx in top_k_indices:\n",
    "        # Convertir el índice plano en coordenadas 2D\n",
    "        i, j = np.unravel_index(idx.item(), fft_img_shifted.shape)\n",
    "        mask[i, j] = 1.0  # Dejar pasar solo estas frecuencias\n",
    "\n",
    "    # Aplicar la máscara\n",
    "    fft_filtered = fft_img_shifted * mask\n",
    "    \n",
    "    # Invertir el desplazamiento del espectro\n",
    "    fft_filtered_shifted_back = torch.fft.ifftshift(fft_filtered)\n",
    "    \n",
    "    # Aplicar la transformada inversa de Fourier\n",
    "    img_filtered = torch.fft.ifft2(fft_filtered_shifted_back)\n",
    "    \n",
    "    # Tomar solo la parte real de la imagen filtrada\n",
    "    img_filtered = torch.real(img_filtered)\n",
    "\n",
    "    return img_filtered\n",
    "\n",
    "# Función para mostrar la imagen original y filtrada\n",
    "def plot_images(original, filtered):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original)\n",
    "    plt.title('Imagen Original')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(filtered)\n",
    "    plt.title('Imagen con 5 Frecuencias Más Energéticas')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(torch.abs(original - filtered))\n",
    "    plt.title('Imagen con 5 Frecuencias Más Energéticas')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(torch.sum(torch.abs(original - filtered))/torch.sum(original))\n",
    "\n",
    "\n",
    "# Cargar la imagen\n",
    "img_path = 'ruta/a/tu/imagen.jpg'\n",
    "image = u[0]\n",
    "\n",
    "# Conservar solo las 5 frecuencias más energéticas\n",
    "filtered_image = keep_top_k_frequencies(image, k=100)\n",
    "\n",
    "# Mostrar las imágeness\n",
    "plot_images(image, filtered_image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_coef = torch.fft.fft2(u)\n",
    "F_ordered = f_coef.flatten(start_dim=1)\n",
    "N = F_ordered.shape[1]\n",
    "\n",
    "Et = torch.sum(torch.sum(torch.square(torch.abs(u)), dim=1), dim=1)\n",
    "Ef = torch.sum(torch.sum(torch.square(torch.abs(f_coef)), dim=1), dim=1)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_coef = torch.fft.fft2(u)\n",
    "\n",
    "columna = f_coef[:, :, 0]\n",
    "fila = f_coef[:, 0, :]\n",
    "\n",
    "nuevo = torch.zeros_like(f_coef, dtype=torch.complex64)\n",
    "nuevo[:, :, 0] = columna\n",
    "nuevo[:, 0, :] = fila\n",
    "\n",
    "\n",
    "\n",
    "# Aplicar la transformada inversa de Fourier\n",
    "img_filtered = torch.fft.ifft2(nuevo)\n",
    "\n",
    "# Tomar solo la parte real de la imagen filtrada\n",
    "img_filtered = torch.real(img_filtered)\n",
    "\n",
    "plt.imshow((img_filtered)[429])\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_coeficients(data, n_modes):\n",
    "\n",
    "    fft_data = torch.fft.fft2(data)\n",
    "    fft_data_shifted = torch.fft.fftshift(fft_data)\n",
    "\n",
    "    N_data, h, w = data.shape\n",
    "    center_h, center_w = h // 2, w // 2\n",
    "\n",
    "    mask = torch.zeros_like(fft_data_shifted, dtype=torch.complex64)\n",
    "\n",
    "    for i in range(-n_modes // 2, n_modes // 2 + 1):\n",
    "        for j in range(-n_modes // 2, n_modes // 2 + 1):\n",
    "            if 0 <= center_h + i < h and 0 <= center_w + j < w:\n",
    "                mask[:, center_h + i, center_w + j] = fft_data_shifted[:, center_h + i, center_w + j]\n",
    "\n",
    "    filtered_fft_data_shifted = fft_data_shifted * mask\n",
    "\n",
    "    return filtered_fft_data_shifted\n",
    "\n",
    "def fft_coeficients_to_tensor(fft_coeficients):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_modes_fft_coef(data, n_modes):\n",
    "    \n",
    "    fft_data = torch.fft.fft2(data)\n",
    "    fft_data_shifted = torch.fft.fftshift(fft_data)\n",
    "\n",
    "    N_data, h, w = data.shape\n",
    "    center_h, center_w = h // 2, w // 2\n",
    "\n",
    "    mask = torch.zeros((N_data, n_modes + 1, n_modes + 1), dtype=torch.complex64)\n",
    "\n",
    "    for i in range(-n_modes // 2, n_modes // 2 + 1):\n",
    "        for j in range(-n_modes // 2, n_modes // 2 + 1):\n",
    "            mask[:, i + n_modes // 2, j + n_modes // 2] = fft_data_shifted[:, center_h + i, center_w + j]\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def reconstruct_relevant_modes(relevant_modes_fft_coef, shape):\n",
    "\n",
    "    N_data, h, w = shape\n",
    "    center_h, center_w = h // 2, w // 2\n",
    "    n_modes = relevant_modes_fft_coef.shape[1] - 1\n",
    "\n",
    "    reconstruction = torch.zeros((N_data, h, w), dtype=torch.complex64)\n",
    "\n",
    "    for i in range(-n_modes // 2, n_modes // 2 + 1):\n",
    "        for j in range(-n_modes // 2, n_modes // 2 + 1):\n",
    "             reconstruction[:, center_h + i, center_w + j] = relevant_modes_fft_coef[:, i + n_modes // 2, j + n_modes // 2]\n",
    "\n",
    "    return torch.fft.ifft2(torch.fft.fftshift(reconstruction)).real\n",
    "\n",
    "\n",
    "\n",
    "a = relevant_modes_fft_coef(u, 49)\n",
    "u_recon = reconstruct_relevant_modes(relevant_modes_fft_coef(u, 49), u.shape)\n",
    "\n",
    "plt.imshow(u_recon[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_images(data, n_modes):\n",
    "\n",
    "    time_start = time.time()  # Use a different variable name for the start time\n",
    "\n",
    "    fft_data = torch.fft.fft2(data)\n",
    "    fft_data_shifted = torch.fft.fftshift(fft_data)\n",
    "\n",
    "    N_data, h, w = data.shape\n",
    "    center_h, center_w = h // 2, w // 2\n",
    "\n",
    "    mask = torch.zeros_like(fft_data_shifted, dtype=torch.complex64)\n",
    "\n",
    "    for data_i in range(N_data):\n",
    "        for i in range(-n_modes//2, n_modes//2 + 1):\n",
    "            for j in range(-n_modes//2, n_modes//2 + 1):\n",
    "                if 0 <= center_h + i < h and 0 <= center_w + j < w:\n",
    "                    mask[data_i, center_h + i, center_w + j] = fft_data_shifted[data_i, center_h + i, center_w + j]\n",
    "\n",
    "    \n",
    "    time_end = time.time()  # Use a different variable name for the end time\n",
    "\n",
    "    print(time_end - time_start)  # Print the elapsed time\n",
    "\n",
    "\n",
    "\n",
    "    # Create a mask and filter low-energetic modes\n",
    "    mask = torch.zeros_like(fft_coef_shifted, dtype=torch.complex64)\n",
    "\n",
    "    for img_idx in range(data.shape[0]):\n",
    "        for idx in top_energy_indices[img_idx]:\n",
    "            i, j = np.unravel_index(idx.item(), data.shape[1:])  \n",
    "            mask[img_idx, i, j] = 1.0 \n",
    "\n",
    "error_images(u, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para conservar solo las 5 frecuencias más energéticas\n",
    "def keep_top_k_frequencies(image, k=10):\n",
    "    # Convertir la imagen a tensor de PyTorch\n",
    "    img_tensor = image\n",
    "    \n",
    "    # Aplicar la transformada de Fourier 2D\n",
    "    \n",
    "    \n",
    "    # Desplazar el espectro de Fourier para centrar las frecuencias bajas\n",
    "    \n",
    "\n",
    "    # Calcular la magnitud (energía) de las frecuencias\n",
    "    magnitude = torch.abs(fft_img_shifted)\n",
    "    \n",
    "    # Aplanar la magnitud y obtener los índices de las top-k frecuencias más energéticas\n",
    "    flat_magnitude = magnitude.flatten()\n",
    "    top_k_indices = torch.topk(flat_magnitude, k).indices\n",
    "\n",
    "    # Crear una máscara con ceros\n",
    "    mask = torch.zeros_like(fft_img_shifted, dtype=torch.complex64)\n",
    "    \n",
    "    # Usar los índices para mantener solo las 5 frecuencias más energéticas\n",
    "    for idx in top_k_indices:\n",
    "        # Convertir el índice plano en coordenadas 2D\n",
    "        i, j = np.unravel_index(idx.item(), fft_img_shifted.shape)\n",
    "        mask[i, j] = 1.0  # Dejar pasar solo estas frecuencias\n",
    "\n",
    "    # Aplicar la máscara\n",
    "    fft_filtered = fft_img_shifted * mask\n",
    "    \n",
    "    # Invertir el desplazamiento del espectro\n",
    "    fft_filtered_shifted_back = \n",
    "    \n",
    "    # Aplicar la transformada inversa de Fourier\n",
    "    \n",
    "    \n",
    "    # Tomar solo la parte real de la imagen filtrada\n",
    "    img_filtered = torch.real(img_filtered)\n",
    "\n",
    "    return img_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = torch.svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = []\n",
    "\n",
    "for index in range(Et.shape[0]):\n",
    "    energy.append(torch.sum(torch.sum(torch.square(torch.abs(F_ordered[index, :10]))))/N/Et[index])\n",
    "\n",
    "minimo = np.min(energy)\n",
    "maximo = np.max(energy)\n",
    "primer_cuartil = np.percentile(energy, 25)\n",
    "mediana = np.percentile(energy, 50)\n",
    "tercer_cuartil = np.percentile(energy, 75)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Máximo: {maximo:.2e}\")\n",
    "print(f\"Tercer cuartil (Q3): {tercer_cuartil:.2e}\")\n",
    "print(f\"Mediana (Q2): {mediana:.2e}\")\n",
    "print(f\"Primer cuartil (Q1): {primer_cuartil:.2e}\")\n",
    "print(f\"Mínimo: {minimo:.2e}\\n\")\n",
    "\n",
    "minimo = np.min(energy)\n",
    "indice_minimo = np.argmin(energy)\n",
    "\n",
    "print(f\"El valor mínimo es: {minimo}\")\n",
    "print(f\"El índice del valor mínimo es: {indice_minimo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(F_ordered)\n",
    "mask[:, :50] = 1\n",
    "\n",
    "F_full = f_coef*mask.reshape(f_coef.shape)\n",
    "u_reconstructed = torch.fft.ifft2(F_full).real\n",
    "\n",
    "print(torch.sum(torch.abs(u - u_reconstructed))/torch.sum(torch.abs(u)))\n",
    "\n",
    "plt.imshow(F_full[0].real)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 429\n",
    "\n",
    "plt.imshow(u[index])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(u_reconstructed[index])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.abs(u_reconstructed[index] - u[index]))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_to_tensor(coefs):\n",
    "\n",
    "    filtered_coefficients_list = []\n",
    "\n",
    "    for img_idx in range(coefs.shape[0]):\n",
    "        non_zero_coefs = coefs[img_idx][coefs[img_idx] != 0]  # Filtrar coeficientes no nulos\n",
    "        filtered_coefficients_list.append(non_zero_coefs)\n",
    "\n",
    "    # Convertir la lista en un tensor de objetos PyTorch\n",
    "    filtered_coefficients_tensor = torch.stack([torch.tensor(coefs) for coefs in filtered_coefficients_list])\n",
    "\n",
    "    print(filtered_coefficients_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_data_FFT(data, n_components):\n",
    "\n",
    "    # Forward FFT\n",
    "    fft_coef = torch.fft.fft2(data)\n",
    "    fft_coef_shifted = torch.fft.fftshift(fft_coef, dim=(-2, -1))\n",
    "    \n",
    "    # Obtain most energetic modes\n",
    "    energy = torch.abs(fft_coef_shifted)\n",
    "    flat_energy = energy.view(data.shape[0], -1) \n",
    "    top_energy_indices = torch.topk(flat_energy, n_components, dim=1).indices\n",
    "\n",
    "    print(top_energy_indices[:, 0:5])\n",
    "\n",
    "    # Create a mask and filter low-energetic modes\n",
    "    mask = torch.zeros_like(fft_coef_shifted, dtype=torch.complex64)\n",
    "\n",
    "    for img_idx in range(data.shape[0]):\n",
    "        for idx in top_energy_indices[img_idx]:\n",
    "            i, j = np.unravel_index(idx.item(), data.shape[1:])  \n",
    "            mask[img_idx, i, j] = 1.0 \n",
    "\n",
    "    fft_coef_filtered = fft_coef_shifted * mask\n",
    "\n",
    "    return fft_coef_filtered\n",
    "\n",
    "def compose_data_FFT(fft_coef_shifted_filtered):\n",
    "\n",
    "    # Backward FFT\n",
    "    fft_filtered_shifted_back = torch.fft.ifftshift(fft_coef_shifted_filtered, dim=(-2, -1))\n",
    "    data_filtered = torch.fft.ifft2(fft_filtered_shifted_back)\n",
    "    data_filtered_real = torch.real(data_filtered)\n",
    "\n",
    "    return data_filtered_real\n",
    "\n",
    "\n",
    "\n",
    "index = 429\n",
    "filtered = decompose_data_FFT(u, 50)[index].real\n",
    "original = u[index]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "    \n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original)\n",
    "plt.title('Imagen Original')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(filtered)\n",
    "plt.title('Imagen con 5 Frecuencias Más Energéticas')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(torch.abs(original - filtered))\n",
    "plt.title('Imagen con 5 Frecuencias Más Energéticas')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para conservar solo las 5 frecuencias más energéticas\n",
    "def keep_top_k_frequencies(image, k=10):\n",
    "    # Convertir la imagen a tensor de PyTorch\n",
    "    img_tensor = image\n",
    "    \n",
    "    # Aplicar la transformada de Fourier 2D\n",
    "    fft_img = torch.fft.fft2(img_tensor)\n",
    "    \n",
    "    # Desplazar el espectro de Fourier para centrar las frecuencias bajas\n",
    "    fft_img_shifted = torch.fft.fftshift(fft_img)\n",
    "\n",
    "    # Calcular la magnitud (energía) de las frecuencias\n",
    "    magnitude = torch.abs(fft_img_shifted)\n",
    "    \n",
    "    # Aplanar la magnitud y obtener los índices de las top-k frecuencias más energéticas\n",
    "    flat_magnitude = magnitude.flatten()\n",
    "    top_k_indices = torch.topk(flat_magnitude, k).indices\n",
    "\n",
    "    # Crear una máscara con ceros\n",
    "    mask = torch.zeros_like(fft_img_shifted, dtype=torch.complex64)\n",
    "    \n",
    "    # Usar los índices para mantener solo las 5 frecuencias más energéticas\n",
    "    for idx in top_k_indices:\n",
    "        # Convertir el índice plano en coordenadas 2D\n",
    "        i, j = np.unravel_index(idx.item(), fft_img_shifted.shape)\n",
    "        mask[i, j] = 1.0  # Dejar pasar solo estas frecuencias\n",
    "\n",
    "    # Aplicar la máscara\n",
    "    fft_filtered = fft_img_shifted * mask\n",
    "    \n",
    "    # Invertir el desplazamiento del espectro\n",
    "    fft_filtered_shifted_back = torch.fft.ifftshift(fft_filtered)\n",
    "    \n",
    "    # Aplicar la transformada inversa de Fourier\n",
    "    img_filtered = torch.fft.ifft2(fft_filtered_shifted_back)\n",
    "    \n",
    "    # Tomar solo la parte real de la imagen filtrada\n",
    "    img_filtered = torch.real(img_filtered)\n",
    "\n",
    "    return img_filtered\n",
    "\n",
    "# Función para mostrar la imagen original y filtrada\n",
    "def plot_images(original, filtered):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original)\n",
    "    plt.title('Imagen Original')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(filtered)\n",
    "    plt.title('Imagen con 5 Frecuencias Más Energéticas')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(torch.abs(original - filtered))\n",
    "    plt.title('Imagen con 5 Frecuencias Más Energéticas')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(torch.sum(torch.abs(original - filtered))/torch.sum(original))\n",
    "\n",
    "\n",
    "# Cargar la imagen\n",
    "img_path = 'ruta/a/tu/imagen.jpg'\n",
    "image = u[429]\n",
    "\n",
    "# Conservar solo las 5 frecuencias más energéticas\n",
    "filtered_image = keep_top_k_frequencies(image, k=50)\n",
    "\n",
    "# Mostrar las imágeness\n",
    "plot_images(image, filtered_image.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
