{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from models.non_constant_diffusivity import NonConstantDiffusivityNeuralNetwork\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: C:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning\\results\\non_linear\n",
      "Folder already exists at: C:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning\\results\\non_linear\\model_fft\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'C:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data\\non_linear\\non_linear_fft_tests.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results\\non_linear')\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results\\non_linear\\model_fft')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: C:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning\\data\\non_linear\\non_linear_fft_tests.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modes_base_and_coeficients(data, n_modes):\n",
    "\n",
    "    # FFT decomposition and obtain energy of each mode\n",
    "    fft_data = torch.fft.fft2(data)\n",
    "    fft_data_shifted = torch.fft.fftshift(fft_data)\n",
    "    energy = torch.abs(fft_data_shifted)\n",
    "    energy_flattened = energy.flatten(1, 2)\n",
    "\n",
    "    # Get the n_modes more energetic modes and their indices\n",
    "    top_energetic = torch.topk(energy_flattened, n_modes).indices\n",
    "    top_energetic_indices, _ = zip(*Counter(top_energetic.flatten()).most_common(n_modes))\n",
    "\n",
    "    # Get base and coefficients\n",
    "    modes_base = list(map(int, top_energetic_indices))\n",
    "    coeficients = fft_data_shifted.flatten(1, 2)[:, top_energetic_indices]\n",
    "\n",
    "    return coeficients, modes_base\n",
    "\n",
    "\n",
    "def reconstruct_data_fft(coeficients, base, data_shape):\n",
    "\n",
    "    # Create the new tensor to allocate filtered modes\n",
    "    filtered_modes = torch.zeros((coeficients.shape[0], data_shape[1]*data_shape[2]), dtype=torch.complex64)\n",
    "    filtered_modes[:, base] = coeficients\n",
    "\n",
    "    # Reshape filtered modes and reconstruct image\n",
    "    filtered_modes_base_fft_shifted =  filtered_modes.reshape(data_shape)\n",
    "    filtered_modes_base = torch.fft.ifftshift(filtered_modes_base_fft_shifted)\n",
    "\n",
    "    reconstructed_data = torch.real(torch.fft.ifft2(filtered_modes_base)) \n",
    "\n",
    "    return reconstructed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = 19\n",
    "\n",
    "u_original = torch.Tensor(dataset['y_train'])\n",
    "u_coeficients, u_modes_base = get_modes_base_and_coeficients(u_original, n_modes)\n",
    "u_reconstructed = reconstruct_data_fft(u_coeficients, u_modes_base, u_original.shape)\n",
    "\n",
    "real_part = u_coeficients.real\n",
    "imag_part = u_coeficients.imag\n",
    "\n",
    "y_train = torch.stack([real_part, imag_part], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train'], dtype=torch.float32, requires_grad=True)\n",
    "f_train = torch.tensor(dataset['f_train'], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "input_size = X_train[0].shape\n",
    "predictive_output_size = y_train[0].shape\n",
    "explanatory_output_size = K_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_data_fft_NN(coeficients, base, data_shape):\n",
    "\n",
    "    # Create the new tensor to allocate filtered modes\n",
    "    filtered_modes = torch.zeros((coeficients.shape[0], data_shape[0]*data_shape[1]), dtype=torch.complex64)\n",
    "    filtered_modes[:, base] = coeficients\n",
    "\n",
    "    # Reshape filtered modes and reconstruct image\n",
    "    filtered_modes_base_fft_shifted =  filtered_modes.reshape((coeficients.shape[0], *data_shape))\n",
    "    filtered_modes_base = torch.fft.ifftshift(filtered_modes_base_fft_shifted)\n",
    "\n",
    "    reconstructed_data = torch.real(torch.fft.ifft2(filtered_modes_base)) \n",
    "\n",
    "    return reconstructed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_original = torch.Tensor(dataset['y_train'])\n",
    "u_coeficients, u_modes_base = get_modes_base_and_coeficients(u_original, n_modes)\n",
    "u_reconstructed = reconstruct_data_fft(u_coeficients, u_modes_base, u_original.shape)\n",
    "\n",
    "real_part = u_coeficients.real\n",
    "imag_part = u_coeficients.imag\n",
    "\n",
    "y_train = torch.stack([real_part, imag_part], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_original = torch.Tensor(dataset['y_val'])\n",
    "u_coeficients, u_modes_base = get_modes_base_and_coeficients(u_original, n_modes)\n",
    "u_reconstructed = reconstruct_data_fft(u_coeficients, u_modes_base, u_original.shape)\n",
    "\n",
    "real_part = u_coeficients.real\n",
    "imag_part = u_coeficients.imag\n",
    "\n",
    "y_val = torch.stack([real_part, imag_part], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de los datos para dividirlos en train y test\n",
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "# y_train = TensOps(fourier_transform_split(dataset['y_train']).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_train = TensOps(torch.tensor(dataset['k_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_train = TensOps(torch.tensor(dataset['f_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "# y_val = TensOps(fourier_transform_split(dataset['y_val']).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "X_np = X_train\n",
    "y_np = y_train\n",
    "K_np = K_train.values\n",
    "f_np = f_train.values\n",
    "\n",
    "X_train_np, X_test_np, y_train_np, y_test_np, K_train_np, K_test_np, f_train_np, f_test_np = train_test_split(X_np, y_np, K_np, f_np, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train_np.to(device)\n",
    "X_test = X_test_np.to(device)\n",
    "\n",
    "y_train = TensOps(y_train_np.requires_grad_(True).to(device), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test_np.requires_grad_(True).to(device), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch 0, Train loss: 1.019e+12, Test loss: 1.002e+12, MSE(e): 1.019e+04, MSE(pi1): 9.006e+00, MSE(pi2): 4.216e+01, MSE(pi3): 2.606e-01\n",
      "Epoch 100, Train loss: 9.515e+11, Test loss: 9.336e+11, MSE(e): 9.515e+03, MSE(pi1): 1.356e+00, MSE(pi2): 4.364e+01, MSE(pi3): 2.013e-01\n",
      "Epoch 200, Train loss: 8.922e+11, Test loss: 8.744e+11, MSE(e): 8.922e+03, MSE(pi1): 6.323e-01, MSE(pi2): 4.203e+01, MSE(pi3): 1.746e-01\n",
      "Epoch 300, Train loss: 8.287e+11, Test loss: 8.118e+11, MSE(e): 8.287e+03, MSE(pi1): 6.523e-01, MSE(pi2): 3.921e+01, MSE(pi3): 1.789e-01\n",
      "Epoch 400, Train loss: 7.660e+11, Test loss: 7.500e+11, MSE(e): 7.660e+03, MSE(pi1): 6.531e-01, MSE(pi2): 3.650e+01, MSE(pi3): 1.791e-01\n",
      "Epoch 500, Train loss: 7.085e+11, Test loss: 6.934e+11, MSE(e): 7.085e+03, MSE(pi1): 6.527e-01, MSE(pi2): 3.397e+01, MSE(pi3): 1.791e-01\n",
      "Epoch 600, Train loss: 6.564e+11, Test loss: 6.422e+11, MSE(e): 6.564e+03, MSE(pi1): 6.523e-01, MSE(pi2): 3.168e+01, MSE(pi3): 1.791e-01\n",
      "Epoch 700, Train loss: 6.071e+11, Test loss: 5.937e+11, MSE(e): 6.071e+03, MSE(pi1): 6.516e-01, MSE(pi2): 2.951e+01, MSE(pi3): 1.791e-01\n",
      "Epoch 800, Train loss: 5.602e+11, Test loss: 5.476e+11, MSE(e): 5.602e+03, MSE(pi1): 6.510e-01, MSE(pi2): 2.744e+01, MSE(pi3): 1.790e-01\n",
      "Epoch 900, Train loss: 5.154e+11, Test loss: 5.037e+11, MSE(e): 5.154e+03, MSE(pi1): 6.508e-01, MSE(pi2): 2.545e+01, MSE(pi3): 1.790e-01\n",
      "Epoch 1000, Train loss: 4.727e+11, Test loss: 4.619e+11, MSE(e): 4.727e+03, MSE(pi1): 6.508e-01, MSE(pi2): 2.355e+01, MSE(pi3): 1.790e-01\n",
      "Epoch 1100, Train loss: 4.322e+11, Test loss: 4.222e+11, MSE(e): 4.322e+03, MSE(pi1): 6.508e-01, MSE(pi2): 2.173e+01, MSE(pi3): 1.790e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m     10\u001b[0m n_checkpoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m---> 12\u001b[0m train_loop(model, optimizer, n_checkpoints,\n\u001b[0;32m     13\u001b[0m            X_train, y_train, X_test, y_test, f_train, f_test,\n\u001b[0;32m     14\u001b[0m            D\u001b[38;5;241m=\u001b[39mD, start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch, n_epochs\u001b[38;5;241m=\u001b[39mn_epochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[0;32m     15\u001b[0m            model_results_path\u001b[38;5;241m=\u001b[39mMODEL_RESULTS_PATH, device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     16\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning\\src_decomposition\\python\\trainers\\train.py:92\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, optimizer, n_checkpoints, X_train, y_train, X_test, y_test, f_train, f_test, D, start_epoch, n_epochs, batch_size, model_results_path, device, new_lr)\u001b[0m\n\u001b[0;32m     89\u001b[0m train_pi2_loss_list\u001b[38;5;241m.\u001b[39mappend(pi2_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39mbatch_size)\n\u001b[0;32m     90\u001b[0m train_pi3_loss_list\u001b[38;5;241m.\u001b[39mappend(pi3_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39mbatch_size)\n\u001b[1;32m---> 92\u001b[0m loss_test, e_loss_test, pi1_loss_test, pi2_loss_test, pi3_loss_test \u001b[38;5;241m=\u001b[39m test_epoch(model, X_test, y_test, f_test, D)\n\u001b[0;32m     94\u001b[0m test_total_loss_list\u001b[38;5;241m.\u001b[39mappend(loss_test\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39mN_test)\n\u001b[0;32m     95\u001b[0m test_e_loss_list\u001b[38;5;241m.\u001b[39mappend(e_loss_test\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39mN_test)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning\\src_decomposition\\python\\trainers\\train.py:24\u001b[0m, in \u001b[0;36mtest_epoch\u001b[1;34m(model, X_test, y_test, f_test, D)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_epoch\u001b[39m(model, X_test, y_test, f_test, D):\n\u001b[1;32m---> 24\u001b[0m     y_pred, u_pred, K_pred \u001b[38;5;241m=\u001b[39m model(X_test)\n\u001b[0;32m     25\u001b[0m     loss, e_loss, pi1_loss, pi2_loss, pi3_loss \u001b[38;5;241m=\u001b[39m loss_function(X_test, y_test, y_pred, u_pred, K_pred, f_test, D)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, e_loss, pi1_loss, pi2_loss, pi3_loss\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\SciML_test_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\SciML_test_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[43], line 56\u001b[0m, in \u001b[0;36mFFTNeuralNetwork.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     53\u001b[0m um_pred \u001b[38;5;241m=\u001b[39m Mx(My(TensOps(u_pred, space_dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, contravariance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, covariance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)))\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Explanatory network\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_exp(um_pred))\n\u001b[0;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten_layer_exp(x)\n\u001b[0;32m     58\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden1_layer_exp(x))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Se carga el modelo y el optimizador\n",
    "model = FFTNeuralNetwork(input_size, predictive_output_size, explanatory_output_size, modes_base=u_modes_base)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 2000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 100\n",
    "\n",
    "train_loop(model, optimizer, n_checkpoints,\n",
    "           X_train, y_train, X_test, y_test, f_train, f_test,\n",
    "           D=D, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=device,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
