{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from models.constant_diffusivity import ConstantDiffusivityNeuralNetwork\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: C:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning\\results\\linear_homogeneous\n",
      "Folder already exists at: C:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning\\results\\linear_homogeneous\\modelo_prueba\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'C:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data\\linear_homogeneous\\linear_homogeneous.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results\\linear_homogeneous')\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results\\linear_homogeneous\\modelo_prueba')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: C:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning\\data\\linear_homogeneous\\linear_homogeneous.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de los datos para dividirlos en train y test\n",
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = TensOps(torch.tensor(dataset['y_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_train = TensOps(torch.tensor(dataset['k_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "X_np = X_train\n",
    "y_np = y_train.values\n",
    "K_np = K_train.values\n",
    "\n",
    "X_train_np, X_test_np, y_train_np, y_test_np, K_train_np, K_test_np = train_test_split(X_np, y_np, K_np, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train_np\n",
    "X_test = X_test_np\n",
    "\n",
    "y_train = TensOps(y_train_np, space_dimension=y_train.space_dim, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test_np, space_dimension=y_train.space_dim, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train_np, space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test_np, space_dimension=K_train.space_dim, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitectura del modelo\n",
    "input_shape = X_train[0].shape  # [1, 10, 8]\n",
    "hidden1_dim = 10\n",
    "hidden2_dim = 10\n",
    "output_shape = y_train.values[0].shape  # [1, 10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se carga el modelo y el optimizador\n",
    "model = ConstantDiffusivityNeuralNetwork(input_shape, hidden1_dim, hidden2_dim, output_shape)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 100\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch 0, Train loss: 5.323e+09, Test loss: 1.630e+10, MSE(e): 3.113e+02, MSE(pi1): 2.086e+05, MSE(pi2): 1.509e+02, MSE(pi3): 1.235e+03\n",
      "Epoch 10, Train loss: 5.200e+09, Test loss: 1.594e+10, MSE(e): 3.107e+02, MSE(pi1): 1.971e+05, MSE(pi2): 1.507e+02, MSE(pi3): 1.221e+03\n",
      "Epoch 20, Train loss: 5.084e+09, Test loss: 1.560e+10, MSE(e): 3.100e+02, MSE(pi1): 1.862e+05, MSE(pi2): 1.505e+02, MSE(pi3): 1.209e+03\n",
      "Epoch 30, Train loss: 4.973e+09, Test loss: 1.528e+10, MSE(e): 3.094e+02, MSE(pi1): 1.759e+05, MSE(pi2): 1.502e+02, MSE(pi3): 1.197e+03\n",
      "Epoch 40, Train loss: 4.869e+09, Test loss: 1.497e+10, MSE(e): 3.088e+02, MSE(pi1): 1.662e+05, MSE(pi2): 1.500e+02, MSE(pi3): 1.185e+03\n",
      "Epoch 50, Train loss: 4.770e+09, Test loss: 1.469e+10, MSE(e): 3.083e+02, MSE(pi1): 1.569e+05, MSE(pi2): 1.498e+02, MSE(pi3): 1.174e+03\n",
      "Epoch 60, Train loss: 4.676e+09, Test loss: 1.441e+10, MSE(e): 3.077e+02, MSE(pi1): 1.482e+05, MSE(pi2): 1.496e+02, MSE(pi3): 1.164e+03\n",
      "Epoch 70, Train loss: 4.587e+09, Test loss: 1.415e+10, MSE(e): 3.072e+02, MSE(pi1): 1.400e+05, MSE(pi2): 1.494e+02, MSE(pi3): 1.153e+03\n",
      "Epoch 80, Train loss: 4.503e+09, Test loss: 1.391e+10, MSE(e): 3.067e+02, MSE(pi1): 1.322e+05, MSE(pi2): 1.492e+02, MSE(pi3): 1.143e+03\n",
      "Epoch 90, Train loss: 4.424e+09, Test loss: 1.368e+10, MSE(e): 3.062e+02, MSE(pi1): 1.248e+05, MSE(pi2): 1.491e+02, MSE(pi3): 1.132e+03\n",
      "\n",
      "Proceso finalizado después de 100 épocas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, optimizer, n_checkpoints,\n",
    "           X_train, y_train, X_test, y_test, D=D, \n",
    "           start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
