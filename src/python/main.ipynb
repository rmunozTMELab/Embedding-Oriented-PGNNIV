{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from models.non_constant_diffusivity import NonConstantDiffusivityNeuralNetwork\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear/model_paper\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/non_linear/non_linear.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/non_linear')\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/non_linear/model_paper')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear/non_linear.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de los datos para dividirlos en train y test\n",
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = TensOps(torch.tensor(dataset['y_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_train = TensOps(torch.tensor(dataset['k_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_train = TensOps(torch.tensor(dataset['f_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "X_np = X_train\n",
    "y_np = y_train.values\n",
    "K_np = K_train.values\n",
    "f_np = f_train.values\n",
    "\n",
    "X_train_np, X_test_np, y_train_np, y_test_np, K_train_np, K_test_np, f_train_np, f_test_np = train_test_split(X_np, y_np, K_np, f_np, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train_np.to(device)\n",
    "X_test = X_test_np.to(device)\n",
    "\n",
    "y_train = TensOps(y_train_np.to(device), space_dimension=y_train.space_dim, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test_np.to(device), space_dimension=y_train.space_dim, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitectura del modelo\n",
    "input_shape = X_train[0].shape  # [1, 10, 8]\n",
    "hidden1_dim = 150\n",
    "hidden2_dim = 150\n",
    "output_shape = y_train.values[0].shape  # [1, 10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch 0, Train loss: 4.800e+07, Test loss: 3.730e+07, MSE(e): 4.790e+00, MSE(pi1): 7.446e+00, MSE(pi2): 2.091e+00, MSE(pi3): 2.474e-01\n",
      "Epoch 100, Train loss: 2.751e+04, Test loss: 2.505e+04, MSE(e): 1.867e-03, MSE(pi1): 2.673e-01, MSE(pi2): 1.200e-03, MSE(pi3): 6.164e-02\n",
      "Epoch 200, Train loss: 5.887e+03, Test loss: 5.100e+03, MSE(e): 4.681e-04, MSE(pi1): 7.559e-02, MSE(pi2): 3.230e-04, MSE(pi3): 4.496e-03\n",
      "Epoch 300, Train loss: 7.087e+03, Test loss: 4.187e+03, MSE(e): 6.206e-04, MSE(pi1): 6.209e-02, MSE(pi2): 3.596e-04, MSE(pi3): 2.593e-03\n",
      "Epoch 400, Train loss: 5.566e+03, Test loss: 3.775e+03, MSE(e): 4.924e-04, MSE(pi1): 4.123e-02, MSE(pi2): 2.599e-04, MSE(pi3): 2.296e-03\n",
      "Epoch 500, Train loss: 4.996e+03, Test loss: 3.354e+03, MSE(e): 4.403e-04, MSE(pi1): 3.881e-02, MSE(pi2): 2.342e-04, MSE(pi3): 2.039e-03\n",
      "Epoch 600, Train loss: 3.299e+03, Test loss: 3.529e+03, MSE(e): 2.589e-04, MSE(pi1): 5.221e-02, MSE(pi2): 1.409e-04, MSE(pi3): 1.878e-03\n",
      "Epoch 700, Train loss: 1.154e+03, Test loss: 1.320e+03, MSE(e): 8.731e-05, MSE(pi1): 1.562e-02, MSE(pi2): 6.133e-05, MSE(pi3): 1.252e-03\n",
      "Epoch 800, Train loss: 9.640e+02, Test loss: 9.892e+02, MSE(e): 6.860e-05, MSE(pi1): 1.582e-02, MSE(pi2): 4.710e-05, MSE(pi3): 1.197e-03\n",
      "Epoch 900, Train loss: 8.819e+02, Test loss: 7.835e+02, MSE(e): 6.200e-05, MSE(pi1): 1.592e-02, MSE(pi2): 4.190e-05, MSE(pi3): 1.027e-03\n",
      "Epoch 1000, Train loss: 1.972e+03, Test loss: 1.127e+03, MSE(e): 1.723e-04, MSE(pi1): 1.467e-02, MSE(pi2): 9.189e-05, MSE(pi3): 1.016e-03\n",
      "Epoch 1100, Train loss: 7.194e+02, Test loss: 1.004e+03, MSE(e): 4.663e-05, MSE(pi1): 1.568e-02, MSE(pi2): 2.852e-05, MSE(pi3): 9.616e-04\n",
      "Epoch 1200, Train loss: 6.686e+02, Test loss: 5.237e+02, MSE(e): 3.986e-05, MSE(pi1): 1.767e-02, MSE(pi2): 2.298e-05, MSE(pi3): 9.323e-04\n",
      "Epoch 1300, Train loss: 1.167e+03, Test loss: 6.080e+02, MSE(e): 9.559e-05, MSE(pi1): 1.186e-02, MSE(pi2): 5.218e-05, MSE(pi3): 9.247e-04\n",
      "Epoch 1400, Train loss: 4.230e+02, Test loss: 4.921e+02, MSE(e): 2.528e-05, MSE(pi1): 9.249e-03, MSE(pi2): 1.753e-05, MSE(pi3): 7.771e-04\n",
      "Epoch 1500, Train loss: 1.993e+03, Test loss: 9.382e+02, MSE(e): 1.782e-04, MSE(pi1): 1.240e-02, MSE(pi2): 8.381e-05, MSE(pi3): 8.699e-04\n",
      "Epoch 1600, Train loss: 3.474e+02, Test loss: 3.634e+02, MSE(e): 2.027e-05, MSE(pi1): 6.698e-03, MSE(pi2): 1.376e-05, MSE(pi3): 7.764e-04\n",
      "Epoch 1700, Train loss: 3.627e+02, Test loss: 4.070e+02, MSE(e): 1.973e-05, MSE(pi1): 8.317e-03, MSE(pi2): 1.215e-05, MSE(pi3): 8.223e-04\n",
      "Epoch 1800, Train loss: 3.204e+02, Test loss: 4.853e+02, MSE(e): 1.807e-05, MSE(pi1): 6.012e-03, MSE(pi2): 1.145e-05, MSE(pi3): 7.959e-04\n",
      "Epoch 1900, Train loss: 2.977e+02, Test loss: 3.320e+02, MSE(e): 1.459e-05, MSE(pi1): 7.898e-03, MSE(pi2): 9.690e-06, MSE(pi3): 7.277e-04\n",
      "Epoch 2000, Train loss: 1.203e+03, Test loss: 8.017e+02, MSE(e): 1.066e-04, MSE(pi1): 5.609e-03, MSE(pi2): 4.883e-05, MSE(pi3): 8.105e-04\n",
      "Epoch 2100, Train loss: 5.842e+02, Test loss: 9.760e+02, MSE(e): 4.332e-05, MSE(pi1): 7.484e-03, MSE(pi2): 2.215e-05, MSE(pi3): 7.614e-04\n",
      "Epoch 2200, Train loss: 2.968e+02, Test loss: 3.926e+02, MSE(e): 1.548e-05, MSE(pi1): 6.449e-03, MSE(pi2): 9.438e-06, MSE(pi3): 7.745e-04\n",
      "Epoch 2300, Train loss: 3.479e+02, Test loss: 3.209e+02, MSE(e): 1.991e-05, MSE(pi1): 7.157e-03, MSE(pi2): 1.171e-05, MSE(pi3): 7.725e-04\n",
      "Epoch 2400, Train loss: 2.601e+02, Test loss: 3.241e+02, MSE(e): 1.276e-05, MSE(pi1): 5.426e-03, MSE(pi2): 6.876e-06, MSE(pi3): 7.820e-04\n",
      "Epoch 2500, Train loss: 6.594e+02, Test loss: 5.414e+02, MSE(e): 5.401e-05, MSE(pi1): 4.245e-03, MSE(pi2): 2.343e-05, MSE(pi3): 7.682e-04\n",
      "Epoch 2600, Train loss: 2.859e+02, Test loss: 4.313e+02, MSE(e): 1.133e-05, MSE(pi1): 1.029e-02, MSE(pi2): 6.404e-06, MSE(pi3): 6.968e-04\n",
      "Epoch 2700, Train loss: 9.572e+02, Test loss: 6.413e+02, MSE(e): 8.082e-05, MSE(pi1): 6.343e-03, MSE(pi2): 3.839e-05, MSE(pi3): 8.546e-04\n",
      "Epoch 2800, Train loss: 6.148e+02, Test loss: 3.308e+02, MSE(e): 4.587e-05, MSE(pi1): 7.658e-03, MSE(pi2): 2.139e-05, MSE(pi3): 7.945e-04\n",
      "Epoch 2900, Train loss: 2.287e+02, Test loss: 2.351e+02, MSE(e): 8.760e-06, MSE(pi1): 6.644e-03, MSE(pi2): 4.672e-06, MSE(pi3): 7.469e-04\n",
      "Epoch 3000, Train loss: 3.575e+02, Test loss: 2.478e+03, MSE(e): 2.007e-05, MSE(pi1): 8.747e-03, MSE(pi2): 8.389e-06, MSE(pi3): 6.934e-04\n",
      "Epoch 3100, Train loss: 1.990e+02, Test loss: 2.159e+02, MSE(e): 7.392e-06, MSE(pi1): 5.564e-03, MSE(pi2): 4.055e-06, MSE(pi3): 6.941e-04\n",
      "Epoch 3200, Train loss: 2.504e+02, Test loss: 2.511e+02, MSE(e): 1.241e-05, MSE(pi1): 4.892e-03, MSE(pi2): 6.206e-06, MSE(pi3): 7.743e-04\n",
      "Epoch 3300, Train loss: 1.957e+02, Test loss: 2.161e+02, MSE(e): 7.281e-06, MSE(pi1): 5.155e-03, MSE(pi2): 4.169e-06, MSE(pi3): 7.139e-04\n",
      "Epoch 3400, Train loss: 2.139e+02, Test loss: 2.391e+02, MSE(e): 7.090e-06, MSE(pi1): 7.284e-03, MSE(pi2): 3.626e-06, MSE(pi3): 7.016e-04\n",
      "Epoch 3500, Train loss: 2.209e+02, Test loss: 2.861e+02, MSE(e): 9.540e-06, MSE(pi1): 5.656e-03, MSE(pi2): 5.474e-06, MSE(pi3): 6.892e-04\n",
      "Epoch 3600, Train loss: 2.234e+02, Test loss: 2.683e+02, MSE(e): 7.797e-06, MSE(pi1): 7.475e-03, MSE(pi2): 4.647e-06, MSE(pi3): 7.072e-04\n",
      "Epoch 3700, Train loss: 5.866e+02, Test loss: 7.476e+02, MSE(e): 4.589e-05, MSE(pi1): 4.958e-03, MSE(pi2): 2.298e-05, MSE(pi3): 7.809e-04\n",
      "Epoch 3800, Train loss: 7.579e+02, Test loss: 6.068e+02, MSE(e): 6.277e-05, MSE(pi1): 5.524e-03, MSE(pi2): 2.900e-05, MSE(pi3): 7.495e-04\n",
      "Epoch 3900, Train loss: 2.537e+02, Test loss: 3.088e+02, MSE(e): 9.890e-06, MSE(pi1): 7.825e-03, MSE(pi2): 4.329e-06, MSE(pi3): 7.655e-04\n",
      "Epoch 4000, Train loss: 4.408e+02, Test loss: 6.200e+02, MSE(e): 1.911e-05, MSE(pi1): 1.677e-02, MSE(pi2): 8.597e-06, MSE(pi3): 8.200e-04\n",
      "Epoch 4100, Train loss: 2.108e+02, Test loss: 2.094e+02, MSE(e): 8.585e-06, MSE(pi1): 5.634e-03, MSE(pi2): 4.270e-06, MSE(pi3): 6.856e-04\n",
      "Epoch 4200, Train loss: 2.709e+02, Test loss: 2.330e+02, MSE(e): 1.402e-05, MSE(pi1): 4.849e-03, MSE(pi2): 6.186e-06, MSE(pi3): 8.218e-04\n",
      "Epoch 4300, Train loss: 1.782e+02, Test loss: 2.000e+02, MSE(e): 5.843e-06, MSE(pi1): 5.054e-03, MSE(pi2): 3.324e-06, MSE(pi3): 6.919e-04\n",
      "Epoch 4400, Train loss: 1.721e+02, Test loss: 1.918e+02, MSE(e): 5.536e-06, MSE(pi1): 4.676e-03, MSE(pi2): 3.034e-06, MSE(pi3): 6.996e-04\n",
      "Epoch 4500, Train loss: 1.670e+02, Test loss: 2.201e+02, MSE(e): 5.141e-06, MSE(pi1): 3.852e-03, MSE(pi2): 2.622e-06, MSE(pi3): 7.708e-04\n",
      "Epoch 4600, Train loss: 5.793e+02, Test loss: 3.562e+02, MSE(e): 4.594e-05, MSE(pi1): 4.513e-03, MSE(pi2): 2.078e-05, MSE(pi3): 7.472e-04\n",
      "Epoch 4700, Train loss: 1.507e+02, Test loss: 2.443e+02, MSE(e): 3.886e-06, MSE(pi1): 4.053e-03, MSE(pi2): 2.138e-06, MSE(pi3): 7.136e-04\n",
      "Epoch 4800, Train loss: 1.544e+02, Test loss: 2.426e+02, MSE(e): 3.888e-06, MSE(pi1): 4.587e-03, MSE(pi2): 2.279e-06, MSE(pi3): 6.963e-04\n",
      "Epoch 4900, Train loss: 1.457e+02, Test loss: 2.223e+02, MSE(e): 3.738e-06, MSE(pi1): 3.710e-03, MSE(pi2): 2.134e-06, MSE(pi3): 7.124e-04\n",
      "Epoch 5000, Train loss: 2.580e+02, Test loss: 2.275e+02, MSE(e): 1.151e-05, MSE(pi1): 7.787e-03, MSE(pi2): 5.805e-06, MSE(pi3): 6.511e-04\n",
      "Epoch 5100, Train loss: 1.677e+02, Test loss: 1.456e+02, MSE(e): 6.876e-06, MSE(pi1): 2.528e-03, MSE(pi2): 3.198e-06, MSE(pi3): 7.363e-04\n",
      "Epoch 5200, Train loss: 1.546e+02, Test loss: 1.746e+02, MSE(e): 3.129e-06, MSE(pi1): 5.516e-03, MSE(pi2): 1.683e-06, MSE(pi3): 6.818e-04\n",
      "Epoch 5300, Train loss: 3.741e+02, Test loss: 2.899e+02, MSE(e): 2.728e-05, MSE(pi1): 2.508e-03, MSE(pi2): 1.319e-05, MSE(pi3): 7.617e-04\n",
      "Epoch 5400, Train loss: 1.885e+02, Test loss: 2.346e+02, MSE(e): 7.095e-06, MSE(pi1): 5.061e-03, MSE(pi2): 3.804e-06, MSE(pi3): 6.696e-04\n",
      "Epoch 5500, Train loss: 2.755e+02, Test loss: 2.857e+02, MSE(e): 1.272e-05, MSE(pi1): 7.851e-03, MSE(pi2): 5.236e-06, MSE(pi3): 6.974e-04\n",
      "Epoch 5600, Train loss: 2.528e+02, Test loss: 2.174e+02, MSE(e): 1.338e-05, MSE(pi1): 4.858e-03, MSE(pi2): 6.978e-06, MSE(pi3): 7.045e-04\n",
      "Epoch 5700, Train loss: 4.559e+02, Test loss: 6.667e+02, MSE(e): 3.115e-05, MSE(pi1): 7.758e-03, MSE(pi2): 1.484e-05, MSE(pi3): 6.686e-04\n",
      "Epoch 5800, Train loss: 1.528e+02, Test loss: 1.984e+02, MSE(e): 3.621e-06, MSE(pi1): 4.782e-03, MSE(pi2): 1.805e-06, MSE(pi3): 6.880e-04\n",
      "Epoch 5900, Train loss: 1.760e+02, Test loss: 1.673e+02, MSE(e): 3.656e-06, MSE(pi1): 6.892e-03, MSE(pi2): 1.933e-06, MSE(pi3): 7.047e-04\n",
      "Epoch 6000, Train loss: 1.753e+02, Test loss: 2.713e+02, MSE(e): 4.975e-06, MSE(pi1): 5.306e-03, MSE(pi2): 2.680e-06, MSE(pi3): 7.244e-04\n",
      "Epoch 6100, Train loss: 1.278e+02, Test loss: 1.665e+02, MSE(e): 2.482e-06, MSE(pi1): 3.224e-03, MSE(pi2): 1.523e-06, MSE(pi3): 7.078e-04\n",
      "Epoch 6200, Train loss: 8.809e+02, Test loss: 9.145e+02, MSE(e): 7.644e-05, MSE(pi1): 4.483e-03, MSE(pi2): 3.300e-05, MSE(pi3): 7.160e-04\n",
      "Epoch 6300, Train loss: 2.578e+02, Test loss: 5.962e+02, MSE(e): 1.077e-05, MSE(pi1): 7.825e-03, MSE(pi2): 4.828e-06, MSE(pi3): 7.181e-04\n",
      "Epoch 6400, Train loss: 1.694e+02, Test loss: 1.800e+02, MSE(e): 5.446e-06, MSE(pi1): 4.041e-03, MSE(pi2): 2.376e-06, MSE(pi3): 7.451e-04\n",
      "Epoch 6500, Train loss: 1.500e+02, Test loss: 1.392e+02, MSE(e): 4.176e-06, MSE(pi1): 3.869e-03, MSE(pi2): 2.022e-06, MSE(pi3): 6.954e-04\n",
      "Epoch 6600, Train loss: 1.450e+02, Test loss: 1.418e+02, MSE(e): 4.100e-06, MSE(pi1): 3.258e-03, MSE(pi2): 1.825e-06, MSE(pi3): 7.138e-04\n",
      "Epoch 6700, Train loss: 1.415e+02, Test loss: 1.676e+02, MSE(e): 3.461e-06, MSE(pi1): 3.668e-03, MSE(pi2): 1.810e-06, MSE(pi3): 7.021e-04\n",
      "Epoch 6800, Train loss: 1.369e+02, Test loss: 1.945e+02, MSE(e): 3.178e-06, MSE(pi1): 3.173e-03, MSE(pi2): 1.427e-06, MSE(pi3): 7.335e-04\n",
      "Epoch 6900, Train loss: 1.517e+02, Test loss: 1.837e+02, MSE(e): 4.227e-06, MSE(pi1): 3.939e-03, MSE(pi2): 2.020e-06, MSE(pi3): 7.002e-04\n",
      "Epoch 7000, Train loss: 1.564e+02, Test loss: 1.655e+02, MSE(e): 5.006e-06, MSE(pi1): 3.472e-03, MSE(pi2): 2.239e-06, MSE(pi3): 7.160e-04\n",
      "Epoch 7100, Train loss: 3.204e+02, Test loss: 2.181e+02, MSE(e): 1.988e-05, MSE(pi1): 4.041e-03, MSE(pi2): 1.029e-05, MSE(pi3): 8.121e-04\n",
      "Epoch 7200, Train loss: 1.889e+02, Test loss: 1.916e+02, MSE(e): 8.133e-06, MSE(pi1): 3.453e-03, MSE(pi2): 3.440e-06, MSE(pi3): 7.301e-04\n",
      "Epoch 7300, Train loss: 1.480e+02, Test loss: 1.750e+02, MSE(e): 3.468e-06, MSE(pi1): 4.096e-03, MSE(pi2): 1.402e-06, MSE(pi3): 7.240e-04\n",
      "Epoch 7400, Train loss: 2.189e+02, Test loss: 3.676e+02, MSE(e): 6.926e-06, MSE(pi1): 7.189e-03, MSE(pi2): 3.614e-06, MSE(pi3): 7.776e-04\n",
      "Epoch 7500, Train loss: 1.814e+02, Test loss: 1.702e+02, MSE(e): 8.149e-06, MSE(pi1): 3.079e-03, MSE(pi2): 4.138e-06, MSE(pi3): 6.914e-04\n",
      "Epoch 7600, Train loss: 1.423e+02, Test loss: 2.163e+02, MSE(e): 3.120e-06, MSE(pi1): 3.632e-03, MSE(pi2): 1.498e-06, MSE(pi3): 7.473e-04\n",
      "Epoch 7700, Train loss: 1.521e+02, Test loss: 1.841e+02, MSE(e): 3.230e-06, MSE(pi1): 4.450e-03, MSE(pi2): 1.518e-06, MSE(pi3): 7.529e-04\n",
      "Epoch 7800, Train loss: 6.283e+02, Test loss: 7.560e+02, MSE(e): 5.235e-05, MSE(pi1): 3.702e-03, MSE(pi2): 2.448e-05, MSE(pi3): 6.782e-04\n",
      "Epoch 7900, Train loss: 1.268e+02, Test loss: 1.375e+02, MSE(e): 2.721e-06, MSE(pi1): 2.806e-03, MSE(pi2): 1.254e-06, MSE(pi3): 7.149e-04\n",
      "Epoch 8000, Train loss: 2.021e+02, Test loss: 3.968e+02, MSE(e): 1.023e-05, MSE(pi1): 2.778e-03, MSE(pi2): 4.747e-06, MSE(pi3): 7.205e-04\n",
      "Epoch 8100, Train loss: 1.396e+02, Test loss: 1.561e+02, MSE(e): 3.496e-06, MSE(pi1): 2.862e-03, MSE(pi2): 1.470e-06, MSE(pi3): 7.606e-04\n",
      "Epoch 8200, Train loss: 1.729e+02, Test loss: 2.070e+02, MSE(e): 6.652e-06, MSE(pi1): 3.444e-03, MSE(pi2): 3.445e-06, MSE(pi3): 7.197e-04\n",
      "Epoch 8300, Train loss: 1.422e+02, Test loss: 1.792e+02, MSE(e): 3.471e-06, MSE(pi1): 3.400e-03, MSE(pi2): 1.506e-06, MSE(pi3): 7.345e-04\n",
      "Epoch 8400, Train loss: 1.598e+03, Test loss: 6.549e+02, MSE(e): 1.483e-04, MSE(pi1): 4.969e-03, MSE(pi2): 6.903e-05, MSE(pi3): 6.487e-04\n",
      "Epoch 8500, Train loss: 1.779e+02, Test loss: 1.766e+02, MSE(e): 5.293e-06, MSE(pi1): 5.382e-03, MSE(pi2): 2.100e-06, MSE(pi3): 7.118e-04\n",
      "Epoch 8600, Train loss: 1.743e+02, Test loss: 2.575e+02, MSE(e): 6.951e-06, MSE(pi1): 3.381e-03, MSE(pi2): 3.549e-06, MSE(pi3): 7.101e-04\n",
      "Epoch 8700, Train loss: 1.818e+02, Test loss: 1.846e+02, MSE(e): 4.507e-06, MSE(pi1): 6.316e-03, MSE(pi2): 1.852e-06, MSE(pi3): 7.352e-04\n",
      "Epoch 8800, Train loss: 4.908e+02, Test loss: 3.313e+02, MSE(e): 3.851e-05, MSE(pi1): 3.393e-03, MSE(pi2): 1.673e-05, MSE(pi3): 7.176e-04\n",
      "Epoch 8900, Train loss: 1.298e+02, Test loss: 1.667e+02, MSE(e): 2.675e-06, MSE(pi1): 3.090e-03, MSE(pi2): 1.225e-06, MSE(pi3): 7.210e-04\n",
      "Epoch 9000, Train loss: 1.365e+02, Test loss: 1.437e+02, MSE(e): 2.992e-06, MSE(pi1): 3.438e-03, MSE(pi2): 1.329e-06, MSE(pi3): 7.216e-04\n",
      "Epoch 9100, Train loss: 1.595e+02, Test loss: 1.501e+02, MSE(e): 4.765e-06, MSE(pi1): 3.902e-03, MSE(pi2): 2.096e-06, MSE(pi3): 7.286e-04\n",
      "Epoch 9200, Train loss: 2.051e+02, Test loss: 2.456e+02, MSE(e): 5.788e-06, MSE(pi1): 6.957e-03, MSE(pi2): 2.299e-06, MSE(pi3): 7.769e-04\n",
      "Epoch 9300, Train loss: 1.404e+02, Test loss: 1.485e+02, MSE(e): 3.556e-06, MSE(pi1): 3.017e-03, MSE(pi2): 1.398e-06, MSE(pi3): 7.469e-04\n",
      "Epoch 9400, Train loss: 2.012e+02, Test loss: 2.250e+02, MSE(e): 9.024e-06, MSE(pi1): 3.677e-03, MSE(pi2): 4.195e-06, MSE(pi3): 7.419e-04\n",
      "Epoch 9500, Train loss: 1.743e+02, Test loss: 2.119e+02, MSE(e): 4.881e-06, MSE(pi1): 5.777e-03, MSE(pi2): 1.985e-06, MSE(pi3): 6.772e-04\n",
      "Epoch 9600, Train loss: 1.403e+02, Test loss: 2.274e+02, MSE(e): 3.414e-06, MSE(pi1): 3.791e-03, MSE(pi2): 1.554e-06, MSE(pi3): 6.824e-04\n",
      "Epoch 9700, Train loss: 6.683e+02, Test loss: 8.011e+02, MSE(e): 5.600e-05, MSE(pi1): 4.105e-03, MSE(pi2): 2.700e-05, MSE(pi3): 6.719e-04\n",
      "Epoch 9800, Train loss: 1.290e+02, Test loss: 1.542e+02, MSE(e): 1.875e-06, MSE(pi1): 3.645e-03, MSE(pi2): 8.454e-07, MSE(pi3): 7.383e-04\n",
      "Epoch 9900, Train loss: 1.298e+02, Test loss: 1.275e+02, MSE(e): 2.032e-06, MSE(pi1): 3.899e-03, MSE(pi2): 8.275e-07, MSE(pi3): 7.052e-04\n",
      "Epoch 10000, Train loss: 1.291e+02, Test loss: 1.719e+02, MSE(e): 2.183e-06, MSE(pi1): 3.502e-03, MSE(pi2): 8.812e-07, MSE(pi3): 7.221e-04\n",
      "\n",
      "Proceso finalizado después de 10001 épocas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se carga el modelo y el optimizador\n",
    "model = NonConstantDiffusivityNeuralNetwork(input_shape, hidden1_dim, hidden2_dim, output_shape).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 10001\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 100\n",
    "\n",
    "train_loop(model, optimizer, n_checkpoints,\n",
    "           X_train, y_train, X_test, y_test, f_train, f_test,\n",
    "           D=D, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=device,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Starting from a checkpoint. Epoch 10000.\n",
      "Epoch 10000, Train loss: 1.530e+02, Test loss: 1.714e+02, MSE(e): 4.862e-06, MSE(pi1): 3.315e-03, MSE(pi2): 2.445e-06, MSE(pi3): 7.124e-04\n",
      "Epoch 10100, Train loss: 1.934e+02, Test loss: 1.650e+02, MSE(e): 7.075e-06, MSE(pi1): 5.581e-03, MSE(pi2): 3.365e-06, MSE(pi3): 6.689e-04\n",
      "Epoch 10200, Train loss: 1.542e+02, Test loss: 1.903e+02, MSE(e): 3.392e-06, MSE(pi1): 4.427e-03, MSE(pi2): 1.527e-06, MSE(pi3): 7.596e-04\n",
      "Epoch 10300, Train loss: 1.280e+02, Test loss: 1.449e+02, MSE(e): 2.225e-06, MSE(pi1): 3.672e-03, MSE(pi2): 1.069e-06, MSE(pi3): 6.900e-04\n",
      "Epoch 10400, Train loss: 1.698e+02, Test loss: 1.573e+02, MSE(e): 4.589e-06, MSE(pi1): 5.057e-03, MSE(pi2): 2.562e-06, MSE(pi3): 7.329e-04\n",
      "Epoch 10500, Train loss: 1.447e+02, Test loss: 1.983e+02, MSE(e): 3.097e-06, MSE(pi1): 3.892e-03, MSE(pi2): 1.309e-06, MSE(pi3): 7.477e-04\n",
      "Epoch 10600, Train loss: 1.154e+02, Test loss: 1.261e+02, MSE(e): 1.521e-06, MSE(pi1): 2.804e-03, MSE(pi2): 6.740e-07, MSE(pi3): 7.213e-04\n",
      "Epoch 10700, Train loss: 1.352e+02, Test loss: 1.878e+02, MSE(e): 2.499e-06, MSE(pi1): 4.226e-03, MSE(pi2): 1.250e-06, MSE(pi3): 6.795e-04\n",
      "Epoch 10800, Train loss: 1.622e+02, Test loss: 1.676e+02, MSE(e): 5.459e-06, MSE(pi1): 3.792e-03, MSE(pi2): 2.376e-06, MSE(pi3): 6.970e-04\n",
      "Epoch 10900, Train loss: 1.561e+02, Test loss: 2.021e+02, MSE(e): 4.511e-06, MSE(pi1): 3.657e-03, MSE(pi2): 2.327e-06, MSE(pi3): 7.446e-04\n",
      "Epoch 11000, Train loss: 1.268e+02, Test loss: 1.562e+02, MSE(e): 2.104e-06, MSE(pi1): 3.092e-03, MSE(pi2): 8.537e-07, MSE(pi3): 7.489e-04\n",
      "Epoch 11100, Train loss: 1.334e+02, Test loss: 1.502e+02, MSE(e): 2.629e-06, MSE(pi1): 3.946e-03, MSE(pi2): 1.242e-06, MSE(pi3): 6.762e-04\n",
      "Epoch 11200, Train loss: 1.440e+02, Test loss: 1.242e+02, MSE(e): 4.454e-06, MSE(pi1): 2.735e-03, MSE(pi2): 2.121e-06, MSE(pi3): 7.209e-04\n",
      "Epoch 11300, Train loss: 1.390e+02, Test loss: 2.117e+02, MSE(e): 2.580e-06, MSE(pi1): 3.880e-03, MSE(pi2): 1.236e-06, MSE(pi3): 7.440e-04\n",
      "Epoch 11400, Train loss: 1.202e+02, Test loss: 1.200e+02, MSE(e): 2.402e-06, MSE(pi1): 2.582e-03, MSE(pi2): 1.119e-06, MSE(pi3): 7.036e-04\n",
      "Epoch 11500, Train loss: 1.253e+02, Test loss: 1.297e+02, MSE(e): 2.055e-06, MSE(pi1): 3.357e-03, MSE(pi2): 8.447e-07, MSE(pi3): 7.117e-04\n",
      "Epoch 11600, Train loss: 1.373e+02, Test loss: 1.496e+02, MSE(e): 3.348e-06, MSE(pi1): 3.515e-03, MSE(pi2): 1.626e-06, MSE(pi3): 6.862e-04\n",
      "Epoch 11700, Train loss: 1.333e+02, Test loss: 1.505e+02, MSE(e): 2.981e-06, MSE(pi1): 3.401e-03, MSE(pi2): 1.170e-06, MSE(pi3): 6.948e-04\n",
      "Epoch 11800, Train loss: 1.239e+02, Test loss: 1.644e+02, MSE(e): 1.887e-06, MSE(pi1): 3.203e-03, MSE(pi2): 7.709e-07, MSE(pi3): 7.297e-04\n",
      "Epoch 11900, Train loss: 1.383e+02, Test loss: 1.625e+02, MSE(e): 3.089e-06, MSE(pi1): 3.859e-03, MSE(pi2): 1.321e-06, MSE(pi3): 6.882e-04\n",
      "Epoch 12000, Train loss: 2.618e+02, Test loss: 2.274e+02, MSE(e): 1.554e-05, MSE(pi1): 2.519e-03, MSE(pi2): 7.131e-06, MSE(pi3): 8.125e-04\n",
      "Epoch 12100, Train loss: 1.205e+02, Test loss: 1.340e+02, MSE(e): 2.424e-06, MSE(pi1): 2.420e-03, MSE(pi2): 9.919e-07, MSE(pi3): 7.208e-04\n",
      "Epoch 12200, Train loss: 2.021e+02, Test loss: 2.582e+02, MSE(e): 6.126e-06, MSE(pi1): 6.390e-03, MSE(pi2): 1.987e-06, MSE(pi3): 7.694e-04\n",
      "Epoch 12300, Train loss: 1.273e+02, Test loss: 1.574e+02, MSE(e): 2.083e-06, MSE(pi1): 3.395e-03, MSE(pi2): 7.917e-07, MSE(pi3): 7.256e-04\n",
      "Epoch 12400, Train loss: 1.158e+02, Test loss: 1.209e+02, MSE(e): 1.800e-06, MSE(pi1): 2.780e-03, MSE(pi2): 7.567e-07, MSE(pi3): 7.000e-04\n",
      "Epoch 12500, Train loss: 1.602e+02, Test loss: 2.035e+02, MSE(e): 3.696e-06, MSE(pi1): 4.994e-03, MSE(pi2): 1.496e-06, MSE(pi3): 7.332e-04\n",
      "Epoch 12600, Train loss: 1.336e+02, Test loss: 1.784e+02, MSE(e): 2.161e-06, MSE(pi1): 3.799e-03, MSE(pi2): 7.472e-07, MSE(pi3): 7.400e-04\n",
      "Epoch 12700, Train loss: 1.661e+02, Test loss: 1.443e+02, MSE(e): 2.933e-06, MSE(pi1): 6.899e-03, MSE(pi2): 1.188e-06, MSE(pi3): 6.778e-04\n",
      "Epoch 12800, Train loss: 1.246e+02, Test loss: 1.255e+02, MSE(e): 2.607e-06, MSE(pi1): 2.548e-03, MSE(pi2): 1.098e-06, MSE(pi3): 7.309e-04\n",
      "Epoch 12900, Train loss: 1.307e+02, Test loss: 1.756e+02, MSE(e): 2.798e-06, MSE(pi1): 2.722e-03, MSE(pi2): 1.139e-06, MSE(pi3): 7.545e-04\n",
      "Epoch 13000, Train loss: 1.184e+02, Test loss: 1.387e+02, MSE(e): 1.710e-06, MSE(pi1): 3.168e-03, MSE(pi2): 8.110e-07, MSE(pi3): 6.967e-04\n",
      "Epoch 13100, Train loss: 1.977e+02, Test loss: 1.747e+02, MSE(e): 5.785e-06, MSE(pi1): 7.109e-03, MSE(pi2): 2.533e-06, MSE(pi3): 6.878e-04\n",
      "Epoch 13200, Train loss: 1.635e+02, Test loss: 2.125e+02, MSE(e): 5.314e-06, MSE(pi1): 3.568e-03, MSE(pi2): 2.335e-06, MSE(pi3): 7.464e-04\n",
      "Epoch 13300, Train loss: 1.447e+02, Test loss: 1.830e+02, MSE(e): 2.491e-06, MSE(pi1): 3.960e-03, MSE(pi2): 8.338e-07, MSE(pi3): 8.019e-04\n",
      "Epoch 13400, Train loss: 1.273e+02, Test loss: 1.562e+02, MSE(e): 2.637e-06, MSE(pi1): 3.027e-03, MSE(pi2): 1.140e-06, MSE(pi3): 7.070e-04\n",
      "Epoch 13500, Train loss: 1.737e+02, Test loss: 2.173e+02, MSE(e): 6.298e-06, MSE(pi1): 4.414e-03, MSE(pi2): 2.873e-06, MSE(pi3): 6.661e-04\n",
      "Epoch 13600, Train loss: 1.756e+02, Test loss: 1.867e+02, MSE(e): 5.358e-06, MSE(pi1): 5.153e-03, MSE(pi2): 2.387e-06, MSE(pi3): 7.050e-04\n",
      "Epoch 13700, Train loss: 5.216e+02, Test loss: 7.327e+02, MSE(e): 4.200e-05, MSE(pi1): 2.538e-03, MSE(pi2): 1.971e-05, MSE(pi3): 7.621e-04\n",
      "Epoch 13800, Train loss: 1.628e+02, Test loss: 1.954e+02, MSE(e): 3.939e-06, MSE(pi1): 5.814e-03, MSE(pi2): 1.729e-06, MSE(pi3): 6.524e-04\n",
      "Epoch 13900, Train loss: 1.546e+02, Test loss: 2.320e+02, MSE(e): 4.358e-06, MSE(pi1): 3.411e-03, MSE(pi2): 2.405e-06, MSE(pi3): 7.691e-04\n",
      "Epoch 14000, Train loss: 9.883e+02, Test loss: 1.246e+03, MSE(e): 8.777e-05, MSE(pi1): 3.491e-03, MSE(pi2): 4.202e-05, MSE(pi3): 7.568e-04\n",
      "Epoch 14100, Train loss: 1.397e+02, Test loss: 1.282e+02, MSE(e): 4.123e-06, MSE(pi1): 3.017e-03, MSE(pi2): 1.950e-06, MSE(pi3): 6.832e-04\n",
      "Epoch 14200, Train loss: 1.204e+02, Test loss: 1.382e+02, MSE(e): 1.589e-06, MSE(pi1): 3.579e-03, MSE(pi2): 6.358e-07, MSE(pi3): 6.876e-04\n",
      "Epoch 14300, Train loss: 1.148e+02, Test loss: 1.227e+02, MSE(e): 1.880e-06, MSE(pi1): 2.505e-03, MSE(pi2): 8.575e-07, MSE(pi3): 7.091e-04\n",
      "Epoch 14400, Train loss: 1.341e+02, Test loss: 1.824e+02, MSE(e): 2.017e-06, MSE(pi1): 4.302e-03, MSE(pi2): 7.593e-07, MSE(pi3): 7.090e-04\n",
      "Epoch 14500, Train loss: 1.245e+02, Test loss: 1.281e+02, MSE(e): 2.028e-06, MSE(pi1): 3.081e-03, MSE(pi2): 7.722e-07, MSE(pi3): 7.338e-04\n",
      "Epoch 14600, Train loss: 1.324e+02, Test loss: 1.204e+02, MSE(e): 3.378e-06, MSE(pi1): 3.095e-03, MSE(pi2): 1.599e-06, MSE(pi3): 6.768e-04\n",
      "Epoch 14700, Train loss: 1.253e+02, Test loss: 1.516e+02, MSE(e): 2.261e-06, MSE(pi1): 2.712e-03, MSE(pi2): 1.011e-06, MSE(pi3): 7.552e-04\n",
      "Epoch 14800, Train loss: 1.145e+02, Test loss: 1.458e+02, MSE(e): 1.645e-06, MSE(pi1): 2.325e-03, MSE(pi2): 7.028e-07, MSE(pi3): 7.482e-04\n",
      "Epoch 14900, Train loss: 1.598e+02, Test loss: 1.383e+02, MSE(e): 6.105e-06, MSE(pi1): 2.796e-03, MSE(pi2): 2.815e-06, MSE(pi3): 7.074e-04\n",
      "Epoch 15000, Train loss: 1.636e+02, Test loss: 2.014e+02, MSE(e): 3.426e-06, MSE(pi1): 5.919e-03, MSE(pi2): 1.197e-06, MSE(pi3): 7.015e-04\n",
      "Epoch 15100, Train loss: 1.271e+02, Test loss: 1.505e+02, MSE(e): 1.795e-06, MSE(pi1): 3.618e-03, MSE(pi2): 7.194e-07, MSE(pi3): 7.294e-04\n",
      "Epoch 15200, Train loss: 1.090e+02, Test loss: 1.153e+02, MSE(e): 1.309e-06, MSE(pi1): 2.554e-03, MSE(pi2): 5.570e-07, MSE(pi3): 7.042e-04\n",
      "Epoch 15300, Train loss: 1.190e+02, Test loss: 1.282e+02, MSE(e): 2.189e-06, MSE(pi1): 2.576e-03, MSE(pi2): 9.556e-07, MSE(pi3): 7.137e-04\n",
      "Epoch 15400, Train loss: 1.287e+02, Test loss: 1.301e+02, MSE(e): 2.649e-06, MSE(pi1): 2.997e-03, MSE(pi2): 1.088e-06, MSE(pi3): 7.220e-04\n",
      "Epoch 15500, Train loss: 1.254e+02, Test loss: 1.509e+02, MSE(e): 1.846e-06, MSE(pi1): 3.116e-03, MSE(pi2): 6.463e-07, MSE(pi3): 7.574e-04\n",
      "Epoch 15600, Train loss: 1.524e+02, Test loss: 1.606e+02, MSE(e): 3.783e-06, MSE(pi1): 4.809e-03, MSE(pi2): 1.920e-06, MSE(pi3): 6.643e-04\n",
      "Epoch 15700, Train loss: 3.639e+02, Test loss: 5.426e+02, MSE(e): 2.555e-05, MSE(pi1): 3.667e-03, MSE(pi2): 1.219e-05, MSE(pi3): 7.169e-04\n",
      "Epoch 15800, Train loss: 1.328e+02, Test loss: 1.734e+02, MSE(e): 1.875e-06, MSE(pi1): 4.441e-03, MSE(pi2): 7.473e-07, MSE(pi3): 6.967e-04\n",
      "Epoch 15900, Train loss: 1.312e+02, Test loss: 1.351e+02, MSE(e): 1.966e-06, MSE(pi1): 3.917e-03, MSE(pi2): 8.010e-07, MSE(pi3): 7.236e-04\n",
      "Epoch 16000, Train loss: 1.413e+02, Test loss: 2.017e+02, MSE(e): 2.986e-06, MSE(pi1): 3.653e-03, MSE(pi2): 1.545e-06, MSE(pi3): 7.491e-04\n",
      "Epoch 16100, Train loss: 1.132e+02, Test loss: 1.289e+02, MSE(e): 1.368e-06, MSE(pi1): 3.099e-03, MSE(pi2): 6.807e-07, MSE(pi3): 6.856e-04\n",
      "Epoch 16200, Train loss: 1.378e+02, Test loss: 1.482e+02, MSE(e): 3.885e-06, MSE(pi1): 2.618e-03, MSE(pi2): 1.948e-06, MSE(pi3): 7.277e-04\n",
      "Epoch 16300, Train loss: 1.172e+02, Test loss: 1.372e+02, MSE(e): 1.575e-06, MSE(pi1): 2.585e-03, MSE(pi2): 7.085e-07, MSE(pi3): 7.563e-04\n",
      "Epoch 16400, Train loss: 1.385e+02, Test loss: 2.131e+02, MSE(e): 3.513e-06, MSE(pi1): 3.040e-03, MSE(pi2): 2.101e-06, MSE(pi3): 7.297e-04\n",
      "Epoch 16500, Train loss: 1.461e+02, Test loss: 2.714e+02, MSE(e): 4.974e-06, MSE(pi1): 2.312e-03, MSE(pi2): 2.963e-06, MSE(pi3): 7.319e-04\n",
      "Epoch 16600, Train loss: 1.278e+02, Test loss: 1.502e+02, MSE(e): 2.569e-06, MSE(pi1): 3.209e-03, MSE(pi2): 1.066e-06, MSE(pi3): 6.999e-04\n",
      "Epoch 16700, Train loss: 1.492e+02, Test loss: 1.511e+02, MSE(e): 3.035e-06, MSE(pi1): 4.939e-03, MSE(pi2): 1.441e-06, MSE(pi3): 6.944e-04\n",
      "Epoch 16800, Train loss: 1.202e+02, Test loss: 1.478e+02, MSE(e): 1.385e-06, MSE(pi1): 3.159e-03, MSE(pi2): 5.328e-07, MSE(pi3): 7.478e-04\n",
      "Epoch 16900, Train loss: 1.661e+02, Test loss: 2.203e+02, MSE(e): 3.205e-06, MSE(pi1): 6.005e-03, MSE(pi2): 8.688e-07, MSE(pi3): 7.397e-04\n",
      "Epoch 17000, Train loss: 1.830e+02, Test loss: 2.509e+02, MSE(e): 4.045e-06, MSE(pi1): 7.147e-03, MSE(pi2): 2.004e-06, MSE(pi3): 7.112e-04\n",
      "Epoch 17100, Train loss: 1.622e+02, Test loss: 1.487e+02, MSE(e): 5.357e-06, MSE(pi1): 4.425e-03, MSE(pi2): 2.639e-06, MSE(pi3): 6.437e-04\n",
      "Epoch 17200, Train loss: 1.274e+02, Test loss: 1.353e+02, MSE(e): 2.435e-06, MSE(pi1): 3.171e-03, MSE(pi2): 9.224e-07, MSE(pi3): 7.129e-04\n",
      "Epoch 17300, Train loss: 1.209e+02, Test loss: 1.382e+02, MSE(e): 1.554e-06, MSE(pi1): 3.916e-03, MSE(pi2): 7.692e-07, MSE(pi3): 6.620e-04\n",
      "Epoch 17400, Train loss: 1.471e+02, Test loss: 1.703e+02, MSE(e): 4.125e-06, MSE(pi1): 3.763e-03, MSE(pi2): 1.846e-06, MSE(pi3): 6.821e-04\n",
      "Epoch 17500, Train loss: 1.548e+02, Test loss: 1.728e+02, MSE(e): 3.560e-06, MSE(pi1): 4.823e-03, MSE(pi2): 1.290e-06, MSE(pi3): 7.095e-04\n",
      "Epoch 17600, Train loss: 1.487e+02, Test loss: 1.946e+02, MSE(e): 2.368e-06, MSE(pi1): 5.689e-03, MSE(pi2): 9.694e-07, MSE(pi3): 6.815e-04\n",
      "Epoch 17700, Train loss: 1.585e+02, Test loss: 1.458e+02, MSE(e): 6.226e-06, MSE(pi1): 2.651e-03, MSE(pi2): 2.829e-06, MSE(pi3): 6.978e-04\n",
      "Epoch 17800, Train loss: 1.556e+02, Test loss: 1.637e+02, MSE(e): 3.544e-06, MSE(pi1): 4.917e-03, MSE(pi2): 1.642e-06, MSE(pi3): 7.099e-04\n",
      "Epoch 17900, Train loss: 1.331e+02, Test loss: 1.241e+02, MSE(e): 3.644e-06, MSE(pi1): 2.594e-03, MSE(pi2): 1.665e-06, MSE(pi3): 7.072e-04\n",
      "Epoch 18000, Train loss: 1.195e+02, Test loss: 1.740e+02, MSE(e): 1.421e-06, MSE(pi1): 3.580e-03, MSE(pi2): 5.582e-07, MSE(pi3): 6.949e-04\n",
      "Epoch 18100, Train loss: 6.573e+02, Test loss: 8.113e+02, MSE(e): 5.554e-05, MSE(pi1): 3.262e-03, MSE(pi2): 2.627e-05, MSE(pi3): 6.915e-04\n",
      "Epoch 18200, Train loss: 1.092e+02, Test loss: 1.147e+02, MSE(e): 1.104e-06, MSE(pi1): 3.083e-03, MSE(pi2): 5.352e-07, MSE(pi3): 6.730e-04\n",
      "Epoch 18300, Train loss: 1.237e+02, Test loss: 1.470e+02, MSE(e): 2.475e-06, MSE(pi1): 2.980e-03, MSE(pi2): 1.348e-06, MSE(pi3): 6.917e-04\n",
      "Epoch 18400, Train loss: 1.019e+02, Test loss: 1.152e+02, MSE(e): 6.858e-07, MSE(pi1): 2.507e-03, MSE(pi2): 3.384e-07, MSE(pi3): 6.993e-04\n",
      "Epoch 18500, Train loss: 1.637e+02, Test loss: 1.888e+02, MSE(e): 5.282e-06, MSE(pi1): 3.841e-03, MSE(pi2): 2.556e-06, MSE(pi3): 7.251e-04\n",
      "Epoch 18600, Train loss: 1.402e+02, Test loss: 1.578e+02, MSE(e): 3.803e-06, MSE(pi1): 3.461e-03, MSE(pi2): 1.975e-06, MSE(pi3): 6.759e-04\n",
      "Epoch 18700, Train loss: 1.153e+02, Test loss: 1.216e+02, MSE(e): 1.457e-06, MSE(pi1): 3.007e-03, MSE(pi2): 5.205e-07, MSE(pi3): 7.062e-04\n",
      "Epoch 18800, Train loss: 1.834e+02, Test loss: 3.083e+02, MSE(e): 7.206e-06, MSE(pi1): 4.006e-03, MSE(pi2): 3.425e-06, MSE(pi3): 7.131e-04\n",
      "Epoch 18900, Train loss: 1.597e+02, Test loss: 1.697e+02, MSE(e): 3.658e-06, MSE(pi1): 5.028e-03, MSE(pi2): 1.171e-06, MSE(pi3): 7.280e-04\n",
      "Epoch 19000, Train loss: 1.120e+02, Test loss: 1.333e+02, MSE(e): 1.544e-06, MSE(pi1): 2.679e-03, MSE(pi2): 7.790e-07, MSE(pi3): 6.975e-04\n",
      "Epoch 19100, Train loss: 1.236e+02, Test loss: 1.318e+02, MSE(e): 2.608e-06, MSE(pi1): 2.823e-03, MSE(pi2): 1.398e-06, MSE(pi3): 6.933e-04\n",
      "Epoch 19200, Train loss: 1.232e+02, Test loss: 1.711e+02, MSE(e): 1.276e-06, MSE(pi1): 3.960e-03, MSE(pi2): 4.620e-07, MSE(pi3): 7.088e-04\n",
      "Epoch 19300, Train loss: 1.404e+02, Test loss: 1.622e+02, MSE(e): 2.698e-06, MSE(pi1): 4.496e-03, MSE(pi2): 1.288e-06, MSE(pi3): 6.850e-04\n",
      "Epoch 19400, Train loss: 1.325e+02, Test loss: 1.271e+02, MSE(e): 3.352e-06, MSE(pi1): 2.814e-03, MSE(pi2): 1.607e-06, MSE(pi3): 7.088e-04\n",
      "Epoch 19500, Train loss: 1.660e+02, Test loss: 1.920e+02, MSE(e): 4.790e-06, MSE(pi1): 5.259e-03, MSE(pi2): 3.217e-06, MSE(pi3): 6.555e-04\n",
      "Epoch 19600, Train loss: 1.599e+02, Test loss: 1.779e+02, MSE(e): 3.329e-06, MSE(pi1): 5.825e-03, MSE(pi2): 1.804e-06, MSE(pi3): 6.833e-04\n",
      "Epoch 19700, Train loss: 1.470e+02, Test loss: 1.659e+02, MSE(e): 5.064e-06, MSE(pi1): 2.552e-03, MSE(pi2): 3.175e-06, MSE(pi3): 7.079e-04\n",
      "Epoch 19800, Train loss: 1.154e+02, Test loss: 1.188e+02, MSE(e): 1.778e-06, MSE(pi1): 2.985e-03, MSE(pi2): 8.915e-07, MSE(pi3): 6.775e-04\n",
      "Epoch 19900, Train loss: 1.631e+02, Test loss: 2.285e+02, MSE(e): 5.018e-06, MSE(pi1): 4.372e-03, MSE(pi2): 2.228e-06, MSE(pi3): 6.918e-04\n",
      "Epoch 20000, Train loss: 1.483e+02, Test loss: 1.425e+02, MSE(e): 4.430e-06, MSE(pi1): 3.983e-03, MSE(pi2): 2.214e-06, MSE(pi3): 6.413e-04\n",
      "Epoch 20100, Train loss: 1.295e+02, Test loss: 1.559e+02, MSE(e): 3.294e-06, MSE(pi1): 2.542e-03, MSE(pi2): 1.823e-06, MSE(pi3): 7.117e-04\n",
      "Epoch 20200, Train loss: 1.571e+02, Test loss: 1.808e+02, MSE(e): 2.892e-06, MSE(pi1): 5.708e-03, MSE(pi2): 9.258e-07, MSE(pi3): 7.113e-04\n",
      "Epoch 20300, Train loss: 1.676e+02, Test loss: 1.657e+02, MSE(e): 6.188e-06, MSE(pi1): 3.873e-03, MSE(pi2): 2.673e-06, MSE(pi3): 6.702e-04\n",
      "Epoch 20400, Train loss: 1.044e+02, Test loss: 1.174e+02, MSE(e): 8.099e-07, MSE(pi1): 2.848e-03, MSE(pi2): 3.947e-07, MSE(pi3): 6.784e-04\n",
      "Epoch 20500, Train loss: 1.331e+02, Test loss: 1.465e+02, MSE(e): 2.241e-06, MSE(pi1): 4.061e-03, MSE(pi2): 9.515e-07, MSE(pi3): 7.010e-04\n",
      "Epoch 20600, Train loss: 1.733e+02, Test loss: 2.410e+02, MSE(e): 4.086e-06, MSE(pi1): 6.109e-03, MSE(pi2): 1.775e-06, MSE(pi3): 7.134e-04\n",
      "Epoch 20700, Train loss: 1.155e+02, Test loss: 1.193e+02, MSE(e): 1.442e-06, MSE(pi1): 3.136e-03, MSE(pi2): 6.327e-07, MSE(pi3): 6.975e-04\n",
      "Epoch 20800, Train loss: 1.134e+02, Test loss: 1.555e+02, MSE(e): 1.661e-06, MSE(pi1): 2.798e-03, MSE(pi2): 7.783e-07, MSE(pi3): 6.879e-04\n",
      "Epoch 20900, Train loss: 1.183e+02, Test loss: 1.216e+02, MSE(e): 1.971e-06, MSE(pi1): 2.837e-03, MSE(pi2): 9.724e-07, MSE(pi3): 7.018e-04\n",
      "Epoch 21000, Train loss: 1.126e+02, Test loss: 1.119e+02, MSE(e): 1.771e-06, MSE(pi1): 2.625e-03, MSE(pi2): 7.735e-07, MSE(pi3): 6.869e-04\n",
      "Epoch 21100, Train loss: 1.664e+02, Test loss: 2.703e+02, MSE(e): 6.156e-06, MSE(pi1): 3.018e-03, MSE(pi2): 3.334e-06, MSE(pi3): 7.470e-04\n",
      "Epoch 21200, Train loss: 1.157e+02, Test loss: 1.186e+02, MSE(e): 1.577e-06, MSE(pi1): 3.032e-03, MSE(pi2): 6.425e-07, MSE(pi3): 6.958e-04\n",
      "Epoch 21300, Train loss: 1.133e+02, Test loss: 1.554e+02, MSE(e): 1.384e-06, MSE(pi1): 2.925e-03, MSE(pi2): 8.039e-07, MSE(pi3): 7.017e-04\n",
      "Epoch 21400, Train loss: 1.177e+02, Test loss: 1.453e+02, MSE(e): 1.827e-06, MSE(pi1): 3.009e-03, MSE(pi2): 7.588e-07, MSE(pi3): 6.936e-04\n",
      "Epoch 21500, Train loss: 1.256e+02, Test loss: 1.307e+02, MSE(e): 2.328e-06, MSE(pi1): 3.554e-03, MSE(pi2): 1.114e-06, MSE(pi3): 6.681e-04\n",
      "Epoch 21600, Train loss: 4.301e+02, Test loss: 5.699e+02, MSE(e): 3.257e-05, MSE(pi1): 3.086e-03, MSE(pi2): 1.490e-05, MSE(pi3): 7.353e-04\n",
      "Epoch 21700, Train loss: 1.227e+02, Test loss: 1.896e+02, MSE(e): 1.775e-06, MSE(pi1): 3.613e-03, MSE(pi2): 8.344e-07, MSE(pi3): 6.884e-04\n",
      "Epoch 21800, Train loss: 1.097e+02, Test loss: 1.245e+02, MSE(e): 9.754e-07, MSE(pi1): 2.842e-03, MSE(pi2): 4.002e-07, MSE(pi3): 7.150e-04\n",
      "Epoch 21900, Train loss: 1.196e+02, Test loss: 1.280e+02, MSE(e): 2.108e-06, MSE(pi1): 3.157e-03, MSE(pi2): 9.149e-07, MSE(pi3): 6.696e-04\n",
      "Epoch 22000, Train loss: 1.119e+02, Test loss: 1.533e+02, MSE(e): 1.641e-06, MSE(pi1): 2.579e-03, MSE(pi2): 7.598e-07, MSE(pi3): 6.968e-04\n",
      "Epoch 22100, Train loss: 1.273e+02, Test loss: 1.348e+02, MSE(e): 2.186e-06, MSE(pi1): 3.816e-03, MSE(pi2): 1.058e-06, MSE(pi3): 6.723e-04\n",
      "Epoch 22200, Train loss: 1.082e+02, Test loss: 1.159e+02, MSE(e): 1.173e-06, MSE(pi1): 2.686e-03, MSE(pi2): 6.197e-07, MSE(pi3): 6.958e-04\n",
      "Epoch 22300, Train loss: 4.889e+02, Test loss: 6.644e+02, MSE(e): 3.834e-05, MSE(pi1): 3.250e-03, MSE(pi2): 1.684e-05, MSE(pi3): 7.300e-04\n",
      "Epoch 22400, Train loss: 1.042e+02, Test loss: 1.123e+02, MSE(e): 7.557e-07, MSE(pi1): 2.767e-03, MSE(pi2): 4.112e-07, MSE(pi3): 6.898e-04\n",
      "Epoch 22500, Train loss: 1.390e+02, Test loss: 1.631e+02, MSE(e): 3.252e-06, MSE(pi1): 4.078e-03, MSE(pi2): 1.623e-06, MSE(pi3): 6.574e-04\n",
      "Epoch 22600, Train loss: 1.347e+02, Test loss: 1.477e+02, MSE(e): 2.608e-06, MSE(pi1): 3.761e-03, MSE(pi2): 9.274e-07, MSE(pi3): 7.103e-04\n",
      "Epoch 22700, Train loss: 1.178e+02, Test loss: 1.260e+02, MSE(e): 1.380e-06, MSE(pi1): 3.611e-03, MSE(pi2): 6.354e-07, MSE(pi3): 6.791e-04\n",
      "Epoch 22800, Train loss: 1.332e+02, Test loss: 1.438e+02, MSE(e): 2.555e-06, MSE(pi1): 3.650e-03, MSE(pi2): 9.211e-07, MSE(pi3): 7.114e-04\n",
      "Epoch 22900, Train loss: 1.106e+02, Test loss: 1.292e+02, MSE(e): 1.321e-06, MSE(pi1): 3.056e-03, MSE(pi2): 5.867e-07, MSE(pi3): 6.687e-04\n",
      "Epoch 23000, Train loss: 2.650e+02, Test loss: 3.128e+02, MSE(e): 7.355e-06, MSE(pi1): 1.277e-02, MSE(pi2): 2.240e-06, MSE(pi3): 6.373e-04\n",
      "Epoch 23100, Train loss: 1.168e+02, Test loss: 1.158e+02, MSE(e): 2.071e-06, MSE(pi1): 2.772e-03, MSE(pi2): 9.484e-07, MSE(pi3): 6.836e-04\n",
      "Epoch 23200, Train loss: 1.419e+02, Test loss: 1.684e+02, MSE(e): 2.890e-06, MSE(pi1): 4.709e-03, MSE(pi2): 1.248e-06, MSE(pi3): 6.587e-04\n",
      "Epoch 23300, Train loss: 1.108e+02, Test loss: 1.170e+02, MSE(e): 8.788e-07, MSE(pi1): 3.683e-03, MSE(pi2): 4.321e-07, MSE(pi3): 6.515e-04\n",
      "Epoch 23400, Train loss: 1.464e+02, Test loss: 1.759e+02, MSE(e): 4.545e-06, MSE(pi1): 3.192e-03, MSE(pi2): 2.145e-06, MSE(pi3): 6.903e-04\n",
      "Epoch 23500, Train loss: 1.323e+02, Test loss: 1.234e+02, MSE(e): 3.227e-06, MSE(pi1): 3.500e-03, MSE(pi2): 1.578e-06, MSE(pi3): 6.500e-04\n",
      "Epoch 23600, Train loss: 1.289e+02, Test loss: 1.757e+02, MSE(e): 1.884e-06, MSE(pi1): 3.910e-03, MSE(pi2): 8.744e-07, MSE(pi3): 7.092e-04\n",
      "Epoch 23700, Train loss: 1.178e+02, Test loss: 1.150e+02, MSE(e): 2.106e-06, MSE(pi1): 2.782e-03, MSE(pi2): 9.652e-07, MSE(pi3): 6.893e-04\n",
      "Epoch 23800, Train loss: 1.308e+02, Test loss: 1.475e+02, MSE(e): 1.832e-06, MSE(pi1): 4.038e-03, MSE(pi2): 1.074e-06, MSE(pi3): 7.206e-04\n",
      "Epoch 23900, Train loss: 1.099e+02, Test loss: 1.525e+02, MSE(e): 1.060e-06, MSE(pi1): 2.978e-03, MSE(pi2): 4.409e-07, MSE(pi3): 6.954e-04\n",
      "Epoch 24000, Train loss: 1.197e+02, Test loss: 1.503e+02, MSE(e): 1.874e-06, MSE(pi1): 3.022e-03, MSE(pi2): 9.202e-07, MSE(pi3): 7.073e-04\n",
      "Epoch 24100, Train loss: 1.288e+02, Test loss: 1.547e+02, MSE(e): 1.341e-06, MSE(pi1): 4.636e-03, MSE(pi2): 4.541e-07, MSE(pi3): 6.907e-04\n",
      "Epoch 24200, Train loss: 1.098e+02, Test loss: 1.522e+02, MSE(e): 1.205e-06, MSE(pi1): 2.797e-03, MSE(pi2): 6.059e-07, MSE(pi3): 6.983e-04\n",
      "Epoch 24300, Train loss: 1.246e+02, Test loss: 1.242e+02, MSE(e): 2.835e-06, MSE(pi1): 2.914e-03, MSE(pi2): 1.387e-06, MSE(pi3): 6.715e-04\n",
      "Epoch 24400, Train loss: 1.256e+02, Test loss: 1.509e+02, MSE(e): 1.782e-06, MSE(pi1): 3.875e-03, MSE(pi2): 6.372e-07, MSE(pi3): 6.907e-04\n",
      "Epoch 24500, Train loss: 1.057e+02, Test loss: 1.199e+02, MSE(e): 7.414e-07, MSE(pi1): 2.818e-03, MSE(pi2): 2.773e-07, MSE(pi3): 7.007e-04\n",
      "Epoch 24600, Train loss: 1.144e+02, Test loss: 1.430e+02, MSE(e): 1.219e-06, MSE(pi1): 3.122e-03, MSE(pi2): 6.087e-07, MSE(pi3): 7.100e-04\n",
      "Epoch 24700, Train loss: 1.020e+02, Test loss: 1.083e+02, MSE(e): 7.046e-07, MSE(pi1): 2.631e-03, MSE(pi2): 3.351e-07, MSE(pi3): 6.863e-04\n",
      "Epoch 24800, Train loss: 1.294e+02, Test loss: 1.268e+02, MSE(e): 3.121e-06, MSE(pi1): 2.703e-03, MSE(pi2): 1.852e-06, MSE(pi3): 7.120e-04\n",
      "Epoch 24900, Train loss: 1.192e+02, Test loss: 1.196e+02, MSE(e): 1.775e-06, MSE(pi1): 3.105e-03, MSE(pi2): 1.020e-06, MSE(pi3): 7.042e-04\n",
      "Epoch 25000, Train loss: 1.063e+02, Test loss: 1.148e+02, MSE(e): 1.010e-06, MSE(pi1): 2.730e-03, MSE(pi2): 4.455e-07, MSE(pi3): 6.887e-04\n",
      "Epoch 25100, Train loss: 1.059e+02, Test loss: 1.178e+02, MSE(e): 6.812e-07, MSE(pi1): 3.179e-03, MSE(pi2): 3.324e-07, MSE(pi3): 6.730e-04\n",
      "Epoch 25200, Train loss: 1.072e+02, Test loss: 1.116e+02, MSE(e): 1.185e-06, MSE(pi1): 2.636e-03, MSE(pi2): 5.611e-07, MSE(pi3): 6.898e-04\n",
      "Epoch 25300, Train loss: 1.286e+02, Test loss: 1.368e+02, MSE(e): 2.562e-06, MSE(pi1): 3.499e-03, MSE(pi2): 1.126e-06, MSE(pi3): 6.798e-04\n",
      "Epoch 25400, Train loss: 1.538e+02, Test loss: 1.815e+02, MSE(e): 4.927e-06, MSE(pi1): 3.308e-03, MSE(pi2): 2.320e-06, MSE(pi3): 7.150e-04\n",
      "Epoch 25500, Train loss: 1.035e+02, Test loss: 1.212e+02, MSE(e): 7.178e-07, MSE(pi1): 2.754e-03, MSE(pi2): 3.090e-07, MSE(pi3): 6.877e-04\n",
      "Epoch 25600, Train loss: 2.205e+02, Test loss: 2.012e+02, MSE(e): 9.379e-06, MSE(pi1): 6.039e-03, MSE(pi2): 4.036e-06, MSE(pi3): 6.633e-04\n",
      "Epoch 25700, Train loss: 1.369e+02, Test loss: 1.876e+02, MSE(e): 3.974e-06, MSE(pi1): 2.514e-03, MSE(pi2): 2.291e-06, MSE(pi3): 7.201e-04\n",
      "Epoch 25800, Train loss: 1.097e+02, Test loss: 1.129e+02, MSE(e): 1.446e-06, MSE(pi1): 2.565e-03, MSE(pi2): 6.484e-07, MSE(pi3): 6.963e-04\n",
      "Epoch 25900, Train loss: 1.184e+02, Test loss: 1.440e+02, MSE(e): 2.134e-06, MSE(pi1): 2.554e-03, MSE(pi2): 1.025e-06, MSE(pi3): 7.151e-04\n",
      "Epoch 26000, Train loss: 1.239e+02, Test loss: 1.326e+02, MSE(e): 2.642e-06, MSE(pi1): 2.754e-03, MSE(pi2): 1.459e-06, MSE(pi3): 6.991e-04\n",
      "Epoch 26100, Train loss: 1.356e+02, Test loss: 1.288e+02, MSE(e): 3.900e-06, MSE(pi1): 2.618e-03, MSE(pi2): 2.187e-06, MSE(pi3): 7.040e-04\n",
      "Epoch 26200, Train loss: 1.324e+02, Test loss: 1.218e+02, MSE(e): 3.609e-06, MSE(pi1): 2.745e-03, MSE(pi2): 1.701e-06, MSE(pi3): 6.882e-04\n",
      "Epoch 26300, Train loss: 1.119e+02, Test loss: 1.321e+02, MSE(e): 1.169e-06, MSE(pi1): 2.886e-03, MSE(pi2): 6.013e-07, MSE(pi3): 7.135e-04\n",
      "Epoch 26400, Train loss: 1.201e+02, Test loss: 1.417e+02, MSE(e): 1.706e-06, MSE(pi1): 3.146e-03, MSE(pi2): 6.419e-07, MSE(pi3): 7.155e-04\n",
      "Epoch 26500, Train loss: 1.157e+02, Test loss: 1.214e+02, MSE(e): 2.002e-06, MSE(pi1): 2.676e-03, MSE(pi2): 9.185e-07, MSE(pi3): 6.891e-04\n",
      "Epoch 26600, Train loss: 1.000e+02, Test loss: 1.069e+02, MSE(e): 5.465e-07, MSE(pi1): 2.562e-03, MSE(pi2): 2.258e-07, MSE(pi3): 6.896e-04\n",
      "Epoch 26700, Train loss: 1.192e+02, Test loss: 1.178e+02, MSE(e): 2.304e-06, MSE(pi1): 2.629e-03, MSE(pi2): 1.018e-06, MSE(pi3): 6.992e-04\n",
      "Epoch 26800, Train loss: 1.458e+02, Test loss: 1.540e+02, MSE(e): 3.208e-06, MSE(pi1): 4.329e-03, MSE(pi2): 2.519e-06, MSE(pi3): 7.048e-04\n",
      "Epoch 26900, Train loss: 1.070e+02, Test loss: 1.274e+02, MSE(e): 9.024e-07, MSE(pi1): 2.922e-03, MSE(pi2): 5.408e-07, MSE(pi3): 6.880e-04\n",
      "Epoch 27000, Train loss: 1.095e+02, Test loss: 1.326e+02, MSE(e): 1.393e-06, MSE(pi1): 2.516e-03, MSE(pi2): 8.027e-07, MSE(pi3): 7.045e-04\n",
      "Epoch 27100, Train loss: 1.104e+02, Test loss: 1.400e+02, MSE(e): 1.120e-06, MSE(pi1): 2.579e-03, MSE(pi2): 5.847e-07, MSE(pi3): 7.343e-04\n",
      "Epoch 27200, Train loss: 1.272e+02, Test loss: 1.402e+02, MSE(e): 1.669e-06, MSE(pi1): 4.153e-03, MSE(pi2): 7.494e-07, MSE(pi3): 6.901e-04\n",
      "Epoch 27300, Train loss: 1.466e+02, Test loss: 1.379e+02, MSE(e): 3.263e-06, MSE(pi1): 4.520e-03, MSE(pi2): 2.410e-06, MSE(pi3): 6.877e-04\n",
      "Epoch 27400, Train loss: 1.229e+02, Test loss: 1.615e+02, MSE(e): 2.393e-06, MSE(pi1): 2.856e-03, MSE(pi2): 1.097e-06, MSE(pi3): 7.045e-04\n",
      "Epoch 27500, Train loss: 1.253e+02, Test loss: 1.500e+02, MSE(e): 2.897e-06, MSE(pi1): 2.460e-03, MSE(pi2): 1.464e-06, MSE(pi3): 7.170e-04\n",
      "Epoch 27600, Train loss: 1.146e+02, Test loss: 1.250e+02, MSE(e): 1.243e-06, MSE(pi1): 3.164e-03, MSE(pi2): 6.929e-07, MSE(pi3): 7.052e-04\n",
      "Epoch 27700, Train loss: 1.118e+02, Test loss: 1.258e+02, MSE(e): 9.437e-07, MSE(pi1): 3.165e-03, MSE(pi2): 6.090e-07, MSE(pi3): 7.068e-04\n",
      "Epoch 27800, Train loss: 1.124e+02, Test loss: 1.256e+02, MSE(e): 1.160e-06, MSE(pi1): 3.318e-03, MSE(pi2): 6.774e-07, MSE(pi3): 6.757e-04\n",
      "Epoch 27900, Train loss: 1.121e+02, Test loss: 1.375e+02, MSE(e): 1.370e-06, MSE(pi1): 2.947e-03, MSE(pi2): 5.941e-07, MSE(pi3): 6.895e-04\n",
      "Epoch 28000, Train loss: 9.873e+01, Test loss: 1.089e+02, MSE(e): 4.017e-07, MSE(pi1): 2.460e-03, MSE(pi2): 2.037e-07, MSE(pi3): 7.012e-04\n",
      "Epoch 28100, Train loss: 1.053e+02, Test loss: 1.265e+02, MSE(e): 9.498e-07, MSE(pi1): 2.439e-03, MSE(pi2): 4.763e-07, MSE(pi3): 7.136e-04\n",
      "Epoch 28200, Train loss: 1.135e+02, Test loss: 1.251e+02, MSE(e): 7.741e-07, MSE(pi1): 3.598e-03, MSE(pi2): 3.342e-07, MSE(pi3): 6.978e-04\n",
      "Epoch 28300, Train loss: 1.033e+02, Test loss: 1.188e+02, MSE(e): 7.505e-07, MSE(pi1): 2.417e-03, MSE(pi2): 4.020e-07, MSE(pi3): 7.158e-04\n",
      "Epoch 28400, Train loss: 1.083e+02, Test loss: 1.156e+02, MSE(e): 6.488e-07, MSE(pi1): 3.384e-03, MSE(pi2): 2.628e-07, MSE(pi3): 6.794e-04\n",
      "Epoch 28500, Train loss: 1.153e+02, Test loss: 1.435e+02, MSE(e): 1.021e-06, MSE(pi1): 3.559e-03, MSE(pi2): 3.823e-07, MSE(pi3): 6.945e-04\n",
      "Epoch 28600, Train loss: 1.435e+02, Test loss: 2.057e+02, MSE(e): 2.066e-06, MSE(pi1): 5.068e-03, MSE(pi2): 9.488e-07, MSE(pi3): 7.213e-04\n",
      "Epoch 28700, Train loss: 1.344e+02, Test loss: 1.453e+02, MSE(e): 3.132e-06, MSE(pi1): 3.397e-03, MSE(pi2): 1.493e-06, MSE(pi3): 6.909e-04\n",
      "Epoch 28800, Train loss: 1.047e+02, Test loss: 1.187e+02, MSE(e): 8.952e-07, MSE(pi1): 2.575e-03, MSE(pi2): 4.422e-07, MSE(pi3): 7.000e-04\n",
      "Epoch 28900, Train loss: 1.098e+02, Test loss: 1.370e+02, MSE(e): 9.786e-07, MSE(pi1): 2.674e-03, MSE(pi2): 4.537e-07, MSE(pi3): 7.323e-04\n",
      "Epoch 29000, Train loss: 1.223e+02, Test loss: 1.464e+02, MSE(e): 1.777e-06, MSE(pi1): 3.302e-03, MSE(pi2): 8.533e-07, MSE(pi3): 7.154e-04\n",
      "Epoch 29100, Train loss: 1.353e+02, Test loss: 1.659e+02, MSE(e): 2.771e-06, MSE(pi1): 3.939e-03, MSE(pi2): 1.124e-06, MSE(pi3): 6.826e-04\n",
      "Epoch 29200, Train loss: 1.184e+02, Test loss: 1.423e+02, MSE(e): 2.134e-06, MSE(pi1): 2.775e-03, MSE(pi2): 1.095e-06, MSE(pi3): 6.930e-04\n",
      "Epoch 29300, Train loss: 1.279e+02, Test loss: 1.756e+02, MSE(e): 2.518e-06, MSE(pi1): 3.205e-03, MSE(pi2): 1.067e-06, MSE(pi3): 7.064e-04\n",
      "Epoch 29400, Train loss: 1.022e+02, Test loss: 1.130e+02, MSE(e): 6.609e-07, MSE(pi1): 2.617e-03, MSE(pi2): 3.467e-07, MSE(pi3): 6.939e-04\n",
      "Epoch 29500, Train loss: 1.542e+02, Test loss: 1.706e+02, MSE(e): 4.502e-06, MSE(pi1): 3.750e-03, MSE(pi2): 2.215e-06, MSE(pi3): 7.172e-04\n",
      "Epoch 29600, Train loss: 1.048e+02, Test loss: 1.083e+02, MSE(e): 1.008e-06, MSE(pi1): 2.526e-03, MSE(pi2): 5.182e-07, MSE(pi3): 6.945e-04\n",
      "Epoch 29700, Train loss: 1.255e+02, Test loss: 1.334e+02, MSE(e): 2.853e-06, MSE(pi1): 2.559e-03, MSE(pi2): 1.547e-06, MSE(pi3): 7.135e-04\n",
      "Epoch 29800, Train loss: 1.196e+02, Test loss: 1.305e+02, MSE(e): 1.167e-06, MSE(pi1): 3.896e-03, MSE(pi2): 4.985e-07, MSE(pi3): 6.899e-04\n",
      "Epoch 29900, Train loss: 1.106e+02, Test loss: 1.274e+02, MSE(e): 1.198e-06, MSE(pi1): 2.771e-03, MSE(pi2): 5.227e-07, MSE(pi3): 7.093e-04\n",
      "Epoch 30000, Train loss: 1.226e+02, Test loss: 1.536e+02, MSE(e): 2.659e-06, MSE(pi1): 2.566e-03, MSE(pi2): 1.202e-06, MSE(pi3): 7.030e-04\n",
      "Epoch 30100, Train loss: 1.292e+02, Test loss: 1.512e+02, MSE(e): 2.964e-06, MSE(pi1): 2.813e-03, MSE(pi2): 1.266e-06, MSE(pi3): 7.138e-04\n",
      "Epoch 30200, Train loss: 1.129e+02, Test loss: 1.283e+02, MSE(e): 1.094e-06, MSE(pi1): 2.850e-03, MSE(pi2): 5.254e-07, MSE(pi3): 7.347e-04\n",
      "Epoch 30300, Train loss: 1.343e+02, Test loss: 1.365e+02, MSE(e): 1.563e-06, MSE(pi1): 4.875e-03, MSE(pi2): 6.657e-07, MSE(pi3): 6.996e-04\n",
      "Epoch 30400, Train loss: 1.321e+02, Test loss: 1.578e+02, MSE(e): 1.473e-06, MSE(pi1): 4.516e-03, MSE(pi2): 6.213e-07, MSE(pi3): 7.224e-04\n",
      "Epoch 30500, Train loss: 1.039e+02, Test loss: 1.102e+02, MSE(e): 9.221e-07, MSE(pi1): 2.394e-03, MSE(pi2): 4.660e-07, MSE(pi3): 7.075e-04\n",
      "Epoch 30600, Train loss: 1.565e+02, Test loss: 1.553e+02, MSE(e): 6.092e-06, MSE(pi1): 2.718e-03, MSE(pi2): 3.053e-06, MSE(pi3): 6.838e-04\n",
      "Epoch 30700, Train loss: 1.335e+02, Test loss: 1.883e+02, MSE(e): 3.230e-06, MSE(pi1): 3.230e-03, MSE(pi2): 1.272e-06, MSE(pi3): 6.892e-04\n",
      "Epoch 30800, Train loss: 1.046e+02, Test loss: 1.273e+02, MSE(e): 7.415e-07, MSE(pi1): 2.908e-03, MSE(pi2): 3.392e-07, MSE(pi3): 6.813e-04\n",
      "Epoch 30900, Train loss: 1.149e+02, Test loss: 1.317e+02, MSE(e): 1.102e-06, MSE(pi1): 3.223e-03, MSE(pi2): 4.499e-07, MSE(pi3): 7.163e-04\n",
      "Epoch 31000, Train loss: 1.971e+02, Test loss: 2.451e+02, MSE(e): 5.139e-06, MSE(pi1): 7.751e-03, MSE(pi2): 3.146e-06, MSE(pi3): 6.821e-04\n",
      "Epoch 31100, Train loss: 9.828e+01, Test loss: 1.077e+02, MSE(e): 3.616e-07, MSE(pi1): 2.460e-03, MSE(pi2): 1.815e-07, MSE(pi3): 7.006e-04\n",
      "Epoch 31200, Train loss: 1.055e+02, Test loss: 1.129e+02, MSE(e): 7.412e-07, MSE(pi1): 2.694e-03, MSE(pi2): 4.329e-07, MSE(pi3): 7.119e-04\n",
      "Epoch 31300, Train loss: 1.840e+02, Test loss: 1.756e+02, MSE(e): 8.495e-06, MSE(pi1): 2.845e-03, MSE(pi2): 3.703e-06, MSE(pi3): 7.064e-04\n",
      "Epoch 31400, Train loss: 1.129e+02, Test loss: 1.327e+02, MSE(e): 1.341e-06, MSE(pi1): 2.942e-03, MSE(pi2): 8.993e-07, MSE(pi3): 7.010e-04\n",
      "Epoch 31500, Train loss: 1.107e+02, Test loss: 1.212e+02, MSE(e): 1.292e-06, MSE(pi1): 2.821e-03, MSE(pi2): 6.567e-07, MSE(pi3): 6.958e-04\n",
      "Epoch 31600, Train loss: 1.191e+02, Test loss: 1.391e+02, MSE(e): 1.872e-06, MSE(pi1): 3.265e-03, MSE(pi2): 7.887e-07, MSE(pi3): 6.771e-04\n",
      "Epoch 31700, Train loss: 1.032e+02, Test loss: 1.165e+02, MSE(e): 6.057e-07, MSE(pi1): 2.615e-03, MSE(pi2): 2.518e-07, MSE(pi3): 7.100e-04\n",
      "Epoch 31800, Train loss: 1.199e+02, Test loss: 1.285e+02, MSE(e): 2.388e-06, MSE(pi1): 2.741e-03, MSE(pi2): 1.042e-06, MSE(pi3): 6.864e-04\n",
      "Epoch 31900, Train loss: 1.481e+02, Test loss: 1.918e+02, MSE(e): 5.095e-06, MSE(pi1): 2.720e-03, MSE(pi2): 2.255e-06, MSE(pi3): 6.992e-04\n",
      "Epoch 32000, Train loss: 1.079e+02, Test loss: 1.164e+02, MSE(e): 1.328e-06, MSE(pi1): 2.500e-03, MSE(pi2): 6.538e-07, MSE(pi3): 6.965e-04\n",
      "Epoch 32100, Train loss: 1.295e+02, Test loss: 1.474e+02, MSE(e): 3.417e-06, MSE(pi1): 2.655e-03, MSE(pi2): 1.609e-06, MSE(pi3): 6.878e-04\n",
      "Epoch 32200, Train loss: 1.123e+02, Test loss: 1.362e+02, MSE(e): 1.323e-06, MSE(pi1): 3.076e-03, MSE(pi2): 6.737e-07, MSE(pi3): 6.831e-04\n",
      "Epoch 32300, Train loss: 1.163e+02, Test loss: 1.392e+02, MSE(e): 1.571e-06, MSE(pi1): 3.187e-03, MSE(pi2): 7.065e-07, MSE(pi3): 6.876e-04\n",
      "Epoch 32400, Train loss: 1.278e+02, Test loss: 1.529e+02, MSE(e): 1.743e-06, MSE(pi1): 4.180e-03, MSE(pi2): 8.142e-07, MSE(pi3): 6.855e-04\n",
      "Epoch 32500, Train loss: 1.043e+02, Test loss: 1.299e+02, MSE(e): 6.545e-07, MSE(pi1): 2.523e-03, MSE(pi2): 3.517e-07, MSE(pi3): 7.256e-04\n",
      "Epoch 32600, Train loss: 1.055e+02, Test loss: 1.158e+02, MSE(e): 9.932e-07, MSE(pi1): 2.476e-03, MSE(pi2): 5.160e-07, MSE(pi3): 7.082e-04\n",
      "Epoch 32700, Train loss: 2.224e+02, Test loss: 1.979e+02, MSE(e): 1.212e-05, MSE(pi1): 3.376e-03, MSE(pi2): 5.547e-06, MSE(pi3): 6.738e-04\n",
      "Epoch 32800, Train loss: 1.034e+02, Test loss: 1.110e+02, MSE(e): 8.768e-07, MSE(pi1): 2.423e-03, MSE(pi2): 3.899e-07, MSE(pi3): 7.037e-04\n",
      "Epoch 32900, Train loss: 1.074e+02, Test loss: 1.126e+02, MSE(e): 1.127e-06, MSE(pi1): 2.546e-03, MSE(pi2): 5.259e-07, MSE(pi3): 7.068e-04\n",
      "Epoch 33000, Train loss: 1.164e+02, Test loss: 1.303e+02, MSE(e): 2.139e-06, MSE(pi1): 2.537e-03, MSE(pi2): 1.058e-06, MSE(pi3): 6.967e-04\n",
      "Epoch 33100, Train loss: 1.316e+02, Test loss: 1.500e+02, MSE(e): 3.436e-06, MSE(pi1): 2.618e-03, MSE(pi2): 1.476e-06, MSE(pi3): 7.107e-04\n",
      "Epoch 33200, Train loss: 1.030e+02, Test loss: 1.168e+02, MSE(e): 5.727e-07, MSE(pi1): 2.693e-03, MSE(pi2): 2.664e-07, MSE(pi3): 7.030e-04\n",
      "Epoch 33300, Train loss: 1.489e+02, Test loss: 1.458e+02, MSE(e): 4.783e-06, MSE(pi1): 3.252e-03, MSE(pi2): 1.898e-06, MSE(pi3): 6.859e-04\n",
      "Epoch 33400, Train loss: 1.220e+02, Test loss: 1.598e+02, MSE(e): 2.256e-06, MSE(pi1): 3.026e-03, MSE(pi2): 1.077e-06, MSE(pi3): 6.916e-04\n",
      "Epoch 33500, Train loss: 1.006e+02, Test loss: 1.104e+02, MSE(e): 4.968e-07, MSE(pi1): 2.516e-03, MSE(pi2): 2.357e-07, MSE(pi3): 7.044e-04\n",
      "Epoch 33600, Train loss: 1.084e+02, Test loss: 1.172e+02, MSE(e): 8.861e-07, MSE(pi1): 2.821e-03, MSE(pi2): 5.284e-07, MSE(pi3): 7.133e-04\n",
      "Epoch 33700, Train loss: 1.005e+02, Test loss: 1.141e+02, MSE(e): 4.593e-07, MSE(pi1): 2.517e-03, MSE(pi2): 2.258e-07, MSE(pi3): 7.077e-04\n",
      "Epoch 33800, Train loss: 1.233e+02, Test loss: 1.365e+02, MSE(e): 1.604e-06, MSE(pi1): 3.823e-03, MSE(pi2): 8.085e-07, MSE(pi3): 6.902e-04\n",
      "Epoch 33900, Train loss: 1.259e+02, Test loss: 1.554e+02, MSE(e): 2.951e-06, MSE(pi1): 2.690e-03, MSE(pi2): 1.477e-06, MSE(pi3): 6.945e-04\n",
      "Epoch 34000, Train loss: 1.087e+02, Test loss: 1.271e+02, MSE(e): 1.030e-06, MSE(pi1): 2.978e-03, MSE(pi2): 4.990e-07, MSE(pi3): 6.863e-04\n",
      "Epoch 34100, Train loss: 1.301e+02, Test loss: 1.328e+02, MSE(e): 2.360e-06, MSE(pi1): 3.294e-03, MSE(pi2): 1.216e-06, MSE(pi3): 7.352e-04\n",
      "Epoch 34200, Train loss: 9.893e+01, Test loss: 1.087e+02, MSE(e): 3.693e-07, MSE(pi1): 2.452e-03, MSE(pi2): 1.794e-07, MSE(pi3): 7.072e-04\n",
      "Epoch 34300, Train loss: 1.106e+02, Test loss: 1.110e+02, MSE(e): 1.060e-06, MSE(pi1): 2.975e-03, MSE(pi2): 5.153e-07, MSE(pi3): 7.028e-04\n",
      "Epoch 34400, Train loss: 1.509e+02, Test loss: 1.784e+02, MSE(e): 2.595e-06, MSE(pi1): 5.224e-03, MSE(pi2): 1.102e-06, MSE(pi3): 7.272e-04\n",
      "Epoch 34500, Train loss: 1.073e+02, Test loss: 1.156e+02, MSE(e): 8.229e-07, MSE(pi1): 2.785e-03, MSE(pi2): 5.309e-07, MSE(pi3): 7.117e-04\n",
      "Epoch 34600, Train loss: 1.079e+02, Test loss: 1.292e+02, MSE(e): 1.047e-06, MSE(pi1): 2.590e-03, MSE(pi2): 6.336e-07, MSE(pi3): 7.155e-04\n",
      "Epoch 34700, Train loss: 1.109e+02, Test loss: 1.245e+02, MSE(e): 1.002e-06, MSE(pi1): 3.304e-03, MSE(pi2): 4.657e-07, MSE(pi3): 6.787e-04\n",
      "Epoch 34800, Train loss: 1.069e+02, Test loss: 1.280e+02, MSE(e): 1.063e-06, MSE(pi1): 2.520e-03, MSE(pi2): 4.847e-07, MSE(pi3): 7.112e-04\n",
      "Epoch 34900, Train loss: 1.036e+02, Test loss: 1.195e+02, MSE(e): 8.567e-07, MSE(pi1): 2.416e-03, MSE(pi2): 3.957e-07, MSE(pi3): 7.088e-04\n",
      "Epoch 35000, Train loss: 1.214e+02, Test loss: 1.290e+02, MSE(e): 2.311e-06, MSE(pi1): 2.740e-03, MSE(pi2): 1.024e-06, MSE(pi3): 7.087e-04\n",
      "Epoch 35100, Train loss: 1.076e+02, Test loss: 1.214e+02, MSE(e): 1.044e-06, MSE(pi1): 2.680e-03, MSE(pi2): 4.907e-07, MSE(pi3): 7.033e-04\n",
      "Epoch 35200, Train loss: 1.448e+02, Test loss: 1.582e+02, MSE(e): 4.922e-06, MSE(pi1): 2.346e-03, MSE(pi2): 2.283e-06, MSE(pi3): 7.216e-04\n",
      "Epoch 35300, Train loss: 1.355e+02, Test loss: 1.287e+02, MSE(e): 4.000e-06, MSE(pi1): 2.722e-03, MSE(pi2): 1.833e-06, MSE(pi3): 6.828e-04\n",
      "Epoch 35400, Train loss: 9.932e+01, Test loss: 1.085e+02, MSE(e): 4.172e-07, MSE(pi1): 2.579e-03, MSE(pi2): 2.215e-07, MSE(pi3): 6.936e-04\n",
      "Epoch 35500, Train loss: 1.068e+02, Test loss: 1.268e+02, MSE(e): 6.858e-07, MSE(pi1): 3.159e-03, MSE(pi2): 2.691e-07, MSE(pi3): 6.840e-04\n",
      "Epoch 35600, Train loss: 1.125e+02, Test loss: 1.212e+02, MSE(e): 1.042e-06, MSE(pi1): 3.344e-03, MSE(pi2): 4.610e-07, MSE(pi3): 6.862e-04\n",
      "Epoch 35700, Train loss: 1.103e+02, Test loss: 1.379e+02, MSE(e): 1.020e-06, MSE(pi1): 3.306e-03, MSE(pi2): 5.048e-07, MSE(pi3): 6.703e-04\n",
      "Epoch 35800, Train loss: 1.125e+02, Test loss: 1.267e+02, MSE(e): 1.487e-06, MSE(pi1): 2.896e-03, MSE(pi2): 8.120e-07, MSE(pi3): 6.864e-04\n",
      "Epoch 35900, Train loss: 1.035e+02, Test loss: 1.147e+02, MSE(e): 5.784e-07, MSE(pi1): 2.851e-03, MSE(pi2): 2.243e-07, MSE(pi3): 6.916e-04\n",
      "Epoch 36000, Train loss: 1.192e+02, Test loss: 1.310e+02, MSE(e): 1.852e-06, MSE(pi1): 2.602e-03, MSE(pi2): 1.123e-06, MSE(pi3): 7.461e-04\n",
      "Epoch 36100, Train loss: 1.075e+02, Test loss: 1.341e+02, MSE(e): 7.972e-07, MSE(pi1): 3.257e-03, MSE(pi2): 3.486e-07, MSE(pi3): 6.691e-04\n",
      "Epoch 36200, Train loss: 1.369e+02, Test loss: 1.286e+02, MSE(e): 3.678e-06, MSE(pi1): 3.039e-03, MSE(pi2): 1.906e-06, MSE(pi3): 6.974e-04\n",
      "Epoch 36300, Train loss: 1.054e+02, Test loss: 1.167e+02, MSE(e): 8.520e-07, MSE(pi1): 2.613e-03, MSE(pi2): 4.446e-07, MSE(pi3): 7.078e-04\n",
      "Epoch 36400, Train loss: 1.034e+02, Test loss: 1.147e+02, MSE(e): 6.989e-07, MSE(pi1): 2.751e-03, MSE(pi2): 3.217e-07, MSE(pi3): 6.887e-04\n",
      "Epoch 36500, Train loss: 1.021e+02, Test loss: 1.102e+02, MSE(e): 7.699e-07, MSE(pi1): 2.477e-03, MSE(pi2): 3.961e-07, MSE(pi3): 6.961e-04\n",
      "Epoch 36600, Train loss: 1.560e+02, Test loss: 1.579e+02, MSE(e): 4.649e-06, MSE(pi1): 3.992e-03, MSE(pi2): 2.000e-06, MSE(pi3): 6.960e-04\n",
      "Epoch 36700, Train loss: 1.164e+02, Test loss: 1.293e+02, MSE(e): 1.201e-06, MSE(pi1): 3.358e-03, MSE(pi2): 5.542e-07, MSE(pi3): 7.085e-04\n",
      "Epoch 36800, Train loss: 1.042e+02, Test loss: 1.177e+02, MSE(e): 6.863e-07, MSE(pi1): 2.543e-03, MSE(pi2): 3.413e-07, MSE(pi3): 7.196e-04\n",
      "Epoch 36900, Train loss: 1.506e+02, Test loss: 1.524e+02, MSE(e): 5.406e-06, MSE(pi1): 2.317e-03, MSE(pi2): 2.508e-06, MSE(pi3): 7.334e-04\n",
      "Epoch 37000, Train loss: 1.096e+02, Test loss: 1.185e+02, MSE(e): 1.159e-06, MSE(pi1): 2.714e-03, MSE(pi2): 5.830e-07, MSE(pi3): 7.084e-04\n",
      "Epoch 37100, Train loss: 1.215e+02, Test loss: 1.330e+02, MSE(e): 1.166e-06, MSE(pi1): 3.925e-03, MSE(pi2): 4.419e-07, MSE(pi3): 7.059e-04\n",
      "Epoch 37200, Train loss: 1.625e+02, Test loss: 1.563e+02, MSE(e): 5.300e-06, MSE(pi1): 3.892e-03, MSE(pi2): 3.603e-06, MSE(pi3): 7.054e-04\n",
      "Epoch 37300, Train loss: 1.032e+02, Test loss: 1.085e+02, MSE(e): 8.307e-07, MSE(pi1): 2.489e-03, MSE(pi2): 5.088e-07, MSE(pi3): 6.996e-04\n",
      "Epoch 37400, Train loss: 1.117e+02, Test loss: 1.239e+02, MSE(e): 1.260e-06, MSE(pi1): 2.911e-03, MSE(pi2): 8.256e-07, MSE(pi3): 7.002e-04\n",
      "Epoch 37500, Train loss: 1.133e+02, Test loss: 1.197e+02, MSE(e): 1.881e-06, MSE(pi1): 2.521e-03, MSE(pi2): 8.812e-07, MSE(pi3): 6.925e-04\n",
      "Epoch 37600, Train loss: 1.069e+02, Test loss: 1.186e+02, MSE(e): 7.003e-07, MSE(pi1): 2.936e-03, MSE(pi2): 3.498e-07, MSE(pi3): 7.056e-04\n",
      "Epoch 37700, Train loss: 1.740e+02, Test loss: 1.446e+02, MSE(e): 7.479e-06, MSE(pi1): 2.837e-03, MSE(pi2): 3.303e-06, MSE(pi3): 7.080e-04\n",
      "Epoch 37800, Train loss: 1.306e+02, Test loss: 1.284e+02, MSE(e): 3.590e-06, MSE(pi1): 2.296e-03, MSE(pi2): 1.552e-06, MSE(pi3): 7.174e-04\n",
      "Epoch 37900, Train loss: 1.085e+02, Test loss: 1.245e+02, MSE(e): 7.793e-07, MSE(pi1): 3.069e-03, MSE(pi2): 3.238e-07, MSE(pi3): 7.001e-04\n",
      "Epoch 38000, Train loss: 1.074e+02, Test loss: 1.173e+02, MSE(e): 9.720e-07, MSE(pi1): 2.761e-03, MSE(pi2): 5.840e-07, MSE(pi3): 7.004e-04\n",
      "Epoch 38100, Train loss: 1.279e+02, Test loss: 1.442e+02, MSE(e): 1.362e-06, MSE(pi1): 4.390e-03, MSE(pi2): 6.780e-07, MSE(pi3): 7.039e-04\n",
      "Epoch 38200, Train loss: 1.037e+02, Test loss: 1.159e+02, MSE(e): 4.937e-07, MSE(pi1): 2.984e-03, MSE(pi2): 1.939e-07, MSE(pi3): 6.889e-04\n",
      "Epoch 38300, Train loss: 1.065e+02, Test loss: 1.387e+02, MSE(e): 7.084e-07, MSE(pi1): 2.574e-03, MSE(pi2): 3.327e-07, MSE(pi3): 7.363e-04\n",
      "Epoch 38400, Train loss: 1.120e+02, Test loss: 1.259e+02, MSE(e): 1.241e-06, MSE(pi1): 2.926e-03, MSE(pi2): 5.139e-07, MSE(pi3): 7.029e-04\n",
      "Epoch 38500, Train loss: 1.834e+02, Test loss: 1.572e+02, MSE(e): 8.107e-06, MSE(pi1): 3.086e-03, MSE(pi2): 3.660e-06, MSE(pi3): 7.145e-04\n",
      "Epoch 38600, Train loss: 1.231e+02, Test loss: 1.312e+02, MSE(e): 2.549e-06, MSE(pi1): 2.751e-03, MSE(pi2): 1.181e-06, MSE(pi3): 7.005e-04\n",
      "Epoch 38700, Train loss: 1.087e+02, Test loss: 1.390e+02, MSE(e): 9.546e-07, MSE(pi1): 2.867e-03, MSE(pi2): 4.169e-07, MSE(pi3): 7.049e-04\n",
      "Epoch 38800, Train loss: 1.257e+02, Test loss: 1.379e+02, MSE(e): 2.634e-06, MSE(pi1): 2.976e-03, MSE(pi2): 1.276e-06, MSE(pi3): 6.955e-04\n",
      "Epoch 38900, Train loss: 1.025e+02, Test loss: 1.194e+02, MSE(e): 7.944e-07, MSE(pi1): 2.496e-03, MSE(pi2): 4.012e-07, MSE(pi3): 6.957e-04\n",
      "Epoch 39000, Train loss: 1.195e+02, Test loss: 1.255e+02, MSE(e): 1.503e-06, MSE(pi1): 3.360e-03, MSE(pi2): 7.468e-07, MSE(pi3): 7.087e-04\n",
      "Epoch 39100, Train loss: 1.028e+02, Test loss: 1.167e+02, MSE(e): 5.188e-07, MSE(pi1): 2.837e-03, MSE(pi2): 2.294e-07, MSE(pi3): 6.924e-04\n",
      "Epoch 39200, Train loss: 1.232e+02, Test loss: 1.295e+02, MSE(e): 2.066e-06, MSE(pi1): 3.345e-03, MSE(pi2): 9.357e-07, MSE(pi3): 6.910e-04\n",
      "Epoch 39300, Train loss: 1.126e+02, Test loss: 1.147e+02, MSE(e): 1.821e-06, MSE(pi1): 2.450e-03, MSE(pi2): 8.065e-07, MSE(pi3): 6.987e-04\n",
      "Epoch 39400, Train loss: 9.841e+01, Test loss: 1.113e+02, MSE(e): 4.211e-07, MSE(pi1): 2.367e-03, MSE(pi2): 2.104e-07, MSE(pi3): 7.054e-04\n",
      "Epoch 39500, Train loss: 1.058e+02, Test loss: 1.189e+02, MSE(e): 8.065e-07, MSE(pi1): 2.899e-03, MSE(pi2): 4.479e-07, MSE(pi3): 6.872e-04\n",
      "Epoch 39600, Train loss: 1.049e+02, Test loss: 1.222e+02, MSE(e): 7.041e-07, MSE(pi1): 2.825e-03, MSE(pi2): 2.951e-07, MSE(pi3): 6.959e-04\n",
      "Epoch 39700, Train loss: 2.165e+02, Test loss: 1.530e+02, MSE(e): 1.108e-05, MSE(pi1): 3.439e-03, MSE(pi2): 5.399e-06, MSE(pi3): 7.130e-04\n",
      "Epoch 39800, Train loss: 1.042e+02, Test loss: 1.208e+02, MSE(e): 8.733e-07, MSE(pi1): 2.573e-03, MSE(pi2): 5.302e-07, MSE(pi3): 6.974e-04\n",
      "Epoch 39900, Train loss: 1.357e+02, Test loss: 1.473e+02, MSE(e): 3.268e-06, MSE(pi1): 3.169e-03, MSE(pi2): 1.534e-06, MSE(pi3): 7.137e-04\n",
      "Epoch 40000, Train loss: 1.031e+02, Test loss: 1.180e+02, MSE(e): 6.191e-07, MSE(pi1): 2.781e-03, MSE(pi2): 3.340e-07, MSE(pi3): 6.911e-04\n",
      "Epoch 40100, Train loss: 1.075e+02, Test loss: 1.177e+02, MSE(e): 1.074e-06, MSE(pi1): 2.733e-03, MSE(pi2): 7.621e-07, MSE(pi3): 6.946e-04\n",
      "Epoch 40200, Train loss: 1.091e+02, Test loss: 1.255e+02, MSE(e): 9.986e-07, MSE(pi1): 2.730e-03, MSE(pi2): 4.141e-07, MSE(pi3): 7.186e-04\n",
      "Epoch 40300, Train loss: 1.026e+02, Test loss: 1.149e+02, MSE(e): 4.889e-07, MSE(pi1): 2.631e-03, MSE(pi2): 2.184e-07, MSE(pi3): 7.138e-04\n",
      "Epoch 40400, Train loss: 1.273e+02, Test loss: 1.697e+02, MSE(e): 2.325e-06, MSE(pi1): 3.498e-03, MSE(pi2): 9.212e-07, MSE(pi3): 6.903e-04\n",
      "Epoch 40500, Train loss: 1.491e+02, Test loss: 1.375e+02, MSE(e): 5.415e-06, MSE(pi1): 2.524e-03, MSE(pi2): 2.960e-06, MSE(pi3): 6.970e-04\n",
      "Epoch 40600, Train loss: 1.199e+02, Test loss: 1.601e+02, MSE(e): 1.675e-06, MSE(pi1): 3.064e-03, MSE(pi2): 6.275e-07, MSE(pi3): 7.249e-04\n",
      "Epoch 40700, Train loss: 1.238e+02, Test loss: 1.299e+02, MSE(e): 2.721e-06, MSE(pi1): 2.652e-03, MSE(pi2): 1.146e-06, MSE(pi3): 7.007e-04\n",
      "Epoch 40800, Train loss: 1.069e+02, Test loss: 1.229e+02, MSE(e): 8.478e-07, MSE(pi1): 2.639e-03, MSE(pi2): 4.091e-07, MSE(pi3): 7.203e-04\n",
      "Epoch 40900, Train loss: 1.116e+02, Test loss: 1.269e+02, MSE(e): 1.238e-06, MSE(pi1): 2.661e-03, MSE(pi2): 4.924e-07, MSE(pi3): 7.261e-04\n",
      "Epoch 41000, Train loss: 9.877e+01, Test loss: 1.083e+02, MSE(e): 3.812e-07, MSE(pi1): 2.607e-03, MSE(pi2): 2.221e-07, MSE(pi3): 6.888e-04\n",
      "Epoch 41100, Train loss: 1.686e+02, Test loss: 1.369e+02, MSE(e): 7.324e-06, MSE(pi1): 2.785e-03, MSE(pi2): 3.921e-06, MSE(pi3): 6.749e-04\n",
      "Epoch 41200, Train loss: 1.014e+02, Test loss: 1.120e+02, MSE(e): 5.341e-07, MSE(pi1): 2.740e-03, MSE(pi2): 3.034e-07, MSE(pi3): 6.868e-04\n",
      "Epoch 41300, Train loss: 1.024e+02, Test loss: 1.152e+02, MSE(e): 6.637e-07, MSE(pi1): 2.573e-03, MSE(pi2): 3.624e-07, MSE(pi3): 7.005e-04\n",
      "Epoch 41400, Train loss: 1.027e+02, Test loss: 1.115e+02, MSE(e): 8.166e-07, MSE(pi1): 2.321e-03, MSE(pi2): 4.435e-07, MSE(pi3): 7.135e-04\n",
      "Epoch 41500, Train loss: 1.043e+02, Test loss: 1.249e+02, MSE(e): 5.207e-07, MSE(pi1): 3.055e-03, MSE(pi2): 2.668e-07, MSE(pi3): 6.859e-04\n",
      "Epoch 41600, Train loss: 1.143e+02, Test loss: 1.231e+02, MSE(e): 1.249e-06, MSE(pi1): 3.218e-03, MSE(pi2): 7.220e-07, MSE(pi3): 6.962e-04\n",
      "Epoch 41700, Train loss: 1.033e+02, Test loss: 1.107e+02, MSE(e): 4.888e-07, MSE(pi1): 2.597e-03, MSE(pi2): 2.029e-07, MSE(pi3): 7.247e-04\n",
      "Epoch 41800, Train loss: 1.023e+02, Test loss: 1.134e+02, MSE(e): 5.346e-07, MSE(pi1): 2.942e-03, MSE(pi2): 2.776e-07, MSE(pi3): 6.758e-04\n",
      "Epoch 41900, Train loss: 1.133e+02, Test loss: 1.269e+02, MSE(e): 1.025e-06, MSE(pi1): 3.217e-03, MSE(pi2): 5.318e-07, MSE(pi3): 7.085e-04\n",
      "Epoch 42000, Train loss: 1.146e+02, Test loss: 1.401e+02, MSE(e): 1.445e-06, MSE(pi1): 3.010e-03, MSE(pi2): 6.110e-07, MSE(pi3): 7.000e-04\n",
      "Epoch 42100, Train loss: 1.160e+02, Test loss: 1.389e+02, MSE(e): 1.846e-06, MSE(pi1): 2.678e-03, MSE(pi2): 8.959e-07, MSE(pi3): 7.075e-04\n",
      "Epoch 42200, Train loss: 1.106e+02, Test loss: 1.200e+02, MSE(e): 1.461e-06, MSE(pi1): 2.552e-03, MSE(pi2): 8.223e-07, MSE(pi3): 7.044e-04\n",
      "Epoch 42300, Train loss: 1.159e+02, Test loss: 1.370e+02, MSE(e): 2.093e-06, MSE(pi1): 2.451e-03, MSE(pi2): 9.367e-07, MSE(pi3): 7.046e-04\n",
      "Epoch 42400, Train loss: 1.059e+02, Test loss: 1.180e+02, MSE(e): 8.760e-07, MSE(pi1): 2.677e-03, MSE(pi2): 4.387e-07, MSE(pi3): 7.037e-04\n",
      "Epoch 42500, Train loss: 1.193e+02, Test loss: 1.335e+02, MSE(e): 1.301e-06, MSE(pi1): 3.672e-03, MSE(pi2): 5.359e-07, MSE(pi3): 6.957e-04\n",
      "Epoch 42600, Train loss: 1.079e+02, Test loss: 1.412e+02, MSE(e): 1.081e-06, MSE(pi1): 2.875e-03, MSE(pi2): 6.041e-07, MSE(pi3): 6.830e-04\n",
      "Epoch 42700, Train loss: 1.131e+02, Test loss: 1.296e+02, MSE(e): 1.532e-06, MSE(pi1): 2.730e-03, MSE(pi2): 7.813e-07, MSE(pi3): 7.052e-04\n",
      "Epoch 42800, Train loss: 1.055e+02, Test loss: 1.124e+02, MSE(e): 1.068e-06, MSE(pi1): 2.491e-03, MSE(pi2): 5.838e-07, MSE(pi3): 6.993e-04\n",
      "Epoch 42900, Train loss: 1.709e+02, Test loss: 1.433e+02, MSE(e): 6.544e-06, MSE(pi1): 3.931e-03, MSE(pi2): 3.522e-06, MSE(pi3): 6.619e-04\n",
      "Epoch 43000, Train loss: 1.037e+02, Test loss: 1.268e+02, MSE(e): 7.051e-07, MSE(pi1): 2.873e-03, MSE(pi2): 3.853e-07, MSE(pi3): 6.791e-04\n",
      "Epoch 43100, Train loss: 1.047e+02, Test loss: 1.144e+02, MSE(e): 8.353e-07, MSE(pi1): 2.407e-03, MSE(pi2): 4.827e-07, MSE(pi3): 7.232e-04\n",
      "Epoch 43200, Train loss: 1.348e+02, Test loss: 1.221e+02, MSE(e): 3.868e-06, MSE(pi1): 2.462e-03, MSE(pi2): 1.878e-06, MSE(pi3): 7.154e-04\n",
      "Epoch 43300, Train loss: 1.005e+02, Test loss: 1.145e+02, MSE(e): 4.495e-07, MSE(pi1): 2.426e-03, MSE(pi2): 2.045e-07, MSE(pi3): 7.170e-04\n",
      "Epoch 43400, Train loss: 2.008e+02, Test loss: 1.998e+02, MSE(e): 1.054e-05, MSE(pi1): 2.409e-03, MSE(pi2): 4.607e-06, MSE(pi3): 7.122e-04\n",
      "Epoch 43500, Train loss: 1.423e+02, Test loss: 1.624e+02, MSE(e): 4.742e-06, MSE(pi1): 2.629e-03, MSE(pi2): 2.424e-06, MSE(pi3): 6.857e-04\n",
      "Epoch 43600, Train loss: 1.099e+02, Test loss: 1.259e+02, MSE(e): 1.049e-06, MSE(pi1): 2.976e-03, MSE(pi2): 4.636e-07, MSE(pi3): 6.967e-04\n",
      "Epoch 43700, Train loss: 1.072e+02, Test loss: 1.167e+02, MSE(e): 1.059e-06, MSE(pi1): 2.591e-03, MSE(pi2): 6.232e-07, MSE(pi3): 7.074e-04\n",
      "Epoch 43800, Train loss: 1.227e+02, Test loss: 1.200e+02, MSE(e): 2.244e-06, MSE(pi1): 2.959e-03, MSE(pi2): 1.119e-06, MSE(pi3): 7.063e-04\n",
      "Epoch 43900, Train loss: 1.201e+02, Test loss: 1.572e+02, MSE(e): 2.045e-06, MSE(pi1): 2.722e-03, MSE(pi2): 9.999e-07, MSE(pi3): 7.248e-04\n",
      "Epoch 44000, Train loss: 1.043e+02, Test loss: 1.124e+02, MSE(e): 7.269e-07, MSE(pi1): 2.722e-03, MSE(pi2): 3.711e-07, MSE(pi3): 6.981e-04\n",
      "Epoch 44100, Train loss: 1.081e+02, Test loss: 1.275e+02, MSE(e): 9.870e-07, MSE(pi1): 2.707e-03, MSE(pi2): 5.740e-07, MSE(pi3): 7.120e-04\n",
      "Epoch 44200, Train loss: 1.077e+02, Test loss: 1.172e+02, MSE(e): 1.137e-06, MSE(pi1): 2.549e-03, MSE(pi2): 5.509e-07, MSE(pi3): 7.080e-04\n",
      "Epoch 44300, Train loss: 1.004e+02, Test loss: 1.073e+02, MSE(e): 3.420e-07, MSE(pi1): 2.579e-03, MSE(pi2): 1.812e-07, MSE(pi3): 7.117e-04\n",
      "Epoch 44400, Train loss: 1.200e+02, Test loss: 1.281e+02, MSE(e): 1.258e-06, MSE(pi1): 3.536e-03, MSE(pi2): 6.238e-07, MSE(pi3): 7.210e-04\n",
      "Epoch 44500, Train loss: 1.010e+02, Test loss: 1.170e+02, MSE(e): 5.143e-07, MSE(pi1): 2.767e-03, MSE(pi2): 2.766e-07, MSE(pi3): 6.822e-04\n",
      "Epoch 44600, Train loss: 1.018e+02, Test loss: 1.089e+02, MSE(e): 5.998e-07, MSE(pi1): 2.382e-03, MSE(pi2): 3.184e-07, MSE(pi3): 7.195e-04\n",
      "Epoch 44700, Train loss: 9.760e+01, Test loss: 1.065e+02, MSE(e): 3.389e-07, MSE(pi1): 2.392e-03, MSE(pi2): 1.856e-07, MSE(pi3): 7.029e-04\n",
      "Epoch 44800, Train loss: 1.337e+02, Test loss: 1.417e+02, MSE(e): 1.353e-06, MSE(pi1): 4.814e-03, MSE(pi2): 5.489e-07, MSE(pi3): 7.199e-04\n",
      "Epoch 44900, Train loss: 1.012e+02, Test loss: 1.086e+02, MSE(e): 3.849e-07, MSE(pi1): 2.687e-03, MSE(pi2): 1.769e-07, MSE(pi3): 7.044e-04\n",
      "Epoch 45000, Train loss: 9.856e+01, Test loss: 1.064e+02, MSE(e): 4.130e-07, MSE(pi1): 2.350e-03, MSE(pi2): 2.193e-07, MSE(pi3): 7.093e-04\n",
      "Epoch 45100, Train loss: 1.230e+02, Test loss: 1.282e+02, MSE(e): 2.803e-06, MSE(pi1): 2.549e-03, MSE(pi2): 1.401e-06, MSE(pi3): 6.946e-04\n",
      "Epoch 45200, Train loss: 1.425e+02, Test loss: 1.601e+02, MSE(e): 4.237e-06, MSE(pi1): 2.828e-03, MSE(pi2): 1.940e-06, MSE(pi3): 7.185e-04\n",
      "Epoch 45300, Train loss: 9.866e+01, Test loss: 1.056e+02, MSE(e): 3.966e-07, MSE(pi1): 2.561e-03, MSE(pi2): 1.917e-07, MSE(pi3): 6.908e-04\n",
      "Epoch 45400, Train loss: 1.054e+02, Test loss: 1.157e+02, MSE(e): 1.031e-06, MSE(pi1): 2.349e-03, MSE(pi2): 4.985e-07, MSE(pi3): 7.161e-04\n",
      "Epoch 45500, Train loss: 9.927e+01, Test loss: 1.121e+02, MSE(e): 3.939e-07, MSE(pi1): 2.517e-03, MSE(pi2): 2.507e-07, MSE(pi3): 7.017e-04\n",
      "Epoch 45600, Train loss: 1.131e+02, Test loss: 1.277e+02, MSE(e): 1.323e-06, MSE(pi1): 2.985e-03, MSE(pi2): 8.490e-07, MSE(pi3): 7.000e-04\n",
      "Epoch 45700, Train loss: 1.177e+02, Test loss: 1.361e+02, MSE(e): 1.372e-06, MSE(pi1): 3.675e-03, MSE(pi2): 5.425e-07, MSE(pi3): 6.728e-04\n",
      "Epoch 45800, Train loss: 1.939e+02, Test loss: 1.621e+02, MSE(e): 8.381e-06, MSE(pi1): 4.132e-03, MSE(pi2): 4.363e-06, MSE(pi3): 6.872e-04\n",
      "Epoch 45900, Train loss: 1.072e+02, Test loss: 1.135e+02, MSE(e): 6.014e-07, MSE(pi1): 2.924e-03, MSE(pi2): 2.554e-07, MSE(pi3): 7.195e-04\n",
      "Epoch 46000, Train loss: 1.160e+02, Test loss: 1.336e+02, MSE(e): 1.630e-06, MSE(pi1): 2.795e-03, MSE(pi2): 8.985e-07, MSE(pi3): 7.179e-04\n",
      "Epoch 46100, Train loss: 1.065e+02, Test loss: 1.143e+02, MSE(e): 7.941e-07, MSE(pi1): 2.762e-03, MSE(pi2): 4.161e-07, MSE(pi3): 7.097e-04\n",
      "Epoch 46200, Train loss: 1.130e+02, Test loss: 1.218e+02, MSE(e): 1.859e-06, MSE(pi1): 2.235e-03, MSE(pi2): 8.922e-07, MSE(pi3): 7.209e-04\n",
      "Epoch 46300, Train loss: 1.094e+02, Test loss: 1.184e+02, MSE(e): 1.077e-06, MSE(pi1): 2.815e-03, MSE(pi2): 6.742e-07, MSE(pi3): 7.052e-04\n",
      "Epoch 46400, Train loss: 1.068e+02, Test loss: 1.169e+02, MSE(e): 6.620e-07, MSE(pi1): 2.886e-03, MSE(pi2): 3.067e-07, MSE(pi3): 7.135e-04\n",
      "Epoch 46500, Train loss: 1.056e+02, Test loss: 1.221e+02, MSE(e): 7.865e-07, MSE(pi1): 2.724e-03, MSE(pi2): 3.946e-07, MSE(pi3): 7.053e-04\n",
      "Epoch 46600, Train loss: 1.116e+02, Test loss: 1.220e+02, MSE(e): 9.822e-07, MSE(pi1): 3.493e-03, MSE(pi2): 4.648e-07, MSE(pi3): 6.681e-04\n",
      "Epoch 46700, Train loss: 1.638e+02, Test loss: 1.526e+02, MSE(e): 6.821e-06, MSE(pi1): 2.835e-03, MSE(pi2): 3.449e-06, MSE(pi3): 6.727e-04\n",
      "Epoch 46800, Train loss: 1.062e+02, Test loss: 1.297e+02, MSE(e): 8.451e-07, MSE(pi1): 2.687e-03, MSE(pi2): 3.481e-07, MSE(pi3): 7.084e-04\n",
      "Epoch 46900, Train loss: 1.038e+02, Test loss: 1.239e+02, MSE(e): 4.525e-07, MSE(pi1): 2.915e-03, MSE(pi2): 2.052e-07, MSE(pi3): 7.010e-04\n",
      "Epoch 47000, Train loss: 1.057e+02, Test loss: 1.213e+02, MSE(e): 8.233e-07, MSE(pi1): 2.837e-03, MSE(pi2): 4.156e-07, MSE(pi3): 6.907e-04\n",
      "Epoch 47100, Train loss: 1.539e+02, Test loss: 1.331e+02, MSE(e): 5.200e-06, MSE(pi1): 3.747e-03, MSE(pi2): 2.868e-06, MSE(pi3): 6.441e-04\n",
      "Epoch 47200, Train loss: 1.020e+02, Test loss: 1.082e+02, MSE(e): 5.138e-07, MSE(pi1): 2.603e-03, MSE(pi2): 2.364e-07, MSE(pi3): 7.086e-04\n",
      "Epoch 47300, Train loss: 1.048e+02, Test loss: 1.097e+02, MSE(e): 7.364e-07, MSE(pi1): 2.910e-03, MSE(pi2): 3.997e-07, MSE(pi3): 6.830e-04\n",
      "Epoch 47400, Train loss: 1.005e+02, Test loss: 1.072e+02, MSE(e): 6.374e-07, MSE(pi1): 2.399e-03, MSE(pi2): 3.522e-07, MSE(pi3): 7.018e-04\n",
      "Epoch 47500, Train loss: 1.065e+02, Test loss: 1.132e+02, MSE(e): 7.592e-07, MSE(pi1): 3.009e-03, MSE(pi2): 4.299e-07, MSE(pi3): 6.878e-04\n",
      "Epoch 47600, Train loss: 9.999e+01, Test loss: 1.071e+02, MSE(e): 4.758e-07, MSE(pi1): 2.530e-03, MSE(pi2): 3.522e-07, MSE(pi3): 6.993e-04\n",
      "Epoch 47700, Train loss: 1.005e+02, Test loss: 1.071e+02, MSE(e): 4.570e-07, MSE(pi1): 2.671e-03, MSE(pi2): 2.581e-07, MSE(pi3): 6.921e-04\n",
      "Epoch 47800, Train loss: 1.023e+02, Test loss: 1.092e+02, MSE(e): 7.951e-07, MSE(pi1): 2.506e-03, MSE(pi2): 4.693e-07, MSE(pi3): 6.925e-04\n",
      "Epoch 47900, Train loss: 1.011e+02, Test loss: 1.087e+02, MSE(e): 5.462e-07, MSE(pi1): 2.704e-03, MSE(pi2): 2.999e-07, MSE(pi3): 6.861e-04\n",
      "Epoch 48000, Train loss: 1.239e+02, Test loss: 1.222e+02, MSE(e): 2.270e-06, MSE(pi1): 2.750e-03, MSE(pi2): 1.715e-06, MSE(pi3): 7.373e-04\n",
      "Epoch 48100, Train loss: 1.055e+02, Test loss: 1.291e+02, MSE(e): 8.036e-07, MSE(pi1): 2.645e-03, MSE(pi2): 4.396e-07, MSE(pi3): 7.096e-04\n",
      "Epoch 48200, Train loss: 1.014e+02, Test loss: 1.117e+02, MSE(e): 4.847e-07, MSE(pi1): 2.799e-03, MSE(pi2): 3.021e-07, MSE(pi3): 6.854e-04\n",
      "Epoch 48300, Train loss: 9.989e+01, Test loss: 1.096e+02, MSE(e): 4.982e-07, MSE(pi1): 2.497e-03, MSE(pi2): 2.723e-07, MSE(pi3): 6.994e-04\n",
      "Epoch 48400, Train loss: 1.029e+02, Test loss: 1.204e+02, MSE(e): 6.770e-07, MSE(pi1): 2.813e-03, MSE(pi2): 4.057e-07, MSE(pi3): 6.803e-04\n",
      "Epoch 48500, Train loss: 1.018e+02, Test loss: 1.173e+02, MSE(e): 6.883e-07, MSE(pi1): 2.504e-03, MSE(pi2): 3.849e-07, MSE(pi3): 6.988e-04\n",
      "Epoch 48600, Train loss: 1.020e+02, Test loss: 1.077e+02, MSE(e): 7.239e-07, MSE(pi1): 2.427e-03, MSE(pi2): 4.583e-07, MSE(pi3): 7.051e-04\n",
      "Epoch 48700, Train loss: 1.031e+02, Test loss: 1.099e+02, MSE(e): 4.058e-07, MSE(pi1): 3.108e-03, MSE(pi2): 2.184e-07, MSE(pi3): 6.794e-04\n",
      "Epoch 48800, Train loss: 1.272e+02, Test loss: 1.222e+02, MSE(e): 3.181e-06, MSE(pi1): 2.338e-03, MSE(pi2): 1.555e-06, MSE(pi3): 7.205e-04\n",
      "Epoch 48900, Train loss: 9.924e+01, Test loss: 1.080e+02, MSE(e): 4.074e-07, MSE(pi1): 2.585e-03, MSE(pi2): 2.234e-07, MSE(pi3): 6.931e-04\n",
      "Epoch 49000, Train loss: 1.246e+02, Test loss: 1.228e+02, MSE(e): 2.223e-06, MSE(pi1): 3.054e-03, MSE(pi2): 1.116e-06, MSE(pi3): 7.186e-04\n",
      "Epoch 49100, Train loss: 1.080e+02, Test loss: 1.230e+02, MSE(e): 1.076e-06, MSE(pi1): 2.838e-03, MSE(pi2): 4.714e-07, MSE(pi3): 6.889e-04\n",
      "Epoch 49200, Train loss: 9.791e+01, Test loss: 1.066e+02, MSE(e): 2.942e-07, MSE(pi1): 2.472e-03, MSE(pi2): 1.620e-07, MSE(pi3): 7.025e-04\n",
      "Epoch 49300, Train loss: 1.002e+02, Test loss: 1.087e+02, MSE(e): 3.645e-07, MSE(pi1): 2.617e-03, MSE(pi2): 2.105e-07, MSE(pi3): 7.036e-04\n",
      "Epoch 49400, Train loss: 1.270e+02, Test loss: 1.125e+02, MSE(e): 3.208e-06, MSE(pi1): 2.464e-03, MSE(pi2): 1.695e-06, MSE(pi3): 7.023e-04\n",
      "Epoch 49500, Train loss: 1.308e+02, Test loss: 1.479e+02, MSE(e): 1.951e-06, MSE(pi1): 4.326e-03, MSE(pi2): 7.585e-07, MSE(pi3): 6.806e-04\n",
      "Epoch 49600, Train loss: 1.084e+02, Test loss: 1.136e+02, MSE(e): 1.338e-06, MSE(pi1): 2.518e-03, MSE(pi2): 5.638e-07, MSE(pi3): 6.986e-04\n",
      "Epoch 49700, Train loss: 1.057e+02, Test loss: 1.129e+02, MSE(e): 8.959e-07, MSE(pi1): 2.529e-03, MSE(pi2): 5.142e-07, MSE(pi3): 7.144e-04\n",
      "Epoch 49800, Train loss: 1.051e+02, Test loss: 1.201e+02, MSE(e): 7.716e-07, MSE(pi1): 2.778e-03, MSE(pi2): 3.196e-07, MSE(pi3): 6.958e-04\n",
      "Epoch 49900, Train loss: 9.929e+01, Test loss: 1.115e+02, MSE(e): 3.324e-07, MSE(pi1): 2.729e-03, MSE(pi2): 1.441e-07, MSE(pi3): 6.867e-04\n",
      "Epoch 50000, Train loss: 1.118e+02, Test loss: 1.148e+02, MSE(e): 1.559e-06, MSE(pi1): 2.479e-03, MSE(pi2): 7.692e-07, MSE(pi3): 7.146e-04\n",
      "Epoch 50100, Train loss: 1.114e+02, Test loss: 1.253e+02, MSE(e): 1.040e-06, MSE(pi1): 3.008e-03, MSE(pi2): 5.074e-07, MSE(pi3): 7.095e-04\n",
      "Epoch 50200, Train loss: 9.946e+01, Test loss: 1.068e+02, MSE(e): 5.078e-07, MSE(pi1): 2.263e-03, MSE(pi2): 2.768e-07, MSE(pi3): 7.175e-04\n",
      "Epoch 50300, Train loss: 1.011e+02, Test loss: 1.100e+02, MSE(e): 4.775e-07, MSE(pi1): 2.842e-03, MSE(pi2): 3.225e-07, MSE(pi3): 6.790e-04\n",
      "Epoch 50400, Train loss: 1.089e+02, Test loss: 1.257e+02, MSE(e): 1.241e-06, MSE(pi1): 2.554e-03, MSE(pi2): 5.856e-07, MSE(pi3): 7.098e-04\n",
      "Epoch 50500, Train loss: 1.026e+02, Test loss: 1.092e+02, MSE(e): 8.213e-07, MSE(pi1): 2.492e-03, MSE(pi2): 4.856e-07, MSE(pi3): 6.947e-04\n",
      "Epoch 50600, Train loss: 1.042e+02, Test loss: 1.171e+02, MSE(e): 8.220e-07, MSE(pi1): 2.542e-03, MSE(pi2): 5.034e-07, MSE(pi3): 7.054e-04\n",
      "Epoch 50700, Train loss: 1.050e+02, Test loss: 1.115e+02, MSE(e): 1.032e-06, MSE(pi1): 2.449e-03, MSE(pi2): 5.995e-07, MSE(pi3): 7.024e-04\n",
      "Epoch 50800, Train loss: 1.025e+02, Test loss: 1.090e+02, MSE(e): 8.102e-07, MSE(pi1): 2.646e-03, MSE(pi2): 4.406e-07, MSE(pi3): 6.796e-04\n",
      "Epoch 50900, Train loss: 1.222e+02, Test loss: 1.408e+02, MSE(e): 2.342e-06, MSE(pi1): 2.825e-03, MSE(pi2): 1.086e-06, MSE(pi3): 7.055e-04\n",
      "Epoch 51000, Train loss: 1.090e+02, Test loss: 1.310e+02, MSE(e): 9.096e-07, MSE(pi1): 3.069e-03, MSE(pi2): 3.356e-07, MSE(pi3): 6.917e-04\n",
      "Epoch 51100, Train loss: 1.050e+02, Test loss: 1.135e+02, MSE(e): 4.599e-07, MSE(pi1): 3.214e-03, MSE(pi2): 1.857e-07, MSE(pi3): 6.825e-04\n",
      "Epoch 51200, Train loss: 1.336e+02, Test loss: 1.219e+02, MSE(e): 3.671e-06, MSE(pi1): 2.685e-03, MSE(pi2): 1.803e-06, MSE(pi3): 7.006e-04\n",
      "Epoch 51300, Train loss: 1.890e+02, Test loss: 1.362e+02, MSE(e): 9.234e-06, MSE(pi1): 2.428e-03, MSE(pi2): 4.901e-06, MSE(pi3): 7.238e-04\n",
      "Epoch 51400, Train loss: 1.096e+02, Test loss: 1.127e+02, MSE(e): 1.338e-06, MSE(pi1): 2.426e-03, MSE(pi2): 6.763e-07, MSE(pi3): 7.192e-04\n",
      "Epoch 51500, Train loss: 1.101e+02, Test loss: 1.200e+02, MSE(e): 1.379e-06, MSE(pi1): 2.384e-03, MSE(pi2): 6.912e-07, MSE(pi3): 7.242e-04\n",
      "Epoch 51600, Train loss: 1.117e+02, Test loss: 1.438e+02, MSE(e): 1.420e-06, MSE(pi1): 2.669e-03, MSE(pi2): 8.116e-07, MSE(pi3): 7.082e-04\n",
      "Epoch 51700, Train loss: 1.063e+02, Test loss: 1.130e+02, MSE(e): 8.985e-07, MSE(pi1): 2.674e-03, MSE(pi2): 5.945e-07, MSE(pi3): 7.059e-04\n",
      "Epoch 51800, Train loss: 9.972e+01, Test loss: 1.073e+02, MSE(e): 4.268e-07, MSE(pi1): 2.514e-03, MSE(pi2): 2.165e-07, MSE(pi3): 7.031e-04\n",
      "Epoch 51900, Train loss: 1.300e+02, Test loss: 1.664e+02, MSE(e): 3.372e-06, MSE(pi1): 2.493e-03, MSE(pi2): 1.416e-06, MSE(pi3): 7.138e-04\n",
      "Epoch 52000, Train loss: 1.026e+02, Test loss: 1.151e+02, MSE(e): 5.912e-07, MSE(pi1): 2.617e-03, MSE(pi2): 3.491e-07, MSE(pi3): 7.050e-04\n",
      "Epoch 52100, Train loss: 1.053e+02, Test loss: 1.203e+02, MSE(e): 8.287e-07, MSE(pi1): 2.683e-03, MSE(pi2): 4.896e-07, MSE(pi3): 7.019e-04\n",
      "Epoch 52200, Train loss: 1.068e+02, Test loss: 1.177e+02, MSE(e): 8.611e-07, MSE(pi1): 2.810e-03, MSE(pi2): 3.837e-07, MSE(pi3): 7.005e-04\n",
      "Epoch 52300, Train loss: 1.050e+02, Test loss: 1.206e+02, MSE(e): 6.876e-07, MSE(pi1): 2.977e-03, MSE(pi2): 3.670e-07, MSE(pi3): 6.840e-04\n",
      "Epoch 52400, Train loss: 1.058e+02, Test loss: 1.193e+02, MSE(e): 8.170e-07, MSE(pi1): 2.785e-03, MSE(pi2): 4.266e-07, MSE(pi3): 6.979e-04\n",
      "Epoch 52500, Train loss: 1.079e+02, Test loss: 1.132e+02, MSE(e): 7.995e-07, MSE(pi1): 2.668e-03, MSE(pi2): 4.655e-07, MSE(pi3): 7.325e-04\n",
      "Epoch 52600, Train loss: 1.338e+02, Test loss: 1.615e+02, MSE(e): 2.588e-06, MSE(pi1): 4.047e-03, MSE(pi2): 1.187e-06, MSE(pi3): 6.740e-04\n",
      "Epoch 52700, Train loss: 1.136e+02, Test loss: 1.228e+02, MSE(e): 1.098e-06, MSE(pi1): 3.186e-03, MSE(pi2): 4.189e-07, MSE(pi3): 7.078e-04\n",
      "Epoch 52800, Train loss: 1.049e+02, Test loss: 1.334e+02, MSE(e): 8.153e-07, MSE(pi1): 2.750e-03, MSE(pi2): 4.054e-07, MSE(pi3): 6.921e-04\n",
      "Epoch 52900, Train loss: 1.321e+02, Test loss: 1.271e+02, MSE(e): 3.508e-06, MSE(pi1): 3.061e-03, MSE(pi2): 1.757e-06, MSE(pi3): 6.638e-04\n",
      "Epoch 53000, Train loss: 1.089e+02, Test loss: 1.147e+02, MSE(e): 1.368e-06, MSE(pi1): 2.425e-03, MSE(pi2): 8.173e-07, MSE(pi3): 7.094e-04\n",
      "Epoch 53100, Train loss: 1.144e+02, Test loss: 1.171e+02, MSE(e): 1.668e-06, MSE(pi1): 2.627e-03, MSE(pi2): 9.054e-07, MSE(pi3): 7.140e-04\n",
      "Epoch 53200, Train loss: 1.033e+02, Test loss: 1.098e+02, MSE(e): 8.032e-07, MSE(pi1): 2.398e-03, MSE(pi2): 4.915e-07, MSE(pi3): 7.132e-04\n",
      "Epoch 53300, Train loss: 1.047e+02, Test loss: 1.155e+02, MSE(e): 8.247e-07, MSE(pi1): 2.544e-03, MSE(pi2): 5.572e-07, MSE(pi3): 7.097e-04\n",
      "Epoch 53400, Train loss: 1.129e+02, Test loss: 1.306e+02, MSE(e): 9.648e-07, MSE(pi1): 3.064e-03, MSE(pi2): 4.358e-07, MSE(pi3): 7.260e-04\n",
      "Epoch 53500, Train loss: 1.246e+02, Test loss: 1.229e+02, MSE(e): 1.961e-06, MSE(pi1): 3.452e-03, MSE(pi2): 9.729e-07, MSE(pi3): 7.045e-04\n",
      "Epoch 53600, Train loss: 1.068e+02, Test loss: 1.132e+02, MSE(e): 1.147e-06, MSE(pi1): 2.548e-03, MSE(pi2): 5.849e-07, MSE(pi3): 6.985e-04\n",
      "Epoch 53700, Train loss: 1.094e+02, Test loss: 1.293e+02, MSE(e): 9.713e-07, MSE(pi1): 3.168e-03, MSE(pi2): 5.567e-07, MSE(pi3): 6.801e-04\n",
      "Epoch 53800, Train loss: 1.167e+02, Test loss: 1.335e+02, MSE(e): 1.679e-06, MSE(pi1): 2.766e-03, MSE(pi2): 8.655e-07, MSE(pi3): 7.226e-04\n",
      "Epoch 53900, Train loss: 1.707e+02, Test loss: 1.333e+02, MSE(e): 6.977e-06, MSE(pi1): 3.230e-03, MSE(pi2): 3.659e-06, MSE(pi3): 6.866e-04\n",
      "Epoch 54000, Train loss: 1.019e+02, Test loss: 1.075e+02, MSE(e): 7.058e-07, MSE(pi1): 2.559e-03, MSE(pi2): 4.149e-07, MSE(pi3): 6.928e-04\n",
      "Epoch 54100, Train loss: 1.033e+02, Test loss: 1.156e+02, MSE(e): 6.619e-07, MSE(pi1): 2.526e-03, MSE(pi2): 4.114e-07, MSE(pi3): 7.137e-04\n",
      "Epoch 54200, Train loss: 1.087e+02, Test loss: 1.157e+02, MSE(e): 8.824e-07, MSE(pi1): 2.941e-03, MSE(pi2): 4.910e-07, MSE(pi3): 7.049e-04\n",
      "Epoch 54300, Train loss: 1.588e+02, Test loss: 1.318e+02, MSE(e): 6.370e-06, MSE(pi1): 2.335e-03, MSE(pi2): 2.949e-06, MSE(pi3): 7.173e-04\n",
      "Epoch 54400, Train loss: 1.299e+02, Test loss: 1.346e+02, MSE(e): 3.432e-06, MSE(pi1): 2.668e-03, MSE(pi2): 1.676e-06, MSE(pi3): 6.891e-04\n",
      "Epoch 54500, Train loss: 1.293e+02, Test loss: 1.687e+02, MSE(e): 3.359e-06, MSE(pi1): 2.696e-03, MSE(pi2): 1.790e-06, MSE(pi3): 6.877e-04\n",
      "Epoch 54600, Train loss: 1.043e+02, Test loss: 1.175e+02, MSE(e): 8.708e-07, MSE(pi1): 2.440e-03, MSE(pi2): 4.327e-07, MSE(pi3): 7.122e-04\n",
      "Epoch 54700, Train loss: 1.363e+02, Test loss: 1.170e+02, MSE(e): 3.878e-06, MSE(pi1): 2.377e-03, MSE(pi2): 1.962e-06, MSE(pi3): 7.379e-04\n",
      "Epoch 54800, Train loss: 1.079e+02, Test loss: 1.410e+02, MSE(e): 1.206e-06, MSE(pi1): 2.467e-03, MSE(pi2): 8.522e-07, MSE(pi3): 7.117e-04\n",
      "Epoch 54900, Train loss: 1.247e+02, Test loss: 1.132e+02, MSE(e): 2.722e-06, MSE(pi1): 2.470e-03, MSE(pi2): 1.478e-06, MSE(pi3): 7.273e-04\n",
      "Epoch 55000, Train loss: 1.107e+02, Test loss: 1.216e+02, MSE(e): 1.107e-06, MSE(pi1): 2.951e-03, MSE(pi2): 6.323e-07, MSE(pi3): 7.008e-04\n",
      "Epoch 55100, Train loss: 1.039e+02, Test loss: 1.123e+02, MSE(e): 8.726e-07, MSE(pi1): 2.525e-03, MSE(pi2): 5.147e-07, MSE(pi3): 6.992e-04\n",
      "Epoch 55200, Train loss: 1.156e+02, Test loss: 1.187e+02, MSE(e): 1.865e-06, MSE(pi1): 2.387e-03, MSE(pi2): 1.013e-06, MSE(pi3): 7.305e-04\n",
      "Epoch 55300, Train loss: 1.133e+02, Test loss: 1.412e+02, MSE(e): 1.450e-06, MSE(pi1): 2.594e-03, MSE(pi2): 6.966e-07, MSE(pi3): 7.286e-04\n",
      "Epoch 55400, Train loss: 1.021e+02, Test loss: 1.161e+02, MSE(e): 5.919e-07, MSE(pi1): 2.620e-03, MSE(pi2): 3.107e-07, MSE(pi3): 6.996e-04\n",
      "Epoch 55500, Train loss: 9.811e+01, Test loss: 1.065e+02, MSE(e): 3.049e-07, MSE(pi1): 2.413e-03, MSE(pi2): 1.767e-07, MSE(pi3): 7.093e-04\n",
      "Epoch 55600, Train loss: 9.866e+01, Test loss: 1.057e+02, MSE(e): 4.219e-07, MSE(pi1): 2.494e-03, MSE(pi2): 2.439e-07, MSE(pi3): 6.950e-04\n",
      "Epoch 55700, Train loss: 1.095e+02, Test loss: 1.482e+02, MSE(e): 1.432e-06, MSE(pi1): 2.378e-03, MSE(pi2): 8.145e-07, MSE(pi3): 7.142e-04\n",
      "Epoch 55800, Train loss: 1.018e+02, Test loss: 1.087e+02, MSE(e): 6.904e-07, MSE(pi1): 2.368e-03, MSE(pi2): 4.169e-07, MSE(pi3): 7.119e-04\n",
      "Epoch 55900, Train loss: 1.172e+02, Test loss: 1.255e+02, MSE(e): 1.305e-06, MSE(pi1): 3.420e-03, MSE(pi2): 7.547e-07, MSE(pi3): 6.997e-04\n",
      "Epoch 56000, Train loss: 1.026e+02, Test loss: 1.203e+02, MSE(e): 5.923e-07, MSE(pi1): 2.647e-03, MSE(pi2): 3.118e-07, MSE(pi3): 7.020e-04\n",
      "Epoch 56100, Train loss: 1.208e+02, Test loss: 1.655e+02, MSE(e): 1.477e-06, MSE(pi1): 3.810e-03, MSE(pi2): 8.301e-07, MSE(pi3): 6.789e-04\n",
      "Epoch 56200, Train loss: 1.305e+02, Test loss: 1.307e+02, MSE(e): 3.377e-06, MSE(pi1): 2.323e-03, MSE(pi2): 1.639e-06, MSE(pi3): 7.354e-04\n",
      "Epoch 56300, Train loss: 1.404e+02, Test loss: 1.369e+02, MSE(e): 3.253e-06, MSE(pi1): 3.723e-03, MSE(pi2): 1.581e-06, MSE(pi3): 7.061e-04\n",
      "Epoch 56400, Train loss: 9.895e+01, Test loss: 1.082e+02, MSE(e): 3.943e-07, MSE(pi1): 2.503e-03, MSE(pi2): 2.018e-07, MSE(pi3): 6.998e-04\n",
      "Epoch 56500, Train loss: 1.072e+02, Test loss: 1.148e+02, MSE(e): 1.070e-06, MSE(pi1): 2.620e-03, MSE(pi2): 5.671e-07, MSE(pi3): 7.030e-04\n",
      "Epoch 56600, Train loss: 1.002e+02, Test loss: 1.178e+02, MSE(e): 4.351e-07, MSE(pi1): 2.361e-03, MSE(pi2): 2.503e-07, MSE(pi3): 7.222e-04\n",
      "Epoch 56700, Train loss: 1.230e+02, Test loss: 1.259e+02, MSE(e): 2.249e-06, MSE(pi1): 2.867e-03, MSE(pi2): 1.034e-06, MSE(pi3): 7.188e-04\n",
      "Epoch 56800, Train loss: 1.219e+02, Test loss: 1.335e+02, MSE(e): 1.566e-06, MSE(pi1): 3.766e-03, MSE(pi2): 9.208e-07, MSE(pi3): 6.857e-04\n",
      "Epoch 56900, Train loss: 1.065e+02, Test loss: 1.155e+02, MSE(e): 7.611e-07, MSE(pi1): 2.946e-03, MSE(pi2): 3.686e-07, MSE(pi3): 6.944e-04\n",
      "Epoch 57000, Train loss: 1.012e+02, Test loss: 1.156e+02, MSE(e): 6.283e-07, MSE(pi1): 2.527e-03, MSE(pi2): 3.818e-07, MSE(pi3): 6.965e-04\n",
      "Epoch 57100, Train loss: 1.296e+02, Test loss: 1.505e+02, MSE(e): 3.152e-06, MSE(pi1): 2.776e-03, MSE(pi2): 1.330e-06, MSE(pi3): 7.027e-04\n",
      "Epoch 57200, Train loss: 1.014e+02, Test loss: 1.075e+02, MSE(e): 6.460e-07, MSE(pi1): 2.387e-03, MSE(pi2): 3.308e-07, MSE(pi3): 7.103e-04\n",
      "Epoch 57300, Train loss: 1.086e+02, Test loss: 1.206e+02, MSE(e): 1.257e-06, MSE(pi1): 2.542e-03, MSE(pi2): 7.374e-07, MSE(pi3): 7.058e-04\n",
      "Epoch 57400, Train loss: 1.003e+02, Test loss: 1.078e+02, MSE(e): 4.169e-07, MSE(pi1): 2.617e-03, MSE(pi2): 2.306e-07, MSE(pi3): 7.000e-04\n",
      "Epoch 57500, Train loss: 1.355e+02, Test loss: 1.144e+02, MSE(e): 3.717e-06, MSE(pi1): 2.854e-03, MSE(pi2): 1.815e-06, MSE(pi3): 6.978e-04\n",
      "Epoch 57600, Train loss: 1.007e+02, Test loss: 1.112e+02, MSE(e): 4.033e-07, MSE(pi1): 2.652e-03, MSE(pi2): 2.237e-07, MSE(pi3): 7.013e-04\n",
      "Epoch 57700, Train loss: 1.052e+02, Test loss: 1.238e+02, MSE(e): 8.026e-07, MSE(pi1): 2.551e-03, MSE(pi2): 4.644e-07, MSE(pi3): 7.168e-04\n",
      "Epoch 57800, Train loss: 1.711e+02, Test loss: 1.681e+02, MSE(e): 5.405e-06, MSE(pi1): 4.311e-03, MSE(pi2): 3.047e-06, MSE(pi3): 7.398e-04\n",
      "Epoch 57900, Train loss: 1.053e+02, Test loss: 1.144e+02, MSE(e): 1.063e-06, MSE(pi1): 2.405e-03, MSE(pi2): 5.399e-07, MSE(pi3): 7.057e-04\n",
      "Epoch 58000, Train loss: 1.040e+02, Test loss: 1.235e+02, MSE(e): 8.441e-07, MSE(pi1): 2.424e-03, MSE(pi2): 5.061e-07, MSE(pi3): 7.133e-04\n",
      "Epoch 58100, Train loss: 1.098e+02, Test loss: 1.165e+02, MSE(e): 1.292e-06, MSE(pi1): 2.749e-03, MSE(pi2): 6.399e-07, MSE(pi3): 6.943e-04\n",
      "Epoch 58200, Train loss: 9.810e+01, Test loss: 1.058e+02, MSE(e): 3.610e-07, MSE(pi1): 2.408e-03, MSE(pi2): 2.083e-07, MSE(pi3): 7.041e-04\n",
      "Epoch 58300, Train loss: 1.183e+02, Test loss: 1.325e+02, MSE(e): 2.229e-06, MSE(pi1): 2.288e-03, MSE(pi2): 1.076e-06, MSE(pi3): 7.312e-04\n",
      "Epoch 58400, Train loss: 1.422e+02, Test loss: 1.679e+02, MSE(e): 2.616e-06, MSE(pi1): 4.966e-03, MSE(pi2): 1.435e-06, MSE(pi3): 6.634e-04\n",
      "Epoch 58500, Train loss: 1.270e+02, Test loss: 1.122e+02, MSE(e): 3.176e-06, MSE(pi1): 2.339e-03, MSE(pi2): 1.644e-06, MSE(pi3): 7.181e-04\n",
      "Epoch 58600, Train loss: 1.221e+02, Test loss: 1.382e+02, MSE(e): 1.733e-06, MSE(pi1): 3.395e-03, MSE(pi2): 1.006e-06, MSE(pi3): 7.087e-04\n",
      "Epoch 58700, Train loss: 1.005e+02, Test loss: 1.081e+02, MSE(e): 4.633e-07, MSE(pi1): 2.493e-03, MSE(pi2): 2.255e-07, MSE(pi3): 7.094e-04\n",
      "Epoch 58800, Train loss: 1.099e+02, Test loss: 1.168e+02, MSE(e): 1.263e-06, MSE(pi1): 2.599e-03, MSE(pi2): 6.492e-07, MSE(pi3): 7.131e-04\n",
      "Epoch 58900, Train loss: 1.003e+02, Test loss: 1.116e+02, MSE(e): 4.267e-07, MSE(pi1): 2.626e-03, MSE(pi2): 1.903e-07, MSE(pi3): 6.982e-04\n",
      "Epoch 59000, Train loss: 1.115e+02, Test loss: 1.241e+02, MSE(e): 9.922e-07, MSE(pi1): 3.116e-03, MSE(pi2): 4.697e-07, MSE(pi3): 7.047e-04\n",
      "Epoch 59100, Train loss: 1.300e+02, Test loss: 1.238e+02, MSE(e): 3.496e-06, MSE(pi1): 2.360e-03, MSE(pi2): 1.721e-06, MSE(pi3): 7.141e-04\n",
      "Epoch 59200, Train loss: 1.089e+02, Test loss: 1.204e+02, MSE(e): 1.157e-06, MSE(pi1): 2.569e-03, MSE(pi2): 6.509e-07, MSE(pi3): 7.166e-04\n",
      "Epoch 59300, Train loss: 1.450e+02, Test loss: 1.215e+02, MSE(e): 4.966e-06, MSE(pi1): 2.745e-03, MSE(pi2): 2.748e-06, MSE(pi3): 6.788e-04\n",
      "Epoch 59400, Train loss: 1.128e+02, Test loss: 1.401e+02, MSE(e): 1.609e-06, MSE(pi1): 2.638e-03, MSE(pi2): 7.002e-07, MSE(pi3): 7.037e-04\n",
      "Epoch 59500, Train loss: 1.013e+02, Test loss: 1.159e+02, MSE(e): 5.025e-07, MSE(pi1): 2.332e-03, MSE(pi2): 2.958e-07, MSE(pi3): 7.296e-04\n",
      "Epoch 59600, Train loss: 9.710e+01, Test loss: 1.051e+02, MSE(e): 2.472e-07, MSE(pi1): 2.367e-03, MSE(pi2): 1.491e-07, MSE(pi3): 7.095e-04\n",
      "Epoch 59700, Train loss: 1.121e+02, Test loss: 1.206e+02, MSE(e): 1.546e-06, MSE(pi1): 2.530e-03, MSE(pi2): 7.848e-07, MSE(pi3): 7.131e-04\n",
      "Epoch 59800, Train loss: 1.104e+02, Test loss: 1.154e+02, MSE(e): 1.044e-06, MSE(pi1): 3.167e-03, MSE(pi2): 6.311e-07, MSE(pi3): 6.825e-04\n",
      "Epoch 59900, Train loss: 1.201e+02, Test loss: 1.366e+02, MSE(e): 2.173e-06, MSE(pi1): 2.908e-03, MSE(pi2): 1.135e-06, MSE(pi3): 6.930e-04\n",
      "Epoch 60000, Train loss: 1.034e+02, Test loss: 1.167e+02, MSE(e): 6.942e-07, MSE(pi1): 2.415e-03, MSE(pi2): 4.570e-07, MSE(pi3): 7.226e-04\n",
      "Epoch 60100, Train loss: 1.139e+02, Test loss: 1.214e+02, MSE(e): 1.692e-06, MSE(pi1): 2.711e-03, MSE(pi2): 1.076e-06, MSE(pi3): 6.985e-04\n",
      "Epoch 60200, Train loss: 1.338e+02, Test loss: 1.468e+02, MSE(e): 3.507e-06, MSE(pi1): 2.900e-03, MSE(pi2): 1.647e-06, MSE(pi3): 6.973e-04\n",
      "Epoch 60300, Train loss: 1.166e+02, Test loss: 1.197e+02, MSE(e): 1.055e-06, MSE(pi1): 3.752e-03, MSE(pi2): 4.986e-07, MSE(pi3): 6.851e-04\n",
      "Epoch 60400, Train loss: 1.053e+02, Test loss: 1.116e+02, MSE(e): 1.050e-06, MSE(pi1): 2.485e-03, MSE(pi2): 5.940e-07, MSE(pi3): 6.998e-04\n",
      "Epoch 60500, Train loss: 1.071e+02, Test loss: 1.194e+02, MSE(e): 1.230e-06, MSE(pi1): 2.538e-03, MSE(pi2): 6.793e-07, MSE(pi3): 6.939e-04\n",
      "Epoch 60600, Train loss: 1.003e+02, Test loss: 1.105e+02, MSE(e): 4.345e-07, MSE(pi1): 2.546e-03, MSE(pi2): 2.345e-07, MSE(pi3): 7.052e-04\n",
      "Epoch 60700, Train loss: 1.328e+02, Test loss: 1.515e+02, MSE(e): 2.030e-06, MSE(pi1): 3.525e-03, MSE(pi2): 1.042e-06, MSE(pi3): 7.721e-04\n",
      "Epoch 60800, Train loss: 1.094e+02, Test loss: 1.090e+02, MSE(e): 1.498e-06, MSE(pi1): 2.342e-03, MSE(pi2): 7.219e-07, MSE(pi3): 7.102e-04\n",
      "Epoch 60900, Train loss: 1.380e+02, Test loss: 1.166e+02, MSE(e): 4.252e-06, MSE(pi1): 2.312e-03, MSE(pi2): 2.448e-06, MSE(pi3): 7.235e-04\n",
      "Epoch 61000, Train loss: 1.343e+02, Test loss: 1.480e+02, MSE(e): 2.483e-06, MSE(pi1): 3.445e-03, MSE(pi2): 1.235e-06, MSE(pi3): 7.504e-04\n",
      "Epoch 61100, Train loss: 9.855e+01, Test loss: 1.063e+02, MSE(e): 3.410e-07, MSE(pi1): 2.392e-03, MSE(pi2): 1.695e-07, MSE(pi3): 7.121e-04\n",
      "Epoch 61200, Train loss: 1.220e+02, Test loss: 1.545e+02, MSE(e): 2.626e-06, MSE(pi1): 2.612e-03, MSE(pi2): 1.476e-06, MSE(pi3): 6.958e-04\n",
      "Epoch 61300, Train loss: 1.187e+02, Test loss: 1.758e+02, MSE(e): 1.439e-06, MSE(pi1): 3.315e-03, MSE(pi2): 7.707e-07, MSE(pi3): 7.114e-04\n",
      "Epoch 61400, Train loss: 1.194e+02, Test loss: 1.366e+02, MSE(e): 1.562e-06, MSE(pi1): 3.165e-03, MSE(pi2): 7.622e-07, MSE(pi3): 7.211e-04\n",
      "Epoch 61500, Train loss: 1.099e+02, Test loss: 1.223e+02, MSE(e): 8.503e-07, MSE(pi1): 3.196e-03, MSE(pi2): 3.145e-07, MSE(pi3): 6.942e-04\n",
      "Epoch 61600, Train loss: 1.527e+02, Test loss: 1.466e+02, MSE(e): 5.106e-06, MSE(pi1): 2.725e-03, MSE(pi2): 2.537e-06, MSE(pi3): 7.439e-04\n",
      "Epoch 61700, Train loss: 1.175e+02, Test loss: 1.615e+02, MSE(e): 2.184e-06, MSE(pi1): 2.462e-03, MSE(pi2): 1.426e-06, MSE(pi3): 7.103e-04\n",
      "Epoch 61800, Train loss: 1.061e+02, Test loss: 1.213e+02, MSE(e): 5.557e-07, MSE(pi1): 3.297e-03, MSE(pi2): 2.821e-07, MSE(pi3): 6.756e-04\n",
      "Epoch 61900, Train loss: 1.597e+02, Test loss: 1.452e+02, MSE(e): 4.871e-06, MSE(pi1): 4.094e-03, MSE(pi2): 2.314e-06, MSE(pi3): 7.002e-04\n",
      "Epoch 62000, Train loss: 9.833e+01, Test loss: 1.082e+02, MSE(e): 3.233e-07, MSE(pi1): 2.493e-03, MSE(pi2): 1.725e-07, MSE(pi3): 7.017e-04\n",
      "Epoch 62100, Train loss: 9.910e+01, Test loss: 1.124e+02, MSE(e): 4.427e-07, MSE(pi1): 2.456e-03, MSE(pi2): 2.714e-07, MSE(pi3): 7.012e-04\n",
      "Epoch 62200, Train loss: 1.184e+02, Test loss: 1.535e+02, MSE(e): 2.178e-06, MSE(pi1): 2.616e-03, MSE(pi2): 1.122e-06, MSE(pi3): 7.047e-04\n",
      "Epoch 62300, Train loss: 1.109e+02, Test loss: 1.297e+02, MSE(e): 1.179e-06, MSE(pi1): 2.964e-03, MSE(pi2): 5.726e-07, MSE(pi3): 6.950e-04\n",
      "Epoch 62400, Train loss: 1.413e+02, Test loss: 1.314e+02, MSE(e): 4.283e-06, MSE(pi1): 2.927e-03, MSE(pi2): 2.045e-06, MSE(pi3): 6.922e-04\n",
      "Epoch 62500, Train loss: 1.147e+02, Test loss: 1.175e+02, MSE(e): 1.923e-06, MSE(pi1): 2.604e-03, MSE(pi2): 1.076e-06, MSE(pi3): 6.943e-04\n",
      "Epoch 62600, Train loss: 1.011e+02, Test loss: 1.098e+02, MSE(e): 4.614e-07, MSE(pi1): 2.539e-03, MSE(pi2): 2.450e-07, MSE(pi3): 7.112e-04\n",
      "Epoch 62700, Train loss: 1.157e+02, Test loss: 1.334e+02, MSE(e): 1.556e-06, MSE(pi1): 2.634e-03, MSE(pi2): 1.127e-06, MSE(pi3): 7.375e-04\n",
      "Epoch 62800, Train loss: 1.031e+02, Test loss: 1.140e+02, MSE(e): 6.174e-07, MSE(pi1): 2.733e-03, MSE(pi2): 3.408e-07, MSE(pi3): 6.959e-04\n",
      "Epoch 62900, Train loss: 1.031e+02, Test loss: 1.161e+02, MSE(e): 6.820e-07, MSE(pi1): 2.457e-03, MSE(pi2): 4.339e-07, MSE(pi3): 7.175e-04\n",
      "Epoch 63000, Train loss: 9.972e+01, Test loss: 1.098e+02, MSE(e): 3.764e-07, MSE(pi1): 2.534e-03, MSE(pi2): 2.179e-07, MSE(pi3): 7.061e-04\n",
      "Epoch 63100, Train loss: 1.156e+02, Test loss: 1.655e+02, MSE(e): 1.558e-06, MSE(pi1): 3.024e-03, MSE(pi2): 7.328e-07, MSE(pi3): 6.983e-04\n",
      "Epoch 63200, Train loss: 1.065e+02, Test loss: 1.166e+02, MSE(e): 8.844e-07, MSE(pi1): 2.669e-03, MSE(pi2): 5.013e-07, MSE(pi3): 7.094e-04\n",
      "Epoch 63300, Train loss: 1.245e+02, Test loss: 1.297e+02, MSE(e): 2.565e-06, MSE(pi1): 2.452e-03, MSE(pi2): 1.362e-06, MSE(pi3): 7.432e-04\n",
      "Epoch 63400, Train loss: 1.149e+02, Test loss: 1.249e+02, MSE(e): 1.836e-06, MSE(pi1): 2.508e-03, MSE(pi2): 8.685e-07, MSE(pi3): 7.144e-04\n",
      "Epoch 63500, Train loss: 1.012e+02, Test loss: 1.143e+02, MSE(e): 4.381e-07, MSE(pi1): 2.669e-03, MSE(pi2): 1.929e-07, MSE(pi3): 7.009e-04\n",
      "Epoch 63600, Train loss: 1.429e+02, Test loss: 1.439e+02, MSE(e): 4.618e-06, MSE(pi1): 2.467e-03, MSE(pi2): 2.258e-06, MSE(pi3): 7.201e-04\n",
      "Epoch 63700, Train loss: 1.167e+02, Test loss: 1.329e+02, MSE(e): 8.656e-07, MSE(pi1): 3.756e-03, MSE(pi2): 3.250e-07, MSE(pi3): 7.048e-04\n",
      "Epoch 63800, Train loss: 1.045e+02, Test loss: 1.086e+02, MSE(e): 6.743e-07, MSE(pi1): 2.800e-03, MSE(pi2): 4.172e-07, MSE(pi3): 6.979e-04\n",
      "Epoch 63900, Train loss: 1.301e+02, Test loss: 1.277e+02, MSE(e): 1.226e-06, MSE(pi1): 4.797e-03, MSE(pi2): 4.367e-07, MSE(pi3): 6.985e-04\n",
      "Epoch 64000, Train loss: 1.038e+02, Test loss: 1.163e+02, MSE(e): 6.603e-07, MSE(pi1): 2.822e-03, MSE(pi2): 2.988e-07, MSE(pi3): 6.893e-04\n",
      "Epoch 64100, Train loss: 1.103e+02, Test loss: 1.274e+02, MSE(e): 1.300e-06, MSE(pi1): 2.786e-03, MSE(pi2): 7.393e-07, MSE(pi3): 6.945e-04\n",
      "Epoch 64200, Train loss: 1.383e+02, Test loss: 1.216e+02, MSE(e): 4.225e-06, MSE(pi1): 2.518e-03, MSE(pi2): 2.392e-06, MSE(pi3): 7.083e-04\n",
      "Epoch 64300, Train loss: 1.221e+02, Test loss: 1.239e+02, MSE(e): 2.310e-06, MSE(pi1): 2.723e-03, MSE(pi2): 1.065e-06, MSE(pi3): 7.178e-04\n",
      "Epoch 64400, Train loss: 1.081e+02, Test loss: 1.288e+02, MSE(e): 9.070e-07, MSE(pi1): 3.232e-03, MSE(pi2): 4.275e-07, MSE(pi3): 6.666e-04\n",
      "Epoch 64500, Train loss: 1.068e+02, Test loss: 1.217e+02, MSE(e): 9.567e-07, MSE(pi1): 3.014e-03, MSE(pi2): 4.952e-07, MSE(pi3): 6.710e-04\n",
      "Epoch 64600, Train loss: 1.074e+02, Test loss: 1.235e+02, MSE(e): 8.900e-07, MSE(pi1): 3.102e-03, MSE(pi2): 4.104e-07, MSE(pi3): 6.751e-04\n",
      "Epoch 64700, Train loss: 9.921e+01, Test loss: 1.118e+02, MSE(e): 3.626e-07, MSE(pi1): 2.505e-03, MSE(pi2): 1.949e-07, MSE(pi3): 7.054e-04\n",
      "Epoch 64800, Train loss: 1.451e+02, Test loss: 1.668e+02, MSE(e): 3.895e-06, MSE(pi1): 3.819e-03, MSE(pi2): 1.760e-06, MSE(pi3): 6.795e-04\n",
      "Epoch 64900, Train loss: 1.231e+02, Test loss: 1.420e+02, MSE(e): 2.659e-06, MSE(pi1): 2.532e-03, MSE(pi2): 1.477e-06, MSE(pi3): 7.124e-04\n",
      "Epoch 65000, Train loss: 1.229e+02, Test loss: 1.292e+02, MSE(e): 1.587e-06, MSE(pi1): 3.984e-03, MSE(pi2): 7.773e-07, MSE(pi3): 6.724e-04\n",
      "Epoch 65100, Train loss: 9.773e+01, Test loss: 1.058e+02, MSE(e): 3.174e-07, MSE(pi1): 2.355e-03, MSE(pi2): 1.771e-07, MSE(pi3): 7.100e-04\n",
      "Epoch 65200, Train loss: 1.042e+02, Test loss: 1.186e+02, MSE(e): 5.131e-07, MSE(pi1): 3.110e-03, MSE(pi2): 2.211e-07, MSE(pi3): 6.794e-04\n",
      "Epoch 65300, Train loss: 1.194e+02, Test loss: 1.305e+02, MSE(e): 2.227e-06, MSE(pi1): 2.604e-03, MSE(pi2): 1.264e-06, MSE(pi3): 7.110e-04\n",
      "Epoch 65400, Train loss: 1.296e+02, Test loss: 1.540e+02, MSE(e): 2.431e-06, MSE(pi1): 2.994e-03, MSE(pi2): 1.447e-06, MSE(pi3): 7.535e-04\n",
      "Epoch 65500, Train loss: 9.808e+01, Test loss: 1.093e+02, MSE(e): 3.452e-07, MSE(pi1): 2.419e-03, MSE(pi2): 1.890e-07, MSE(pi3): 7.044e-04\n",
      "Epoch 65600, Train loss: 9.737e+01, Test loss: 1.054e+02, MSE(e): 2.615e-07, MSE(pi1): 2.390e-03, MSE(pi2): 1.437e-07, MSE(pi3): 7.086e-04\n",
      "Epoch 65700, Train loss: 9.768e+01, Test loss: 1.088e+02, MSE(e): 3.096e-07, MSE(pi1): 2.395e-03, MSE(pi2): 1.648e-07, MSE(pi3): 7.063e-04\n",
      "Epoch 65800, Train loss: 1.069e+02, Test loss: 1.119e+02, MSE(e): 1.210e-06, MSE(pi1): 2.269e-03, MSE(pi2): 6.101e-07, MSE(pi3): 7.207e-04\n",
      "Epoch 65900, Train loss: 1.003e+02, Test loss: 1.080e+02, MSE(e): 6.071e-07, MSE(pi1): 2.363e-03, MSE(pi2): 3.221e-07, MSE(pi3): 7.060e-04\n",
      "Epoch 66000, Train loss: 9.994e+01, Test loss: 1.095e+02, MSE(e): 5.325e-07, MSE(pi1): 2.495e-03, MSE(pi2): 3.052e-07, MSE(pi3): 6.966e-04\n",
      "Epoch 66100, Train loss: 1.177e+02, Test loss: 1.333e+02, MSE(e): 1.379e-06, MSE(pi1): 3.295e-03, MSE(pi2): 9.265e-07, MSE(pi3): 7.092e-04\n",
      "Epoch 66200, Train loss: 1.162e+02, Test loss: 1.278e+02, MSE(e): 1.759e-06, MSE(pi1): 2.533e-03, MSE(pi2): 8.389e-07, MSE(pi3): 7.328e-04\n",
      "Epoch 66300, Train loss: 1.106e+02, Test loss: 1.227e+02, MSE(e): 1.609e-06, MSE(pi1): 2.325e-03, MSE(pi2): 7.760e-07, MSE(pi3): 7.126e-04\n",
      "Epoch 66400, Train loss: 1.278e+02, Test loss: 1.376e+02, MSE(e): 2.085e-06, MSE(pi1): 3.763e-03, MSE(pi2): 9.587e-07, MSE(pi3): 6.930e-04\n",
      "Epoch 66500, Train loss: 1.244e+02, Test loss: 1.518e+02, MSE(e): 2.025e-06, MSE(pi1): 3.545e-03, MSE(pi2): 8.424e-07, MSE(pi3): 6.867e-04\n",
      "Epoch 66600, Train loss: 1.104e+02, Test loss: 1.326e+02, MSE(e): 1.364e-06, MSE(pi1): 2.780e-03, MSE(pi2): 7.110e-07, MSE(pi3): 6.893e-04\n",
      "Epoch 66700, Train loss: 1.155e+02, Test loss: 1.204e+02, MSE(e): 1.578e-06, MSE(pi1): 2.815e-03, MSE(pi2): 7.708e-07, MSE(pi3): 7.160e-04\n",
      "Epoch 66800, Train loss: 9.671e+01, Test loss: 1.052e+02, MSE(e): 2.435e-07, MSE(pi1): 2.414e-03, MSE(pi2): 1.320e-07, MSE(pi3): 7.014e-04\n",
      "Epoch 66900, Train loss: 1.056e+02, Test loss: 1.150e+02, MSE(e): 1.061e-06, MSE(pi1): 2.295e-03, MSE(pi2): 6.257e-07, MSE(pi3): 7.199e-04\n",
      "Epoch 67000, Train loss: 1.178e+02, Test loss: 1.139e+02, MSE(e): 2.261e-06, MSE(pi1): 2.283e-03, MSE(pi2): 1.171e-06, MSE(pi3): 7.236e-04\n",
      "Epoch 67100, Train loss: 1.033e+02, Test loss: 1.075e+02, MSE(e): 7.287e-07, MSE(pi1): 2.739e-03, MSE(pi2): 3.591e-07, MSE(pi3): 6.866e-04\n",
      "Epoch 67200, Train loss: 1.242e+02, Test loss: 1.373e+02, MSE(e): 2.197e-06, MSE(pi1): 3.113e-03, MSE(pi2): 1.082e-06, MSE(pi3): 7.110e-04\n",
      "Epoch 67300, Train loss: 1.102e+02, Test loss: 1.415e+02, MSE(e): 1.276e-06, MSE(pi1): 2.466e-03, MSE(pi2): 6.838e-07, MSE(pi3): 7.282e-04\n",
      "Epoch 67400, Train loss: 1.136e+02, Test loss: 1.133e+02, MSE(e): 1.790e-06, MSE(pi1): 2.301e-03, MSE(pi2): 8.718e-07, MSE(pi3): 7.268e-04\n",
      "Epoch 67500, Train loss: 1.025e+02, Test loss: 1.232e+02, MSE(e): 7.598e-07, MSE(pi1): 2.519e-03, MSE(pi2): 4.105e-07, MSE(pi3): 6.967e-04\n",
      "Epoch 67600, Train loss: 1.083e+02, Test loss: 1.204e+02, MSE(e): 1.260e-06, MSE(pi1): 2.226e-03, MSE(pi2): 6.326e-07, MSE(pi3): 7.344e-04\n",
      "Epoch 67700, Train loss: 1.298e+02, Test loss: 1.342e+02, MSE(e): 2.245e-06, MSE(pi1): 3.614e-03, MSE(pi2): 1.170e-06, MSE(pi3): 7.120e-04\n",
      "Epoch 67800, Train loss: 1.097e+02, Test loss: 1.395e+02, MSE(e): 1.040e-06, MSE(pi1): 3.062e-03, MSE(pi2): 4.833e-07, MSE(pi3): 6.869e-04\n",
      "Epoch 67900, Train loss: 9.794e+01, Test loss: 1.099e+02, MSE(e): 3.474e-07, MSE(pi1): 2.335e-03, MSE(pi2): 1.729e-07, MSE(pi3): 7.112e-04\n",
      "Epoch 68000, Train loss: 9.708e+01, Test loss: 1.085e+02, MSE(e): 2.700e-07, MSE(pi1): 2.408e-03, MSE(pi2): 1.440e-07, MSE(pi3): 7.029e-04\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 10000\n",
    "n_epochs = 110001\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 100\n",
    "\n",
    "second_lr = 3e-5\n",
    "\n",
    "train_loop(model, optimizer, n_checkpoints,\n",
    "           X_train, y_train, X_test, y_test, f_train, f_test,\n",
    "           D=D, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=device,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
