{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from models.non_constant_diffusivity import NonConstantDiffusivityNeuralNetwork\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear/model few data\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/non_linear/non_linear_few_data.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/non_linear')\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/non_linear/model few data')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear/non_linear_few_data.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reshaped_data = y_train.values.to('cpu').detach().reshape(y_train.values.shape[0], -1)\n",
    "\n",
    "U, S, Vh = np.linalg.svd(reshaped_data, full_matrices=False)\n",
    "\n",
    "# Step 4: Reconstruct POD modes\n",
    "# POD modes are the columns of U, singular values are S\n",
    "pod_modes = U  # Each column of U is a POD mode\n",
    "singular_values = S  # Singular values give the importance of each mode\n",
    "\n",
    "# Step 5: Compute energy contribution of each mode (optional)\n",
    "energy_contribution = (S**2) / np.sum(S**2)\n",
    "\n",
    "# # Print results\n",
    "# print(\"POD Modes Shape:\", pod_modes.shape)  # Should be (100, 100), 100 modes\n",
    "# print(\"Singular Values:\", singular_values)\n",
    "# print(\"Energy Contribution of Each Mode:\", energy_contribution)\n",
    "\n",
    "\n",
    "# plt.plot(singular_values)\n",
    "# plt.show()\n",
    "# Optionally: Reconstruct the data using only a few POD modes\n",
    "# For example, reconstruct using the first 10 modes\n",
    "n_modes = 10\n",
    "reconstructed_data = np.dot(U[:, :n_modes], np.dot(np.diag(S[:n_modes]), Vh[:n_modes, :]))\n",
    "\n",
    "# print(\"Reconstructed Data Shape:\", reconstructed_data.shape)  # Should be (100, 100)\n",
    "\n",
    "plt.imshow(y_train.values.to('cpu').detach()[0, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(reconstructed_data.reshape(y_train.values.shape)[0, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow((y_train.values.to('cpu').detach() - reconstructed_data.reshape(y_train.values.shape))[0, 0])\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de los datos para dividirlos en train y test\n",
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = TensOps(torch.tensor(dataset['y_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_train = TensOps(torch.tensor(dataset['k_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_train = TensOps(torch.tensor(dataset['f_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "X_np = X_train\n",
    "y_np = y_train.values\n",
    "K_np = K_train.values\n",
    "f_np = f_train.values\n",
    "\n",
    "X_train_np, X_test_np, y_train_np, y_test_np, K_train_np, K_test_np, f_train_np, f_test_np = train_test_split(X_np, y_np, K_np, f_np, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train_np.to(device)\n",
    "X_test = X_test_np.to(device)\n",
    "\n",
    "y_train = TensOps(y_train_np.to(device), space_dimension=y_train.space_dim, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test_np.to(device), space_dimension=y_train.space_dim, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test_np.to(device), space_dimension=K_train.space_dim, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitectura del modelo\n",
    "input_shape = X_train[0].shape  # [1, 10, 8]\n",
    "hidden1_dim = 150\n",
    "hidden2_dim = 150\n",
    "output_shape = y_train.values[0].shape  # [1, 10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch 0, Train loss: 1.094e+09, Test loss: 1.246e+09, MSE(e): 1.071e+02, MSE(pi1): 2.190e+03, MSE(pi2): 4.239e+01, MSE(pi3): 5.815e+00\n",
      "Epoch 100, Train loss: 3.272e+07, Test loss: 3.292e+07, MSE(e): 3.267e+00, MSE(pi1): 3.105e+00, MSE(pi2): 1.519e+00, MSE(pi3): 2.146e-01\n",
      "Epoch 200, Train loss: 3.032e+07, Test loss: 3.054e+07, MSE(e): 3.028e+00, MSE(pi1): 1.602e+00, MSE(pi2): 1.422e+00, MSE(pi3): 1.761e-01\n",
      "Epoch 300, Train loss: 2.634e+07, Test loss: 2.630e+07, MSE(e): 2.631e+00, MSE(pi1): 1.436e+00, MSE(pi2): 1.262e+00, MSE(pi3): 1.716e-01\n",
      "Epoch 400, Train loss: 1.963e+07, Test loss: 1.908e+07, MSE(e): 1.959e+00, MSE(pi1): 1.860e+00, MSE(pi2): 9.805e-01, MSE(pi3): 1.799e-01\n",
      "Epoch 500, Train loss: 1.236e+07, Test loss: 1.079e+07, MSE(e): 1.232e+00, MSE(pi1): 2.076e+00, MSE(pi2): 6.596e-01, MSE(pi3): 1.928e-01\n",
      "Epoch 600, Train loss: 9.111e+06, Test loss: 7.124e+06, MSE(e): 9.071e-01, MSE(pi1): 2.011e+00, MSE(pi2): 5.129e-01, MSE(pi3): 1.950e-01\n",
      "Epoch 700, Train loss: 7.727e+06, Test loss: 5.979e+06, MSE(e): 7.690e-01, MSE(pi1): 1.836e+00, MSE(pi2): 4.573e-01, MSE(pi3): 1.871e-01\n",
      "Epoch 800, Train loss: 6.950e+06, Test loss: 5.475e+06, MSE(e): 6.916e-01, MSE(pi1): 1.623e+00, MSE(pi2): 4.282e-01, MSE(pi3): 1.769e-01\n",
      "Epoch 900, Train loss: 6.474e+06, Test loss: 5.220e+06, MSE(e): 6.442e-01, MSE(pi1): 1.457e+00, MSE(pi2): 4.094e-01, MSE(pi3): 1.681e-01\n",
      "Epoch 1000, Train loss: 6.123e+06, Test loss: 5.052e+06, MSE(e): 6.093e-01, MSE(pi1): 1.359e+00, MSE(pi2): 3.930e-01, MSE(pi3): 1.612e-01\n",
      "Epoch 1100, Train loss: 5.784e+06, Test loss: 4.880e+06, MSE(e): 5.756e-01, MSE(pi1): 1.308e+00, MSE(pi2): 3.736e-01, MSE(pi3): 1.553e-01\n",
      "Epoch 1200, Train loss: 5.370e+06, Test loss: 4.636e+06, MSE(e): 5.342e-01, MSE(pi1): 1.306e+00, MSE(pi2): 3.465e-01, MSE(pi3): 1.499e-01\n",
      "Epoch 1300, Train loss: 4.792e+06, Test loss: 4.248e+06, MSE(e): 4.764e-01, MSE(pi1): 1.365e+00, MSE(pi2): 3.062e-01, MSE(pi3): 1.450e-01\n",
      "Epoch 1400, Train loss: 3.993e+06, Test loss: 3.654e+06, MSE(e): 3.964e-01, MSE(pi1): 1.458e+00, MSE(pi2): 2.494e-01, MSE(pi3): 1.407e-01\n",
      "Epoch 1500, Train loss: 3.062e+06, Test loss: 2.899e+06, MSE(e): 3.033e-01, MSE(pi1): 1.491e+00, MSE(pi2): 1.844e-01, MSE(pi3): 1.356e-01\n",
      "Epoch 1600, Train loss: 2.241e+06, Test loss: 2.167e+06, MSE(e): 2.214e-01, MSE(pi1): 1.430e+00, MSE(pi2): 1.302e-01, MSE(pi3): 1.271e-01\n",
      "Epoch 1700, Train loss: 1.618e+06, Test loss: 1.573e+06, MSE(e): 1.593e-01, MSE(pi1): 1.331e+00, MSE(pi2): 9.095e-02, MSE(pi3): 1.174e-01\n",
      "Epoch 1800, Train loss: 1.140e+06, Test loss: 1.109e+06, MSE(e): 1.117e-01, MSE(pi1): 1.249e+00, MSE(pi2): 6.088e-02, MSE(pi3): 1.104e-01\n",
      "Epoch 1900, Train loss: 7.937e+05, Test loss: 7.684e+05, MSE(e): 7.717e-02, MSE(pi1): 1.154e+00, MSE(pi2): 3.974e-02, MSE(pi3): 1.045e-01\n",
      "Epoch 2000, Train loss: 5.619e+05, Test loss: 5.373e+05, MSE(e): 5.419e-02, MSE(pi1): 1.022e+00, MSE(pi2): 2.678e-02, MSE(pi3): 9.794e-02\n",
      "Epoch 2100, Train loss: 4.129e+05, Test loss: 3.868e+05, MSE(e): 3.950e-02, MSE(pi1): 8.696e-01, MSE(pi2): 1.934e-02, MSE(pi3): 9.191e-02\n",
      "Epoch 2200, Train loss: 3.172e+05, Test loss: 2.898e+05, MSE(e): 3.012e-02, MSE(pi1): 7.235e-01, MSE(pi2): 1.505e-02, MSE(pi3): 8.754e-02\n",
      "Epoch 2300, Train loss: 2.545e+05, Test loss: 2.269e+05, MSE(e): 2.400e-02, MSE(pi1): 6.017e-01, MSE(pi2): 1.244e-02, MSE(pi3): 8.476e-02\n",
      "Epoch 2400, Train loss: 2.123e+05, Test loss: 1.854e+05, MSE(e): 1.989e-02, MSE(pi1): 5.104e-01, MSE(pi2): 1.075e-02, MSE(pi3): 8.309e-02\n",
      "Epoch 2500, Train loss: 1.831e+05, Test loss: 1.577e+05, MSE(e): 1.704e-02, MSE(pi1): 4.466e-01, MSE(pi2): 9.598e-03, MSE(pi3): 8.211e-02\n",
      "Epoch 2600, Train loss: 1.622e+05, Test loss: 1.387e+05, MSE(e): 1.500e-02, MSE(pi1): 4.026e-01, MSE(pi2): 8.771e-03, MSE(pi3): 8.152e-02\n",
      "Epoch 2700, Train loss: 1.467e+05, Test loss: 1.253e+05, MSE(e): 1.348e-02, MSE(pi1): 3.713e-01, MSE(pi2): 8.145e-03, MSE(pi3): 8.116e-02\n",
      "Epoch 2800, Train loss: 1.347e+05, Test loss: 1.155e+05, MSE(e): 1.231e-02, MSE(pi1): 3.476e-01, MSE(pi2): 7.644e-03, MSE(pi3): 8.093e-02\n",
      "Epoch 2900, Train loss: 1.250e+05, Test loss: 1.079e+05, MSE(e): 1.136e-02, MSE(pi1): 3.285e-01, MSE(pi2): 7.220e-03, MSE(pi3): 8.078e-02\n",
      "Epoch 3000, Train loss: 1.169e+05, Test loss: 1.016e+05, MSE(e): 1.057e-02, MSE(pi1): 3.126e-01, MSE(pi2): 6.845e-03, MSE(pi3): 8.068e-02\n",
      "Epoch 3100, Train loss: 1.098e+05, Test loss: 9.620e+04, MSE(e): 9.875e-03, MSE(pi1): 2.990e-01, MSE(pi2): 6.504e-03, MSE(pi3): 8.060e-02\n",
      "Epoch 3200, Train loss: 1.035e+05, Test loss: 9.137e+04, MSE(e): 9.257e-03, MSE(pi1): 2.873e-01, MSE(pi2): 6.189e-03, MSE(pi3): 8.052e-02\n",
      "Epoch 3300, Train loss: 9.779e+04, Test loss: 8.694e+04, MSE(e): 8.696e-03, MSE(pi1): 2.772e-01, MSE(pi2): 5.894e-03, MSE(pi3): 8.046e-02\n",
      "Epoch 3400, Train loss: 9.255e+04, Test loss: 8.281e+04, MSE(e): 8.182e-03, MSE(pi1): 2.685e-01, MSE(pi2): 5.618e-03, MSE(pi3): 8.040e-02\n",
      "Epoch 3500, Train loss: 8.771e+04, Test loss: 7.892e+04, MSE(e): 7.706e-03, MSE(pi1): 2.609e-01, MSE(pi2): 5.358e-03, MSE(pi3): 8.035e-02\n",
      "Epoch 3600, Train loss: 8.320e+04, Test loss: 7.525e+04, MSE(e): 7.263e-03, MSE(pi1): 2.543e-01, MSE(pi2): 5.113e-03, MSE(pi3): 8.030e-02\n",
      "Epoch 3700, Train loss: 7.900e+04, Test loss: 7.176e+04, MSE(e): 6.849e-03, MSE(pi1): 2.484e-01, MSE(pi2): 4.881e-03, MSE(pi3): 8.024e-02\n",
      "Epoch 3800, Train loss: 7.506e+04, Test loss: 6.846e+04, MSE(e): 6.461e-03, MSE(pi1): 2.433e-01, MSE(pi2): 4.661e-03, MSE(pi3): 8.019e-02\n",
      "Epoch 3900, Train loss: 7.137e+04, Test loss: 6.534e+04, MSE(e): 6.097e-03, MSE(pi1): 2.387e-01, MSE(pi2): 4.453e-03, MSE(pi3): 8.013e-02\n",
      "Epoch 4000, Train loss: 6.791e+04, Test loss: 6.241e+04, MSE(e): 5.755e-03, MSE(pi1): 2.347e-01, MSE(pi2): 4.256e-03, MSE(pi3): 8.007e-02\n",
      "Epoch 4100, Train loss: 6.465e+04, Test loss: 5.966e+04, MSE(e): 5.434e-03, MSE(pi1): 2.312e-01, MSE(pi2): 4.069e-03, MSE(pi3): 8.000e-02\n",
      "Epoch 4200, Train loss: 6.160e+04, Test loss: 5.708e+04, MSE(e): 5.132e-03, MSE(pi1): 2.280e-01, MSE(pi2): 3.891e-03, MSE(pi3): 7.992e-02\n",
      "Epoch 4300, Train loss: 5.872e+04, Test loss: 5.467e+04, MSE(e): 4.848e-03, MSE(pi1): 2.252e-01, MSE(pi2): 3.720e-03, MSE(pi3): 7.983e-02\n",
      "Epoch 4400, Train loss: 5.600e+04, Test loss: 5.240e+04, MSE(e): 4.580e-03, MSE(pi1): 2.227e-01, MSE(pi2): 3.557e-03, MSE(pi3): 7.973e-02\n",
      "Epoch 4500, Train loss: 5.343e+04, Test loss: 5.026e+04, MSE(e): 4.327e-03, MSE(pi1): 2.205e-01, MSE(pi2): 3.400e-03, MSE(pi3): 7.961e-02\n",
      "Epoch 4600, Train loss: 5.100e+04, Test loss: 4.823e+04, MSE(e): 4.086e-03, MSE(pi1): 2.185e-01, MSE(pi2): 3.248e-03, MSE(pi3): 7.948e-02\n",
      "Epoch 4700, Train loss: 4.870e+04, Test loss: 4.631e+04, MSE(e): 3.859e-03, MSE(pi1): 2.167e-01, MSE(pi2): 3.102e-03, MSE(pi3): 7.933e-02\n",
      "Epoch 4800, Train loss: 4.652e+04, Test loss: 4.449e+04, MSE(e): 3.645e-03, MSE(pi1): 2.151e-01, MSE(pi2): 2.960e-03, MSE(pi3): 7.915e-02\n",
      "Epoch 4900, Train loss: 4.447e+04, Test loss: 4.279e+04, MSE(e): 3.444e-03, MSE(pi1): 2.136e-01, MSE(pi2): 2.823e-03, MSE(pi3): 7.895e-02\n",
      "Epoch 5000, Train loss: 4.254e+04, Test loss: 4.119e+04, MSE(e): 3.254e-03, MSE(pi1): 2.123e-01, MSE(pi2): 2.690e-03, MSE(pi3): 7.870e-02\n",
      "Epoch 5100, Train loss: 4.071e+04, Test loss: 3.969e+04, MSE(e): 3.076e-03, MSE(pi1): 2.111e-01, MSE(pi2): 2.561e-03, MSE(pi3): 7.839e-02\n",
      "Epoch 5200, Train loss: 3.898e+04, Test loss: 3.828e+04, MSE(e): 2.907e-03, MSE(pi1): 2.101e-01, MSE(pi2): 2.435e-03, MSE(pi3): 7.802e-02\n",
      "Epoch 5300, Train loss: 3.733e+04, Test loss: 3.696e+04, MSE(e): 2.748e-03, MSE(pi1): 2.093e-01, MSE(pi2): 2.312e-03, MSE(pi3): 7.755e-02\n",
      "Epoch 5400, Train loss: 3.590e+04, Test loss: 3.529e+04, MSE(e): 2.611e-03, MSE(pi1): 2.090e-01, MSE(pi2): 2.198e-03, MSE(pi3): 7.698e-02\n",
      "Epoch 5500, Train loss: 3.424e+04, Test loss: 3.455e+04, MSE(e): 2.453e-03, MSE(pi1): 2.084e-01, MSE(pi2): 2.075e-03, MSE(pi3): 7.625e-02\n",
      "Epoch 5600, Train loss: 3.281e+04, Test loss: 3.320e+04, MSE(e): 2.318e-03, MSE(pi1): 2.088e-01, MSE(pi2): 1.962e-03, MSE(pi3): 7.539e-02\n",
      "Epoch 5700, Train loss: 3.140e+04, Test loss: 3.239e+04, MSE(e): 2.186e-03, MSE(pi1): 2.094e-01, MSE(pi2): 1.851e-03, MSE(pi3): 7.441e-02\n",
      "Epoch 5800, Train loss: 3.008e+04, Test loss: 3.153e+04, MSE(e): 2.064e-03, MSE(pi1): 2.104e-01, MSE(pi2): 1.744e-03, MSE(pi3): 7.337e-02\n",
      "Epoch 5900, Train loss: 2.879e+04, Test loss: 3.046e+04, MSE(e): 1.944e-03, MSE(pi1): 2.114e-01, MSE(pi2): 1.640e-03, MSE(pi3): 7.233e-02\n",
      "Epoch 6000, Train loss: 2.757e+04, Test loss: 2.957e+04, MSE(e): 1.832e-03, MSE(pi1): 2.119e-01, MSE(pi2): 1.539e-03, MSE(pi3): 7.132e-02\n",
      "Epoch 6100, Train loss: 2.656e+04, Test loss: 2.857e+04, MSE(e): 1.739e-03, MSE(pi1): 2.132e-01, MSE(pi2): 1.447e-03, MSE(pi3): 7.031e-02\n",
      "Epoch 6200, Train loss: 2.524e+04, Test loss: 2.799e+04, MSE(e): 1.621e-03, MSE(pi1): 2.105e-01, MSE(pi2): 1.348e-03, MSE(pi3): 6.928e-02\n",
      "Epoch 6300, Train loss: 2.414e+04, Test loss: 2.710e+04, MSE(e): 1.523e-03, MSE(pi1): 2.095e-01, MSE(pi2): 1.258e-03, MSE(pi3): 6.814e-02\n",
      "Epoch 6400, Train loss: 2.305e+04, Test loss: 2.648e+04, MSE(e): 1.429e-03, MSE(pi1): 2.073e-01, MSE(pi2): 1.172e-03, MSE(pi3): 6.688e-02\n",
      "Epoch 6500, Train loss: 2.199e+04, Test loss: 2.575e+04, MSE(e): 1.340e-03, MSE(pi1): 2.053e-01, MSE(pi2): 1.090e-03, MSE(pi3): 6.536e-02\n",
      "Epoch 6600, Train loss: 2.096e+04, Test loss: 2.501e+04, MSE(e): 1.257e-03, MSE(pi1): 2.034e-01, MSE(pi2): 1.013e-03, MSE(pi3): 6.352e-02\n",
      "Epoch 6700, Train loss: 1.992e+04, Test loss: 2.431e+04, MSE(e): 1.178e-03, MSE(pi1): 2.017e-01, MSE(pi2): 9.415e-04, MSE(pi3): 6.125e-02\n",
      "Epoch 6800, Train loss: 1.892e+04, Test loss: 2.359e+04, MSE(e): 1.105e-03, MSE(pi1): 2.014e-01, MSE(pi2): 8.751e-04, MSE(pi3): 5.851e-02\n",
      "Epoch 6900, Train loss: 1.791e+04, Test loss: 2.286e+04, MSE(e): 1.036e-03, MSE(pi1): 2.019e-01, MSE(pi2): 8.139e-04, MSE(pi3): 5.522e-02\n",
      "Epoch 7000, Train loss: 1.693e+04, Test loss: 2.211e+04, MSE(e): 9.738e-04, MSE(pi1): 2.037e-01, MSE(pi2): 7.584e-04, MSE(pi3): 5.156e-02\n",
      "Epoch 7100, Train loss: 1.667e+04, Test loss: 2.250e+04, MSE(e): 9.624e-04, MSE(pi1): 2.260e-01, MSE(pi2): 7.229e-04, MSE(pi3): 4.782e-02\n",
      "Epoch 7200, Train loss: 1.505e+04, Test loss: 2.066e+04, MSE(e): 8.648e-04, MSE(pi1): 2.021e-01, MSE(pi2): 6.630e-04, MSE(pi3): 4.383e-02\n",
      "Epoch 7300, Train loss: 1.514e+04, Test loss: 2.088e+04, MSE(e): 8.962e-04, MSE(pi1): 2.203e-01, MSE(pi2): 6.476e-04, MSE(pi3): 3.976e-02\n",
      "Epoch 7400, Train loss: 1.342e+04, Test loss: 1.915e+04, MSE(e): 7.876e-04, MSE(pi1): 1.933e-01, MSE(pi2): 5.935e-04, MSE(pi3): 3.606e-02\n",
      "Epoch 7500, Train loss: 1.246e+04, Test loss: 1.832e+04, MSE(e): 7.349e-04, MSE(pi1): 1.900e-01, MSE(pi2): 5.537e-04, MSE(pi3): 3.208e-02\n",
      "Epoch 7600, Train loss: 1.159e+04, Test loss: 1.758e+04, MSE(e): 6.976e-04, MSE(pi1): 1.764e-01, MSE(pi2): 5.243e-04, MSE(pi3): 2.853e-02\n",
      "Epoch 7700, Train loss: 1.120e+04, Test loss: 1.729e+04, MSE(e): 6.746e-04, MSE(pi1): 1.880e-01, MSE(pi2): 4.996e-04, MSE(pi3): 2.572e-02\n",
      "Epoch 7800, Train loss: 1.044e+04, Test loss: 1.671e+04, MSE(e): 6.533e-04, MSE(pi1): 1.627e-01, MSE(pi2): 4.837e-04, MSE(pi3): 2.278e-02\n",
      "Epoch 7900, Train loss: 1.090e+04, Test loss: 1.805e+04, MSE(e): 6.607e-04, MSE(pi1): 2.188e-01, MSE(pi2): 4.705e-04, MSE(pi3): 2.101e-02\n",
      "Epoch 8000, Train loss: 1.099e+04, Test loss: 1.724e+04, MSE(e): 6.289e-04, MSE(pi1): 2.692e-01, MSE(pi2): 4.416e-04, MSE(pi3): 2.006e-02\n",
      "Epoch 8100, Train loss: 1.754e+04, Test loss: 2.129e+04, MSE(e): 1.003e-03, MSE(pi1): 5.460e-01, MSE(pi2): 6.130e-04, MSE(pi3): 2.044e-02\n",
      "Epoch 8200, Train loss: 9.018e+03, Test loss: 1.537e+04, MSE(e): 5.807e-04, MSE(pi1): 1.477e-01, MSE(pi2): 4.225e-04, MSE(pi3): 1.733e-02\n",
      "Epoch 8300, Train loss: 1.493e+04, Test loss: 2.045e+04, MSE(e): 7.263e-04, MSE(pi1): 5.925e-01, MSE(pi2): 4.510e-04, MSE(pi3): 1.738e-02\n",
      "Epoch 8400, Train loss: 9.438e+03, Test loss: 1.490e+04, MSE(e): 5.463e-04, MSE(pi1): 2.347e-01, MSE(pi2): 3.848e-04, MSE(pi3): 1.628e-02\n",
      "Epoch 8500, Train loss: 1.272e+04, Test loss: 2.083e+04, MSE(e): 7.073e-04, MSE(pi1): 3.254e-01, MSE(pi2): 4.846e-04, MSE(pi3): 2.397e-02\n",
      "Epoch 8600, Train loss: 7.371e+03, Test loss: 1.336e+04, MSE(e): 4.677e-04, MSE(pi1): 1.246e-01, MSE(pi2): 3.529e-04, MSE(pi3): 1.447e-02\n",
      "Epoch 8700, Train loss: 7.488e+03, Test loss: 1.356e+04, MSE(e): 4.701e-04, MSE(pi1): 1.383e-01, MSE(pi2): 3.488e-04, MSE(pi3): 1.404e-02\n",
      "Epoch 8800, Train loss: 1.552e+04, Test loss: 3.113e+04, MSE(e): 6.572e-04, MSE(pi1): 7.463e-01, MSE(pi2): 3.679e-04, MSE(pi3): 1.484e-02\n",
      "Epoch 8900, Train loss: 1.048e+04, Test loss: 1.545e+04, MSE(e): 7.253e-04, MSE(pi1): 1.745e-01, MSE(pi2): 4.904e-04, MSE(pi3): 1.478e-02\n",
      "Epoch 9000, Train loss: 6.946e+03, Test loss: 1.285e+04, MSE(e): 4.355e-04, MSE(pi1): 1.305e-01, MSE(pi2): 3.224e-04, MSE(pi3): 1.286e-02\n",
      "Epoch 9100, Train loss: 2.681e+04, Test loss: 2.839e+04, MSE(e): 1.062e-03, MSE(pi1): 1.040e+00, MSE(pi2): 5.852e-04, MSE(pi3): 5.786e-02\n",
      "Epoch 9200, Train loss: 1.004e+04, Test loss: 1.485e+04, MSE(e): 4.171e-04, MSE(pi1): 1.499e-01, MSE(pi2): 3.111e-04, MSE(pi3): 4.373e-02\n",
      "Epoch 9300, Train loss: 7.318e+03, Test loss: 1.294e+04, MSE(e): 3.907e-04, MSE(pi1): 1.367e-01, MSE(pi2): 2.965e-04, MSE(pi3): 2.043e-02\n",
      "Epoch 9400, Train loss: 6.643e+03, Test loss: 1.246e+04, MSE(e): 3.811e-04, MSE(pi1): 1.201e-01, MSE(pi2): 2.899e-04, MSE(pi3): 1.631e-02\n",
      "Epoch 9500, Train loss: 6.284e+03, Test loss: 1.211e+04, MSE(e): 3.725e-04, MSE(pi1): 1.106e-01, MSE(pi2): 2.838e-04, MSE(pi3): 1.452e-02\n",
      "Epoch 9600, Train loss: 6.034e+03, Test loss: 1.182e+04, MSE(e): 3.644e-04, MSE(pi1): 1.057e-01, MSE(pi2): 2.778e-04, MSE(pi3): 1.333e-02\n",
      "Epoch 9700, Train loss: 7.436e+03, Test loss: 1.921e+04, MSE(e): 4.660e-04, MSE(pi1): 1.383e-01, MSE(pi2): 3.359e-04, MSE(pi3): 1.392e-02\n",
      "Epoch 9800, Train loss: 5.789e+03, Test loss: 1.175e+04, MSE(e): 3.514e-04, MSE(pi1): 1.104e-01, MSE(pi2): 2.672e-04, MSE(pi3): 1.171e-02\n",
      "Epoch 9900, Train loss: 5.564e+03, Test loss: 1.118e+04, MSE(e): 3.431e-04, MSE(pi1): 1.001e-01, MSE(pi2): 2.617e-04, MSE(pi3): 1.131e-02\n",
      "\n",
      "Proceso finalizado después de 10000 épocas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se carga el modelo y el optimizador\n",
    "model = NonConstantDiffusivityNeuralNetwork(input_shape, hidden1_dim, hidden2_dim, output_shape).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 10000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(model, optimizer, n_checkpoints,\n",
    "           X_train, y_train, X_test, y_test, f_train, f_test,\n",
    "           D=D, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=device,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Starting from a checkpoint. Epoch 9000.\n",
      "Epoch 9000, Train loss: 6.973e+03, Test loss: 1.293e+04, MSE(e): 4.439e-04, MSE(pi1): 1.239e-01, MSE(pi2): 3.261e-04, MSE(pi3): 1.295e-02\n",
      "Epoch 9100, Train loss: 2.447e+04, Test loss: 3.159e+04, MSE(e): 1.004e-03, MSE(pi1): 8.554e-01, MSE(pi2): 5.731e-04, MSE(pi3): 5.875e-02\n",
      "Epoch 9200, Train loss: 9.867e+03, Test loss: 1.476e+04, MSE(e): 4.115e-04, MSE(pi1): 1.479e-01, MSE(pi2): 3.102e-04, MSE(pi3): 4.273e-02\n",
      "Epoch 9300, Train loss: 7.296e+03, Test loss: 1.293e+04, MSE(e): 3.905e-04, MSE(pi1): 1.364e-01, MSE(pi2): 2.963e-04, MSE(pi3): 2.026e-02\n",
      "Epoch 9400, Train loss: 6.634e+03, Test loss: 1.245e+04, MSE(e): 3.809e-04, MSE(pi1): 1.199e-01, MSE(pi2): 2.898e-04, MSE(pi3): 1.626e-02\n",
      "Epoch 9500, Train loss: 6.278e+03, Test loss: 1.210e+04, MSE(e): 3.724e-04, MSE(pi1): 1.105e-01, MSE(pi2): 2.836e-04, MSE(pi3): 1.449e-02\n",
      "Epoch 9600, Train loss: 6.030e+03, Test loss: 1.182e+04, MSE(e): 3.643e-04, MSE(pi1): 1.056e-01, MSE(pi2): 2.777e-04, MSE(pi3): 1.331e-02\n",
      "Epoch 9700, Train loss: 1.423e+04, Test loss: 1.887e+04, MSE(e): 1.116e-03, MSE(pi1): 1.602e-01, MSE(pi2): 7.043e-04, MSE(pi3): 1.469e-02\n",
      "Epoch 9800, Train loss: 5.968e+03, Test loss: 1.230e+04, MSE(e): 3.546e-04, MSE(pi1): 1.253e-01, MSE(pi2): 2.682e-04, MSE(pi3): 1.168e-02\n",
      "Epoch 9900, Train loss: 5.559e+03, Test loss: 1.118e+04, MSE(e): 3.441e-04, MSE(pi1): 9.877e-02, MSE(pi2): 2.620e-04, MSE(pi3): 1.130e-02\n",
      "Epoch 10000, Train loss: 5.561e+03, Test loss: 1.132e+04, MSE(e): 3.386e-04, MSE(pi1): 1.093e-01, MSE(pi2): 2.570e-04, MSE(pi3): 1.082e-02\n",
      "Epoch 10100, Train loss: 9.069e+03, Test loss: 1.547e+04, MSE(e): 6.881e-04, MSE(pi1): 1.144e-01, MSE(pi2): 4.587e-04, MSE(pi3): 1.044e-02\n",
      "Epoch 10200, Train loss: 6.398e+03, Test loss: 1.074e+04, MSE(e): 3.572e-04, MSE(pi1): 1.653e-01, MSE(pi2): 2.539e-04, MSE(pi3): 1.173e-02\n",
      "Epoch 10300, Train loss: 5.450e+03, Test loss: 1.189e+04, MSE(e): 3.293e-04, MSE(pi1): 1.051e-01, MSE(pi2): 2.459e-04, MSE(pi3): 1.106e-02\n",
      "Epoch 10400, Train loss: 5.904e+03, Test loss: 1.192e+04, MSE(e): 3.492e-04, MSE(pi1): 1.385e-01, MSE(pi2): 2.558e-04, MSE(pi3): 1.027e-02\n",
      "Epoch 10500, Train loss: 5.677e+03, Test loss: 1.112e+04, MSE(e): 3.479e-04, MSE(pi1): 1.254e-01, MSE(pi2): 2.510e-04, MSE(pi3): 9.441e-03\n",
      "Epoch 10600, Train loss: 8.868e+03, Test loss: 1.359e+04, MSE(e): 6.901e-04, MSE(pi1): 1.102e-01, MSE(pi2): 4.634e-04, MSE(pi3): 8.642e-03\n",
      "Epoch 10700, Train loss: 4.776e+03, Test loss: 1.036e+04, MSE(e): 2.983e-04, MSE(pi1): 9.483e-02, MSE(pi2): 2.254e-04, MSE(pi3): 8.445e-03\n",
      "Epoch 10800, Train loss: 7.926e+03, Test loss: 2.032e+04, MSE(e): 3.803e-04, MSE(pi1): 3.249e-01, MSE(pi2): 2.501e-04, MSE(pi3): 8.745e-03\n",
      "Epoch 10900, Train loss: 1.148e+04, Test loss: 2.001e+04, MSE(e): 9.431e-04, MSE(pi1): 1.234e-01, MSE(pi2): 6.348e-04, MSE(pi3): 8.143e-03\n",
      "Epoch 11000, Train loss: 4.338e+03, Test loss: 9.749e+03, MSE(e): 2.812e-04, MSE(pi1): 8.033e-02, MSE(pi2): 2.127e-04, MSE(pi3): 7.222e-03\n",
      "Epoch 11100, Train loss: 4.973e+03, Test loss: 1.052e+04, MSE(e): 3.142e-04, MSE(pi1): 1.097e-01, MSE(pi2): 2.260e-04, MSE(pi3): 7.340e-03\n",
      "Epoch 11200, Train loss: 5.625e+03, Test loss: 1.077e+04, MSE(e): 3.201e-04, MSE(pi1): 1.683e-01, MSE(pi2): 2.186e-04, MSE(pi3): 7.408e-03\n",
      "Epoch 11300, Train loss: 4.278e+03, Test loss: 9.558e+03, MSE(e): 2.753e-04, MSE(pi1): 9.189e-02, MSE(pi2): 2.031e-04, MSE(pi3): 6.053e-03\n",
      "Epoch 11400, Train loss: 4.891e+03, Test loss: 9.621e+03, MSE(e): 2.951e-04, MSE(pi1): 1.285e-01, MSE(pi2): 2.087e-04, MSE(pi3): 6.550e-03\n",
      "Epoch 11500, Train loss: 3.985e+03, Test loss: 9.040e+03, MSE(e): 2.686e-04, MSE(pi1): 7.252e-02, MSE(pi2): 2.014e-04, MSE(pi3): 5.737e-03\n",
      "Epoch 11600, Train loss: 4.973e+03, Test loss: 9.689e+03, MSE(e): 3.438e-04, MSE(pi1): 9.155e-02, MSE(pi2): 2.310e-04, MSE(pi3): 6.188e-03\n",
      "Epoch 11700, Train loss: 4.423e+03, Test loss: 9.408e+03, MSE(e): 2.755e-04, MSE(pi1): 1.137e-01, MSE(pi2): 1.948e-04, MSE(pi3): 5.304e-03\n",
      "Epoch 11800, Train loss: 4.310e+03, Test loss: 8.908e+03, MSE(e): 2.852e-04, MSE(pi1): 9.736e-02, MSE(pi2): 1.963e-04, MSE(pi3): 4.837e-03\n",
      "Epoch 11900, Train loss: 3.454e+03, Test loss: 8.552e+03, MSE(e): 2.507e-04, MSE(pi1): 5.264e-02, MSE(pi2): 1.892e-04, MSE(pi3): 4.211e-03\n",
      "Epoch 12000, Train loss: 5.383e+03, Test loss: 1.056e+04, MSE(e): 3.479e-04, MSE(pi1): 1.420e-01, MSE(pi2): 2.166e-04, MSE(pi3): 4.842e-03\n",
      "Epoch 12100, Train loss: 1.024e+04, Test loss: 2.253e+04, MSE(e): 4.153e-04, MSE(pi1): 5.570e-01, MSE(pi2): 2.202e-04, MSE(pi3): 5.146e-03\n",
      "Epoch 12200, Train loss: 3.188e+03, Test loss: 7.871e+03, MSE(e): 2.364e-04, MSE(pi1): 4.532e-02, MSE(pi2): 1.771e-04, MSE(pi3): 3.701e-03\n",
      "Epoch 12300, Train loss: 4.302e+03, Test loss: 8.895e+03, MSE(e): 2.938e-04, MSE(pi1): 1.046e-01, MSE(pi2): 2.066e-04, MSE(pi3): 3.174e-03\n",
      "Epoch 12400, Train loss: 6.262e+03, Test loss: 9.849e+03, MSE(e): 3.559e-04, MSE(pi1): 2.262e-01, MSE(pi2): 2.178e-04, MSE(pi3): 4.414e-03\n",
      "Epoch 12500, Train loss: 7.980e+03, Test loss: 1.150e+04, MSE(e): 3.902e-04, MSE(pi1): 3.526e-01, MSE(pi2): 2.177e-04, MSE(pi3): 5.519e-03\n",
      "Epoch 12600, Train loss: 4.285e+03, Test loss: 9.310e+03, MSE(e): 2.595e-04, MSE(pi1): 1.286e-01, MSE(pi2): 1.800e-04, MSE(pi3): 4.035e-03\n",
      "Epoch 12700, Train loss: 3.209e+03, Test loss: 7.856e+03, MSE(e): 2.264e-04, MSE(pi1): 5.960e-02, MSE(pi2): 1.695e-04, MSE(pi3): 3.491e-03\n",
      "Epoch 12800, Train loss: 3.080e+03, Test loss: 7.341e+03, MSE(e): 2.282e-04, MSE(pi1): 5.477e-02, MSE(pi2): 1.633e-04, MSE(pi3): 2.502e-03\n",
      "Epoch 12900, Train loss: 5.530e+03, Test loss: 9.390e+03, MSE(e): 4.083e-04, MSE(pi1): 1.078e-01, MSE(pi2): 2.472e-04, MSE(pi3): 3.700e-03\n",
      "Epoch 13000, Train loss: 3.544e+03, Test loss: 8.107e+03, MSE(e): 2.352e-04, MSE(pi1): 7.785e-02, MSE(pi2): 1.640e-04, MSE(pi3): 4.128e-03\n",
      "Epoch 13100, Train loss: 6.283e+03, Test loss: 8.851e+03, MSE(e): 3.151e-04, MSE(pi1): 2.488e-01, MSE(pi2): 1.704e-04, MSE(pi3): 6.436e-03\n",
      "Epoch 13200, Train loss: 5.302e+03, Test loss: 1.080e+04, MSE(e): 2.706e-04, MSE(pi1): 2.368e-01, MSE(pi2): 1.669e-04, MSE(pi3): 2.275e-03\n",
      "Epoch 13300, Train loss: 2.701e+03, Test loss: 7.107e+03, MSE(e): 2.037e-04, MSE(pi1): 4.146e-02, MSE(pi2): 1.539e-04, MSE(pi3): 2.491e-03\n",
      "Epoch 13400, Train loss: 5.356e+03, Test loss: 1.085e+04, MSE(e): 3.142e-04, MSE(pi1): 1.336e-01, MSE(pi2): 1.868e-04, MSE(pi3): 8.769e-03\n",
      "Epoch 13500, Train loss: 1.071e+04, Test loss: 1.425e+04, MSE(e): 2.645e-04, MSE(pi1): 2.230e-01, MSE(pi2): 1.769e-04, MSE(pi3): 5.835e-02\n",
      "Epoch 13600, Train loss: 6.530e+03, Test loss: 1.040e+04, MSE(e): 1.883e-04, MSE(pi1): 1.193e-01, MSE(pi2): 1.457e-04, MSE(pi3): 3.454e-02\n",
      "Epoch 13700, Train loss: 4.598e+03, Test loss: 8.411e+03, MSE(e): 1.854e-04, MSE(pi1): 9.651e-02, MSE(pi2): 1.429e-04, MSE(pi3): 1.778e-02\n",
      "Epoch 13800, Train loss: 3.314e+03, Test loss: 7.191e+03, MSE(e): 1.818e-04, MSE(pi1): 6.250e-02, MSE(pi2): 1.405e-04, MSE(pi3): 8.714e-03\n",
      "Epoch 13900, Train loss: 2.690e+03, Test loss: 6.611e+03, MSE(e): 1.777e-04, MSE(pi1): 3.842e-02, MSE(pi2): 1.381e-04, MSE(pi3): 5.289e-03\n",
      "Epoch 14000, Train loss: 2.591e+03, Test loss: 6.505e+03, MSE(e): 1.905e-04, MSE(pi1): 2.914e-02, MSE(pi2): 1.448e-04, MSE(pi3): 3.948e-03\n",
      "Epoch 14100, Train loss: 2.298e+03, Test loss: 6.198e+03, MSE(e): 1.722e-04, MSE(pi1): 2.444e-02, MSE(pi2): 1.345e-04, MSE(pi3): 3.313e-03\n",
      "Epoch 14200, Train loss: 2.320e+03, Test loss: 6.438e+03, MSE(e): 1.714e-04, MSE(pi1): 2.702e-02, MSE(pi2): 1.332e-04, MSE(pi3): 3.359e-03\n",
      "Epoch 14300, Train loss: 2.360e+03, Test loss: 6.320e+03, MSE(e): 1.863e-04, MSE(pi1): 2.198e-02, MSE(pi2): 1.419e-04, MSE(pi3): 2.778e-03\n",
      "Epoch 14400, Train loss: 3.431e+03, Test loss: 6.575e+03, MSE(e): 2.822e-04, MSE(pi1): 3.554e-02, MSE(pi2): 1.946e-04, MSE(pi3): 2.537e-03\n",
      "Epoch 14500, Train loss: 4.184e+03, Test loss: 8.888e+03, MSE(e): 3.568e-04, MSE(pi1): 3.201e-02, MSE(pi2): 2.341e-04, MSE(pi3): 2.957e-03\n",
      "Epoch 14600, Train loss: 4.426e+03, Test loss: 7.924e+03, MSE(e): 3.570e-04, MSE(pi1): 5.910e-02, MSE(pi2): 2.295e-04, MSE(pi3): 2.641e-03\n",
      "Epoch 14700, Train loss: 2.800e+03, Test loss: 7.995e+03, MSE(e): 2.121e-04, MSE(pi1): 3.978e-02, MSE(pi2): 1.508e-04, MSE(pi3): 2.811e-03\n",
      "Epoch 14800, Train loss: 2.052e+03, Test loss: 5.740e+03, MSE(e): 1.605e-04, MSE(pi1): 2.179e-02, MSE(pi2): 1.253e-04, MSE(pi3): 2.294e-03\n",
      "Epoch 14900, Train loss: 2.493e+03, Test loss: 6.085e+03, MSE(e): 1.742e-04, MSE(pi1): 4.042e-02, MSE(pi2): 1.323e-04, MSE(pi3): 3.471e-03\n",
      "Epoch 15000, Train loss: 2.050e+03, Test loss: 5.697e+03, MSE(e): 1.579e-04, MSE(pi1): 2.679e-02, MSE(pi2): 1.225e-04, MSE(pi3): 2.027e-03\n",
      "Epoch 15100, Train loss: 5.753e+03, Test loss: 1.295e+04, MSE(e): 2.588e-04, MSE(pi1): 2.971e-01, MSE(pi2): 1.417e-04, MSE(pi3): 1.933e-03\n",
      "Epoch 15200, Train loss: 1.944e+03, Test loss: 5.421e+03, MSE(e): 1.529e-04, MSE(pi1): 2.096e-02, MSE(pi2): 1.198e-04, MSE(pi3): 2.049e-03\n",
      "Epoch 15300, Train loss: 2.404e+03, Test loss: 5.633e+03, MSE(e): 1.671e-04, MSE(pi1): 4.817e-02, MSE(pi2): 1.218e-04, MSE(pi3): 2.512e-03\n",
      "Epoch 15400, Train loss: 3.618e+03, Test loss: 7.261e+03, MSE(e): 3.080e-04, MSE(pi1): 3.059e-02, MSE(pi2): 2.103e-04, MSE(pi3): 2.312e-03\n",
      "Epoch 15500, Train loss: 2.241e+03, Test loss: 5.889e+03, MSE(e): 1.823e-04, MSE(pi1): 2.226e-02, MSE(pi2): 1.377e-04, MSE(pi3): 1.949e-03\n",
      "Epoch 15600, Train loss: 2.607e+03, Test loss: 6.539e+03, MSE(e): 1.896e-04, MSE(pi1): 3.778e-02, MSE(pi2): 1.356e-04, MSE(pi3): 3.327e-03\n",
      "Epoch 15700, Train loss: 1.873e+03, Test loss: 5.141e+03, MSE(e): 1.470e-04, MSE(pi1): 1.883e-02, MSE(pi2): 1.155e-04, MSE(pi3): 2.145e-03\n",
      "Epoch 15800, Train loss: 6.633e+03, Test loss: 7.736e+03, MSE(e): 3.328e-04, MSE(pi1): 2.917e-01, MSE(pi2): 1.646e-04, MSE(pi3): 3.884e-03\n",
      "Epoch 15900, Train loss: 2.115e+03, Test loss: 5.560e+03, MSE(e): 1.512e-04, MSE(pi1): 3.823e-02, MSE(pi2): 1.151e-04, MSE(pi3): 2.216e-03\n",
      "Epoch 16000, Train loss: 5.596e+03, Test loss: 6.660e+03, MSE(e): 2.708e-04, MSE(pi1): 2.460e-01, MSE(pi2): 1.597e-04, MSE(pi3): 4.275e-03\n",
      "Epoch 16100, Train loss: 1.912e+03, Test loss: 5.149e+03, MSE(e): 1.452e-04, MSE(pi1): 2.299e-02, MSE(pi2): 1.134e-04, MSE(pi3): 2.299e-03\n",
      "Epoch 16200, Train loss: 4.491e+03, Test loss: 8.118e+03, MSE(e): 2.761e-04, MSE(pi1): 1.259e-01, MSE(pi2): 1.643e-04, MSE(pi3): 4.713e-03\n",
      "Epoch 16300, Train loss: 2.157e+03, Test loss: 5.859e+03, MSE(e): 1.454e-04, MSE(pi1): 5.077e-02, MSE(pi2): 1.105e-04, MSE(pi3): 1.955e-03\n",
      "Epoch 16400, Train loss: 5.541e+03, Test loss: 7.466e+03, MSE(e): 2.576e-04, MSE(pi1): 2.748e-01, MSE(pi2): 1.316e-04, MSE(pi3): 2.176e-03\n",
      "Epoch 16500, Train loss: 1.880e+03, Test loss: 4.992e+03, MSE(e): 1.394e-04, MSE(pi1): 3.177e-02, MSE(pi2): 1.070e-04, MSE(pi3): 1.683e-03\n",
      "Epoch 16600, Train loss: 2.228e+03, Test loss: 5.665e+03, MSE(e): 1.506e-04, MSE(pi1): 4.171e-02, MSE(pi2): 1.127e-04, MSE(pi3): 3.047e-03\n",
      "Epoch 16700, Train loss: 5.390e+03, Test loss: 7.904e+03, MSE(e): 2.353e-04, MSE(pi1): 2.677e-01, MSE(pi2): 1.267e-04, MSE(pi3): 3.597e-03\n",
      "Epoch 16800, Train loss: 6.359e+03, Test loss: 8.204e+03, MSE(e): 5.361e-04, MSE(pi1): 8.086e-02, MSE(pi2): 3.560e-04, MSE(pi3): 1.896e-03\n",
      "Epoch 16900, Train loss: 2.131e+03, Test loss: 5.257e+03, MSE(e): 1.515e-04, MSE(pi1): 4.162e-02, MSE(pi2): 1.106e-04, MSE(pi3): 1.997e-03\n",
      "Epoch 17000, Train loss: 2.108e+03, Test loss: 5.225e+03, MSE(e): 1.516e-04, MSE(pi1): 3.214e-02, MSE(pi2): 1.159e-04, MSE(pi3): 2.703e-03\n",
      "Epoch 17100, Train loss: 8.758e+03, Test loss: 1.801e+04, MSE(e): 3.130e-04, MSE(pi1): 5.488e-01, MSE(pi2): 1.438e-04, MSE(pi3): 1.399e-03\n",
      "Epoch 17200, Train loss: 3.915e+03, Test loss: 7.631e+03, MSE(e): 1.889e-04, MSE(pi1): 1.764e-01, MSE(pi2): 1.142e-04, MSE(pi3): 2.623e-03\n",
      "Epoch 17300, Train loss: 5.635e+03, Test loss: 8.753e+03, MSE(e): 2.588e-04, MSE(pi1): 2.492e-01, MSE(pi2): 1.269e-04, MSE(pi3): 5.539e-03\n",
      "Epoch 17400, Train loss: 3.654e+03, Test loss: 6.610e+03, MSE(e): 2.320e-04, MSE(pi1): 1.010e-01, MSE(pi2): 1.608e-04, MSE(pi3): 3.246e-03\n",
      "Epoch 17500, Train loss: 2.073e+03, Test loss: 4.788e+03, MSE(e): 1.391e-04, MSE(pi1): 4.653e-02, MSE(pi2): 1.054e-04, MSE(pi3): 2.175e-03\n",
      "Epoch 17600, Train loss: 2.056e+03, Test loss: 5.233e+03, MSE(e): 1.550e-04, MSE(pi1): 3.568e-02, MSE(pi2): 1.162e-04, MSE(pi3): 1.493e-03\n",
      "Epoch 17700, Train loss: 1.699e+03, Test loss: 4.422e+03, MSE(e): 1.320e-04, MSE(pi1): 2.032e-02, MSE(pi2): 1.042e-04, MSE(pi3): 1.754e-03\n",
      "Epoch 17800, Train loss: 1.777e+03, Test loss: 4.958e+03, MSE(e): 1.241e-04, MSE(pi1): 3.090e-02, MSE(pi2): 9.700e-05, MSE(pi3): 2.262e-03\n",
      "Epoch 17900, Train loss: 1.699e+03, Test loss: 4.527e+03, MSE(e): 1.262e-04, MSE(pi1): 2.518e-02, MSE(pi2): 9.872e-05, MSE(pi3): 1.848e-03\n",
      "Epoch 18000, Train loss: 2.336e+03, Test loss: 5.065e+03, MSE(e): 1.590e-04, MSE(pi1): 5.279e-02, MSE(pi2): 1.139e-04, MSE(pi3): 2.179e-03\n",
      "Epoch 18100, Train loss: 2.904e+03, Test loss: 5.928e+03, MSE(e): 2.246e-04, MSE(pi1): 4.518e-02, MSE(pi2): 1.582e-04, MSE(pi3): 2.061e-03\n",
      "Epoch 18200, Train loss: 2.026e+03, Test loss: 4.676e+03, MSE(e): 1.545e-04, MSE(pi1): 2.844e-02, MSE(pi2): 1.159e-04, MSE(pi3): 1.963e-03\n",
      "Epoch 18300, Train loss: 1.540e+03, Test loss: 4.270e+03, MSE(e): 1.161e-04, MSE(pi1): 2.197e-02, MSE(pi2): 9.247e-05, MSE(pi3): 1.602e-03\n",
      "Epoch 18400, Train loss: 3.334e+03, Test loss: 7.257e+03, MSE(e): 2.575e-04, MSE(pi1): 6.010e-02, MSE(pi2): 1.759e-04, MSE(pi3): 1.585e-03\n",
      "Epoch 18500, Train loss: 2.780e+03, Test loss: 5.833e+03, MSE(e): 2.206e-04, MSE(pi1): 4.153e-02, MSE(pi2): 1.533e-04, MSE(pi3): 1.588e-03\n",
      "Epoch 18600, Train loss: 1.855e+03, Test loss: 4.746e+03, MSE(e): 1.318e-04, MSE(pi1): 2.666e-02, MSE(pi2): 1.015e-04, MSE(pi3): 2.702e-03\n",
      "Epoch 18700, Train loss: 3.292e+03, Test loss: 5.860e+03, MSE(e): 2.270e-04, MSE(pi1): 7.620e-02, MSE(pi2): 1.488e-04, MSE(pi3): 2.597e-03\n",
      "Epoch 18800, Train loss: 1.530e+03, Test loss: 4.248e+03, MSE(e): 1.191e-04, MSE(pi1): 1.897e-02, MSE(pi2): 9.422e-05, MSE(pi3): 1.493e-03\n",
      "Epoch 18900, Train loss: 1.056e+04, Test loss: 1.321e+04, MSE(e): 8.425e-04, MSE(pi1): 1.739e-01, MSE(pi2): 5.230e-04, MSE(pi3): 3.974e-03\n",
      "Epoch 19000, Train loss: 2.812e+03, Test loss: 4.994e+03, MSE(e): 1.593e-04, MSE(pi1): 9.750e-02, MSE(pi2): 1.033e-04, MSE(pi3): 2.446e-03\n",
      "Epoch 19100, Train loss: 3.578e+03, Test loss: 6.690e+03, MSE(e): 2.947e-04, MSE(pi1): 4.659e-02, MSE(pi2): 2.051e-04, MSE(pi3): 1.653e-03\n",
      "Epoch 19200, Train loss: 3.513e+03, Test loss: 5.968e+03, MSE(e): 1.903e-04, MSE(pi1): 1.076e-01, MSE(pi2): 1.215e-04, MSE(pi3): 5.341e-03\n",
      "Epoch 19300, Train loss: 2.986e+03, Test loss: 5.535e+03, MSE(e): 1.849e-04, MSE(pi1): 9.254e-02, MSE(pi2): 1.043e-04, MSE(pi3): 2.117e-03\n",
      "Epoch 19400, Train loss: 2.619e+03, Test loss: 4.951e+03, MSE(e): 1.419e-04, MSE(pi1): 1.041e-01, MSE(pi2): 1.000e-04, MSE(pi3): 1.592e-03\n",
      "Epoch 19500, Train loss: 2.990e+03, Test loss: 5.429e+03, MSE(e): 2.017e-04, MSE(pi1): 7.137e-02, MSE(pi2): 1.284e-04, MSE(pi3): 2.586e-03\n",
      "Epoch 19600, Train loss: 3.024e+03, Test loss: 5.531e+03, MSE(e): 1.742e-04, MSE(pi1): 1.060e-01, MSE(pi2): 1.176e-04, MSE(pi3): 2.224e-03\n",
      "Epoch 19700, Train loss: 1.716e+03, Test loss: 4.363e+03, MSE(e): 1.179e-04, MSE(pi1): 4.077e-02, MSE(pi2): 8.927e-05, MSE(pi3): 1.298e-03\n",
      "Epoch 19800, Train loss: 1.629e+03, Test loss: 4.137e+03, MSE(e): 1.100e-04, MSE(pi1): 3.811e-02, MSE(pi2): 8.486e-05, MSE(pi3): 1.477e-03\n",
      "Epoch 19900, Train loss: 1.561e+03, Test loss: 3.810e+03, MSE(e): 1.076e-04, MSE(pi1): 3.452e-02, MSE(pi2): 8.314e-05, MSE(pi3): 1.393e-03\n",
      "Epoch 20000, Train loss: 3.426e+03, Test loss: 7.783e+03, MSE(e): 2.418e-04, MSE(pi1): 8.438e-02, MSE(pi2): 1.537e-04, MSE(pi3): 1.644e-03\n",
      "Epoch 20100, Train loss: 1.647e+03, Test loss: 4.348e+03, MSE(e): 1.075e-04, MSE(pi1): 4.180e-02, MSE(pi2): 8.293e-05, MSE(pi3): 1.540e-03\n",
      "Epoch 20200, Train loss: 1.728e+03, Test loss: 4.040e+03, MSE(e): 1.307e-04, MSE(pi1): 2.629e-02, MSE(pi2): 9.971e-05, MSE(pi3): 1.587e-03\n",
      "Epoch 20300, Train loss: 2.918e+03, Test loss: 6.060e+03, MSE(e): 1.854e-04, MSE(pi1): 8.495e-02, MSE(pi2): 1.316e-04, MSE(pi3): 2.140e-03\n",
      "Epoch 20400, Train loss: 3.202e+03, Test loss: 5.623e+03, MSE(e): 2.401e-04, MSE(pi1): 5.891e-02, MSE(pi2): 1.675e-04, MSE(pi3): 2.113e-03\n",
      "Epoch 20500, Train loss: 1.666e+03, Test loss: 4.183e+03, MSE(e): 1.072e-04, MSE(pi1): 4.280e-02, MSE(pi2): 8.193e-05, MSE(pi3): 1.665e-03\n",
      "Epoch 20600, Train loss: 5.153e+03, Test loss: 6.651e+03, MSE(e): 2.080e-04, MSE(pi1): 2.783e-01, MSE(pi2): 9.959e-05, MSE(pi3): 2.903e-03\n",
      "Epoch 20700, Train loss: 2.739e+03, Test loss: 6.058e+03, MSE(e): 1.928e-04, MSE(pi1): 4.037e-02, MSE(pi2): 1.443e-04, MSE(pi3): 4.071e-03\n",
      "Epoch 20800, Train loss: 1.959e+03, Test loss: 4.561e+03, MSE(e): 1.143e-04, MSE(pi1): 6.808e-02, MSE(pi2): 8.171e-05, MSE(pi3): 1.349e-03\n",
      "Epoch 20900, Train loss: 2.759e+03, Test loss: 5.362e+03, MSE(e): 1.762e-04, MSE(pi1): 7.768e-02, MSE(pi2): 1.267e-04, MSE(pi3): 2.203e-03\n",
      "Epoch 21000, Train loss: 1.916e+03, Test loss: 4.580e+03, MSE(e): 1.300e-04, MSE(pi1): 4.319e-02, MSE(pi2): 9.807e-05, MSE(pi3): 1.840e-03\n",
      "Epoch 21100, Train loss: 3.365e+03, Test loss: 5.174e+03, MSE(e): 2.170e-04, MSE(pi1): 9.624e-02, MSE(pi2): 1.458e-04, MSE(pi3): 2.319e-03\n",
      "Epoch 21200, Train loss: 1.845e+03, Test loss: 4.057e+03, MSE(e): 1.241e-04, MSE(pi1): 4.137e-02, MSE(pi2): 8.505e-05, MSE(pi3): 1.904e-03\n",
      "Epoch 21300, Train loss: 1.417e+03, Test loss: 3.686e+03, MSE(e): 9.870e-05, MSE(pi1): 2.994e-02, MSE(pi2): 7.555e-05, MSE(pi3): 1.308e-03\n",
      "Epoch 21400, Train loss: 3.907e+03, Test loss: 5.715e+03, MSE(e): 3.042e-04, MSE(pi1): 5.262e-02, MSE(pi2): 1.639e-04, MSE(pi3): 3.383e-03\n",
      "Epoch 21500, Train loss: 1.510e+03, Test loss: 3.691e+03, MSE(e): 1.100e-04, MSE(pi1): 2.572e-02, MSE(pi2): 8.436e-05, MSE(pi3): 1.529e-03\n",
      "Epoch 21600, Train loss: 5.605e+03, Test loss: 7.251e+03, MSE(e): 4.726e-04, MSE(pi1): 7.156e-02, MSE(pi2): 3.070e-04, MSE(pi3): 1.629e-03\n",
      "Epoch 21700, Train loss: 1.492e+03, Test loss: 3.555e+03, MSE(e): 1.001e-04, MSE(pi1): 3.023e-02, MSE(pi2): 7.685e-05, MSE(pi3): 1.884e-03\n",
      "Epoch 21800, Train loss: 1.797e+03, Test loss: 4.136e+03, MSE(e): 1.246e-04, MSE(pi1): 3.518e-02, MSE(pi2): 8.574e-05, MSE(pi3): 1.993e-03\n",
      "Epoch 21900, Train loss: 3.700e+03, Test loss: 6.346e+03, MSE(e): 2.976e-04, MSE(pi1): 4.788e-02, MSE(pi2): 1.899e-04, MSE(pi3): 2.451e-03\n",
      "Epoch 22000, Train loss: 1.792e+03, Test loss: 3.916e+03, MSE(e): 1.144e-04, MSE(pi1): 3.811e-02, MSE(pi2): 7.985e-05, MSE(pi3): 2.668e-03\n",
      "Epoch 22100, Train loss: 7.110e+03, Test loss: 9.578e+03, MSE(e): 2.503e-04, MSE(pi1): 4.447e-01, MSE(pi2): 1.052e-04, MSE(pi3): 1.610e-03\n",
      "Epoch 22200, Train loss: 1.991e+03, Test loss: 4.239e+03, MSE(e): 1.235e-04, MSE(pi1): 5.601e-02, MSE(pi2): 9.664e-05, MSE(pi3): 1.964e-03\n",
      "Epoch 22300, Train loss: 1.907e+03, Test loss: 4.162e+03, MSE(e): 1.297e-04, MSE(pi1): 4.523e-02, MSE(pi2): 9.360e-05, MSE(pi3): 1.576e-03\n",
      "Epoch 22400, Train loss: 1.370e+03, Test loss: 3.332e+03, MSE(e): 9.137e-05, MSE(pi1): 2.788e-02, MSE(pi2): 7.278e-05, MSE(pi3): 1.775e-03\n",
      "Epoch 22500, Train loss: 2.188e+03, Test loss: 5.168e+03, MSE(e): 1.590e-04, MSE(pi1): 4.708e-02, MSE(pi2): 1.155e-04, MSE(pi3): 1.263e-03\n",
      "Epoch 22600, Train loss: 2.378e+03, Test loss: 4.759e+03, MSE(e): 1.197e-04, MSE(pi1): 1.053e-01, MSE(pi2): 8.198e-05, MSE(pi3): 1.281e-03\n",
      "Epoch 22700, Train loss: 1.458e+03, Test loss: 3.515e+03, MSE(e): 1.018e-04, MSE(pi1): 3.097e-02, MSE(pi2): 7.822e-05, MSE(pi3): 1.300e-03\n",
      "Epoch 22800, Train loss: 4.037e+03, Test loss: 6.264e+03, MSE(e): 1.574e-04, MSE(pi1): 2.268e-01, MSE(pi2): 8.392e-05, MSE(pi3): 1.940e-03\n",
      "Epoch 22900, Train loss: 1.633e+03, Test loss: 4.165e+03, MSE(e): 1.012e-04, MSE(pi1): 4.829e-02, MSE(pi2): 7.543e-05, MSE(pi3): 1.382e-03\n",
      "Epoch 23000, Train loss: 1.795e+03, Test loss: 3.955e+03, MSE(e): 1.329e-04, MSE(pi1): 2.924e-02, MSE(pi2): 9.410e-05, MSE(pi3): 1.735e-03\n",
      "Epoch 23100, Train loss: 1.707e+03, Test loss: 3.610e+03, MSE(e): 9.996e-05, MSE(pi1): 5.502e-02, MSE(pi2): 7.365e-05, MSE(pi3): 1.570e-03\n",
      "Epoch 23200, Train loss: 2.142e+03, Test loss: 4.077e+03, MSE(e): 1.173e-04, MSE(pi1): 7.711e-02, MSE(pi2): 7.845e-05, MSE(pi3): 1.975e-03\n",
      "Epoch 23300, Train loss: 1.627e+03, Test loss: 4.050e+03, MSE(e): 1.077e-04, MSE(pi1): 3.504e-02, MSE(pi2): 8.018e-05, MSE(pi3): 2.001e-03\n",
      "Epoch 23400, Train loss: 3.909e+03, Test loss: 5.798e+03, MSE(e): 2.934e-04, MSE(pi1): 6.854e-02, MSE(pi2): 1.922e-04, MSE(pi3): 2.894e-03\n",
      "Epoch 23500, Train loss: 2.248e+03, Test loss: 4.101e+03, MSE(e): 1.117e-04, MSE(pi1): 9.339e-02, MSE(pi2): 7.537e-05, MSE(pi3): 1.970e-03\n",
      "Epoch 23600, Train loss: 1.519e+03, Test loss: 3.773e+03, MSE(e): 9.175e-05, MSE(pi1): 4.751e-02, MSE(pi2): 6.856e-05, MSE(pi3): 1.260e-03\n",
      "Epoch 23700, Train loss: 1.620e+03, Test loss: 3.875e+03, MSE(e): 1.031e-04, MSE(pi1): 4.080e-02, MSE(pi2): 7.223e-05, MSE(pi3): 1.809e-03\n",
      "Epoch 23800, Train loss: 1.226e+03, Test loss: 3.113e+03, MSE(e): 9.262e-05, MSE(pi1): 1.656e-02, MSE(pi2): 7.111e-05, MSE(pi3): 1.340e-03\n",
      "Epoch 23900, Train loss: 1.652e+03, Test loss: 3.472e+03, MSE(e): 9.517e-05, MSE(pi1): 5.604e-02, MSE(pi2): 6.701e-05, MSE(pi3): 1.400e-03\n",
      "Epoch 24000, Train loss: 6.410e+03, Test loss: 1.114e+04, MSE(e): 4.040e-04, MSE(pi1): 2.220e-01, MSE(pi2): 2.518e-04, MSE(pi3): 1.491e-03\n",
      "Epoch 24100, Train loss: 4.907e+03, Test loss: 7.883e+03, MSE(e): 3.946e-04, MSE(pi1): 7.020e-02, MSE(pi2): 2.247e-04, MSE(pi3): 2.587e-03\n",
      "Epoch 24200, Train loss: 1.190e+03, Test loss: 3.144e+03, MSE(e): 8.459e-05, MSE(pi1): 1.810e-02, MSE(pi2): 6.753e-05, MSE(pi3): 1.629e-03\n",
      "Epoch 24300, Train loss: 6.081e+03, Test loss: 9.069e+03, MSE(e): 2.920e-04, MSE(pi1): 3.036e-01, MSE(pi2): 1.437e-04, MSE(pi3): 1.250e-03\n",
      "Epoch 24400, Train loss: 4.851e+03, Test loss: 8.696e+03, MSE(e): 4.327e-04, MSE(pi1): 3.713e-02, MSE(pi2): 2.762e-04, MSE(pi3): 1.525e-03\n",
      "Epoch 24500, Train loss: 2.137e+03, Test loss: 4.032e+03, MSE(e): 1.071e-04, MSE(pi1): 9.099e-02, MSE(pi2): 6.950e-05, MSE(pi3): 1.564e-03\n",
      "Epoch 24600, Train loss: 1.567e+03, Test loss: 3.269e+03, MSE(e): 9.039e-05, MSE(pi1): 5.017e-02, MSE(pi2): 6.704e-05, MSE(pi3): 1.616e-03\n",
      "Epoch 24700, Train loss: 1.808e+03, Test loss: 4.180e+03, MSE(e): 9.808e-05, MSE(pi1): 6.958e-02, MSE(pi2): 6.834e-05, MSE(pi3): 1.312e-03\n",
      "Epoch 24800, Train loss: 2.274e+03, Test loss: 4.112e+03, MSE(e): 1.470e-04, MSE(pi1): 5.530e-02, MSE(pi2): 1.082e-04, MSE(pi3): 2.501e-03\n",
      "Epoch 24900, Train loss: 1.762e+03, Test loss: 3.384e+03, MSE(e): 1.059e-04, MSE(pi1): 5.331e-02, MSE(pi2): 7.379e-05, MSE(pi3): 1.705e-03\n",
      "Epoch 25000, Train loss: 1.319e+03, Test loss: 3.226e+03, MSE(e): 1.019e-04, MSE(pi1): 1.542e-02, MSE(pi2): 7.889e-05, MSE(pi3): 1.454e-03\n",
      "Epoch 25100, Train loss: 2.905e+03, Test loss: 5.409e+03, MSE(e): 1.606e-04, MSE(pi1): 1.117e-01, MSE(pi2): 9.681e-05, MSE(pi3): 1.819e-03\n",
      "Epoch 25200, Train loss: 1.154e+03, Test loss: 2.967e+03, MSE(e): 7.831e-05, MSE(pi1): 2.353e-02, MSE(pi2): 6.184e-05, MSE(pi3): 1.359e-03\n",
      "Epoch 25300, Train loss: 1.485e+03, Test loss: 3.401e+03, MSE(e): 1.162e-04, MSE(pi1): 1.874e-02, MSE(pi2): 8.458e-05, MSE(pi3): 1.353e-03\n",
      "Epoch 25400, Train loss: 3.776e+03, Test loss: 4.897e+03, MSE(e): 1.595e-04, MSE(pi1): 1.933e-01, MSE(pi2): 8.907e-05, MSE(pi3): 2.467e-03\n",
      "Epoch 25500, Train loss: 1.214e+03, Test loss: 3.067e+03, MSE(e): 7.719e-05, MSE(pi1): 2.633e-02, MSE(pi2): 6.148e-05, MSE(pi3): 1.788e-03\n",
      "Epoch 25600, Train loss: 3.835e+03, Test loss: 5.554e+03, MSE(e): 3.138e-04, MSE(pi1): 5.104e-02, MSE(pi2): 2.067e-04, MSE(pi3): 1.866e-03\n",
      "Epoch 25700, Train loss: 1.906e+03, Test loss: 4.070e+03, MSE(e): 1.038e-04, MSE(pi1): 6.387e-02, MSE(pi2): 6.877e-05, MSE(pi3): 2.300e-03\n",
      "Epoch 25800, Train loss: 1.324e+03, Test loss: 3.201e+03, MSE(e): 8.591e-05, MSE(pi1): 3.041e-02, MSE(pi2): 6.459e-05, MSE(pi3): 1.605e-03\n",
      "Epoch 25900, Train loss: 1.143e+03, Test loss: 2.787e+03, MSE(e): 7.478e-05, MSE(pi1): 2.580e-02, MSE(pi2): 5.932e-05, MSE(pi3): 1.376e-03\n",
      "Epoch 26000, Train loss: 1.166e+03, Test loss: 3.056e+03, MSE(e): 7.410e-05, MSE(pi1): 2.787e-02, MSE(pi2): 5.943e-05, MSE(pi3): 1.466e-03\n",
      "Epoch 26100, Train loss: 1.056e+03, Test loss: 2.803e+03, MSE(e): 7.645e-05, MSE(pi1): 1.304e-02, MSE(pi2): 6.235e-05, MSE(pi3): 1.609e-03\n",
      "Epoch 26200, Train loss: 1.967e+03, Test loss: 3.365e+03, MSE(e): 1.089e-04, MSE(pi1): 6.204e-02, MSE(pi2): 6.602e-05, MSE(pi3): 2.575e-03\n",
      "Epoch 26300, Train loss: 1.159e+03, Test loss: 2.983e+03, MSE(e): 7.609e-05, MSE(pi1): 2.492e-02, MSE(pi2): 5.967e-05, MSE(pi3): 1.487e-03\n",
      "Epoch 26400, Train loss: 2.027e+03, Test loss: 4.018e+03, MSE(e): 1.139e-04, MSE(pi1): 6.590e-02, MSE(pi2): 7.538e-05, MSE(pi3): 2.292e-03\n",
      "Epoch 26500, Train loss: 1.630e+03, Test loss: 4.615e+03, MSE(e): 8.496e-05, MSE(pi1): 6.207e-02, MSE(pi2): 6.160e-05, MSE(pi3): 1.594e-03\n",
      "Epoch 26600, Train loss: 1.156e+03, Test loss: 2.796e+03, MSE(e): 8.393e-05, MSE(pi1): 1.775e-02, MSE(pi2): 6.426e-05, MSE(pi3): 1.387e-03\n",
      "Epoch 26700, Train loss: 1.674e+03, Test loss: 4.126e+03, MSE(e): 1.166e-04, MSE(pi1): 3.071e-02, MSE(pi2): 7.965e-05, MSE(pi3): 2.000e-03\n",
      "Epoch 26800, Train loss: 1.767e+03, Test loss: 3.799e+03, MSE(e): 1.401e-04, MSE(pi1): 2.247e-02, MSE(pi2): 9.761e-05, MSE(pi3): 1.412e-03\n",
      "Epoch 26900, Train loss: 2.329e+03, Test loss: 5.823e+03, MSE(e): 1.034e-04, MSE(pi1): 1.150e-01, MSE(pi2): 6.446e-05, MSE(pi3): 1.443e-03\n",
      "Epoch 27000, Train loss: 1.555e+03, Test loss: 3.002e+03, MSE(e): 1.025e-04, MSE(pi1): 3.298e-02, MSE(pi2): 7.165e-05, MSE(pi3): 2.006e-03\n",
      "Epoch 27100, Train loss: 2.029e+03, Test loss: 3.848e+03, MSE(e): 1.570e-04, MSE(pi1): 3.349e-02, MSE(pi2): 1.082e-04, MSE(pi3): 1.248e-03\n",
      "Epoch 27200, Train loss: 1.057e+03, Test loss: 2.743e+03, MSE(e): 7.669e-05, MSE(pi1): 1.442e-02, MSE(pi2): 6.075e-05, MSE(pi3): 1.458e-03\n",
      "Epoch 27300, Train loss: 1.337e+03, Test loss: 3.334e+03, MSE(e): 7.847e-05, MSE(pi1): 3.471e-02, MSE(pi2): 5.950e-05, MSE(pi3): 2.049e-03\n",
      "Epoch 27400, Train loss: 1.205e+03, Test loss: 2.953e+03, MSE(e): 8.012e-05, MSE(pi1): 2.716e-02, MSE(pi2): 6.113e-05, MSE(pi3): 1.317e-03\n",
      "Epoch 27500, Train loss: 9.247e+02, Test loss: 2.511e+03, MSE(e): 6.757e-05, MSE(pi1): 1.261e-02, MSE(pi2): 5.621e-05, MSE(pi3): 1.228e-03\n",
      "Epoch 27600, Train loss: 1.160e+03, Test loss: 2.805e+03, MSE(e): 7.315e-05, MSE(pi1): 2.839e-02, MSE(pi2): 5.660e-05, MSE(pi3): 1.442e-03\n",
      "Epoch 27700, Train loss: 1.643e+03, Test loss: 3.322e+03, MSE(e): 8.250e-05, MSE(pi1): 6.244e-02, MSE(pi2): 5.684e-05, MSE(pi3): 1.935e-03\n",
      "Epoch 27800, Train loss: 2.200e+03, Test loss: 4.671e+03, MSE(e): 1.098e-04, MSE(pi1): 1.003e-01, MSE(pi2): 6.972e-05, MSE(pi3): 9.884e-04\n",
      "Epoch 27900, Train loss: 1.250e+03, Test loss: 2.876e+03, MSE(e): 7.352e-05, MSE(pi1): 3.006e-02, MSE(pi2): 5.673e-05, MSE(pi3): 2.140e-03\n",
      "Epoch 28000, Train loss: 1.209e+03, Test loss: 2.958e+03, MSE(e): 8.133e-05, MSE(pi1): 2.713e-02, MSE(pi2): 6.338e-05, MSE(pi3): 1.240e-03\n",
      "Epoch 28100, Train loss: 1.272e+03, Test loss: 2.887e+03, MSE(e): 9.480e-05, MSE(pi1): 1.706e-02, MSE(pi2): 7.246e-05, MSE(pi3): 1.529e-03\n",
      "Epoch 28200, Train loss: 1.192e+03, Test loss: 3.099e+03, MSE(e): 9.116e-05, MSE(pi1): 1.474e-02, MSE(pi2): 6.717e-05, MSE(pi3): 1.329e-03\n",
      "Epoch 28300, Train loss: 2.184e+03, Test loss: 3.630e+03, MSE(e): 1.454e-04, MSE(pi1): 5.211e-02, MSE(pi2): 9.888e-05, MSE(pi3): 2.091e-03\n",
      "Epoch 28400, Train loss: 1.478e+03, Test loss: 3.138e+03, MSE(e): 1.104e-04, MSE(pi1): 1.936e-02, MSE(pi2): 7.496e-05, MSE(pi3): 1.798e-03\n",
      "Epoch 28500, Train loss: 1.179e+03, Test loss: 2.544e+03, MSE(e): 7.204e-05, MSE(pi1): 2.659e-02, MSE(pi2): 5.555e-05, MSE(pi3): 1.930e-03\n",
      "Epoch 28600, Train loss: 1.419e+03, Test loss: 2.732e+03, MSE(e): 9.537e-05, MSE(pi1): 2.519e-02, MSE(pi2): 7.084e-05, MSE(pi3): 2.134e-03\n",
      "Epoch 28700, Train loss: 1.142e+03, Test loss: 2.969e+03, MSE(e): 6.971e-05, MSE(pi1): 3.400e-02, MSE(pi2): 5.312e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 28800, Train loss: 1.513e+03, Test loss: 2.985e+03, MSE(e): 1.086e-04, MSE(pi1): 2.931e-02, MSE(pi2): 7.456e-05, MSE(pi3): 1.336e-03\n",
      "Epoch 28900, Train loss: 1.116e+03, Test loss: 2.780e+03, MSE(e): 6.696e-05, MSE(pi1): 2.862e-02, MSE(pi2): 5.231e-05, MSE(pi3): 1.603e-03\n",
      "Epoch 29000, Train loss: 1.425e+03, Test loss: 3.207e+03, MSE(e): 1.004e-04, MSE(pi1): 2.627e-02, MSE(pi2): 6.892e-05, MSE(pi3): 1.581e-03\n",
      "Epoch 29100, Train loss: 2.201e+03, Test loss: 4.359e+03, MSE(e): 1.716e-04, MSE(pi1): 3.338e-02, MSE(pi2): 1.218e-04, MSE(pi3): 1.512e-03\n",
      "Epoch 29200, Train loss: 1.186e+03, Test loss: 2.436e+03, MSE(e): 6.943e-05, MSE(pi1): 2.810e-02, MSE(pi2): 5.153e-05, MSE(pi3): 2.103e-03\n",
      "Epoch 29300, Train loss: 3.637e+03, Test loss: 3.904e+03, MSE(e): 1.485e-04, MSE(pi1): 1.596e-01, MSE(pi2): 8.005e-05, MSE(pi3): 5.570e-03\n",
      "Epoch 29400, Train loss: 9.330e+02, Test loss: 2.683e+03, MSE(e): 6.172e-05, MSE(pi1): 1.854e-02, MSE(pi2): 5.016e-05, MSE(pi3): 1.303e-03\n",
      "Epoch 29500, Train loss: 1.237e+03, Test loss: 2.862e+03, MSE(e): 7.638e-05, MSE(pi1): 3.554e-02, MSE(pi2): 5.697e-05, MSE(pi3): 1.174e-03\n",
      "Epoch 29600, Train loss: 1.938e+03, Test loss: 4.898e+03, MSE(e): 8.765e-05, MSE(pi1): 9.621e-02, MSE(pi2): 5.515e-05, MSE(pi3): 9.953e-04\n",
      "Epoch 29700, Train loss: 1.291e+03, Test loss: 3.055e+03, MSE(e): 8.354e-05, MSE(pi1): 3.087e-02, MSE(pi2): 6.316e-05, MSE(pi3): 1.469e-03\n",
      "Epoch 29800, Train loss: 2.239e+03, Test loss: 4.627e+03, MSE(e): 1.281e-04, MSE(pi1): 8.041e-02, MSE(pi2): 8.898e-05, MSE(pi3): 1.538e-03\n",
      "Epoch 29900, Train loss: 2.038e+03, Test loss: 4.090e+03, MSE(e): 9.367e-05, MSE(pi1): 9.923e-02, MSE(pi2): 6.301e-05, MSE(pi3): 1.091e-03\n",
      "\n",
      "Proceso finalizado después de 30000 épocas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 9000\n",
    "n_epochs = 30000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 100\n",
    "\n",
    "second_lr = 3e-5\n",
    "\n",
    "train_loop(model, optimizer, n_checkpoints,\n",
    "           X_train, y_train, X_test, y_test, f_train, f_test,\n",
    "           D=D, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=device,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Starting from a checkpoint. Epoch 275000.\n",
      "Epoch 275000, Train loss: 3.086e+02, Test loss: 1.451e+03, MSE(e): 1.381e-05, MSE(pi1): 7.800e-03, MSE(pi2): 5.676e-06, MSE(pi3): 9.250e-04\n",
      "Epoch 275100, Train loss: 2.779e+02, Test loss: 1.149e+03, MSE(e): 9.965e-06, MSE(pi1): 8.112e-03, MSE(pi2): 4.650e-06, MSE(pi3): 9.708e-04\n",
      "Epoch 275200, Train loss: 2.219e+02, Test loss: 1.053e+03, MSE(e): 4.137e-06, MSE(pi1): 9.114e-03, MSE(pi2): 1.517e-06, MSE(pi3): 8.934e-04\n",
      "Epoch 275300, Train loss: 2.145e+02, Test loss: 1.052e+03, MSE(e): 5.975e-06, MSE(pi1): 6.529e-03, MSE(pi2): 3.077e-06, MSE(pi3): 8.948e-04\n",
      "Epoch 275400, Train loss: 2.893e+02, Test loss: 1.271e+03, MSE(e): 6.111e-06, MSE(pi1): 1.248e-02, MSE(pi2): 2.072e-06, MSE(pi3): 1.034e-03\n",
      "Epoch 275500, Train loss: 2.290e+02, Test loss: 1.024e+03, MSE(e): 5.883e-06, MSE(pi1): 6.646e-03, MSE(pi2): 2.343e-06, MSE(pi3): 1.037e-03\n",
      "Epoch 275600, Train loss: 3.428e+02, Test loss: 1.349e+03, MSE(e): 1.589e-05, MSE(pi1): 9.275e-03, MSE(pi2): 6.855e-06, MSE(pi3): 9.109e-04\n",
      "Epoch 275700, Train loss: 4.587e+02, Test loss: 1.161e+03, MSE(e): 2.331e-05, MSE(pi1): 1.004e-02, MSE(pi2): 1.080e-05, MSE(pi3): 1.252e-03\n",
      "Epoch 275800, Train loss: 4.638e+02, Test loss: 1.672e+03, MSE(e): 2.704e-05, MSE(pi1): 8.965e-03, MSE(pi2): 1.374e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 275900, Train loss: 4.177e+02, Test loss: 1.552e+03, MSE(e): 2.314e-05, MSE(pi1): 9.381e-03, MSE(pi2): 1.050e-05, MSE(pi3): 9.242e-04\n",
      "Epoch 276000, Train loss: 2.971e+02, Test loss: 1.122e+03, MSE(e): 8.690e-06, MSE(pi1): 1.072e-02, MSE(pi2): 3.411e-06, MSE(pi3): 1.030e-03\n",
      "Epoch 276100, Train loss: 7.887e+02, Test loss: 1.862e+03, MSE(e): 1.831e-05, MSE(pi1): 4.908e-02, MSE(pi2): 4.416e-06, MSE(pi3): 1.148e-03\n",
      "Epoch 276200, Train loss: 1.704e+02, Test loss: 1.026e+03, MSE(e): 3.069e-06, MSE(pi1): 4.233e-03, MSE(pi2): 1.484e-06, MSE(pi3): 9.740e-04\n",
      "Epoch 276300, Train loss: 2.342e+02, Test loss: 1.046e+03, MSE(e): 5.241e-06, MSE(pi1): 8.564e-03, MSE(pi2): 2.196e-06, MSE(pi3): 9.619e-04\n",
      "Epoch 276400, Train loss: 1.932e+02, Test loss: 1.092e+03, MSE(e): 4.981e-06, MSE(pi1): 5.073e-03, MSE(pi2): 2.323e-06, MSE(pi3): 9.265e-04\n",
      "Epoch 276500, Train loss: 2.568e+02, Test loss: 1.071e+03, MSE(e): 4.949e-06, MSE(pi1): 1.204e-02, MSE(pi2): 1.639e-06, MSE(pi3): 8.696e-04\n",
      "Epoch 276600, Train loss: 3.394e+02, Test loss: 1.294e+03, MSE(e): 6.660e-06, MSE(pi1): 1.667e-02, MSE(pi2): 2.005e-06, MSE(pi3): 1.061e-03\n",
      "Epoch 276700, Train loss: 2.181e+02, Test loss: 1.075e+03, MSE(e): 4.576e-06, MSE(pi1): 7.106e-03, MSE(pi2): 1.714e-06, MSE(pi3): 1.013e-03\n",
      "Epoch 276800, Train loss: 7.779e+02, Test loss: 1.304e+03, MSE(e): 5.336e-05, MSE(pi1): 1.514e-02, MSE(pi2): 2.359e-05, MSE(pi3): 9.291e-04\n",
      "Epoch 276900, Train loss: 1.722e+02, Test loss: 1.021e+03, MSE(e): 3.460e-06, MSE(pi1): 4.160e-03, MSE(pi2): 1.715e-06, MSE(pi3): 9.597e-04\n",
      "Epoch 277000, Train loss: 3.990e+02, Test loss: 1.337e+03, MSE(e): 1.114e-05, MSE(pi1): 1.768e-02, MSE(pi2): 3.575e-06, MSE(pi3): 1.108e-03\n",
      "Epoch 277100, Train loss: 2.463e+02, Test loss: 1.160e+03, MSE(e): 5.061e-06, MSE(pi1): 1.066e-02, MSE(pi2): 1.711e-06, MSE(pi3): 8.906e-04\n",
      "Epoch 277200, Train loss: 4.640e+02, Test loss: 1.724e+03, MSE(e): 3.108e-05, MSE(pi1): 5.314e-03, MSE(pi2): 1.401e-05, MSE(pi3): 1.000e-03\n",
      "Epoch 277300, Train loss: 2.723e+02, Test loss: 1.133e+03, MSE(e): 5.396e-06, MSE(pi1): 1.087e-02, MSE(pi2): 1.822e-06, MSE(pi3): 1.096e-03\n",
      "Epoch 277400, Train loss: 1.900e+02, Test loss: 1.050e+03, MSE(e): 3.345e-06, MSE(pi1): 6.433e-03, MSE(pi2): 1.441e-06, MSE(pi3): 9.223e-04\n",
      "Epoch 277500, Train loss: 2.366e+02, Test loss: 1.071e+03, MSE(e): 6.502e-06, MSE(pi1): 7.201e-03, MSE(pi2): 2.685e-06, MSE(pi3): 9.955e-04\n",
      "Epoch 277600, Train loss: 5.978e+02, Test loss: 1.388e+03, MSE(e): 2.873e-05, MSE(pi1): 1.921e-02, MSE(pi2): 1.104e-05, MSE(pi3): 1.184e-03\n",
      "Epoch 277700, Train loss: 2.661e+02, Test loss: 1.293e+03, MSE(e): 1.247e-05, MSE(pi1): 4.462e-03, MSE(pi2): 6.000e-06, MSE(pi3): 9.675e-04\n",
      "Epoch 277800, Train loss: 4.555e+02, Test loss: 1.415e+03, MSE(e): 9.137e-06, MSE(pi1): 2.326e-02, MSE(pi2): 2.209e-06, MSE(pi3): 1.316e-03\n",
      "Epoch 277900, Train loss: 3.166e+02, Test loss: 1.090e+03, MSE(e): 1.636e-05, MSE(pi1): 6.265e-03, MSE(pi2): 8.707e-06, MSE(pi3): 9.036e-04\n",
      "Epoch 278000, Train loss: 5.659e+02, Test loss: 1.624e+03, MSE(e): 3.502e-05, MSE(pi1): 1.172e-02, MSE(pi2): 1.594e-05, MSE(pi3): 9.852e-04\n",
      "Epoch 278100, Train loss: 3.576e+02, Test loss: 1.186e+03, MSE(e): 9.825e-06, MSE(pi1): 1.571e-02, MSE(pi2): 3.287e-06, MSE(pi3): 1.022e-03\n",
      "Epoch 278200, Train loss: 5.094e+02, Test loss: 1.440e+03, MSE(e): 1.122e-05, MSE(pi1): 3.024e-02, MSE(pi2): 2.967e-06, MSE(pi3): 9.482e-04\n",
      "Epoch 278300, Train loss: 4.566e+02, Test loss: 1.283e+03, MSE(e): 2.856e-05, MSE(pi1): 7.970e-03, MSE(pi2): 1.342e-05, MSE(pi3): 9.133e-04\n",
      "Epoch 278400, Train loss: 3.319e+02, Test loss: 1.225e+03, MSE(e): 1.205e-05, MSE(pi1): 1.203e-02, MSE(pi2): 5.556e-06, MSE(pi3): 9.108e-04\n",
      "Epoch 278500, Train loss: 3.289e+02, Test loss: 1.288e+03, MSE(e): 7.560e-06, MSE(pi1): 1.602e-02, MSE(pi2): 3.111e-06, MSE(pi3): 9.310e-04\n",
      "Epoch 278600, Train loss: 1.647e+02, Test loss: 1.021e+03, MSE(e): 3.086e-06, MSE(pi1): 4.195e-03, MSE(pi2): 1.480e-06, MSE(pi3): 9.190e-04\n",
      "Epoch 278700, Train loss: 1.015e+03, Test loss: 2.098e+03, MSE(e): 6.350e-05, MSE(pi1): 2.517e-02, MSE(pi2): 2.700e-05, MSE(pi3): 1.281e-03\n",
      "Epoch 278800, Train loss: 2.044e+02, Test loss: 1.007e+03, MSE(e): 4.467e-06, MSE(pi1): 6.097e-03, MSE(pi2): 2.075e-06, MSE(pi3): 9.878e-04\n",
      "Epoch 278900, Train loss: 1.685e+02, Test loss: 9.925e+02, MSE(e): 2.918e-06, MSE(pi1): 3.814e-03, MSE(pi2): 1.409e-06, MSE(pi3): 1.012e-03\n",
      "Epoch 279000, Train loss: 2.432e+02, Test loss: 1.092e+03, MSE(e): 5.111e-06, MSE(pi1): 8.547e-03, MSE(pi2): 2.011e-06, MSE(pi3): 1.067e-03\n",
      "Epoch 279100, Train loss: 3.288e+02, Test loss: 1.185e+03, MSE(e): 9.730e-06, MSE(pi1): 1.428e-02, MSE(pi2): 3.529e-06, MSE(pi3): 8.863e-04\n",
      "Epoch 279200, Train loss: 3.185e+02, Test loss: 1.296e+03, MSE(e): 6.665e-06, MSE(pi1): 1.403e-02, MSE(pi2): 1.995e-06, MSE(pi3): 1.116e-03\n",
      "Epoch 279300, Train loss: 2.695e+02, Test loss: 1.004e+03, MSE(e): 1.062e-05, MSE(pi1): 6.789e-03, MSE(pi2): 4.883e-06, MSE(pi3): 9.539e-04\n",
      "Epoch 279400, Train loss: 2.948e+02, Test loss: 1.242e+03, MSE(e): 6.062e-06, MSE(pi1): 1.223e-02, MSE(pi2): 2.088e-06, MSE(pi3): 1.119e-03\n",
      "Epoch 279500, Train loss: 4.553e+02, Test loss: 1.332e+03, MSE(e): 2.768e-05, MSE(pi1): 7.840e-03, MSE(pi2): 1.252e-05, MSE(pi3): 1.001e-03\n",
      "Epoch 279600, Train loss: 3.188e+02, Test loss: 1.213e+03, MSE(e): 9.926e-06, MSE(pi1): 1.233e-02, MSE(pi2): 4.135e-06, MSE(pi3): 9.628e-04\n",
      "Epoch 279700, Train loss: 5.033e+02, Test loss: 1.149e+03, MSE(e): 1.336e-05, MSE(pi1): 2.335e-02, MSE(pi2): 3.641e-06, MSE(pi3): 1.363e-03\n",
      "Epoch 279800, Train loss: 2.378e+02, Test loss: 1.175e+03, MSE(e): 4.547e-06, MSE(pi1): 1.026e-02, MSE(pi2): 1.600e-06, MSE(pi3): 8.969e-04\n",
      "Epoch 279900, Train loss: 1.279e+03, Test loss: 2.917e+03, MSE(e): 9.913e-05, MSE(pi1): 1.848e-02, MSE(pi2): 4.620e-05, MSE(pi3): 1.026e-03\n",
      "Epoch 280000, Train loss: 4.977e+02, Test loss: 1.398e+03, MSE(e): 3.540e-05, MSE(pi1): 3.756e-03, MSE(pi2): 1.624e-05, MSE(pi3): 1.061e-03\n",
      "Epoch 280100, Train loss: 2.974e+02, Test loss: 1.346e+03, MSE(e): 1.322e-05, MSE(pi1): 7.311e-03, MSE(pi2): 5.693e-06, MSE(pi3): 9.202e-04\n",
      "Epoch 280200, Train loss: 2.725e+02, Test loss: 1.154e+03, MSE(e): 5.898e-06, MSE(pi1): 1.039e-02, MSE(pi2): 2.214e-06, MSE(pi3): 1.096e-03\n",
      "Epoch 280300, Train loss: 1.876e+02, Test loss: 1.028e+03, MSE(e): 4.280e-06, MSE(pi1): 4.551e-03, MSE(pi2): 1.987e-06, MSE(pi3): 9.925e-04\n",
      "Epoch 280400, Train loss: 1.680e+02, Test loss: 1.019e+03, MSE(e): 2.807e-06, MSE(pi1): 4.487e-03, MSE(pi2): 1.412e-06, MSE(pi3): 9.501e-04\n",
      "Epoch 280500, Train loss: 1.806e+02, Test loss: 1.083e+03, MSE(e): 4.628e-06, MSE(pi1): 4.185e-03, MSE(pi2): 2.179e-06, MSE(pi3): 9.250e-04\n",
      "Epoch 280600, Train loss: 6.662e+02, Test loss: 1.668e+03, MSE(e): 3.409e-05, MSE(pi1): 2.164e-02, MSE(pi2): 1.454e-05, MSE(pi3): 1.088e-03\n",
      "Epoch 280700, Train loss: 2.885e+02, Test loss: 1.158e+03, MSE(e): 5.883e-06, MSE(pi1): 1.413e-02, MSE(pi2): 1.787e-06, MSE(pi3): 8.835e-04\n",
      "Epoch 280800, Train loss: 4.194e+02, Test loss: 1.447e+03, MSE(e): 1.239e-05, MSE(pi1): 2.084e-02, MSE(pi2): 3.652e-06, MSE(pi3): 8.710e-04\n",
      "Epoch 280900, Train loss: 2.422e+02, Test loss: 1.147e+03, MSE(e): 5.496e-06, MSE(pi1): 9.014e-03, MSE(pi2): 2.056e-06, MSE(pi3): 9.710e-04\n",
      "Epoch 281000, Train loss: 2.467e+02, Test loss: 1.162e+03, MSE(e): 6.643e-06, MSE(pi1): 7.381e-03, MSE(pi2): 3.127e-06, MSE(pi3): 1.064e-03\n",
      "Epoch 281100, Train loss: 4.411e+02, Test loss: 1.638e+03, MSE(e): 2.844e-05, MSE(pi1): 6.272e-03, MSE(pi2): 1.303e-05, MSE(pi3): 9.394e-04\n",
      "Epoch 281200, Train loss: 1.926e+02, Test loss: 9.819e+02, MSE(e): 4.380e-06, MSE(pi1): 6.136e-03, MSE(pi2): 1.991e-06, MSE(pi3): 8.748e-04\n",
      "Epoch 281300, Train loss: 5.655e+02, Test loss: 1.777e+03, MSE(e): 1.438e-05, MSE(pi1): 3.073e-02, MSE(pi2): 4.858e-06, MSE(pi3): 1.144e-03\n",
      "Epoch 281400, Train loss: 3.790e+02, Test loss: 1.380e+03, MSE(e): 1.099e-05, MSE(pi1): 1.824e-02, MSE(pi2): 3.386e-06, MSE(pi3): 8.667e-04\n",
      "Epoch 281500, Train loss: 2.946e+02, Test loss: 1.150e+03, MSE(e): 1.031e-05, MSE(pi1): 8.836e-03, MSE(pi2): 4.226e-06, MSE(pi3): 1.031e-03\n",
      "Epoch 281600, Train loss: 3.193e+02, Test loss: 1.273e+03, MSE(e): 6.821e-06, MSE(pi1): 1.567e-02, MSE(pi2): 2.104e-06, MSE(pi3): 9.438e-04\n",
      "Epoch 281700, Train loss: 3.122e+02, Test loss: 1.101e+03, MSE(e): 7.210e-06, MSE(pi1): 1.317e-02, MSE(pi2): 2.090e-06, MSE(pi3): 1.084e-03\n",
      "Epoch 281800, Train loss: 3.220e+02, Test loss: 1.265e+03, MSE(e): 7.110e-06, MSE(pi1): 1.549e-02, MSE(pi2): 2.136e-06, MSE(pi3): 9.599e-04\n",
      "Epoch 281900, Train loss: 1.133e+03, Test loss: 1.865e+03, MSE(e): 6.826e-05, MSE(pi1): 3.689e-02, MSE(pi2): 3.179e-05, MSE(pi3): 8.147e-04\n",
      "Epoch 282000, Train loss: 1.474e+03, Test loss: 1.949e+03, MSE(e): 1.201e-04, MSE(pi1): 1.812e-02, MSE(pi2): 5.949e-05, MSE(pi3): 9.252e-04\n",
      "Epoch 282100, Train loss: 5.576e+02, Test loss: 1.706e+03, MSE(e): 2.489e-05, MSE(pi1): 2.152e-02, MSE(pi2): 9.483e-06, MSE(pi3): 9.338e-04\n",
      "Epoch 282200, Train loss: 2.050e+03, Test loss: 2.891e+03, MSE(e): 1.897e-04, MSE(pi1): 6.615e-03, MSE(pi2): 8.972e-05, MSE(pi3): 8.635e-04\n",
      "Epoch 282300, Train loss: 2.944e+02, Test loss: 1.357e+03, MSE(e): 1.462e-05, MSE(pi1): 4.989e-03, MSE(pi2): 6.158e-06, MSE(pi3): 9.832e-04\n",
      "Epoch 282400, Train loss: 2.696e+02, Test loss: 1.226e+03, MSE(e): 1.311e-05, MSE(pi1): 4.457e-03, MSE(pi2): 6.288e-06, MSE(pi3): 9.394e-04\n",
      "Epoch 282500, Train loss: 2.563e+03, Test loss: 2.850e+03, MSE(e): 1.998e-04, MSE(pi1): 4.821e-02, MSE(pi2): 9.035e-05, MSE(pi3): 8.261e-04\n",
      "Epoch 282600, Train loss: 1.483e+03, Test loss: 2.502e+03, MSE(e): 1.132e-04, MSE(pi1): 2.396e-02, MSE(pi2): 4.903e-05, MSE(pi3): 1.105e-03\n",
      "Epoch 282700, Train loss: 3.752e+02, Test loss: 1.173e+03, MSE(e): 9.519e-06, MSE(pi1): 1.880e-02, MSE(pi2): 3.376e-06, MSE(pi3): 9.205e-04\n",
      "Epoch 282800, Train loss: 2.291e+02, Test loss: 1.025e+03, MSE(e): 7.942e-06, MSE(pi1): 5.637e-03, MSE(pi2): 3.624e-06, MSE(pi3): 9.326e-04\n",
      "Epoch 282900, Train loss: 1.377e+03, Test loss: 2.916e+03, MSE(e): 9.551e-05, MSE(pi1): 3.307e-02, MSE(pi2): 4.064e-05, MSE(pi3): 9.096e-04\n",
      "Epoch 283000, Train loss: 3.295e+02, Test loss: 1.358e+03, MSE(e): 1.271e-05, MSE(pi1): 1.075e-02, MSE(pi2): 6.034e-06, MSE(pi3): 9.487e-04\n",
      "Epoch 283100, Train loss: 4.766e+02, Test loss: 1.563e+03, MSE(e): 9.838e-06, MSE(pi1): 2.757e-02, MSE(pi2): 2.489e-06, MSE(pi3): 1.026e-03\n",
      "Epoch 283200, Train loss: 5.848e+02, Test loss: 1.609e+03, MSE(e): 1.259e-05, MSE(pi1): 3.726e-02, MSE(pi2): 2.599e-06, MSE(pi3): 8.633e-04\n",
      "Epoch 283300, Train loss: 2.131e+02, Test loss: 1.088e+03, MSE(e): 3.934e-06, MSE(pi1): 7.929e-03, MSE(pi2): 1.561e-06, MSE(pi3): 9.450e-04\n",
      "Epoch 283400, Train loss: 8.925e+02, Test loss: 2.378e+03, MSE(e): 6.228e-05, MSE(pi1): 1.563e-02, MSE(pi2): 2.986e-05, MSE(pi3): 1.134e-03\n",
      "Epoch 283500, Train loss: 1.313e+03, Test loss: 2.515e+03, MSE(e): 1.069e-04, MSE(pi1): 1.444e-02, MSE(pi2): 4.679e-05, MSE(pi3): 9.973e-04\n",
      "Epoch 283600, Train loss: 6.219e+02, Test loss: 1.445e+03, MSE(e): 2.179e-05, MSE(pi1): 3.199e-02, MSE(pi2): 8.433e-06, MSE(pi3): 8.405e-04\n",
      "Epoch 283700, Train loss: 1.973e+02, Test loss: 1.014e+03, MSE(e): 3.671e-06, MSE(pi1): 6.571e-03, MSE(pi2): 1.702e-06, MSE(pi3): 9.491e-04\n",
      "Epoch 283800, Train loss: 5.788e+02, Test loss: 1.255e+03, MSE(e): 1.341e-05, MSE(pi1): 3.098e-02, MSE(pi2): 3.143e-06, MSE(pi3): 1.349e-03\n",
      "Epoch 283900, Train loss: 5.678e+02, Test loss: 1.486e+03, MSE(e): 2.432e-05, MSE(pi1): 2.083e-02, MSE(pi2): 1.070e-05, MSE(pi3): 1.162e-03\n",
      "Epoch 284000, Train loss: 9.506e+02, Test loss: 2.308e+03, MSE(e): 7.525e-05, MSE(pi1): 8.149e-03, MSE(pi2): 3.688e-05, MSE(pi3): 1.166e-03\n",
      "Epoch 284100, Train loss: 3.035e+02, Test loss: 1.198e+03, MSE(e): 6.221e-06, MSE(pi1): 1.496e-02, MSE(pi2): 1.735e-06, MSE(pi3): 9.165e-04\n",
      "Epoch 284200, Train loss: 3.168e+02, Test loss: 1.122e+03, MSE(e): 8.798e-06, MSE(pi1): 1.154e-02, MSE(pi2): 2.665e-06, MSE(pi3): 1.134e-03\n",
      "Epoch 284300, Train loss: 1.886e+02, Test loss: 1.117e+03, MSE(e): 3.308e-06, MSE(pi1): 6.136e-03, MSE(pi2): 1.444e-06, MSE(pi3): 9.416e-04\n",
      "Epoch 284400, Train loss: 2.455e+02, Test loss: 1.191e+03, MSE(e): 6.698e-06, MSE(pi1): 7.223e-03, MSE(pi2): 2.651e-06, MSE(pi3): 1.063e-03\n",
      "Epoch 284500, Train loss: 3.297e+02, Test loss: 1.169e+03, MSE(e): 9.819e-06, MSE(pi1): 1.365e-02, MSE(pi2): 3.977e-06, MSE(pi3): 9.505e-04\n",
      "Epoch 284600, Train loss: 1.896e+02, Test loss: 1.077e+03, MSE(e): 3.618e-06, MSE(pi1): 5.394e-03, MSE(pi2): 1.813e-06, MSE(pi3): 9.947e-04\n",
      "Epoch 284700, Train loss: 2.056e+02, Test loss: 1.028e+03, MSE(e): 3.762e-06, MSE(pi1): 6.534e-03, MSE(pi2): 1.476e-06, MSE(pi3): 1.026e-03\n",
      "Epoch 284800, Train loss: 3.579e+02, Test loss: 1.265e+03, MSE(e): 1.316e-05, MSE(pi1): 1.386e-02, MSE(pi2): 6.123e-06, MSE(pi3): 8.771e-04\n",
      "Epoch 284900, Train loss: 2.386e+03, Test loss: 4.575e+03, MSE(e): 2.035e-04, MSE(pi1): 2.198e-02, MSE(pi2): 9.572e-05, MSE(pi3): 1.309e-03\n",
      "Epoch 285000, Train loss: 1.611e+02, Test loss: 1.010e+03, MSE(e): 2.585e-06, MSE(pi1): 4.110e-03, MSE(pi2): 1.348e-06, MSE(pi3): 9.419e-04\n",
      "Epoch 285100, Train loss: 2.061e+02, Test loss: 1.021e+03, MSE(e): 3.749e-06, MSE(pi1): 8.103e-03, MSE(pi2): 1.428e-06, MSE(pi3): 8.763e-04\n",
      "Epoch 285200, Train loss: 4.829e+02, Test loss: 1.277e+03, MSE(e): 3.107e-05, MSE(pi1): 8.317e-03, MSE(pi2): 1.318e-05, MSE(pi3): 8.908e-04\n",
      "Epoch 285300, Train loss: 4.648e+02, Test loss: 1.364e+03, MSE(e): 2.670e-05, MSE(pi1): 1.094e-02, MSE(pi2): 1.303e-05, MSE(pi3): 8.848e-04\n",
      "Epoch 285400, Train loss: 8.098e+02, Test loss: 2.152e+03, MSE(e): 1.718e-05, MSE(pi1): 4.958e-02, MSE(pi2): 4.523e-06, MSE(pi3): 1.422e-03\n",
      "Epoch 285500, Train loss: 3.791e+02, Test loss: 1.182e+03, MSE(e): 1.268e-05, MSE(pi1): 1.490e-02, MSE(pi2): 4.432e-06, MSE(pi3): 1.032e-03\n",
      "Epoch 285600, Train loss: 6.126e+02, Test loss: 1.519e+03, MSE(e): 4.004e-05, MSE(pi1): 1.291e-02, MSE(pi2): 2.022e-05, MSE(pi3): 8.311e-04\n",
      "Epoch 285700, Train loss: 2.638e+02, Test loss: 1.083e+03, MSE(e): 8.233e-06, MSE(pi1): 8.091e-03, MSE(pi2): 3.472e-06, MSE(pi3): 1.006e-03\n",
      "Epoch 285800, Train loss: 3.101e+02, Test loss: 1.185e+03, MSE(e): 7.164e-06, MSE(pi1): 1.501e-02, MSE(pi2): 2.582e-06, MSE(pi3): 8.840e-04\n",
      "Epoch 285900, Train loss: 1.990e+02, Test loss: 1.126e+03, MSE(e): 6.009e-06, MSE(pi1): 4.246e-03, MSE(pi2): 2.753e-06, MSE(pi3): 9.646e-04\n",
      "Epoch 286000, Train loss: 5.733e+02, Test loss: 1.425e+03, MSE(e): 3.146e-05, MSE(pi1): 1.751e-02, MSE(pi2): 1.166e-05, MSE(pi3): 8.358e-04\n",
      "Epoch 286100, Train loss: 5.205e+02, Test loss: 1.388e+03, MSE(e): 3.217e-05, MSE(pi1): 9.631e-03, MSE(pi2): 1.414e-05, MSE(pi3): 1.025e-03\n",
      "Epoch 286200, Train loss: 3.537e+02, Test loss: 1.258e+03, MSE(e): 7.635e-06, MSE(pi1): 1.739e-02, MSE(pi2): 2.006e-06, MSE(pi3): 1.034e-03\n",
      "Epoch 286300, Train loss: 6.927e+02, Test loss: 1.654e+03, MSE(e): 5.305e-05, MSE(pi1): 6.407e-03, MSE(pi2): 2.368e-05, MSE(pi3): 9.811e-04\n",
      "Epoch 286400, Train loss: 1.858e+02, Test loss: 1.008e+03, MSE(e): 4.474e-06, MSE(pi1): 4.947e-03, MSE(pi2): 2.231e-06, MSE(pi3): 9.159e-04\n",
      "Epoch 286500, Train loss: 3.663e+02, Test loss: 1.176e+03, MSE(e): 1.456e-05, MSE(pi1): 1.342e-02, MSE(pi2): 7.557e-06, MSE(pi3): 8.648e-04\n",
      "Epoch 286600, Train loss: 2.463e+02, Test loss: 1.007e+03, MSE(e): 5.449e-06, MSE(pi1): 8.521e-03, MSE(pi2): 2.042e-06, MSE(pi3): 1.066e-03\n",
      "Epoch 286700, Train loss: 2.438e+02, Test loss: 1.086e+03, MSE(e): 6.111e-06, MSE(pi1): 8.526e-03, MSE(pi2): 1.820e-06, MSE(pi3): 9.741e-04\n",
      "Epoch 286800, Train loss: 4.040e+02, Test loss: 1.428e+03, MSE(e): 8.866e-06, MSE(pi1): 2.194e-02, MSE(pi2): 2.241e-06, MSE(pi3): 9.592e-04\n",
      "Epoch 286900, Train loss: 8.216e+02, Test loss: 1.401e+03, MSE(e): 4.149e-05, MSE(pi1): 3.100e-02, MSE(pi2): 1.564e-05, MSE(pi3): 9.666e-04\n",
      "Epoch 287000, Train loss: 5.475e+02, Test loss: 1.343e+03, MSE(e): 1.789e-05, MSE(pi1): 2.426e-02, MSE(pi2): 6.237e-06, MSE(pi3): 1.260e-03\n",
      "Epoch 287100, Train loss: 2.309e+02, Test loss: 1.198e+03, MSE(e): 8.092e-06, MSE(pi1): 5.012e-03, MSE(pi2): 3.997e-06, MSE(pi3): 9.984e-04\n",
      "Epoch 287200, Train loss: 3.893e+02, Test loss: 1.344e+03, MSE(e): 8.613e-06, MSE(pi1): 2.141e-02, MSE(pi2): 2.361e-06, MSE(pi3): 8.909e-04\n",
      "Epoch 287300, Train loss: 1.600e+02, Test loss: 1.016e+03, MSE(e): 2.543e-06, MSE(pi1): 3.677e-03, MSE(pi2): 1.338e-06, MSE(pi3): 9.779e-04\n",
      "Epoch 287400, Train loss: 6.942e+02, Test loss: 1.686e+03, MSE(e): 1.773e-05, MSE(pi1): 3.825e-02, MSE(pi2): 4.328e-06, MSE(pi3): 1.345e-03\n",
      "Epoch 287500, Train loss: 3.958e+02, Test loss: 1.245e+03, MSE(e): 1.587e-05, MSE(pi1): 1.428e-02, MSE(pi2): 6.261e-06, MSE(pi3): 9.431e-04\n",
      "Epoch 287600, Train loss: 6.159e+02, Test loss: 1.469e+03, MSE(e): 2.228e-05, MSE(pi1): 2.880e-02, MSE(pi2): 8.061e-06, MSE(pi3): 1.051e-03\n",
      "Epoch 287700, Train loss: 5.544e+02, Test loss: 1.566e+03, MSE(e): 1.752e-05, MSE(pi1): 2.452e-02, MSE(pi2): 6.818e-06, MSE(pi3): 1.340e-03\n",
      "Epoch 287800, Train loss: 2.777e+02, Test loss: 1.251e+03, MSE(e): 8.776e-06, MSE(pi1): 8.436e-03, MSE(pi2): 4.179e-06, MSE(pi3): 1.055e-03\n",
      "Epoch 287900, Train loss: 2.664e+02, Test loss: 1.112e+03, MSE(e): 9.756e-06, MSE(pi1): 7.273e-03, MSE(pi2): 4.405e-06, MSE(pi3): 9.611e-04\n",
      "Epoch 288000, Train loss: 1.742e+03, Test loss: 3.895e+03, MSE(e): 1.535e-04, MSE(pi1): 1.031e-02, MSE(pi2): 7.070e-05, MSE(pi3): 1.039e-03\n",
      "Epoch 288100, Train loss: 3.049e+02, Test loss: 1.248e+03, MSE(e): 5.762e-06, MSE(pi1): 1.374e-02, MSE(pi2): 1.732e-06, MSE(pi3): 1.098e-03\n",
      "Epoch 288200, Train loss: 3.150e+02, Test loss: 1.046e+03, MSE(e): 1.044e-05, MSE(pi1): 1.005e-02, MSE(pi2): 4.233e-06, MSE(pi3): 1.101e-03\n",
      "Epoch 288300, Train loss: 4.447e+02, Test loss: 1.534e+03, MSE(e): 9.051e-06, MSE(pi1): 2.323e-02, MSE(pi2): 2.803e-06, MSE(pi3): 1.219e-03\n",
      "Epoch 288400, Train loss: 4.038e+02, Test loss: 1.315e+03, MSE(e): 1.026e-05, MSE(pi1): 1.969e-02, MSE(pi2): 3.855e-06, MSE(pi3): 1.042e-03\n",
      "Epoch 288500, Train loss: 2.962e+02, Test loss: 1.247e+03, MSE(e): 5.895e-06, MSE(pi1): 1.322e-02, MSE(pi2): 1.783e-06, MSE(pi3): 1.051e-03\n",
      "Epoch 288600, Train loss: 2.626e+02, Test loss: 1.163e+03, MSE(e): 4.940e-06, MSE(pi1): 1.085e-02, MSE(pi2): 1.705e-06, MSE(pi3): 1.047e-03\n",
      "Epoch 288700, Train loss: 3.146e+02, Test loss: 1.338e+03, MSE(e): 7.515e-06, MSE(pi1): 1.420e-02, MSE(pi2): 2.566e-06, MSE(pi3): 9.744e-04\n",
      "Epoch 288800, Train loss: 1.905e+02, Test loss: 1.040e+03, MSE(e): 5.214e-06, MSE(pi1): 3.950e-03, MSE(pi2): 2.413e-06, MSE(pi3): 9.887e-04\n",
      "Epoch 288900, Train loss: 3.965e+02, Test loss: 1.632e+03, MSE(e): 2.163e-05, MSE(pi1): 7.762e-03, MSE(pi2): 1.060e-05, MSE(pi3): 1.026e-03\n",
      "Epoch 289000, Train loss: 7.013e+02, Test loss: 1.625e+03, MSE(e): 4.766e-05, MSE(pi1): 1.431e-02, MSE(pi2): 2.290e-05, MSE(pi3): 8.155e-04\n",
      "Epoch 289100, Train loss: 2.938e+02, Test loss: 1.146e+03, MSE(e): 6.683e-06, MSE(pi1): 1.172e-02, MSE(pi2): 2.004e-06, MSE(pi3): 1.098e-03\n",
      "Epoch 289200, Train loss: 3.534e+02, Test loss: 1.335e+03, MSE(e): 8.130e-06, MSE(pi1): 1.867e-02, MSE(pi2): 2.083e-06, MSE(pi3): 8.540e-04\n",
      "Epoch 289300, Train loss: 2.611e+02, Test loss: 1.170e+03, MSE(e): 8.882e-06, MSE(pi1): 7.387e-03, MSE(pi2): 4.169e-06, MSE(pi3): 9.836e-04\n",
      "Epoch 289400, Train loss: 1.281e+03, Test loss: 1.639e+03, MSE(e): 1.050e-04, MSE(pi1): 1.457e-02, MSE(pi2): 4.852e-05, MSE(pi3): 8.541e-04\n",
      "Epoch 289500, Train loss: 2.534e+02, Test loss: 1.119e+03, MSE(e): 4.596e-06, MSE(pi1): 9.992e-03, MSE(pi2): 1.596e-06, MSE(pi3): 1.076e-03\n",
      "Epoch 289600, Train loss: 3.025e+02, Test loss: 1.045e+03, MSE(e): 9.748e-06, MSE(pi1): 1.195e-02, MSE(pi2): 4.187e-06, MSE(pi3): 8.554e-04\n",
      "Epoch 289700, Train loss: 1.160e+03, Test loss: 2.204e+03, MSE(e): 9.703e-05, MSE(pi1): 1.046e-02, MSE(pi2): 4.784e-05, MSE(pi3): 8.468e-04\n",
      "Epoch 289800, Train loss: 6.927e+02, Test loss: 1.650e+03, MSE(e): 3.930e-05, MSE(pi1): 2.096e-02, MSE(pi2): 1.938e-05, MSE(pi3): 9.007e-04\n",
      "Epoch 289900, Train loss: 2.498e+03, Test loss: 3.171e+03, MSE(e): 2.264e-04, MSE(pi1): 1.412e-02, MSE(pi2): 1.087e-04, MSE(pi3): 9.255e-04\n",
      "Epoch 290000, Train loss: 6.023e+02, Test loss: 1.251e+03, MSE(e): 2.748e-05, MSE(pi1): 1.999e-02, MSE(pi2): 1.104e-05, MSE(pi3): 1.275e-03\n",
      "Epoch 290100, Train loss: 1.826e+02, Test loss: 1.011e+03, MSE(e): 3.525e-06, MSE(pi1): 4.828e-03, MSE(pi2): 1.561e-06, MSE(pi3): 9.904e-04\n",
      "Epoch 290200, Train loss: 2.447e+02, Test loss: 1.000e+03, MSE(e): 5.735e-06, MSE(pi1): 8.884e-03, MSE(pi2): 2.080e-06, MSE(pi3): 9.847e-04\n",
      "Epoch 290300, Train loss: 5.577e+02, Test loss: 1.711e+03, MSE(e): 2.343e-05, MSE(pi1): 1.935e-02, MSE(pi2): 1.069e-05, MSE(pi3): 1.299e-03\n",
      "Epoch 290400, Train loss: 2.198e+03, Test loss: 3.610e+03, MSE(e): 1.912e-04, MSE(pi1): 1.822e-02, MSE(pi2): 9.379e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 290500, Train loss: 5.046e+02, Test loss: 1.341e+03, MSE(e): 1.277e-05, MSE(pi1): 2.704e-02, MSE(pi2): 3.315e-06, MSE(pi3): 1.066e-03\n",
      "Epoch 290600, Train loss: 2.972e+02, Test loss: 1.270e+03, MSE(e): 9.040e-06, MSE(pi1): 1.172e-02, MSE(pi2): 3.367e-06, MSE(pi3): 8.956e-04\n",
      "Epoch 290700, Train loss: 6.993e+02, Test loss: 1.587e+03, MSE(e): 5.483e-05, MSE(pi1): 6.083e-03, MSE(pi2): 2.745e-05, MSE(pi3): 9.008e-04\n",
      "Epoch 290800, Train loss: 3.798e+02, Test loss: 1.246e+03, MSE(e): 2.322e-05, MSE(pi1): 5.972e-03, MSE(pi2): 1.162e-05, MSE(pi3): 8.785e-04\n",
      "Epoch 290900, Train loss: 3.522e+02, Test loss: 1.142e+03, MSE(e): 7.272e-06, MSE(pi1): 1.764e-02, MSE(pi2): 2.218e-06, MSE(pi3): 1.030e-03\n",
      "Epoch 291000, Train loss: 2.253e+02, Test loss: 1.083e+03, MSE(e): 5.338e-06, MSE(pi1): 6.935e-03, MSE(pi2): 2.200e-06, MSE(pi3): 1.025e-03\n",
      "Epoch 291100, Train loss: 4.091e+02, Test loss: 1.406e+03, MSE(e): 1.468e-05, MSE(pi1): 1.454e-02, MSE(pi2): 5.885e-06, MSE(pi3): 1.169e-03\n",
      "Epoch 291200, Train loss: 8.704e+02, Test loss: 1.465e+03, MSE(e): 5.291e-05, MSE(pi1): 2.061e-02, MSE(pi2): 2.625e-05, MSE(pi3): 1.351e-03\n",
      "Epoch 291300, Train loss: 1.138e+03, Test loss: 2.510e+03, MSE(e): 7.947e-05, MSE(pi1): 2.214e-02, MSE(pi2): 4.023e-05, MSE(pi3): 1.222e-03\n",
      "Epoch 291400, Train loss: 3.400e+02, Test loss: 1.212e+03, MSE(e): 1.373e-05, MSE(pi1): 9.169e-03, MSE(pi2): 4.998e-06, MSE(pi3): 1.110e-03\n",
      "Epoch 291500, Train loss: 2.279e+02, Test loss: 1.167e+03, MSE(e): 4.762e-06, MSE(pi1): 7.437e-03, MSE(pi2): 1.901e-06, MSE(pi3): 1.060e-03\n",
      "Epoch 291600, Train loss: 1.798e+02, Test loss: 1.024e+03, MSE(e): 2.885e-06, MSE(pi1): 6.187e-03, MSE(pi2): 1.274e-06, MSE(pi3): 8.904e-04\n",
      "Epoch 291700, Train loss: 9.971e+02, Test loss: 2.129e+03, MSE(e): 5.001e-05, MSE(pi1): 3.718e-02, MSE(pi2): 2.125e-05, MSE(pi3): 1.251e-03\n",
      "Epoch 291800, Train loss: 1.526e+03, Test loss: 2.768e+03, MSE(e): 1.252e-04, MSE(pi1): 1.547e-02, MSE(pi2): 5.643e-05, MSE(pi3): 1.195e-03\n",
      "Epoch 291900, Train loss: 2.382e+02, Test loss: 1.013e+03, MSE(e): 5.254e-06, MSE(pi1): 9.160e-03, MSE(pi2): 2.045e-06, MSE(pi3): 9.403e-04\n",
      "Epoch 292000, Train loss: 4.219e+02, Test loss: 1.354e+03, MSE(e): 8.887e-06, MSE(pi1): 2.272e-02, MSE(pi2): 2.389e-06, MSE(pi3): 1.058e-03\n",
      "Epoch 292100, Train loss: 4.242e+02, Test loss: 1.335e+03, MSE(e): 8.743e-06, MSE(pi1): 2.517e-02, MSE(pi2): 2.104e-06, MSE(pi3): 8.510e-04\n",
      "Epoch 292200, Train loss: 1.636e+02, Test loss: 1.014e+03, MSE(e): 2.478e-06, MSE(pi1): 4.742e-03, MSE(pi2): 1.232e-06, MSE(pi3): 9.141e-04\n",
      "Epoch 292300, Train loss: 2.105e+02, Test loss: 1.021e+03, MSE(e): 6.521e-06, MSE(pi1): 4.975e-03, MSE(pi2): 3.074e-06, MSE(pi3): 9.551e-04\n",
      "Epoch 292400, Train loss: 2.737e+02, Test loss: 1.300e+03, MSE(e): 6.058e-06, MSE(pi1): 1.207e-02, MSE(pi2): 2.451e-06, MSE(pi3): 9.242e-04\n",
      "Epoch 292500, Train loss: 2.035e+02, Test loss: 1.045e+03, MSE(e): 3.761e-06, MSE(pi1): 6.418e-03, MSE(pi2): 1.484e-06, MSE(pi3): 1.017e-03\n",
      "Epoch 292600, Train loss: 2.571e+02, Test loss: 1.199e+03, MSE(e): 5.439e-06, MSE(pi1): 9.721e-03, MSE(pi2): 2.242e-06, MSE(pi3): 1.055e-03\n",
      "Epoch 292700, Train loss: 8.744e+02, Test loss: 2.012e+03, MSE(e): 5.557e-05, MSE(pi1): 2.008e-02, MSE(pi2): 2.466e-05, MSE(pi3): 1.178e-03\n",
      "Epoch 292800, Train loss: 2.411e+02, Test loss: 1.253e+03, MSE(e): 8.201e-06, MSE(pi1): 6.304e-03, MSE(pi2): 3.667e-06, MSE(pi3): 9.610e-04\n",
      "Epoch 292900, Train loss: 5.132e+02, Test loss: 1.081e+03, MSE(e): 3.288e-05, MSE(pi1): 9.341e-03, MSE(pi2): 1.280e-05, MSE(pi3): 9.103e-04\n",
      "Epoch 293000, Train loss: 3.073e+02, Test loss: 1.204e+03, MSE(e): 9.580e-06, MSE(pi1): 1.211e-02, MSE(pi2): 4.742e-06, MSE(pi3): 9.038e-04\n",
      "Epoch 293100, Train loss: 2.164e+02, Test loss: 1.095e+03, MSE(e): 4.315e-06, MSE(pi1): 7.625e-03, MSE(pi2): 1.661e-06, MSE(pi3): 9.696e-04\n",
      "Epoch 293200, Train loss: 2.045e+02, Test loss: 1.024e+03, MSE(e): 6.024e-06, MSE(pi1): 5.108e-03, MSE(pi2): 2.877e-06, MSE(pi3): 9.315e-04\n",
      "Epoch 293300, Train loss: 2.413e+02, Test loss: 1.051e+03, MSE(e): 7.809e-06, MSE(pi1): 7.303e-03, MSE(pi2): 3.715e-06, MSE(pi3): 9.014e-04\n",
      "Epoch 293400, Train loss: 3.615e+02, Test loss: 1.404e+03, MSE(e): 1.380e-05, MSE(pi1): 1.113e-02, MSE(pi2): 6.486e-06, MSE(pi3): 1.122e-03\n",
      "Epoch 293500, Train loss: 1.370e+03, Test loss: 2.091e+03, MSE(e): 1.028e-04, MSE(pi1): 2.010e-02, MSE(pi2): 4.534e-05, MSE(pi3): 1.408e-03\n",
      "Epoch 293600, Train loss: 3.244e+02, Test loss: 1.078e+03, MSE(e): 8.355e-06, MSE(pi1): 1.529e-02, MSE(pi2): 3.298e-06, MSE(pi3): 8.790e-04\n",
      "Epoch 293700, Train loss: 7.149e+02, Test loss: 1.707e+03, MSE(e): 5.134e-05, MSE(pi1): 9.540e-03, MSE(pi2): 2.319e-05, MSE(pi3): 1.060e-03\n",
      "Epoch 293800, Train loss: 3.670e+02, Test loss: 1.297e+03, MSE(e): 8.580e-06, MSE(pi1): 1.962e-02, MSE(pi2): 2.751e-06, MSE(pi3): 8.494e-04\n",
      "Epoch 293900, Train loss: 1.981e+02, Test loss: 1.103e+03, MSE(e): 5.245e-06, MSE(pi1): 4.996e-03, MSE(pi2): 2.047e-06, MSE(pi3): 9.566e-04\n",
      "Epoch 294000, Train loss: 7.282e+02, Test loss: 1.882e+03, MSE(e): 1.552e-05, MSE(pi1): 4.632e-02, MSE(pi2): 3.560e-06, MSE(pi3): 1.098e-03\n",
      "Epoch 294100, Train loss: 2.198e+02, Test loss: 1.099e+03, MSE(e): 7.252e-06, MSE(pi1): 5.504e-03, MSE(pi2): 3.483e-06, MSE(pi3): 9.224e-04\n",
      "Epoch 294200, Train loss: 6.523e+02, Test loss: 1.684e+03, MSE(e): 1.542e-05, MSE(pi1): 3.581e-02, MSE(pi2): 4.185e-06, MSE(pi3): 1.400e-03\n",
      "Epoch 294300, Train loss: 4.632e+02, Test loss: 1.592e+03, MSE(e): 1.689e-05, MSE(pi1): 1.895e-02, MSE(pi2): 7.152e-06, MSE(pi3): 1.048e-03\n",
      "Epoch 294400, Train loss: 6.403e+02, Test loss: 1.473e+03, MSE(e): 4.434e-05, MSE(pi1): 1.136e-02, MSE(pi2): 2.265e-05, MSE(pi3): 8.324e-04\n",
      "Epoch 294500, Train loss: 2.107e+02, Test loss: 1.159e+03, MSE(e): 6.909e-06, MSE(pi1): 4.180e-03, MSE(pi2): 3.350e-06, MSE(pi3): 9.983e-04\n",
      "Epoch 294600, Train loss: 2.695e+02, Test loss: 1.213e+03, MSE(e): 1.091e-05, MSE(pi1): 6.408e-03, MSE(pi2): 4.895e-06, MSE(pi3): 9.636e-04\n",
      "Epoch 294700, Train loss: 2.665e+02, Test loss: 1.230e+03, MSE(e): 1.135e-05, MSE(pi1): 6.025e-03, MSE(pi2): 5.285e-06, MSE(pi3): 9.283e-04\n",
      "Epoch 294800, Train loss: 5.176e+02, Test loss: 1.502e+03, MSE(e): 1.084e-05, MSE(pi1): 3.072e-02, MSE(pi2): 2.350e-06, MSE(pi3): 1.020e-03\n",
      "Epoch 294900, Train loss: 1.359e+03, Test loss: 1.850e+03, MSE(e): 1.053e-04, MSE(pi1): 2.245e-02, MSE(pi2): 5.046e-05, MSE(pi3): 8.121e-04\n",
      "Epoch 295000, Train loss: 2.970e+03, Test loss: 4.647e+03, MSE(e): 2.783e-04, MSE(pi1): 8.467e-03, MSE(pi2): 1.308e-04, MSE(pi3): 1.021e-03\n",
      "Epoch 295100, Train loss: 8.439e+02, Test loss: 1.622e+03, MSE(e): 6.667e-05, MSE(pi1): 8.345e-03, MSE(pi2): 3.185e-05, MSE(pi3): 9.367e-04\n",
      "Epoch 295200, Train loss: 3.435e+02, Test loss: 1.255e+03, MSE(e): 7.208e-06, MSE(pi1): 1.644e-02, MSE(pi2): 1.958e-06, MSE(pi3): 1.070e-03\n",
      "Epoch 295300, Train loss: 3.065e+02, Test loss: 1.122e+03, MSE(e): 1.470e-05, MSE(pi1): 7.150e-03, MSE(pi2): 6.681e-06, MSE(pi3): 8.801e-04\n",
      "Epoch 295400, Train loss: 2.308e+02, Test loss: 1.163e+03, MSE(e): 4.084e-06, MSE(pi1): 8.594e-03, MSE(pi2): 1.597e-06, MSE(pi3): 1.040e-03\n",
      "Epoch 295500, Train loss: 5.122e+02, Test loss: 1.461e+03, MSE(e): 2.159e-05, MSE(pi1): 1.717e-02, MSE(pi2): 8.994e-06, MSE(pi3): 1.245e-03\n",
      "Epoch 295600, Train loss: 1.902e+02, Test loss: 1.025e+03, MSE(e): 3.203e-06, MSE(pi1): 6.991e-03, MSE(pi2): 1.401e-06, MSE(pi3): 8.823e-04\n",
      "Epoch 295700, Train loss: 1.906e+02, Test loss: 1.081e+03, MSE(e): 4.306e-06, MSE(pi1): 4.742e-03, MSE(pi2): 2.165e-06, MSE(pi3): 1.001e-03\n",
      "Epoch 295800, Train loss: 2.223e+02, Test loss: 1.053e+03, MSE(e): 5.021e-06, MSE(pi1): 8.200e-03, MSE(pi2): 1.897e-06, MSE(pi3): 9.010e-04\n",
      "Epoch 295900, Train loss: 3.617e+02, Test loss: 1.397e+03, MSE(e): 1.068e-05, MSE(pi1): 1.406e-02, MSE(pi2): 4.650e-06, MSE(pi3): 1.143e-03\n",
      "Epoch 296000, Train loss: 3.424e+02, Test loss: 1.122e+03, MSE(e): 6.905e-06, MSE(pi1): 1.683e-02, MSE(pi2): 1.994e-06, MSE(pi3): 1.050e-03\n",
      "Epoch 296100, Train loss: 6.422e+02, Test loss: 1.997e+03, MSE(e): 4.561e-05, MSE(pi1): 8.111e-03, MSE(pi2): 2.204e-05, MSE(pi3): 1.050e-03\n",
      "Epoch 296200, Train loss: 4.596e+02, Test loss: 1.695e+03, MSE(e): 3.136e-05, MSE(pi1): 4.011e-03, MSE(pi2): 1.484e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 296300, Train loss: 3.791e+02, Test loss: 1.293e+03, MSE(e): 7.793e-06, MSE(pi1): 1.907e-02, MSE(pi2): 1.904e-06, MSE(pi3): 1.105e-03\n",
      "Epoch 296400, Train loss: 4.082e+02, Test loss: 1.321e+03, MSE(e): 9.159e-06, MSE(pi1): 2.133e-02, MSE(pi2): 2.731e-06, MSE(pi3): 1.033e-03\n",
      "Epoch 296500, Train loss: 2.809e+02, Test loss: 1.016e+03, MSE(e): 6.509e-06, MSE(pi1): 1.245e-02, MSE(pi2): 2.258e-06, MSE(pi3): 9.126e-04\n",
      "Epoch 296600, Train loss: 6.362e+02, Test loss: 1.155e+03, MSE(e): 4.574e-05, MSE(pi1): 9.214e-03, MSE(pi2): 2.292e-05, MSE(pi3): 8.668e-04\n",
      "Epoch 296700, Train loss: 6.850e+02, Test loss: 1.746e+03, MSE(e): 5.444e-05, MSE(pi1): 5.264e-03, MSE(pi2): 2.545e-05, MSE(pi3): 8.790e-04\n",
      "Epoch 296800, Train loss: 2.109e+02, Test loss: 9.992e+02, MSE(e): 7.125e-06, MSE(pi1): 5.189e-03, MSE(pi2): 3.436e-06, MSE(pi3): 8.774e-04\n",
      "Epoch 296900, Train loss: 3.240e+02, Test loss: 1.139e+03, MSE(e): 1.004e-05, MSE(pi1): 1.163e-02, MSE(pi2): 3.538e-06, MSE(pi3): 1.072e-03\n",
      "Epoch 297000, Train loss: 2.883e+02, Test loss: 1.241e+03, MSE(e): 5.543e-06, MSE(pi1): 1.367e-02, MSE(pi2): 1.691e-06, MSE(pi3): 9.618e-04\n",
      "Epoch 297100, Train loss: 1.930e+02, Test loss: 1.006e+03, MSE(e): 3.336e-06, MSE(pi1): 6.756e-03, MSE(pi2): 1.328e-06, MSE(pi3): 9.207e-04\n",
      "Epoch 297200, Train loss: 3.324e+02, Test loss: 1.398e+03, MSE(e): 1.045e-05, MSE(pi1): 1.168e-02, MSE(pi2): 4.356e-06, MSE(pi3): 1.111e-03\n",
      "Epoch 297300, Train loss: 1.878e+02, Test loss: 9.942e+02, MSE(e): 4.722e-06, MSE(pi1): 4.590e-03, MSE(pi2): 2.173e-06, MSE(pi3): 9.471e-04\n",
      "Epoch 297400, Train loss: 4.328e+02, Test loss: 1.176e+03, MSE(e): 2.640e-05, MSE(pi1): 6.931e-03, MSE(pi2): 1.279e-05, MSE(pi3): 9.948e-04\n",
      "Epoch 297500, Train loss: 1.627e+02, Test loss: 1.072e+03, MSE(e): 2.493e-06, MSE(pi1): 4.220e-03, MSE(pi2): 1.271e-06, MSE(pi3): 9.560e-04\n",
      "Epoch 297600, Train loss: 2.486e+02, Test loss: 1.050e+03, MSE(e): 6.507e-06, MSE(pi1): 8.902e-03, MSE(pi2): 2.755e-06, MSE(pi3): 9.450e-04\n",
      "Epoch 297700, Train loss: 2.873e+02, Test loss: 1.171e+03, MSE(e): 1.404e-05, MSE(pi1): 5.253e-03, MSE(pi2): 5.855e-06, MSE(pi3): 9.439e-04\n",
      "Epoch 297800, Train loss: 3.269e+02, Test loss: 1.093e+03, MSE(e): 1.892e-05, MSE(pi1): 4.476e-03, MSE(pi2): 8.449e-06, MSE(pi3): 9.301e-04\n",
      "Epoch 297900, Train loss: 3.875e+02, Test loss: 1.139e+03, MSE(e): 2.157e-05, MSE(pi1): 7.154e-03, MSE(pi2): 1.001e-05, MSE(pi3): 1.003e-03\n",
      "Epoch 298000, Train loss: 2.355e+02, Test loss: 1.171e+03, MSE(e): 7.332e-06, MSE(pi1): 6.637e-03, MSE(pi2): 3.149e-06, MSE(pi3): 9.581e-04\n",
      "Epoch 298100, Train loss: 2.678e+02, Test loss: 1.086e+03, MSE(e): 4.823e-06, MSE(pi1): 1.156e-02, MSE(pi2): 1.700e-06, MSE(pi3): 1.039e-03\n",
      "Epoch 298200, Train loss: 3.134e+02, Test loss: 1.395e+03, MSE(e): 1.224e-05, MSE(pi1): 1.014e-02, MSE(pi2): 4.831e-06, MSE(pi3): 8.965e-04\n",
      "Epoch 298300, Train loss: 3.807e+02, Test loss: 1.119e+03, MSE(e): 2.267e-05, MSE(pi1): 6.125e-03, MSE(pi2): 1.086e-05, MSE(pi3): 9.276e-04\n",
      "Epoch 298400, Train loss: 1.955e+02, Test loss: 1.005e+03, MSE(e): 5.799e-06, MSE(pi1): 4.451e-03, MSE(pi2): 2.783e-06, MSE(pi3): 9.297e-04\n",
      "Epoch 298500, Train loss: 1.036e+03, Test loss: 1.953e+03, MSE(e): 8.515e-05, MSE(pi1): 9.379e-03, MSE(pi2): 4.053e-05, MSE(pi3): 9.062e-04\n",
      "Epoch 298600, Train loss: 1.461e+03, Test loss: 3.243e+03, MSE(e): 1.159e-04, MSE(pi1): 1.806e-02, MSE(pi2): 5.463e-05, MSE(pi3): 1.213e-03\n",
      "Epoch 298700, Train loss: 8.124e+02, Test loss: 1.727e+03, MSE(e): 5.141e-05, MSE(pi1): 1.521e-02, MSE(pi2): 2.395e-05, MSE(pi3): 1.463e-03\n",
      "Epoch 298800, Train loss: 3.765e+02, Test loss: 1.031e+03, MSE(e): 1.834e-05, MSE(pi1): 9.916e-03, MSE(pi2): 9.688e-06, MSE(pi3): 9.398e-04\n",
      "Epoch 298900, Train loss: 7.168e+02, Test loss: 2.069e+03, MSE(e): 3.440e-05, MSE(pi1): 2.568e-02, MSE(pi2): 1.603e-05, MSE(pi3): 1.160e-03\n",
      "Epoch 299000, Train loss: 3.275e+02, Test loss: 1.399e+03, MSE(e): 1.893e-05, MSE(pi1): 4.196e-03, MSE(pi2): 9.258e-06, MSE(pi3): 9.624e-04\n",
      "Epoch 299100, Train loss: 2.072e+03, Test loss: 3.784e+03, MSE(e): 1.516e-04, MSE(pi1): 4.749e-02, MSE(pi2): 7.596e-05, MSE(pi3): 8.074e-04\n",
      "Epoch 299200, Train loss: 2.488e+02, Test loss: 1.124e+03, MSE(e): 4.296e-06, MSE(pi1): 1.045e-02, MSE(pi2): 1.525e-06, MSE(pi3): 1.013e-03\n",
      "Epoch 299300, Train loss: 3.502e+02, Test loss: 1.249e+03, MSE(e): 1.169e-05, MSE(pi1): 1.269e-02, MSE(pi2): 4.867e-06, MSE(pi3): 1.064e-03\n",
      "Epoch 299400, Train loss: 2.946e+02, Test loss: 1.178e+03, MSE(e): 6.243e-06, MSE(pi1): 1.457e-02, MSE(pi2): 2.296e-06, MSE(pi3): 8.646e-04\n",
      "Epoch 299500, Train loss: 2.798e+02, Test loss: 1.181e+03, MSE(e): 6.682e-06, MSE(pi1): 1.135e-02, MSE(pi2): 2.647e-06, MSE(pi3): 9.943e-04\n",
      "Epoch 299600, Train loss: 5.402e+02, Test loss: 1.073e+03, MSE(e): 2.499e-05, MSE(pi1): 1.886e-02, MSE(pi2): 1.118e-05, MSE(pi3): 1.017e-03\n",
      "Epoch 299700, Train loss: 3.974e+02, Test loss: 1.190e+03, MSE(e): 2.631e-05, MSE(pi1): 3.687e-03, MSE(pi2): 1.181e-05, MSE(pi3): 9.735e-04\n",
      "Epoch 299800, Train loss: 2.088e+02, Test loss: 1.036e+03, MSE(e): 3.372e-06, MSE(pi1): 7.408e-03, MSE(pi2): 1.332e-06, MSE(pi3): 1.010e-03\n",
      "Epoch 299900, Train loss: 6.556e+02, Test loss: 1.547e+03, MSE(e): 3.479e-05, MSE(pi1): 2.161e-02, MSE(pi2): 1.623e-05, MSE(pi3): 9.160e-04\n",
      "Epoch 300000, Train loss: 4.820e+02, Test loss: 1.050e+03, MSE(e): 3.282e-05, MSE(pi1): 5.368e-03, MSE(pi2): 1.517e-05, MSE(pi3): 1.001e-03\n",
      "Epoch 300100, Train loss: 5.396e+02, Test loss: 1.294e+03, MSE(e): 3.803e-05, MSE(pi1): 5.682e-03, MSE(pi2): 1.816e-05, MSE(pi3): 1.025e-03\n",
      "Epoch 300200, Train loss: 6.327e+02, Test loss: 1.552e+03, MSE(e): 4.033e-05, MSE(pi1): 1.409e-02, MSE(pi2): 1.830e-05, MSE(pi3): 8.855e-04\n",
      "Epoch 300300, Train loss: 2.948e+02, Test loss: 1.155e+03, MSE(e): 8.548e-06, MSE(pi1): 1.214e-02, MSE(pi2): 4.356e-06, MSE(pi3): 8.789e-04\n",
      "Epoch 300400, Train loss: 3.422e+02, Test loss: 1.418e+03, MSE(e): 7.948e-06, MSE(pi1): 1.619e-02, MSE(pi2): 2.884e-06, MSE(pi3): 1.008e-03\n",
      "Epoch 300500, Train loss: 1.223e+03, Test loss: 2.198e+03, MSE(e): 1.012e-04, MSE(pi1): 1.106e-02, MSE(pi2): 4.796e-05, MSE(pi3): 1.008e-03\n",
      "Epoch 300600, Train loss: 3.541e+02, Test loss: 1.462e+03, MSE(e): 2.197e-05, MSE(pi1): 3.672e-03, MSE(pi2): 1.076e-05, MSE(pi3): 9.759e-04\n",
      "Epoch 300700, Train loss: 3.876e+02, Test loss: 1.196e+03, MSE(e): 1.098e-05, MSE(pi1): 1.948e-02, MSE(pi2): 3.937e-06, MSE(pi3): 8.301e-04\n",
      "Epoch 300800, Train loss: 1.456e+03, Test loss: 2.534e+03, MSE(e): 1.112e-04, MSE(pi1): 2.637e-02, MSE(pi2): 5.351e-05, MSE(pi3): 7.983e-04\n",
      "Epoch 300900, Train loss: 2.356e+02, Test loss: 1.125e+03, MSE(e): 5.278e-06, MSE(pi1): 9.417e-03, MSE(pi2): 1.986e-06, MSE(pi3): 8.861e-04\n",
      "Epoch 301000, Train loss: 5.672e+02, Test loss: 1.583e+03, MSE(e): 1.274e-05, MSE(pi1): 2.951e-02, MSE(pi2): 2.709e-06, MSE(pi3): 1.447e-03\n",
      "Epoch 301100, Train loss: 1.561e+02, Test loss: 9.788e+02, MSE(e): 2.388e-06, MSE(pi1): 3.524e-03, MSE(pi2): 1.222e-06, MSE(pi3): 9.695e-04\n",
      "Epoch 301200, Train loss: 2.317e+02, Test loss: 1.010e+03, MSE(e): 6.291e-06, MSE(pi1): 7.662e-03, MSE(pi2): 3.317e-06, MSE(pi3): 9.216e-04\n",
      "Epoch 301300, Train loss: 3.849e+02, Test loss: 1.256e+03, MSE(e): 1.476e-05, MSE(pi1): 1.306e-02, MSE(pi2): 8.080e-06, MSE(pi3): 1.066e-03\n",
      "Epoch 301400, Train loss: 2.019e+02, Test loss: 1.100e+03, MSE(e): 3.175e-06, MSE(pi1): 7.989e-03, MSE(pi2): 1.320e-06, MSE(pi3): 9.025e-04\n",
      "Epoch 301500, Train loss: 9.936e+02, Test loss: 2.144e+03, MSE(e): 6.555e-05, MSE(pi1): 2.547e-02, MSE(pi2): 3.122e-05, MSE(pi3): 8.340e-04\n",
      "Epoch 301600, Train loss: 2.753e+02, Test loss: 1.032e+03, MSE(e): 7.378e-06, MSE(pi1): 1.030e-02, MSE(pi2): 2.606e-06, MSE(pi3): 9.846e-04\n",
      "Epoch 301700, Train loss: 2.255e+02, Test loss: 1.116e+03, MSE(e): 4.018e-06, MSE(pi1): 8.876e-03, MSE(pi2): 1.401e-06, MSE(pi3): 9.656e-04\n",
      "Epoch 301800, Train loss: 2.175e+02, Test loss: 1.130e+03, MSE(e): 7.678e-06, MSE(pi1): 4.443e-03, MSE(pi2): 3.795e-06, MSE(pi3): 9.633e-04\n",
      "Epoch 301900, Train loss: 2.340e+02, Test loss: 1.086e+03, MSE(e): 5.483e-06, MSE(pi1): 7.078e-03, MSE(pi2): 2.621e-06, MSE(pi3): 1.084e-03\n",
      "Epoch 302000, Train loss: 2.468e+03, Test loss: 4.479e+03, MSE(e): 2.306e-04, MSE(pi1): 5.979e-03, MSE(pi2): 1.062e-04, MSE(pi3): 1.022e-03\n",
      "Epoch 302100, Train loss: 3.205e+02, Test loss: 1.130e+03, MSE(e): 1.702e-05, MSE(pi1): 6.356e-03, MSE(pi2): 8.472e-06, MSE(pi3): 8.674e-04\n",
      "Epoch 302200, Train loss: 1.841e+02, Test loss: 1.045e+03, MSE(e): 4.181e-06, MSE(pi1): 4.728e-03, MSE(pi2): 1.990e-06, MSE(pi3): 9.502e-04\n",
      "Epoch 302300, Train loss: 8.432e+02, Test loss: 2.418e+03, MSE(e): 3.515e-05, MSE(pi1): 3.599e-02, MSE(pi2): 1.450e-05, MSE(pi3): 1.317e-03\n",
      "Epoch 302400, Train loss: 2.818e+02, Test loss: 1.265e+03, MSE(e): 9.549e-06, MSE(pi1): 8.147e-03, MSE(pi2): 4.483e-06, MSE(pi3): 1.049e-03\n",
      "Epoch 302500, Train loss: 2.161e+02, Test loss: 1.097e+03, MSE(e): 5.617e-06, MSE(pi1): 6.630e-03, MSE(pi2): 2.248e-06, MSE(pi3): 9.361e-04\n",
      "Epoch 302600, Train loss: 1.931e+02, Test loss: 1.111e+03, MSE(e): 5.931e-06, MSE(pi1): 3.734e-03, MSE(pi2): 3.137e-06, MSE(pi3): 9.642e-04\n",
      "Epoch 302700, Train loss: 2.125e+02, Test loss: 1.121e+03, MSE(e): 5.286e-06, MSE(pi1): 5.521e-03, MSE(pi2): 2.469e-06, MSE(pi3): 1.044e-03\n",
      "Epoch 302800, Train loss: 3.321e+02, Test loss: 1.188e+03, MSE(e): 1.717e-05, MSE(pi1): 4.939e-03, MSE(pi2): 9.063e-06, MSE(pi3): 1.110e-03\n",
      "Epoch 302900, Train loss: 2.906e+03, Test loss: 5.447e+03, MSE(e): 2.629e-04, MSE(pi1): 1.356e-02, MSE(pi2): 1.248e-04, MSE(pi3): 1.419e-03\n",
      "Epoch 303000, Train loss: 3.229e+02, Test loss: 1.210e+03, MSE(e): 7.848e-06, MSE(pi1): 1.397e-02, MSE(pi2): 2.486e-06, MSE(pi3): 1.048e-03\n",
      "Epoch 303100, Train loss: 2.589e+03, Test loss: 4.261e+03, MSE(e): 2.297e-04, MSE(pi1): 1.634e-02, MSE(pi2): 1.136e-04, MSE(pi3): 1.287e-03\n",
      "Epoch 303200, Train loss: 7.583e+02, Test loss: 1.695e+03, MSE(e): 4.392e-05, MSE(pi1): 2.348e-02, MSE(pi2): 2.173e-05, MSE(pi3): 8.420e-04\n",
      "Epoch 303300, Train loss: 3.764e+02, Test loss: 1.184e+03, MSE(e): 8.032e-06, MSE(pi1): 1.762e-02, MSE(pi2): 1.983e-06, MSE(pi3): 1.199e-03\n",
      "Epoch 303400, Train loss: 1.920e+02, Test loss: 1.024e+03, MSE(e): 3.121e-06, MSE(pi1): 6.872e-03, MSE(pi2): 1.311e-06, MSE(pi3): 9.206e-04\n",
      "Epoch 303500, Train loss: 1.637e+03, Test loss: 3.230e+03, MSE(e): 1.226e-04, MSE(pi1): 2.746e-02, MSE(pi2): 5.536e-05, MSE(pi3): 1.359e-03\n",
      "Epoch 303600, Train loss: 2.647e+02, Test loss: 1.244e+03, MSE(e): 9.322e-06, MSE(pi1): 7.982e-03, MSE(pi2): 3.782e-06, MSE(pi3): 9.169e-04\n",
      "Epoch 303700, Train loss: 1.074e+03, Test loss: 1.565e+03, MSE(e): 8.362e-05, MSE(pi1): 1.365e-02, MSE(pi2): 3.811e-05, MSE(pi3): 1.014e-03\n",
      "Epoch 303800, Train loss: 4.621e+02, Test loss: 1.367e+03, MSE(e): 1.970e-05, MSE(pi1): 1.603e-02, MSE(pi2): 7.787e-06, MSE(pi3): 1.049e-03\n",
      "Epoch 303900, Train loss: 2.411e+02, Test loss: 1.016e+03, MSE(e): 5.095e-06, MSE(pi1): 8.459e-03, MSE(pi2): 2.130e-06, MSE(pi3): 1.055e-03\n",
      "Epoch 304000, Train loss: 1.628e+03, Test loss: 3.677e+03, MSE(e): 1.363e-04, MSE(pi1): 1.410e-02, MSE(pi2): 6.398e-05, MSE(pi3): 1.237e-03\n",
      "Epoch 304100, Train loss: 2.369e+02, Test loss: 1.084e+03, MSE(e): 4.330e-06, MSE(pi1): 8.998e-03, MSE(pi2): 1.572e-06, MSE(pi3): 1.037e-03\n",
      "Epoch 304200, Train loss: 3.751e+02, Test loss: 1.221e+03, MSE(e): 1.156e-05, MSE(pi1): 1.568e-02, MSE(pi2): 4.174e-06, MSE(pi3): 1.027e-03\n",
      "Epoch 304300, Train loss: 2.114e+02, Test loss: 1.107e+03, MSE(e): 6.371e-06, MSE(pi1): 4.555e-03, MSE(pi2): 3.280e-06, MSE(pi3): 1.021e-03\n",
      "Epoch 304400, Train loss: 2.229e+03, Test loss: 3.419e+03, MSE(e): 1.978e-04, MSE(pi1): 1.537e-02, MSE(pi2): 9.240e-05, MSE(pi3): 9.784e-04\n",
      "Epoch 304500, Train loss: 3.747e+02, Test loss: 1.318e+03, MSE(e): 8.434e-06, MSE(pi1): 1.824e-02, MSE(pi2): 2.136e-06, MSE(pi3): 1.079e-03\n",
      "Epoch 304600, Train loss: 1.339e+03, Test loss: 2.796e+03, MSE(e): 8.492e-05, MSE(pi1): 3.672e-02, MSE(pi2): 3.831e-05, MSE(pi3): 1.227e-03\n",
      "Epoch 304700, Train loss: 1.997e+02, Test loss: 1.002e+03, MSE(e): 4.565e-06, MSE(pi1): 5.857e-03, MSE(pi2): 2.110e-06, MSE(pi3): 9.551e-04\n",
      "Epoch 304800, Train loss: 3.102e+02, Test loss: 1.033e+03, MSE(e): 6.784e-06, MSE(pi1): 1.551e-02, MSE(pi2): 2.154e-06, MSE(pi3): 8.732e-04\n",
      "Epoch 304900, Train loss: 1.741e+02, Test loss: 9.960e+02, MSE(e): 4.355e-06, MSE(pi1): 3.394e-03, MSE(pi2): 1.981e-06, MSE(pi3): 9.665e-04\n",
      "Epoch 305000, Train loss: 5.949e+02, Test loss: 2.049e+03, MSE(e): 1.259e-05, MSE(pi1): 3.620e-02, MSE(pi2): 2.881e-06, MSE(pi3): 1.070e-03\n",
      "Epoch 305100, Train loss: 3.186e+02, Test loss: 1.202e+03, MSE(e): 6.422e-06, MSE(pi1): 1.677e-02, MSE(pi2): 1.709e-06, MSE(pi3): 8.666e-04\n",
      "Epoch 305200, Train loss: 1.978e+02, Test loss: 1.066e+03, MSE(e): 3.142e-06, MSE(pi1): 7.602e-03, MSE(pi2): 1.226e-06, MSE(pi3): 9.038e-04\n",
      "Epoch 305300, Train loss: 5.011e+02, Test loss: 1.312e+03, MSE(e): 1.247e-05, MSE(pi1): 2.542e-02, MSE(pi2): 2.606e-06, MSE(pi3): 1.222e-03\n",
      "Epoch 305400, Train loss: 1.854e+02, Test loss: 1.015e+03, MSE(e): 4.000e-06, MSE(pi1): 4.889e-03, MSE(pi2): 1.819e-06, MSE(pi3): 9.650e-04\n",
      "Epoch 305500, Train loss: 3.284e+02, Test loss: 1.142e+03, MSE(e): 8.656e-06, MSE(pi1): 1.509e-02, MSE(pi2): 3.614e-06, MSE(pi3): 9.099e-04\n",
      "Epoch 305600, Train loss: 2.709e+03, Test loss: 3.684e+03, MSE(e): 2.333e-04, MSE(pi1): 2.944e-02, MSE(pi2): 1.170e-04, MSE(pi3): 8.176e-04\n",
      "Epoch 305700, Train loss: 2.416e+03, Test loss: 4.450e+03, MSE(e): 1.885e-04, MSE(pi1): 4.337e-02, MSE(pi2): 8.257e-05, MSE(pi3): 9.722e-04\n",
      "Epoch 305800, Train loss: 2.791e+03, Test loss: 4.779e+03, MSE(e): 2.399e-04, MSE(pi1): 2.678e-02, MSE(pi2): 1.132e-04, MSE(pi3): 1.240e-03\n",
      "Epoch 305900, Train loss: 2.757e+02, Test loss: 1.141e+03, MSE(e): 8.871e-06, MSE(pi1): 1.003e-02, MSE(pi2): 4.128e-06, MSE(pi3): 8.667e-04\n",
      "Epoch 306000, Train loss: 2.334e+02, Test loss: 1.066e+03, MSE(e): 4.067e-06, MSE(pi1): 8.993e-03, MSE(pi2): 1.553e-06, MSE(pi3): 1.028e-03\n",
      "Epoch 306100, Train loss: 2.530e+02, Test loss: 1.194e+03, MSE(e): 4.514e-06, MSE(pi1): 1.044e-02, MSE(pi2): 1.530e-06, MSE(pi3): 1.034e-03\n",
      "Epoch 306200, Train loss: 4.891e+02, Test loss: 1.501e+03, MSE(e): 1.248e-05, MSE(pi1): 2.721e-02, MSE(pi2): 3.180e-06, MSE(pi3): 9.221e-04\n",
      "Epoch 306300, Train loss: 3.682e+02, Test loss: 1.334e+03, MSE(e): 8.500e-06, MSE(pi1): 1.689e-02, MSE(pi2): 2.831e-06, MSE(pi3): 1.143e-03\n",
      "Epoch 306400, Train loss: 1.564e+02, Test loss: 1.008e+03, MSE(e): 2.487e-06, MSE(pi1): 3.603e-03, MSE(pi2): 1.270e-06, MSE(pi3): 9.552e-04\n",
      "Epoch 306500, Train loss: 1.929e+02, Test loss: 1.032e+03, MSE(e): 3.027e-06, MSE(pi1): 6.905e-03, MSE(pi2): 1.259e-06, MSE(pi3): 9.362e-04\n",
      "Epoch 306600, Train loss: 3.158e+02, Test loss: 1.111e+03, MSE(e): 1.173e-05, MSE(pi1): 1.078e-02, MSE(pi2): 5.878e-06, MSE(pi3): 9.074e-04\n",
      "Epoch 306700, Train loss: 9.571e+02, Test loss: 2.554e+03, MSE(e): 7.045e-05, MSE(pi1): 1.335e-02, MSE(pi2): 3.486e-05, MSE(pi3): 1.192e-03\n",
      "Epoch 306800, Train loss: 1.614e+03, Test loss: 3.469e+03, MSE(e): 1.402e-04, MSE(pi1): 9.254e-03, MSE(pi2): 6.682e-05, MSE(pi3): 1.194e-03\n",
      "Epoch 306900, Train loss: 1.840e+03, Test loss: 3.426e+03, MSE(e): 1.615e-04, MSE(pi1): 9.798e-03, MSE(pi2): 7.843e-05, MSE(pi3): 1.274e-03\n",
      "Epoch 307000, Train loss: 7.592e+02, Test loss: 2.284e+03, MSE(e): 4.507e-05, MSE(pi1): 1.876e-02, MSE(pi2): 2.132e-05, MSE(pi3): 1.208e-03\n",
      "Epoch 307100, Train loss: 4.992e+02, Test loss: 1.489e+03, MSE(e): 9.930e-06, MSE(pi1): 2.937e-02, MSE(pi2): 2.578e-06, MSE(pi3): 1.062e-03\n",
      "Epoch 307200, Train loss: 4.879e+02, Test loss: 1.605e+03, MSE(e): 3.090e-05, MSE(pi1): 9.099e-03, MSE(pi2): 1.524e-05, MSE(pi3): 8.786e-04\n",
      "Epoch 307300, Train loss: 3.707e+02, Test loss: 1.392e+03, MSE(e): 8.398e-06, MSE(pi1): 1.988e-02, MSE(pi2): 3.153e-06, MSE(pi3): 8.789e-04\n",
      "Epoch 307400, Train loss: 3.146e+02, Test loss: 1.310e+03, MSE(e): 8.870e-06, MSE(pi1): 1.349e-02, MSE(pi2): 3.074e-06, MSE(pi3): 9.102e-04\n",
      "Epoch 307500, Train loss: 1.226e+03, Test loss: 2.662e+03, MSE(e): 1.024e-04, MSE(pi1): 9.464e-03, MSE(pi2): 4.787e-05, MSE(pi3): 1.068e-03\n",
      "Epoch 307600, Train loss: 2.809e+02, Test loss: 1.291e+03, MSE(e): 1.131e-05, MSE(pi1): 7.469e-03, MSE(pi2): 4.763e-06, MSE(pi3): 9.307e-04\n",
      "Epoch 307700, Train loss: 3.282e+02, Test loss: 1.275e+03, MSE(e): 6.827e-06, MSE(pi1): 1.678e-02, MSE(pi2): 2.028e-06, MSE(pi3): 9.210e-04\n",
      "Epoch 307800, Train loss: 4.014e+02, Test loss: 1.329e+03, MSE(e): 8.061e-06, MSE(pi1): 2.221e-02, MSE(pi2): 2.141e-06, MSE(pi3): 9.871e-04\n",
      "Epoch 307900, Train loss: 2.072e+02, Test loss: 1.031e+03, MSE(e): 4.195e-06, MSE(pi1): 6.452e-03, MSE(pi2): 1.583e-06, MSE(pi3): 1.007e-03\n",
      "Epoch 308000, Train loss: 1.923e+02, Test loss: 1.100e+03, MSE(e): 4.459e-06, MSE(pi1): 5.189e-03, MSE(pi2): 2.207e-06, MSE(pi3): 9.586e-04\n",
      "Epoch 308100, Train loss: 2.478e+02, Test loss: 1.109e+03, MSE(e): 5.267e-06, MSE(pi1): 8.956e-03, MSE(pi2): 1.855e-06, MSE(pi3): 1.056e-03\n",
      "Epoch 308200, Train loss: 1.270e+03, Test loss: 2.727e+03, MSE(e): 9.662e-05, MSE(pi1): 2.118e-02, MSE(pi2): 4.394e-05, MSE(pi3): 9.210e-04\n",
      "Epoch 308300, Train loss: 1.587e+03, Test loss: 2.279e+03, MSE(e): 1.359e-04, MSE(pi1): 1.469e-02, MSE(pi2): 6.523e-05, MSE(pi3): 8.144e-04\n",
      "Epoch 308400, Train loss: 3.836e+02, Test loss: 1.378e+03, MSE(e): 7.413e-06, MSE(pi1): 1.915e-02, MSE(pi2): 2.243e-06, MSE(pi3): 1.180e-03\n",
      "Epoch 308500, Train loss: 4.979e+02, Test loss: 1.540e+03, MSE(e): 1.958e-05, MSE(pi1): 2.096e-02, MSE(pi2): 7.090e-06, MSE(pi3): 9.252e-04\n",
      "Epoch 308600, Train loss: 4.884e+02, Test loss: 1.377e+03, MSE(e): 1.912e-05, MSE(pi1): 1.797e-02, MSE(pi2): 7.557e-06, MSE(pi3): 1.176e-03\n",
      "Epoch 308700, Train loss: 1.779e+02, Test loss: 9.897e+02, MSE(e): 3.515e-06, MSE(pi1): 5.257e-03, MSE(pi2): 1.550e-06, MSE(pi3): 9.016e-04\n",
      "Epoch 308800, Train loss: 2.709e+02, Test loss: 1.194e+03, MSE(e): 4.509e-06, MSE(pi1): 1.386e-02, MSE(pi2): 1.565e-06, MSE(pi3): 8.714e-04\n",
      "Epoch 308900, Train loss: 1.670e+03, Test loss: 3.216e+03, MSE(e): 1.128e-04, MSE(pi1): 3.879e-02, MSE(pi2): 5.202e-05, MSE(pi3): 1.535e-03\n",
      "Epoch 309000, Train loss: 3.181e+02, Test loss: 1.270e+03, MSE(e): 9.807e-06, MSE(pi1): 1.141e-02, MSE(pi2): 4.440e-06, MSE(pi3): 1.060e-03\n",
      "Epoch 309100, Train loss: 1.988e+02, Test loss: 1.028e+03, MSE(e): 4.247e-06, MSE(pi1): 5.878e-03, MSE(pi2): 1.798e-06, MSE(pi3): 9.755e-04\n",
      "Epoch 309200, Train loss: 3.595e+02, Test loss: 1.314e+03, MSE(e): 6.941e-06, MSE(pi1): 2.003e-02, MSE(pi2): 1.697e-06, MSE(pi3): 8.976e-04\n",
      "Epoch 309300, Train loss: 2.005e+02, Test loss: 9.771e+02, MSE(e): 6.649e-06, MSE(pi1): 4.336e-03, MSE(pi2): 3.428e-06, MSE(pi3): 9.067e-04\n",
      "Epoch 309400, Train loss: 2.209e+02, Test loss: 1.173e+03, MSE(e): 3.528e-06, MSE(pi1): 8.788e-03, MSE(pi2): 1.347e-06, MSE(pi3): 9.771e-04\n",
      "Epoch 309500, Train loss: 1.587e+02, Test loss: 1.005e+03, MSE(e): 2.753e-06, MSE(pi1): 3.437e-03, MSE(pi2): 1.370e-06, MSE(pi3): 9.679e-04\n",
      "Epoch 309600, Train loss: 1.218e+03, Test loss: 2.520e+03, MSE(e): 1.028e-04, MSE(pi1): 9.820e-03, MSE(pi2): 4.918e-05, MSE(pi3): 9.198e-04\n",
      "Epoch 309700, Train loss: 3.017e+02, Test loss: 1.204e+03, MSE(e): 5.571e-06, MSE(pi1): 1.353e-02, MSE(pi2): 1.633e-06, MSE(pi3): 1.106e-03\n",
      "Epoch 309800, Train loss: 2.766e+02, Test loss: 1.132e+03, MSE(e): 5.150e-06, MSE(pi1): 1.337e-02, MSE(pi2): 1.860e-06, MSE(pi3): 9.143e-04\n",
      "Epoch 309900, Train loss: 5.244e+02, Test loss: 1.402e+03, MSE(e): 1.217e-05, MSE(pi1): 2.998e-02, MSE(pi2): 3.211e-06, MSE(pi3): 1.028e-03\n",
      "Epoch 310000, Train loss: 3.790e+02, Test loss: 1.295e+03, MSE(e): 8.840e-06, MSE(pi1): 1.687e-02, MSE(pi2): 3.237e-06, MSE(pi3): 1.220e-03\n",
      "Epoch 310100, Train loss: 2.759e+02, Test loss: 1.187e+03, MSE(e): 4.975e-06, MSE(pi1): 1.308e-02, MSE(pi2): 1.469e-06, MSE(pi3): 9.536e-04\n",
      "Epoch 310200, Train loss: 6.983e+02, Test loss: 1.719e+03, MSE(e): 2.081e-05, MSE(pi1): 3.802e-02, MSE(pi2): 5.697e-06, MSE(pi3): 1.100e-03\n",
      "Epoch 310300, Train loss: 2.767e+03, Test loss: 4.670e+03, MSE(e): 2.495e-04, MSE(pi1): 1.354e-02, MSE(pi2): 1.194e-04, MSE(pi3): 1.366e-03\n",
      "Epoch 310400, Train loss: 3.208e+02, Test loss: 1.115e+03, MSE(e): 8.333e-06, MSE(pi1): 1.343e-02, MSE(pi2): 2.738e-06, MSE(pi3): 1.031e-03\n",
      "Epoch 310500, Train loss: 1.917e+02, Test loss: 1.093e+03, MSE(e): 3.260e-06, MSE(pi1): 6.124e-03, MSE(pi2): 1.398e-06, MSE(pi3): 9.785e-04\n",
      "Epoch 310600, Train loss: 1.921e+02, Test loss: 1.060e+03, MSE(e): 3.120e-06, MSE(pi1): 6.633e-03, MSE(pi2): 1.349e-06, MSE(pi3): 9.458e-04\n",
      "Epoch 310700, Train loss: 2.499e+02, Test loss: 1.026e+03, MSE(e): 4.651e-06, MSE(pi1): 1.095e-02, MSE(pi2): 1.591e-06, MSE(pi3): 9.393e-04\n",
      "Epoch 310800, Train loss: 5.639e+02, Test loss: 1.306e+03, MSE(e): 3.309e-05, MSE(pi1): 1.501e-02, MSE(pi2): 1.550e-05, MSE(pi3): 8.289e-04\n",
      "Epoch 310900, Train loss: 8.811e+02, Test loss: 1.812e+03, MSE(e): 5.292e-05, MSE(pi1): 2.181e-02, MSE(pi2): 2.639e-05, MSE(pi3): 1.337e-03\n",
      "Epoch 311000, Train loss: 5.356e+02, Test loss: 1.384e+03, MSE(e): 2.382e-05, MSE(pi1): 2.086e-02, MSE(pi2): 1.083e-05, MSE(pi3): 8.879e-04\n",
      "Epoch 311100, Train loss: 4.564e+02, Test loss: 1.419e+03, MSE(e): 2.594e-05, MSE(pi1): 9.069e-03, MSE(pi2): 1.380e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 311200, Train loss: 2.253e+03, Test loss: 4.645e+03, MSE(e): 1.940e-04, MSE(pi1): 2.067e-02, MSE(pi2): 9.071e-05, MSE(pi3): 1.058e-03\n",
      "Epoch 311300, Train loss: 3.249e+02, Test loss: 1.218e+03, MSE(e): 7.163e-06, MSE(pi1): 1.425e-02, MSE(pi2): 2.047e-06, MSE(pi3): 1.108e-03\n",
      "Epoch 311400, Train loss: 1.614e+02, Test loss: 9.645e+02, MSE(e): 2.911e-06, MSE(pi1): 3.868e-03, MSE(pi2): 1.575e-06, MSE(pi3): 9.360e-04\n",
      "Epoch 311500, Train loss: 5.055e+02, Test loss: 1.636e+03, MSE(e): 9.568e-06, MSE(pi1): 2.845e-02, MSE(pi2): 2.231e-06, MSE(pi3): 1.253e-03\n",
      "Epoch 311600, Train loss: 4.178e+03, Test loss: 5.930e+03, MSE(e): 3.648e-04, MSE(pi1): 3.664e-02, MSE(pi2): 1.737e-04, MSE(pi3): 1.628e-03\n",
      "Epoch 311700, Train loss: 3.357e+02, Test loss: 1.349e+03, MSE(e): 8.924e-06, MSE(pi1): 1.364e-02, MSE(pi2): 3.693e-06, MSE(pi3): 1.101e-03\n",
      "Epoch 311800, Train loss: 1.713e+03, Test loss: 4.027e+03, MSE(e): 1.290e-04, MSE(pi1): 2.927e-02, MSE(pi2): 6.336e-05, MSE(pi3): 1.311e-03\n",
      "Epoch 311900, Train loss: 3.824e+02, Test loss: 1.371e+03, MSE(e): 1.768e-05, MSE(pi1): 1.068e-02, MSE(pi2): 7.736e-06, MSE(pi3): 9.875e-04\n",
      "Epoch 312000, Train loss: 2.984e+03, Test loss: 5.411e+03, MSE(e): 2.629e-04, MSE(pi1): 2.314e-02, MSE(pi2): 1.301e-04, MSE(pi3): 1.234e-03\n",
      "Epoch 312100, Train loss: 2.893e+02, Test loss: 1.154e+03, MSE(e): 5.323e-06, MSE(pi1): 1.252e-02, MSE(pi2): 1.519e-06, MSE(pi3): 1.109e-03\n",
      "Epoch 312200, Train loss: 2.789e+02, Test loss: 1.269e+03, MSE(e): 5.047e-06, MSE(pi1): 1.193e-02, MSE(pi2): 1.860e-06, MSE(pi3): 1.091e-03\n",
      "Epoch 312300, Train loss: 2.853e+02, Test loss: 1.426e+03, MSE(e): 1.151e-05, MSE(pi1): 7.087e-03, MSE(pi2): 4.723e-06, MSE(pi3): 9.938e-04\n",
      "Epoch 312400, Train loss: 4.881e+02, Test loss: 1.376e+03, MSE(e): 1.137e-05, MSE(pi1): 2.630e-02, MSE(pi2): 3.082e-06, MSE(pi3): 1.114e-03\n",
      "Epoch 312500, Train loss: 1.500e+02, Test loss: 9.864e+02, MSE(e): 2.108e-06, MSE(pi1): 3.477e-03, MSE(pi2): 1.117e-06, MSE(pi3): 9.412e-04\n",
      "Epoch 312600, Train loss: 2.489e+02, Test loss: 1.080e+03, MSE(e): 4.628e-06, MSE(pi1): 1.005e-02, MSE(pi2): 1.573e-06, MSE(pi3): 1.021e-03\n",
      "Epoch 312700, Train loss: 2.080e+02, Test loss: 1.147e+03, MSE(e): 4.468e-06, MSE(pi1): 7.296e-03, MSE(pi2): 1.672e-06, MSE(pi3): 9.033e-04\n",
      "Epoch 312800, Train loss: 1.740e+02, Test loss: 1.042e+03, MSE(e): 3.647e-06, MSE(pi1): 3.987e-03, MSE(pi2): 1.906e-06, MSE(pi3): 9.766e-04\n",
      "Epoch 312900, Train loss: 8.496e+02, Test loss: 2.475e+03, MSE(e): 6.870e-05, MSE(pi1): 6.143e-03, MSE(pi2): 3.195e-05, MSE(pi3): 1.011e-03\n",
      "Epoch 313000, Train loss: 4.352e+02, Test loss: 1.276e+03, MSE(e): 1.212e-05, MSE(pi1): 2.212e-02, MSE(pi2): 4.849e-06, MSE(pi3): 9.279e-04\n",
      "Epoch 313100, Train loss: 1.872e+02, Test loss: 1.001e+03, MSE(e): 2.978e-06, MSE(pi1): 5.910e-03, MSE(pi2): 1.267e-06, MSE(pi3): 9.831e-04\n",
      "Epoch 313200, Train loss: 5.026e+02, Test loss: 1.470e+03, MSE(e): 1.195e-05, MSE(pi1): 2.833e-02, MSE(pi2): 3.793e-06, MSE(pi3): 9.987e-04\n",
      "Epoch 313300, Train loss: 1.594e+02, Test loss: 1.012e+03, MSE(e): 2.417e-06, MSE(pi1): 3.765e-03, MSE(pi2): 1.238e-06, MSE(pi3): 9.753e-04\n",
      "Epoch 313400, Train loss: 2.134e+02, Test loss: 1.143e+03, MSE(e): 5.569e-06, MSE(pi1): 6.336e-03, MSE(pi2): 2.467e-06, MSE(pi3): 9.439e-04\n",
      "Epoch 313500, Train loss: 1.760e+02, Test loss: 9.571e+02, MSE(e): 3.088e-06, MSE(pi1): 4.820e-03, MSE(pi2): 1.322e-06, MSE(pi3): 9.693e-04\n",
      "Epoch 313600, Train loss: 5.210e+02, Test loss: 1.341e+03, MSE(e): 2.690e-05, MSE(pi1): 1.634e-02, MSE(pi2): 1.225e-05, MSE(pi3): 8.846e-04\n",
      "Epoch 313700, Train loss: 3.521e+02, Test loss: 1.121e+03, MSE(e): 1.950e-05, MSE(pi1): 6.934e-03, MSE(pi2): 9.365e-06, MSE(pi3): 8.782e-04\n",
      "Epoch 313800, Train loss: 1.924e+03, Test loss: 4.221e+03, MSE(e): 1.680e-04, MSE(pi1): 1.283e-02, MSE(pi2): 7.953e-05, MSE(pi3): 1.151e-03\n",
      "Epoch 313900, Train loss: 2.812e+02, Test loss: 1.277e+03, MSE(e): 1.439e-05, MSE(pi1): 3.728e-03, MSE(pi2): 7.317e-06, MSE(pi3): 1.000e-03\n",
      "Epoch 314000, Train loss: 6.335e+02, Test loss: 1.430e+03, MSE(e): 4.585e-05, MSE(pi1): 8.440e-03, MSE(pi2): 2.079e-05, MSE(pi3): 9.060e-04\n",
      "Epoch 314100, Train loss: 1.606e+02, Test loss: 1.008e+03, MSE(e): 2.523e-06, MSE(pi1): 4.195e-03, MSE(pi2): 1.272e-06, MSE(pi3): 9.346e-04\n",
      "Epoch 314200, Train loss: 2.802e+02, Test loss: 1.315e+03, MSE(e): 4.663e-06, MSE(pi1): 1.532e-02, MSE(pi2): 1.667e-06, MSE(pi3): 8.038e-04\n",
      "Epoch 314300, Train loss: 1.253e+03, Test loss: 2.289e+03, MSE(e): 5.444e-05, MSE(pi1): 6.109e-02, MSE(pi2): 1.791e-05, MSE(pi3): 9.734e-04\n",
      "Epoch 314400, Train loss: 2.382e+02, Test loss: 9.862e+02, MSE(e): 9.607e-06, MSE(pi1): 5.128e-03, MSE(pi2): 4.388e-06, MSE(pi3): 9.080e-04\n",
      "Epoch 314500, Train loss: 2.467e+02, Test loss: 1.238e+03, MSE(e): 8.457e-06, MSE(pi1): 6.790e-03, MSE(pi2): 3.731e-06, MSE(pi3): 9.419e-04\n",
      "Epoch 314600, Train loss: 4.379e+02, Test loss: 1.303e+03, MSE(e): 1.038e-05, MSE(pi1): 2.139e-02, MSE(pi2): 2.538e-06, MSE(pi3): 1.202e-03\n",
      "Epoch 314700, Train loss: 4.163e+02, Test loss: 1.207e+03, MSE(e): 2.118e-05, MSE(pi1): 1.109e-02, MSE(pi2): 9.574e-06, MSE(pi3): 9.359e-04\n",
      "Epoch 314800, Train loss: 1.207e+03, Test loss: 2.612e+03, MSE(e): 9.685e-05, MSE(pi1): 1.150e-02, MSE(pi2): 4.761e-05, MSE(pi3): 1.230e-03\n",
      "Epoch 314900, Train loss: 4.322e+02, Test loss: 1.314e+03, MSE(e): 1.196e-05, MSE(pi1): 1.913e-02, MSE(pi2): 4.846e-06, MSE(pi3): 1.212e-03\n",
      "Epoch 315000, Train loss: 2.722e+02, Test loss: 1.316e+03, MSE(e): 9.354e-06, MSE(pi1): 7.824e-03, MSE(pi2): 4.471e-06, MSE(pi3): 1.004e-03\n",
      "Epoch 315100, Train loss: 2.019e+02, Test loss: 1.224e+03, MSE(e): 4.208e-06, MSE(pi1): 7.312e-03, MSE(pi2): 1.800e-06, MSE(pi3): 8.669e-04\n",
      "Epoch 315200, Train loss: 6.983e+02, Test loss: 1.643e+03, MSE(e): 3.785e-05, MSE(pi1): 2.132e-02, MSE(pi2): 1.687e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 315300, Train loss: 2.573e+03, Test loss: 4.161e+03, MSE(e): 2.083e-04, MSE(pi1): 4.086e-02, MSE(pi2): 1.051e-04, MSE(pi3): 8.073e-04\n",
      "Epoch 315400, Train loss: 3.173e+02, Test loss: 1.234e+03, MSE(e): 7.664e-06, MSE(pi1): 1.511e-02, MSE(pi2): 3.324e-06, MSE(pi3): 8.955e-04\n",
      "Epoch 315500, Train loss: 4.270e+02, Test loss: 1.276e+03, MSE(e): 2.640e-05, MSE(pi1): 7.229e-03, MSE(pi2): 1.273e-05, MSE(pi3): 9.069e-04\n",
      "Epoch 315600, Train loss: 2.911e+02, Test loss: 1.206e+03, MSE(e): 5.495e-06, MSE(pi1): 1.259e-02, MSE(pi2): 1.615e-06, MSE(pi3): 1.103e-03\n",
      "Epoch 315700, Train loss: 2.869e+02, Test loss: 1.232e+03, MSE(e): 4.824e-06, MSE(pi1): 1.478e-02, MSE(pi2): 1.449e-06, MSE(pi3): 9.078e-04\n",
      "Epoch 315800, Train loss: 3.022e+02, Test loss: 1.188e+03, MSE(e): 5.693e-06, MSE(pi1): 1.518e-02, MSE(pi2): 1.718e-06, MSE(pi3): 9.351e-04\n",
      "Epoch 315900, Train loss: 3.466e+02, Test loss: 1.375e+03, MSE(e): 1.128e-05, MSE(pi1): 1.442e-02, MSE(pi2): 4.504e-06, MSE(pi3): 8.951e-04\n",
      "Epoch 316000, Train loss: 2.233e+02, Test loss: 1.068e+03, MSE(e): 3.601e-06, MSE(pi1): 8.214e-03, MSE(pi2): 1.329e-06, MSE(pi3): 1.051e-03\n",
      "Epoch 316100, Train loss: 2.662e+02, Test loss: 1.156e+03, MSE(e): 9.055e-06, MSE(pi1): 7.034e-03, MSE(pi2): 4.056e-06, MSE(pi3): 1.053e-03\n",
      "Epoch 316200, Train loss: 1.701e+02, Test loss: 1.023e+03, MSE(e): 2.932e-06, MSE(pi1): 5.099e-03, MSE(pi2): 1.496e-06, MSE(pi3): 8.979e-04\n",
      "Epoch 316300, Train loss: 5.953e+02, Test loss: 1.760e+03, MSE(e): 3.712e-05, MSE(pi1): 1.260e-02, MSE(pi2): 1.727e-05, MSE(pi3): 9.812e-04\n",
      "Epoch 316400, Train loss: 1.273e+03, Test loss: 2.226e+03, MSE(e): 8.860e-05, MSE(pi1): 2.995e-02, MSE(pi2): 4.409e-05, MSE(pi3): 8.757e-04\n",
      "Epoch 316500, Train loss: 4.591e+02, Test loss: 1.542e+03, MSE(e): 1.668e-05, MSE(pi1): 1.834e-02, MSE(pi2): 7.466e-06, MSE(pi3): 1.089e-03\n",
      "Epoch 316600, Train loss: 1.870e+02, Test loss: 9.737e+02, MSE(e): 3.779e-06, MSE(pi1): 5.955e-03, MSE(pi2): 1.786e-06, MSE(pi3): 8.962e-04\n",
      "Epoch 316700, Train loss: 1.897e+02, Test loss: 1.011e+03, MSE(e): 2.954e-06, MSE(pi1): 5.579e-03, MSE(pi2): 1.252e-06, MSE(pi3): 1.044e-03\n",
      "Epoch 316800, Train loss: 1.943e+02, Test loss: 9.732e+02, MSE(e): 3.931e-06, MSE(pi1): 6.744e-03, MSE(pi2): 1.741e-06, MSE(pi3): 8.757e-04\n",
      "Epoch 316900, Train loss: 1.510e+02, Test loss: 1.006e+03, MSE(e): 2.038e-06, MSE(pi1): 3.431e-03, MSE(pi2): 1.083e-06, MSE(pi3): 9.629e-04\n",
      "Epoch 317000, Train loss: 3.268e+02, Test loss: 1.197e+03, MSE(e): 6.157e-06, MSE(pi1): 1.804e-02, MSE(pi2): 1.608e-06, MSE(pi3): 8.483e-04\n",
      "Epoch 317100, Train loss: 6.581e+02, Test loss: 1.595e+03, MSE(e): 4.722e-05, MSE(pi1): 8.620e-03, MSE(pi2): 2.226e-05, MSE(pi3): 9.964e-04\n",
      "Epoch 317200, Train loss: 1.751e+02, Test loss: 1.026e+03, MSE(e): 2.574e-06, MSE(pi1): 5.945e-03, MSE(pi2): 1.076e-06, MSE(pi3): 8.994e-04\n",
      "Epoch 317300, Train loss: 2.178e+02, Test loss: 1.076e+03, MSE(e): 3.415e-06, MSE(pi1): 9.140e-03, MSE(pi2): 1.209e-06, MSE(pi3): 9.223e-04\n",
      "Epoch 317400, Train loss: 3.824e+02, Test loss: 1.137e+03, MSE(e): 2.081e-05, MSE(pi1): 8.759e-03, MSE(pi2): 9.978e-06, MSE(pi3): 8.666e-04\n",
      "Epoch 317500, Train loss: 5.185e+02, Test loss: 1.633e+03, MSE(e): 1.709e-05, MSE(pi1): 2.623e-02, MSE(pi2): 7.247e-06, MSE(pi3): 8.524e-04\n",
      "Epoch 317600, Train loss: 1.751e+02, Test loss: 1.074e+03, MSE(e): 4.343e-06, MSE(pi1): 3.675e-03, MSE(pi2): 2.163e-06, MSE(pi3): 9.492e-04\n",
      "Epoch 317700, Train loss: 5.062e+02, Test loss: 1.562e+03, MSE(e): 3.201e-05, MSE(pi1): 9.132e-03, MSE(pi2): 1.408e-05, MSE(pi3): 9.469e-04\n",
      "Epoch 317800, Train loss: 2.213e+03, Test loss: 2.124e+03, MSE(e): 1.995e-04, MSE(pi1): 1.366e-02, MSE(pi2): 9.721e-05, MSE(pi3): 8.074e-04\n",
      "Epoch 317900, Train loss: 3.411e+02, Test loss: 1.281e+03, MSE(e): 7.593e-06, MSE(pi1): 1.767e-02, MSE(pi2): 2.269e-06, MSE(pi3): 8.850e-04\n",
      "Epoch 318000, Train loss: 9.638e+02, Test loss: 2.370e+03, MSE(e): 6.949e-05, MSE(pi1): 1.768e-02, MSE(pi2): 3.045e-05, MSE(pi3): 9.207e-04\n",
      "Epoch 318100, Train loss: 4.670e+02, Test loss: 1.320e+03, MSE(e): 1.728e-05, MSE(pi1): 1.879e-02, MSE(pi2): 7.159e-06, MSE(pi3): 1.062e-03\n",
      "Epoch 318200, Train loss: 1.653e+02, Test loss: 9.673e+02, MSE(e): 2.983e-06, MSE(pi1): 4.024e-03, MSE(pi2): 1.557e-06, MSE(pi3): 9.524e-04\n",
      "Epoch 318300, Train loss: 2.926e+02, Test loss: 1.191e+03, MSE(e): 6.422e-06, MSE(pi1): 1.162e-02, MSE(pi2): 1.974e-06, MSE(pi3): 1.122e-03\n",
      "Epoch 318400, Train loss: 2.331e+02, Test loss: 1.213e+03, MSE(e): 5.433e-06, MSE(pi1): 8.707e-03, MSE(pi2): 2.216e-06, MSE(pi3): 9.171e-04\n",
      "Epoch 318500, Train loss: 2.608e+02, Test loss: 1.192e+03, MSE(e): 9.636e-06, MSE(pi1): 7.178e-03, MSE(pi2): 3.815e-06, MSE(pi3): 9.265e-04\n",
      "Epoch 318600, Train loss: 3.961e+02, Test loss: 1.443e+03, MSE(e): 8.000e-06, MSE(pi1): 2.388e-02, MSE(pi2): 1.932e-06, MSE(pi3): 7.732e-04\n",
      "Epoch 318700, Train loss: 5.325e+02, Test loss: 1.455e+03, MSE(e): 2.539e-05, MSE(pi1): 1.770e-02, MSE(pi2): 1.091e-05, MSE(pi3): 1.016e-03\n",
      "Epoch 318800, Train loss: 1.968e+03, Test loss: 3.783e+03, MSE(e): 1.682e-04, MSE(pi1): 1.607e-02, MSE(pi2): 7.982e-05, MSE(pi3): 1.252e-03\n",
      "Epoch 318900, Train loss: 8.389e+02, Test loss: 1.780e+03, MSE(e): 5.662e-05, MSE(pi1): 1.338e-02, MSE(pi2): 2.287e-05, MSE(pi3): 1.389e-03\n",
      "Epoch 319000, Train loss: 1.635e+02, Test loss: 9.731e+02, MSE(e): 3.330e-06, MSE(pi1): 3.848e-03, MSE(pi2): 1.659e-06, MSE(pi3): 9.177e-04\n",
      "Epoch 319100, Train loss: 2.546e+02, Test loss: 1.060e+03, MSE(e): 6.784e-06, MSE(pi1): 8.427e-03, MSE(pi2): 2.565e-06, MSE(pi3): 1.025e-03\n",
      "Epoch 319200, Train loss: 3.565e+02, Test loss: 1.369e+03, MSE(e): 1.490e-05, MSE(pi1): 9.838e-03, MSE(pi2): 7.275e-06, MSE(pi3): 1.092e-03\n",
      "Epoch 319300, Train loss: 2.134e+03, Test loss: 4.109e+03, MSE(e): 1.911e-04, MSE(pi1): 1.163e-02, MSE(pi2): 9.376e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 319400, Train loss: 3.862e+02, Test loss: 1.244e+03, MSE(e): 8.805e-06, MSE(pi1): 2.035e-02, MSE(pi2): 2.372e-06, MSE(pi3): 9.459e-04\n",
      "Epoch 319500, Train loss: 2.770e+02, Test loss: 1.123e+03, MSE(e): 9.796e-06, MSE(pi1): 7.909e-03, MSE(pi2): 3.977e-06, MSE(pi3): 9.998e-04\n",
      "Epoch 319600, Train loss: 1.553e+02, Test loss: 1.016e+03, MSE(e): 2.473e-06, MSE(pi1): 3.500e-03, MSE(pi2): 1.264e-06, MSE(pi3): 9.558e-04\n",
      "Epoch 319700, Train loss: 3.956e+02, Test loss: 1.213e+03, MSE(e): 8.503e-06, MSE(pi1): 2.254e-02, MSE(pi2): 2.713e-06, MSE(pi3): 8.513e-04\n",
      "Epoch 319800, Train loss: 1.787e+02, Test loss: 9.895e+02, MSE(e): 3.306e-06, MSE(pi1): 4.835e-03, MSE(pi2): 1.468e-06, MSE(pi3): 9.725e-04\n",
      "Epoch 319900, Train loss: 3.323e+02, Test loss: 1.174e+03, MSE(e): 1.641e-05, MSE(pi1): 6.122e-03, MSE(pi2): 7.251e-06, MSE(pi3): 1.070e-03\n",
      "Epoch 320000, Train loss: 1.735e+02, Test loss: 1.047e+03, MSE(e): 2.608e-06, MSE(pi1): 5.803e-03, MSE(pi2): 1.174e-06, MSE(pi3): 8.942e-04\n",
      "Epoch 320100, Train loss: 3.397e+02, Test loss: 1.191e+03, MSE(e): 6.126e-06, MSE(pi1): 1.914e-02, MSE(pi2): 1.868e-06, MSE(pi3): 8.704e-04\n",
      "Epoch 320200, Train loss: 2.355e+02, Test loss: 1.122e+03, MSE(e): 4.841e-06, MSE(pi1): 8.730e-03, MSE(pi2): 1.953e-06, MSE(pi3): 9.975e-04\n",
      "Epoch 320300, Train loss: 8.755e+02, Test loss: 1.697e+03, MSE(e): 7.018e-05, MSE(pi1): 7.766e-03, MSE(pi2): 3.577e-05, MSE(pi3): 9.597e-04\n",
      "Epoch 320400, Train loss: 4.205e+02, Test loss: 1.191e+03, MSE(e): 2.603e-05, MSE(pi1): 6.083e-03, MSE(pi2): 1.085e-05, MSE(pi3): 9.937e-04\n",
      "Epoch 320500, Train loss: 2.887e+02, Test loss: 1.122e+03, MSE(e): 6.946e-06, MSE(pi1): 1.251e-02, MSE(pi2): 2.888e-06, MSE(pi3): 9.419e-04\n",
      "Epoch 320600, Train loss: 2.980e+02, Test loss: 1.220e+03, MSE(e): 5.641e-06, MSE(pi1): 1.445e-02, MSE(pi2): 1.777e-06, MSE(pi3): 9.714e-04\n",
      "Epoch 320700, Train loss: 2.704e+02, Test loss: 1.099e+03, MSE(e): 6.746e-06, MSE(pi1): 1.106e-02, MSE(pi2): 2.481e-06, MSE(pi3): 9.229e-04\n",
      "Epoch 320800, Train loss: 9.493e+02, Test loss: 2.449e+03, MSE(e): 7.228e-05, MSE(pi1): 1.184e-02, MSE(pi2): 3.504e-05, MSE(pi3): 1.080e-03\n",
      "Epoch 320900, Train loss: 2.861e+03, Test loss: 2.961e+03, MSE(e): 2.398e-04, MSE(pi1): 3.822e-02, MSE(pi2): 1.129e-04, MSE(pi3): 8.057e-04\n",
      "Epoch 321000, Train loss: 2.605e+02, Test loss: 9.976e+02, MSE(e): 5.658e-06, MSE(pi1): 9.708e-03, MSE(pi2): 1.907e-06, MSE(pi3): 1.068e-03\n",
      "Epoch 321100, Train loss: 3.049e+02, Test loss: 1.189e+03, MSE(e): 6.892e-06, MSE(pi1): 1.404e-02, MSE(pi2): 2.112e-06, MSE(pi3): 9.553e-04\n",
      "Epoch 321200, Train loss: 2.545e+02, Test loss: 1.141e+03, MSE(e): 5.480e-06, MSE(pi1): 1.166e-02, MSE(pi2): 2.409e-06, MSE(pi3): 8.306e-04\n",
      "Epoch 321300, Train loss: 4.849e+02, Test loss: 1.308e+03, MSE(e): 2.581e-05, MSE(pi1): 1.436e-02, MSE(pi2): 1.210e-05, MSE(pi3): 8.317e-04\n",
      "Epoch 321400, Train loss: 4.010e+02, Test loss: 1.257e+03, MSE(e): 1.018e-05, MSE(pi1): 2.056e-02, MSE(pi2): 2.605e-06, MSE(pi3): 9.360e-04\n",
      "Epoch 321500, Train loss: 6.001e+02, Test loss: 1.481e+03, MSE(e): 4.225e-05, MSE(pi1): 8.547e-03, MSE(pi2): 2.052e-05, MSE(pi3): 9.209e-04\n",
      "Epoch 321600, Train loss: 3.814e+02, Test loss: 1.368e+03, MSE(e): 1.327e-05, MSE(pi1): 1.601e-02, MSE(pi2): 4.500e-06, MSE(pi3): 8.857e-04\n",
      "Epoch 321700, Train loss: 1.615e+02, Test loss: 1.036e+03, MSE(e): 2.345e-06, MSE(pi1): 4.589e-03, MSE(pi2): 1.073e-06, MSE(pi3): 9.220e-04\n",
      "Epoch 321800, Train loss: 3.814e+02, Test loss: 1.201e+03, MSE(e): 7.257e-06, MSE(pi1): 1.881e-02, MSE(pi2): 1.835e-06, MSE(pi3): 1.208e-03\n",
      "Epoch 321900, Train loss: 2.227e+02, Test loss: 1.056e+03, MSE(e): 5.053e-06, MSE(pi1): 8.036e-03, MSE(pi2): 2.064e-06, MSE(pi3): 9.178e-04\n",
      "Epoch 322000, Train loss: 1.221e+03, Test loss: 2.870e+03, MSE(e): 9.119e-05, MSE(pi1): 2.147e-02, MSE(pi2): 4.116e-05, MSE(pi3): 9.440e-04\n",
      "Epoch 322100, Train loss: 3.853e+02, Test loss: 1.128e+03, MSE(e): 1.442e-05, MSE(pi1): 1.297e-02, MSE(pi2): 5.646e-06, MSE(pi3): 1.115e-03\n",
      "Epoch 322200, Train loss: 4.206e+02, Test loss: 1.359e+03, MSE(e): 2.745e-05, MSE(pi1): 4.575e-03, MSE(pi2): 1.262e-05, MSE(pi3): 1.004e-03\n",
      "Epoch 322300, Train loss: 2.524e+02, Test loss: 1.046e+03, MSE(e): 5.328e-06, MSE(pi1): 9.235e-03, MSE(pi2): 1.749e-06, MSE(pi3): 1.068e-03\n",
      "Epoch 322400, Train loss: 1.228e+03, Test loss: 2.090e+03, MSE(e): 8.728e-05, MSE(pi1): 2.679e-02, MSE(pi2): 4.456e-05, MSE(pi3): 8.685e-04\n",
      "Epoch 322500, Train loss: 1.737e+02, Test loss: 1.050e+03, MSE(e): 2.404e-06, MSE(pi1): 5.909e-03, MSE(pi2): 1.100e-06, MSE(pi3): 9.059e-04\n",
      "Epoch 322600, Train loss: 2.981e+02, Test loss: 1.150e+03, MSE(e): 5.843e-06, MSE(pi1): 1.496e-02, MSE(pi2): 2.066e-06, MSE(pi3): 9.008e-04\n",
      "Epoch 322700, Train loss: 2.400e+02, Test loss: 1.080e+03, MSE(e): 4.231e-06, MSE(pi1): 1.028e-02, MSE(pi2): 1.286e-06, MSE(pi3): 9.489e-04\n",
      "Epoch 322800, Train loss: 4.192e+02, Test loss: 1.467e+03, MSE(e): 1.768e-05, MSE(pi1): 1.422e-02, MSE(pi2): 7.785e-06, MSE(pi3): 1.002e-03\n",
      "Epoch 322900, Train loss: 4.474e+02, Test loss: 1.895e+03, MSE(e): 1.388e-05, MSE(pi1): 1.988e-02, MSE(pi2): 6.185e-06, MSE(pi3): 1.098e-03\n",
      "Epoch 323000, Train loss: 3.117e+02, Test loss: 1.083e+03, MSE(e): 1.407e-05, MSE(pi1): 8.527e-03, MSE(pi2): 6.715e-06, MSE(pi3): 8.566e-04\n",
      "Epoch 323100, Train loss: 2.449e+02, Test loss: 1.062e+03, MSE(e): 4.524e-06, MSE(pi1): 1.125e-02, MSE(pi2): 1.395e-06, MSE(pi3): 8.721e-04\n",
      "Epoch 323200, Train loss: 3.412e+02, Test loss: 1.091e+03, MSE(e): 1.499e-05, MSE(pi1): 9.931e-03, MSE(pi2): 8.376e-06, MSE(pi3): 9.199e-04\n",
      "Epoch 323300, Train loss: 2.134e+02, Test loss: 9.984e+02, MSE(e): 3.852e-06, MSE(pi1): 7.669e-03, MSE(pi2): 1.287e-06, MSE(pi3): 9.822e-04\n",
      "Epoch 323400, Train loss: 2.088e+02, Test loss: 1.164e+03, MSE(e): 6.620e-06, MSE(pi1): 4.948e-03, MSE(pi2): 3.033e-06, MSE(pi3): 9.316e-04\n",
      "Epoch 323500, Train loss: 4.627e+02, Test loss: 1.416e+03, MSE(e): 9.482e-06, MSE(pi1): 2.430e-02, MSE(pi2): 2.343e-06, MSE(pi3): 1.249e-03\n",
      "Epoch 323600, Train loss: 1.893e+02, Test loss: 9.677e+02, MSE(e): 5.774e-06, MSE(pi1): 3.548e-03, MSE(pi2): 2.871e-06, MSE(pi3): 9.604e-04\n",
      "Epoch 323700, Train loss: 3.550e+02, Test loss: 1.221e+03, MSE(e): 1.397e-05, MSE(pi1): 1.053e-02, MSE(pi2): 5.036e-06, MSE(pi3): 1.099e-03\n",
      "Epoch 323800, Train loss: 3.130e+03, Test loss: 5.334e+03, MSE(e): 2.589e-04, MSE(pi1): 3.948e-02, MSE(pi2): 1.234e-04, MSE(pi3): 1.464e-03\n",
      "Epoch 323900, Train loss: 3.007e+02, Test loss: 1.206e+03, MSE(e): 6.130e-06, MSE(pi1): 1.496e-02, MSE(pi2): 1.666e-06, MSE(pi3): 8.984e-04\n",
      "Epoch 324000, Train loss: 1.089e+03, Test loss: 2.823e+03, MSE(e): 6.917e-05, MSE(pi1): 2.735e-02, MSE(pi2): 3.250e-05, MSE(pi3): 1.236e-03\n",
      "Epoch 324100, Train loss: 4.200e+02, Test loss: 1.574e+03, MSE(e): 9.129e-06, MSE(pi1): 2.519e-02, MSE(pi2): 3.170e-06, MSE(pi3): 7.679e-04\n",
      "Epoch 324200, Train loss: 2.598e+02, Test loss: 1.185e+03, MSE(e): 5.444e-06, MSE(pi1): 1.108e-02, MSE(pi2): 1.881e-06, MSE(pi3): 9.455e-04\n",
      "Epoch 324300, Train loss: 1.580e+02, Test loss: 9.736e+02, MSE(e): 2.185e-06, MSE(pi1): 4.283e-03, MSE(pi2): 1.045e-06, MSE(pi3): 9.329e-04\n",
      "Epoch 324400, Train loss: 1.893e+02, Test loss: 1.029e+03, MSE(e): 3.048e-06, MSE(pi1): 6.577e-03, MSE(pi2): 1.209e-06, MSE(pi3): 9.305e-04\n",
      "Epoch 324500, Train loss: 3.922e+02, Test loss: 1.250e+03, MSE(e): 9.910e-06, MSE(pi1): 1.782e-02, MSE(pi2): 2.677e-06, MSE(pi3): 1.148e-03\n",
      "Epoch 324600, Train loss: 4.310e+02, Test loss: 1.165e+03, MSE(e): 2.242e-05, MSE(pi1): 1.169e-02, MSE(pi2): 1.165e-05, MSE(pi3): 8.995e-04\n",
      "Epoch 324700, Train loss: 3.348e+02, Test loss: 1.238e+03, MSE(e): 7.017e-06, MSE(pi1): 1.528e-02, MSE(pi2): 1.882e-06, MSE(pi3): 1.118e-03\n",
      "Epoch 324800, Train loss: 2.030e+02, Test loss: 1.136e+03, MSE(e): 3.125e-06, MSE(pi1): 7.616e-03, MSE(pi2): 1.263e-06, MSE(pi3): 9.556e-04\n",
      "Epoch 324900, Train loss: 2.580e+02, Test loss: 1.127e+03, MSE(e): 5.423e-06, MSE(pi1): 1.026e-02, MSE(pi2): 2.023e-06, MSE(pi3): 1.011e-03\n",
      "Epoch 325000, Train loss: 2.410e+02, Test loss: 1.103e+03, MSE(e): 3.852e-06, MSE(pi1): 1.150e-02, MSE(pi2): 1.399e-06, MSE(pi3): 8.751e-04\n",
      "Epoch 325100, Train loss: 6.456e+02, Test loss: 1.928e+03, MSE(e): 2.811e-05, MSE(pi1): 2.504e-02, MSE(pi2): 1.528e-05, MSE(pi3): 1.141e-03\n",
      "Epoch 325200, Train loss: 1.788e+03, Test loss: 2.209e+03, MSE(e): 1.525e-04, MSE(pi1): 1.736e-02, MSE(pi2): 7.465e-05, MSE(pi3): 8.903e-04\n",
      "Epoch 325300, Train loss: 1.006e+03, Test loss: 1.216e+03, MSE(e): 8.602e-05, MSE(pi1): 5.582e-03, MSE(pi2): 4.035e-05, MSE(pi3): 8.975e-04\n",
      "Epoch 325400, Train loss: 4.671e+02, Test loss: 1.195e+03, MSE(e): 2.673e-05, MSE(pi1): 1.160e-02, MSE(pi2): 1.315e-05, MSE(pi3): 8.375e-04\n",
      "Epoch 325500, Train loss: 2.290e+02, Test loss: 1.122e+03, MSE(e): 3.669e-06, MSE(pi1): 1.043e-02, MSE(pi2): 1.188e-06, MSE(pi3): 8.799e-04\n",
      "Epoch 325600, Train loss: 3.188e+02, Test loss: 1.177e+03, MSE(e): 9.234e-06, MSE(pi1): 1.275e-02, MSE(pi2): 3.408e-06, MSE(pi3): 9.895e-04\n",
      "Epoch 325700, Train loss: 4.688e+02, Test loss: 1.346e+03, MSE(e): 2.349e-05, MSE(pi1): 1.292e-02, MSE(pi2): 9.264e-06, MSE(pi3): 1.048e-03\n",
      "Epoch 325800, Train loss: 1.370e+03, Test loss: 2.028e+03, MSE(e): 1.097e-04, MSE(pi1): 1.660e-02, MSE(pi2): 5.143e-05, MSE(pi3): 1.073e-03\n",
      "Epoch 325900, Train loss: 5.336e+02, Test loss: 1.203e+03, MSE(e): 3.774e-05, MSE(pi1): 6.752e-03, MSE(pi2): 1.904e-05, MSE(pi3): 8.867e-04\n",
      "Epoch 326000, Train loss: 7.840e+02, Test loss: 1.861e+03, MSE(e): 5.169e-05, MSE(pi1): 1.812e-02, MSE(pi2): 2.415e-05, MSE(pi3): 8.590e-04\n",
      "Epoch 326100, Train loss: 2.550e+02, Test loss: 1.075e+03, MSE(e): 4.701e-06, MSE(pi1): 1.068e-02, MSE(pi2): 1.490e-06, MSE(pi3): 1.012e-03\n",
      "Epoch 326200, Train loss: 8.669e+02, Test loss: 2.064e+03, MSE(e): 6.192e-05, MSE(pi1): 1.474e-02, MSE(pi2): 2.869e-05, MSE(pi3): 1.003e-03\n",
      "Epoch 326300, Train loss: 1.856e+02, Test loss: 1.073e+03, MSE(e): 2.774e-06, MSE(pi1): 6.775e-03, MSE(pi2): 1.171e-06, MSE(pi3): 9.009e-04\n",
      "Epoch 326400, Train loss: 1.834e+03, Test loss: 2.795e+03, MSE(e): 1.635e-04, MSE(pi1): 1.013e-02, MSE(pi2): 7.970e-05, MSE(pi3): 9.782e-04\n",
      "Epoch 326500, Train loss: 3.884e+02, Test loss: 1.299e+03, MSE(e): 1.066e-05, MSE(pi1): 1.916e-02, MSE(pi2): 2.915e-06, MSE(pi3): 9.020e-04\n",
      "Epoch 326600, Train loss: 2.649e+02, Test loss: 1.123e+03, MSE(e): 7.037e-06, MSE(pi1): 9.409e-03, MSE(pi2): 3.239e-06, MSE(pi3): 1.004e-03\n",
      "Epoch 326700, Train loss: 2.253e+02, Test loss: 1.150e+03, MSE(e): 7.743e-06, MSE(pi1): 4.980e-03, MSE(pi2): 3.340e-06, MSE(pi3): 9.805e-04\n",
      "Epoch 326800, Train loss: 4.232e+02, Test loss: 1.504e+03, MSE(e): 1.476e-05, MSE(pi1): 1.824e-02, MSE(pi2): 5.334e-06, MSE(pi3): 9.311e-04\n",
      "Epoch 326900, Train loss: 4.614e+02, Test loss: 1.633e+03, MSE(e): 2.351e-05, MSE(pi1): 1.194e-02, MSE(pi2): 1.111e-05, MSE(pi3): 1.069e-03\n",
      "Epoch 327000, Train loss: 2.092e+02, Test loss: 1.022e+03, MSE(e): 4.061e-06, MSE(pi1): 7.566e-03, MSE(pi2): 1.490e-06, MSE(pi3): 9.292e-04\n",
      "Epoch 327100, Train loss: 2.714e+02, Test loss: 1.201e+03, MSE(e): 7.342e-06, MSE(pi1): 1.113e-02, MSE(pi2): 1.946e-06, MSE(pi3): 8.662e-04\n",
      "Epoch 327200, Train loss: 7.533e+02, Test loss: 1.729e+03, MSE(e): 4.382e-05, MSE(pi1): 2.103e-02, MSE(pi2): 1.888e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 327300, Train loss: 1.486e+03, Test loss: 2.066e+03, MSE(e): 1.233e-04, MSE(pi1): 1.659e-02, MSE(pi2): 5.668e-05, MSE(pi3): 8.702e-04\n",
      "Epoch 327400, Train loss: 2.531e+02, Test loss: 1.193e+03, MSE(e): 7.963e-06, MSE(pi1): 7.552e-03, MSE(pi2): 3.596e-06, MSE(pi3): 9.797e-04\n",
      "Epoch 327500, Train loss: 6.164e+02, Test loss: 1.397e+03, MSE(e): 4.251e-05, MSE(pi1): 1.068e-02, MSE(pi2): 2.031e-05, MSE(pi3): 8.445e-04\n",
      "Epoch 327600, Train loss: 2.873e+02, Test loss: 1.235e+03, MSE(e): 8.736e-06, MSE(pi1): 1.083e-02, MSE(pi2): 3.460e-06, MSE(pi3): 9.164e-04\n",
      "Epoch 327700, Train loss: 4.233e+02, Test loss: 1.469e+03, MSE(e): 8.101e-06, MSE(pi1): 2.374e-02, MSE(pi2): 2.023e-06, MSE(pi3): 1.049e-03\n",
      "Epoch 327800, Train loss: 4.282e+02, Test loss: 1.323e+03, MSE(e): 1.501e-05, MSE(pi1): 1.981e-02, MSE(pi2): 6.025e-06, MSE(pi3): 7.998e-04\n",
      "Epoch 327900, Train loss: 2.048e+02, Test loss: 1.372e+03, MSE(e): 3.516e-06, MSE(pi1): 6.520e-03, MSE(pi2): 1.165e-06, MSE(pi3): 1.045e-03\n",
      "Epoch 328000, Train loss: 2.761e+02, Test loss: 1.226e+03, MSE(e): 5.125e-06, MSE(pi1): 1.200e-02, MSE(pi2): 1.625e-06, MSE(pi3): 1.049e-03\n",
      "Epoch 328100, Train loss: 2.270e+02, Test loss: 1.122e+03, MSE(e): 3.668e-06, MSE(pi1): 9.545e-03, MSE(pi2): 1.361e-06, MSE(pi3): 9.488e-04\n",
      "Epoch 328200, Train loss: 2.919e+02, Test loss: 1.055e+03, MSE(e): 1.235e-05, MSE(pi1): 7.728e-03, MSE(pi2): 6.144e-06, MSE(pi3): 9.115e-04\n",
      "Epoch 328300, Train loss: 1.658e+02, Test loss: 9.929e+02, MSE(e): 2.409e-06, MSE(pi1): 5.207e-03, MSE(pi2): 1.023e-06, MSE(pi3): 8.962e-04\n",
      "Epoch 328400, Train loss: 3.245e+02, Test loss: 1.399e+03, MSE(e): 1.802e-05, MSE(pi1): 4.732e-03, MSE(pi2): 8.724e-06, MSE(pi3): 9.701e-04\n",
      "Epoch 328500, Train loss: 4.284e+02, Test loss: 1.318e+03, MSE(e): 9.552e-06, MSE(pi1): 2.465e-02, MSE(pi2): 2.137e-06, MSE(pi3): 8.636e-04\n",
      "Epoch 328600, Train loss: 2.399e+03, Test loss: 3.235e+03, MSE(e): 2.211e-04, MSE(pi1): 7.785e-03, MSE(pi2): 9.919e-05, MSE(pi3): 1.093e-03\n",
      "Epoch 328700, Train loss: 2.382e+02, Test loss: 1.213e+03, MSE(e): 7.719e-06, MSE(pi1): 6.045e-03, MSE(pi2): 3.454e-06, MSE(pi3): 1.006e-03\n",
      "Epoch 328800, Train loss: 4.926e+02, Test loss: 1.299e+03, MSE(e): 1.161e-05, MSE(pi1): 2.478e-02, MSE(pi2): 2.907e-06, MSE(pi3): 1.287e-03\n",
      "Epoch 328900, Train loss: 3.243e+02, Test loss: 1.241e+03, MSE(e): 5.837e-06, MSE(pi1): 1.490e-02, MSE(pi2): 1.895e-06, MSE(pi3): 1.169e-03\n",
      "Epoch 329000, Train loss: 4.065e+03, Test loss: 5.761e+03, MSE(e): 3.458e-04, MSE(pi1): 4.212e-02, MSE(pi2): 1.646e-04, MSE(pi3): 1.864e-03\n",
      "Epoch 329100, Train loss: 2.215e+02, Test loss: 1.023e+03, MSE(e): 3.801e-06, MSE(pi1): 8.743e-03, MSE(pi2): 1.413e-06, MSE(pi3): 9.609e-04\n",
      "Epoch 329200, Train loss: 1.512e+02, Test loss: 9.612e+02, MSE(e): 2.044e-06, MSE(pi1): 3.899e-03, MSE(pi2): 1.099e-06, MSE(pi3): 9.176e-04\n",
      "Epoch 329300, Train loss: 2.289e+02, Test loss: 1.065e+03, MSE(e): 4.643e-06, MSE(pi1): 9.495e-03, MSE(pi2): 1.681e-06, MSE(pi3): 8.749e-04\n",
      "Epoch 329400, Train loss: 3.965e+02, Test loss: 1.085e+03, MSE(e): 8.923e-06, MSE(pi1): 1.904e-02, MSE(pi2): 2.496e-06, MSE(pi3): 1.169e-03\n",
      "Epoch 329500, Train loss: 5.775e+02, Test loss: 1.435e+03, MSE(e): 2.682e-05, MSE(pi1): 2.178e-02, MSE(pi2): 1.125e-05, MSE(pi3): 9.148e-04\n",
      "Epoch 329600, Train loss: 4.248e+02, Test loss: 1.305e+03, MSE(e): 2.663e-05, MSE(pi1): 6.010e-03, MSE(pi2): 1.169e-05, MSE(pi3): 9.838e-04\n",
      "Epoch 329700, Train loss: 3.270e+02, Test loss: 1.077e+03, MSE(e): 1.775e-05, MSE(pi1): 5.570e-03, MSE(pi2): 8.259e-06, MSE(pi3): 9.383e-04\n",
      "Epoch 329800, Train loss: 5.371e+02, Test loss: 1.333e+03, MSE(e): 1.957e-05, MSE(pi1): 2.426e-02, MSE(pi2): 7.629e-06, MSE(pi3): 9.881e-04\n",
      "Epoch 329900, Train loss: 3.011e+02, Test loss: 1.167e+03, MSE(e): 8.715e-06, MSE(pi1): 1.092e-02, MSE(pi2): 3.086e-06, MSE(pi3): 1.047e-03\n",
      "Epoch 330000, Train loss: 2.710e+02, Test loss: 1.226e+03, MSE(e): 6.452e-06, MSE(pi1): 1.078e-02, MSE(pi2): 2.498e-06, MSE(pi3): 9.865e-04\n",
      "Epoch 330100, Train loss: 2.224e+02, Test loss: 1.122e+03, MSE(e): 3.552e-06, MSE(pi1): 8.958e-03, MSE(pi2): 1.280e-06, MSE(pi3): 9.728e-04\n",
      "Epoch 330200, Train loss: 1.921e+02, Test loss: 1.077e+03, MSE(e): 5.103e-06, MSE(pi1): 4.637e-03, MSE(pi2): 2.274e-06, MSE(pi3): 9.475e-04\n",
      "Epoch 330300, Train loss: 1.538e+02, Test loss: 9.541e+02, MSE(e): 2.566e-06, MSE(pi1): 3.200e-03, MSE(pi2): 1.320e-06, MSE(pi3): 9.615e-04\n",
      "Epoch 330400, Train loss: 2.133e+02, Test loss: 1.002e+03, MSE(e): 4.179e-06, MSE(pi1): 7.201e-03, MSE(pi2): 1.646e-06, MSE(pi3): 9.947e-04\n",
      "Epoch 330500, Train loss: 3.046e+02, Test loss: 1.190e+03, MSE(e): 6.777e-06, MSE(pi1): 1.334e-02, MSE(pi2): 2.226e-06, MSE(pi3): 1.034e-03\n",
      "Epoch 330600, Train loss: 3.453e+02, Test loss: 1.484e+03, MSE(e): 1.093e-05, MSE(pi1): 1.397e-02, MSE(pi2): 3.949e-06, MSE(pi3): 9.625e-04\n",
      "Epoch 330700, Train loss: 1.518e+03, Test loss: 2.651e+03, MSE(e): 1.295e-04, MSE(pi1): 1.035e-02, MSE(pi2): 6.267e-05, MSE(pi3): 1.194e-03\n",
      "Epoch 330800, Train loss: 2.476e+02, Test loss: 1.153e+03, MSE(e): 1.043e-05, MSE(pi1): 4.960e-03, MSE(pi2): 5.127e-06, MSE(pi3): 9.372e-04\n",
      "Epoch 330900, Train loss: 2.083e+03, Test loss: 2.124e+03, MSE(e): 1.879e-04, MSE(pi1): 1.250e-02, MSE(pi2): 8.887e-05, MSE(pi3): 7.924e-04\n",
      "Epoch 331000, Train loss: 7.140e+02, Test loss: 2.130e+03, MSE(e): 4.641e-05, MSE(pi1): 1.391e-02, MSE(pi2): 2.049e-05, MSE(pi3): 1.107e-03\n",
      "Epoch 331100, Train loss: 2.857e+02, Test loss: 1.194e+03, MSE(e): 4.988e-06, MSE(pi1): 1.254e-02, MSE(pi2): 1.428e-06, MSE(pi3): 1.104e-03\n",
      "Epoch 331200, Train loss: 2.889e+02, Test loss: 1.078e+03, MSE(e): 5.739e-06, MSE(pi1): 1.458e-02, MSE(pi2): 1.753e-06, MSE(pi3): 8.568e-04\n",
      "Epoch 331300, Train loss: 3.983e+02, Test loss: 1.274e+03, MSE(e): 9.122e-06, MSE(pi1): 2.082e-02, MSE(pi2): 2.533e-06, MSE(pi3): 9.888e-04\n",
      "Epoch 331400, Train loss: 1.768e+02, Test loss: 9.963e+02, MSE(e): 2.737e-06, MSE(pi1): 6.023e-03, MSE(pi2): 1.294e-06, MSE(pi3): 8.915e-04\n",
      "Epoch 331500, Train loss: 6.138e+02, Test loss: 1.182e+03, MSE(e): 4.537e-05, MSE(pi1): 6.276e-03, MSE(pi2): 1.959e-05, MSE(pi3): 9.739e-04\n",
      "Epoch 331600, Train loss: 1.895e+02, Test loss: 1.018e+03, MSE(e): 2.951e-06, MSE(pi1): 6.391e-03, MSE(pi2): 1.119e-06, MSE(pi3): 9.609e-04\n",
      "Epoch 331700, Train loss: 1.592e+02, Test loss: 1.022e+03, MSE(e): 2.269e-06, MSE(pi1): 4.067e-03, MSE(pi2): 1.136e-06, MSE(pi3): 9.579e-04\n",
      "Epoch 331800, Train loss: 2.080e+02, Test loss: 1.083e+03, MSE(e): 3.632e-06, MSE(pi1): 8.205e-03, MSE(pi2): 1.243e-06, MSE(pi3): 8.964e-04\n",
      "Epoch 331900, Train loss: 1.554e+02, Test loss: 1.009e+03, MSE(e): 2.166e-06, MSE(pi1): 3.970e-03, MSE(pi2): 9.739e-07, MSE(pi3): 9.406e-04\n",
      "Epoch 332000, Train loss: 3.080e+02, Test loss: 1.263e+03, MSE(e): 1.309e-05, MSE(pi1): 8.044e-03, MSE(pi2): 5.798e-06, MSE(pi3): 9.671e-04\n",
      "Epoch 332100, Train loss: 2.189e+02, Test loss: 1.023e+03, MSE(e): 5.245e-06, MSE(pi1): 7.726e-03, MSE(pi2): 2.724e-06, MSE(pi3): 8.915e-04\n",
      "Epoch 332200, Train loss: 5.501e+02, Test loss: 1.426e+03, MSE(e): 3.544e-05, MSE(pi1): 1.114e-02, MSE(pi2): 1.744e-05, MSE(pi3): 8.424e-04\n",
      "Epoch 332300, Train loss: 7.710e+02, Test loss: 1.597e+03, MSE(e): 5.069e-05, MSE(pi1): 1.690e-02, MSE(pi2): 2.315e-05, MSE(pi3): 9.508e-04\n",
      "Epoch 332400, Train loss: 3.817e+02, Test loss: 1.491e+03, MSE(e): 1.740e-05, MSE(pi1): 9.500e-03, MSE(pi2): 8.168e-06, MSE(pi3): 1.127e-03\n",
      "Epoch 332500, Train loss: 5.618e+02, Test loss: 1.663e+03, MSE(e): 3.086e-05, MSE(pi1): 1.179e-02, MSE(pi2): 1.057e-05, MSE(pi3): 1.353e-03\n",
      "Epoch 332600, Train loss: 2.468e+02, Test loss: 1.232e+03, MSE(e): 1.025e-05, MSE(pi1): 4.688e-03, MSE(pi2): 5.026e-06, MSE(pi3): 9.750e-04\n",
      "Epoch 332700, Train loss: 3.590e+02, Test loss: 1.299e+03, MSE(e): 1.401e-05, MSE(pi1): 1.066e-02, MSE(pi2): 5.249e-06, MSE(pi3): 1.123e-03\n",
      "Epoch 332800, Train loss: 1.954e+02, Test loss: 1.038e+03, MSE(e): 4.409e-06, MSE(pi1): 5.958e-03, MSE(pi2): 1.660e-06, MSE(pi3): 9.175e-04\n",
      "Epoch 332900, Train loss: 1.551e+02, Test loss: 9.672e+02, MSE(e): 2.255e-06, MSE(pi1): 3.831e-03, MSE(pi2): 1.070e-06, MSE(pi3): 9.423e-04\n",
      "Epoch 333000, Train loss: 4.332e+02, Test loss: 1.336e+03, MSE(e): 9.690e-06, MSE(pi1): 2.282e-02, MSE(pi2): 2.751e-06, MSE(pi3): 1.081e-03\n",
      "Epoch 333100, Train loss: 3.302e+02, Test loss: 1.306e+03, MSE(e): 7.896e-06, MSE(pi1): 1.603e-02, MSE(pi2): 2.297e-06, MSE(pi3): 9.098e-04\n",
      "Epoch 333200, Train loss: 3.132e+02, Test loss: 1.047e+03, MSE(e): 7.846e-06, MSE(pi1): 1.502e-02, MSE(pi2): 2.124e-06, MSE(pi3): 8.458e-04\n",
      "Epoch 333300, Train loss: 4.561e+02, Test loss: 1.297e+03, MSE(e): 1.078e-05, MSE(pi1): 2.455e-02, MSE(pi2): 3.428e-06, MSE(pi3): 1.028e-03\n",
      "Epoch 333400, Train loss: 2.858e+02, Test loss: 1.064e+03, MSE(e): 1.199e-05, MSE(pi1): 5.984e-03, MSE(pi2): 5.392e-06, MSE(pi3): 1.061e-03\n",
      "Epoch 333500, Train loss: 1.688e+02, Test loss: 1.137e+03, MSE(e): 2.430e-06, MSE(pi1): 5.076e-03, MSE(pi2): 1.059e-06, MSE(pi3): 9.377e-04\n",
      "Epoch 333600, Train loss: 3.516e+02, Test loss: 1.147e+03, MSE(e): 1.764e-05, MSE(pi1): 7.448e-03, MSE(pi2): 7.144e-06, MSE(pi3): 1.007e-03\n",
      "Epoch 333700, Train loss: 3.574e+02, Test loss: 1.190e+03, MSE(e): 1.385e-05, MSE(pi1): 1.152e-02, MSE(pi2): 5.255e-06, MSE(pi3): 1.038e-03\n",
      "Epoch 333800, Train loss: 2.700e+02, Test loss: 1.177e+03, MSE(e): 4.992e-06, MSE(pi1): 1.123e-02, MSE(pi2): 1.643e-06, MSE(pi3): 1.077e-03\n",
      "Epoch 333900, Train loss: 7.485e+02, Test loss: 2.294e+03, MSE(e): 5.153e-05, MSE(pi1): 1.239e-02, MSE(pi2): 2.520e-05, MSE(pi3): 1.094e-03\n",
      "Epoch 334000, Train loss: 3.138e+02, Test loss: 1.121e+03, MSE(e): 6.329e-06, MSE(pi1): 1.615e-02, MSE(pi2): 1.451e-06, MSE(pi3): 8.907e-04\n",
      "Epoch 334100, Train loss: 2.820e+02, Test loss: 1.158e+03, MSE(e): 5.051e-06, MSE(pi1): 1.425e-02, MSE(pi2): 1.689e-06, MSE(pi3): 8.901e-04\n",
      "Epoch 334200, Train loss: 4.348e+02, Test loss: 1.439e+03, MSE(e): 8.010e-06, MSE(pi1): 2.507e-02, MSE(pi2): 2.397e-06, MSE(pi3): 1.040e-03\n",
      "Epoch 334300, Train loss: 2.083e+02, Test loss: 1.021e+03, MSE(e): 4.691e-06, MSE(pi1): 7.150e-03, MSE(pi2): 2.365e-06, MSE(pi3): 8.992e-04\n",
      "Epoch 334400, Train loss: 1.672e+03, Test loss: 3.984e+03, MSE(e): 1.505e-04, MSE(pi1): 6.371e-03, MSE(pi2): 6.560e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 334500, Train loss: 1.491e+02, Test loss: 9.734e+02, MSE(e): 1.871e-06, MSE(pi1): 3.575e-03, MSE(pi2): 9.363e-07, MSE(pi3): 9.462e-04\n",
      "Epoch 334600, Train loss: 2.281e+02, Test loss: 1.161e+03, MSE(e): 5.260e-06, MSE(pi1): 8.873e-03, MSE(pi2): 2.214e-06, MSE(pi3): 8.678e-04\n",
      "Epoch 334700, Train loss: 4.129e+02, Test loss: 1.404e+03, MSE(e): 7.968e-06, MSE(pi1): 2.186e-02, MSE(pi2): 1.727e-06, MSE(pi3): 1.147e-03\n",
      "Epoch 334800, Train loss: 2.456e+02, Test loss: 1.059e+03, MSE(e): 7.772e-06, MSE(pi1): 6.898e-03, MSE(pi2): 3.329e-06, MSE(pi3): 9.889e-04\n",
      "Epoch 334900, Train loss: 5.568e+02, Test loss: 1.221e+03, MSE(e): 3.643e-05, MSE(pi1): 9.680e-03, MSE(pi2): 1.616e-05, MSE(pi3): 9.563e-04\n",
      "Epoch 335000, Train loss: 2.115e+02, Test loss: 1.005e+03, MSE(e): 5.736e-06, MSE(pi1): 5.507e-03, MSE(pi2): 2.444e-06, MSE(pi3): 9.911e-04\n",
      "Epoch 335100, Train loss: 3.256e+02, Test loss: 1.038e+03, MSE(e): 7.365e-06, MSE(pi1): 1.536e-02, MSE(pi2): 2.021e-06, MSE(pi3): 9.842e-04\n",
      "Epoch 335200, Train loss: 1.857e+02, Test loss: 1.062e+03, MSE(e): 3.683e-06, MSE(pi1): 5.979e-03, MSE(pi2): 1.532e-06, MSE(pi3): 8.907e-04\n",
      "Epoch 335300, Train loss: 2.167e+02, Test loss: 1.082e+03, MSE(e): 4.334e-06, MSE(pi1): 7.156e-03, MSE(pi2): 1.546e-06, MSE(pi3): 1.018e-03\n",
      "Epoch 335400, Train loss: 2.009e+02, Test loss: 1.076e+03, MSE(e): 3.124e-06, MSE(pi1): 7.828e-03, MSE(pi2): 1.226e-06, MSE(pi3): 9.136e-04\n",
      "Epoch 335500, Train loss: 3.968e+02, Test loss: 1.332e+03, MSE(e): 2.429e-05, MSE(pi1): 6.256e-03, MSE(pi2): 1.119e-05, MSE(pi3): 9.129e-04\n",
      "Epoch 335600, Train loss: 5.316e+02, Test loss: 1.514e+03, MSE(e): 3.605e-05, MSE(pi1): 6.295e-03, MSE(pi2): 1.702e-05, MSE(pi3): 1.081e-03\n",
      "Epoch 335700, Train loss: 2.405e+02, Test loss: 1.161e+03, MSE(e): 5.042e-06, MSE(pi1): 1.003e-02, MSE(pi2): 1.455e-06, MSE(pi3): 8.980e-04\n",
      "Epoch 335800, Train loss: 3.474e+02, Test loss: 1.261e+03, MSE(e): 1.812e-05, MSE(pi1): 6.522e-03, MSE(pi2): 8.405e-06, MSE(pi3): 1.010e-03\n",
      "Epoch 335900, Train loss: 4.470e+02, Test loss: 1.118e+03, MSE(e): 2.162e-05, MSE(pi1): 1.232e-02, MSE(pi2): 8.467e-06, MSE(pi3): 1.077e-03\n",
      "Epoch 336000, Train loss: 2.065e+02, Test loss: 1.065e+03, MSE(e): 4.982e-06, MSE(pi1): 6.731e-03, MSE(pi2): 2.255e-06, MSE(pi3): 8.935e-04\n",
      "Epoch 336100, Train loss: 2.247e+02, Test loss: 1.091e+03, MSE(e): 3.930e-06, MSE(pi1): 8.313e-03, MSE(pi2): 1.320e-06, MSE(pi3): 1.023e-03\n",
      "Epoch 336200, Train loss: 3.505e+02, Test loss: 1.078e+03, MSE(e): 1.143e-05, MSE(pi1): 1.263e-02, MSE(pi2): 3.480e-06, MSE(pi3): 1.099e-03\n",
      "Epoch 336300, Train loss: 3.718e+02, Test loss: 1.146e+03, MSE(e): 1.862e-05, MSE(pi1): 9.535e-03, MSE(pi2): 7.517e-06, MSE(pi3): 9.022e-04\n",
      "Epoch 336400, Train loss: 2.482e+02, Test loss: 1.173e+03, MSE(e): 4.735e-06, MSE(pi1): 1.051e-02, MSE(pi2): 1.436e-06, MSE(pi3): 9.575e-04\n",
      "Epoch 336500, Train loss: 1.750e+02, Test loss: 9.664e+02, MSE(e): 3.854e-06, MSE(pi1): 3.943e-03, MSE(pi2): 1.871e-06, MSE(pi3): 9.702e-04\n",
      "Epoch 336600, Train loss: 3.531e+02, Test loss: 1.096e+03, MSE(e): 1.767e-05, MSE(pi1): 8.147e-03, MSE(pi2): 7.603e-06, MSE(pi3): 9.497e-04\n",
      "Epoch 336700, Train loss: 2.846e+02, Test loss: 1.065e+03, MSE(e): 1.203e-05, MSE(pi1): 7.506e-03, MSE(pi2): 5.135e-06, MSE(pi3): 8.923e-04\n",
      "Epoch 336800, Train loss: 4.156e+02, Test loss: 1.264e+03, MSE(e): 8.376e-06, MSE(pi1): 2.264e-02, MSE(pi2): 2.080e-06, MSE(pi3): 1.054e-03\n",
      "Epoch 336900, Train loss: 2.196e+02, Test loss: 1.037e+03, MSE(e): 3.750e-06, MSE(pi1): 9.582e-03, MSE(pi2): 1.178e-06, MSE(pi3): 8.628e-04\n",
      "Epoch 337000, Train loss: 4.325e+02, Test loss: 1.426e+03, MSE(e): 8.263e-06, MSE(pi1): 2.276e-02, MSE(pi2): 1.972e-06, MSE(pi3): 1.223e-03\n",
      "Epoch 337100, Train loss: 5.232e+02, Test loss: 1.177e+03, MSE(e): 2.929e-05, MSE(pi1): 1.340e-02, MSE(pi2): 1.307e-05, MSE(pi3): 9.633e-04\n",
      "Epoch 337200, Train loss: 3.397e+02, Test loss: 1.220e+03, MSE(e): 5.739e-06, MSE(pi1): 1.670e-02, MSE(pi2): 1.729e-06, MSE(pi3): 1.153e-03\n",
      "Epoch 337300, Train loss: 1.100e+03, Test loss: 1.243e+03, MSE(e): 8.085e-05, MSE(pi1): 1.955e-02, MSE(pi2): 3.682e-05, MSE(pi3): 9.555e-04\n",
      "Epoch 337400, Train loss: 4.135e+02, Test loss: 1.359e+03, MSE(e): 8.019e-06, MSE(pi1): 2.483e-02, MSE(pi2): 2.612e-06, MSE(pi3): 8.502e-04\n",
      "Epoch 337500, Train loss: 2.895e+02, Test loss: 1.138e+03, MSE(e): 6.450e-06, MSE(pi1): 1.183e-02, MSE(pi2): 2.109e-06, MSE(pi3): 1.066e-03\n",
      "Epoch 337600, Train loss: 3.907e+02, Test loss: 1.522e+03, MSE(e): 2.332e-05, MSE(pi1): 6.508e-03, MSE(pi2): 1.086e-05, MSE(pi3): 9.240e-04\n",
      "Epoch 337700, Train loss: 2.549e+02, Test loss: 1.144e+03, MSE(e): 4.237e-06, MSE(pi1): 1.129e-02, MSE(pi2): 1.370e-06, MSE(pi3): 9.963e-04\n",
      "Epoch 337800, Train loss: 4.622e+02, Test loss: 1.350e+03, MSE(e): 1.057e-05, MSE(pi1): 2.510e-02, MSE(pi2): 2.966e-06, MSE(pi3): 1.055e-03\n",
      "Epoch 337900, Train loss: 3.459e+02, Test loss: 1.262e+03, MSE(e): 6.314e-06, MSE(pi1): 1.663e-02, MSE(pi2): 1.792e-06, MSE(pi3): 1.164e-03\n",
      "Epoch 338000, Train loss: 2.133e+02, Test loss: 9.806e+02, MSE(e): 7.406e-06, MSE(pi1): 4.143e-03, MSE(pi2): 3.334e-06, MSE(pi3): 9.780e-04\n",
      "Epoch 338100, Train loss: 2.400e+02, Test loss: 9.756e+02, MSE(e): 6.214e-06, MSE(pi1): 8.425e-03, MSE(pi2): 2.639e-06, MSE(pi3): 9.361e-04\n",
      "Epoch 338200, Train loss: 1.534e+02, Test loss: 9.933e+02, MSE(e): 1.910e-06, MSE(pi1): 3.769e-03, MSE(pi2): 9.476e-07, MSE(pi3): 9.665e-04\n",
      "Epoch 338300, Train loss: 2.960e+02, Test loss: 1.149e+03, MSE(e): 7.296e-06, MSE(pi1): 1.148e-02, MSE(pi2): 2.138e-06, MSE(pi3): 1.082e-03\n",
      "Epoch 338400, Train loss: 1.536e+02, Test loss: 9.921e+02, MSE(e): 1.916e-06, MSE(pi1): 4.136e-03, MSE(pi2): 9.328e-07, MSE(pi3): 9.313e-04\n",
      "Epoch 338500, Train loss: 3.304e+02, Test loss: 1.126e+03, MSE(e): 6.335e-06, MSE(pi1): 1.792e-02, MSE(pi2): 1.685e-06, MSE(pi3): 8.788e-04\n",
      "Epoch 338600, Train loss: 2.301e+02, Test loss: 1.182e+03, MSE(e): 4.470e-06, MSE(pi1): 8.147e-03, MSE(pi2): 1.782e-06, MSE(pi3): 1.039e-03\n",
      "Epoch 338700, Train loss: 3.083e+02, Test loss: 1.197e+03, MSE(e): 6.563e-06, MSE(pi1): 1.453e-02, MSE(pi2): 2.077e-06, MSE(pi3): 9.740e-04\n",
      "Epoch 338800, Train loss: 1.889e+02, Test loss: 1.013e+03, MSE(e): 3.951e-06, MSE(pi1): 5.205e-03, MSE(pi2): 1.468e-06, MSE(pi3): 9.737e-04\n",
      "Epoch 338900, Train loss: 3.897e+02, Test loss: 1.421e+03, MSE(e): 1.568e-05, MSE(pi1): 1.310e-02, MSE(pi2): 6.247e-06, MSE(pi3): 1.019e-03\n",
      "Epoch 339000, Train loss: 9.418e+02, Test loss: 2.011e+03, MSE(e): 7.496e-05, MSE(pi1): 1.000e-02, MSE(pi2): 3.591e-05, MSE(pi3): 9.213e-04\n",
      "Epoch 339100, Train loss: 1.504e+02, Test loss: 9.591e+02, MSE(e): 2.048e-06, MSE(pi1): 3.446e-03, MSE(pi2): 1.043e-06, MSE(pi3): 9.546e-04\n",
      "Epoch 339200, Train loss: 4.125e+02, Test loss: 1.326e+03, MSE(e): 7.454e-06, MSE(pi1): 2.133e-02, MSE(pi2): 1.796e-06, MSE(pi3): 1.247e-03\n",
      "Epoch 339300, Train loss: 2.811e+02, Test loss: 1.228e+03, MSE(e): 7.886e-06, MSE(pi1): 9.444e-03, MSE(pi2): 3.191e-06, MSE(pi3): 1.078e-03\n",
      "Epoch 339400, Train loss: 3.916e+02, Test loss: 1.216e+03, MSE(e): 8.927e-06, MSE(pi1): 1.953e-02, MSE(pi2): 2.153e-06, MSE(pi3): 1.071e-03\n",
      "Epoch 339500, Train loss: 1.950e+02, Test loss: 1.048e+03, MSE(e): 3.108e-06, MSE(pi1): 7.177e-03, MSE(pi2): 1.290e-06, MSE(pi3): 9.212e-04\n",
      "Epoch 339600, Train loss: 2.246e+02, Test loss: 9.693e+02, MSE(e): 9.141e-06, MSE(pi1): 4.057e-03, MSE(pi2): 3.916e-06, MSE(pi3): 9.258e-04\n",
      "Epoch 339700, Train loss: 1.617e+02, Test loss: 1.031e+03, MSE(e): 2.569e-06, MSE(pi1): 4.285e-03, MSE(pi2): 1.258e-06, MSE(pi3): 9.314e-04\n",
      "Epoch 339800, Train loss: 4.017e+02, Test loss: 1.153e+03, MSE(e): 2.198e-05, MSE(pi1): 8.511e-03, MSE(pi2): 1.024e-05, MSE(pi3): 9.678e-04\n",
      "Epoch 339900, Train loss: 1.136e+03, Test loss: 2.324e+03, MSE(e): 8.143e-05, MSE(pi1): 1.917e-02, MSE(pi2): 3.858e-05, MSE(pi3): 1.296e-03\n",
      "Epoch 340000, Train loss: 1.737e+02, Test loss: 1.032e+03, MSE(e): 4.109e-06, MSE(pi1): 3.536e-03, MSE(pi2): 1.981e-06, MSE(pi3): 9.725e-04\n",
      "Epoch 340100, Train loss: 2.155e+02, Test loss: 9.756e+02, MSE(e): 8.237e-06, MSE(pi1): 3.798e-03, MSE(pi2): 3.770e-06, MSE(pi3): 9.516e-04\n",
      "Epoch 340200, Train loss: 2.746e+02, Test loss: 1.155e+03, MSE(e): 7.053e-06, MSE(pi1): 9.951e-03, MSE(pi2): 2.778e-06, MSE(pi3): 1.046e-03\n",
      "Epoch 340300, Train loss: 4.979e+02, Test loss: 1.247e+03, MSE(e): 2.789e-05, MSE(pi1): 1.297e-02, MSE(pi2): 1.422e-05, MSE(pi3): 8.918e-04\n",
      "Epoch 340400, Train loss: 5.660e+02, Test loss: 1.533e+03, MSE(e): 1.235e-05, MSE(pi1): 3.576e-02, MSE(pi2): 2.385e-06, MSE(pi3): 8.489e-04\n",
      "Epoch 340500, Train loss: 2.725e+02, Test loss: 1.230e+03, MSE(e): 5.415e-06, MSE(pi1): 1.179e-02, MSE(pi2): 2.045e-06, MSE(pi3): 1.004e-03\n",
      "Epoch 340600, Train loss: 1.801e+02, Test loss: 1.016e+03, MSE(e): 2.819e-06, MSE(pi1): 5.163e-03, MSE(pi2): 1.135e-06, MSE(pi3): 1.003e-03\n",
      "Epoch 340700, Train loss: 2.952e+02, Test loss: 1.130e+03, MSE(e): 5.790e-06, MSE(pi1): 1.404e-02, MSE(pi2): 1.567e-06, MSE(pi3): 9.691e-04\n",
      "Epoch 340800, Train loss: 1.479e+02, Test loss: 9.654e+02, MSE(e): 1.773e-06, MSE(pi1): 3.361e-03, MSE(pi2): 8.940e-07, MSE(pi3): 9.654e-04\n",
      "Epoch 340900, Train loss: 4.875e+02, Test loss: 1.067e+03, MSE(e): 3.116e-05, MSE(pi1): 8.722e-03, MSE(pi2): 1.454e-05, MSE(pi3): 8.859e-04\n",
      "Epoch 341000, Train loss: 3.390e+02, Test loss: 1.257e+03, MSE(e): 7.888e-06, MSE(pi1): 1.662e-02, MSE(pi2): 2.299e-06, MSE(pi3): 9.391e-04\n",
      "Epoch 341100, Train loss: 7.198e+02, Test loss: 1.595e+03, MSE(e): 4.802e-05, MSE(pi1): 1.569e-02, MSE(pi2): 2.338e-05, MSE(pi3): 8.263e-04\n",
      "Epoch 341200, Train loss: 2.262e+02, Test loss: 9.760e+02, MSE(e): 6.351e-06, MSE(pi1): 7.206e-03, MSE(pi2): 2.690e-06, MSE(pi3): 9.061e-04\n",
      "Epoch 341300, Train loss: 2.280e+02, Test loss: 1.127e+03, MSE(e): 4.349e-06, MSE(pi1): 9.220e-03, MSE(pi2): 1.472e-06, MSE(pi3): 9.226e-04\n",
      "Epoch 341400, Train loss: 3.806e+02, Test loss: 1.272e+03, MSE(e): 7.833e-06, MSE(pi1): 1.874e-02, MSE(pi2): 1.850e-06, MSE(pi3): 1.149e-03\n",
      "Epoch 341500, Train loss: 3.192e+02, Test loss: 1.198e+03, MSE(e): 5.466e-06, MSE(pi1): 1.768e-02, MSE(pi2): 1.378e-06, MSE(pi3): 8.767e-04\n",
      "Epoch 341600, Train loss: 5.256e+02, Test loss: 1.073e+03, MSE(e): 3.065e-05, MSE(pi1): 1.285e-02, MSE(pi2): 1.532e-05, MSE(pi3): 9.058e-04\n",
      "Epoch 341700, Train loss: 2.975e+02, Test loss: 1.261e+03, MSE(e): 9.136e-06, MSE(pi1): 1.169e-02, MSE(pi2): 2.603e-06, MSE(pi3): 8.917e-04\n",
      "Epoch 341800, Train loss: 1.980e+02, Test loss: 1.045e+03, MSE(e): 3.129e-06, MSE(pi1): 6.456e-03, MSE(pi2): 1.146e-06, MSE(pi3): 1.022e-03\n",
      "Epoch 341900, Train loss: 1.990e+02, Test loss: 9.713e+02, MSE(e): 6.614e-06, MSE(pi1): 4.256e-03, MSE(pi2): 2.814e-06, MSE(pi3): 9.026e-04\n",
      "Epoch 342000, Train loss: 5.373e+02, Test loss: 1.254e+03, MSE(e): 2.445e-05, MSE(pi1): 2.056e-02, MSE(pi2): 9.227e-06, MSE(pi3): 8.723e-04\n",
      "Epoch 342100, Train loss: 7.059e+02, Test loss: 1.864e+03, MSE(e): 5.439e-05, MSE(pi1): 5.422e-03, MSE(pi2): 2.716e-05, MSE(pi3): 1.078e-03\n",
      "Epoch 342200, Train loss: 5.566e+02, Test loss: 1.773e+03, MSE(e): 3.685e-05, MSE(pi1): 8.969e-03, MSE(pi2): 1.794e-05, MSE(pi3): 9.840e-04\n",
      "Epoch 342300, Train loss: 4.473e+02, Test loss: 1.279e+03, MSE(e): 2.503e-05, MSE(pi1): 1.039e-02, MSE(pi2): 1.210e-05, MSE(pi3): 9.309e-04\n",
      "Epoch 342400, Train loss: 2.188e+02, Test loss: 1.014e+03, MSE(e): 3.585e-06, MSE(pi1): 9.276e-03, MSE(pi2): 1.170e-06, MSE(pi3): 9.021e-04\n",
      "Epoch 342500, Train loss: 5.752e+02, Test loss: 1.703e+03, MSE(e): 1.288e-05, MSE(pi1): 3.621e-02, MSE(pi2): 4.237e-06, MSE(pi3): 8.436e-04\n",
      "Epoch 342600, Train loss: 1.762e+03, Test loss: 3.161e+03, MSE(e): 1.295e-04, MSE(pi1): 3.802e-02, MSE(pi2): 6.501e-05, MSE(pi3): 8.599e-04\n",
      "Epoch 342700, Train loss: 2.291e+02, Test loss: 1.190e+03, MSE(e): 8.108e-06, MSE(pi1): 4.505e-03, MSE(pi2): 4.099e-06, MSE(pi3): 1.030e-03\n",
      "Epoch 342800, Train loss: 2.400e+02, Test loss: 1.007e+03, MSE(e): 8.807e-06, MSE(pi1): 5.801e-03, MSE(pi2): 4.083e-06, MSE(pi3): 9.396e-04\n",
      "Epoch 342900, Train loss: 7.898e+02, Test loss: 1.773e+03, MSE(e): 5.506e-05, MSE(pi1): 1.383e-02, MSE(pi2): 2.446e-05, MSE(pi3): 1.009e-03\n",
      "Epoch 343000, Train loss: 4.052e+02, Test loss: 1.523e+03, MSE(e): 1.816e-05, MSE(pi1): 1.272e-02, MSE(pi2): 8.117e-06, MSE(pi3): 9.631e-04\n",
      "Epoch 343100, Train loss: 9.778e+02, Test loss: 1.849e+03, MSE(e): 5.177e-05, MSE(pi1): 3.768e-02, MSE(pi2): 2.353e-05, MSE(pi3): 8.323e-04\n",
      "Epoch 343200, Train loss: 1.684e+03, Test loss: 2.207e+03, MSE(e): 1.466e-04, MSE(pi1): 1.283e-02, MSE(pi2): 6.885e-05, MSE(pi3): 8.958e-04\n",
      "Epoch 343300, Train loss: 1.179e+03, Test loss: 1.720e+03, MSE(e): 8.585e-05, MSE(pi1): 2.317e-02, MSE(pi2): 4.177e-05, MSE(pi3): 8.851e-04\n",
      "Epoch 343400, Train loss: 8.354e+02, Test loss: 1.741e+03, MSE(e): 5.998e-05, MSE(pi1): 1.296e-02, MSE(pi2): 2.747e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 343500, Train loss: 4.127e+02, Test loss: 1.576e+03, MSE(e): 2.013e-05, MSE(pi1): 1.104e-02, MSE(pi2): 8.302e-06, MSE(pi3): 1.009e-03\n",
      "Epoch 343600, Train loss: 3.547e+02, Test loss: 1.265e+03, MSE(e): 7.255e-06, MSE(pi1): 1.752e-02, MSE(pi2): 1.803e-06, MSE(pi3): 1.069e-03\n",
      "Epoch 343700, Train loss: 2.598e+02, Test loss: 1.117e+03, MSE(e): 7.862e-06, MSE(pi1): 9.120e-03, MSE(pi2): 3.297e-06, MSE(pi3): 9.001e-04\n",
      "Epoch 343800, Train loss: 2.459e+02, Test loss: 1.127e+03, MSE(e): 4.298e-06, MSE(pi1): 1.042e-02, MSE(pi2): 1.504e-06, MSE(pi3): 9.879e-04\n",
      "Epoch 343900, Train loss: 1.047e+03, Test loss: 1.783e+03, MSE(e): 7.526e-05, MSE(pi1): 1.855e-02, MSE(pi2): 3.425e-05, MSE(pi3): 1.084e-03\n",
      "Epoch 344000, Train loss: 4.368e+02, Test loss: 1.192e+03, MSE(e): 1.327e-05, MSE(pi1): 2.183e-02, MSE(pi2): 5.407e-06, MSE(pi3): 8.580e-04\n",
      "Epoch 344100, Train loss: 3.454e+02, Test loss: 1.264e+03, MSE(e): 6.183e-06, MSE(pi1): 1.890e-02, MSE(pi2): 1.657e-06, MSE(pi3): 9.460e-04\n",
      "Epoch 344200, Train loss: 4.871e+02, Test loss: 1.503e+03, MSE(e): 2.386e-05, MSE(pi1): 1.298e-02, MSE(pi2): 1.111e-05, MSE(pi3): 1.187e-03\n",
      "Epoch 344300, Train loss: 5.779e+02, Test loss: 1.381e+03, MSE(e): 3.760e-05, MSE(pi1): 1.144e-02, MSE(pi2): 1.703e-05, MSE(pi3): 8.754e-04\n",
      "Epoch 344400, Train loss: 2.786e+02, Test loss: 1.171e+03, MSE(e): 1.410e-05, MSE(pi1): 4.318e-03, MSE(pi2): 6.334e-06, MSE(pi3): 9.443e-04\n",
      "Epoch 344500, Train loss: 1.232e+03, Test loss: 1.798e+03, MSE(e): 1.081e-04, MSE(pi1): 6.177e-03, MSE(pi2): 5.241e-05, MSE(pi3): 8.959e-04\n",
      "Epoch 344600, Train loss: 4.078e+02, Test loss: 1.314e+03, MSE(e): 9.601e-06, MSE(pi1): 2.210e-02, MSE(pi2): 2.323e-06, MSE(pi3): 9.076e-04\n",
      "Epoch 344700, Train loss: 4.134e+02, Test loss: 1.269e+03, MSE(e): 1.227e-05, MSE(pi1): 1.661e-02, MSE(pi2): 4.179e-06, MSE(pi3): 1.246e-03\n",
      "Epoch 344800, Train loss: 4.207e+02, Test loss: 1.394e+03, MSE(e): 8.480e-06, MSE(pi1): 2.349e-02, MSE(pi2): 1.988e-06, MSE(pi3): 1.011e-03\n",
      "Epoch 344900, Train loss: 3.017e+03, Test loss: 4.505e+03, MSE(e): 2.803e-04, MSE(pi1): 1.178e-02, MSE(pi2): 1.359e-04, MSE(pi3): 9.609e-04\n",
      "Epoch 345000, Train loss: 3.506e+02, Test loss: 1.164e+03, MSE(e): 8.760e-06, MSE(pi1): 1.651e-02, MSE(pi2): 2.461e-06, MSE(pi3): 9.792e-04\n",
      "Epoch 345100, Train loss: 1.971e+02, Test loss: 1.084e+03, MSE(e): 4.286e-06, MSE(pi1): 5.206e-03, MSE(pi2): 1.915e-06, MSE(pi3): 1.022e-03\n",
      "Epoch 345200, Train loss: 2.137e+02, Test loss: 1.073e+03, MSE(e): 3.660e-06, MSE(pi1): 7.221e-03, MSE(pi2): 1.288e-06, MSE(pi3): 1.049e-03\n",
      "Epoch 345300, Train loss: 2.364e+02, Test loss: 1.050e+03, MSE(e): 4.644e-06, MSE(pi1): 9.273e-03, MSE(pi2): 1.593e-06, MSE(pi3): 9.722e-04\n",
      "Epoch 345400, Train loss: 2.599e+02, Test loss: 1.170e+03, MSE(e): 4.178e-06, MSE(pi1): 1.290e-02, MSE(pi2): 1.378e-06, MSE(pi3): 8.916e-04\n",
      "Epoch 345500, Train loss: 3.116e+02, Test loss: 1.107e+03, MSE(e): 5.761e-06, MSE(pi1): 1.680e-02, MSE(pi2): 1.486e-06, MSE(pi3): 8.593e-04\n",
      "Epoch 345600, Train loss: 2.044e+02, Test loss: 1.024e+03, MSE(e): 3.357e-06, MSE(pi1): 6.666e-03, MSE(pi2): 1.148e-06, MSE(pi3): 1.042e-03\n",
      "Epoch 345700, Train loss: 3.598e+02, Test loss: 1.003e+03, MSE(e): 2.093e-05, MSE(pi1): 6.254e-03, MSE(pi2): 1.027e-05, MSE(pi3): 8.796e-04\n",
      "Epoch 345800, Train loss: 3.003e+02, Test loss: 9.909e+02, MSE(e): 1.642e-05, MSE(pi1): 4.416e-03, MSE(pi2): 7.958e-06, MSE(pi3): 9.193e-04\n",
      "Epoch 345900, Train loss: 2.860e+02, Test loss: 1.219e+03, MSE(e): 5.256e-06, MSE(pi1): 1.332e-02, MSE(pi2): 1.501e-06, MSE(pi3): 1.002e-03\n",
      "Epoch 346000, Train loss: 1.814e+02, Test loss: 1.003e+03, MSE(e): 2.734e-06, MSE(pi1): 5.507e-03, MSE(pi2): 1.051e-06, MSE(pi3): 9.895e-04\n",
      "Epoch 346100, Train loss: 5.283e+02, Test loss: 1.553e+03, MSE(e): 3.636e-05, MSE(pi1): 5.922e-03, MSE(pi2): 1.820e-05, MSE(pi3): 1.054e-03\n",
      "Epoch 346200, Train loss: 2.368e+02, Test loss: 1.140e+03, MSE(e): 4.065e-06, MSE(pi1): 1.019e-02, MSE(pi2): 1.352e-06, MSE(pi3): 9.425e-04\n",
      "Epoch 346300, Train loss: 2.626e+02, Test loss: 1.223e+03, MSE(e): 4.180e-06, MSE(pi1): 1.340e-02, MSE(pi2): 1.430e-06, MSE(pi3): 8.677e-04\n",
      "Epoch 346400, Train loss: 2.753e+02, Test loss: 1.150e+03, MSE(e): 5.285e-06, MSE(pi1): 1.121e-02, MSE(pi2): 1.825e-06, MSE(pi3): 1.104e-03\n",
      "Epoch 346500, Train loss: 2.766e+02, Test loss: 1.214e+03, MSE(e): 5.054e-06, MSE(pi1): 1.371e-02, MSE(pi2): 1.403e-06, MSE(pi3): 8.893e-04\n",
      "Epoch 346600, Train loss: 2.959e+02, Test loss: 1.269e+03, MSE(e): 5.629e-06, MSE(pi1): 1.302e-02, MSE(pi2): 1.415e-06, MSE(pi3): 1.094e-03\n",
      "Epoch 346700, Train loss: 2.697e+02, Test loss: 1.170e+03, MSE(e): 5.123e-06, MSE(pi1): 1.194e-02, MSE(pi2): 1.613e-06, MSE(pi3): 9.907e-04\n",
      "Epoch 346800, Train loss: 8.359e+02, Test loss: 2.019e+03, MSE(e): 6.515e-05, MSE(pi1): 8.797e-03, MSE(pi2): 2.936e-05, MSE(pi3): 9.650e-04\n",
      "Epoch 346900, Train loss: 2.321e+02, Test loss: 1.238e+03, MSE(e): 6.825e-06, MSE(pi1): 7.208e-03, MSE(pi2): 3.060e-06, MSE(pi3): 9.173e-04\n",
      "Epoch 347000, Train loss: 2.173e+03, Test loss: 2.744e+03, MSE(e): 1.959e-04, MSE(pi1): 1.205e-02, MSE(pi2): 9.287e-05, MSE(pi3): 9.401e-04\n",
      "Epoch 347100, Train loss: 5.321e+02, Test loss: 1.204e+03, MSE(e): 3.461e-05, MSE(pi1): 8.450e-03, MSE(pi2): 1.582e-05, MSE(pi3): 1.015e-03\n",
      "Epoch 347200, Train loss: 2.548e+02, Test loss: 1.021e+03, MSE(e): 8.475e-06, MSE(pi1): 8.185e-03, MSE(pi2): 4.439e-06, MSE(pi3): 8.819e-04\n",
      "Epoch 347300, Train loss: 1.686e+02, Test loss: 1.010e+03, MSE(e): 2.753e-06, MSE(pi1): 5.078e-03, MSE(pi2): 1.261e-06, MSE(pi3): 9.028e-04\n",
      "Epoch 347400, Train loss: 1.112e+03, Test loss: 2.620e+03, MSE(e): 8.493e-05, MSE(pi1): 1.449e-02, MSE(pi2): 3.989e-05, MSE(pi3): 1.178e-03\n",
      "Epoch 347500, Train loss: 3.737e+02, Test loss: 1.412e+03, MSE(e): 2.087e-05, MSE(pi1): 5.927e-03, MSE(pi2): 9.807e-06, MSE(pi3): 1.057e-03\n",
      "Epoch 347600, Train loss: 3.416e+02, Test loss: 1.141e+03, MSE(e): 1.315e-05, MSE(pi1): 1.020e-02, MSE(pi2): 5.360e-06, MSE(pi3): 1.080e-03\n",
      "Epoch 347700, Train loss: 2.864e+02, Test loss: 1.075e+03, MSE(e): 1.111e-05, MSE(pi1): 7.394e-03, MSE(pi2): 4.586e-06, MSE(pi3): 1.014e-03\n",
      "Epoch 347800, Train loss: 2.772e+02, Test loss: 1.213e+03, MSE(e): 8.033e-06, MSE(pi1): 9.859e-03, MSE(pi2): 3.236e-06, MSE(pi3): 9.831e-04\n",
      "Epoch 347900, Train loss: 1.765e+02, Test loss: 9.618e+02, MSE(e): 3.634e-06, MSE(pi1): 4.327e-03, MSE(pi2): 1.674e-06, MSE(pi3): 9.684e-04\n",
      "Epoch 348000, Train loss: 1.518e+02, Test loss: 9.920e+02, MSE(e): 1.829e-06, MSE(pi1): 3.540e-03, MSE(pi2): 8.929e-07, MSE(pi3): 9.814e-04\n",
      "Epoch 348100, Train loss: 1.026e+03, Test loss: 2.166e+03, MSE(e): 4.118e-05, MSE(pi1): 5.030e-02, MSE(pi2): 1.297e-05, MSE(pi3): 1.108e-03\n",
      "Epoch 348200, Train loss: 2.634e+02, Test loss: 1.191e+03, MSE(e): 5.201e-06, MSE(pi1): 1.119e-02, MSE(pi2): 1.647e-06, MSE(pi3): 9.957e-04\n",
      "Epoch 348300, Train loss: 1.668e+02, Test loss: 9.506e+02, MSE(e): 2.578e-06, MSE(pi1): 4.751e-03, MSE(pi2): 1.180e-06, MSE(pi3): 9.348e-04\n",
      "Epoch 348400, Train loss: 3.642e+02, Test loss: 1.339e+03, MSE(e): 7.840e-06, MSE(pi1): 1.882e-02, MSE(pi2): 2.305e-06, MSE(pi3): 9.752e-04\n",
      "Epoch 348500, Train loss: 2.142e+02, Test loss: 1.022e+03, MSE(e): 5.907e-06, MSE(pi1): 5.607e-03, MSE(pi2): 2.398e-06, MSE(pi3): 9.908e-04\n",
      "Epoch 348600, Train loss: 4.770e+02, Test loss: 1.487e+03, MSE(e): 9.390e-06, MSE(pi1): 2.783e-02, MSE(pi2): 2.108e-06, MSE(pi3): 1.048e-03\n",
      "Epoch 348700, Train loss: 4.557e+02, Test loss: 1.442e+03, MSE(e): 3.153e-05, MSE(pi1): 4.058e-03, MSE(pi2): 1.471e-05, MSE(pi3): 9.980e-04\n",
      "Epoch 348800, Train loss: 4.626e+02, Test loss: 1.252e+03, MSE(e): 2.537e-05, MSE(pi1): 1.028e-02, MSE(pi2): 1.066e-05, MSE(pi3): 1.061e-03\n",
      "Epoch 348900, Train loss: 1.928e+02, Test loss: 1.109e+03, MSE(e): 5.398e-06, MSE(pi1): 4.282e-03, MSE(pi2): 2.445e-06, MSE(pi3): 9.602e-04\n",
      "Epoch 349000, Train loss: 6.512e+02, Test loss: 1.400e+03, MSE(e): 1.431e-05, MSE(pi1): 4.170e-02, MSE(pi2): 2.610e-06, MSE(pi3): 9.108e-04\n",
      "Epoch 349100, Train loss: 1.683e+02, Test loss: 1.179e+03, MSE(e): 2.276e-06, MSE(pi1): 5.572e-03, MSE(pi2): 9.471e-07, MSE(pi3): 8.982e-04\n",
      "Epoch 349200, Train loss: 1.730e+02, Test loss: 9.921e+02, MSE(e): 2.489e-06, MSE(pi1): 4.996e-03, MSE(pi2): 9.995e-07, MSE(pi3): 9.814e-04\n",
      "Epoch 349300, Train loss: 6.903e+02, Test loss: 1.845e+03, MSE(e): 3.412e-05, MSE(pi1): 2.277e-02, MSE(pi2): 1.470e-05, MSE(pi3): 1.215e-03\n",
      "Epoch 349400, Train loss: 1.663e+02, Test loss: 1.001e+03, MSE(e): 2.133e-06, MSE(pi1): 4.886e-03, MSE(pi2): 9.338e-07, MSE(pi3): 9.608e-04\n",
      "Epoch 349500, Train loss: 2.265e+02, Test loss: 1.125e+03, MSE(e): 5.640e-06, MSE(pi1): 7.725e-03, MSE(pi2): 2.039e-06, MSE(pi3): 9.284e-04\n",
      "Epoch 349600, Train loss: 5.437e+02, Test loss: 1.765e+03, MSE(e): 2.062e-05, MSE(pi1): 2.101e-02, MSE(pi2): 9.156e-06, MSE(pi3): 1.274e-03\n",
      "Epoch 349700, Train loss: 2.305e+02, Test loss: 1.171e+03, MSE(e): 7.478e-06, MSE(pi1): 5.609e-03, MSE(pi2): 3.330e-06, MSE(pi3): 9.963e-04\n",
      "Epoch 349800, Train loss: 2.671e+02, Test loss: 1.232e+03, MSE(e): 8.287e-06, MSE(pi1): 7.924e-03, MSE(pi2): 3.587e-06, MSE(pi3): 1.050e-03\n",
      "Epoch 349900, Train loss: 3.013e+02, Test loss: 1.212e+03, MSE(e): 6.121e-06, MSE(pi1): 1.507e-02, MSE(pi2): 1.658e-06, MSE(pi3): 8.943e-04\n",
      "Epoch 350000, Train loss: 3.414e+02, Test loss: 1.376e+03, MSE(e): 1.398e-05, MSE(pi1): 1.034e-02, MSE(pi2): 5.805e-06, MSE(pi3): 9.816e-04\n",
      "Epoch 350100, Train loss: 2.008e+02, Test loss: 1.037e+03, MSE(e): 3.354e-06, MSE(pi1): 6.695e-03, MSE(pi2): 1.308e-06, MSE(pi3): 1.003e-03\n",
      "Epoch 350200, Train loss: 1.857e+02, Test loss: 9.745e+02, MSE(e): 2.935e-06, MSE(pi1): 5.523e-03, MSE(pi2): 1.127e-06, MSE(pi3): 1.012e-03\n",
      "Epoch 350300, Train loss: 9.952e+02, Test loss: 1.770e+03, MSE(e): 7.938e-05, MSE(pi1): 9.704e-03, MSE(pi2): 3.802e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 350400, Train loss: 2.843e+02, Test loss: 1.230e+03, MSE(e): 1.138e-05, MSE(pi1): 6.988e-03, MSE(pi2): 5.468e-06, MSE(pi3): 1.006e-03\n",
      "Epoch 350500, Train loss: 2.533e+02, Test loss: 1.098e+03, MSE(e): 4.949e-06, MSE(pi1): 1.191e-02, MSE(pi2): 1.410e-06, MSE(pi3): 8.475e-04\n",
      "Epoch 350600, Train loss: 3.009e+02, Test loss: 1.213e+03, MSE(e): 5.999e-06, MSE(pi1): 1.433e-02, MSE(pi2): 1.660e-06, MSE(pi3): 9.767e-04\n",
      "Epoch 350700, Train loss: 2.386e+02, Test loss: 1.136e+03, MSE(e): 3.986e-06, MSE(pi1): 1.027e-02, MSE(pi2): 1.220e-06, MSE(pi3): 9.609e-04\n",
      "Epoch 350800, Train loss: 1.492e+02, Test loss: 1.011e+03, MSE(e): 1.759e-06, MSE(pi1): 3.701e-03, MSE(pi2): 8.843e-07, MSE(pi3): 9.455e-04\n",
      "Epoch 350900, Train loss: 1.762e+03, Test loss: 2.849e+03, MSE(e): 1.577e-04, MSE(pi1): 5.649e-03, MSE(pi2): 7.363e-05, MSE(pi3): 1.284e-03\n",
      "Epoch 351000, Train loss: 1.032e+03, Test loss: 1.638e+03, MSE(e): 8.848e-05, MSE(pi1): 3.872e-03, MSE(pi2): 4.043e-05, MSE(pi3): 1.082e-03\n",
      "Epoch 351100, Train loss: 1.134e+03, Test loss: 2.781e+03, MSE(e): 8.515e-05, MSE(pi1): 1.664e-02, MSE(pi2): 4.102e-05, MSE(pi3): 1.164e-03\n",
      "Epoch 351200, Train loss: 5.026e+02, Test loss: 1.245e+03, MSE(e): 1.867e-05, MSE(pi1): 2.227e-02, MSE(pi2): 7.037e-06, MSE(pi3): 9.319e-04\n",
      "Epoch 351300, Train loss: 5.642e+02, Test loss: 1.587e+03, MSE(e): 1.994e-05, MSE(pi1): 2.328e-02, MSE(pi2): 6.654e-06, MSE(pi3): 1.319e-03\n",
      "Epoch 351400, Train loss: 2.832e+02, Test loss: 1.051e+03, MSE(e): 1.362e-05, MSE(pi1): 5.441e-03, MSE(pi2): 6.104e-06, MSE(pi3): 9.262e-04\n",
      "Epoch 351500, Train loss: 3.218e+02, Test loss: 1.416e+03, MSE(e): 1.598e-05, MSE(pi1): 7.014e-03, MSE(pi2): 7.302e-06, MSE(pi3): 9.191e-04\n",
      "Epoch 351600, Train loss: 2.533e+02, Test loss: 1.174e+03, MSE(e): 4.861e-06, MSE(pi1): 1.071e-02, MSE(pi2): 1.705e-06, MSE(pi3): 9.760e-04\n",
      "Epoch 351700, Train loss: 1.600e+02, Test loss: 9.806e+02, MSE(e): 2.044e-06, MSE(pi1): 4.372e-03, MSE(pi2): 9.224e-07, MSE(pi3): 9.580e-04\n",
      "Epoch 351800, Train loss: 2.201e+03, Test loss: 2.453e+03, MSE(e): 2.029e-04, MSE(pi1): 5.762e-03, MSE(pi2): 9.697e-05, MSE(pi3): 1.143e-03\n",
      "Epoch 351900, Train loss: 1.574e+02, Test loss: 9.516e+02, MSE(e): 2.259e-06, MSE(pi1): 4.041e-03, MSE(pi2): 1.133e-06, MSE(pi3): 9.445e-04\n",
      "Epoch 352000, Train loss: 2.127e+02, Test loss: 1.132e+03, MSE(e): 4.398e-06, MSE(pi1): 6.415e-03, MSE(pi2): 1.729e-06, MSE(pi3): 1.046e-03\n",
      "Epoch 352100, Train loss: 1.706e+02, Test loss: 1.037e+03, MSE(e): 2.357e-06, MSE(pi1): 4.983e-03, MSE(pi2): 9.773e-07, MSE(pi3): 9.716e-04\n",
      "Epoch 352200, Train loss: 1.617e+03, Test loss: 2.589e+03, MSE(e): 1.108e-04, MSE(pi1): 4.270e-02, MSE(pi2): 5.145e-05, MSE(pi3): 8.200e-04\n",
      "Epoch 352300, Train loss: 2.053e+02, Test loss: 1.057e+03, MSE(e): 5.375e-06, MSE(pi1): 5.183e-03, MSE(pi2): 2.784e-06, MSE(pi3): 9.973e-04\n",
      "Epoch 352400, Train loss: 5.293e+02, Test loss: 1.588e+03, MSE(e): 1.355e-05, MSE(pi1): 2.916e-02, MSE(pi2): 3.847e-06, MSE(pi3): 1.022e-03\n",
      "Epoch 352500, Train loss: 3.429e+02, Test loss: 1.340e+03, MSE(e): 1.172e-05, MSE(pi1): 1.141e-02, MSE(pi2): 5.005e-06, MSE(pi3): 1.116e-03\n",
      "Epoch 352600, Train loss: 1.836e+02, Test loss: 1.036e+03, MSE(e): 3.506e-06, MSE(pi1): 5.363e-03, MSE(pi2): 1.348e-06, MSE(pi3): 9.496e-04\n",
      "Epoch 352700, Train loss: 2.174e+02, Test loss: 1.051e+03, MSE(e): 3.505e-06, MSE(pi1): 8.245e-03, MSE(pi2): 1.143e-06, MSE(pi3): 9.987e-04\n",
      "Epoch 352800, Train loss: 1.683e+02, Test loss: 1.030e+03, MSE(e): 2.510e-06, MSE(pi1): 5.199e-03, MSE(pi2): 1.067e-06, MSE(pi3): 9.124e-04\n",
      "Epoch 352900, Train loss: 1.189e+03, Test loss: 2.359e+03, MSE(e): 9.091e-05, MSE(pi1): 1.583e-02, MSE(pi2): 4.170e-05, MSE(pi3): 1.218e-03\n",
      "Epoch 353000, Train loss: 2.051e+02, Test loss: 9.871e+02, MSE(e): 3.407e-06, MSE(pi1): 6.561e-03, MSE(pi2): 1.217e-06, MSE(pi3): 1.055e-03\n",
      "Epoch 353100, Train loss: 3.604e+02, Test loss: 1.248e+03, MSE(e): 1.615e-05, MSE(pi1): 8.772e-03, MSE(pi2): 7.111e-06, MSE(pi3): 1.111e-03\n",
      "Epoch 353200, Train loss: 9.232e+02, Test loss: 2.570e+03, MSE(e): 6.526e-05, MSE(pi1): 1.772e-02, MSE(pi2): 2.979e-05, MSE(pi3): 9.338e-04\n",
      "Epoch 353300, Train loss: 5.460e+02, Test loss: 1.793e+03, MSE(e): 2.338e-05, MSE(pi1): 2.213e-02, MSE(pi2): 8.666e-06, MSE(pi3): 9.089e-04\n",
      "Epoch 353400, Train loss: 1.023e+03, Test loss: 1.608e+03, MSE(e): 8.476e-05, MSE(pi1): 8.075e-03, MSE(pi2): 3.777e-05, MSE(pi3): 9.422e-04\n",
      "Epoch 353500, Train loss: 3.720e+02, Test loss: 1.268e+03, MSE(e): 1.676e-05, MSE(pi1): 9.075e-03, MSE(pi2): 7.234e-06, MSE(pi3): 1.136e-03\n",
      "Epoch 353600, Train loss: 2.082e+02, Test loss: 1.053e+03, MSE(e): 2.986e-06, MSE(pi1): 8.678e-03, MSE(pi2): 1.043e-06, MSE(pi3): 9.153e-04\n",
      "Epoch 353700, Train loss: 2.619e+02, Test loss: 1.189e+03, MSE(e): 5.549e-06, MSE(pi1): 1.181e-02, MSE(pi2): 1.652e-06, MSE(pi3): 8.835e-04\n",
      "Epoch 353800, Train loss: 2.015e+02, Test loss: 1.079e+03, MSE(e): 3.210e-06, MSE(pi1): 8.008e-03, MSE(pi2): 1.132e-06, MSE(pi3): 8.934e-04\n",
      "Epoch 353900, Train loss: 2.870e+02, Test loss: 1.056e+03, MSE(e): 6.558e-06, MSE(pi1): 1.262e-02, MSE(pi2): 1.853e-06, MSE(pi3): 9.520e-04\n",
      "Epoch 354000, Train loss: 3.433e+02, Test loss: 1.238e+03, MSE(e): 9.989e-06, MSE(pi1): 1.444e-02, MSE(pi2): 3.669e-06, MSE(pi3): 9.898e-04\n",
      "Epoch 354100, Train loss: 2.018e+02, Test loss: 1.034e+03, MSE(e): 3.998e-06, MSE(pi1): 7.079e-03, MSE(pi2): 1.597e-06, MSE(pi3): 9.100e-04\n",
      "Epoch 354200, Train loss: 1.512e+02, Test loss: 9.812e+02, MSE(e): 1.725e-06, MSE(pi1): 4.185e-03, MSE(pi2): 8.522e-07, MSE(pi3): 9.207e-04\n",
      "Epoch 354300, Train loss: 2.027e+02, Test loss: 1.094e+03, MSE(e): 3.839e-06, MSE(pi1): 6.285e-03, MSE(pi2): 1.743e-06, MSE(pi3): 1.015e-03\n",
      "Epoch 354400, Train loss: 2.667e+02, Test loss: 1.207e+03, MSE(e): 6.255e-06, MSE(pi1): 1.116e-02, MSE(pi2): 2.628e-06, MSE(pi3): 9.252e-04\n",
      "Epoch 354500, Train loss: 3.514e+02, Test loss: 1.388e+03, MSE(e): 1.268e-05, MSE(pi1): 1.360e-02, MSE(pi2): 4.501e-06, MSE(pi3): 8.864e-04\n",
      "Epoch 354600, Train loss: 5.630e+02, Test loss: 1.295e+03, MSE(e): 2.134e-05, MSE(pi1): 2.610e-02, MSE(pi2): 8.234e-06, MSE(pi3): 8.860e-04\n",
      "Epoch 354700, Train loss: 2.355e+02, Test loss: 1.133e+03, MSE(e): 6.107e-06, MSE(pi1): 8.395e-03, MSE(pi2): 2.283e-06, MSE(pi3): 9.050e-04\n",
      "Epoch 354800, Train loss: 2.542e+02, Test loss: 1.138e+03, MSE(e): 4.486e-06, MSE(pi1): 1.041e-02, MSE(pi2): 1.323e-06, MSE(pi3): 1.052e-03\n",
      "Epoch 354900, Train loss: 2.577e+02, Test loss: 1.210e+03, MSE(e): 4.166e-06, MSE(pi1): 1.202e-02, MSE(pi2): 1.366e-06, MSE(pi3): 9.583e-04\n",
      "Epoch 355000, Train loss: 1.718e+02, Test loss: 1.004e+03, MSE(e): 4.005e-06, MSE(pi1): 3.837e-03, MSE(pi2): 1.692e-06, MSE(pi3): 9.336e-04\n",
      "Epoch 355100, Train loss: 4.179e+02, Test loss: 1.054e+03, MSE(e): 2.654e-05, MSE(pi1): 6.030e-03, MSE(pi2): 1.261e-05, MSE(pi3): 9.210e-04\n",
      "Epoch 355200, Train loss: 5.328e+02, Test loss: 1.945e+03, MSE(e): 3.941e-05, MSE(pi1): 3.968e-03, MSE(pi2): 1.894e-05, MSE(pi3): 9.904e-04\n",
      "Epoch 355300, Train loss: 2.829e+02, Test loss: 1.178e+03, MSE(e): 4.955e-06, MSE(pi1): 1.215e-02, MSE(pi2): 1.647e-06, MSE(pi3): 1.118e-03\n",
      "Epoch 355400, Train loss: 1.458e+03, Test loss: 2.033e+03, MSE(e): 1.245e-04, MSE(pi1): 1.200e-02, MSE(pi2): 5.973e-05, MSE(pi3): 9.285e-04\n",
      "Epoch 355500, Train loss: 5.087e+02, Test loss: 1.279e+03, MSE(e): 1.185e-05, MSE(pi1): 2.749e-02, MSE(pi2): 3.086e-06, MSE(pi3): 1.153e-03\n",
      "Epoch 355600, Train loss: 2.434e+02, Test loss: 9.922e+02, MSE(e): 5.079e-06, MSE(pi1): 1.082e-02, MSE(pi2): 1.462e-06, MSE(pi3): 8.440e-04\n",
      "Epoch 355700, Train loss: 4.922e+02, Test loss: 1.434e+03, MSE(e): 1.342e-05, MSE(pi1): 2.708e-02, MSE(pi2): 3.231e-06, MSE(pi3): 8.711e-04\n",
      "Epoch 355800, Train loss: 1.773e+02, Test loss: 9.647e+02, MSE(e): 3.370e-06, MSE(pi1): 5.198e-03, MSE(pi2): 1.718e-06, MSE(pi3): 9.157e-04\n",
      "Epoch 355900, Train loss: 2.915e+02, Test loss: 1.100e+03, MSE(e): 8.760e-06, MSE(pi1): 1.084e-02, MSE(pi2): 3.717e-06, MSE(pi3): 9.551e-04\n",
      "Epoch 356000, Train loss: 1.838e+02, Test loss: 1.063e+03, MSE(e): 2.639e-06, MSE(pi1): 5.753e-03, MSE(pi2): 1.034e-06, MSE(pi3): 9.984e-04\n",
      "Epoch 356100, Train loss: 1.450e+02, Test loss: 9.740e+02, MSE(e): 1.624e-06, MSE(pi1): 3.542e-03, MSE(pi2): 8.113e-07, MSE(pi3): 9.339e-04\n",
      "Epoch 356200, Train loss: 1.800e+03, Test loss: 3.154e+03, MSE(e): 1.647e-04, MSE(pi1): 5.055e-03, MSE(pi2): 7.733e-05, MSE(pi3): 1.023e-03\n",
      "Epoch 356300, Train loss: 7.734e+02, Test loss: 1.882e+03, MSE(e): 4.651e-05, MSE(pi1): 2.121e-02, MSE(pi2): 1.916e-05, MSE(pi3): 9.625e-04\n",
      "Epoch 356400, Train loss: 4.362e+02, Test loss: 1.404e+03, MSE(e): 2.879e-05, MSE(pi1): 4.421e-03, MSE(pi2): 1.448e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 356500, Train loss: 2.131e+02, Test loss: 1.053e+03, MSE(e): 3.195e-06, MSE(pi1): 8.606e-03, MSE(pi2): 1.096e-06, MSE(pi3): 9.509e-04\n",
      "Epoch 356600, Train loss: 3.450e+02, Test loss: 1.318e+03, MSE(e): 6.436e-06, MSE(pi1): 1.738e-02, MSE(pi2): 1.704e-06, MSE(pi3): 1.069e-03\n",
      "Epoch 356700, Train loss: 1.817e+02, Test loss: 1.074e+03, MSE(e): 3.647e-06, MSE(pi1): 5.003e-03, MSE(pi2): 1.639e-06, MSE(pi3): 9.516e-04\n",
      "Epoch 356800, Train loss: 3.955e+02, Test loss: 1.292e+03, MSE(e): 1.281e-05, MSE(pi1): 1.790e-02, MSE(pi2): 3.398e-06, MSE(pi3): 8.840e-04\n",
      "Epoch 356900, Train loss: 2.527e+02, Test loss: 1.187e+03, MSE(e): 4.457e-06, MSE(pi1): 1.027e-02, MSE(pi2): 1.432e-06, MSE(pi3): 1.054e-03\n",
      "Epoch 357000, Train loss: 4.075e+02, Test loss: 1.162e+03, MSE(e): 8.974e-06, MSE(pi1): 1.840e-02, MSE(pi2): 2.297e-06, MSE(pi3): 1.337e-03\n",
      "Epoch 357100, Train loss: 7.504e+02, Test loss: 1.623e+03, MSE(e): 5.094e-05, MSE(pi1): 1.603e-02, MSE(pi2): 2.480e-05, MSE(pi3): 8.073e-04\n",
      "Epoch 357200, Train loss: 1.558e+02, Test loss: 1.007e+03, MSE(e): 2.069e-06, MSE(pi1): 3.819e-03, MSE(pi2): 9.494e-07, MSE(pi3): 9.687e-04\n",
      "Epoch 357300, Train loss: 3.950e+02, Test loss: 1.148e+03, MSE(e): 1.609e-05, MSE(pi1): 1.479e-02, MSE(pi2): 8.152e-06, MSE(pi3): 8.615e-04\n",
      "Epoch 357400, Train loss: 4.970e+02, Test loss: 1.416e+03, MSE(e): 3.205e-05, MSE(pi1): 7.558e-03, MSE(pi2): 1.497e-05, MSE(pi3): 1.009e-03\n",
      "Epoch 357500, Train loss: 1.321e+03, Test loss: 2.644e+03, MSE(e): 1.115e-04, MSE(pi1): 1.136e-02, MSE(pi2): 5.194e-05, MSE(pi3): 9.192e-04\n",
      "Epoch 357600, Train loss: 2.667e+02, Test loss: 1.165e+03, MSE(e): 4.894e-06, MSE(pi1): 1.277e-02, MSE(pi2): 1.824e-06, MSE(pi3): 9.000e-04\n",
      "Epoch 357700, Train loss: 9.402e+02, Test loss: 2.134e+03, MSE(e): 6.903e-05, MSE(pi1): 1.302e-02, MSE(pi2): 3.503e-05, MSE(pi3): 1.197e-03\n",
      "Epoch 357800, Train loss: 4.584e+02, Test loss: 1.730e+03, MSE(e): 3.096e-05, MSE(pi1): 5.261e-03, MSE(pi2): 1.502e-05, MSE(pi3): 9.611e-04\n",
      "Epoch 357900, Train loss: 2.424e+02, Test loss: 1.116e+03, MSE(e): 3.908e-06, MSE(pi1): 1.074e-02, MSE(pi2): 1.231e-06, MSE(pi3): 9.588e-04\n",
      "Epoch 358000, Train loss: 1.859e+02, Test loss: 1.028e+03, MSE(e): 2.413e-06, MSE(pi1): 6.660e-03, MSE(pi2): 9.765e-07, MSE(pi3): 9.515e-04\n",
      "Epoch 358100, Train loss: 3.360e+02, Test loss: 1.240e+03, MSE(e): 9.908e-06, MSE(pi1): 1.202e-02, MSE(pi2): 3.802e-06, MSE(pi3): 1.167e-03\n",
      "Epoch 358200, Train loss: 1.604e+02, Test loss: 9.755e+02, MSE(e): 2.220e-06, MSE(pi1): 4.505e-03, MSE(pi2): 1.019e-06, MSE(pi3): 9.310e-04\n",
      "Epoch 358300, Train loss: 2.389e+02, Test loss: 1.149e+03, MSE(e): 4.154e-06, MSE(pi1): 1.091e-02, MSE(pi2): 1.179e-06, MSE(pi3): 8.821e-04\n",
      "Epoch 358400, Train loss: 3.377e+02, Test loss: 9.851e+02, MSE(e): 8.801e-06, MSE(pi1): 1.534e-02, MSE(pi2): 3.202e-06, MSE(pi3): 9.634e-04\n",
      "Epoch 358500, Train loss: 2.741e+02, Test loss: 1.128e+03, MSE(e): 5.063e-06, MSE(pi1): 1.326e-02, MSE(pi2): 1.507e-06, MSE(pi3): 9.086e-04\n",
      "Epoch 358600, Train loss: 1.962e+03, Test loss: 2.998e+03, MSE(e): 1.564e-04, MSE(pi1): 2.985e-02, MSE(pi2): 7.562e-05, MSE(pi3): 9.905e-04\n",
      "Epoch 358700, Train loss: 1.820e+03, Test loss: 3.126e+03, MSE(e): 1.598e-04, MSE(pi1): 1.321e-02, MSE(pi2): 7.815e-05, MSE(pi3): 8.965e-04\n",
      "Epoch 358800, Train loss: 2.351e+02, Test loss: 1.159e+03, MSE(e): 3.999e-06, MSE(pi1): 8.985e-03, MSE(pi2): 1.319e-06, MSE(pi3): 1.053e-03\n",
      "Epoch 358900, Train loss: 3.268e+02, Test loss: 1.135e+03, MSE(e): 6.554e-06, MSE(pi1): 1.754e-02, MSE(pi2): 2.318e-06, MSE(pi3): 8.580e-04\n",
      "Epoch 359000, Train loss: 2.554e+02, Test loss: 1.214e+03, MSE(e): 7.447e-06, MSE(pi1): 7.582e-03, MSE(pi2): 2.989e-06, MSE(pi3): 1.051e-03\n",
      "Epoch 359100, Train loss: 1.172e+03, Test loss: 1.983e+03, MSE(e): 9.866e-05, MSE(pi1): 7.577e-03, MSE(pi2): 4.651e-05, MSE(pi3): 1.095e-03\n",
      "Epoch 359200, Train loss: 2.699e+03, Test loss: 3.898e+03, MSE(e): 2.364e-04, MSE(pi1): 2.529e-02, MSE(pi2): 1.166e-04, MSE(pi3): 8.106e-04\n",
      "Epoch 359300, Train loss: 3.232e+02, Test loss: 1.233e+03, MSE(e): 5.903e-06, MSE(pi1): 1.450e-02, MSE(pi2): 1.504e-06, MSE(pi3): 1.192e-03\n",
      "Epoch 359400, Train loss: 2.489e+02, Test loss: 1.201e+03, MSE(e): 4.554e-06, MSE(pi1): 9.988e-03, MSE(pi2): 1.715e-06, MSE(pi3): 1.035e-03\n",
      "Epoch 359500, Train loss: 2.428e+02, Test loss: 1.107e+03, MSE(e): 3.985e-06, MSE(pi1): 1.129e-02, MSE(pi2): 1.263e-06, MSE(pi3): 9.008e-04\n",
      "Epoch 359600, Train loss: 1.997e+02, Test loss: 9.861e+02, MSE(e): 4.910e-06, MSE(pi1): 5.162e-03, MSE(pi2): 1.922e-06, MSE(pi3): 9.899e-04\n",
      "Epoch 359700, Train loss: 2.475e+02, Test loss: 1.036e+03, MSE(e): 5.396e-06, MSE(pi1): 9.078e-03, MSE(pi2): 1.715e-06, MSE(pi3): 1.028e-03\n",
      "Epoch 359800, Train loss: 1.879e+02, Test loss: 1.073e+03, MSE(e): 2.591e-06, MSE(pi1): 6.851e-03, MSE(pi2): 9.700e-07, MSE(pi3): 9.346e-04\n",
      "Epoch 359900, Train loss: 5.649e+02, Test loss: 1.259e+03, MSE(e): 3.444e-05, MSE(pi1): 1.197e-02, MSE(pi2): 1.357e-05, MSE(pi3): 1.008e-03\n",
      "Epoch 360000, Train loss: 4.528e+02, Test loss: 1.642e+03, MSE(e): 1.105e-05, MSE(pi1): 2.269e-02, MSE(pi2): 3.757e-06, MSE(pi3): 1.154e-03\n",
      "Epoch 360100, Train loss: 3.598e+02, Test loss: 1.129e+03, MSE(e): 1.143e-05, MSE(pi1): 1.568e-02, MSE(pi2): 4.946e-06, MSE(pi3): 8.875e-04\n",
      "Epoch 360200, Train loss: 1.015e+03, Test loss: 1.795e+03, MSE(e): 7.662e-05, MSE(pi1): 1.642e-02, MSE(pi2): 3.808e-05, MSE(pi3): 8.426e-04\n",
      "Epoch 360300, Train loss: 3.107e+02, Test loss: 1.103e+03, MSE(e): 1.199e-05, MSE(pi1): 1.031e-02, MSE(pi2): 4.038e-06, MSE(pi3): 8.766e-04\n",
      "Epoch 360400, Train loss: 3.075e+02, Test loss: 1.025e+03, MSE(e): 6.532e-06, MSE(pi1): 1.190e-02, MSE(pi2): 1.824e-06, MSE(pi3): 1.232e-03\n",
      "Epoch 360500, Train loss: 2.466e+02, Test loss: 1.086e+03, MSE(e): 4.293e-06, MSE(pi1): 1.088e-02, MSE(pi2): 1.395e-06, MSE(pi3): 9.482e-04\n",
      "Epoch 360600, Train loss: 2.020e+02, Test loss: 1.055e+03, MSE(e): 3.167e-06, MSE(pi1): 7.104e-03, MSE(pi2): 1.069e-06, MSE(pi3): 9.924e-04\n",
      "Epoch 360700, Train loss: 2.147e+02, Test loss: 1.012e+03, MSE(e): 4.743e-06, MSE(pi1): 7.423e-03, MSE(pi2): 2.483e-06, MSE(pi3): 9.303e-04\n",
      "Epoch 360800, Train loss: 8.829e+02, Test loss: 1.818e+03, MSE(e): 6.492e-05, MSE(pi1): 1.315e-02, MSE(pi2): 2.893e-05, MSE(pi3): 1.022e-03\n",
      "Epoch 360900, Train loss: 6.744e+02, Test loss: 2.023e+03, MSE(e): 4.785e-05, MSE(pi1): 8.239e-03, MSE(pi2): 2.259e-05, MSE(pi3): 1.136e-03\n",
      "Epoch 361000, Train loss: 8.300e+02, Test loss: 1.724e+03, MSE(e): 4.680e-05, MSE(pi1): 2.539e-02, MSE(pi2): 1.673e-05, MSE(pi3): 1.081e-03\n",
      "Epoch 361100, Train loss: 3.596e+02, Test loss: 1.256e+03, MSE(e): 7.002e-06, MSE(pi1): 1.756e-02, MSE(pi2): 1.885e-06, MSE(pi3): 1.140e-03\n",
      "Epoch 361200, Train loss: 3.822e+02, Test loss: 1.315e+03, MSE(e): 9.542e-06, MSE(pi1): 1.874e-02, MSE(pi2): 2.868e-06, MSE(pi3): 9.936e-04\n",
      "Epoch 361300, Train loss: 1.794e+02, Test loss: 1.055e+03, MSE(e): 2.293e-06, MSE(pi1): 5.891e-03, MSE(pi2): 9.498e-07, MSE(pi3): 9.751e-04\n",
      "Epoch 361400, Train loss: 1.570e+02, Test loss: 1.021e+03, MSE(e): 2.400e-06, MSE(pi1): 3.813e-03, MSE(pi2): 1.164e-06, MSE(pi3): 9.485e-04\n",
      "Epoch 361500, Train loss: 1.468e+02, Test loss: 9.824e+02, MSE(e): 1.855e-06, MSE(pi1): 3.442e-03, MSE(pi2): 9.515e-07, MSE(pi3): 9.388e-04\n",
      "Epoch 361600, Train loss: 4.015e+02, Test loss: 1.178e+03, MSE(e): 2.487e-05, MSE(pi1): 6.024e-03, MSE(pi2): 1.242e-05, MSE(pi3): 9.252e-04\n",
      "Epoch 361700, Train loss: 1.973e+03, Test loss: 3.580e+03, MSE(e): 1.773e-04, MSE(pi1): 9.664e-03, MSE(pi2): 8.238e-05, MSE(pi3): 1.036e-03\n",
      "Epoch 361800, Train loss: 2.965e+03, Test loss: 5.342e+03, MSE(e): 2.652e-04, MSE(pi1): 1.768e-02, MSE(pi2): 1.287e-04, MSE(pi3): 1.369e-03\n",
      "Epoch 361900, Train loss: 2.699e+02, Test loss: 1.001e+03, MSE(e): 8.895e-06, MSE(pi1): 7.986e-03, MSE(pi2): 3.950e-06, MSE(pi3): 1.011e-03\n",
      "Epoch 362000, Train loss: 4.490e+02, Test loss: 1.130e+03, MSE(e): 2.946e-05, MSE(pi1): 5.974e-03, MSE(pi2): 1.353e-05, MSE(pi3): 9.464e-04\n",
      "Epoch 362100, Train loss: 7.008e+02, Test loss: 1.898e+03, MSE(e): 5.209e-05, MSE(pi1): 7.317e-03, MSE(pi2): 2.525e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 362200, Train loss: 3.603e+02, Test loss: 1.450e+03, MSE(e): 1.421e-05, MSE(pi1): 1.207e-02, MSE(pi2): 5.757e-06, MSE(pi3): 9.752e-04\n",
      "Epoch 362300, Train loss: 2.055e+03, Test loss: 4.116e+03, MSE(e): 1.736e-04, MSE(pi1): 1.876e-02, MSE(pi2): 8.302e-05, MSE(pi3): 1.308e-03\n",
      "Epoch 362400, Train loss: 3.516e+02, Test loss: 1.117e+03, MSE(e): 1.935e-05, MSE(pi1): 6.651e-03, MSE(pi2): 8.693e-06, MSE(pi3): 9.164e-04\n",
      "Epoch 362500, Train loss: 2.188e+02, Test loss: 1.191e+03, MSE(e): 7.705e-06, MSE(pi1): 4.370e-03, MSE(pi2): 3.539e-06, MSE(pi3): 9.803e-04\n",
      "Epoch 362600, Train loss: 2.482e+02, Test loss: 1.036e+03, MSE(e): 4.602e-06, MSE(pi1): 9.733e-03, MSE(pi2): 1.335e-06, MSE(pi3): 1.048e-03\n",
      "Epoch 362700, Train loss: 1.858e+02, Test loss: 1.035e+03, MSE(e): 2.462e-06, MSE(pi1): 7.261e-03, MSE(pi2): 8.905e-07, MSE(pi3): 8.854e-04\n",
      "Epoch 362800, Train loss: 5.722e+02, Test loss: 1.201e+03, MSE(e): 3.374e-05, MSE(pi1): 1.443e-02, MSE(pi2): 1.839e-05, MSE(pi3): 9.050e-04\n",
      "Epoch 362900, Train loss: 1.927e+02, Test loss: 1.063e+03, MSE(e): 3.111e-06, MSE(pi1): 6.629e-03, MSE(pi2): 1.250e-06, MSE(pi3): 9.530e-04\n",
      "Epoch 363000, Train loss: 1.678e+02, Test loss: 9.555e+02, MSE(e): 3.089e-06, MSE(pi1): 4.568e-03, MSE(pi2): 1.424e-06, MSE(pi3): 9.120e-04\n",
      "Epoch 363100, Train loss: 3.742e+02, Test loss: 1.465e+03, MSE(e): 2.087e-05, MSE(pi1): 7.024e-03, MSE(pi2): 9.427e-06, MSE(pi3): 9.517e-04\n",
      "Epoch 363200, Train loss: 2.060e+02, Test loss: 9.952e+02, MSE(e): 4.269e-06, MSE(pi1): 6.246e-03, MSE(pi2): 1.528e-06, MSE(pi3): 1.009e-03\n",
      "Epoch 363300, Train loss: 2.859e+02, Test loss: 1.362e+03, MSE(e): 1.449e-05, MSE(pi1): 4.496e-03, MSE(pi2): 6.419e-06, MSE(pi3): 9.603e-04\n",
      "Epoch 363400, Train loss: 5.043e+02, Test loss: 1.381e+03, MSE(e): 2.245e-05, MSE(pi1): 1.796e-02, MSE(pi2): 9.570e-06, MSE(pi3): 1.002e-03\n",
      "Epoch 363500, Train loss: 4.922e+02, Test loss: 1.378e+03, MSE(e): 1.938e-05, MSE(pi1): 2.139e-02, MSE(pi2): 9.183e-06, MSE(pi3): 8.446e-04\n",
      "Epoch 363600, Train loss: 2.618e+02, Test loss: 1.181e+03, MSE(e): 6.077e-06, MSE(pi1): 9.576e-03, MSE(pi2): 2.178e-06, MSE(pi3): 1.053e-03\n",
      "Epoch 363700, Train loss: 2.939e+02, Test loss: 1.159e+03, MSE(e): 6.367e-06, MSE(pi1): 1.374e-02, MSE(pi2): 2.372e-06, MSE(pi3): 9.280e-04\n",
      "Epoch 363800, Train loss: 3.968e+02, Test loss: 1.154e+03, MSE(e): 1.885e-05, MSE(pi1): 1.212e-02, MSE(pi2): 9.120e-06, MSE(pi3): 8.708e-04\n",
      "Epoch 363900, Train loss: 2.189e+02, Test loss: 9.654e+02, MSE(e): 8.794e-06, MSE(pi1): 4.090e-03, MSE(pi2): 4.341e-06, MSE(pi3): 9.003e-04\n",
      "Epoch 364000, Train loss: 2.753e+02, Test loss: 1.170e+03, MSE(e): 7.496e-06, MSE(pi1): 1.121e-02, MSE(pi2): 2.796e-06, MSE(pi3): 8.823e-04\n",
      "Epoch 364100, Train loss: 2.785e+02, Test loss: 1.214e+03, MSE(e): 5.029e-06, MSE(pi1): 1.295e-02, MSE(pi2): 1.455e-06, MSE(pi3): 9.867e-04\n",
      "Epoch 364200, Train loss: 2.698e+02, Test loss: 1.221e+03, MSE(e): 4.280e-06, MSE(pi1): 1.247e-02, MSE(pi2): 1.185e-06, MSE(pi3): 1.023e-03\n",
      "Epoch 364300, Train loss: 3.516e+02, Test loss: 1.102e+03, MSE(e): 1.853e-05, MSE(pi1): 7.520e-03, MSE(pi2): 9.052e-06, MSE(pi3): 9.115e-04\n",
      "Epoch 364400, Train loss: 1.311e+03, Test loss: 2.879e+03, MSE(e): 7.865e-05, MSE(pi1): 3.699e-02, MSE(pi2): 3.501e-05, MSE(pi3): 1.544e-03\n",
      "Epoch 364500, Train loss: 3.394e+02, Test loss: 1.031e+03, MSE(e): 9.429e-06, MSE(pi1): 1.448e-02, MSE(pi2): 2.955e-06, MSE(pi3): 1.003e-03\n",
      "Epoch 364600, Train loss: 1.501e+02, Test loss: 9.887e+02, MSE(e): 1.874e-06, MSE(pi1): 3.809e-03, MSE(pi2): 8.842e-07, MSE(pi3): 9.323e-04\n",
      "Epoch 364700, Train loss: 2.721e+02, Test loss: 1.106e+03, MSE(e): 4.620e-06, MSE(pi1): 1.159e-02, MSE(pi2): 1.219e-06, MSE(pi3): 1.100e-03\n",
      "Epoch 364800, Train loss: 1.593e+02, Test loss: 1.016e+03, MSE(e): 1.871e-06, MSE(pi1): 5.074e-03, MSE(pi2): 8.642e-07, MSE(pi3): 8.985e-04\n",
      "Epoch 364900, Train loss: 3.238e+02, Test loss: 1.220e+03, MSE(e): 7.340e-06, MSE(pi1): 1.418e-02, MSE(pi2): 1.966e-06, MSE(pi3): 1.087e-03\n",
      "Epoch 365000, Train loss: 3.132e+02, Test loss: 1.034e+03, MSE(e): 1.684e-05, MSE(pi1): 5.300e-03, MSE(pi2): 8.242e-06, MSE(pi3): 9.180e-04\n",
      "Epoch 365100, Train loss: 4.942e+03, Test loss: 6.640e+03, MSE(e): 4.706e-04, MSE(pi1): 1.204e-02, MSE(pi2): 2.252e-04, MSE(pi3): 1.145e-03\n",
      "Epoch 365200, Train loss: 1.741e+02, Test loss: 1.057e+03, MSE(e): 2.616e-06, MSE(pi1): 4.796e-03, MSE(pi2): 1.189e-06, MSE(pi3): 9.993e-04\n",
      "Epoch 365300, Train loss: 2.141e+02, Test loss: 1.195e+03, MSE(e): 4.951e-06, MSE(pi1): 7.310e-03, MSE(pi2): 2.039e-06, MSE(pi3): 9.153e-04\n",
      "Epoch 365400, Train loss: 5.205e+02, Test loss: 1.544e+03, MSE(e): 1.616e-05, MSE(pi1): 2.189e-02, MSE(pi2): 5.050e-06, MSE(pi3): 1.401e-03\n",
      "Epoch 365500, Train loss: 2.656e+02, Test loss: 1.103e+03, MSE(e): 4.349e-06, MSE(pi1): 1.373e-02, MSE(pi2): 1.211e-06, MSE(pi3): 8.482e-04\n",
      "Epoch 365600, Train loss: 3.979e+02, Test loss: 1.395e+03, MSE(e): 7.106e-06, MSE(pi1): 2.413e-02, MSE(pi2): 1.517e-06, MSE(pi3): 8.554e-04\n",
      "Epoch 365700, Train loss: 1.234e+03, Test loss: 1.787e+03, MSE(e): 9.696e-05, MSE(pi1): 1.783e-02, MSE(pi2): 4.409e-05, MSE(pi3): 8.607e-04\n",
      "Epoch 365800, Train loss: 4.742e+02, Test loss: 1.451e+03, MSE(e): 9.437e-06, MSE(pi1): 2.531e-02, MSE(pi2): 2.443e-06, MSE(pi3): 1.268e-03\n",
      "Epoch 365900, Train loss: 2.315e+02, Test loss: 1.057e+03, MSE(e): 4.466e-06, MSE(pi1): 8.920e-03, MSE(pi2): 1.529e-06, MSE(pi3): 9.766e-04\n",
      "Epoch 366000, Train loss: 3.651e+02, Test loss: 1.015e+03, MSE(e): 9.202e-06, MSE(pi1): 1.697e-02, MSE(pi2): 3.131e-06, MSE(pi3): 1.034e-03\n",
      "Epoch 366100, Train loss: 2.084e+02, Test loss: 1.007e+03, MSE(e): 4.470e-06, MSE(pi1): 7.553e-03, MSE(pi2): 2.115e-06, MSE(pi3): 8.814e-04\n",
      "Epoch 366200, Train loss: 2.244e+02, Test loss: 1.076e+03, MSE(e): 4.106e-06, MSE(pi1): 8.188e-03, MSE(pi2): 1.228e-06, MSE(pi3): 1.015e-03\n",
      "Epoch 366300, Train loss: 7.378e+02, Test loss: 2.053e+03, MSE(e): 4.615e-05, MSE(pi1): 1.608e-02, MSE(pi2): 2.064e-05, MSE(pi3): 1.155e-03\n",
      "Epoch 366400, Train loss: 4.841e+02, Test loss: 1.585e+03, MSE(e): 2.972e-05, MSE(pi1): 7.930e-03, MSE(pi2): 1.442e-05, MSE(pi3): 1.076e-03\n",
      "Epoch 366500, Train loss: 4.187e+02, Test loss: 1.104e+03, MSE(e): 8.819e-06, MSE(pi1): 2.396e-02, MSE(pi2): 1.969e-06, MSE(pi3): 9.085e-04\n",
      "Epoch 366600, Train loss: 2.268e+02, Test loss: 1.163e+03, MSE(e): 5.074e-06, MSE(pi1): 7.813e-03, MSE(pi2): 2.082e-06, MSE(pi3): 9.789e-04\n",
      "Epoch 366700, Train loss: 2.531e+02, Test loss: 1.027e+03, MSE(e): 8.998e-06, MSE(pi1): 6.959e-03, MSE(pi2): 4.289e-06, MSE(pi3): 9.356e-04\n",
      "Epoch 366800, Train loss: 1.998e+02, Test loss: 1.006e+03, MSE(e): 3.642e-06, MSE(pi1): 6.228e-03, MSE(pi2): 1.304e-06, MSE(pi3): 1.011e-03\n",
      "Epoch 366900, Train loss: 2.457e+02, Test loss: 1.124e+03, MSE(e): 5.044e-06, MSE(pi1): 1.053e-02, MSE(pi2): 1.471e-06, MSE(pi3): 8.997e-04\n",
      "Epoch 367000, Train loss: 1.756e+02, Test loss: 1.085e+03, MSE(e): 4.179e-06, MSE(pi1): 3.536e-03, MSE(pi2): 2.003e-06, MSE(pi3): 9.843e-04\n",
      "Epoch 367100, Train loss: 1.135e+03, Test loss: 2.430e+03, MSE(e): 8.332e-05, MSE(pi1): 1.884e-02, MSE(pi2): 3.986e-05, MSE(pi3): 1.138e-03\n",
      "Epoch 367200, Train loss: 3.050e+02, Test loss: 1.132e+03, MSE(e): 6.840e-06, MSE(pi1): 1.449e-02, MSE(pi2): 2.535e-06, MSE(pi3): 9.169e-04\n",
      "Epoch 367300, Train loss: 2.639e+02, Test loss: 1.187e+03, MSE(e): 6.401e-06, MSE(pi1): 9.465e-03, MSE(pi2): 2.596e-06, MSE(pi3): 1.053e-03\n",
      "Epoch 367400, Train loss: 4.962e+02, Test loss: 1.194e+03, MSE(e): 3.424e-05, MSE(pi1): 5.488e-03, MSE(pi2): 1.606e-05, MSE(pi3): 9.890e-04\n",
      "Epoch 367500, Train loss: 2.534e+02, Test loss: 1.080e+03, MSE(e): 5.567e-06, MSE(pi1): 9.310e-03, MSE(pi2): 1.871e-06, MSE(pi3): 1.046e-03\n",
      "Epoch 367600, Train loss: 1.820e+02, Test loss: 9.524e+02, MSE(e): 4.833e-06, MSE(pi1): 3.785e-03, MSE(pi2): 2.161e-06, MSE(pi3): 9.585e-04\n",
      "Epoch 367700, Train loss: 1.897e+02, Test loss: 1.034e+03, MSE(e): 2.575e-06, MSE(pi1): 6.842e-03, MSE(pi2): 9.436e-07, MSE(pi3): 9.557e-04\n",
      "Epoch 367800, Train loss: 6.814e+02, Test loss: 1.514e+03, MSE(e): 4.871e-05, MSE(pi1): 1.084e-02, MSE(pi2): 2.463e-05, MSE(pi3): 8.583e-04\n",
      "Epoch 367900, Train loss: 6.802e+02, Test loss: 1.677e+03, MSE(e): 5.234e-05, MSE(pi1): 5.696e-03, MSE(pi2): 2.234e-05, MSE(pi3): 9.982e-04\n",
      "Epoch 368000, Train loss: 2.809e+02, Test loss: 1.164e+03, MSE(e): 1.034e-05, MSE(pi1): 9.157e-03, MSE(pi2): 5.115e-06, MSE(pi3): 8.592e-04\n",
      "Epoch 368100, Train loss: 3.427e+02, Test loss: 1.122e+03, MSE(e): 1.305e-05, MSE(pi1): 1.222e-02, MSE(pi2): 4.870e-06, MSE(pi3): 8.998e-04\n",
      "Epoch 368200, Train loss: 1.774e+02, Test loss: 1.012e+03, MSE(e): 2.607e-06, MSE(pi1): 5.183e-03, MSE(pi2): 1.046e-06, MSE(pi3): 9.946e-04\n",
      "Epoch 368300, Train loss: 1.670e+02, Test loss: 9.575e+02, MSE(e): 3.231e-06, MSE(pi1): 4.071e-03, MSE(pi2): 1.477e-06, MSE(pi3): 9.400e-04\n",
      "Epoch 368400, Train loss: 2.747e+02, Test loss: 1.141e+03, MSE(e): 7.685e-06, MSE(pi1): 1.067e-02, MSE(pi2): 3.075e-06, MSE(pi3): 9.114e-04\n",
      "Epoch 368500, Train loss: 1.756e+03, Test loss: 2.782e+03, MSE(e): 1.537e-04, MSE(pi1): 1.042e-02, MSE(pi2): 7.065e-05, MSE(pi3): 1.153e-03\n",
      "Epoch 368600, Train loss: 4.715e+02, Test loss: 1.794e+03, MSE(e): 3.263e-05, MSE(pi1): 4.190e-03, MSE(pi2): 1.606e-05, MSE(pi3): 1.033e-03\n",
      "Epoch 368700, Train loss: 1.456e+02, Test loss: 9.651e+02, MSE(e): 1.540e-06, MSE(pi1): 3.644e-03, MSE(pi2): 7.655e-07, MSE(pi3): 9.379e-04\n",
      "Epoch 368800, Train loss: 2.550e+02, Test loss: 9.900e+02, MSE(e): 7.572e-06, MSE(pi1): 9.096e-03, MSE(pi2): 3.309e-06, MSE(pi3): 8.836e-04\n",
      "Epoch 368900, Train loss: 2.467e+02, Test loss: 1.098e+03, MSE(e): 7.131e-06, MSE(pi1): 8.071e-03, MSE(pi2): 3.026e-06, MSE(pi3): 9.469e-04\n",
      "Epoch 369000, Train loss: 1.544e+02, Test loss: 9.901e+02, MSE(e): 1.758e-06, MSE(pi1): 4.425e-03, MSE(pi2): 7.861e-07, MSE(pi3): 9.257e-04\n",
      "Epoch 369100, Train loss: 1.948e+02, Test loss: 1.103e+03, MSE(e): 4.168e-06, MSE(pi1): 5.337e-03, MSE(pi2): 1.749e-06, MSE(pi3): 9.974e-04\n",
      "Epoch 369200, Train loss: 9.968e+02, Test loss: 1.479e+03, MSE(e): 7.953e-05, MSE(pi1): 1.069e-02, MSE(pi2): 3.531e-05, MSE(pi3): 9.453e-04\n",
      "Epoch 369300, Train loss: 3.559e+03, Test loss: 4.422e+03, MSE(e): 3.261e-04, MSE(pi1): 1.946e-02, MSE(pi2): 1.501e-04, MSE(pi3): 1.027e-03\n",
      "Epoch 369400, Train loss: 4.626e+02, Test loss: 1.608e+03, MSE(e): 2.328e-05, MSE(pi1): 1.175e-02, MSE(pi2): 1.075e-05, MSE(pi3): 1.122e-03\n",
      "Epoch 369500, Train loss: 3.347e+02, Test loss: 1.243e+03, MSE(e): 7.654e-06, MSE(pi1): 1.573e-02, MSE(pi2): 2.308e-06, MSE(pi3): 1.008e-03\n",
      "Epoch 369600, Train loss: 4.674e+02, Test loss: 1.112e+03, MSE(e): 3.097e-05, MSE(pi1): 5.906e-03, MSE(pi2): 1.257e-05, MSE(pi3): 9.854e-04\n",
      "Epoch 369700, Train loss: 2.337e+02, Test loss: 1.147e+03, MSE(e): 3.250e-06, MSE(pi1): 1.105e-02, MSE(pi2): 1.012e-06, MSE(pi3): 9.073e-04\n",
      "Epoch 369800, Train loss: 2.251e+02, Test loss: 1.034e+03, MSE(e): 7.238e-06, MSE(pi1): 5.419e-03, MSE(pi2): 3.247e-06, MSE(pi3): 9.848e-04\n",
      "Epoch 369900, Train loss: 3.481e+03, Test loss: 5.619e+03, MSE(e): 3.064e-04, MSE(pi1): 2.360e-02, MSE(pi2): 1.393e-04, MSE(pi3): 1.800e-03\n",
      "Epoch 370000, Train loss: 4.039e+02, Test loss: 1.385e+03, MSE(e): 1.172e-05, MSE(pi1): 1.646e-02, MSE(pi2): 4.910e-06, MSE(pi3): 1.221e-03\n",
      "Epoch 370100, Train loss: 2.613e+02, Test loss: 1.020e+03, MSE(e): 4.788e-06, MSE(pi1): 1.080e-02, MSE(pi2): 1.436e-06, MSE(pi3): 1.055e-03\n",
      "Epoch 370200, Train loss: 2.088e+02, Test loss: 1.068e+03, MSE(e): 3.159e-06, MSE(pi1): 8.813e-03, MSE(pi2): 1.045e-06, MSE(pi3): 8.909e-04\n",
      "Epoch 370300, Train loss: 1.432e+02, Test loss: 9.714e+02, MSE(e): 1.473e-06, MSE(pi1): 3.465e-03, MSE(pi2): 7.499e-07, MSE(pi3): 9.379e-04\n",
      "Epoch 370400, Train loss: 1.167e+03, Test loss: 1.137e+03, MSE(e): 9.910e-05, MSE(pi1): 9.439e-03, MSE(pi2): 4.533e-05, MSE(pi3): 8.167e-04\n",
      "Epoch 370500, Train loss: 2.449e+02, Test loss: 1.193e+03, MSE(e): 4.093e-06, MSE(pi1): 1.026e-02, MSE(pi2): 1.405e-06, MSE(pi3): 1.014e-03\n",
      "Epoch 370600, Train loss: 5.214e+02, Test loss: 1.398e+03, MSE(e): 2.691e-05, MSE(pi1): 1.594e-02, MSE(pi2): 1.240e-05, MSE(pi3): 9.287e-04\n",
      "Epoch 370700, Train loss: 3.644e+02, Test loss: 1.448e+03, MSE(e): 6.575e-06, MSE(pi1): 1.947e-02, MSE(pi2): 1.753e-06, MSE(pi3): 1.039e-03\n",
      "Epoch 370800, Train loss: 1.708e+02, Test loss: 1.024e+03, MSE(e): 2.431e-06, MSE(pi1): 4.830e-03, MSE(pi2): 1.084e-06, MSE(pi3): 9.815e-04\n",
      "Epoch 370900, Train loss: 3.004e+02, Test loss: 1.113e+03, MSE(e): 1.084e-05, MSE(pi1): 8.966e-03, MSE(pi2): 4.244e-06, MSE(pi3): 1.023e-03\n",
      "Epoch 371000, Train loss: 1.848e+02, Test loss: 1.086e+03, MSE(e): 2.991e-06, MSE(pi1): 5.759e-03, MSE(pi2): 1.231e-06, MSE(pi3): 9.728e-04\n",
      "Epoch 371100, Train loss: 4.894e+02, Test loss: 1.140e+03, MSE(e): 1.283e-05, MSE(pi1): 2.545e-02, MSE(pi2): 4.250e-06, MSE(pi3): 1.066e-03\n",
      "Epoch 371200, Train loss: 2.377e+02, Test loss: 1.172e+03, MSE(e): 8.127e-06, MSE(pi1): 6.566e-03, MSE(pi2): 4.229e-06, MSE(pi3): 9.077e-04\n",
      "Epoch 371300, Train loss: 8.871e+02, Test loss: 1.810e+03, MSE(e): 6.890e-05, MSE(pi1): 1.078e-02, MSE(pi2): 3.258e-05, MSE(pi3): 9.025e-04\n",
      "Epoch 371400, Train loss: 1.367e+03, Test loss: 2.158e+03, MSE(e): 9.416e-05, MSE(pi1): 2.806e-02, MSE(pi2): 4.427e-05, MSE(pi3): 1.450e-03\n",
      "Epoch 371500, Train loss: 2.555e+02, Test loss: 1.022e+03, MSE(e): 9.704e-06, MSE(pi1): 7.109e-03, MSE(pi2): 4.659e-06, MSE(pi3): 8.732e-04\n",
      "Epoch 371600, Train loss: 3.623e+02, Test loss: 1.358e+03, MSE(e): 6.424e-06, MSE(pi1): 1.865e-02, MSE(pi2): 1.622e-06, MSE(pi3): 1.115e-03\n",
      "Epoch 371700, Train loss: 1.830e+02, Test loss: 1.062e+03, MSE(e): 3.203e-06, MSE(pi1): 5.836e-03, MSE(pi2): 1.253e-06, MSE(pi3): 9.259e-04\n",
      "Epoch 371800, Train loss: 7.809e+02, Test loss: 1.741e+03, MSE(e): 4.967e-05, MSE(pi1): 1.984e-02, MSE(pi2): 2.459e-05, MSE(pi3): 8.575e-04\n",
      "Epoch 371900, Train loss: 1.091e+03, Test loss: 1.857e+03, MSE(e): 9.104e-05, MSE(pi1): 8.117e-03, MSE(pi2): 4.445e-05, MSE(pi3): 9.981e-04\n",
      "Epoch 372000, Train loss: 2.222e+02, Test loss: 9.545e+02, MSE(e): 3.887e-06, MSE(pi1): 8.888e-03, MSE(pi2): 1.349e-06, MSE(pi3): 9.444e-04\n",
      "Epoch 372100, Train loss: 1.884e+02, Test loss: 1.049e+03, MSE(e): 4.282e-06, MSE(pi1): 5.382e-03, MSE(pi2): 1.842e-06, MSE(pi3): 9.173e-04\n",
      "Epoch 372200, Train loss: 4.075e+02, Test loss: 1.271e+03, MSE(e): 7.738e-06, MSE(pi1): 2.431e-02, MSE(pi2): 2.211e-06, MSE(pi3): 8.704e-04\n",
      "Epoch 372300, Train loss: 2.564e+02, Test loss: 1.130e+03, MSE(e): 4.482e-06, MSE(pi1): 1.203e-02, MSE(pi2): 1.186e-06, MSE(pi3): 9.135e-04\n",
      "Epoch 372400, Train loss: 1.532e+02, Test loss: 9.924e+02, MSE(e): 1.699e-06, MSE(pi1): 3.805e-03, MSE(pi2): 8.098e-07, MSE(pi3): 9.814e-04\n",
      "Epoch 372500, Train loss: 2.578e+02, Test loss: 1.206e+03, MSE(e): 4.015e-06, MSE(pi1): 1.195e-02, MSE(pi2): 1.172e-06, MSE(pi3): 9.811e-04\n",
      "Epoch 372600, Train loss: 1.838e+02, Test loss: 1.040e+03, MSE(e): 3.569e-06, MSE(pi1): 5.682e-03, MSE(pi2): 1.319e-06, MSE(pi3): 9.127e-04\n",
      "Epoch 372700, Train loss: 1.950e+02, Test loss: 1.036e+03, MSE(e): 3.423e-06, MSE(pi1): 7.106e-03, MSE(pi2): 1.249e-06, MSE(pi3): 8.968e-04\n",
      "Epoch 372800, Train loss: 6.962e+02, Test loss: 1.946e+03, MSE(e): 5.244e-05, MSE(pi1): 6.409e-03, MSE(pi2): 2.472e-05, MSE(pi3): 1.077e-03\n",
      "Epoch 372900, Train loss: 5.263e+02, Test loss: 1.298e+03, MSE(e): 3.321e-05, MSE(pi1): 9.780e-03, MSE(pi2): 1.693e-05, MSE(pi3): 9.636e-04\n",
      "Epoch 373000, Train loss: 3.772e+02, Test loss: 1.312e+03, MSE(e): 1.024e-05, MSE(pi1): 1.554e-02, MSE(pi2): 3.415e-06, MSE(pi3): 1.193e-03\n",
      "Epoch 373100, Train loss: 3.073e+03, Test loss: 4.883e+03, MSE(e): 2.821e-04, MSE(pi1): 1.288e-02, MSE(pi2): 1.329e-04, MSE(pi3): 1.231e-03\n",
      "Epoch 373200, Train loss: 2.514e+02, Test loss: 1.077e+03, MSE(e): 4.286e-06, MSE(pi1): 1.227e-02, MSE(pi2): 1.109e-06, MSE(pi3): 8.577e-04\n",
      "Epoch 373300, Train loss: 3.747e+02, Test loss: 1.394e+03, MSE(e): 1.170e-05, MSE(pi1): 1.678e-02, MSE(pi2): 3.811e-06, MSE(pi3): 8.993e-04\n",
      "Epoch 373400, Train loss: 1.565e+02, Test loss: 1.022e+03, MSE(e): 1.730e-06, MSE(pi1): 4.891e-03, MSE(pi2): 8.178e-07, MSE(pi3): 9.031e-04\n",
      "Epoch 373500, Train loss: 1.666e+02, Test loss: 9.708e+02, MSE(e): 3.040e-06, MSE(pi1): 4.443e-03, MSE(pi2): 1.318e-06, MSE(pi3): 9.177e-04\n",
      "Epoch 373600, Train loss: 2.367e+02, Test loss: 1.265e+03, MSE(e): 1.037e-05, MSE(pi1): 3.768e-03, MSE(pi2): 4.890e-06, MSE(pi3): 9.535e-04\n",
      "Epoch 373700, Train loss: 1.442e+02, Test loss: 9.659e+02, MSE(e): 1.506e-06, MSE(pi1): 3.322e-03, MSE(pi2): 7.615e-07, MSE(pi3): 9.587e-04\n",
      "Epoch 373800, Train loss: 2.425e+02, Test loss: 1.048e+03, MSE(e): 6.053e-06, MSE(pi1): 8.065e-03, MSE(pi2): 2.844e-06, MSE(pi3): 1.013e-03\n",
      "Epoch 373900, Train loss: 2.862e+02, Test loss: 1.165e+03, MSE(e): 4.891e-06, MSE(pi1): 1.398e-02, MSE(pi2): 1.286e-06, MSE(pi3): 9.743e-04\n",
      "Epoch 374000, Train loss: 1.881e+02, Test loss: 1.046e+03, MSE(e): 2.566e-06, MSE(pi1): 7.210e-03, MSE(pi2): 1.005e-06, MSE(pi3): 9.037e-04\n",
      "Epoch 374100, Train loss: 4.432e+02, Test loss: 1.348e+03, MSE(e): 2.178e-05, MSE(pi1): 1.225e-02, MSE(pi2): 8.327e-06, MSE(pi3): 1.030e-03\n",
      "Epoch 374200, Train loss: 3.228e+02, Test loss: 1.317e+03, MSE(e): 6.756e-06, MSE(pi1): 1.593e-02, MSE(pi2): 2.083e-06, MSE(pi3): 9.593e-04\n",
      "Epoch 374300, Train loss: 2.141e+02, Test loss: 1.129e+03, MSE(e): 5.018e-06, MSE(pi1): 7.256e-03, MSE(pi2): 1.792e-06, MSE(pi3): 9.138e-04\n",
      "Epoch 374400, Train loss: 3.044e+02, Test loss: 1.066e+03, MSE(e): 1.135e-05, MSE(pi1): 9.746e-03, MSE(pi2): 3.346e-06, MSE(pi3): 9.336e-04\n",
      "Epoch 374500, Train loss: 3.038e+02, Test loss: 9.554e+02, MSE(e): 1.555e-05, MSE(pi1): 5.975e-03, MSE(pi2): 7.734e-06, MSE(pi3): 8.849e-04\n",
      "Epoch 374600, Train loss: 2.328e+02, Test loss: 1.220e+03, MSE(e): 4.994e-06, MSE(pi1): 9.774e-03, MSE(pi2): 1.565e-06, MSE(pi3): 8.512e-04\n",
      "Epoch 374700, Train loss: 3.977e+02, Test loss: 1.119e+03, MSE(e): 1.552e-05, MSE(pi1): 1.323e-02, MSE(pi2): 5.534e-06, MSE(pi3): 1.103e-03\n",
      "Epoch 374800, Train loss: 3.974e+02, Test loss: 1.331e+03, MSE(e): 1.754e-05, MSE(pi1): 1.093e-02, MSE(pi2): 9.384e-06, MSE(pi3): 1.127e-03\n",
      "Epoch 374900, Train loss: 1.971e+02, Test loss: 1.070e+03, MSE(e): 2.685e-06, MSE(pi1): 7.610e-03, MSE(pi2): 9.565e-07, MSE(pi3): 9.411e-04\n",
      "Epoch 375000, Train loss: 1.128e+03, Test loss: 1.933e+03, MSE(e): 9.285e-05, MSE(pi1): 1.071e-02, MSE(pi2): 4.377e-05, MSE(pi3): 9.194e-04\n",
      "Epoch 375100, Train loss: 2.551e+02, Test loss: 9.925e+02, MSE(e): 9.791e-06, MSE(pi1): 6.262e-03, MSE(pi2): 3.599e-06, MSE(pi3): 9.457e-04\n",
      "Epoch 375200, Train loss: 3.862e+02, Test loss: 1.055e+03, MSE(e): 1.746e-05, MSE(pi1): 1.009e-02, MSE(pi2): 7.387e-06, MSE(pi3): 1.107e-03\n",
      "Epoch 375300, Train loss: 3.283e+02, Test loss: 1.291e+03, MSE(e): 5.943e-06, MSE(pi1): 1.535e-02, MSE(pi2): 1.757e-06, MSE(pi3): 1.153e-03\n",
      "Epoch 375400, Train loss: 3.796e+02, Test loss: 1.221e+03, MSE(e): 7.969e-06, MSE(pi1): 2.027e-02, MSE(pi2): 2.107e-06, MSE(pi3): 9.718e-04\n",
      "Epoch 375500, Train loss: 4.798e+02, Test loss: 1.545e+03, MSE(e): 1.918e-05, MSE(pi1): 1.674e-02, MSE(pi2): 8.213e-06, MSE(pi3): 1.207e-03\n",
      "Epoch 375600, Train loss: 2.060e+02, Test loss: 1.145e+03, MSE(e): 4.886e-06, MSE(pi1): 6.016e-03, MSE(pi2): 2.450e-06, MSE(pi3): 9.697e-04\n",
      "Epoch 375700, Train loss: 3.620e+02, Test loss: 1.300e+03, MSE(e): 6.485e-06, MSE(pi1): 2.064e-02, MSE(pi2): 1.508e-06, MSE(pi3): 9.076e-04\n",
      "Epoch 375800, Train loss: 2.104e+02, Test loss: 9.999e+02, MSE(e): 3.910e-06, MSE(pi1): 6.813e-03, MSE(pi2): 1.637e-06, MSE(pi3): 1.031e-03\n",
      "Epoch 375900, Train loss: 3.672e+02, Test loss: 1.057e+03, MSE(e): 2.230e-05, MSE(pi1): 5.574e-03, MSE(pi2): 9.943e-06, MSE(pi3): 8.844e-04\n",
      "Epoch 376000, Train loss: 2.926e+02, Test loss: 1.199e+03, MSE(e): 6.712e-06, MSE(pi1): 1.352e-02, MSE(pi2): 2.680e-06, MSE(pi3): 9.027e-04\n",
      "Epoch 376100, Train loss: 1.624e+02, Test loss: 9.594e+02, MSE(e): 2.381e-06, MSE(pi1): 4.358e-03, MSE(pi2): 1.033e-06, MSE(pi3): 9.498e-04\n",
      "Epoch 376200, Train loss: 2.740e+02, Test loss: 1.159e+03, MSE(e): 6.420e-06, MSE(pi1): 1.082e-02, MSE(pi2): 2.377e-06, MSE(pi3): 1.016e-03\n",
      "Epoch 376300, Train loss: 2.503e+02, Test loss: 9.694e+02, MSE(e): 6.507e-06, MSE(pi1): 9.029e-03, MSE(pi2): 2.368e-06, MSE(pi3): 9.495e-04\n",
      "Epoch 376400, Train loss: 1.430e+02, Test loss: 9.734e+02, MSE(e): 1.417e-06, MSE(pi1): 3.366e-03, MSE(pi2): 7.227e-07, MSE(pi3): 9.512e-04\n",
      "Epoch 376500, Train loss: 1.478e+02, Test loss: 9.896e+02, MSE(e): 1.602e-06, MSE(pi1): 3.648e-03, MSE(pi2): 7.760e-07, MSE(pi3): 9.528e-04\n",
      "Epoch 376600, Train loss: 3.090e+02, Test loss: 1.238e+03, MSE(e): 5.229e-06, MSE(pi1): 1.681e-02, MSE(pi2): 1.195e-06, MSE(pi3): 8.864e-04\n",
      "Epoch 376700, Train loss: 1.936e+02, Test loss: 1.074e+03, MSE(e): 2.929e-06, MSE(pi1): 6.194e-03, MSE(pi2): 1.229e-06, MSE(pi3): 1.024e-03\n",
      "Epoch 376800, Train loss: 2.036e+02, Test loss: 1.044e+03, MSE(e): 4.457e-06, MSE(pi1): 6.348e-03, MSE(pi2): 1.633e-06, MSE(pi3): 9.558e-04\n",
      "Epoch 376900, Train loss: 4.088e+02, Test loss: 1.249e+03, MSE(e): 8.932e-06, MSE(pi1): 2.182e-02, MSE(pi2): 2.360e-06, MSE(pi3): 1.013e-03\n",
      "Epoch 377000, Train loss: 3.944e+02, Test loss: 1.305e+03, MSE(e): 8.132e-06, MSE(pi1): 2.206e-02, MSE(pi2): 1.988e-06, MSE(pi3): 9.249e-04\n",
      "Epoch 377100, Train loss: 1.939e+02, Test loss: 1.109e+03, MSE(e): 2.847e-06, MSE(pi1): 6.313e-03, MSE(pi2): 1.190e-06, MSE(pi3): 1.023e-03\n",
      "Epoch 377200, Train loss: 2.227e+02, Test loss: 1.094e+03, MSE(e): 3.863e-06, MSE(pi1): 8.838e-03, MSE(pi2): 1.346e-06, MSE(pi3): 9.572e-04\n",
      "Epoch 377300, Train loss: 3.754e+03, Test loss: 7.243e+03, MSE(e): 3.311e-04, MSE(pi1): 2.956e-02, MSE(pi2): 1.571e-04, MSE(pi3): 1.466e-03\n",
      "Epoch 377400, Train loss: 2.827e+02, Test loss: 1.140e+03, MSE(e): 4.928e-06, MSE(pi1): 1.474e-02, MSE(pi2): 1.724e-06, MSE(pi3): 8.608e-04\n",
      "Epoch 377500, Train loss: 6.642e+02, Test loss: 1.442e+03, MSE(e): 1.552e-05, MSE(pi1): 4.157e-02, MSE(pi2): 2.926e-06, MSE(pi3): 9.331e-04\n",
      "Epoch 377600, Train loss: 2.258e+02, Test loss: 1.003e+03, MSE(e): 5.292e-06, MSE(pi1): 6.858e-03, MSE(pi2): 2.350e-06, MSE(pi3): 1.043e-03\n",
      "Epoch 377700, Train loss: 6.365e+02, Test loss: 1.707e+03, MSE(e): 4.276e-05, MSE(pi1): 1.014e-02, MSE(pi2): 1.844e-05, MSE(pi3): 1.074e-03\n",
      "Epoch 377800, Train loss: 2.452e+02, Test loss: 1.120e+03, MSE(e): 3.780e-06, MSE(pi1): 1.181e-02, MSE(pi2): 1.117e-06, MSE(pi3): 8.931e-04\n",
      "Epoch 377900, Train loss: 1.955e+02, Test loss: 1.059e+03, MSE(e): 3.259e-06, MSE(pi1): 6.347e-03, MSE(pi2): 1.267e-06, MSE(pi3): 9.940e-04\n",
      "Epoch 378000, Train loss: 2.539e+02, Test loss: 1.242e+03, MSE(e): 8.686e-06, MSE(pi1): 6.546e-03, MSE(pi2): 4.016e-06, MSE(pi3): 1.016e-03\n",
      "Epoch 378100, Train loss: 2.532e+02, Test loss: 1.078e+03, MSE(e): 5.062e-06, MSE(pi1): 1.158e-02, MSE(pi2): 1.956e-06, MSE(pi3): 8.680e-04\n",
      "Epoch 378200, Train loss: 3.816e+02, Test loss: 1.297e+03, MSE(e): 6.517e-06, MSE(pi1): 1.960e-02, MSE(pi2): 1.731e-06, MSE(pi3): 1.204e-03\n",
      "Epoch 378300, Train loss: 2.079e+02, Test loss: 9.850e+02, MSE(e): 6.531e-06, MSE(pi1): 4.540e-03, MSE(pi2): 3.058e-06, MSE(pi3): 9.716e-04\n",
      "Epoch 378400, Train loss: 3.737e+02, Test loss: 1.295e+03, MSE(e): 1.314e-05, MSE(pi1): 1.211e-02, MSE(pi2): 5.518e-06, MSE(pi3): 1.211e-03\n",
      "Epoch 378500, Train loss: 3.005e+02, Test loss: 1.090e+03, MSE(e): 1.239e-05, MSE(pi1): 6.759e-03, MSE(pi2): 6.113e-06, MSE(pi3): 1.090e-03\n",
      "Epoch 378600, Train loss: 2.004e+03, Test loss: 3.620e+03, MSE(e): 1.838e-04, MSE(pi1): 6.179e-03, MSE(pi2): 8.539e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 378700, Train loss: 1.732e+03, Test loss: 2.854e+03, MSE(e): 1.494e-04, MSE(pi1): 1.187e-02, MSE(pi2): 6.985e-05, MSE(pi3): 1.195e-03\n",
      "Epoch 378800, Train loss: 2.652e+03, Test loss: 3.456e+03, MSE(e): 2.379e-04, MSE(pi1): 1.658e-02, MSE(pi2): 1.118e-04, MSE(pi3): 1.072e-03\n",
      "Epoch 378900, Train loss: 2.653e+02, Test loss: 1.238e+03, MSE(e): 9.478e-06, MSE(pi1): 7.004e-03, MSE(pi2): 4.383e-06, MSE(pi3): 1.004e-03\n",
      "Epoch 379000, Train loss: 1.705e+02, Test loss: 9.845e+02, MSE(e): 2.263e-06, MSE(pi1): 5.548e-03, MSE(pi2): 1.044e-06, MSE(pi3): 9.240e-04\n",
      "Epoch 379100, Train loss: 2.670e+02, Test loss: 1.303e+03, MSE(e): 9.552e-06, MSE(pi1): 7.582e-03, MSE(pi2): 4.275e-06, MSE(pi3): 9.565e-04\n",
      "Epoch 379200, Train loss: 2.364e+02, Test loss: 1.028e+03, MSE(e): 6.082e-06, MSE(pi1): 7.025e-03, MSE(pi2): 2.441e-06, MSE(pi3): 1.053e-03\n",
      "Epoch 379300, Train loss: 2.963e+02, Test loss: 1.242e+03, MSE(e): 5.400e-06, MSE(pi1): 1.313e-02, MSE(pi2): 1.319e-06, MSE(pi3): 1.110e-03\n",
      "Epoch 379400, Train loss: 6.152e+02, Test loss: 1.879e+03, MSE(e): 1.246e-05, MSE(pi1): 3.874e-02, MSE(pi2): 2.505e-06, MSE(pi3): 1.032e-03\n",
      "Epoch 379500, Train loss: 2.557e+02, Test loss: 1.230e+03, MSE(e): 1.052e-05, MSE(pi1): 5.561e-03, MSE(pi2): 4.906e-06, MSE(pi3): 9.482e-04\n",
      "Epoch 379600, Train loss: 4.460e+02, Test loss: 1.429e+03, MSE(e): 2.134e-05, MSE(pi1): 1.396e-02, MSE(pi2): 8.926e-06, MSE(pi3): 9.301e-04\n",
      "Epoch 379700, Train loss: 2.461e+02, Test loss: 1.170e+03, MSE(e): 4.499e-06, MSE(pi1): 1.112e-02, MSE(pi2): 1.349e-06, MSE(pi3): 8.986e-04\n",
      "Epoch 379800, Train loss: 5.492e+02, Test loss: 1.216e+03, MSE(e): 1.242e-05, MSE(pi1): 3.111e-02, MSE(pi2): 2.562e-06, MSE(pi3): 1.139e-03\n",
      "Epoch 379900, Train loss: 1.744e+02, Test loss: 9.548e+02, MSE(e): 3.105e-06, MSE(pi1): 5.368e-03, MSE(pi2): 1.087e-06, MSE(pi3): 8.965e-04\n",
      "Epoch 380000, Train loss: 1.103e+03, Test loss: 1.753e+03, MSE(e): 9.005e-05, MSE(pi1): 1.094e-02, MSE(pi2): 4.479e-05, MSE(pi3): 9.347e-04\n",
      "Epoch 380100, Train loss: 5.039e+02, Test loss: 1.439e+03, MSE(e): 1.382e-05, MSE(pi1): 2.810e-02, MSE(pi2): 4.988e-06, MSE(pi3): 8.467e-04\n",
      "Epoch 380200, Train loss: 2.845e+02, Test loss: 1.336e+03, MSE(e): 1.058e-05, MSE(pi1): 7.228e-03, MSE(pi2): 4.994e-06, MSE(pi3): 1.064e-03\n",
      "Epoch 380300, Train loss: 4.952e+02, Test loss: 1.723e+03, MSE(e): 2.386e-05, MSE(pi1): 1.494e-02, MSE(pi2): 1.043e-05, MSE(pi3): 1.073e-03\n",
      "Epoch 380400, Train loss: 8.945e+02, Test loss: 1.512e+03, MSE(e): 7.249e-05, MSE(pi1): 6.552e-03, MSE(pi2): 3.331e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 380500, Train loss: 3.985e+02, Test loss: 1.266e+03, MSE(e): 1.659e-05, MSE(pi1): 1.387e-02, MSE(pi2): 7.218e-06, MSE(pi3): 9.393e-04\n",
      "Epoch 380600, Train loss: 6.606e+02, Test loss: 1.799e+03, MSE(e): 2.187e-05, MSE(pi1): 3.378e-02, MSE(pi2): 7.677e-06, MSE(pi3): 1.041e-03\n",
      "Epoch 380700, Train loss: 5.083e+02, Test loss: 1.667e+03, MSE(e): 3.642e-05, MSE(pi1): 4.879e-03, MSE(pi2): 1.721e-05, MSE(pi3): 9.530e-04\n",
      "Epoch 380800, Train loss: 6.080e+02, Test loss: 2.670e+03, MSE(e): 4.368e-05, MSE(pi1): 5.359e-03, MSE(pi2): 1.998e-05, MSE(pi3): 1.176e-03\n",
      "Epoch 380900, Train loss: 4.252e+02, Test loss: 1.325e+03, MSE(e): 8.488e-06, MSE(pi1): 2.128e-02, MSE(pi2): 2.642e-06, MSE(pi3): 1.276e-03\n",
      "Epoch 381000, Train loss: 2.518e+03, Test loss: 4.374e+03, MSE(e): 2.166e-04, MSE(pi1): 2.688e-02, MSE(pi2): 1.070e-04, MSE(pi3): 8.357e-04\n",
      "Epoch 381100, Train loss: 1.830e+02, Test loss: 1.047e+03, MSE(e): 2.369e-06, MSE(pi1): 6.542e-03, MSE(pi2): 8.465e-07, MSE(pi3): 9.385e-04\n",
      "Epoch 381200, Train loss: 4.189e+03, Test loss: 5.226e+03, MSE(e): 3.906e-04, MSE(pi1): 1.980e-02, MSE(pi2): 1.867e-04, MSE(pi3): 8.507e-04\n",
      "Epoch 381300, Train loss: 2.628e+02, Test loss: 1.143e+03, MSE(e): 4.546e-06, MSE(pi1): 1.210e-02, MSE(pi2): 1.233e-06, MSE(pi3): 9.631e-04\n",
      "Epoch 381400, Train loss: 1.057e+03, Test loss: 1.667e+03, MSE(e): 8.351e-05, MSE(pi1): 1.229e-02, MSE(pi2): 4.197e-05, MSE(pi3): 9.907e-04\n",
      "Epoch 381500, Train loss: 2.157e+02, Test loss: 1.008e+03, MSE(e): 5.420e-06, MSE(pi1): 6.438e-03, MSE(pi2): 2.455e-06, MSE(pi3): 9.708e-04\n",
      "Epoch 381600, Train loss: 3.358e+02, Test loss: 1.164e+03, MSE(e): 6.949e-06, MSE(pi1): 1.677e-02, MSE(pi2): 1.945e-06, MSE(pi3): 9.863e-04\n",
      "Epoch 381700, Train loss: 4.050e+02, Test loss: 1.303e+03, MSE(e): 8.134e-06, MSE(pi1): 2.129e-02, MSE(pi2): 2.046e-06, MSE(pi3): 1.107e-03\n",
      "Epoch 381800, Train loss: 4.033e+02, Test loss: 1.423e+03, MSE(e): 7.512e-06, MSE(pi1): 2.355e-02, MSE(pi2): 1.675e-06, MSE(pi3): 9.264e-04\n",
      "Epoch 381900, Train loss: 1.845e+02, Test loss: 1.024e+03, MSE(e): 2.518e-06, MSE(pi1): 6.246e-03, MSE(pi2): 9.315e-07, MSE(pi3): 9.689e-04\n",
      "Epoch 382000, Train loss: 1.779e+02, Test loss: 1.065e+03, MSE(e): 4.409e-06, MSE(pi1): 4.015e-03, MSE(pi2): 2.164e-06, MSE(pi3): 9.369e-04\n",
      "Epoch 382100, Train loss: 1.541e+02, Test loss: 1.019e+03, MSE(e): 1.746e-06, MSE(pi1): 3.929e-03, MSE(pi2): 8.655e-07, MSE(pi3): 9.739e-04\n",
      "Epoch 382200, Train loss: 2.360e+02, Test loss: 1.242e+03, MSE(e): 4.261e-06, MSE(pi1): 9.807e-03, MSE(pi2): 1.517e-06, MSE(pi3): 9.535e-04\n",
      "Epoch 382300, Train loss: 1.841e+03, Test loss: 1.987e+03, MSE(e): 1.290e-04, MSE(pi1): 3.805e-02, MSE(pi2): 5.667e-05, MSE(pi3): 1.711e-03\n",
      "Epoch 382400, Train loss: 2.373e+02, Test loss: 1.220e+03, MSE(e): 1.012e-05, MSE(pi1): 3.977e-03, MSE(pi2): 4.869e-06, MSE(pi3): 9.624e-04\n",
      "Epoch 382500, Train loss: 2.941e+02, Test loss: 1.258e+03, MSE(e): 4.893e-06, MSE(pi1): 1.522e-02, MSE(pi2): 1.301e-06, MSE(pi3): 9.304e-04\n",
      "Epoch 382600, Train loss: 1.175e+03, Test loss: 1.984e+03, MSE(e): 1.003e-04, MSE(pi1): 7.803e-03, MSE(pi2): 4.791e-05, MSE(pi3): 9.407e-04\n",
      "Epoch 382700, Train loss: 4.321e+02, Test loss: 1.335e+03, MSE(e): 1.932e-05, MSE(pi1): 1.455e-02, MSE(pi2): 9.325e-06, MSE(pi3): 9.343e-04\n",
      "Epoch 382800, Train loss: 4.741e+02, Test loss: 1.397e+03, MSE(e): 1.049e-05, MSE(pi1): 2.714e-02, MSE(pi2): 3.143e-06, MSE(pi3): 9.783e-04\n",
      "Epoch 382900, Train loss: 1.899e+02, Test loss: 1.063e+03, MSE(e): 3.045e-06, MSE(pi1): 6.240e-03, MSE(pi2): 1.430e-06, MSE(pi3): 9.702e-04\n",
      "Epoch 383000, Train loss: 2.545e+02, Test loss: 1.073e+03, MSE(e): 5.153e-06, MSE(pi1): 9.564e-03, MSE(pi2): 1.651e-06, MSE(pi3): 1.074e-03\n",
      "Epoch 383100, Train loss: 9.231e+02, Test loss: 2.316e+03, MSE(e): 4.903e-05, MSE(pi1): 2.971e-02, MSE(pi2): 1.962e-05, MSE(pi3): 1.357e-03\n",
      "Epoch 383200, Train loss: 1.538e+02, Test loss: 9.607e+02, MSE(e): 2.052e-06, MSE(pi1): 3.883e-03, MSE(pi2): 9.846e-07, MSE(pi3): 9.447e-04\n",
      "Epoch 383300, Train loss: 1.953e+02, Test loss: 1.064e+03, MSE(e): 2.817e-06, MSE(pi1): 7.009e-03, MSE(pi2): 9.540e-07, MSE(pi3): 9.701e-04\n",
      "Epoch 383400, Train loss: 2.143e+02, Test loss: 1.019e+03, MSE(e): 3.700e-06, MSE(pi1): 7.211e-03, MSE(pi2): 1.219e-06, MSE(pi3): 1.052e-03\n",
      "Epoch 383500, Train loss: 3.145e+02, Test loss: 1.222e+03, MSE(e): 1.623e-05, MSE(pi1): 6.609e-03, MSE(pi2): 7.654e-06, MSE(pi3): 8.604e-04\n",
      "Epoch 383600, Train loss: 1.645e+02, Test loss: 1.054e+03, MSE(e): 2.983e-06, MSE(pi1): 4.109e-03, MSE(pi2): 1.393e-06, MSE(pi3): 9.359e-04\n",
      "Epoch 383700, Train loss: 2.093e+02, Test loss: 9.798e+02, MSE(e): 3.997e-06, MSE(pi1): 7.359e-03, MSE(pi2): 1.506e-06, MSE(pi3): 9.575e-04\n",
      "Epoch 383800, Train loss: 4.339e+02, Test loss: 1.394e+03, MSE(e): 7.951e-06, MSE(pi1): 2.497e-02, MSE(pi2): 1.769e-06, MSE(pi3): 1.046e-03\n",
      "Epoch 383900, Train loss: 2.647e+02, Test loss: 1.286e+03, MSE(e): 7.907e-06, MSE(pi1): 9.029e-03, MSE(pi2): 3.058e-06, MSE(pi3): 9.536e-04\n",
      "Epoch 384000, Train loss: 4.164e+02, Test loss: 1.170e+03, MSE(e): 1.053e-05, MSE(pi1): 2.001e-02, MSE(pi2): 3.658e-06, MSE(pi3): 1.110e-03\n",
      "Epoch 384100, Train loss: 1.754e+02, Test loss: 1.028e+03, MSE(e): 2.474e-06, MSE(pi1): 6.008e-03, MSE(pi2): 9.018e-07, MSE(pi3): 9.054e-04\n",
      "Epoch 384200, Train loss: 1.790e+02, Test loss: 1.040e+03, MSE(e): 2.664e-06, MSE(pi1): 6.095e-03, MSE(pi2): 9.662e-07, MSE(pi3): 9.136e-04\n",
      "Epoch 384300, Train loss: 2.666e+02, Test loss: 1.281e+03, MSE(e): 1.099e-05, MSE(pi1): 5.817e-03, MSE(pi2): 4.929e-06, MSE(pi3): 9.847e-04\n",
      "Epoch 384400, Train loss: 2.844e+02, Test loss: 1.247e+03, MSE(e): 1.508e-05, MSE(pi1): 3.373e-03, MSE(pi2): 6.913e-06, MSE(pi3): 9.981e-04\n",
      "Epoch 384500, Train loss: 3.930e+02, Test loss: 1.242e+03, MSE(e): 1.537e-05, MSE(pi1): 1.548e-02, MSE(pi2): 7.373e-06, MSE(pi3): 8.439e-04\n",
      "Epoch 384600, Train loss: 8.308e+02, Test loss: 2.289e+03, MSE(e): 5.902e-05, MSE(pi1): 1.331e-02, MSE(pi2): 2.851e-05, MSE(pi3): 1.076e-03\n",
      "Epoch 384700, Train loss: 1.543e+02, Test loss: 1.016e+03, MSE(e): 2.194e-06, MSE(pi1): 3.756e-03, MSE(pi2): 9.193e-07, MSE(pi3): 9.480e-04\n",
      "Epoch 384800, Train loss: 1.908e+02, Test loss: 1.103e+03, MSE(e): 4.653e-06, MSE(pi1): 4.425e-03, MSE(pi2): 2.154e-06, MSE(pi3): 1.000e-03\n",
      "Epoch 384900, Train loss: 2.020e+03, Test loss: 3.453e+03, MSE(e): 1.846e-04, MSE(pi1): 6.315e-03, MSE(pi2): 8.535e-05, MSE(pi3): 1.110e-03\n",
      "Epoch 385000, Train loss: 2.432e+02, Test loss: 1.276e+03, MSE(e): 9.424e-06, MSE(pi1): 4.857e-03, MSE(pi2): 4.570e-06, MSE(pi3): 1.003e-03\n",
      "Epoch 385100, Train loss: 2.979e+02, Test loss: 1.249e+03, MSE(e): 4.869e-06, MSE(pi1): 1.473e-02, MSE(pi2): 1.348e-06, MSE(pi3): 1.019e-03\n",
      "Epoch 385200, Train loss: 1.830e+02, Test loss: 9.643e+02, MSE(e): 3.891e-06, MSE(pi1): 5.474e-03, MSE(pi2): 1.888e-06, MSE(pi3): 8.934e-04\n",
      "Epoch 385300, Train loss: 2.759e+02, Test loss: 1.177e+03, MSE(e): 5.195e-06, MSE(pi1): 1.365e-02, MSE(pi2): 1.319e-06, MSE(pi3): 8.744e-04\n",
      "Epoch 385400, Train loss: 2.110e+02, Test loss: 1.016e+03, MSE(e): 3.260e-06, MSE(pi1): 7.756e-03, MSE(pi2): 1.135e-06, MSE(pi3): 1.008e-03\n",
      "Epoch 385500, Train loss: 3.462e+02, Test loss: 1.233e+03, MSE(e): 5.817e-06, MSE(pi1): 1.715e-02, MSE(pi2): 1.413e-06, MSE(pi3): 1.165e-03\n",
      "Epoch 385600, Train loss: 5.593e+02, Test loss: 1.842e+03, MSE(e): 3.853e-05, MSE(pi1): 7.234e-03, MSE(pi2): 1.844e-05, MSE(pi3): 1.016e-03\n",
      "Epoch 385700, Train loss: 3.638e+02, Test loss: 1.016e+03, MSE(e): 2.287e-05, MSE(pi1): 4.586e-03, MSE(pi2): 1.112e-05, MSE(pi3): 8.917e-04\n",
      "Epoch 385800, Train loss: 2.176e+02, Test loss: 1.053e+03, MSE(e): 6.844e-06, MSE(pi1): 5.367e-03, MSE(pi2): 2.948e-06, MSE(pi3): 9.548e-04\n",
      "Epoch 385900, Train loss: 3.807e+02, Test loss: 1.253e+03, MSE(e): 1.246e-05, MSE(pi1): 1.569e-02, MSE(pi2): 4.772e-06, MSE(pi3): 9.917e-04\n",
      "Epoch 386000, Train loss: 1.689e+02, Test loss: 1.032e+03, MSE(e): 2.776e-06, MSE(pi1): 5.230e-03, MSE(pi2): 1.041e-06, MSE(pi3): 8.887e-04\n",
      "Epoch 386100, Train loss: 3.383e+02, Test loss: 1.416e+03, MSE(e): 7.540e-06, MSE(pi1): 1.508e-02, MSE(pi2): 2.760e-06, MSE(pi3): 1.121e-03\n",
      "Epoch 386200, Train loss: 1.997e+02, Test loss: 9.627e+02, MSE(e): 5.925e-06, MSE(pi1): 4.855e-03, MSE(pi2): 2.964e-06, MSE(pi3): 9.195e-04\n",
      "Epoch 386300, Train loss: 3.993e+02, Test loss: 1.203e+03, MSE(e): 1.492e-05, MSE(pi1): 1.660e-02, MSE(pi2): 6.408e-06, MSE(pi3): 8.410e-04\n",
      "Epoch 386400, Train loss: 2.603e+02, Test loss: 1.082e+03, MSE(e): 6.025e-06, MSE(pi1): 1.133e-02, MSE(pi2): 2.378e-06, MSE(pi3): 8.670e-04\n",
      "Epoch 386500, Train loss: 2.571e+02, Test loss: 1.121e+03, MSE(e): 5.315e-06, MSE(pi1): 1.016e-02, MSE(pi2): 1.588e-06, MSE(pi3): 1.024e-03\n",
      "Epoch 386600, Train loss: 3.407e+02, Test loss: 1.195e+03, MSE(e): 1.965e-05, MSE(pi1): 4.336e-03, MSE(pi2): 8.360e-06, MSE(pi3): 1.009e-03\n",
      "Epoch 386700, Train loss: 2.638e+02, Test loss: 1.151e+03, MSE(e): 5.022e-06, MSE(pi1): 1.036e-02, MSE(pi2): 1.364e-06, MSE(pi3): 1.099e-03\n",
      "Epoch 386800, Train loss: 4.883e+02, Test loss: 1.366e+03, MSE(e): 2.044e-05, MSE(pi1): 1.933e-02, MSE(pi2): 7.645e-06, MSE(pi3): 9.057e-04\n",
      "Epoch 386900, Train loss: 9.178e+02, Test loss: 1.499e+03, MSE(e): 6.657e-05, MSE(pi1): 1.614e-02, MSE(pi2): 3.318e-05, MSE(pi3): 9.069e-04\n",
      "Epoch 387000, Train loss: 1.537e+02, Test loss: 9.693e+02, MSE(e): 1.793e-06, MSE(pi1): 4.413e-03, MSE(pi2): 8.749e-07, MSE(pi3): 9.162e-04\n",
      "Epoch 387100, Train loss: 4.981e+02, Test loss: 1.582e+03, MSE(e): 2.523e-05, MSE(pi1): 1.418e-02, MSE(pi2): 1.064e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 387200, Train loss: 1.484e+02, Test loss: 9.637e+02, MSE(e): 1.518e-06, MSE(pi1): 4.185e-03, MSE(pi2): 6.977e-07, MSE(pi3): 9.136e-04\n",
      "Epoch 387300, Train loss: 3.770e+02, Test loss: 1.517e+03, MSE(e): 1.066e-05, MSE(pi1): 1.825e-02, MSE(pi2): 3.728e-06, MSE(pi3): 8.792e-04\n",
      "Epoch 387400, Train loss: 4.820e+02, Test loss: 1.695e+03, MSE(e): 3.152e-05, MSE(pi1): 6.813e-03, MSE(pi2): 1.480e-05, MSE(pi3): 9.860e-04\n",
      "Epoch 387500, Train loss: 7.482e+02, Test loss: 1.665e+03, MSE(e): 5.128e-05, MSE(pi1): 1.296e-02, MSE(pi2): 2.501e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 387600, Train loss: 1.768e+02, Test loss: 9.896e+02, MSE(e): 2.353e-06, MSE(pi1): 6.253e-03, MSE(pi2): 8.403e-07, MSE(pi3): 9.074e-04\n",
      "Epoch 387700, Train loss: 3.373e+02, Test loss: 1.334e+03, MSE(e): 6.959e-06, MSE(pi1): 1.511e-02, MSE(pi2): 2.819e-06, MSE(pi3): 1.166e-03\n",
      "Epoch 387800, Train loss: 4.522e+02, Test loss: 1.475e+03, MSE(e): 2.820e-05, MSE(pi1): 8.606e-03, MSE(pi2): 1.269e-05, MSE(pi3): 8.411e-04\n",
      "Epoch 387900, Train loss: 7.591e+02, Test loss: 1.793e+03, MSE(e): 3.342e-05, MSE(pi1): 3.027e-02, MSE(pi2): 1.070e-05, MSE(pi3): 1.222e-03\n",
      "Epoch 388000, Train loss: 3.913e+02, Test loss: 1.155e+03, MSE(e): 2.427e-05, MSE(pi1): 6.527e-03, MSE(pi2): 1.230e-05, MSE(pi3): 8.327e-04\n",
      "Epoch 388100, Train loss: 4.253e+02, Test loss: 9.665e+02, MSE(e): 2.644e-05, MSE(pi1): 6.738e-03, MSE(pi2): 1.357e-05, MSE(pi3): 9.352e-04\n",
      "Epoch 388200, Train loss: 1.498e+02, Test loss: 1.005e+03, MSE(e): 2.308e-06, MSE(pi1): 3.151e-03, MSE(pi2): 1.130e-06, MSE(pi3): 9.519e-04\n",
      "Epoch 388300, Train loss: 5.282e+02, Test loss: 1.133e+03, MSE(e): 2.960e-05, MSE(pi1): 1.415e-02, MSE(pi2): 1.253e-05, MSE(pi3): 9.068e-04\n",
      "Epoch 388400, Train loss: 1.686e+02, Test loss: 1.036e+03, MSE(e): 2.143e-06, MSE(pi1): 5.340e-03, MSE(pi2): 8.657e-07, MSE(pi3): 9.375e-04\n",
      "Epoch 388500, Train loss: 4.171e+02, Test loss: 1.586e+03, MSE(e): 2.107e-05, MSE(pi1): 9.666e-03, MSE(pi2): 1.063e-05, MSE(pi3): 1.097e-03\n",
      "Epoch 388600, Train loss: 9.861e+02, Test loss: 2.744e+03, MSE(e): 8.043e-05, MSE(pi1): 8.441e-03, MSE(pi2): 3.850e-05, MSE(pi3): 9.745e-04\n",
      "Epoch 388700, Train loss: 1.864e+02, Test loss: 1.032e+03, MSE(e): 2.424e-06, MSE(pi1): 6.753e-03, MSE(pi2): 8.705e-07, MSE(pi3): 9.464e-04\n",
      "Epoch 388800, Train loss: 2.121e+02, Test loss: 9.406e+02, MSE(e): 3.489e-06, MSE(pi1): 7.518e-03, MSE(pi2): 1.336e-06, MSE(pi3): 1.020e-03\n",
      "Epoch 388900, Train loss: 4.695e+03, Test loss: 4.279e+03, MSE(e): 4.337e-04, MSE(pi1): 2.771e-02, MSE(pi2): 2.073e-04, MSE(pi3): 8.001e-04\n",
      "Epoch 389000, Train loss: 2.662e+02, Test loss: 1.170e+03, MSE(e): 4.965e-06, MSE(pi1): 1.182e-02, MSE(pi2): 1.427e-06, MSE(pi3): 9.833e-04\n",
      "Epoch 389100, Train loss: 2.466e+02, Test loss: 1.131e+03, MSE(e): 5.340e-06, MSE(pi1): 9.486e-03, MSE(pi2): 2.062e-06, MSE(pi3): 9.836e-04\n",
      "Epoch 389200, Train loss: 3.225e+02, Test loss: 9.662e+02, MSE(e): 1.774e-05, MSE(pi1): 5.025e-03, MSE(pi2): 8.505e-06, MSE(pi3): 9.487e-04\n",
      "Epoch 389300, Train loss: 1.705e+02, Test loss: 9.849e+02, MSE(e): 3.139e-06, MSE(pi1): 4.293e-03, MSE(pi2): 1.176e-06, MSE(pi3): 9.615e-04\n",
      "Epoch 389400, Train loss: 3.046e+02, Test loss: 1.100e+03, MSE(e): 6.455e-06, MSE(pi1): 1.318e-02, MSE(pi2): 1.825e-06, MSE(pi3): 1.082e-03\n",
      "Epoch 389500, Train loss: 4.457e+02, Test loss: 1.408e+03, MSE(e): 9.537e-06, MSE(pi1): 2.557e-02, MSE(pi2): 2.538e-06, MSE(pi3): 9.461e-04\n",
      "Epoch 389600, Train loss: 2.762e+02, Test loss: 1.264e+03, MSE(e): 5.904e-06, MSE(pi1): 1.084e-02, MSE(pi2): 2.241e-06, MSE(pi3): 1.087e-03\n",
      "Epoch 389700, Train loss: 2.505e+02, Test loss: 1.130e+03, MSE(e): 4.250e-06, MSE(pi1): 1.082e-02, MSE(pi2): 1.331e-06, MSE(pi3): 9.985e-04\n",
      "Epoch 389800, Train loss: 1.904e+02, Test loss: 1.083e+03, MSE(e): 2.700e-06, MSE(pi1): 6.737e-03, MSE(pi2): 1.115e-06, MSE(pi3): 9.601e-04\n",
      "Epoch 389900, Train loss: 2.117e+02, Test loss: 1.094e+03, MSE(e): 3.530e-06, MSE(pi1): 8.084e-03, MSE(pi2): 1.293e-06, MSE(pi3): 9.554e-04\n",
      "Epoch 390000, Train loss: 2.657e+02, Test loss: 1.095e+03, MSE(e): 4.699e-06, MSE(pi1): 1.237e-02, MSE(pi2): 1.203e-06, MSE(pi3): 9.507e-04\n",
      "Epoch 390100, Train loss: 3.976e+02, Test loss: 1.303e+03, MSE(e): 1.141e-05, MSE(pi1): 1.868e-02, MSE(pi2): 3.864e-06, MSE(pi3): 9.672e-04\n",
      "Epoch 390200, Train loss: 1.547e+02, Test loss: 9.544e+02, MSE(e): 1.591e-06, MSE(pi1): 4.732e-03, MSE(pi2): 7.234e-07, MSE(pi3): 9.150e-04\n",
      "Epoch 390300, Train loss: 1.822e+02, Test loss: 1.069e+03, MSE(e): 2.316e-06, MSE(pi1): 5.782e-03, MSE(pi2): 8.394e-07, MSE(pi3): 1.013e-03\n",
      "Epoch 390400, Train loss: 1.953e+02, Test loss: 1.040e+03, MSE(e): 2.598e-06, MSE(pi1): 7.285e-03, MSE(pi2): 9.036e-07, MSE(pi3): 9.644e-04\n",
      "Epoch 390500, Train loss: 1.938e+02, Test loss: 9.491e+02, MSE(e): 5.820e-06, MSE(pi1): 4.360e-03, MSE(pi2): 2.918e-06, MSE(pi3): 9.203e-04\n",
      "Epoch 390600, Train loss: 2.131e+02, Test loss: 1.050e+03, MSE(e): 4.291e-06, MSE(pi1): 6.562e-03, MSE(pi2): 1.699e-06, MSE(pi3): 1.046e-03\n",
      "Epoch 390700, Train loss: 3.263e+02, Test loss: 1.134e+03, MSE(e): 1.321e-05, MSE(pi1): 9.109e-03, MSE(pi2): 5.018e-06, MSE(pi3): 1.031e-03\n",
      "Epoch 390800, Train loss: 2.226e+02, Test loss: 9.525e+02, MSE(e): 7.342e-06, MSE(pi1): 5.220e-03, MSE(pi2): 3.250e-06, MSE(pi3): 9.696e-04\n",
      "Epoch 390900, Train loss: 1.023e+03, Test loss: 1.655e+03, MSE(e): 6.945e-05, MSE(pi1): 2.444e-02, MSE(pi2): 3.260e-05, MSE(pi3): 8.429e-04\n",
      "Epoch 391000, Train loss: 1.935e+02, Test loss: 1.145e+03, MSE(e): 2.777e-06, MSE(pi1): 7.340e-03, MSE(pi2): 9.552e-07, MSE(pi3): 9.233e-04\n",
      "Epoch 391100, Train loss: 1.350e+03, Test loss: 2.881e+03, MSE(e): 1.051e-04, MSE(pi1): 1.721e-02, MSE(pi2): 5.227e-05, MSE(pi3): 1.262e-03\n",
      "Epoch 391200, Train loss: 3.096e+02, Test loss: 1.017e+03, MSE(e): 1.607e-05, MSE(pi1): 5.586e-03, MSE(pi2): 7.694e-06, MSE(pi3): 9.298e-04\n",
      "Epoch 391300, Train loss: 1.053e+03, Test loss: 2.662e+03, MSE(e): 8.216e-05, MSE(pi1): 1.315e-02, MSE(pi2): 3.694e-05, MSE(pi3): 1.001e-03\n",
      "Epoch 391400, Train loss: 2.144e+02, Test loss: 1.160e+03, MSE(e): 4.295e-06, MSE(pi1): 6.751e-03, MSE(pi2): 1.792e-06, MSE(pi3): 1.039e-03\n",
      "Epoch 391500, Train loss: 2.394e+02, Test loss: 1.029e+03, MSE(e): 3.697e-06, MSE(pi1): 1.081e-02, MSE(pi2): 1.175e-06, MSE(pi3): 9.429e-04\n",
      "Epoch 391600, Train loss: 1.236e+03, Test loss: 1.579e+03, MSE(e): 9.460e-05, MSE(pi1): 1.875e-02, MSE(pi2): 4.638e-05, MSE(pi3): 1.024e-03\n",
      "Epoch 391700, Train loss: 3.029e+02, Test loss: 1.334e+03, MSE(e): 1.407e-05, MSE(pi1): 6.993e-03, MSE(pi2): 5.962e-06, MSE(pi3): 9.230e-04\n",
      "Epoch 391800, Train loss: 6.164e+02, Test loss: 1.622e+03, MSE(e): 3.744e-05, MSE(pi1): 1.437e-02, MSE(pi2): 1.718e-05, MSE(pi3): 9.829e-04\n",
      "Epoch 391900, Train loss: 8.662e+02, Test loss: 2.191e+03, MSE(e): 6.013e-05, MSE(pi1): 1.834e-02, MSE(pi2): 3.134e-05, MSE(pi3): 8.140e-04\n",
      "Epoch 392000, Train loss: 3.183e+02, Test loss: 1.227e+03, MSE(e): 5.526e-06, MSE(pi1): 1.579e-02, MSE(pi2): 1.375e-06, MSE(pi3): 1.052e-03\n",
      "Epoch 392100, Train loss: 2.087e+02, Test loss: 1.044e+03, MSE(e): 2.878e-06, MSE(pi1): 8.907e-03, MSE(pi2): 9.963e-07, MSE(pi3): 9.086e-04\n",
      "Epoch 392200, Train loss: 1.472e+02, Test loss: 9.860e+02, MSE(e): 1.824e-06, MSE(pi1): 3.433e-03, MSE(pi2): 8.968e-07, MSE(pi3): 9.463e-04\n",
      "Epoch 392300, Train loss: 2.643e+02, Test loss: 1.225e+03, MSE(e): 8.446e-06, MSE(pi1): 8.999e-03, MSE(pi2): 3.300e-06, MSE(pi3): 8.982e-04\n",
      "Epoch 392400, Train loss: 1.661e+02, Test loss: 1.014e+03, MSE(e): 1.989e-06, MSE(pi1): 4.697e-03, MSE(pi2): 8.102e-07, MSE(pi3): 9.925e-04\n",
      "Epoch 392500, Train loss: 1.320e+03, Test loss: 2.531e+03, MSE(e): 1.044e-04, MSE(pi1): 1.767e-02, MSE(pi2): 4.613e-05, MSE(pi3): 9.930e-04\n",
      "Epoch 392600, Train loss: 3.273e+02, Test loss: 1.208e+03, MSE(e): 6.561e-06, MSE(pi1): 1.550e-02, MSE(pi2): 1.870e-06, MSE(pi3): 1.067e-03\n",
      "Epoch 392700, Train loss: 1.524e+02, Test loss: 9.461e+02, MSE(e): 2.108e-06, MSE(pi1): 4.236e-03, MSE(pi2): 1.109e-06, MSE(pi3): 8.893e-04\n",
      "Epoch 392800, Train loss: 4.355e+02, Test loss: 1.542e+03, MSE(e): 1.803e-05, MSE(pi1): 1.565e-02, MSE(pi2): 7.226e-06, MSE(pi3): 9.866e-04\n",
      "Epoch 392900, Train loss: 3.696e+02, Test loss: 1.230e+03, MSE(e): 1.469e-05, MSE(pi1): 1.363e-02, MSE(pi2): 5.843e-06, MSE(pi3): 8.643e-04\n",
      "Epoch 393000, Train loss: 2.027e+02, Test loss: 1.095e+03, MSE(e): 4.278e-06, MSE(pi1): 6.537e-03, MSE(pi2): 1.701e-06, MSE(pi3): 9.456e-04\n",
      "Epoch 393100, Train loss: 3.453e+02, Test loss: 1.076e+03, MSE(e): 9.627e-06, MSE(pi1): 1.540e-02, MSE(pi2): 2.805e-06, MSE(pi3): 9.501e-04\n",
      "Epoch 393200, Train loss: 4.246e+02, Test loss: 1.348e+03, MSE(e): 1.691e-05, MSE(pi1): 1.730e-02, MSE(pi2): 9.060e-06, MSE(pi3): 8.244e-04\n",
      "Epoch 393300, Train loss: 8.379e+02, Test loss: 2.365e+03, MSE(e): 6.964e-05, MSE(pi1): 4.368e-03, MSE(pi2): 3.283e-05, MSE(pi3): 9.776e-04\n",
      "Epoch 393400, Train loss: 2.379e+03, Test loss: 2.994e+03, MSE(e): 2.058e-04, MSE(pi1): 2.370e-02, MSE(pi2): 9.652e-05, MSE(pi3): 8.394e-04\n",
      "Epoch 393500, Train loss: 1.618e+03, Test loss: 3.471e+03, MSE(e): 1.322e-04, MSE(pi1): 1.684e-02, MSE(pi2): 6.271e-05, MSE(pi3): 1.270e-03\n",
      "Epoch 393600, Train loss: 9.308e+02, Test loss: 2.631e+03, MSE(e): 7.843e-05, MSE(pi1): 4.768e-03, MSE(pi2): 3.739e-05, MSE(pi3): 9.882e-04\n",
      "Epoch 393700, Train loss: 1.482e+02, Test loss: 1.006e+03, MSE(e): 1.738e-06, MSE(pi1): 3.543e-03, MSE(pi2): 8.135e-07, MSE(pi3): 9.543e-04\n",
      "Epoch 393800, Train loss: 1.789e+02, Test loss: 1.026e+03, MSE(e): 2.322e-06, MSE(pi1): 6.007e-03, MSE(pi2): 8.337e-07, MSE(pi3): 9.562e-04\n",
      "Epoch 393900, Train loss: 1.966e+02, Test loss: 1.053e+03, MSE(e): 2.504e-06, MSE(pi1): 8.366e-03, MSE(pi2): 9.003e-07, MSE(pi3): 8.794e-04\n",
      "Epoch 394000, Train loss: 1.955e+02, Test loss: 1.095e+03, MSE(e): 2.422e-06, MSE(pi1): 8.290e-03, MSE(pi2): 9.857e-07, MSE(pi3): 8.835e-04\n",
      "Epoch 394100, Train loss: 2.133e+02, Test loss: 1.092e+03, MSE(e): 5.697e-06, MSE(pi1): 6.421e-03, MSE(pi2): 2.027e-06, MSE(pi3): 9.215e-04\n",
      "Epoch 394200, Train loss: 2.838e+02, Test loss: 9.979e+02, MSE(e): 1.480e-05, MSE(pi1): 4.400e-03, MSE(pi2): 6.827e-06, MSE(pi3): 9.180e-04\n",
      "Epoch 394300, Train loss: 5.850e+02, Test loss: 1.364e+03, MSE(e): 4.451e-05, MSE(pi1): 4.755e-03, MSE(pi2): 2.141e-05, MSE(pi3): 9.226e-04\n",
      "Epoch 394400, Train loss: 1.148e+03, Test loss: 1.637e+03, MSE(e): 9.612e-05, MSE(pi1): 8.634e-03, MSE(pi2): 4.433e-05, MSE(pi3): 1.003e-03\n",
      "Epoch 394500, Train loss: 1.510e+03, Test loss: 2.751e+03, MSE(e): 1.292e-04, MSE(pi1): 8.769e-03, MSE(pi2): 6.440e-05, MSE(pi3): 1.296e-03\n",
      "Epoch 394600, Train loss: 1.616e+02, Test loss: 9.646e+02, MSE(e): 1.815e-06, MSE(pi1): 4.859e-03, MSE(pi2): 7.603e-07, MSE(pi3): 9.490e-04\n",
      "Epoch 394700, Train loss: 1.765e+02, Test loss: 9.712e+02, MSE(e): 3.653e-06, MSE(pi1): 4.461e-03, MSE(pi2): 1.637e-06, MSE(pi3): 9.536e-04\n",
      "Epoch 394800, Train loss: 2.417e+02, Test loss: 1.121e+03, MSE(e): 4.771e-06, MSE(pi1): 8.762e-03, MSE(pi2): 1.837e-06, MSE(pi3): 1.064e-03\n",
      "Epoch 394900, Train loss: 1.669e+02, Test loss: 1.059e+03, MSE(e): 3.004e-06, MSE(pi1): 4.312e-03, MSE(pi2): 1.358e-06, MSE(pi3): 9.374e-04\n",
      "Epoch 395000, Train loss: 3.370e+02, Test loss: 1.235e+03, MSE(e): 6.393e-06, MSE(pi1): 1.748e-02, MSE(pi2): 1.618e-06, MSE(pi3): 9.828e-04\n",
      "Epoch 395100, Train loss: 2.144e+02, Test loss: 1.191e+03, MSE(e): 6.829e-06, MSE(pi1): 4.708e-03, MSE(pi2): 3.275e-06, MSE(pi3): 9.907e-04\n",
      "Epoch 395200, Train loss: 6.990e+02, Test loss: 1.211e+03, MSE(e): 3.621e-05, MSE(pi1): 2.180e-02, MSE(pi2): 1.464e-05, MSE(pi3): 1.189e-03\n",
      "Epoch 395300, Train loss: 5.073e+02, Test loss: 1.993e+03, MSE(e): 2.967e-05, MSE(pi1): 1.104e-02, MSE(pi2): 1.283e-05, MSE(pi3): 1.002e-03\n",
      "Epoch 395400, Train loss: 3.045e+02, Test loss: 1.186e+03, MSE(e): 5.389e-06, MSE(pi1): 1.638e-02, MSE(pi2): 1.690e-06, MSE(pi3): 8.679e-04\n",
      "Epoch 395500, Train loss: 4.549e+02, Test loss: 1.415e+03, MSE(e): 3.103e-05, MSE(pi1): 4.424e-03, MSE(pi2): 1.481e-05, MSE(pi3): 1.003e-03\n",
      "Epoch 395600, Train loss: 2.510e+02, Test loss: 9.820e+02, MSE(e): 4.666e-06, MSE(pi1): 1.093e-02, MSE(pi2): 1.178e-06, MSE(pi3): 9.502e-04\n",
      "Epoch 395700, Train loss: 4.243e+02, Test loss: 1.101e+03, MSE(e): 2.244e-05, MSE(pi1): 9.616e-03, MSE(pi2): 1.008e-05, MSE(pi3): 1.037e-03\n",
      "Epoch 395800, Train loss: 8.303e+02, Test loss: 1.723e+03, MSE(e): 4.049e-05, MSE(pi1): 3.295e-02, MSE(pi2): 1.758e-05, MSE(pi3): 9.594e-04\n",
      "Epoch 395900, Train loss: 3.169e+02, Test loss: 1.192e+03, MSE(e): 8.453e-06, MSE(pi1): 1.445e-02, MSE(pi2): 2.726e-06, MSE(pi3): 8.785e-04\n",
      "Epoch 396000, Train loss: 1.184e+03, Test loss: 1.757e+03, MSE(e): 9.815e-05, MSE(pi1): 1.222e-02, MSE(pi2): 4.580e-05, MSE(pi3): 8.010e-04\n",
      "Epoch 396100, Train loss: 2.981e+02, Test loss: 1.038e+03, MSE(e): 8.494e-06, MSE(pi1): 1.179e-02, MSE(pi2): 3.487e-06, MSE(pi3): 9.521e-04\n",
      "Epoch 396200, Train loss: 4.922e+02, Test loss: 1.753e+03, MSE(e): 3.542e-05, MSE(pi1): 4.284e-03, MSE(pi2): 1.683e-05, MSE(pi3): 9.515e-04\n",
      "Epoch 396300, Train loss: 1.651e+02, Test loss: 1.012e+03, MSE(e): 2.050e-06, MSE(pi1): 5.245e-03, MSE(pi2): 7.655e-07, MSE(pi3): 9.218e-04\n",
      "Epoch 396400, Train loss: 1.455e+02, Test loss: 9.459e+02, MSE(e): 1.539e-06, MSE(pi1): 3.505e-03, MSE(pi2): 7.352e-07, MSE(pi3): 9.509e-04\n",
      "Epoch 396500, Train loss: 1.166e+03, Test loss: 2.028e+03, MSE(e): 9.987e-05, MSE(pi1): 7.450e-03, MSE(pi2): 4.691e-05, MSE(pi3): 9.304e-04\n",
      "Epoch 396600, Train loss: 3.279e+02, Test loss: 1.339e+03, MSE(e): 1.908e-05, MSE(pi1): 3.575e-03, MSE(pi2): 9.212e-06, MSE(pi3): 1.013e-03\n",
      "Epoch 396700, Train loss: 5.543e+02, Test loss: 1.284e+03, MSE(e): 2.272e-05, MSE(pi1): 2.206e-02, MSE(pi2): 7.630e-06, MSE(pi3): 1.065e-03\n",
      "Epoch 396800, Train loss: 2.450e+02, Test loss: 1.095e+03, MSE(e): 8.317e-06, MSE(pi1): 6.286e-03, MSE(pi2): 4.047e-06, MSE(pi3): 9.895e-04\n",
      "Epoch 396900, Train loss: 2.898e+02, Test loss: 9.889e+02, MSE(e): 1.083e-05, MSE(pi1): 9.464e-03, MSE(pi2): 4.197e-06, MSE(pi3): 8.687e-04\n",
      "Epoch 397000, Train loss: 3.296e+02, Test loss: 1.203e+03, MSE(e): 5.965e-06, MSE(pi1): 1.798e-02, MSE(pi2): 1.331e-06, MSE(pi3): 9.016e-04\n",
      "Epoch 397100, Train loss: 3.006e+02, Test loss: 1.067e+03, MSE(e): 1.065e-05, MSE(pi1): 1.087e-02, MSE(pi2): 5.223e-06, MSE(pi3): 8.530e-04\n",
      "Epoch 397200, Train loss: 8.538e+02, Test loss: 1.068e+03, MSE(e): 6.774e-05, MSE(pi1): 8.166e-03, MSE(pi2): 3.246e-05, MSE(pi3): 9.473e-04\n",
      "Epoch 397300, Train loss: 1.734e+02, Test loss: 1.001e+03, MSE(e): 2.213e-06, MSE(pi1): 6.098e-03, MSE(pi2): 9.035e-07, MSE(pi3): 9.033e-04\n",
      "Epoch 397400, Train loss: 4.670e+02, Test loss: 1.639e+03, MSE(e): 2.625e-05, MSE(pi1): 9.663e-03, MSE(pi2): 1.285e-05, MSE(pi3): 1.079e-03\n",
      "Epoch 397500, Train loss: 2.665e+02, Test loss: 1.062e+03, MSE(e): 4.409e-06, MSE(pi1): 1.324e-02, MSE(pi2): 1.420e-06, MSE(pi3): 9.001e-04\n",
      "Epoch 397600, Train loss: 1.053e+03, Test loss: 1.973e+03, MSE(e): 8.173e-05, MSE(pi1): 1.361e-02, MSE(pi2): 3.974e-05, MSE(pi3): 9.952e-04\n",
      "Epoch 397700, Train loss: 4.805e+02, Test loss: 1.280e+03, MSE(e): 3.039e-05, MSE(pi1): 7.703e-03, MSE(pi2): 1.319e-05, MSE(pi3): 9.954e-04\n",
      "Epoch 397800, Train loss: 2.387e+02, Test loss: 1.183e+03, MSE(e): 9.978e-06, MSE(pi1): 4.522e-03, MSE(pi2): 4.429e-06, MSE(pi3): 9.373e-04\n",
      "Epoch 397900, Train loss: 2.442e+02, Test loss: 9.379e+02, MSE(e): 7.719e-06, MSE(pi1): 7.857e-03, MSE(pi2): 3.703e-06, MSE(pi3): 8.841e-04\n",
      "Epoch 398000, Train loss: 2.214e+02, Test loss: 1.089e+03, MSE(e): 3.473e-06, MSE(pi1): 8.946e-03, MSE(pi2): 1.327e-06, MSE(pi3): 9.718e-04\n",
      "Epoch 398100, Train loss: 2.738e+02, Test loss: 1.014e+03, MSE(e): 5.239e-06, MSE(pi1): 1.187e-02, MSE(pi2): 1.326e-06, MSE(pi3): 1.026e-03\n",
      "Epoch 398200, Train loss: 2.771e+02, Test loss: 1.129e+03, MSE(e): 4.980e-06, MSE(pi1): 1.413e-02, MSE(pi2): 1.265e-06, MSE(pi3): 8.599e-04\n",
      "Epoch 398300, Train loss: 6.324e+02, Test loss: 1.210e+03, MSE(e): 3.908e-05, MSE(pi1): 1.321e-02, MSE(pi2): 1.562e-05, MSE(pi3): 1.094e-03\n",
      "Epoch 398400, Train loss: 6.619e+02, Test loss: 1.955e+03, MSE(e): 3.711e-05, MSE(pi1): 1.775e-02, MSE(pi2): 1.590e-05, MSE(pi3): 1.133e-03\n",
      "Epoch 398500, Train loss: 7.267e+02, Test loss: 1.468e+03, MSE(e): 3.008e-05, MSE(pi1): 3.315e-02, MSE(pi2): 1.310e-05, MSE(pi3): 9.439e-04\n",
      "Epoch 398600, Train loss: 3.443e+02, Test loss: 1.397e+03, MSE(e): 1.211e-05, MSE(pi1): 1.108e-02, MSE(pi2): 5.802e-06, MSE(pi3): 1.124e-03\n",
      "Epoch 398700, Train loss: 4.369e+02, Test loss: 1.285e+03, MSE(e): 2.317e-05, MSE(pi1): 1.145e-02, MSE(pi2): 1.190e-05, MSE(pi3): 9.073e-04\n",
      "Epoch 398800, Train loss: 1.412e+03, Test loss: 2.151e+03, MSE(e): 1.222e-04, MSE(pi1): 8.941e-03, MSE(pi2): 5.759e-05, MSE(pi3): 1.005e-03\n",
      "Epoch 398900, Train loss: 1.038e+03, Test loss: 2.507e+03, MSE(e): 6.829e-05, MSE(pi1): 2.238e-02, MSE(pi2): 3.209e-05, MSE(pi3): 1.314e-03\n",
      "Epoch 399000, Train loss: 1.591e+02, Test loss: 9.455e+02, MSE(e): 2.802e-06, MSE(pi1): 3.894e-03, MSE(pi2): 1.334e-06, MSE(pi3): 9.216e-04\n",
      "Epoch 399100, Train loss: 1.147e+03, Test loss: 2.100e+03, MSE(e): 9.765e-05, MSE(pi1): 7.463e-03, MSE(pi2): 4.594e-05, MSE(pi3): 9.619e-04\n",
      "Epoch 399200, Train loss: 3.401e+02, Test loss: 1.137e+03, MSE(e): 1.007e-05, MSE(pi1): 1.544e-02, MSE(pi2): 3.839e-06, MSE(pi3): 8.489e-04\n",
      "Epoch 399300, Train loss: 1.662e+03, Test loss: 2.541e+03, MSE(e): 1.422e-04, MSE(pi1): 1.580e-02, MSE(pi2): 6.888e-05, MSE(pi3): 8.168e-04\n",
      "Epoch 399400, Train loss: 4.456e+02, Test loss: 1.669e+03, MSE(e): 2.666e-05, MSE(pi1): 8.560e-03, MSE(pi2): 1.193e-05, MSE(pi3): 9.341e-04\n",
      "Epoch 399500, Train loss: 3.161e+02, Test loss: 1.182e+03, MSE(e): 1.404e-05, MSE(pi1): 7.766e-03, MSE(pi2): 5.432e-06, MSE(pi3): 9.805e-04\n",
      "Epoch 399600, Train loss: 1.858e+02, Test loss: 1.099e+03, MSE(e): 4.459e-06, MSE(pi1): 4.864e-03, MSE(pi2): 1.960e-06, MSE(pi3): 9.254e-04\n",
      "Epoch 399700, Train loss: 2.289e+02, Test loss: 1.135e+03, MSE(e): 4.814e-06, MSE(pi1): 8.036e-03, MSE(pi2): 2.067e-06, MSE(pi3): 1.004e-03\n",
      "Epoch 399800, Train loss: 2.394e+02, Test loss: 1.015e+03, MSE(e): 4.789e-06, MSE(pi1): 8.970e-03, MSE(pi2): 1.335e-06, MSE(pi3): 1.018e-03\n",
      "Epoch 399900, Train loss: 2.974e+02, Test loss: 1.205e+03, MSE(e): 4.734e-06, MSE(pi1): 1.394e-02, MSE(pi2): 1.302e-06, MSE(pi3): 1.107e-03\n",
      "Epoch 400000, Train loss: 1.664e+02, Test loss: 9.500e+02, MSE(e): 2.793e-06, MSE(pi1): 4.079e-03, MSE(pi2): 1.279e-06, MSE(pi3): 9.769e-04\n",
      "Epoch 400100, Train loss: 3.293e+02, Test loss: 1.156e+03, MSE(e): 5.893e-06, MSE(pi1): 1.826e-02, MSE(pi2): 1.506e-06, MSE(pi3): 8.775e-04\n",
      "Epoch 400200, Train loss: 2.404e+02, Test loss: 1.085e+03, MSE(e): 3.606e-06, MSE(pi1): 1.148e-02, MSE(pi2): 1.013e-06, MSE(pi3): 8.960e-04\n",
      "Epoch 400300, Train loss: 4.225e+02, Test loss: 1.082e+03, MSE(e): 1.963e-05, MSE(pi1): 1.154e-02, MSE(pi2): 8.553e-06, MSE(pi3): 1.108e-03\n",
      "Epoch 400400, Train loss: 2.267e+02, Test loss: 9.860e+02, MSE(e): 6.395e-06, MSE(pi1): 7.599e-03, MSE(pi2): 2.849e-06, MSE(pi3): 8.672e-04\n",
      "Epoch 400500, Train loss: 3.408e+02, Test loss: 1.139e+03, MSE(e): 8.510e-06, MSE(pi1): 1.561e-02, MSE(pi2): 2.650e-06, MSE(pi3): 9.957e-04\n",
      "Epoch 400600, Train loss: 2.580e+02, Test loss: 1.224e+03, MSE(e): 1.100e-05, MSE(pi1): 5.477e-03, MSE(pi2): 4.657e-06, MSE(pi3): 9.322e-04\n",
      "Epoch 400700, Train loss: 2.233e+02, Test loss: 1.185e+03, MSE(e): 7.879e-06, MSE(pi1): 5.002e-03, MSE(pi2): 3.784e-06, MSE(pi3): 9.450e-04\n",
      "Epoch 400800, Train loss: 2.365e+02, Test loss: 1.141e+03, MSE(e): 3.439e-06, MSE(pi1): 1.133e-02, MSE(pi2): 1.224e-06, MSE(pi3): 8.876e-04\n",
      "Epoch 400900, Train loss: 1.775e+02, Test loss: 1.027e+03, MSE(e): 2.241e-06, MSE(pi1): 5.837e-03, MSE(pi2): 7.987e-07, MSE(pi3): 9.671e-04\n",
      "Epoch 401000, Train loss: 2.694e+02, Test loss: 1.222e+03, MSE(e): 7.079e-06, MSE(pi1): 1.099e-02, MSE(pi2): 2.220e-06, MSE(pi3): 8.868e-04\n",
      "Epoch 401100, Train loss: 1.680e+02, Test loss: 9.903e+02, MSE(e): 1.931e-06, MSE(pi1): 5.494e-03, MSE(pi2): 8.306e-07, MSE(pi3): 9.375e-04\n",
      "Epoch 401200, Train loss: 1.920e+02, Test loss: 9.479e+02, MSE(e): 4.801e-06, MSE(pi1): 4.853e-03, MSE(pi2): 2.538e-06, MSE(pi3): 9.550e-04\n",
      "Epoch 401300, Train loss: 2.121e+02, Test loss: 1.035e+03, MSE(e): 4.425e-06, MSE(pi1): 7.853e-03, MSE(pi2): 1.957e-06, MSE(pi3): 8.933e-04\n",
      "Epoch 401400, Train loss: 1.664e+02, Test loss: 1.001e+03, MSE(e): 2.192e-06, MSE(pi1): 4.834e-03, MSE(pi2): 8.944e-07, MSE(pi3): 9.615e-04\n",
      "Epoch 401500, Train loss: 1.624e+02, Test loss: 1.021e+03, MSE(e): 2.903e-06, MSE(pi1): 3.545e-03, MSE(pi2): 1.460e-06, MSE(pi3): 9.791e-04\n",
      "Epoch 401600, Train loss: 3.819e+02, Test loss: 1.486e+03, MSE(e): 1.460e-05, MSE(pi1): 1.320e-02, MSE(pi2): 6.384e-06, MSE(pi3): 1.039e-03\n",
      "Epoch 401700, Train loss: 6.262e+02, Test loss: 1.905e+03, MSE(e): 4.729e-05, MSE(pi1): 5.846e-03, MSE(pi2): 2.192e-05, MSE(pi3): 9.484e-04\n",
      "Epoch 401800, Train loss: 1.532e+03, Test loss: 1.413e+03, MSE(e): 1.363e-04, MSE(pi1): 8.353e-03, MSE(pi2): 6.523e-05, MSE(pi3): 8.602e-04\n",
      "Epoch 401900, Train loss: 1.779e+02, Test loss: 9.294e+02, MSE(e): 4.960e-06, MSE(pi1): 3.542e-03, MSE(pi2): 2.331e-06, MSE(pi3): 9.284e-04\n",
      "Epoch 402000, Train loss: 2.291e+02, Test loss: 1.145e+03, MSE(e): 3.400e-06, MSE(pi1): 9.329e-03, MSE(pi2): 1.150e-06, MSE(pi3): 1.018e-03\n",
      "Epoch 402100, Train loss: 2.846e+02, Test loss: 1.112e+03, MSE(e): 7.471e-06, MSE(pi1): 1.049e-02, MSE(pi2): 2.589e-06, MSE(pi3): 1.050e-03\n",
      "Epoch 402200, Train loss: 1.623e+02, Test loss: 9.572e+02, MSE(e): 2.640e-06, MSE(pi1): 4.340e-03, MSE(pi2): 1.213e-06, MSE(pi3): 9.250e-04\n",
      "Epoch 402300, Train loss: 5.833e+02, Test loss: 1.504e+03, MSE(e): 1.831e-05, MSE(pi1): 3.013e-02, MSE(pi2): 6.897e-06, MSE(pi3): 9.889e-04\n",
      "Epoch 402400, Train loss: 1.455e+02, Test loss: 9.674e+02, MSE(e): 1.508e-06, MSE(pi1): 3.373e-03, MSE(pi2): 7.033e-07, MSE(pi3): 9.668e-04\n",
      "Epoch 402500, Train loss: 1.518e+02, Test loss: 9.683e+02, MSE(e): 1.671e-06, MSE(pi1): 4.204e-03, MSE(pi2): 7.345e-07, MSE(pi3): 9.300e-04\n",
      "Epoch 402600, Train loss: 1.217e+03, Test loss: 1.852e+03, MSE(e): 1.011e-04, MSE(pi1): 1.177e-02, MSE(pi2): 4.780e-05, MSE(pi3): 8.764e-04\n",
      "Epoch 402700, Train loss: 2.762e+02, Test loss: 1.035e+03, MSE(e): 1.102e-05, MSE(pi1): 7.924e-03, MSE(pi2): 5.779e-06, MSE(pi3): 8.679e-04\n",
      "Epoch 402800, Train loss: 1.269e+03, Test loss: 2.381e+03, MSE(e): 8.147e-05, MSE(pi1): 3.725e-02, MSE(pi2): 3.904e-05, MSE(pi3): 8.125e-04\n",
      "Epoch 402900, Train loss: 2.632e+02, Test loss: 1.105e+03, MSE(e): 4.397e-06, MSE(pi1): 1.222e-02, MSE(pi2): 1.124e-06, MSE(pi3): 9.699e-04\n",
      "Epoch 403000, Train loss: 7.406e+02, Test loss: 1.873e+03, MSE(e): 4.359e-05, MSE(pi1): 1.815e-02, MSE(pi2): 2.133e-05, MSE(pi3): 1.233e-03\n",
      "Epoch 403100, Train loss: 2.107e+02, Test loss: 9.662e+02, MSE(e): 3.972e-06, MSE(pi1): 7.716e-03, MSE(pi2): 1.803e-06, MSE(pi3): 9.384e-04\n",
      "Epoch 403200, Train loss: 2.039e+02, Test loss: 1.053e+03, MSE(e): 2.633e-06, MSE(pi1): 8.754e-03, MSE(pi2): 8.245e-07, MSE(pi3): 9.007e-04\n",
      "Epoch 403300, Train loss: 2.575e+02, Test loss: 1.137e+03, MSE(e): 4.829e-06, MSE(pi1): 1.172e-02, MSE(pi2): 1.193e-06, MSE(pi3): 9.202e-04\n",
      "Epoch 403400, Train loss: 6.159e+02, Test loss: 1.216e+03, MSE(e): 4.613e-05, MSE(pi1): 6.068e-03, MSE(pi2): 1.983e-05, MSE(pi3): 9.399e-04\n",
      "Epoch 403500, Train loss: 2.182e+02, Test loss: 1.124e+03, MSE(e): 3.845e-06, MSE(pi1): 9.158e-03, MSE(pi2): 1.117e-06, MSE(pi3): 8.816e-04\n",
      "Epoch 403600, Train loss: 5.874e+02, Test loss: 1.941e+03, MSE(e): 3.450e-05, MSE(pi1): 1.378e-02, MSE(pi2): 1.671e-05, MSE(pi3): 1.046e-03\n",
      "Epoch 403700, Train loss: 1.603e+02, Test loss: 9.952e+02, MSE(e): 1.685e-06, MSE(pi1): 5.205e-03, MSE(pi2): 7.437e-07, MSE(pi3): 9.138e-04\n",
      "Epoch 403800, Train loss: 3.199e+02, Test loss: 1.086e+03, MSE(e): 6.461e-06, MSE(pi1): 1.576e-02, MSE(pi2): 1.426e-06, MSE(pi3): 9.769e-04\n",
      "Epoch 403900, Train loss: 1.790e+02, Test loss: 1.038e+03, MSE(e): 2.524e-06, MSE(pi1): 6.308e-03, MSE(pi2): 9.624e-07, MSE(pi3): 9.070e-04\n",
      "Epoch 404000, Train loss: 8.448e+02, Test loss: 2.390e+03, MSE(e): 6.553e-05, MSE(pi1): 9.583e-03, MSE(pi2): 2.956e-05, MSE(pi3): 9.368e-04\n",
      "Epoch 404100, Train loss: 2.523e+02, Test loss: 1.151e+03, MSE(e): 4.008e-06, MSE(pi1): 1.164e-02, MSE(pi2): 1.173e-06, MSE(pi3): 9.582e-04\n",
      "Epoch 404200, Train loss: 1.082e+03, Test loss: 1.837e+03, MSE(e): 9.279e-05, MSE(pi1): 7.005e-03, MSE(pi2): 4.544e-05, MSE(pi3): 8.442e-04\n",
      "Epoch 404300, Train loss: 9.689e+02, Test loss: 2.504e+03, MSE(e): 8.193e-05, MSE(pi1): 4.117e-03, MSE(pi2): 3.962e-05, MSE(pi3): 1.084e-03\n",
      "Epoch 404400, Train loss: 2.973e+02, Test loss: 1.195e+03, MSE(e): 5.797e-06, MSE(pi1): 1.283e-02, MSE(pi2): 1.629e-06, MSE(pi3): 1.110e-03\n",
      "Epoch 404500, Train loss: 2.266e+02, Test loss: 1.063e+03, MSE(e): 3.255e-06, MSE(pi1): 9.303e-03, MSE(pi2): 1.011e-06, MSE(pi3): 1.010e-03\n",
      "Epoch 404600, Train loss: 3.295e+02, Test loss: 1.336e+03, MSE(e): 6.851e-06, MSE(pi1): 1.779e-02, MSE(pi2): 1.901e-06, MSE(pi3): 8.305e-04\n",
      "Epoch 404700, Train loss: 1.588e+02, Test loss: 1.003e+03, MSE(e): 1.656e-06, MSE(pi1): 4.411e-03, MSE(pi2): 7.276e-07, MSE(pi3): 9.814e-04\n",
      "Epoch 404800, Train loss: 2.372e+02, Test loss: 1.094e+03, MSE(e): 3.584e-06, MSE(pi1): 1.030e-02, MSE(pi2): 9.986e-07, MSE(pi3): 9.836e-04\n",
      "Epoch 404900, Train loss: 1.952e+02, Test loss: 9.786e+02, MSE(e): 4.064e-06, MSE(pi1): 5.387e-03, MSE(pi2): 1.554e-06, MSE(pi3): 1.007e-03\n",
      "Epoch 405000, Train loss: 1.662e+02, Test loss: 9.965e+02, MSE(e): 2.913e-06, MSE(pi1): 4.471e-03, MSE(pi2): 1.259e-06, MSE(pi3): 9.238e-04\n",
      "Epoch 405100, Train loss: 7.412e+02, Test loss: 1.548e+03, MSE(e): 4.956e-05, MSE(pi1): 1.564e-02, MSE(pi2): 2.396e-05, MSE(pi3): 8.918e-04\n",
      "Epoch 405200, Train loss: 2.811e+02, Test loss: 1.063e+03, MSE(e): 8.306e-06, MSE(pi1): 9.365e-03, MSE(pi2): 3.125e-06, MSE(pi3): 1.044e-03\n",
      "Epoch 405300, Train loss: 2.301e+02, Test loss: 1.058e+03, MSE(e): 4.473e-06, MSE(pi1): 8.272e-03, MSE(pi2): 1.369e-06, MSE(pi3): 1.026e-03\n",
      "Epoch 405400, Train loss: 1.810e+03, Test loss: 3.296e+03, MSE(e): 1.659e-04, MSE(pi1): 4.232e-03, MSE(pi2): 7.855e-05, MSE(pi3): 1.083e-03\n",
      "Epoch 405500, Train loss: 2.689e+02, Test loss: 1.106e+03, MSE(e): 4.267e-06, MSE(pi1): 1.278e-02, MSE(pi2): 1.203e-06, MSE(pi3): 9.838e-04\n",
      "Epoch 405600, Train loss: 6.682e+02, Test loss: 1.437e+03, MSE(e): 2.621e-05, MSE(pi1): 3.111e-02, MSE(pi2): 9.445e-06, MSE(pi3): 9.505e-04\n",
      "Epoch 405700, Train loss: 2.117e+02, Test loss: 9.847e+02, MSE(e): 3.022e-06, MSE(pi1): 7.789e-03, MSE(pi2): 1.074e-06, MSE(pi3): 1.035e-03\n",
      "Epoch 405800, Train loss: 1.829e+02, Test loss: 1.081e+03, MSE(e): 3.287e-06, MSE(pi1): 4.789e-03, MSE(pi2): 1.516e-06, MSE(pi3): 1.021e-03\n",
      "Epoch 405900, Train loss: 2.222e+02, Test loss: 1.047e+03, MSE(e): 3.186e-06, MSE(pi1): 8.342e-03, MSE(pi2): 9.721e-07, MSE(pi3): 1.070e-03\n",
      "Epoch 406000, Train loss: 2.330e+02, Test loss: 1.062e+03, MSE(e): 3.536e-06, MSE(pi1): 9.362e-03, MSE(pi2): 9.904e-07, MSE(pi3): 1.040e-03\n",
      "Epoch 406100, Train loss: 3.750e+02, Test loss: 1.380e+03, MSE(e): 1.622e-05, MSE(pi1): 1.216e-02, MSE(pi2): 5.821e-06, MSE(pi3): 9.120e-04\n",
      "Epoch 406200, Train loss: 1.699e+02, Test loss: 1.021e+03, MSE(e): 2.059e-06, MSE(pi1): 5.177e-03, MSE(pi2): 7.783e-07, MSE(pi3): 9.754e-04\n",
      "Epoch 406300, Train loss: 2.159e+02, Test loss: 1.114e+03, MSE(e): 5.422e-06, MSE(pi1): 7.145e-03, MSE(pi2): 2.109e-06, MSE(pi3): 9.019e-04\n",
      "Epoch 406400, Train loss: 3.917e+02, Test loss: 1.151e+03, MSE(e): 1.670e-05, MSE(pi1): 1.216e-02, MSE(pi2): 7.247e-06, MSE(pi3): 1.031e-03\n",
      "Epoch 406500, Train loss: 3.345e+02, Test loss: 1.012e+03, MSE(e): 7.884e-06, MSE(pi1): 1.507e-02, MSE(pi2): 2.437e-06, MSE(pi3): 1.049e-03\n",
      "Epoch 406600, Train loss: 3.103e+02, Test loss: 1.254e+03, MSE(e): 5.166e-06, MSE(pi1): 1.728e-02, MSE(pi2): 1.515e-06, MSE(pi3): 8.588e-04\n",
      "Epoch 406700, Train loss: 4.027e+02, Test loss: 1.440e+03, MSE(e): 7.407e-06, MSE(pi1): 2.100e-02, MSE(pi2): 1.847e-06, MSE(pi3): 1.187e-03\n",
      "Epoch 406800, Train loss: 9.538e+02, Test loss: 2.315e+03, MSE(e): 4.384e-05, MSE(pi1): 3.821e-02, MSE(pi2): 1.729e-05, MSE(pi3): 1.332e-03\n",
      "Epoch 406900, Train loss: 2.034e+02, Test loss: 9.350e+02, MSE(e): 7.610e-06, MSE(pi1): 3.516e-03, MSE(pi2): 3.577e-06, MSE(pi3): 9.218e-04\n",
      "Epoch 407000, Train loss: 1.660e+02, Test loss: 9.665e+02, MSE(e): 1.868e-06, MSE(pi1): 4.894e-03, MSE(pi2): 7.048e-07, MSE(pi3): 9.836e-04\n",
      "Epoch 407100, Train loss: 2.951e+02, Test loss: 1.081e+03, MSE(e): 5.403e-06, MSE(pi1): 1.375e-02, MSE(pi2): 1.423e-06, MSE(pi3): 1.036e-03\n",
      "Epoch 407200, Train loss: 2.006e+02, Test loss: 9.486e+02, MSE(e): 4.793e-06, MSE(pi1): 5.018e-03, MSE(pi2): 2.150e-06, MSE(pi3): 1.025e-03\n",
      "Epoch 407300, Train loss: 4.160e+02, Test loss: 1.453e+03, MSE(e): 8.240e-06, MSE(pi1): 2.156e-02, MSE(pi2): 2.032e-06, MSE(pi3): 1.180e-03\n",
      "Epoch 407400, Train loss: 1.964e+02, Test loss: 1.050e+03, MSE(e): 2.612e-06, MSE(pi1): 7.060e-03, MSE(pi2): 8.087e-07, MSE(pi3): 9.964e-04\n",
      "Epoch 407500, Train loss: 2.083e+03, Test loss: 4.299e+03, MSE(e): 1.860e-04, MSE(pi1): 1.240e-02, MSE(pi2): 8.585e-05, MSE(pi3): 9.885e-04\n",
      "Epoch 407600, Train loss: 5.066e+02, Test loss: 1.101e+03, MSE(e): 3.234e-05, MSE(pi1): 8.336e-03, MSE(pi2): 1.528e-05, MSE(pi3): 9.979e-04\n",
      "Epoch 407700, Train loss: 2.170e+02, Test loss: 1.140e+03, MSE(e): 6.697e-06, MSE(pi1): 4.904e-03, MSE(pi2): 3.094e-06, MSE(pi3): 1.010e-03\n",
      "Epoch 407800, Train loss: 2.402e+02, Test loss: 1.044e+03, MSE(e): 4.000e-06, MSE(pi1): 1.000e-02, MSE(pi2): 1.103e-06, MSE(pi3): 1.002e-03\n",
      "Epoch 407900, Train loss: 4.177e+02, Test loss: 1.397e+03, MSE(e): 1.289e-05, MSE(pi1): 1.995e-02, MSE(pi2): 4.233e-06, MSE(pi3): 8.934e-04\n",
      "Epoch 408000, Train loss: 3.309e+02, Test loss: 1.237e+03, MSE(e): 5.570e-06, MSE(pi1): 1.762e-02, MSE(pi2): 1.312e-06, MSE(pi3): 9.899e-04\n",
      "Epoch 408100, Train loss: 3.628e+02, Test loss: 1.457e+03, MSE(e): 1.851e-05, MSE(pi1): 9.084e-03, MSE(pi2): 6.902e-06, MSE(pi3): 8.686e-04\n",
      "Epoch 408200, Train loss: 1.048e+03, Test loss: 2.420e+03, MSE(e): 8.097e-05, MSE(pi1): 1.543e-02, MSE(pi2): 3.794e-05, MSE(pi3): 8.443e-04\n",
      "Epoch 408300, Train loss: 7.683e+02, Test loss: 2.162e+03, MSE(e): 6.146e-05, MSE(pi1): 4.626e-03, MSE(pi2): 2.866e-05, MSE(pi3): 1.074e-03\n",
      "Epoch 408400, Train loss: 1.619e+02, Test loss: 9.525e+02, MSE(e): 3.210e-06, MSE(pi1): 4.081e-03, MSE(pi2): 1.613e-06, MSE(pi3): 8.896e-04\n",
      "Epoch 408500, Train loss: 6.672e+02, Test loss: 1.604e+03, MSE(e): 1.610e-05, MSE(pi1): 4.011e-02, MSE(pi2): 3.905e-06, MSE(pi3): 1.051e-03\n",
      "Epoch 408600, Train loss: 1.799e+02, Test loss: 1.025e+03, MSE(e): 2.951e-06, MSE(pi1): 5.967e-03, MSE(pi2): 1.296e-06, MSE(pi3): 9.072e-04\n",
      "Epoch 408700, Train loss: 2.159e+02, Test loss: 1.030e+03, MSE(e): 3.100e-06, MSE(pi1): 8.325e-03, MSE(pi2): 1.015e-06, MSE(pi3): 1.017e-03\n",
      "Epoch 408800, Train loss: 1.906e+02, Test loss: 1.058e+03, MSE(e): 2.415e-06, MSE(pi1): 7.249e-03, MSE(pi2): 8.718e-07, MSE(pi3): 9.399e-04\n",
      "Epoch 408900, Train loss: 4.226e+02, Test loss: 1.478e+03, MSE(e): 1.121e-05, MSE(pi1): 2.181e-02, MSE(pi2): 2.792e-06, MSE(pi3): 9.242e-04\n",
      "Epoch 409000, Train loss: 1.474e+02, Test loss: 9.591e+02, MSE(e): 1.472e-06, MSE(pi1): 4.094e-03, MSE(pi2): 6.818e-07, MSE(pi3): 9.176e-04\n",
      "Epoch 409100, Train loss: 1.713e+02, Test loss: 9.620e+02, MSE(e): 2.168e-06, MSE(pi1): 5.884e-03, MSE(pi2): 8.354e-07, MSE(pi3): 9.074e-04\n",
      "Epoch 409200, Train loss: 3.761e+02, Test loss: 1.198e+03, MSE(e): 9.385e-06, MSE(pi1): 1.696e-02, MSE(pi2): 2.952e-06, MSE(pi3): 1.126e-03\n",
      "Epoch 409300, Train loss: 1.512e+02, Test loss: 1.000e+03, MSE(e): 1.498e-06, MSE(pi1): 4.123e-03, MSE(pi2): 6.730e-07, MSE(pi3): 9.499e-04\n",
      "Epoch 409400, Train loss: 8.037e+02, Test loss: 1.696e+03, MSE(e): 5.499e-05, MSE(pi1): 1.595e-02, MSE(pi2): 2.491e-05, MSE(pi3): 9.423e-04\n",
      "Epoch 409500, Train loss: 3.327e+02, Test loss: 1.316e+03, MSE(e): 8.666e-06, MSE(pi1): 1.329e-02, MSE(pi2): 3.404e-06, MSE(pi3): 1.132e-03\n",
      "Epoch 409600, Train loss: 2.446e+02, Test loss: 1.254e+03, MSE(e): 6.722e-06, MSE(pi1): 7.894e-03, MSE(pi2): 3.040e-06, MSE(pi3): 9.843e-04\n",
      "Epoch 409700, Train loss: 3.540e+02, Test loss: 1.321e+03, MSE(e): 1.724e-05, MSE(pi1): 7.452e-03, MSE(pi2): 8.143e-06, MSE(pi3): 1.071e-03\n",
      "Epoch 409800, Train loss: 3.401e+02, Test loss: 9.776e+02, MSE(e): 1.899e-05, MSE(pi1): 5.950e-03, MSE(pi2): 7.543e-06, MSE(pi3): 9.063e-04\n",
      "Epoch 409900, Train loss: 2.935e+02, Test loss: 1.116e+03, MSE(e): 8.574e-06, MSE(pi1): 1.229e-02, MSE(pi2): 3.805e-06, MSE(pi3): 8.493e-04\n",
      "Epoch 410000, Train loss: 3.700e+02, Test loss: 1.263e+03, MSE(e): 6.639e-06, MSE(pi1): 2.123e-02, MSE(pi2): 2.019e-06, MSE(pi3): 9.130e-04\n",
      "Epoch 410100, Train loss: 2.153e+02, Test loss: 1.140e+03, MSE(e): 3.391e-06, MSE(pi1): 8.746e-03, MSE(pi2): 1.137e-06, MSE(pi3): 9.390e-04\n",
      "Epoch 410200, Train loss: 2.183e+02, Test loss: 1.209e+03, MSE(e): 5.054e-06, MSE(pi1): 7.664e-03, MSE(pi2): 1.657e-06, MSE(pi3): 9.109e-04\n",
      "Epoch 410300, Train loss: 2.601e+02, Test loss: 1.262e+03, MSE(e): 6.880e-06, MSE(pi1): 9.618e-03, MSE(pi2): 2.805e-06, MSE(pi3): 9.515e-04\n",
      "Epoch 410400, Train loss: 2.659e+02, Test loss: 1.253e+03, MSE(e): 1.003e-05, MSE(pi1): 6.513e-03, MSE(pi2): 4.371e-06, MSE(pi3): 1.004e-03\n",
      "Epoch 410500, Train loss: 5.334e+02, Test loss: 1.393e+03, MSE(e): 2.575e-05, MSE(pi1): 1.754e-02, MSE(pi2): 1.149e-05, MSE(pi3): 1.004e-03\n",
      "Epoch 410600, Train loss: 9.224e+02, Test loss: 2.503e+03, MSE(e): 7.822e-05, MSE(pi1): 4.162e-03, MSE(pi2): 3.659e-05, MSE(pi3): 9.856e-04\n",
      "Epoch 410700, Train loss: 2.205e+02, Test loss: 9.775e+02, MSE(e): 8.104e-06, MSE(pi1): 5.304e-03, MSE(pi2): 4.004e-06, MSE(pi3): 8.643e-04\n",
      "Epoch 410800, Train loss: 3.345e+02, Test loss: 1.348e+03, MSE(e): 5.429e-06, MSE(pi1): 1.828e-02, MSE(pi2): 1.323e-06, MSE(pi3): 9.746e-04\n",
      "Epoch 410900, Train loss: 2.187e+02, Test loss: 1.106e+03, MSE(e): 7.064e-06, MSE(pi1): 5.448e-03, MSE(pi2): 2.857e-06, MSE(pi3): 9.359e-04\n",
      "Epoch 411000, Train loss: 7.012e+02, Test loss: 1.527e+03, MSE(e): 4.856e-05, MSE(pi1): 1.104e-02, MSE(pi2): 2.390e-05, MSE(pi3): 1.052e-03\n",
      "Epoch 411100, Train loss: 4.711e+02, Test loss: 1.303e+03, MSE(e): 9.758e-06, MSE(pi1): 2.613e-02, MSE(pi2): 2.348e-06, MSE(pi3): 1.123e-03\n",
      "Epoch 411200, Train loss: 2.917e+02, Test loss: 1.240e+03, MSE(e): 6.201e-06, MSE(pi1): 1.328e-02, MSE(pi2): 1.771e-06, MSE(pi3): 9.681e-04\n",
      "Epoch 411300, Train loss: 5.716e+02, Test loss: 1.300e+03, MSE(e): 4.211e-05, MSE(pi1): 6.347e-03, MSE(pi2): 2.099e-05, MSE(pi3): 8.701e-04\n",
      "Epoch 411400, Train loss: 6.015e+02, Test loss: 1.851e+03, MSE(e): 3.774e-05, MSE(pi1): 1.263e-02, MSE(pi2): 1.640e-05, MSE(pi3): 9.786e-04\n",
      "Epoch 411500, Train loss: 8.304e+02, Test loss: 2.181e+03, MSE(e): 5.912e-05, MSE(pi1): 1.293e-02, MSE(pi2): 2.635e-05, MSE(pi3): 1.099e-03\n",
      "Epoch 411600, Train loss: 2.057e+02, Test loss: 1.117e+03, MSE(e): 3.141e-06, MSE(pi1): 8.500e-03, MSE(pi2): 8.923e-07, MSE(pi3): 8.927e-04\n",
      "Epoch 411700, Train loss: 3.007e+02, Test loss: 1.196e+03, MSE(e): 5.279e-06, MSE(pi1): 1.524e-02, MSE(pi2): 1.346e-06, MSE(pi3): 9.551e-04\n",
      "Epoch 411800, Train loss: 3.197e+02, Test loss: 1.180e+03, MSE(e): 5.814e-06, MSE(pi1): 1.737e-02, MSE(pi2): 1.284e-06, MSE(pi3): 8.785e-04\n",
      "Epoch 411900, Train loss: 1.466e+02, Test loss: 9.653e+02, MSE(e): 1.852e-06, MSE(pi1): 3.198e-03, MSE(pi2): 9.462e-07, MSE(pi3): 9.610e-04\n",
      "Epoch 412000, Train loss: 1.861e+03, Test loss: 2.055e+03, MSE(e): 1.625e-04, MSE(pi1): 1.493e-02, MSE(pi2): 8.032e-05, MSE(pi3): 8.663e-04\n",
      "Epoch 412100, Train loss: 3.943e+02, Test loss: 1.258e+03, MSE(e): 7.810e-06, MSE(pi1): 1.986e-02, MSE(pi2): 1.507e-06, MSE(pi3): 1.176e-03\n",
      "Epoch 412200, Train loss: 4.247e+02, Test loss: 1.224e+03, MSE(e): 1.046e-05, MSE(pi1): 2.295e-02, MSE(pi2): 3.827e-06, MSE(pi3): 9.054e-04\n",
      "Epoch 412300, Train loss: 2.472e+02, Test loss: 9.833e+02, MSE(e): 5.156e-06, MSE(pi1): 8.719e-03, MSE(pi2): 1.589e-06, MSE(pi3): 1.084e-03\n",
      "Epoch 412400, Train loss: 1.845e+02, Test loss: 9.494e+02, MSE(e): 4.669e-06, MSE(pi1): 4.737e-03, MSE(pi2): 2.469e-06, MSE(pi3): 9.040e-04\n",
      "Epoch 412500, Train loss: 6.293e+02, Test loss: 1.427e+03, MSE(e): 3.447e-05, MSE(pi1): 1.835e-02, MSE(pi2): 1.299e-05, MSE(pi3): 1.012e-03\n",
      "Epoch 412600, Train loss: 1.939e+03, Test loss: 2.830e+03, MSE(e): 1.772e-04, MSE(pi1): 5.709e-03, MSE(pi2): 8.423e-05, MSE(pi3): 1.099e-03\n",
      "Epoch 412700, Train loss: 4.895e+02, Test loss: 1.195e+03, MSE(e): 3.333e-05, MSE(pi1): 6.260e-03, MSE(pi2): 1.473e-05, MSE(pi3): 9.361e-04\n",
      "Epoch 412800, Train loss: 2.109e+02, Test loss: 1.047e+03, MSE(e): 3.904e-06, MSE(pi1): 7.939e-03, MSE(pi2): 1.243e-06, MSE(pi3): 9.244e-04\n",
      "Epoch 412900, Train loss: 4.595e+02, Test loss: 1.480e+03, MSE(e): 3.012e-05, MSE(pi1): 6.075e-03, MSE(pi2): 1.398e-05, MSE(pi3): 9.760e-04\n",
      "Epoch 413000, Train loss: 1.842e+03, Test loss: 3.005e+03, MSE(e): 1.574e-04, MSE(pi1): 1.680e-02, MSE(pi2): 8.388e-05, MSE(pi3): 1.005e-03\n",
      "Epoch 413100, Train loss: 1.697e+02, Test loss: 1.027e+03, MSE(e): 2.038e-06, MSE(pi1): 5.448e-03, MSE(pi2): 7.596e-07, MSE(pi3): 9.487e-04\n",
      "Epoch 413200, Train loss: 1.687e+02, Test loss: 9.691e+02, MSE(e): 2.898e-06, MSE(pi1): 4.661e-03, MSE(pi2): 1.309e-06, MSE(pi3): 9.307e-04\n",
      "Epoch 413300, Train loss: 1.709e+02, Test loss: 9.982e+02, MSE(e): 3.489e-06, MSE(pi1): 4.128e-03, MSE(pi2): 1.316e-06, MSE(pi3): 9.477e-04\n",
      "Epoch 413400, Train loss: 3.735e+02, Test loss: 1.057e+03, MSE(e): 2.340e-05, MSE(pi1): 5.125e-03, MSE(pi2): 1.171e-05, MSE(pi3): 8.821e-04\n",
      "Epoch 413500, Train loss: 1.911e+02, Test loss: 1.127e+03, MSE(e): 5.865e-06, MSE(pi1): 3.510e-03, MSE(pi2): 2.838e-06, MSE(pi3): 9.733e-04\n",
      "Epoch 413600, Train loss: 3.538e+02, Test loss: 1.158e+03, MSE(e): 9.865e-06, MSE(pi1): 1.424e-02, MSE(pi2): 2.700e-06, MSE(pi3): 1.127e-03\n",
      "Epoch 413700, Train loss: 3.065e+02, Test loss: 1.013e+03, MSE(e): 1.083e-05, MSE(pi1): 1.127e-02, MSE(pi2): 4.461e-06, MSE(pi3): 8.557e-04\n",
      "Epoch 413800, Train loss: 1.814e+02, Test loss: 9.851e+02, MSE(e): 2.634e-06, MSE(pi1): 6.117e-03, MSE(pi2): 8.313e-07, MSE(pi3): 9.389e-04\n",
      "Epoch 413900, Train loss: 1.938e+02, Test loss: 9.954e+02, MSE(e): 3.041e-06, MSE(pi1): 6.439e-03, MSE(pi2): 1.196e-06, MSE(pi3): 9.900e-04\n",
      "Epoch 414000, Train loss: 1.775e+02, Test loss: 9.455e+02, MSE(e): 4.138e-06, MSE(pi1): 4.360e-03, MSE(pi2): 2.176e-06, MSE(pi3): 9.254e-04\n",
      "Epoch 414100, Train loss: 2.182e+02, Test loss: 1.323e+03, MSE(e): 6.623e-06, MSE(pi1): 5.736e-03, MSE(pi2): 2.725e-06, MSE(pi3): 9.465e-04\n",
      "Epoch 414200, Train loss: 2.175e+02, Test loss: 1.167e+03, MSE(e): 4.833e-06, MSE(pi1): 6.838e-03, MSE(pi2): 1.953e-06, MSE(pi3): 1.008e-03\n",
      "Epoch 414300, Train loss: 1.610e+02, Test loss: 1.017e+03, MSE(e): 1.756e-06, MSE(pi1): 4.369e-03, MSE(pi2): 7.131e-07, MSE(pi3): 9.978e-04\n",
      "Epoch 414400, Train loss: 2.692e+02, Test loss: 1.194e+03, MSE(e): 4.379e-06, MSE(pi1): 1.169e-02, MSE(pi2): 1.116e-06, MSE(pi3): 1.085e-03\n",
      "Epoch 414500, Train loss: 1.593e+02, Test loss: 1.020e+03, MSE(e): 1.738e-06, MSE(pi1): 4.949e-03, MSE(pi2): 6.912e-07, MSE(pi3): 9.245e-04\n",
      "Epoch 414600, Train loss: 1.836e+02, Test loss: 9.401e+02, MSE(e): 5.197e-06, MSE(pi1): 4.126e-03, MSE(pi2): 2.635e-06, MSE(pi3): 9.040e-04\n",
      "Epoch 414700, Train loss: 1.485e+03, Test loss: 2.334e+03, MSE(e): 1.307e-04, MSE(pi1): 7.674e-03, MSE(pi2): 6.257e-05, MSE(pi3): 1.009e-03\n",
      "Epoch 414800, Train loss: 3.677e+02, Test loss: 1.557e+03, MSE(e): 2.134e-05, MSE(pi1): 5.566e-03, MSE(pi2): 1.013e-05, MSE(pi3): 9.864e-04\n",
      "Epoch 414900, Train loss: 3.302e+02, Test loss: 1.270e+03, MSE(e): 9.778e-06, MSE(pi1): 1.159e-02, MSE(pi2): 4.393e-06, MSE(pi3): 1.165e-03\n",
      "Epoch 415000, Train loss: 2.117e+02, Test loss: 1.053e+03, MSE(e): 3.042e-06, MSE(pi1): 7.673e-03, MSE(pi2): 9.629e-07, MSE(pi3): 1.045e-03\n",
      "Epoch 415100, Train loss: 2.365e+02, Test loss: 1.095e+03, MSE(e): 3.782e-06, MSE(pi1): 1.025e-02, MSE(pi2): 1.157e-06, MSE(pi3): 9.618e-04\n",
      "Epoch 415200, Train loss: 2.834e+02, Test loss: 1.242e+03, MSE(e): 5.202e-06, MSE(pi1): 1.283e-02, MSE(pi2): 1.607e-06, MSE(pi3): 1.031e-03\n",
      "Epoch 415300, Train loss: 3.354e+02, Test loss: 1.318e+03, MSE(e): 5.581e-06, MSE(pi1): 1.900e-02, MSE(pi2): 1.567e-06, MSE(pi3): 8.957e-04\n",
      "Epoch 415400, Train loss: 2.985e+02, Test loss: 1.190e+03, MSE(e): 1.308e-05, MSE(pi1): 6.714e-03, MSE(pi2): 5.162e-06, MSE(pi3): 1.005e-03\n",
      "Epoch 415500, Train loss: 9.376e+02, Test loss: 2.667e+03, MSE(e): 6.562e-05, MSE(pi1): 1.881e-02, MSE(pi2): 2.894e-05, MSE(pi3): 9.331e-04\n",
      "Epoch 415600, Train loss: 3.538e+02, Test loss: 1.082e+03, MSE(e): 1.374e-05, MSE(pi1): 1.245e-02, MSE(pi2): 5.714e-06, MSE(pi3): 9.179e-04\n",
      "Epoch 415700, Train loss: 3.774e+02, Test loss: 1.096e+03, MSE(e): 2.336e-05, MSE(pi1): 5.179e-03, MSE(pi2): 1.198e-05, MSE(pi3): 9.203e-04\n",
      "Epoch 415800, Train loss: 2.456e+02, Test loss: 1.118e+03, MSE(e): 5.255e-06, MSE(pi1): 9.548e-03, MSE(pi2): 2.056e-06, MSE(pi3): 9.759e-04\n",
      "Epoch 415900, Train loss: 2.968e+02, Test loss: 1.161e+03, MSE(e): 5.093e-06, MSE(pi1): 1.467e-02, MSE(pi2): 1.227e-06, MSE(pi3): 9.923e-04\n",
      "Epoch 416000, Train loss: 2.269e+02, Test loss: 9.644e+02, MSE(e): 4.166e-06, MSE(pi1): 8.829e-03, MSE(pi2): 1.293e-06, MSE(pi3): 9.694e-04\n",
      "Epoch 416100, Train loss: 1.952e+02, Test loss: 1.027e+03, MSE(e): 2.862e-06, MSE(pi1): 7.138e-03, MSE(pi2): 9.345e-07, MSE(pi3): 9.515e-04\n",
      "Epoch 416200, Train loss: 2.630e+02, Test loss: 9.827e+02, MSE(e): 1.345e-05, MSE(pi1): 3.704e-03, MSE(pi2): 6.484e-06, MSE(pi3): 9.149e-04\n",
      "Epoch 416300, Train loss: 5.466e+02, Test loss: 1.449e+03, MSE(e): 2.871e-05, MSE(pi1): 1.757e-02, MSE(pi2): 1.411e-05, MSE(pi3): 8.385e-04\n",
      "Epoch 416400, Train loss: 5.188e+02, Test loss: 1.609e+03, MSE(e): 1.250e-05, MSE(pi1): 2.641e-02, MSE(pi2): 4.183e-06, MSE(pi3): 1.296e-03\n",
      "Epoch 416500, Train loss: 2.127e+02, Test loss: 1.184e+03, MSE(e): 6.301e-06, MSE(pi1): 5.294e-03, MSE(pi2): 2.989e-06, MSE(pi3): 9.672e-04\n",
      "Epoch 416600, Train loss: 1.537e+02, Test loss: 1.017e+03, MSE(e): 1.771e-06, MSE(pi1): 4.360e-03, MSE(pi2): 7.563e-07, MSE(pi3): 9.243e-04\n",
      "Epoch 416700, Train loss: 7.889e+02, Test loss: 1.617e+03, MSE(e): 6.049e-05, MSE(pi1): 9.745e-03, MSE(pi2): 3.058e-05, MSE(pi3): 8.649e-04\n",
      "Epoch 416800, Train loss: 4.139e+02, Test loss: 1.440e+03, MSE(e): 1.916e-05, MSE(pi1): 1.192e-02, MSE(pi2): 7.560e-06, MSE(pi3): 1.031e-03\n",
      "Epoch 416900, Train loss: 1.687e+02, Test loss: 1.032e+03, MSE(e): 3.387e-06, MSE(pi1): 4.039e-03, MSE(pi2): 1.680e-06, MSE(pi3): 9.441e-04\n",
      "Epoch 417000, Train loss: 2.458e+02, Test loss: 1.156e+03, MSE(e): 6.997e-06, MSE(pi1): 8.472e-03, MSE(pi2): 1.824e-06, MSE(pi3): 9.109e-04\n",
      "Epoch 417100, Train loss: 4.853e+02, Test loss: 1.533e+03, MSE(e): 1.110e-05, MSE(pi1): 2.464e-02, MSE(pi2): 4.076e-06, MSE(pi3): 1.278e-03\n",
      "Epoch 417200, Train loss: 1.027e+03, Test loss: 1.908e+03, MSE(e): 8.363e-05, MSE(pi1): 9.523e-03, MSE(pi2): 4.150e-05, MSE(pi3): 9.519e-04\n",
      "Epoch 417300, Train loss: 3.637e+02, Test loss: 1.077e+03, MSE(e): 9.964e-06, MSE(pi1): 1.611e-02, MSE(pi2): 3.187e-06, MSE(pi3): 1.029e-03\n",
      "Epoch 417400, Train loss: 2.953e+02, Test loss: 1.175e+03, MSE(e): 5.264e-06, MSE(pi1): 1.542e-02, MSE(pi2): 1.150e-06, MSE(pi3): 8.848e-04\n",
      "Epoch 417500, Train loss: 2.360e+02, Test loss: 1.134e+03, MSE(e): 3.466e-06, MSE(pi1): 9.683e-03, MSE(pi2): 9.310e-07, MSE(pi3): 1.046e-03\n",
      "Epoch 417600, Train loss: 6.573e+02, Test loss: 2.050e+03, MSE(e): 3.966e-05, MSE(pi1): 1.449e-02, MSE(pi2): 1.840e-05, MSE(pi3): 1.157e-03\n",
      "Epoch 417700, Train loss: 3.230e+02, Test loss: 1.323e+03, MSE(e): 1.415e-05, MSE(pi1): 7.925e-03, MSE(pi2): 6.248e-06, MSE(pi3): 1.022e-03\n",
      "Epoch 417800, Train loss: 4.460e+02, Test loss: 1.390e+03, MSE(e): 2.680e-05, MSE(pi1): 8.588e-03, MSE(pi2): 1.095e-05, MSE(pi3): 9.219e-04\n",
      "Epoch 417900, Train loss: 2.271e+02, Test loss: 1.180e+03, MSE(e): 6.020e-06, MSE(pi1): 6.659e-03, MSE(pi2): 2.588e-06, MSE(pi3): 1.003e-03\n",
      "Epoch 418000, Train loss: 2.154e+02, Test loss: 1.127e+03, MSE(e): 4.717e-06, MSE(pi1): 7.829e-03, MSE(pi2): 1.582e-06, MSE(pi3): 8.999e-04\n",
      "Epoch 418100, Train loss: 1.499e+02, Test loss: 9.258e+02, MSE(e): 2.127e-06, MSE(pi1): 3.684e-03, MSE(pi2): 1.071e-06, MSE(pi3): 9.181e-04\n",
      "Epoch 418200, Train loss: 2.408e+02, Test loss: 1.016e+03, MSE(e): 7.993e-06, MSE(pi1): 7.251e-03, MSE(pi2): 3.683e-06, MSE(pi3): 8.838e-04\n",
      "Epoch 418300, Train loss: 2.421e+03, Test loss: 2.389e+03, MSE(e): 2.061e-04, MSE(pi1): 2.708e-02, MSE(pi2): 9.932e-05, MSE(pi3): 8.968e-04\n",
      "Epoch 418400, Train loss: 4.587e+02, Test loss: 1.559e+03, MSE(e): 1.237e-05, MSE(pi1): 2.187e-02, MSE(pi2): 3.936e-06, MSE(pi3): 1.164e-03\n",
      "Epoch 418500, Train loss: 2.371e+02, Test loss: 9.492e+02, MSE(e): 1.061e-05, MSE(pi1): 3.792e-03, MSE(pi2): 4.949e-06, MSE(pi3): 9.310e-04\n",
      "Epoch 418600, Train loss: 2.201e+02, Test loss: 1.130e+03, MSE(e): 3.999e-06, MSE(pi1): 8.750e-03, MSE(pi2): 1.349e-06, MSE(pi3): 9.263e-04\n",
      "Epoch 418700, Train loss: 1.565e+02, Test loss: 1.019e+03, MSE(e): 2.233e-06, MSE(pi1): 3.578e-03, MSE(pi2): 1.092e-06, MSE(pi3): 9.834e-04\n",
      "Epoch 418800, Train loss: 1.564e+02, Test loss: 1.028e+03, MSE(e): 1.819e-06, MSE(pi1): 4.337e-03, MSE(pi2): 7.306e-07, MSE(pi3): 9.480e-04\n",
      "Epoch 418900, Train loss: 2.201e+02, Test loss: 9.962e+02, MSE(e): 6.146e-06, MSE(pi1): 6.694e-03, MSE(pi2): 2.632e-06, MSE(pi3): 9.169e-04\n",
      "Epoch 419000, Train loss: 3.376e+02, Test loss: 1.159e+03, MSE(e): 1.396e-05, MSE(pi1): 9.208e-03, MSE(pi2): 5.756e-06, MSE(pi3): 1.058e-03\n",
      "Epoch 419100, Train loss: 2.890e+02, Test loss: 1.364e+03, MSE(e): 4.296e-06, MSE(pi1): 1.411e-02, MSE(pi2): 1.061e-06, MSE(pi3): 1.049e-03\n",
      "Epoch 419200, Train loss: 2.493e+02, Test loss: 1.073e+03, MSE(e): 6.137e-06, MSE(pi1): 8.558e-03, MSE(pi2): 2.028e-06, MSE(pi3): 1.024e-03\n",
      "Epoch 419300, Train loss: 2.990e+03, Test loss: 4.169e+03, MSE(e): 2.722e-04, MSE(pi1): 1.301e-02, MSE(pi2): 1.298e-04, MSE(pi3): 1.380e-03\n",
      "Epoch 419400, Train loss: 3.863e+02, Test loss: 1.432e+03, MSE(e): 1.846e-05, MSE(pi1): 9.955e-03, MSE(pi2): 8.480e-06, MSE(pi3): 1.021e-03\n",
      "Epoch 419500, Train loss: 1.956e+02, Test loss: 1.116e+03, MSE(e): 2.669e-06, MSE(pi1): 7.958e-03, MSE(pi2): 8.629e-07, MSE(pi3): 8.930e-04\n",
      "Epoch 419600, Train loss: 2.377e+02, Test loss: 1.012e+03, MSE(e): 8.269e-06, MSE(pi1): 5.987e-03, MSE(pi2): 3.584e-06, MSE(pi3): 9.510e-04\n",
      "Epoch 419700, Train loss: 1.856e+02, Test loss: 1.093e+03, MSE(e): 3.765e-06, MSE(pi1): 5.658e-03, MSE(pi2): 1.487e-06, MSE(pi3): 9.134e-04\n",
      "Epoch 419800, Train loss: 1.673e+02, Test loss: 1.012e+03, MSE(e): 2.021e-06, MSE(pi1): 5.704e-03, MSE(pi2): 6.940e-07, MSE(pi3): 9.003e-04\n",
      "Epoch 419900, Train loss: 2.244e+02, Test loss: 1.157e+03, MSE(e): 4.910e-06, MSE(pi1): 7.371e-03, MSE(pi2): 2.082e-06, MSE(pi3): 1.016e-03\n",
      "Epoch 420000, Train loss: 2.433e+02, Test loss: 1.010e+03, MSE(e): 4.231e-06, MSE(pi1): 9.633e-03, MSE(pi2): 1.307e-06, MSE(pi3): 1.047e-03\n",
      "Epoch 420100, Train loss: 1.429e+02, Test loss: 9.678e+02, MSE(e): 1.291e-06, MSE(pi1): 3.621e-03, MSE(pi2): 6.280e-07, MSE(pi3): 9.374e-04\n",
      "Epoch 420200, Train loss: 3.324e+02, Test loss: 1.306e+03, MSE(e): 5.502e-06, MSE(pi1): 1.741e-02, MSE(pi2): 1.346e-06, MSE(pi3): 1.033e-03\n",
      "Epoch 420300, Train loss: 9.988e+02, Test loss: 1.730e+03, MSE(e): 6.940e-05, MSE(pi1): 2.182e-02, MSE(pi2): 3.381e-05, MSE(pi3): 8.649e-04\n",
      "Epoch 420400, Train loss: 1.950e+02, Test loss: 1.104e+03, MSE(e): 5.490e-06, MSE(pi1): 4.933e-03, MSE(pi2): 2.587e-06, MSE(pi3): 9.079e-04\n",
      "Epoch 420500, Train loss: 1.915e+02, Test loss: 1.024e+03, MSE(e): 2.345e-06, MSE(pi1): 7.842e-03, MSE(pi2): 8.785e-07, MSE(pi3): 8.967e-04\n",
      "Epoch 420600, Train loss: 2.364e+02, Test loss: 1.114e+03, MSE(e): 3.419e-06, MSE(pi1): 1.070e-02, MSE(pi2): 1.072e-06, MSE(pi3): 9.524e-04\n",
      "Epoch 420700, Train loss: 2.448e+03, Test loss: 3.297e+03, MSE(e): 2.242e-04, MSE(pi1): 1.171e-02, MSE(pi2): 1.095e-04, MSE(pi3): 8.960e-04\n",
      "Epoch 420800, Train loss: 2.871e+02, Test loss: 1.218e+03, MSE(e): 4.925e-06, MSE(pi1): 1.492e-02, MSE(pi2): 1.151e-06, MSE(pi3): 8.864e-04\n",
      "Epoch 420900, Train loss: 2.250e+02, Test loss: 1.157e+03, MSE(e): 3.437e-06, MSE(pi1): 8.265e-03, MSE(pi2): 1.446e-06, MSE(pi3): 1.079e-03\n",
      "Epoch 421000, Train loss: 3.217e+02, Test loss: 1.174e+03, MSE(e): 5.438e-06, MSE(pi1): 1.746e-02, MSE(pi2): 1.322e-06, MSE(pi3): 9.273e-04\n",
      "Epoch 421100, Train loss: 2.456e+02, Test loss: 1.012e+03, MSE(e): 4.604e-06, MSE(pi1): 1.011e-02, MSE(pi2): 1.647e-06, MSE(pi3): 9.848e-04\n",
      "Epoch 421200, Train loss: 1.677e+02, Test loss: 9.879e+02, MSE(e): 3.463e-06, MSE(pi1): 3.756e-03, MSE(pi2): 1.542e-06, MSE(pi3): 9.555e-04\n",
      "Epoch 421300, Train loss: 5.099e+02, Test loss: 1.188e+03, MSE(e): 3.627e-05, MSE(pi1): 5.924e-03, MSE(pi2): 1.772e-05, MSE(pi3): 8.794e-04\n",
      "Epoch 421400, Train loss: 1.676e+02, Test loss: 1.039e+03, MSE(e): 2.149e-06, MSE(pi1): 5.432e-03, MSE(pi2): 8.241e-07, MSE(pi3): 9.181e-04\n",
      "Epoch 421500, Train loss: 1.570e+02, Test loss: 9.927e+02, MSE(e): 1.728e-06, MSE(pi1): 4.434e-03, MSE(pi2): 7.700e-07, MSE(pi3): 9.534e-04\n",
      "Epoch 421600, Train loss: 2.883e+03, Test loss: 3.454e+03, MSE(e): 2.623e-04, MSE(pi1): 1.798e-02, MSE(pi2): 1.270e-04, MSE(pi3): 7.962e-04\n",
      "Epoch 421700, Train loss: 3.131e+02, Test loss: 1.307e+03, MSE(e): 7.146e-06, MSE(pi1): 1.525e-02, MSE(pi2): 1.984e-06, MSE(pi3): 8.910e-04\n",
      "Epoch 421800, Train loss: 2.042e+02, Test loss: 9.763e+02, MSE(e): 3.292e-06, MSE(pi1): 8.402e-03, MSE(pi2): 9.426e-07, MSE(pi3): 8.725e-04\n",
      "Epoch 421900, Train loss: 1.633e+02, Test loss: 1.001e+03, MSE(e): 1.694e-06, MSE(pi1): 5.363e-03, MSE(pi2): 6.744e-07, MSE(pi3): 9.271e-04\n",
      "Epoch 422000, Train loss: 1.613e+02, Test loss: 9.915e+02, MSE(e): 2.174e-06, MSE(pi1): 4.246e-03, MSE(pi2): 9.736e-07, MSE(pi3): 9.709e-04\n",
      "Epoch 422100, Train loss: 3.049e+02, Test loss: 1.336e+03, MSE(e): 1.564e-05, MSE(pi1): 4.946e-03, MSE(pi2): 7.651e-06, MSE(pi3): 9.897e-04\n",
      "Epoch 422200, Train loss: 6.463e+02, Test loss: 1.147e+03, MSE(e): 5.101e-05, MSE(pi1): 4.628e-03, MSE(pi2): 2.402e-05, MSE(pi3): 8.987e-04\n",
      "Epoch 422300, Train loss: 1.765e+02, Test loss: 1.036e+03, MSE(e): 2.138e-06, MSE(pi1): 5.729e-03, MSE(pi2): 7.777e-07, MSE(pi3): 9.787e-04\n",
      "Epoch 422400, Train loss: 3.357e+02, Test loss: 1.236e+03, MSE(e): 6.801e-06, MSE(pi1): 1.687e-02, MSE(pi2): 1.717e-06, MSE(pi3): 9.898e-04\n",
      "Epoch 422500, Train loss: 2.764e+02, Test loss: 1.022e+03, MSE(e): 4.757e-06, MSE(pi1): 1.154e-02, MSE(pi2): 1.105e-06, MSE(pi3): 1.133e-03\n",
      "Epoch 422600, Train loss: 1.441e+02, Test loss: 1.021e+03, MSE(e): 1.439e-06, MSE(pi1): 3.579e-03, MSE(pi2): 6.811e-07, MSE(pi3): 9.391e-04\n",
      "Epoch 422700, Train loss: 2.192e+02, Test loss: 1.095e+03, MSE(e): 6.610e-06, MSE(pi1): 6.350e-03, MSE(pi2): 2.590e-06, MSE(pi3): 8.959e-04\n",
      "Epoch 422800, Train loss: 2.519e+02, Test loss: 1.183e+03, MSE(e): 4.642e-06, MSE(pi1): 1.175e-02, MSE(pi2): 1.251e-06, MSE(pi3): 8.799e-04\n",
      "Epoch 422900, Train loss: 1.724e+02, Test loss: 9.520e+02, MSE(e): 2.262e-06, MSE(pi1): 4.968e-03, MSE(pi2): 8.620e-07, MSE(pi3): 1.001e-03\n",
      "Epoch 423000, Train loss: 3.086e+02, Test loss: 9.685e+02, MSE(e): 1.740e-05, MSE(pi1): 4.480e-03, MSE(pi2): 8.889e-06, MSE(pi3): 8.979e-04\n",
      "Epoch 423100, Train loss: 2.042e+02, Test loss: 1.125e+03, MSE(e): 2.614e-06, MSE(pi1): 7.571e-03, MSE(pi2): 9.079e-07, MSE(pi3): 1.023e-03\n",
      "Epoch 423200, Train loss: 2.213e+02, Test loss: 1.005e+03, MSE(e): 3.534e-06, MSE(pi1): 1.013e-02, MSE(pi2): 9.852e-07, MSE(pi3): 8.471e-04\n",
      "Epoch 423300, Train loss: 3.020e+02, Test loss: 1.215e+03, MSE(e): 5.316e-06, MSE(pi1): 1.398e-02, MSE(pi2): 1.498e-06, MSE(pi3): 1.091e-03\n",
      "Epoch 423400, Train loss: 2.182e+02, Test loss: 9.607e+02, MSE(e): 6.180e-06, MSE(pi1): 6.701e-03, MSE(pi2): 3.104e-06, MSE(pi3): 8.943e-04\n",
      "Epoch 423500, Train loss: 6.380e+02, Test loss: 1.754e+03, MSE(e): 1.387e-05, MSE(pi1): 3.969e-02, MSE(pi2): 2.713e-06, MSE(pi3): 1.024e-03\n",
      "Epoch 423600, Train loss: 6.838e+02, Test loss: 1.447e+03, MSE(e): 4.573e-05, MSE(pi1): 1.269e-02, MSE(pi2): 2.180e-05, MSE(pi3): 9.955e-04\n",
      "Epoch 423700, Train loss: 4.096e+02, Test loss: 1.501e+03, MSE(e): 1.934e-05, MSE(pi1): 1.207e-02, MSE(pi2): 8.963e-06, MSE(pi3): 9.544e-04\n",
      "Epoch 423800, Train loss: 3.264e+02, Test loss: 1.007e+03, MSE(e): 1.370e-05, MSE(pi1): 9.261e-03, MSE(pi2): 5.690e-06, MSE(pi3): 9.681e-04\n",
      "Epoch 423900, Train loss: 7.088e+02, Test loss: 1.417e+03, MSE(e): 4.876e-05, MSE(pi1): 1.203e-02, MSE(pi2): 2.210e-05, MSE(pi3): 1.009e-03\n",
      "Epoch 424000, Train loss: 2.657e+02, Test loss: 1.169e+03, MSE(e): 7.072e-06, MSE(pi1): 9.291e-03, MSE(pi2): 2.752e-06, MSE(pi3): 1.021e-03\n",
      "Epoch 424100, Train loss: 3.478e+02, Test loss: 1.238e+03, MSE(e): 9.366e-06, MSE(pi1): 1.529e-02, MSE(pi2): 2.973e-06, MSE(pi3): 1.012e-03\n",
      "Epoch 424200, Train loss: 1.873e+02, Test loss: 9.551e+02, MSE(e): 4.389e-06, MSE(pi1): 5.212e-03, MSE(pi2): 2.087e-06, MSE(pi3): 9.128e-04\n",
      "Epoch 424300, Train loss: 3.203e+02, Test loss: 1.215e+03, MSE(e): 6.477e-06, MSE(pi1): 1.588e-02, MSE(pi2): 1.670e-06, MSE(pi3): 9.678e-04\n",
      "Epoch 424400, Train loss: 1.768e+02, Test loss: 1.012e+03, MSE(e): 2.245e-06, MSE(pi1): 5.719e-03, MSE(pi2): 8.691e-07, MSE(pi3): 9.714e-04\n",
      "Epoch 424500, Train loss: 3.511e+02, Test loss: 1.295e+03, MSE(e): 5.967e-06, MSE(pi1): 1.874e-02, MSE(pi2): 1.394e-06, MSE(pi3): 1.041e-03\n",
      "Epoch 424600, Train loss: 4.457e+02, Test loss: 1.176e+03, MSE(e): 2.351e-05, MSE(pi1): 1.156e-02, MSE(pi2): 9.697e-06, MSE(pi3): 9.495e-04\n",
      "Epoch 424700, Train loss: 2.381e+02, Test loss: 1.035e+03, MSE(e): 5.857e-06, MSE(pi1): 8.554e-03, MSE(pi2): 2.599e-06, MSE(pi3): 9.396e-04\n",
      "Epoch 424800, Train loss: 3.778e+02, Test loss: 1.511e+03, MSE(e): 1.330e-05, MSE(pi1): 1.332e-02, MSE(pi2): 5.981e-06, MSE(pi3): 1.116e-03\n",
      "Epoch 424900, Train loss: 6.982e+02, Test loss: 1.323e+03, MSE(e): 4.524e-05, MSE(pi1): 1.543e-02, MSE(pi2): 2.254e-05, MSE(pi3): 9.146e-04\n",
      "Epoch 425000, Train loss: 3.367e+02, Test loss: 1.247e+03, MSE(e): 1.170e-05, MSE(pi1): 1.128e-02, MSE(pi2): 4.164e-06, MSE(pi3): 1.069e-03\n",
      "Epoch 425100, Train loss: 5.405e+02, Test loss: 1.451e+03, MSE(e): 2.383e-05, MSE(pi1): 2.054e-02, MSE(pi2): 8.474e-06, MSE(pi3): 9.679e-04\n",
      "Epoch 425200, Train loss: 2.935e+02, Test loss: 1.174e+03, MSE(e): 9.638e-06, MSE(pi1): 1.158e-02, MSE(pi2): 3.507e-06, MSE(pi3): 8.131e-04\n",
      "Epoch 425300, Train loss: 3.019e+02, Test loss: 1.096e+03, MSE(e): 6.589e-06, MSE(pi1): 1.358e-02, MSE(pi2): 1.974e-06, MSE(pi3): 1.002e-03\n",
      "Epoch 425400, Train loss: 1.389e+02, Test loss: 9.393e+02, MSE(e): 1.245e-06, MSE(pi1): 3.183e-03, MSE(pi2): 6.332e-07, MSE(pi3): 9.462e-04\n",
      "Epoch 425500, Train loss: 1.767e+02, Test loss: 1.072e+03, MSE(e): 1.959e-06, MSE(pi1): 6.793e-03, MSE(pi2): 7.276e-07, MSE(pi3): 8.916e-04\n",
      "Epoch 425600, Train loss: 1.862e+02, Test loss: 1.037e+03, MSE(e): 2.923e-06, MSE(pi1): 6.096e-03, MSE(pi2): 1.012e-06, MSE(pi3): 9.596e-04\n",
      "Epoch 425700, Train loss: 2.033e+02, Test loss: 1.007e+03, MSE(e): 3.804e-06, MSE(pi1): 6.696e-03, MSE(pi2): 1.468e-06, MSE(pi3): 9.827e-04\n",
      "Epoch 425800, Train loss: 9.595e+02, Test loss: 1.823e+03, MSE(e): 6.590e-05, MSE(pi1): 2.161e-02, MSE(pi2): 3.169e-05, MSE(pi3): 8.442e-04\n",
      "Epoch 425900, Train loss: 2.442e+02, Test loss: 1.112e+03, MSE(e): 3.727e-06, MSE(pi1): 1.181e-02, MSE(pi2): 9.538e-07, MSE(pi3): 8.882e-04\n",
      "Epoch 426000, Train loss: 2.979e+02, Test loss: 1.096e+03, MSE(e): 5.141e-06, MSE(pi1): 1.459e-02, MSE(pi2): 1.224e-06, MSE(pi3): 1.005e-03\n",
      "Epoch 426100, Train loss: 1.526e+02, Test loss: 9.964e+02, MSE(e): 1.434e-06, MSE(pi1): 4.934e-03, MSE(pi2): 5.985e-07, MSE(pi3): 8.895e-04\n",
      "Epoch 426200, Train loss: 2.473e+02, Test loss: 1.158e+03, MSE(e): 3.477e-06, MSE(pi1): 1.090e-02, MSE(pi2): 1.097e-06, MSE(pi3): 1.035e-03\n",
      "Epoch 426300, Train loss: 2.039e+02, Test loss: 1.285e+03, MSE(e): 6.190e-06, MSE(pi1): 4.882e-03, MSE(pi2): 3.174e-06, MSE(pi3): 9.322e-04\n",
      "Epoch 426400, Train loss: 4.298e+02, Test loss: 1.158e+03, MSE(e): 8.978e-06, MSE(pi1): 2.524e-02, MSE(pi2): 1.919e-06, MSE(pi3): 8.763e-04\n",
      "Epoch 426500, Train loss: 1.471e+02, Test loss: 9.997e+02, MSE(e): 1.392e-06, MSE(pi1): 3.803e-03, MSE(pi2): 6.259e-07, MSE(pi3): 9.512e-04\n",
      "Epoch 426600, Train loss: 1.539e+03, Test loss: 2.058e+03, MSE(e): 1.312e-04, MSE(pi1): 1.461e-02, MSE(pi2): 6.067e-05, MSE(pi3): 8.046e-04\n",
      "Epoch 426700, Train loss: 6.866e+02, Test loss: 1.129e+03, MSE(e): 5.297e-05, MSE(pi1): 5.254e-03, MSE(pi2): 2.575e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 426800, Train loss: 5.389e+02, Test loss: 1.344e+03, MSE(e): 1.338e-05, MSE(pi1): 3.109e-02, MSE(pi2): 4.009e-06, MSE(pi3): 9.411e-04\n",
      "Epoch 426900, Train loss: 4.252e+02, Test loss: 1.325e+03, MSE(e): 1.101e-05, MSE(pi1): 2.205e-02, MSE(pi2): 4.364e-06, MSE(pi3): 9.457e-04\n",
      "Epoch 427000, Train loss: 2.155e+02, Test loss: 1.136e+03, MSE(e): 5.595e-06, MSE(pi1): 6.790e-03, MSE(pi2): 2.121e-06, MSE(pi3): 9.165e-04\n",
      "Epoch 427100, Train loss: 1.388e+02, Test loss: 9.422e+02, MSE(e): 1.170e-06, MSE(pi1): 3.262e-03, MSE(pi2): 5.858e-07, MSE(pi3): 9.448e-04\n",
      "Epoch 427200, Train loss: 3.888e+02, Test loss: 1.322e+03, MSE(e): 2.204e-05, MSE(pi1): 6.310e-03, MSE(pi2): 1.053e-05, MSE(pi3): 1.053e-03\n",
      "Epoch 427300, Train loss: 2.281e+02, Test loss: 1.097e+03, MSE(e): 3.203e-06, MSE(pi1): 1.034e-02, MSE(pi2): 8.880e-07, MSE(pi3): 9.265e-04\n",
      "Epoch 427400, Train loss: 3.421e+02, Test loss: 1.226e+03, MSE(e): 1.893e-05, MSE(pi1): 5.074e-03, MSE(pi2): 9.337e-06, MSE(pi3): 1.021e-03\n",
      "Epoch 427500, Train loss: 2.210e+02, Test loss: 1.007e+03, MSE(e): 3.544e-06, MSE(pi1): 8.532e-03, MSE(pi2): 1.211e-06, MSE(pi3): 1.002e-03\n",
      "Epoch 427600, Train loss: 2.023e+02, Test loss: 1.009e+03, MSE(e): 3.882e-06, MSE(pi1): 6.269e-03, MSE(pi2): 1.584e-06, MSE(pi3): 1.008e-03\n",
      "Epoch 427700, Train loss: 9.888e+02, Test loss: 2.803e+03, MSE(e): 8.212e-05, MSE(pi1): 6.700e-03, MSE(pi2): 3.993e-05, MSE(pi3): 1.005e-03\n",
      "Epoch 427800, Train loss: 3.470e+02, Test loss: 1.318e+03, MSE(e): 6.362e-06, MSE(pi1): 1.747e-02, MSE(pi2): 1.568e-06, MSE(pi3): 1.087e-03\n",
      "Epoch 427900, Train loss: 4.716e+02, Test loss: 1.188e+03, MSE(e): 2.729e-05, MSE(pi1): 1.135e-02, MSE(pi2): 1.351e-05, MSE(pi3): 8.525e-04\n",
      "Epoch 428000, Train loss: 1.902e+02, Test loss: 9.682e+02, MSE(e): 3.697e-06, MSE(pi1): 6.207e-03, MSE(pi2): 1.529e-06, MSE(pi3): 9.120e-04\n",
      "Epoch 428100, Train loss: 1.636e+02, Test loss: 9.898e+02, MSE(e): 1.714e-06, MSE(pi1): 5.558e-03, MSE(pi2): 6.530e-07, MSE(pi3): 9.085e-04\n",
      "Epoch 428200, Train loss: 2.980e+02, Test loss: 1.169e+03, MSE(e): 5.074e-06, MSE(pi1): 1.479e-02, MSE(pi2): 1.171e-06, MSE(pi3): 9.933e-04\n",
      "Epoch 428300, Train loss: 6.093e+02, Test loss: 1.230e+03, MSE(e): 4.298e-05, MSE(pi1): 8.776e-03, MSE(pi2): 1.964e-05, MSE(pi3): 9.172e-04\n",
      "Epoch 428400, Train loss: 2.165e+02, Test loss: 1.194e+03, MSE(e): 4.015e-06, MSE(pi1): 8.973e-03, MSE(pi2): 1.317e-06, MSE(pi3): 8.662e-04\n",
      "Epoch 428500, Train loss: 2.211e+02, Test loss: 1.183e+03, MSE(e): 8.032e-06, MSE(pi1): 5.233e-03, MSE(pi2): 3.473e-06, MSE(pi3): 8.850e-04\n",
      "Epoch 428600, Train loss: 2.052e+02, Test loss: 1.105e+03, MSE(e): 5.488e-06, MSE(pi1): 5.103e-03, MSE(pi2): 2.330e-06, MSE(pi3): 9.925e-04\n",
      "Epoch 428700, Train loss: 2.245e+02, Test loss: 1.204e+03, MSE(e): 4.588e-06, MSE(pi1): 7.465e-03, MSE(pi2): 2.103e-06, MSE(pi3): 1.039e-03\n",
      "Epoch 428800, Train loss: 3.670e+02, Test loss: 1.155e+03, MSE(e): 1.006e-05, MSE(pi1): 1.658e-02, MSE(pi2): 3.547e-06, MSE(pi3): 1.006e-03\n",
      "Epoch 428900, Train loss: 1.754e+02, Test loss: 1.015e+03, MSE(e): 1.988e-06, MSE(pi1): 6.608e-03, MSE(pi2): 7.282e-07, MSE(pi3): 8.940e-04\n",
      "Epoch 429000, Train loss: 2.083e+02, Test loss: 1.126e+03, MSE(e): 3.001e-06, MSE(pi1): 7.546e-03, MSE(pi2): 1.071e-06, MSE(pi3): 1.028e-03\n",
      "Epoch 429100, Train loss: 3.384e+02, Test loss: 1.304e+03, MSE(e): 1.225e-05, MSE(pi1): 1.159e-02, MSE(pi2): 5.292e-06, MSE(pi3): 1.000e-03\n",
      "Epoch 429200, Train loss: 8.721e+02, Test loss: 2.609e+03, MSE(e): 6.315e-05, MSE(pi1): 1.227e-02, MSE(pi2): 3.214e-05, MSE(pi3): 1.178e-03\n",
      "Epoch 429300, Train loss: 1.507e+02, Test loss: 9.516e+02, MSE(e): 1.524e-06, MSE(pi1): 3.923e-03, MSE(pi2): 6.836e-07, MSE(pi3): 9.619e-04\n",
      "Epoch 429400, Train loss: 1.404e+02, Test loss: 9.511e+02, MSE(e): 1.141e-06, MSE(pi1): 3.500e-03, MSE(pi2): 5.612e-07, MSE(pi3): 9.399e-04\n",
      "Epoch 429500, Train loss: 2.391e+02, Test loss: 9.519e+02, MSE(e): 9.265e-06, MSE(pi1): 4.827e-03, MSE(pi2): 3.840e-06, MSE(pi3): 9.814e-04\n",
      "Epoch 429600, Train loss: 1.839e+03, Test loss: 2.423e+03, MSE(e): 1.688e-04, MSE(pi1): 6.455e-03, MSE(pi2): 8.177e-05, MSE(pi3): 8.654e-04\n",
      "Epoch 429700, Train loss: 1.614e+03, Test loss: 2.985e+03, MSE(e): 1.316e-04, MSE(pi1): 2.161e-02, MSE(pi2): 6.572e-05, MSE(pi3): 8.179e-04\n",
      "Epoch 429800, Train loss: 1.464e+02, Test loss: 9.415e+02, MSE(e): 1.622e-06, MSE(pi1): 3.638e-03, MSE(pi2): 7.896e-07, MSE(pi3): 9.382e-04\n",
      "Epoch 429900, Train loss: 2.567e+02, Test loss: 1.203e+03, MSE(e): 4.178e-06, MSE(pi1): 1.067e-02, MSE(pi2): 1.271e-06, MSE(pi3): 1.082e-03\n",
      "Epoch 430000, Train loss: 3.037e+02, Test loss: 1.053e+03, MSE(e): 8.070e-06, MSE(pi1): 1.219e-02, MSE(pi2): 3.013e-06, MSE(pi3): 1.011e-03\n",
      "Epoch 430100, Train loss: 6.092e+02, Test loss: 1.100e+03, MSE(e): 3.315e-05, MSE(pi1): 1.711e-02, MSE(pi2): 1.560e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 430200, Train loss: 3.248e+02, Test loss: 1.118e+03, MSE(e): 7.727e-06, MSE(pi1): 1.556e-02, MSE(pi2): 2.209e-06, MSE(pi3): 9.190e-04\n",
      "Epoch 430300, Train loss: 4.890e+02, Test loss: 1.210e+03, MSE(e): 2.867e-05, MSE(pi1): 1.118e-02, MSE(pi2): 1.379e-05, MSE(pi3): 9.044e-04\n",
      "Epoch 430400, Train loss: 4.370e+02, Test loss: 1.415e+03, MSE(e): 1.792e-05, MSE(pi1): 1.466e-02, MSE(pi2): 8.422e-06, MSE(pi3): 1.112e-03\n",
      "Epoch 430500, Train loss: 6.087e+02, Test loss: 1.443e+03, MSE(e): 3.681e-05, MSE(pi1): 1.176e-02, MSE(pi2): 1.735e-05, MSE(pi3): 1.230e-03\n",
      "Epoch 430600, Train loss: 1.807e+03, Test loss: 2.490e+03, MSE(e): 1.610e-04, MSE(pi1): 1.054e-02, MSE(pi2): 7.440e-05, MSE(pi3): 9.114e-04\n",
      "Epoch 430700, Train loss: 4.109e+02, Test loss: 1.325e+03, MSE(e): 1.189e-05, MSE(pi1): 2.019e-02, MSE(pi2): 3.940e-06, MSE(pi3): 9.018e-04\n",
      "Epoch 430800, Train loss: 2.076e+02, Test loss: 9.596e+02, MSE(e): 4.464e-06, MSE(pi1): 6.750e-03, MSE(pi2): 1.936e-06, MSE(pi3): 9.547e-04\n",
      "Epoch 430900, Train loss: 8.278e+02, Test loss: 2.223e+03, MSE(e): 6.612e-05, MSE(pi1): 5.666e-03, MSE(pi2): 3.160e-05, MSE(pi3): 1.099e-03\n",
      "Epoch 431000, Train loss: 2.617e+02, Test loss: 1.176e+03, MSE(e): 3.964e-06, MSE(pi1): 1.322e-02, MSE(pi2): 9.844e-07, MSE(pi3): 8.987e-04\n",
      "Epoch 431100, Train loss: 2.660e+02, Test loss: 1.181e+03, MSE(e): 1.215e-05, MSE(pi1): 4.466e-03, MSE(pi2): 5.680e-06, MSE(pi3): 9.984e-04\n",
      "Epoch 431200, Train loss: 2.196e+02, Test loss: 1.181e+03, MSE(e): 6.577e-06, MSE(pi1): 5.696e-03, MSE(pi2): 2.701e-06, MSE(pi3): 9.690e-04\n",
      "Epoch 431300, Train loss: 7.767e+02, Test loss: 2.274e+03, MSE(e): 5.907e-05, MSE(pi1): 7.298e-03, MSE(pi2): 2.841e-05, MSE(pi3): 1.130e-03\n",
      "Epoch 431400, Train loss: 3.440e+03, Test loss: 4.328e+03, MSE(e): 3.156e-04, MSE(pi1): 2.039e-02, MSE(pi2): 1.513e-04, MSE(pi3): 8.067e-04\n",
      "Epoch 431500, Train loss: 1.638e+02, Test loss: 1.006e+03, MSE(e): 1.767e-06, MSE(pi1): 4.840e-03, MSE(pi2): 6.749e-07, MSE(pi3): 9.772e-04\n",
      "Epoch 431600, Train loss: 2.157e+02, Test loss: 1.030e+03, MSE(e): 4.339e-06, MSE(pi1): 7.967e-03, MSE(pi2): 1.727e-06, MSE(pi3): 9.259e-04\n",
      "Epoch 431700, Train loss: 1.667e+02, Test loss: 1.014e+03, MSE(e): 2.539e-06, MSE(pi1): 4.908e-03, MSE(pi2): 1.081e-06, MSE(pi3): 9.226e-04\n",
      "Epoch 431800, Train loss: 3.587e+02, Test loss: 1.344e+03, MSE(e): 1.168e-05, MSE(pi1): 1.471e-02, MSE(pi2): 4.424e-06, MSE(pi3): 9.476e-04\n",
      "Epoch 431900, Train loss: 3.396e+02, Test loss: 1.476e+03, MSE(e): 1.718e-05, MSE(pi1): 7.536e-03, MSE(pi2): 7.491e-06, MSE(pi3): 9.246e-04\n",
      "Epoch 432000, Train loss: 1.928e+02, Test loss: 9.919e+02, MSE(e): 2.698e-06, MSE(pi1): 6.878e-03, MSE(pi2): 8.807e-07, MSE(pi3): 9.701e-04\n",
      "Epoch 432100, Train loss: 3.053e+02, Test loss: 1.130e+03, MSE(e): 5.407e-06, MSE(pi1): 1.538e-02, MSE(pi2): 1.315e-06, MSE(pi3): 9.739e-04\n",
      "Epoch 432200, Train loss: 2.574e+02, Test loss: 1.126e+03, MSE(e): 4.313e-06, MSE(pi1): 9.991e-03, MSE(pi2): 1.211e-06, MSE(pi3): 1.144e-03\n",
      "Epoch 432300, Train loss: 2.013e+02, Test loss: 1.331e+03, MSE(e): 6.802e-06, MSE(pi1): 3.966e-03, MSE(pi2): 2.899e-06, MSE(pi3): 9.360e-04\n",
      "Epoch 432400, Train loss: 3.381e+02, Test loss: 1.364e+03, MSE(e): 1.572e-05, MSE(pi1): 8.090e-03, MSE(pi2): 6.793e-06, MSE(pi3): 9.999e-04\n",
      "Epoch 432500, Train loss: 1.507e+03, Test loss: 2.534e+03, MSE(e): 1.262e-04, MSE(pi1): 1.624e-02, MSE(pi2): 5.996e-05, MSE(pi3): 8.208e-04\n",
      "Epoch 432600, Train loss: 2.817e+02, Test loss: 1.251e+03, MSE(e): 5.553e-06, MSE(pi1): 1.159e-02, MSE(pi2): 1.899e-06, MSE(pi3): 1.102e-03\n",
      "Epoch 432700, Train loss: 1.601e+02, Test loss: 9.744e+02, MSE(e): 1.556e-06, MSE(pi1): 5.149e-03, MSE(pi2): 6.546e-07, MSE(pi3): 9.304e-04\n",
      "Epoch 432800, Train loss: 1.265e+03, Test loss: 1.533e+03, MSE(e): 1.012e-04, MSE(pi1): 1.679e-02, MSE(pi2): 4.895e-05, MSE(pi3): 8.494e-04\n",
      "Epoch 432900, Train loss: 6.815e+02, Test loss: 1.583e+03, MSE(e): 4.373e-05, MSE(pi1): 1.286e-02, MSE(pi2): 2.035e-05, MSE(pi3): 1.156e-03\n",
      "Epoch 433000, Train loss: 3.125e+02, Test loss: 1.378e+03, MSE(e): 1.218e-05, MSE(pi1): 1.041e-02, MSE(pi2): 5.445e-06, MSE(pi3): 8.654e-04\n",
      "Epoch 433100, Train loss: 1.618e+02, Test loss: 9.265e+02, MSE(e): 3.346e-06, MSE(pi1): 3.403e-03, MSE(pi2): 1.513e-06, MSE(pi3): 9.435e-04\n",
      "Epoch 433200, Train loss: 3.656e+02, Test loss: 1.113e+03, MSE(e): 1.832e-05, MSE(pi1): 8.168e-03, MSE(pi2): 7.974e-06, MSE(pi3): 1.008e-03\n",
      "Epoch 433300, Train loss: 1.964e+02, Test loss: 1.448e+03, MSE(e): 3.850e-06, MSE(pi1): 6.811e-03, MSE(pi2): 1.542e-06, MSE(pi3): 8.978e-04\n",
      "Epoch 433400, Train loss: 5.538e+02, Test loss: 1.720e+03, MSE(e): 1.808e-05, MSE(pi1): 2.498e-02, MSE(pi2): 6.389e-06, MSE(pi3): 1.231e-03\n",
      "Epoch 433500, Train loss: 8.101e+02, Test loss: 1.597e+03, MSE(e): 4.359e-05, MSE(pi1): 2.792e-02, MSE(pi2): 2.010e-05, MSE(pi3): 9.499e-04\n",
      "Epoch 433600, Train loss: 1.651e+02, Test loss: 9.385e+02, MSE(e): 2.882e-06, MSE(pi1): 4.640e-03, MSE(pi2): 1.393e-06, MSE(pi3): 8.985e-04\n",
      "Epoch 433700, Train loss: 1.706e+02, Test loss: 9.526e+02, MSE(e): 2.976e-06, MSE(pi1): 4.908e-03, MSE(pi2): 1.465e-06, MSE(pi3): 9.172e-04\n",
      "Epoch 433800, Train loss: 5.286e+02, Test loss: 1.101e+03, MSE(e): 2.558e-05, MSE(pi1): 1.741e-02, MSE(pi2): 1.262e-05, MSE(pi3): 9.870e-04\n",
      "Epoch 433900, Train loss: 8.178e+02, Test loss: 1.535e+03, MSE(e): 5.477e-05, MSE(pi1): 1.653e-02, MSE(pi2): 2.170e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 434000, Train loss: 3.484e+02, Test loss: 9.915e+02, MSE(e): 1.639e-05, MSE(pi1): 8.317e-03, MSE(pi2): 8.392e-06, MSE(pi3): 1.013e-03\n",
      "Epoch 434100, Train loss: 3.000e+02, Test loss: 1.066e+03, MSE(e): 9.268e-06, MSE(pi1): 1.155e-02, MSE(pi2): 3.246e-06, MSE(pi3): 9.182e-04\n",
      "Epoch 434200, Train loss: 2.002e+02, Test loss: 9.736e+02, MSE(e): 2.553e-06, MSE(pi1): 8.770e-03, MSE(pi2): 7.540e-07, MSE(pi3): 8.698e-04\n",
      "Epoch 434300, Train loss: 3.513e+02, Test loss: 1.067e+03, MSE(e): 1.268e-05, MSE(pi1): 1.403e-02, MSE(pi2): 5.017e-06, MSE(pi3): 8.423e-04\n",
      "Epoch 434400, Train loss: 4.771e+02, Test loss: 1.526e+03, MSE(e): 2.841e-05, MSE(pi1): 9.215e-03, MSE(pi2): 1.299e-05, MSE(pi3): 1.008e-03\n",
      "Epoch 434500, Train loss: 2.215e+02, Test loss: 9.752e+02, MSE(e): 7.853e-06, MSE(pi1): 5.266e-03, MSE(pi2): 3.294e-06, MSE(pi3): 9.033e-04\n",
      "Epoch 434600, Train loss: 3.273e+02, Test loss: 9.694e+02, MSE(e): 1.900e-05, MSE(pi1): 4.403e-03, MSE(pi2): 8.700e-06, MSE(pi3): 9.328e-04\n",
      "Epoch 434700, Train loss: 3.609e+02, Test loss: 1.166e+03, MSE(e): 1.230e-05, MSE(pi1): 1.494e-02, MSE(pi2): 5.944e-06, MSE(pi3): 8.847e-04\n",
      "Epoch 434800, Train loss: 3.040e+02, Test loss: 1.191e+03, MSE(e): 5.415e-06, MSE(pi1): 1.646e-02, MSE(pi2): 1.217e-06, MSE(pi3): 8.529e-04\n",
      "Epoch 434900, Train loss: 3.730e+02, Test loss: 1.251e+03, MSE(e): 6.911e-06, MSE(pi1): 1.990e-02, MSE(pi2): 1.557e-06, MSE(pi3): 1.049e-03\n",
      "Epoch 435000, Train loss: 1.931e+02, Test loss: 1.014e+03, MSE(e): 2.283e-06, MSE(pi1): 8.084e-03, MSE(pi2): 7.856e-07, MSE(pi3): 8.941e-04\n",
      "Epoch 435100, Train loss: 1.739e+02, Test loss: 1.040e+03, MSE(e): 1.852e-06, MSE(pi1): 6.541e-03, MSE(pi2): 6.479e-07, MSE(pi3): 8.999e-04\n",
      "Epoch 435200, Train loss: 1.677e+02, Test loss: 9.997e+02, MSE(e): 1.740e-06, MSE(pi1): 5.979e-03, MSE(pi2): 6.523e-07, MSE(pi3): 9.047e-04\n",
      "Epoch 435300, Train loss: 1.643e+02, Test loss: 9.260e+02, MSE(e): 3.362e-06, MSE(pi1): 3.390e-03, MSE(pi2): 1.627e-06, MSE(pi3): 9.676e-04\n",
      "Epoch 435400, Train loss: 2.735e+02, Test loss: 1.568e+03, MSE(e): 4.470e-06, MSE(pi1): 1.272e-02, MSE(pi2): 1.226e-06, MSE(pi3): 1.016e-03\n",
      "Epoch 435500, Train loss: 1.380e+02, Test loss: 9.593e+02, MSE(e): 1.104e-06, MSE(pi1): 3.256e-03, MSE(pi2): 5.550e-07, MSE(pi3): 9.440e-04\n",
      "Epoch 435600, Train loss: 2.420e+02, Test loss: 1.098e+03, MSE(e): 5.290e-06, MSE(pi1): 9.173e-03, MSE(pi2): 1.836e-06, MSE(pi3): 9.737e-04\n",
      "Epoch 435700, Train loss: 1.560e+02, Test loss: 9.888e+02, MSE(e): 1.609e-06, MSE(pi1): 4.108e-03, MSE(pi2): 6.517e-07, MSE(pi3): 9.883e-04\n",
      "Epoch 435800, Train loss: 2.002e+02, Test loss: 1.029e+03, MSE(e): 2.655e-06, MSE(pi1): 8.375e-03, MSE(pi2): 7.316e-07, MSE(pi3): 8.991e-04\n",
      "Epoch 435900, Train loss: 2.712e+02, Test loss: 1.020e+03, MSE(e): 9.559e-06, MSE(pi1): 7.291e-03, MSE(pi2): 3.665e-06, MSE(pi3): 1.027e-03\n",
      "Epoch 436000, Train loss: 1.910e+03, Test loss: 2.602e+03, MSE(e): 1.757e-04, MSE(pi1): 6.879e-03, MSE(pi2): 8.271e-05, MSE(pi3): 8.390e-04\n",
      "Epoch 436100, Train loss: 2.089e+02, Test loss: 1.138e+03, MSE(e): 4.563e-06, MSE(pi1): 6.009e-03, MSE(pi2): 2.062e-06, MSE(pi3): 1.032e-03\n",
      "Epoch 436200, Train loss: 3.097e+02, Test loss: 1.129e+03, MSE(e): 5.487e-06, MSE(pi1): 1.708e-02, MSE(pi2): 1.198e-06, MSE(pi3): 8.401e-04\n",
      "Epoch 436300, Train loss: 3.699e+02, Test loss: 1.534e+03, MSE(e): 1.049e-05, MSE(pi1): 1.512e-02, MSE(pi2): 4.550e-06, MSE(pi3): 1.138e-03\n",
      "Epoch 436400, Train loss: 2.100e+02, Test loss: 1.095e+03, MSE(e): 5.225e-06, MSE(pi1): 5.922e-03, MSE(pi2): 2.180e-06, MSE(pi3): 9.851e-04\n",
      "Epoch 436500, Train loss: 7.238e+02, Test loss: 1.434e+03, MSE(e): 2.327e-05, MSE(pi1): 3.611e-02, MSE(pi2): 7.084e-06, MSE(pi3): 1.300e-03\n",
      "Epoch 436600, Train loss: 2.117e+02, Test loss: 1.077e+03, MSE(e): 3.298e-06, MSE(pi1): 8.643e-03, MSE(pi2): 1.020e-06, MSE(pi3): 9.227e-04\n",
      "Epoch 436700, Train loss: 2.477e+02, Test loss: 1.028e+03, MSE(e): 8.469e-06, MSE(pi1): 6.967e-03, MSE(pi2): 3.990e-06, MSE(pi3): 9.336e-04\n",
      "Epoch 436800, Train loss: 1.576e+02, Test loss: 1.034e+03, MSE(e): 1.493e-06, MSE(pi1): 5.431e-03, MSE(pi2): 7.265e-07, MSE(pi3): 8.834e-04\n",
      "Epoch 436900, Train loss: 7.502e+02, Test loss: 1.143e+03, MSE(e): 5.881e-05, MSE(pi1): 7.194e-03, MSE(pi2): 2.821e-05, MSE(pi3): 9.013e-04\n",
      "Epoch 437000, Train loss: 2.005e+02, Test loss: 1.104e+03, MSE(e): 5.611e-06, MSE(pi1): 4.716e-03, MSE(pi2): 2.414e-06, MSE(pi3): 9.722e-04\n",
      "Epoch 437100, Train loss: 2.969e+02, Test loss: 1.216e+03, MSE(e): 5.523e-06, MSE(pi1): 1.463e-02, MSE(pi2): 1.505e-06, MSE(pi3): 9.533e-04\n",
      "Epoch 437200, Train loss: 4.610e+02, Test loss: 1.249e+03, MSE(e): 2.532e-05, MSE(pi1): 1.137e-02, MSE(pi2): 1.117e-05, MSE(pi3): 9.406e-04\n",
      "Epoch 437300, Train loss: 7.756e+02, Test loss: 2.140e+03, MSE(e): 5.699e-05, MSE(pi1): 9.758e-03, MSE(pi2): 2.500e-05, MSE(pi3): 1.081e-03\n",
      "Epoch 437400, Train loss: 1.576e+02, Test loss: 9.335e+02, MSE(e): 2.774e-06, MSE(pi1): 3.894e-03, MSE(pi2): 1.412e-06, MSE(pi3): 9.093e-04\n",
      "Epoch 437500, Train loss: 2.977e+02, Test loss: 1.261e+03, MSE(e): 8.539e-06, MSE(pi1): 1.232e-02, MSE(pi2): 2.621e-06, MSE(pi3): 8.910e-04\n",
      "Epoch 437600, Train loss: 2.479e+02, Test loss: 9.503e+02, MSE(e): 7.675e-06, MSE(pi1): 6.999e-03, MSE(pi2): 2.862e-06, MSE(pi3): 1.011e-03\n",
      "Epoch 437700, Train loss: 2.459e+02, Test loss: 1.112e+03, MSE(e): 4.235e-06, MSE(pi1): 1.004e-02, MSE(pi2): 1.246e-06, MSE(pi3): 1.031e-03\n",
      "Epoch 437800, Train loss: 1.683e+02, Test loss: 1.001e+03, MSE(e): 2.225e-06, MSE(pi1): 4.953e-03, MSE(pi2): 8.654e-07, MSE(pi3): 9.651e-04\n",
      "Epoch 437900, Train loss: 2.578e+02, Test loss: 9.777e+02, MSE(e): 1.290e-05, MSE(pi1): 3.603e-03, MSE(pi2): 5.858e-06, MSE(pi3): 9.280e-04\n",
      "Epoch 438000, Train loss: 3.841e+02, Test loss: 1.357e+03, MSE(e): 7.698e-06, MSE(pi1): 2.030e-02, MSE(pi2): 1.841e-06, MSE(pi3): 1.041e-03\n",
      "Epoch 438100, Train loss: 6.541e+02, Test loss: 1.497e+03, MSE(e): 3.390e-05, MSE(pi1): 2.301e-02, MSE(pi2): 1.482e-05, MSE(pi3): 8.495e-04\n",
      "Epoch 438200, Train loss: 1.535e+02, Test loss: 9.749e+02, MSE(e): 1.463e-06, MSE(pi1): 4.923e-03, MSE(pi2): 5.894e-07, MSE(pi3): 8.968e-04\n",
      "Epoch 438300, Train loss: 6.062e+02, Test loss: 1.673e+03, MSE(e): 1.178e-05, MSE(pi1): 3.780e-02, MSE(pi2): 2.413e-06, MSE(pi3): 1.104e-03\n",
      "Epoch 438400, Train loss: 1.621e+02, Test loss: 1.014e+03, MSE(e): 2.711e-06, MSE(pi1): 4.264e-03, MSE(pi2): 1.144e-06, MSE(pi3): 9.231e-04\n",
      "Epoch 438500, Train loss: 2.783e+02, Test loss: 1.136e+03, MSE(e): 4.529e-06, MSE(pi1): 1.194e-02, MSE(pi2): 1.138e-06, MSE(pi3): 1.137e-03\n",
      "Epoch 438600, Train loss: 2.416e+02, Test loss: 1.244e+03, MSE(e): 7.399e-06, MSE(pi1): 7.190e-03, MSE(pi2): 2.881e-06, MSE(pi3): 9.572e-04\n",
      "Epoch 438700, Train loss: 3.875e+02, Test loss: 1.108e+03, MSE(e): 1.071e-05, MSE(pi1): 1.916e-02, MSE(pi2): 3.172e-06, MSE(pi3): 8.877e-04\n",
      "Epoch 438800, Train loss: 1.940e+03, Test loss: 3.086e+03, MSE(e): 1.651e-04, MSE(pi1): 2.070e-02, MSE(pi2): 8.115e-05, MSE(pi3): 8.110e-04\n",
      "Epoch 438900, Train loss: 5.870e+02, Test loss: 1.817e+03, MSE(e): 4.076e-05, MSE(pi1): 7.765e-03, MSE(pi2): 1.842e-05, MSE(pi3): 1.018e-03\n",
      "Epoch 439000, Train loss: 3.420e+02, Test loss: 1.447e+03, MSE(e): 2.092e-05, MSE(pi1): 3.364e-03, MSE(pi2): 1.040e-05, MSE(pi3): 9.916e-04\n",
      "Epoch 439100, Train loss: 1.443e+03, Test loss: 3.288e+03, MSE(e): 1.096e-04, MSE(pi1): 2.069e-02, MSE(pi2): 5.156e-05, MSE(pi3): 1.399e-03\n",
      "Epoch 439200, Train loss: 2.279e+02, Test loss: 1.040e+03, MSE(e): 4.746e-06, MSE(pi1): 9.022e-03, MSE(pi2): 1.925e-06, MSE(pi3): 9.018e-04\n",
      "Epoch 439300, Train loss: 6.637e+02, Test loss: 1.462e+03, MSE(e): 3.957e-05, MSE(pi1): 1.635e-02, MSE(pi2): 1.665e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 439400, Train loss: 2.079e+02, Test loss: 1.087e+03, MSE(e): 4.129e-06, MSE(pi1): 6.893e-03, MSE(pi2): 1.614e-06, MSE(pi3): 9.765e-04\n",
      "Epoch 439500, Train loss: 1.631e+02, Test loss: 9.991e+02, MSE(e): 2.157e-06, MSE(pi1): 4.602e-03, MSE(pi2): 9.145e-07, MSE(pi3): 9.553e-04\n",
      "Epoch 439600, Train loss: 2.031e+02, Test loss: 9.702e+02, MSE(e): 4.487e-06, MSE(pi1): 6.659e-03, MSE(pi2): 1.882e-06, MSE(pi3): 9.166e-04\n",
      "Epoch 439700, Train loss: 1.613e+02, Test loss: 9.929e+02, MSE(e): 1.622e-06, MSE(pi1): 5.324e-03, MSE(pi2): 6.478e-07, MSE(pi3): 9.180e-04\n",
      "Epoch 439800, Train loss: 3.066e+02, Test loss: 1.157e+03, MSE(e): 5.307e-06, MSE(pi1): 1.393e-02, MSE(pi2): 1.317e-06, MSE(pi3): 1.143e-03\n",
      "Epoch 439900, Train loss: 1.736e+02, Test loss: 1.041e+03, MSE(e): 2.821e-06, MSE(pi1): 4.886e-03, MSE(pi2): 1.261e-06, MSE(pi3): 9.652e-04\n",
      "Epoch 440000, Train loss: 2.398e+02, Test loss: 1.315e+03, MSE(e): 7.491e-06, MSE(pi1): 6.646e-03, MSE(pi2): 3.368e-06, MSE(pi3): 9.845e-04\n",
      "Epoch 440100, Train loss: 1.008e+03, Test loss: 1.679e+03, MSE(e): 7.909e-05, MSE(pi1): 1.166e-02, MSE(pi2): 3.655e-05, MSE(pi3): 9.997e-04\n",
      "Epoch 440200, Train loss: 1.279e+03, Test loss: 2.654e+03, MSE(e): 1.023e-04, MSE(pi1): 1.282e-02, MSE(pi2): 4.834e-05, MSE(pi3): 1.283e-03\n",
      "Epoch 440300, Train loss: 2.234e+02, Test loss: 1.068e+03, MSE(e): 3.123e-06, MSE(pi1): 9.390e-03, MSE(pi2): 1.038e-06, MSE(pi3): 9.831e-04\n",
      "Epoch 440400, Train loss: 6.681e+02, Test loss: 2.133e+03, MSE(e): 3.997e-05, MSE(pi1): 1.816e-02, MSE(pi2): 1.524e-05, MSE(pi3): 8.672e-04\n",
      "Epoch 440500, Train loss: 1.542e+03, Test loss: 3.069e+03, MSE(e): 1.294e-04, MSE(pi1): 1.314e-02, MSE(pi2): 6.394e-05, MSE(pi3): 1.170e-03\n",
      "Epoch 440600, Train loss: 4.347e+02, Test loss: 1.334e+03, MSE(e): 2.803e-05, MSE(pi1): 4.457e-03, MSE(pi2): 1.314e-05, MSE(pi3): 1.098e-03\n",
      "Epoch 440700, Train loss: 3.662e+02, Test loss: 1.340e+03, MSE(e): 7.792e-06, MSE(pi1): 1.903e-02, MSE(pi2): 2.896e-06, MSE(pi3): 9.794e-04\n",
      "Epoch 440800, Train loss: 1.655e+02, Test loss: 9.427e+02, MSE(e): 2.314e-06, MSE(pi1): 4.589e-03, MSE(pi2): 9.253e-07, MSE(pi3): 9.647e-04\n",
      "Epoch 440900, Train loss: 8.629e+02, Test loss: 1.493e+03, MSE(e): 6.730e-05, MSE(pi1): 1.057e-02, MSE(pi2): 3.240e-05, MSE(pi3): 8.415e-04\n",
      "Epoch 441000, Train loss: 2.885e+02, Test loss: 1.211e+03, MSE(e): 5.777e-06, MSE(pi1): 1.308e-02, MSE(pi2): 1.779e-06, MSE(pi3): 9.986e-04\n",
      "Epoch 441100, Train loss: 6.833e+02, Test loss: 2.052e+03, MSE(e): 5.421e-05, MSE(pi1): 3.936e-03, MSE(pi2): 2.636e-05, MSE(pi3): 1.018e-03\n",
      "Epoch 441200, Train loss: 2.792e+02, Test loss: 1.060e+03, MSE(e): 1.014e-05, MSE(pi1): 9.045e-03, MSE(pi2): 4.789e-06, MSE(pi3): 8.732e-04\n",
      "Epoch 441300, Train loss: 4.516e+02, Test loss: 1.332e+03, MSE(e): 1.686e-05, MSE(pi1): 1.804e-02, MSE(pi2): 6.055e-06, MSE(pi3): 1.026e-03\n",
      "Epoch 441400, Train loss: 1.620e+02, Test loss: 9.854e+02, MSE(e): 1.948e-06, MSE(pi1): 4.784e-03, MSE(pi2): 8.271e-07, MSE(pi3): 9.465e-04\n",
      "Epoch 441500, Train loss: 2.396e+02, Test loss: 1.064e+03, MSE(e): 4.178e-06, MSE(pi1): 9.424e-03, MSE(pi2): 1.169e-06, MSE(pi3): 1.036e-03\n",
      "Epoch 441600, Train loss: 1.650e+02, Test loss: 9.947e+02, MSE(e): 1.847e-06, MSE(pi1): 5.364e-03, MSE(pi2): 7.681e-07, MSE(pi3): 9.290e-04\n",
      "Epoch 441700, Train loss: 1.802e+02, Test loss: 1.001e+03, MSE(e): 2.596e-06, MSE(pi1): 5.954e-03, MSE(pi2): 9.615e-07, MSE(pi3): 9.475e-04\n",
      "Epoch 441800, Train loss: 4.705e+02, Test loss: 1.305e+03, MSE(e): 1.238e-05, MSE(pi1): 2.393e-02, MSE(pi2): 4.026e-06, MSE(pi3): 1.074e-03\n",
      "Epoch 441900, Train loss: 1.809e+02, Test loss: 1.205e+03, MSE(e): 4.174e-06, MSE(pi1): 4.924e-03, MSE(pi2): 1.856e-06, MSE(pi3): 8.997e-04\n",
      "Epoch 442000, Train loss: 2.773e+02, Test loss: 1.085e+03, MSE(e): 4.043e-06, MSE(pi1): 1.485e-02, MSE(pi2): 1.036e-06, MSE(pi3): 8.832e-04\n",
      "Epoch 442100, Train loss: 1.241e+03, Test loss: 2.897e+03, MSE(e): 9.367e-05, MSE(pi1): 2.106e-02, MSE(pi2): 4.264e-05, MSE(pi3): 9.370e-04\n",
      "Epoch 442200, Train loss: 3.100e+02, Test loss: 1.316e+03, MSE(e): 1.113e-05, MSE(pi1): 1.007e-02, MSE(pi2): 4.374e-06, MSE(pi3): 9.797e-04\n",
      "Epoch 442300, Train loss: 5.073e+02, Test loss: 1.131e+03, MSE(e): 3.336e-05, MSE(pi1): 8.511e-03, MSE(pi2): 1.375e-05, MSE(pi3): 8.859e-04\n",
      "Epoch 442400, Train loss: 2.323e+02, Test loss: 9.766e+02, MSE(e): 6.403e-06, MSE(pi1): 6.985e-03, MSE(pi2): 2.495e-06, MSE(pi3): 9.847e-04\n",
      "Epoch 442500, Train loss: 3.148e+02, Test loss: 1.299e+03, MSE(e): 4.996e-06, MSE(pi1): 1.636e-02, MSE(pi2): 1.179e-06, MSE(pi3): 1.012e-03\n",
      "Epoch 442600, Train loss: 1.428e+02, Test loss: 9.915e+02, MSE(e): 1.530e-06, MSE(pi1): 3.249e-03, MSE(pi2): 7.513e-07, MSE(pi3): 9.503e-04\n",
      "Epoch 442700, Train loss: 5.460e+02, Test loss: 1.200e+03, MSE(e): 3.186e-05, MSE(pi1): 1.366e-02, MSE(pi2): 1.629e-05, MSE(pi3): 9.083e-04\n",
      "Epoch 442800, Train loss: 4.175e+02, Test loss: 1.244e+03, MSE(e): 1.681e-05, MSE(pi1): 1.445e-02, MSE(pi2): 6.099e-06, MSE(pi3): 1.050e-03\n",
      "Epoch 442900, Train loss: 1.516e+02, Test loss: 9.336e+02, MSE(e): 2.200e-06, MSE(pi1): 3.447e-03, MSE(pi2): 1.099e-06, MSE(pi3): 9.510e-04\n",
      "Epoch 443000, Train loss: 2.244e+02, Test loss: 1.057e+03, MSE(e): 4.091e-06, MSE(pi1): 8.013e-03, MSE(pi2): 1.155e-06, MSE(pi3): 1.034e-03\n",
      "Epoch 443100, Train loss: 1.016e+03, Test loss: 2.094e+03, MSE(e): 8.461e-05, MSE(pi1): 6.496e-03, MSE(pi2): 4.001e-05, MSE(pi3): 1.051e-03\n",
      "Epoch 443200, Train loss: 1.864e+02, Test loss: 1.017e+03, MSE(e): 2.492e-06, MSE(pi1): 6.114e-03, MSE(pi2): 8.087e-07, MSE(pi3): 1.004e-03\n",
      "Epoch 443300, Train loss: 3.914e+02, Test loss: 1.425e+03, MSE(e): 2.004e-05, MSE(pi1): 8.299e-03, MSE(pi2): 7.442e-06, MSE(pi3): 1.080e-03\n",
      "Epoch 443400, Train loss: 2.514e+02, Test loss: 1.262e+03, MSE(e): 1.182e-05, MSE(pi1): 4.017e-03, MSE(pi2): 5.402e-06, MSE(pi3): 9.307e-04\n",
      "Epoch 443500, Train loss: 4.041e+02, Test loss: 1.527e+03, MSE(e): 2.017e-05, MSE(pi1): 9.430e-03, MSE(pi2): 9.476e-06, MSE(pi3): 1.081e-03\n",
      "Epoch 443600, Train loss: 1.263e+03, Test loss: 2.817e+03, MSE(e): 1.101e-04, MSE(pi1): 5.110e-03, MSE(pi2): 4.806e-05, MSE(pi3): 1.105e-03\n",
      "Epoch 443700, Train loss: 3.146e+02, Test loss: 9.777e+02, MSE(e): 1.432e-05, MSE(pi1): 8.235e-03, MSE(pi2): 6.930e-06, MSE(pi3): 8.902e-04\n",
      "Epoch 443800, Train loss: 1.059e+03, Test loss: 1.095e+03, MSE(e): 8.844e-05, MSE(pi1): 9.165e-03, MSE(pi2): 4.150e-05, MSE(pi3): 8.279e-04\n",
      "Epoch 443900, Train loss: 1.897e+02, Test loss: 1.031e+03, MSE(e): 2.176e-06, MSE(pi1): 7.743e-03, MSE(pi2): 7.196e-07, MSE(pi3): 9.052e-04\n",
      "Epoch 444000, Train loss: 2.360e+02, Test loss: 1.207e+03, MSE(e): 6.201e-06, MSE(pi1): 8.043e-03, MSE(pi2): 2.582e-06, MSE(pi3): 9.359e-04\n",
      "Epoch 444100, Train loss: 1.071e+03, Test loss: 2.515e+03, MSE(e): 9.289e-05, MSE(pi1): 4.247e-03, MSE(pi2): 4.432e-05, MSE(pi3): 9.988e-04\n",
      "Epoch 444200, Train loss: 2.828e+02, Test loss: 9.830e+02, MSE(e): 1.058e-05, MSE(pi1): 9.146e-03, MSE(pi2): 5.089e-06, MSE(pi3): 8.560e-04\n",
      "Epoch 444300, Train loss: 2.234e+02, Test loss: 1.039e+03, MSE(e): 4.136e-06, MSE(pi1): 7.841e-03, MSE(pi2): 1.476e-06, MSE(pi3): 1.036e-03\n",
      "Epoch 444400, Train loss: 2.219e+02, Test loss: 1.126e+03, MSE(e): 3.478e-06, MSE(pi1): 8.463e-03, MSE(pi2): 1.140e-06, MSE(pi3): 1.025e-03\n",
      "Epoch 444500, Train loss: 5.526e+02, Test loss: 1.378e+03, MSE(e): 1.504e-05, MSE(pi1): 2.825e-02, MSE(pi2): 3.987e-06, MSE(pi3): 1.197e-03\n",
      "Epoch 444600, Train loss: 3.559e+02, Test loss: 1.196e+03, MSE(e): 6.692e-06, MSE(pi1): 2.025e-02, MSE(pi2): 1.314e-06, MSE(pi3): 8.644e-04\n",
      "Epoch 444700, Train loss: 3.176e+02, Test loss: 1.398e+03, MSE(e): 6.556e-06, MSE(pi1): 1.403e-02, MSE(pi2): 2.697e-06, MSE(pi3): 1.118e-03\n",
      "Epoch 444800, Train loss: 2.086e+02, Test loss: 9.953e+02, MSE(e): 3.474e-06, MSE(pi1): 8.632e-03, MSE(pi2): 1.093e-06, MSE(pi3): 8.754e-04\n",
      "Epoch 444900, Train loss: 2.952e+02, Test loss: 1.217e+03, MSE(e): 4.922e-06, MSE(pi1): 1.375e-02, MSE(pi2): 1.109e-06, MSE(pi3): 1.085e-03\n",
      "Epoch 445000, Train loss: 9.489e+02, Test loss: 2.399e+03, MSE(e): 7.527e-05, MSE(pi1): 9.605e-03, MSE(pi2): 3.428e-05, MSE(pi3): 1.001e-03\n",
      "Epoch 445100, Train loss: 3.209e+02, Test loss: 1.038e+03, MSE(e): 1.739e-05, MSE(pi1): 6.184e-03, MSE(pi2): 8.199e-06, MSE(pi3): 8.519e-04\n",
      "Epoch 445200, Train loss: 1.619e+02, Test loss: 1.046e+03, MSE(e): 2.533e-06, MSE(pi1): 3.881e-03, MSE(pi2): 1.166e-06, MSE(pi3): 9.779e-04\n",
      "Epoch 445300, Train loss: 1.563e+02, Test loss: 9.978e+02, MSE(e): 2.462e-06, MSE(pi1): 3.792e-03, MSE(pi2): 1.056e-06, MSE(pi3): 9.379e-04\n",
      "Epoch 445400, Train loss: 5.293e+02, Test loss: 1.817e+03, MSE(e): 3.254e-05, MSE(pi1): 1.068e-02, MSE(pi2): 1.393e-05, MSE(pi3): 9.702e-04\n",
      "Epoch 445500, Train loss: 2.253e+02, Test loss: 1.213e+03, MSE(e): 7.362e-06, MSE(pi1): 4.936e-03, MSE(pi2): 3.456e-06, MSE(pi3): 1.024e-03\n",
      "Epoch 445600, Train loss: 2.101e+02, Test loss: 1.105e+03, MSE(e): 2.861e-06, MSE(pi1): 8.353e-03, MSE(pi2): 8.913e-07, MSE(pi3): 9.799e-04\n",
      "Epoch 445700, Train loss: 1.710e+02, Test loss: 9.590e+02, MSE(e): 2.744e-06, MSE(pi1): 5.114e-03, MSE(pi2): 1.270e-06, MSE(pi3): 9.246e-04\n",
      "Epoch 445800, Train loss: 5.900e+02, Test loss: 1.317e+03, MSE(e): 1.310e-05, MSE(pi1): 3.500e-02, MSE(pi2): 2.488e-06, MSE(pi3): 1.091e-03\n",
      "Epoch 445900, Train loss: 2.167e+02, Test loss: 9.675e+02, MSE(e): 5.259e-06, MSE(pi1): 7.494e-03, MSE(pi2): 2.595e-06, MSE(pi3): 8.920e-04\n",
      "Epoch 446000, Train loss: 1.447e+02, Test loss: 9.306e+02, MSE(e): 1.702e-06, MSE(pi1): 3.416e-03, MSE(pi2): 8.203e-07, MSE(pi3): 9.356e-04\n",
      "Epoch 446100, Train loss: 2.371e+02, Test loss: 9.620e+02, MSE(e): 4.156e-06, MSE(pi1): 9.392e-03, MSE(pi2): 1.239e-06, MSE(pi3): 1.016e-03\n",
      "Epoch 446200, Train loss: 3.174e+02, Test loss: 1.258e+03, MSE(e): 1.673e-05, MSE(pi1): 5.745e-03, MSE(pi2): 6.689e-06, MSE(pi3): 9.259e-04\n",
      "Epoch 446300, Train loss: 1.874e+02, Test loss: 1.012e+03, MSE(e): 5.249e-06, MSE(pi1): 4.790e-03, MSE(pi2): 2.558e-06, MSE(pi3): 8.696e-04\n",
      "Epoch 446400, Train loss: 1.515e+02, Test loss: 9.699e+02, MSE(e): 1.516e-06, MSE(pi1): 3.885e-03, MSE(pi2): 6.408e-07, MSE(pi3): 9.752e-04\n",
      "Epoch 446500, Train loss: 2.176e+02, Test loss: 1.093e+03, MSE(e): 3.066e-06, MSE(pi1): 9.862e-03, MSE(pi2): 7.685e-07, MSE(pi3): 8.836e-04\n",
      "Epoch 446600, Train loss: 2.460e+02, Test loss: 1.178e+03, MSE(e): 5.740e-06, MSE(pi1): 9.861e-03, MSE(pi2): 1.785e-06, MSE(pi3): 9.002e-04\n",
      "Epoch 446700, Train loss: 2.120e+02, Test loss: 1.077e+03, MSE(e): 3.189e-06, MSE(pi1): 9.536e-03, MSE(pi2): 9.481e-07, MSE(pi3): 8.479e-04\n",
      "Epoch 446800, Train loss: 3.577e+02, Test loss: 1.191e+03, MSE(e): 6.458e-06, MSE(pi1): 1.893e-02, MSE(pi2): 1.431e-06, MSE(pi3): 1.038e-03\n",
      "Epoch 446900, Train loss: 2.269e+02, Test loss: 1.035e+03, MSE(e): 3.245e-06, MSE(pi1): 1.081e-02, MSE(pi2): 9.316e-07, MSE(pi3): 8.630e-04\n",
      "Epoch 447000, Train loss: 3.079e+02, Test loss: 1.054e+03, MSE(e): 1.510e-05, MSE(pi1): 5.345e-03, MSE(pi2): 6.952e-06, MSE(pi3): 1.034e-03\n",
      "Epoch 447100, Train loss: 2.057e+02, Test loss: 1.155e+03, MSE(e): 3.463e-06, MSE(pi1): 7.233e-03, MSE(pi2): 1.687e-06, MSE(pi3): 9.871e-04\n",
      "Epoch 447200, Train loss: 3.162e+02, Test loss: 1.253e+03, MSE(e): 5.204e-06, MSE(pi1): 1.666e-02, MSE(pi2): 1.197e-06, MSE(pi3): 9.756e-04\n",
      "Epoch 447300, Train loss: 2.589e+02, Test loss: 1.162e+03, MSE(e): 4.509e-06, MSE(pi1): 1.123e-02, MSE(pi2): 1.417e-06, MSE(pi3): 1.014e-03\n",
      "Epoch 447400, Train loss: 2.159e+02, Test loss: 1.145e+03, MSE(e): 3.090e-06, MSE(pi1): 8.026e-03, MSE(pi2): 1.163e-06, MSE(pi3): 1.047e-03\n",
      "Epoch 447500, Train loss: 2.912e+02, Test loss: 1.055e+03, MSE(e): 4.997e-06, MSE(pi1): 1.548e-02, MSE(pi2): 1.391e-06, MSE(pi3): 8.639e-04\n",
      "Epoch 447600, Train loss: 1.603e+02, Test loss: 1.012e+03, MSE(e): 2.004e-06, MSE(pi1): 4.681e-03, MSE(pi2): 8.076e-07, MSE(pi3): 9.347e-04\n",
      "Epoch 447700, Train loss: 3.999e+02, Test loss: 1.350e+03, MSE(e): 8.367e-06, MSE(pi1): 2.129e-02, MSE(pi2): 2.704e-06, MSE(pi3): 1.034e-03\n",
      "Epoch 447800, Train loss: 2.280e+02, Test loss: 1.117e+03, MSE(e): 3.290e-06, MSE(pi1): 1.075e-02, MSE(pi2): 8.114e-07, MSE(pi3): 8.756e-04\n",
      "Epoch 447900, Train loss: 1.653e+02, Test loss: 1.149e+03, MSE(e): 2.205e-06, MSE(pi1): 4.910e-03, MSE(pi2): 8.282e-07, MSE(pi3): 9.414e-04\n",
      "Epoch 448000, Train loss: 1.795e+03, Test loss: 3.424e+03, MSE(e): 1.516e-04, MSE(pi1): 1.540e-02, MSE(pi2): 7.478e-05, MSE(pi3): 1.245e-03\n",
      "Epoch 448100, Train loss: 2.355e+02, Test loss: 1.162e+03, MSE(e): 7.629e-06, MSE(pi1): 5.217e-03, MSE(pi2): 3.983e-06, MSE(pi3): 1.070e-03\n",
      "Epoch 448200, Train loss: 2.456e+03, Test loss: 3.152e+03, MSE(e): 2.260e-04, MSE(pi1): 1.128e-02, MSE(pi2): 1.073e-04, MSE(pi3): 8.300e-04\n",
      "Epoch 448300, Train loss: 1.871e+02, Test loss: 1.035e+03, MSE(e): 2.213e-06, MSE(pi1): 6.815e-03, MSE(pi2): 7.864e-07, MSE(pi3): 9.683e-04\n",
      "Epoch 448400, Train loss: 3.082e+02, Test loss: 1.229e+03, MSE(e): 5.236e-06, MSE(pi1): 1.531e-02, MSE(pi2): 1.304e-06, MSE(pi3): 1.027e-03\n",
      "Epoch 448500, Train loss: 1.646e+02, Test loss: 1.018e+03, MSE(e): 1.639e-06, MSE(pi1): 5.327e-03, MSE(pi2): 6.301e-07, MSE(pi3): 9.495e-04\n",
      "Epoch 448600, Train loss: 1.613e+02, Test loss: 1.006e+03, MSE(e): 1.877e-06, MSE(pi1): 5.169e-03, MSE(pi2): 6.941e-07, MSE(pi3): 9.080e-04\n",
      "Epoch 448700, Train loss: 3.475e+02, Test loss: 1.282e+03, MSE(e): 6.093e-06, MSE(pi1): 2.011e-02, MSE(pi2): 2.151e-06, MSE(pi3): 8.548e-04\n",
      "Epoch 448800, Train loss: 1.841e+02, Test loss: 9.363e+02, MSE(e): 4.312e-06, MSE(pi1): 5.605e-03, MSE(pi2): 1.913e-06, MSE(pi3): 8.497e-04\n",
      "Epoch 448900, Train loss: 1.953e+02, Test loss: 1.152e+03, MSE(e): 6.519e-06, MSE(pi1): 3.479e-03, MSE(pi2): 3.013e-06, MSE(pi3): 9.527e-04\n",
      "Epoch 449000, Train loss: 1.975e+03, Test loss: 2.557e+03, MSE(e): 1.791e-04, MSE(pi1): 9.112e-03, MSE(pi2): 8.599e-05, MSE(pi3): 9.254e-04\n",
      "Epoch 449100, Train loss: 6.001e+02, Test loss: 1.843e+03, MSE(e): 3.660e-05, MSE(pi1): 1.440e-02, MSE(pi2): 1.610e-05, MSE(pi3): 9.007e-04\n",
      "Epoch 449200, Train loss: 5.720e+02, Test loss: 1.912e+03, MSE(e): 4.235e-05, MSE(pi1): 4.471e-03, MSE(pi2): 2.113e-05, MSE(pi3): 1.037e-03\n",
      "Epoch 449300, Train loss: 4.404e+02, Test loss: 1.641e+03, MSE(e): 1.229e-05, MSE(pi1): 1.984e-02, MSE(pi2): 4.468e-06, MSE(pi3): 1.191e-03\n",
      "Epoch 449400, Train loss: 1.722e+02, Test loss: 1.038e+03, MSE(e): 2.033e-06, MSE(pi1): 5.538e-03, MSE(pi2): 7.791e-07, MSE(pi3): 9.644e-04\n",
      "Epoch 449500, Train loss: 1.641e+02, Test loss: 9.953e+02, MSE(e): 3.048e-06, MSE(pi1): 4.012e-03, MSE(pi2): 1.456e-06, MSE(pi3): 9.347e-04\n",
      "Epoch 449600, Train loss: 1.778e+02, Test loss: 9.191e+02, MSE(e): 4.789e-06, MSE(pi1): 3.700e-03, MSE(pi2): 2.082e-06, MSE(pi3): 9.289e-04\n",
      "Epoch 449700, Train loss: 1.785e+02, Test loss: 9.597e+02, MSE(e): 3.559e-06, MSE(pi1): 4.551e-03, MSE(pi2): 1.543e-06, MSE(pi3): 9.740e-04\n",
      "Epoch 449800, Train loss: 2.182e+02, Test loss: 1.070e+03, MSE(e): 2.791e-06, MSE(pi1): 9.599e-03, MSE(pi2): 8.534e-07, MSE(pi3): 9.429e-04\n",
      "Epoch 449900, Train loss: 1.546e+02, Test loss: 9.751e+02, MSE(e): 1.544e-06, MSE(pi1): 4.648e-03, MSE(pi2): 5.907e-07, MSE(pi3): 9.269e-04\n",
      "Epoch 450000, Train loss: 2.060e+02, Test loss: 1.027e+03, MSE(e): 3.037e-06, MSE(pi1): 7.581e-03, MSE(pi2): 9.605e-07, MSE(pi3): 9.981e-04\n",
      "Epoch 450100, Train loss: 3.345e+02, Test loss: 1.237e+03, MSE(e): 1.207e-05, MSE(pi1): 1.075e-02, MSE(pi2): 4.559e-06, MSE(pi3): 1.063e-03\n",
      "Epoch 450200, Train loss: 2.963e+03, Test loss: 3.729e+03, MSE(e): 2.806e-04, MSE(pi1): 7.366e-03, MSE(pi2): 1.289e-04, MSE(pi3): 8.315e-04\n",
      "Epoch 450300, Train loss: 6.834e+02, Test loss: 1.810e+03, MSE(e): 2.258e-05, MSE(pi1): 3.169e-02, MSE(pi2): 8.768e-06, MSE(pi3): 1.407e-03\n",
      "Epoch 450400, Train loss: 1.610e+02, Test loss: 9.996e+02, MSE(e): 1.785e-06, MSE(pi1): 4.838e-03, MSE(pi2): 7.038e-07, MSE(pi3): 9.481e-04\n",
      "Epoch 450500, Train loss: 3.934e+02, Test loss: 1.418e+03, MSE(e): 6.438e-06, MSE(pi1): 2.259e-02, MSE(pi2): 1.501e-06, MSE(pi3): 1.031e-03\n",
      "Epoch 450600, Train loss: 1.503e+02, Test loss: 9.999e+02, MSE(e): 1.365e-06, MSE(pi1): 4.025e-03, MSE(pi2): 6.072e-07, MSE(pi3): 9.641e-04\n",
      "Epoch 450700, Train loss: 2.056e+02, Test loss: 9.892e+02, MSE(e): 3.100e-06, MSE(pi1): 8.157e-03, MSE(pi2): 8.765e-07, MSE(pi3): 9.304e-04\n",
      "Epoch 450800, Train loss: 2.103e+02, Test loss: 1.041e+03, MSE(e): 3.258e-06, MSE(pi1): 9.044e-03, MSE(pi2): 1.252e-06, MSE(pi3): 8.725e-04\n",
      "Epoch 450900, Train loss: 3.017e+02, Test loss: 1.124e+03, MSE(e): 5.405e-06, MSE(pi1): 1.417e-02, MSE(pi2): 1.478e-06, MSE(pi3): 1.060e-03\n",
      "Epoch 451000, Train loss: 4.359e+02, Test loss: 1.663e+03, MSE(e): 1.418e-05, MSE(pi1): 1.966e-02, MSE(pi2): 5.273e-06, MSE(pi3): 9.754e-04\n",
      "Epoch 451100, Train loss: 1.880e+02, Test loss: 1.081e+03, MSE(e): 2.167e-06, MSE(pi1): 6.296e-03, MSE(pi2): 7.439e-07, MSE(pi3): 1.034e-03\n",
      "Epoch 451200, Train loss: 8.485e+02, Test loss: 2.466e+03, MSE(e): 6.624e-05, MSE(pi1): 8.292e-03, MSE(pi2): 3.287e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 451300, Train loss: 1.861e+02, Test loss: 1.130e+03, MSE(e): 5.705e-06, MSE(pi1): 3.146e-03, MSE(pi2): 2.724e-06, MSE(pi3): 9.755e-04\n",
      "Epoch 451400, Train loss: 2.518e+02, Test loss: 1.118e+03, MSE(e): 3.844e-06, MSE(pi1): 1.255e-02, MSE(pi2): 1.008e-06, MSE(pi3): 8.781e-04\n",
      "Epoch 451500, Train loss: 1.495e+03, Test loss: 1.761e+03, MSE(e): 1.271e-04, MSE(pi1): 1.395e-02, MSE(pi2): 6.267e-05, MSE(pi3): 8.441e-04\n",
      "Epoch 451600, Train loss: 1.366e+03, Test loss: 2.145e+03, MSE(e): 1.123e-04, MSE(pi1): 1.444e-02, MSE(pi2): 5.340e-05, MSE(pi3): 9.828e-04\n",
      "Epoch 451700, Train loss: 2.155e+02, Test loss: 9.415e+02, MSE(e): 6.880e-06, MSE(pi1): 5.424e-03, MSE(pi2): 2.796e-06, MSE(pi3): 9.245e-04\n",
      "Epoch 451800, Train loss: 2.312e+02, Test loss: 1.150e+03, MSE(e): 3.140e-06, MSE(pi1): 1.120e-02, MSE(pi2): 7.736e-07, MSE(pi3): 8.781e-04\n",
      "Epoch 451900, Train loss: 2.386e+02, Test loss: 1.146e+03, MSE(e): 6.986e-06, MSE(pi1): 7.668e-03, MSE(pi2): 2.548e-06, MSE(pi3): 9.205e-04\n",
      "Epoch 452000, Train loss: 4.752e+02, Test loss: 1.375e+03, MSE(e): 1.470e-05, MSE(pi1): 2.363e-02, MSE(pi2): 5.648e-06, MSE(pi3): 9.191e-04\n",
      "Epoch 452100, Train loss: 6.116e+02, Test loss: 1.604e+03, MSE(e): 4.231e-05, MSE(pi1): 7.923e-03, MSE(pi2): 2.097e-05, MSE(pi3): 1.092e-03\n",
      "Epoch 452200, Train loss: 1.207e+03, Test loss: 2.953e+03, MSE(e): 1.058e-04, MSE(pi1): 4.857e-03, MSE(pi2): 4.828e-05, MSE(pi3): 1.011e-03\n",
      "Epoch 452300, Train loss: 9.749e+02, Test loss: 2.480e+03, MSE(e): 7.144e-05, MSE(pi1): 1.509e-02, MSE(pi2): 3.435e-05, MSE(pi3): 1.096e-03\n",
      "Epoch 452400, Train loss: 4.079e+02, Test loss: 1.139e+03, MSE(e): 2.166e-05, MSE(pi1): 1.054e-02, MSE(pi2): 1.085e-05, MSE(pi3): 8.591e-04\n",
      "Epoch 452500, Train loss: 4.594e+02, Test loss: 1.110e+03, MSE(e): 3.006e-05, MSE(pi1): 7.093e-03, MSE(pi2): 1.574e-05, MSE(pi3): 8.777e-04\n",
      "Epoch 452600, Train loss: 3.954e+02, Test loss: 1.229e+03, MSE(e): 1.796e-05, MSE(pi1): 1.270e-02, MSE(pi2): 7.993e-06, MSE(pi3): 8.877e-04\n",
      "Epoch 452700, Train loss: 2.643e+02, Test loss: 1.193e+03, MSE(e): 5.657e-06, MSE(pi1): 1.058e-02, MSE(pi2): 1.873e-06, MSE(pi3): 1.019e-03\n",
      "Epoch 452800, Train loss: 1.842e+02, Test loss: 9.871e+02, MSE(e): 2.591e-06, MSE(pi1): 6.096e-03, MSE(pi2): 9.934e-07, MSE(pi3): 9.736e-04\n",
      "Epoch 452900, Train loss: 1.672e+03, Test loss: 2.426e+03, MSE(e): 1.494e-04, MSE(pi1): 9.046e-03, MSE(pi2): 7.331e-05, MSE(pi3): 8.752e-04\n",
      "Epoch 453000, Train loss: 5.755e+02, Test loss: 1.774e+03, MSE(e): 4.359e-05, MSE(pi1): 4.482e-03, MSE(pi2): 1.980e-05, MSE(pi3): 9.468e-04\n",
      "Epoch 453100, Train loss: 6.184e+02, Test loss: 1.131e+03, MSE(e): 3.432e-05, MSE(pi1): 1.644e-02, MSE(pi2): 1.591e-05, MSE(pi3): 1.108e-03\n",
      "Epoch 453200, Train loss: 1.886e+02, Test loss: 1.006e+03, MSE(e): 2.817e-06, MSE(pi1): 5.786e-03, MSE(pi2): 1.050e-06, MSE(pi3): 1.026e-03\n",
      "Epoch 453300, Train loss: 2.296e+03, Test loss: 2.500e+03, MSE(e): 2.119e-04, MSE(pi1): 8.842e-03, MSE(pi2): 9.749e-05, MSE(pi3): 8.866e-04\n",
      "Epoch 453400, Train loss: 3.290e+02, Test loss: 1.194e+03, MSE(e): 6.764e-06, MSE(pi1): 1.744e-02, MSE(pi2): 2.561e-06, MSE(pi3): 8.691e-04\n",
      "Epoch 453500, Train loss: 1.757e+03, Test loss: 2.580e+03, MSE(e): 1.541e-04, MSE(pi1): 1.309e-02, MSE(pi2): 7.175e-05, MSE(pi3): 8.518e-04\n",
      "Epoch 453600, Train loss: 2.957e+02, Test loss: 1.178e+03, MSE(e): 5.703e-06, MSE(pi1): 1.295e-02, MSE(pi2): 1.408e-06, MSE(pi3): 1.091e-03\n",
      "Epoch 453700, Train loss: 7.086e+02, Test loss: 1.651e+03, MSE(e): 2.201e-05, MSE(pi1): 4.079e-02, MSE(pi2): 7.938e-06, MSE(pi3): 8.066e-04\n",
      "Epoch 453800, Train loss: 2.666e+02, Test loss: 1.010e+03, MSE(e): 5.993e-06, MSE(pi1): 1.093e-02, MSE(pi2): 2.459e-06, MSE(pi3): 9.738e-04\n",
      "Epoch 453900, Train loss: 2.335e+02, Test loss: 1.126e+03, MSE(e): 5.211e-06, MSE(pi1): 9.293e-03, MSE(pi2): 1.756e-06, MSE(pi3): 8.850e-04\n",
      "Epoch 454000, Train loss: 2.902e+02, Test loss: 1.328e+03, MSE(e): 1.458e-05, MSE(pi1): 5.130e-03, MSE(pi2): 6.481e-06, MSE(pi3): 9.314e-04\n",
      "Epoch 454100, Train loss: 2.825e+02, Test loss: 1.027e+03, MSE(e): 9.300e-06, MSE(pi1): 9.254e-03, MSE(pi2): 3.695e-06, MSE(pi3): 9.692e-04\n",
      "Epoch 454200, Train loss: 4.073e+02, Test loss: 1.133e+03, MSE(e): 1.771e-05, MSE(pi1): 1.433e-02, MSE(pi2): 8.572e-06, MSE(pi3): 8.693e-04\n",
      "Epoch 454300, Train loss: 2.637e+02, Test loss: 1.126e+03, MSE(e): 8.514e-06, MSE(pi1): 6.926e-03, MSE(pi2): 3.369e-06, MSE(pi3): 1.093e-03\n",
      "Epoch 454400, Train loss: 3.786e+02, Test loss: 1.485e+03, MSE(e): 7.496e-06, MSE(pi1): 2.079e-02, MSE(pi2): 1.837e-06, MSE(pi3): 9.575e-04\n",
      "Epoch 454500, Train loss: 1.459e+02, Test loss: 9.439e+02, MSE(e): 1.402e-06, MSE(pi1): 3.581e-03, MSE(pi2): 6.242e-07, MSE(pi3): 9.610e-04\n",
      "Epoch 454600, Train loss: 2.695e+02, Test loss: 1.199e+03, MSE(e): 4.153e-06, MSE(pi1): 1.168e-02, MSE(pi2): 1.078e-06, MSE(pi3): 1.112e-03\n",
      "Epoch 454700, Train loss: 2.825e+02, Test loss: 1.037e+03, MSE(e): 1.131e-05, MSE(pi1): 8.176e-03, MSE(pi2): 5.638e-06, MSE(pi3): 8.758e-04\n",
      "Epoch 454800, Train loss: 1.854e+02, Test loss: 1.092e+03, MSE(e): 4.168e-06, MSE(pi1): 5.609e-03, MSE(pi2): 1.733e-06, MSE(pi3): 8.763e-04\n",
      "Epoch 454900, Train loss: 2.230e+02, Test loss: 1.112e+03, MSE(e): 3.569e-06, MSE(pi1): 9.812e-03, MSE(pi2): 9.335e-07, MSE(pi3): 8.916e-04\n",
      "Epoch 455000, Train loss: 4.530e+02, Test loss: 1.280e+03, MSE(e): 2.194e-05, MSE(pi1): 1.431e-02, MSE(pi2): 1.022e-05, MSE(pi3): 9.054e-04\n",
      "Epoch 455100, Train loss: 2.322e+02, Test loss: 1.103e+03, MSE(e): 4.328e-06, MSE(pi1): 8.934e-03, MSE(pi2): 1.557e-06, MSE(pi3): 9.958e-04\n",
      "Epoch 455200, Train loss: 1.976e+02, Test loss: 1.138e+03, MSE(e): 4.528e-06, MSE(pi1): 6.240e-03, MSE(pi2): 1.756e-06, MSE(pi3): 8.996e-04\n",
      "Epoch 455300, Train loss: 3.412e+02, Test loss: 1.420e+03, MSE(e): 1.271e-05, MSE(pi1): 1.255e-02, MSE(pi2): 4.562e-06, MSE(pi3): 8.857e-04\n",
      "Epoch 455400, Train loss: 2.887e+02, Test loss: 1.268e+03, MSE(e): 9.615e-06, MSE(pi1): 9.099e-03, MSE(pi2): 4.335e-06, MSE(pi3): 1.016e-03\n",
      "Epoch 455500, Train loss: 1.481e+02, Test loss: 9.436e+02, MSE(e): 1.899e-06, MSE(pi1): 3.707e-03, MSE(pi2): 9.368e-07, MSE(pi3): 9.200e-04\n",
      "Epoch 455600, Train loss: 4.795e+02, Test loss: 1.275e+03, MSE(e): 1.096e-05, MSE(pi1): 2.682e-02, MSE(pi2): 2.776e-06, MSE(pi3): 1.017e-03\n",
      "Epoch 455700, Train loss: 3.498e+02, Test loss: 1.094e+03, MSE(e): 8.909e-06, MSE(pi1): 1.453e-02, MSE(pi2): 2.914e-06, MSE(pi3): 1.154e-03\n",
      "Epoch 455800, Train loss: 2.503e+02, Test loss: 1.105e+03, MSE(e): 4.517e-06, MSE(pi1): 9.954e-03, MSE(pi2): 1.299e-06, MSE(pi3): 1.055e-03\n",
      "Epoch 455900, Train loss: 5.253e+02, Test loss: 1.356e+03, MSE(e): 1.191e-05, MSE(pi1): 2.987e-02, MSE(pi2): 2.780e-06, MSE(pi3): 1.075e-03\n",
      "Epoch 456000, Train loss: 1.590e+02, Test loss: 9.796e+02, MSE(e): 1.528e-06, MSE(pi1): 5.155e-03, MSE(pi2): 5.968e-07, MSE(pi3): 9.214e-04\n",
      "Epoch 456100, Train loss: 2.636e+02, Test loss: 1.068e+03, MSE(e): 6.123e-06, MSE(pi1): 1.077e-02, MSE(pi2): 2.072e-06, MSE(pi3): 9.463e-04\n",
      "Epoch 456200, Train loss: 2.018e+02, Test loss: 1.016e+03, MSE(e): 2.614e-06, MSE(pi1): 8.318e-03, MSE(pi2): 7.781e-07, MSE(pi3): 9.246e-04\n",
      "Epoch 456300, Train loss: 3.603e+02, Test loss: 1.515e+03, MSE(e): 2.158e-05, MSE(pi1): 4.455e-03, MSE(pi2): 1.037e-05, MSE(pi3): 9.996e-04\n",
      "Epoch 456400, Train loss: 2.581e+02, Test loss: 1.238e+03, MSE(e): 6.131e-06, MSE(pi1): 8.901e-03, MSE(pi2): 2.768e-06, MSE(pi3): 1.078e-03\n",
      "Epoch 456500, Train loss: 2.352e+02, Test loss: 1.030e+03, MSE(e): 3.391e-06, MSE(pi1): 1.141e-02, MSE(pi2): 1.093e-06, MSE(pi3): 8.718e-04\n",
      "Epoch 456600, Train loss: 9.127e+02, Test loss: 2.494e+03, MSE(e): 7.602e-05, MSE(pi1): 3.679e-03, MSE(pi2): 3.618e-05, MSE(pi3): 1.157e-03\n",
      "Epoch 456700, Train loss: 1.727e+02, Test loss: 9.749e+02, MSE(e): 2.483e-06, MSE(pi1): 5.681e-03, MSE(pi2): 1.101e-06, MSE(pi3): 9.103e-04\n",
      "Epoch 456800, Train loss: 3.941e+02, Test loss: 1.036e+03, MSE(e): 8.823e-06, MSE(pi1): 2.000e-02, MSE(pi2): 2.245e-06, MSE(pi3): 1.059e-03\n",
      "Epoch 456900, Train loss: 2.063e+02, Test loss: 1.047e+03, MSE(e): 2.913e-06, MSE(pi1): 8.161e-03, MSE(pi2): 9.310e-07, MSE(pi3): 9.559e-04\n",
      "Epoch 457000, Train loss: 2.917e+02, Test loss: 1.095e+03, MSE(e): 5.161e-06, MSE(pi1): 1.435e-02, MSE(pi2): 1.142e-06, MSE(pi3): 9.650e-04\n",
      "Epoch 457100, Train loss: 1.713e+02, Test loss: 9.798e+02, MSE(e): 2.100e-06, MSE(pi1): 5.704e-03, MSE(pi2): 7.827e-07, MSE(pi3): 9.328e-04\n",
      "Epoch 457200, Train loss: 2.713e+02, Test loss: 1.341e+03, MSE(e): 1.132e-05, MSE(pi1): 6.050e-03, MSE(pi2): 4.899e-06, MSE(pi3): 9.760e-04\n",
      "Epoch 457300, Train loss: 3.256e+02, Test loss: 1.374e+03, MSE(e): 1.388e-05, MSE(pi1): 8.436e-03, MSE(pi2): 6.514e-06, MSE(pi3): 1.024e-03\n",
      "Epoch 457400, Train loss: 1.168e+03, Test loss: 1.997e+03, MSE(e): 5.609e-05, MSE(pi1): 4.572e-02, MSE(pi2): 2.238e-05, MSE(pi3): 1.496e-03\n",
      "Epoch 457500, Train loss: 2.082e+02, Test loss: 1.028e+03, MSE(e): 2.846e-06, MSE(pi1): 8.475e-03, MSE(pi2): 9.259e-07, MSE(pi3): 9.503e-04\n",
      "Epoch 457600, Train loss: 3.764e+02, Test loss: 1.364e+03, MSE(e): 6.335e-06, MSE(pi1): 2.127e-02, MSE(pi2): 1.403e-06, MSE(pi3): 1.003e-03\n",
      "Epoch 457700, Train loss: 2.558e+02, Test loss: 9.980e+02, MSE(e): 6.039e-06, MSE(pi1): 1.096e-02, MSE(pi2): 2.257e-06, MSE(pi3): 8.580e-04\n",
      "Epoch 457800, Train loss: 2.074e+02, Test loss: 1.111e+03, MSE(e): 3.034e-06, MSE(pi1): 8.971e-03, MSE(pi2): 8.615e-07, MSE(pi3): 8.732e-04\n",
      "Epoch 457900, Train loss: 2.513e+02, Test loss: 1.078e+03, MSE(e): 3.712e-06, MSE(pi1): 1.098e-02, MSE(pi2): 9.599e-07, MSE(pi3): 1.043e-03\n",
      "Epoch 458000, Train loss: 2.369e+02, Test loss: 1.132e+03, MSE(e): 4.443e-06, MSE(pi1): 1.005e-02, MSE(pi2): 1.915e-06, MSE(pi3): 9.191e-04\n",
      "Epoch 458100, Train loss: 8.136e+02, Test loss: 1.704e+03, MSE(e): 5.487e-05, MSE(pi1): 1.620e-02, MSE(pi2): 2.303e-05, MSE(pi3): 1.030e-03\n",
      "Epoch 458200, Train loss: 1.552e+03, Test loss: 2.888e+03, MSE(e): 1.308e-04, MSE(pi1): 1.192e-02, MSE(pi2): 6.272e-05, MSE(pi3): 1.249e-03\n",
      "Epoch 458300, Train loss: 3.715e+02, Test loss: 1.185e+03, MSE(e): 1.376e-05, MSE(pi1): 1.427e-02, MSE(pi2): 5.528e-06, MSE(pi3): 9.116e-04\n",
      "Epoch 458400, Train loss: 6.179e+02, Test loss: 1.279e+03, MSE(e): 4.361e-05, MSE(pi1): 9.501e-03, MSE(pi2): 2.071e-05, MSE(pi3): 8.679e-04\n",
      "Epoch 458500, Train loss: 2.777e+03, Test loss: 4.311e+03, MSE(e): 2.606e-04, MSE(pi1): 5.318e-03, MSE(pi2): 1.243e-04, MSE(pi3): 1.176e-03\n",
      "Epoch 458600, Train loss: 1.559e+02, Test loss: 1.033e+03, MSE(e): 2.592e-06, MSE(pi1): 3.288e-03, MSE(pi2): 1.252e-06, MSE(pi3): 9.706e-04\n",
      "Epoch 458700, Train loss: 2.276e+02, Test loss: 1.052e+03, MSE(e): 3.077e-06, MSE(pi1): 1.014e-02, MSE(pi2): 9.523e-07, MSE(pi3): 9.542e-04\n",
      "Epoch 458800, Train loss: 1.551e+02, Test loss: 9.725e+02, MSE(e): 1.429e-06, MSE(pi1): 4.702e-03, MSE(pi2): 5.710e-07, MSE(pi3): 9.382e-04\n",
      "Epoch 458900, Train loss: 1.931e+02, Test loss: 1.009e+03, MSE(e): 2.443e-06, MSE(pi1): 6.832e-03, MSE(pi2): 8.261e-07, MSE(pi3): 1.004e-03\n",
      "Epoch 459000, Train loss: 3.050e+02, Test loss: 1.270e+03, MSE(e): 6.863e-06, MSE(pi1): 1.333e-02, MSE(pi2): 2.045e-06, MSE(pi3): 1.031e-03\n",
      "Epoch 459100, Train loss: 1.539e+02, Test loss: 9.675e+02, MSE(e): 1.472e-06, MSE(pi1): 4.402e-03, MSE(pi2): 6.039e-07, MSE(pi3): 9.513e-04\n",
      "Epoch 459200, Train loss: 1.551e+02, Test loss: 9.691e+02, MSE(e): 1.561e-06, MSE(pi1): 4.076e-03, MSE(pi2): 6.402e-07, MSE(pi3): 9.875e-04\n",
      "Epoch 459300, Train loss: 3.369e+02, Test loss: 1.548e+03, MSE(e): 2.025e-05, MSE(pi1): 3.710e-03, MSE(pi2): 9.963e-06, MSE(pi3): 9.729e-04\n",
      "Epoch 459400, Train loss: 1.736e+03, Test loss: 2.569e+03, MSE(e): 8.538e-05, MSE(pi1): 7.566e-02, MSE(pi2): 3.166e-05, MSE(pi3): 1.258e-03\n",
      "Epoch 459500, Train loss: 4.171e+02, Test loss: 1.679e+03, MSE(e): 2.752e-05, MSE(pi1): 3.989e-03, MSE(pi2): 1.375e-05, MSE(pi3): 1.020e-03\n",
      "Epoch 459600, Train loss: 2.396e+02, Test loss: 1.059e+03, MSE(e): 3.691e-06, MSE(pi1): 1.074e-02, MSE(pi2): 1.178e-06, MSE(pi3): 9.525e-04\n",
      "Epoch 459700, Train loss: 1.572e+02, Test loss: 9.700e+02, MSE(e): 2.153e-06, MSE(pi1): 4.141e-03, MSE(pi2): 9.814e-07, MSE(pi3): 9.422e-04\n",
      "Epoch 459800, Train loss: 2.108e+02, Test loss: 1.060e+03, MSE(e): 3.824e-06, MSE(pi1): 6.496e-03, MSE(pi2): 1.544e-06, MSE(pi3): 1.076e-03\n",
      "Epoch 459900, Train loss: 1.407e+02, Test loss: 9.444e+02, MSE(e): 1.339e-06, MSE(pi1): 3.234e-03, MSE(pi2): 6.493e-07, MSE(pi3): 9.494e-04\n",
      "Epoch 460000, Train loss: 2.214e+02, Test loss: 9.609e+02, MSE(e): 4.700e-06, MSE(pi1): 7.585e-03, MSE(pi2): 1.869e-06, MSE(pi3): 9.858e-04\n",
      "Epoch 460100, Train loss: 2.815e+02, Test loss: 1.080e+03, MSE(e): 6.720e-06, MSE(pi1): 1.148e-02, MSE(pi2): 2.503e-06, MSE(pi3): 9.959e-04\n",
      "Epoch 460200, Train loss: 9.790e+02, Test loss: 1.808e+03, MSE(e): 8.025e-05, MSE(pi1): 8.985e-03, MSE(pi2): 3.942e-05, MSE(pi3): 8.653e-04\n",
      "Epoch 460300, Train loss: 2.526e+03, Test loss: 3.136e+03, MSE(e): 2.266e-04, MSE(pi1): 1.788e-02, MSE(pi2): 1.085e-04, MSE(pi3): 8.027e-04\n",
      "Epoch 460400, Train loss: 1.517e+02, Test loss: 1.015e+03, MSE(e): 1.617e-06, MSE(pi1): 4.264e-03, MSE(pi2): 7.003e-07, MSE(pi3): 9.286e-04\n",
      "Epoch 460500, Train loss: 3.957e+02, Test loss: 1.298e+03, MSE(e): 7.871e-06, MSE(pi1): 2.108e-02, MSE(pi2): 1.857e-06, MSE(pi3): 1.062e-03\n",
      "Epoch 460600, Train loss: 1.733e+02, Test loss: 1.074e+03, MSE(e): 3.055e-06, MSE(pi1): 4.813e-03, MSE(pi2): 1.133e-06, MSE(pi3): 9.458e-04\n",
      "Epoch 460700, Train loss: 2.169e+02, Test loss: 1.100e+03, MSE(e): 5.036e-06, MSE(pi1): 7.530e-03, MSE(pi2): 1.674e-06, MSE(pi3): 9.125e-04\n",
      "Epoch 460800, Train loss: 1.914e+02, Test loss: 1.002e+03, MSE(e): 3.005e-06, MSE(pi1): 6.490e-03, MSE(pi2): 1.115e-06, MSE(pi3): 9.644e-04\n",
      "Epoch 460900, Train loss: 1.392e+02, Test loss: 9.661e+02, MSE(e): 1.071e-06, MSE(pi1): 3.290e-03, MSE(pi2): 5.236e-07, MSE(pi3): 9.565e-04\n",
      "Epoch 461000, Train loss: 3.168e+02, Test loss: 1.147e+03, MSE(e): 5.422e-06, MSE(pi1): 1.619e-02, MSE(pi2): 1.289e-06, MSE(pi3): 1.007e-03\n",
      "Epoch 461100, Train loss: 6.005e+02, Test loss: 1.331e+03, MSE(e): 4.237e-05, MSE(pi1): 7.943e-03, MSE(pi2): 1.851e-05, MSE(pi3): 9.742e-04\n",
      "Epoch 461200, Train loss: 3.956e+02, Test loss: 1.146e+03, MSE(e): 7.887e-06, MSE(pi1): 2.317e-02, MSE(pi2): 1.880e-06, MSE(pi3): 8.504e-04\n",
      "Epoch 461300, Train loss: 2.988e+02, Test loss: 1.232e+03, MSE(e): 5.610e-06, MSE(pi1): 1.476e-02, MSE(pi2): 1.351e-06, MSE(pi3): 9.507e-04\n",
      "Epoch 461400, Train loss: 2.783e+02, Test loss: 1.056e+03, MSE(e): 5.209e-06, MSE(pi1): 1.327e-02, MSE(pi2): 1.379e-06, MSE(pi3): 9.357e-04\n",
      "Epoch 461500, Train loss: 2.855e+02, Test loss: 1.238e+03, MSE(e): 4.533e-06, MSE(pi1): 1.470e-02, MSE(pi2): 1.116e-06, MSE(pi3): 9.312e-04\n",
      "Epoch 461600, Train loss: 2.365e+02, Test loss: 1.120e+03, MSE(e): 3.615e-06, MSE(pi1): 1.116e-02, MSE(pi2): 9.220e-07, MSE(pi3): 8.873e-04\n",
      "Epoch 461700, Train loss: 2.257e+02, Test loss: 9.798e+02, MSE(e): 7.804e-06, MSE(pi1): 5.375e-03, MSE(pi2): 3.972e-06, MSE(pi3): 9.389e-04\n",
      "Epoch 461800, Train loss: 2.223e+02, Test loss: 1.174e+03, MSE(e): 7.194e-06, MSE(pi1): 5.038e-03, MSE(pi2): 3.418e-06, MSE(pi3): 9.993e-04\n",
      "Epoch 461900, Train loss: 3.702e+02, Test loss: 1.219e+03, MSE(e): 6.872e-06, MSE(pi1): 1.907e-02, MSE(pi2): 1.335e-06, MSE(pi3): 1.108e-03\n",
      "Epoch 462000, Train loss: 2.386e+02, Test loss: 1.081e+03, MSE(e): 3.841e-06, MSE(pi1): 1.068e-02, MSE(pi2): 1.113e-06, MSE(pi3): 9.339e-04\n",
      "Epoch 462100, Train loss: 2.035e+02, Test loss: 1.075e+03, MSE(e): 3.564e-06, MSE(pi1): 7.489e-03, MSE(pi2): 1.161e-06, MSE(pi3): 9.292e-04\n",
      "Epoch 462200, Train loss: 2.091e+02, Test loss: 9.664e+02, MSE(e): 4.999e-06, MSE(pi1): 6.872e-03, MSE(pi2): 2.099e-06, MSE(pi3): 9.044e-04\n",
      "Epoch 462300, Train loss: 2.747e+02, Test loss: 1.200e+03, MSE(e): 9.670e-06, MSE(pi1): 7.143e-03, MSE(pi2): 4.257e-06, MSE(pi3): 1.065e-03\n",
      "Epoch 462400, Train loss: 1.096e+03, Test loss: 1.368e+03, MSE(e): 9.436e-05, MSE(pi1): 6.757e-03, MSE(pi2): 4.460e-05, MSE(pi3): 8.497e-04\n",
      "Epoch 462500, Train loss: 1.505e+03, Test loss: 1.686e+03, MSE(e): 1.336e-04, MSE(pi1): 8.022e-03, MSE(pi2): 6.354e-05, MSE(pi3): 8.806e-04\n",
      "Epoch 462600, Train loss: 3.468e+02, Test loss: 1.258e+03, MSE(e): 6.292e-06, MSE(pi1): 2.001e-02, MSE(pi2): 1.297e-06, MSE(pi3): 8.375e-04\n",
      "Epoch 462700, Train loss: 2.731e+02, Test loss: 1.123e+03, MSE(e): 4.195e-06, MSE(pi1): 1.330e-02, MSE(pi2): 9.914e-07, MSE(pi3): 9.807e-04\n",
      "Epoch 462800, Train loss: 2.195e+02, Test loss: 1.130e+03, MSE(e): 4.957e-06, MSE(pi1): 7.548e-03, MSE(pi2): 1.902e-06, MSE(pi3): 9.443e-04\n",
      "Epoch 462900, Train loss: 3.466e+02, Test loss: 1.037e+03, MSE(e): 2.052e-05, MSE(pi1): 4.806e-03, MSE(pi2): 9.896e-06, MSE(pi3): 9.336e-04\n",
      "Epoch 463000, Train loss: 3.103e+02, Test loss: 1.453e+03, MSE(e): 1.232e-05, MSE(pi1): 7.823e-03, MSE(pi2): 6.099e-06, MSE(pi3): 1.088e-03\n",
      "Epoch 463100, Train loss: 4.601e+03, Test loss: 6.027e+03, MSE(e): 4.419e-04, MSE(pi1): 5.890e-03, MSE(pi2): 2.065e-04, MSE(pi3): 1.235e-03\n",
      "Epoch 463200, Train loss: 2.369e+02, Test loss: 1.111e+03, MSE(e): 3.306e-06, MSE(pi1): 1.074e-02, MSE(pi2): 8.900e-07, MSE(pi3): 9.642e-04\n",
      "Epoch 463300, Train loss: 2.712e+02, Test loss: 1.019e+03, MSE(e): 1.045e-05, MSE(pi1): 6.658e-03, MSE(pi2): 4.074e-06, MSE(pi3): 1.002e-03\n",
      "Epoch 463400, Train loss: 1.644e+02, Test loss: 9.665e+02, MSE(e): 2.120e-06, MSE(pi1): 5.214e-03, MSE(pi2): 9.280e-07, MSE(pi3): 9.108e-04\n",
      "Epoch 463500, Train loss: 1.581e+02, Test loss: 9.603e+02, MSE(e): 1.492e-06, MSE(pi1): 5.271e-03, MSE(pi2): 6.075e-07, MSE(pi3): 9.045e-04\n",
      "Epoch 463600, Train loss: 2.040e+03, Test loss: 2.617e+03, MSE(e): 1.817e-04, MSE(pi1): 1.411e-02, MSE(pi2): 8.868e-05, MSE(pi3): 8.258e-04\n",
      "Epoch 463700, Train loss: 8.424e+02, Test loss: 2.282e+03, MSE(e): 4.829e-05, MSE(pi1): 2.625e-02, MSE(pi2): 2.007e-05, MSE(pi3): 9.702e-04\n",
      "Epoch 463800, Train loss: 2.762e+02, Test loss: 1.069e+03, MSE(e): 9.553e-06, MSE(pi1): 9.339e-03, MSE(pi2): 4.407e-06, MSE(pi3): 8.727e-04\n",
      "Epoch 463900, Train loss: 3.313e+02, Test loss: 1.201e+03, MSE(e): 5.463e-06, MSE(pi1): 1.917e-02, MSE(pi2): 1.445e-06, MSE(pi3): 8.495e-04\n",
      "Epoch 464000, Train loss: 8.637e+02, Test loss: 2.261e+03, MSE(e): 6.298e-05, MSE(pi1): 1.357e-02, MSE(pi2): 2.841e-05, MSE(pi3): 9.819e-04\n",
      "Epoch 464100, Train loss: 3.287e+02, Test loss: 1.124e+03, MSE(e): 1.102e-05, MSE(pi1): 1.249e-02, MSE(pi2): 4.680e-06, MSE(pi3): 9.359e-04\n",
      "Epoch 464200, Train loss: 7.279e+02, Test loss: 1.153e+03, MSE(e): 5.494e-05, MSE(pi1): 8.327e-03, MSE(pi2): 2.540e-05, MSE(pi3): 9.514e-04\n",
      "Epoch 464300, Train loss: 2.683e+02, Test loss: 1.348e+03, MSE(e): 9.387e-06, MSE(pi1): 8.210e-03, MSE(pi2): 3.144e-06, MSE(pi3): 9.234e-04\n",
      "Epoch 464400, Train loss: 1.417e+03, Test loss: 2.936e+03, MSE(e): 1.159e-04, MSE(pi1): 1.326e-02, MSE(pi2): 5.669e-05, MSE(pi3): 1.255e-03\n",
      "Epoch 464500, Train loss: 2.620e+02, Test loss: 1.182e+03, MSE(e): 5.535e-06, MSE(pi1): 1.032e-02, MSE(pi2): 2.171e-06, MSE(pi3): 1.035e-03\n",
      "Epoch 464600, Train loss: 2.282e+02, Test loss: 9.722e+02, MSE(e): 7.091e-06, MSE(pi1): 6.000e-03, MSE(pi2): 3.037e-06, MSE(pi3): 9.730e-04\n",
      "Epoch 464700, Train loss: 2.541e+02, Test loss: 9.256e+02, MSE(e): 1.193e-05, MSE(pi1): 4.335e-03, MSE(pi2): 6.028e-06, MSE(pi3): 9.141e-04\n",
      "Epoch 464800, Train loss: 4.909e+02, Test loss: 1.661e+03, MSE(e): 2.077e-05, MSE(pi1): 1.959e-02, MSE(pi2): 7.199e-06, MSE(pi3): 8.732e-04\n",
      "Epoch 464900, Train loss: 2.021e+02, Test loss: 9.481e+02, MSE(e): 6.107e-06, MSE(pi1): 5.091e-03, MSE(pi2): 3.062e-06, MSE(pi3): 9.013e-04\n",
      "Epoch 465000, Train loss: 6.353e+02, Test loss: 2.155e+03, MSE(e): 4.668e-05, MSE(pi1): 6.043e-03, MSE(pi2): 2.282e-05, MSE(pi3): 1.080e-03\n",
      "Epoch 465100, Train loss: 2.280e+02, Test loss: 1.138e+03, MSE(e): 3.240e-06, MSE(pi1): 1.076e-02, MSE(pi2): 7.399e-07, MSE(pi3): 8.805e-04\n",
      "Epoch 465200, Train loss: 2.844e+02, Test loss: 9.824e+02, MSE(e): 1.433e-05, MSE(pi1): 5.235e-03, MSE(pi2): 7.028e-06, MSE(pi3): 8.872e-04\n",
      "Epoch 465300, Train loss: 2.391e+02, Test loss: 1.110e+03, MSE(e): 4.279e-06, MSE(pi1): 8.820e-03, MSE(pi2): 1.383e-06, MSE(pi3): 1.081e-03\n",
      "Epoch 465400, Train loss: 2.735e+02, Test loss: 1.195e+03, MSE(e): 4.155e-06, MSE(pi1): 1.366e-02, MSE(pi2): 1.011e-06, MSE(pi3): 9.537e-04\n",
      "Epoch 465500, Train loss: 1.640e+02, Test loss: 1.046e+03, MSE(e): 3.527e-06, MSE(pi1): 3.435e-03, MSE(pi2): 1.574e-06, MSE(pi3): 9.441e-04\n",
      "Epoch 465600, Train loss: 6.015e+02, Test loss: 1.487e+03, MSE(e): 2.804e-05, MSE(pi1): 2.149e-02, MSE(pi2): 1.086e-05, MSE(pi3): 1.062e-03\n",
      "Epoch 465700, Train loss: 1.624e+02, Test loss: 1.023e+03, MSE(e): 1.701e-06, MSE(pi1): 5.065e-03, MSE(pi2): 6.373e-07, MSE(pi3): 9.477e-04\n",
      "Epoch 465800, Train loss: 3.788e+02, Test loss: 1.101e+03, MSE(e): 9.520e-06, MSE(pi1): 1.911e-02, MSE(pi2): 3.131e-06, MSE(pi3): 9.252e-04\n",
      "Epoch 465900, Train loss: 1.421e+02, Test loss: 9.893e+02, MSE(e): 1.470e-06, MSE(pi1): 3.223e-03, MSE(pi2): 7.025e-07, MSE(pi3): 9.515e-04\n",
      "Epoch 466000, Train loss: 1.671e+02, Test loss: 9.658e+02, MSE(e): 1.905e-06, MSE(pi1): 5.888e-03, MSE(pi2): 8.225e-07, MSE(pi3): 8.920e-04\n",
      "Epoch 466100, Train loss: 2.274e+02, Test loss: 1.071e+03, MSE(e): 3.115e-06, MSE(pi1): 1.044e-02, MSE(pi2): 7.946e-07, MSE(pi3): 9.187e-04\n",
      "Epoch 466200, Train loss: 3.223e+02, Test loss: 1.042e+03, MSE(e): 1.782e-05, MSE(pi1): 4.028e-03, MSE(pi2): 8.928e-06, MSE(pi3): 1.038e-03\n",
      "Epoch 466300, Train loss: 1.752e+02, Test loss: 1.041e+03, MSE(e): 2.575e-06, MSE(pi1): 5.347e-03, MSE(pi2): 1.090e-06, MSE(pi3): 9.598e-04\n",
      "Epoch 466400, Train loss: 1.960e+02, Test loss: 1.059e+03, MSE(e): 2.438e-06, MSE(pi1): 7.111e-03, MSE(pi2): 7.797e-07, MSE(pi3): 1.005e-03\n",
      "Epoch 466500, Train loss: 2.809e+02, Test loss: 1.232e+03, MSE(e): 1.253e-05, MSE(pi1): 5.044e-03, MSE(pi2): 5.999e-06, MSE(pi3): 1.052e-03\n",
      "Epoch 466600, Train loss: 1.873e+03, Test loss: 3.276e+03, MSE(e): 1.423e-04, MSE(pi1): 2.941e-02, MSE(pi2): 6.687e-05, MSE(pi3): 1.566e-03\n",
      "Epoch 466700, Train loss: 2.553e+02, Test loss: 1.119e+03, MSE(e): 3.761e-06, MSE(pi1): 1.316e-02, MSE(pi2): 8.374e-07, MSE(pi3): 8.609e-04\n",
      "Epoch 466800, Train loss: 4.771e+02, Test loss: 1.353e+03, MSE(e): 1.115e-05, MSE(pi1): 2.575e-02, MSE(pi2): 3.025e-06, MSE(pi3): 1.080e-03\n",
      "Epoch 466900, Train loss: 2.090e+02, Test loss: 1.137e+03, MSE(e): 3.274e-06, MSE(pi1): 7.236e-03, MSE(pi2): 1.231e-06, MSE(pi3): 1.039e-03\n",
      "Epoch 467000, Train loss: 1.530e+02, Test loss: 9.664e+02, MSE(e): 1.512e-06, MSE(pi1): 4.407e-03, MSE(pi2): 7.358e-07, MSE(pi3): 9.385e-04\n",
      "Epoch 467100, Train loss: 2.388e+02, Test loss: 1.159e+03, MSE(e): 6.086e-06, MSE(pi1): 8.144e-03, MSE(pi2): 2.625e-06, MSE(pi3): 9.645e-04\n",
      "Epoch 467200, Train loss: 3.290e+02, Test loss: 1.073e+03, MSE(e): 1.677e-05, MSE(pi1): 7.342e-03, MSE(pi2): 8.543e-06, MSE(pi3): 8.790e-04\n",
      "Epoch 467300, Train loss: 4.126e+02, Test loss: 1.692e+03, MSE(e): 1.715e-05, MSE(pi1): 1.328e-02, MSE(pi2): 8.092e-06, MSE(pi3): 1.084e-03\n",
      "Epoch 467400, Train loss: 1.440e+02, Test loss: 1.000e+03, MSE(e): 1.240e-06, MSE(pi1): 3.840e-03, MSE(pi2): 5.796e-07, MSE(pi3): 9.316e-04\n",
      "Epoch 467500, Train loss: 1.954e+02, Test loss: 1.134e+03, MSE(e): 2.404e-06, MSE(pi1): 7.013e-03, MSE(pi2): 8.383e-07, MSE(pi3): 1.012e-03\n",
      "Epoch 467600, Train loss: 1.556e+02, Test loss: 1.081e+03, MSE(e): 1.388e-06, MSE(pi1): 5.124e-03, MSE(pi2): 6.452e-07, MSE(pi3): 9.045e-04\n",
      "Epoch 467700, Train loss: 5.051e+02, Test loss: 1.609e+03, MSE(e): 2.039e-05, MSE(pi1): 1.761e-02, MSE(pi2): 8.474e-06, MSE(pi3): 1.251e-03\n",
      "Epoch 467800, Train loss: 3.491e+02, Test loss: 1.129e+03, MSE(e): 7.592e-06, MSE(pi1): 1.707e-02, MSE(pi2): 2.178e-06, MSE(pi3): 1.025e-03\n",
      "Epoch 467900, Train loss: 2.410e+02, Test loss: 1.012e+03, MSE(e): 7.527e-06, MSE(pi1): 6.620e-03, MSE(pi2): 3.226e-06, MSE(pi3): 9.951e-04\n",
      "Epoch 468000, Train loss: 3.554e+02, Test loss: 1.146e+03, MSE(e): 2.083e-05, MSE(pi1): 5.327e-03, MSE(pi2): 8.798e-06, MSE(pi3): 9.387e-04\n",
      "Epoch 468100, Train loss: 1.951e+02, Test loss: 9.156e+02, MSE(e): 6.724e-06, MSE(pi1): 3.461e-03, MSE(pi2): 3.040e-06, MSE(pi3): 9.325e-04\n",
      "Epoch 468200, Train loss: 3.550e+02, Test loss: 1.426e+03, MSE(e): 8.224e-06, MSE(pi1): 1.592e-02, MSE(pi2): 2.982e-06, MSE(pi3): 1.136e-03\n",
      "Epoch 468300, Train loss: 2.538e+02, Test loss: 1.125e+03, MSE(e): 3.822e-06, MSE(pi1): 1.144e-02, MSE(pi2): 1.027e-06, MSE(pi3): 1.011e-03\n",
      "Epoch 468400, Train loss: 1.666e+02, Test loss: 9.743e+02, MSE(e): 1.706e-06, MSE(pi1): 4.808e-03, MSE(pi2): 6.147e-07, MSE(pi3): 1.014e-03\n",
      "Epoch 468500, Train loss: 4.775e+02, Test loss: 1.499e+03, MSE(e): 1.277e-05, MSE(pi1): 2.546e-02, MSE(pi2): 3.806e-06, MSE(pi3): 9.519e-04\n",
      "Epoch 468600, Train loss: 2.304e+02, Test loss: 1.037e+03, MSE(e): 3.894e-06, MSE(pi1): 1.024e-02, MSE(pi2): 1.527e-06, MSE(pi3): 8.902e-04\n",
      "Epoch 468700, Train loss: 2.211e+02, Test loss: 1.210e+03, MSE(e): 6.735e-06, MSE(pi1): 5.025e-03, MSE(pi2): 3.136e-06, MSE(pi3): 1.035e-03\n",
      "Epoch 468800, Train loss: 4.341e+02, Test loss: 1.152e+03, MSE(e): 2.541e-05, MSE(pi1): 9.149e-03, MSE(pi2): 1.239e-05, MSE(pi3): 8.848e-04\n",
      "Epoch 468900, Train loss: 2.084e+02, Test loss: 1.059e+03, MSE(e): 2.923e-06, MSE(pi1): 7.582e-03, MSE(pi2): 8.234e-07, MSE(pi3): 1.033e-03\n",
      "Epoch 469000, Train loss: 2.756e+02, Test loss: 1.154e+03, MSE(e): 6.179e-06, MSE(pi1): 9.959e-03, MSE(pi2): 1.874e-06, MSE(pi3): 1.142e-03\n",
      "Epoch 469100, Train loss: 2.321e+02, Test loss: 9.444e+02, MSE(e): 8.666e-06, MSE(pi1): 5.491e-03, MSE(pi2): 4.396e-06, MSE(pi3): 9.050e-04\n",
      "Epoch 469200, Train loss: 1.609e+02, Test loss: 9.633e+02, MSE(e): 1.631e-06, MSE(pi1): 4.432e-03, MSE(pi2): 6.305e-07, MSE(pi3): 1.002e-03\n",
      "Epoch 469300, Train loss: 1.576e+02, Test loss: 1.013e+03, MSE(e): 1.644e-06, MSE(pi1): 4.858e-03, MSE(pi2): 5.983e-07, MSE(pi3): 9.258e-04\n",
      "Epoch 469400, Train loss: 2.769e+02, Test loss: 1.259e+03, MSE(e): 1.050e-05, MSE(pi1): 6.669e-03, MSE(pi2): 5.238e-06, MSE(pi3): 1.052e-03\n",
      "Epoch 469500, Train loss: 1.740e+02, Test loss: 1.053e+03, MSE(e): 2.598e-06, MSE(pi1): 5.197e-03, MSE(pi2): 9.780e-07, MSE(pi3): 9.608e-04\n",
      "Epoch 469600, Train loss: 1.454e+02, Test loss: 9.987e+02, MSE(e): 1.468e-06, MSE(pi1): 3.632e-03, MSE(pi2): 6.778e-07, MSE(pi3): 9.435e-04\n",
      "Epoch 469700, Train loss: 1.462e+02, Test loss: 9.279e+02, MSE(e): 1.791e-06, MSE(pi1): 3.442e-03, MSE(pi2): 8.667e-07, MSE(pi3): 9.391e-04\n",
      "Epoch 469800, Train loss: 2.312e+02, Test loss: 1.088e+03, MSE(e): 4.059e-06, MSE(pi1): 8.727e-03, MSE(pi2): 1.146e-06, MSE(pi3): 1.033e-03\n",
      "Epoch 469900, Train loss: 1.486e+03, Test loss: 2.415e+03, MSE(e): 1.126e-04, MSE(pi1): 2.669e-02, MSE(pi2): 5.130e-05, MSE(pi3): 9.259e-04\n",
      "Epoch 470000, Train loss: 3.282e+02, Test loss: 1.137e+03, MSE(e): 6.114e-06, MSE(pi1): 1.759e-02, MSE(pi2): 1.832e-06, MSE(pi3): 9.117e-04\n",
      "Epoch 470100, Train loss: 2.691e+02, Test loss: 1.091e+03, MSE(e): 4.594e-06, MSE(pi1): 1.378e-02, MSE(pi2): 1.248e-06, MSE(pi3): 8.540e-04\n",
      "Epoch 470200, Train loss: 1.919e+02, Test loss: 1.013e+03, MSE(e): 2.333e-06, MSE(pi1): 7.534e-03, MSE(pi2): 7.327e-07, MSE(pi3): 9.321e-04\n",
      "Epoch 470300, Train loss: 1.853e+02, Test loss: 1.024e+03, MSE(e): 2.896e-06, MSE(pi1): 5.651e-03, MSE(pi2): 9.039e-07, MSE(pi3): 9.980e-04\n",
      "Epoch 470400, Train loss: 1.980e+02, Test loss: 1.126e+03, MSE(e): 3.694e-06, MSE(pi1): 5.808e-03, MSE(pi2): 1.509e-06, MSE(pi3): 1.030e-03\n",
      "Epoch 470500, Train loss: 1.190e+03, Test loss: 2.918e+03, MSE(e): 1.010e-04, MSE(pi1): 7.114e-03, MSE(pi2): 4.947e-05, MSE(pi3): 1.096e-03\n",
      "Epoch 470600, Train loss: 3.885e+02, Test loss: 1.303e+03, MSE(e): 1.019e-05, MSE(pi1): 1.911e-02, MSE(pi2): 3.843e-06, MSE(pi3): 9.553e-04\n",
      "Epoch 470700, Train loss: 1.697e+02, Test loss: 9.347e+02, MSE(e): 3.233e-06, MSE(pi1): 4.499e-03, MSE(pi2): 1.590e-06, MSE(pi3): 9.233e-04\n",
      "Epoch 470800, Train loss: 2.847e+02, Test loss: 1.204e+03, MSE(e): 5.250e-06, MSE(pi1): 1.207e-02, MSE(pi2): 1.514e-06, MSE(pi3): 1.115e-03\n",
      "Epoch 470900, Train loss: 2.279e+02, Test loss: 9.859e+02, MSE(e): 4.227e-06, MSE(pi1): 9.974e-03, MSE(pi2): 1.299e-06, MSE(pi3): 8.590e-04\n",
      "Epoch 471000, Train loss: 1.623e+02, Test loss: 9.276e+02, MSE(e): 2.717e-06, MSE(pi1): 4.144e-03, MSE(pi2): 1.402e-06, MSE(pi3): 9.372e-04\n",
      "Epoch 471100, Train loss: 2.444e+02, Test loss: 1.185e+03, MSE(e): 1.030e-05, MSE(pi1): 4.822e-03, MSE(pi2): 4.589e-06, MSE(pi3): 9.318e-04\n",
      "Epoch 471200, Train loss: 5.934e+02, Test loss: 1.838e+03, MSE(e): 4.393e-05, MSE(pi1): 5.387e-03, MSE(pi2): 2.109e-05, MSE(pi3): 1.002e-03\n",
      "Epoch 471300, Train loss: 1.081e+03, Test loss: 1.918e+03, MSE(e): 6.933e-05, MSE(pi1): 2.760e-02, MSE(pi2): 2.894e-05, MSE(pi3): 1.115e-03\n",
      "Epoch 471400, Train loss: 2.259e+03, Test loss: 2.755e+03, MSE(e): 1.669e-04, MSE(pi1): 4.939e-02, MSE(pi2): 8.015e-05, MSE(pi3): 9.614e-04\n",
      "Epoch 471500, Train loss: 2.015e+02, Test loss: 1.197e+03, MSE(e): 7.080e-06, MSE(pi1): 3.683e-03, MSE(pi2): 3.227e-06, MSE(pi3): 9.382e-04\n",
      "Epoch 471600, Train loss: 1.706e+02, Test loss: 1.037e+03, MSE(e): 1.726e-06, MSE(pi1): 5.722e-03, MSE(pi2): 6.200e-07, MSE(pi3): 9.616e-04\n",
      "Epoch 471700, Train loss: 2.528e+03, Test loss: 3.245e+03, MSE(e): 2.304e-04, MSE(pi1): 1.383e-02, MSE(pi2): 1.125e-04, MSE(pi3): 8.519e-04\n",
      "Epoch 471800, Train loss: 3.324e+02, Test loss: 1.196e+03, MSE(e): 6.037e-06, MSE(pi1): 1.859e-02, MSE(pi2): 1.365e-06, MSE(pi3): 8.610e-04\n",
      "Epoch 471900, Train loss: 1.701e+02, Test loss: 9.860e+02, MSE(e): 2.196e-06, MSE(pi1): 4.937e-03, MSE(pi2): 7.899e-07, MSE(pi3): 9.879e-04\n",
      "Epoch 472000, Train loss: 1.834e+02, Test loss: 9.266e+02, MSE(e): 5.035e-06, MSE(pi1): 4.045e-03, MSE(pi2): 2.570e-06, MSE(pi3): 9.259e-04\n",
      "Epoch 472100, Train loss: 1.600e+02, Test loss: 9.705e+02, MSE(e): 1.686e-06, MSE(pi1): 4.860e-03, MSE(pi2): 7.027e-07, MSE(pi3): 9.456e-04\n",
      "Epoch 472200, Train loss: 6.520e+02, Test loss: 1.700e+03, MSE(e): 4.922e-05, MSE(pi1): 6.469e-03, MSE(pi2): 2.204e-05, MSE(pi3): 9.500e-04\n",
      "Epoch 472300, Train loss: 2.117e+02, Test loss: 1.111e+03, MSE(e): 3.247e-06, MSE(pi1): 7.589e-03, MSE(pi2): 1.175e-06, MSE(pi3): 1.034e-03\n",
      "Epoch 472400, Train loss: 2.680e+02, Test loss: 1.092e+03, MSE(e): 5.776e-06, MSE(pi1): 1.103e-02, MSE(pi2): 2.008e-06, MSE(pi3): 9.995e-04\n",
      "Epoch 472500, Train loss: 3.904e+02, Test loss: 1.470e+03, MSE(e): 1.334e-05, MSE(pi1): 1.482e-02, MSE(pi2): 5.186e-06, MSE(pi3): 1.088e-03\n",
      "Epoch 472600, Train loss: 3.113e+02, Test loss: 1.141e+03, MSE(e): 1.000e-05, MSE(pi1): 1.076e-02, MSE(pi2): 3.519e-06, MSE(pi3): 1.036e-03\n",
      "Epoch 472700, Train loss: 4.319e+02, Test loss: 1.473e+03, MSE(e): 1.296e-05, MSE(pi1): 2.121e-02, MSE(pi2): 4.285e-06, MSE(pi3): 9.023e-04\n",
      "Epoch 472800, Train loss: 1.653e+02, Test loss: 9.400e+02, MSE(e): 2.354e-06, MSE(pi1): 4.636e-03, MSE(pi2): 9.842e-07, MSE(pi3): 9.537e-04\n",
      "Epoch 472900, Train loss: 3.274e+02, Test loss: 1.040e+03, MSE(e): 8.706e-06, MSE(pi1): 1.428e-02, MSE(pi2): 3.000e-06, MSE(pi3): 9.760e-04\n",
      "Epoch 473000, Train loss: 1.596e+02, Test loss: 1.024e+03, MSE(e): 2.182e-06, MSE(pi1): 4.514e-03, MSE(pi2): 9.266e-07, MSE(pi3): 9.266e-04\n",
      "Epoch 473100, Train loss: 4.905e+02, Test loss: 1.242e+03, MSE(e): 1.814e-05, MSE(pi1): 2.167e-02, MSE(pi2): 6.990e-06, MSE(pi3): 9.228e-04\n",
      "Epoch 473200, Train loss: 3.874e+02, Test loss: 1.218e+03, MSE(e): 1.814e-05, MSE(pi1): 1.170e-02, MSE(pi2): 7.846e-06, MSE(pi3): 8.902e-04\n",
      "Epoch 473300, Train loss: 2.772e+02, Test loss: 1.271e+03, MSE(e): 1.084e-05, MSE(pi1): 7.720e-03, MSE(pi2): 4.147e-06, MSE(pi3): 9.159e-04\n",
      "Epoch 473400, Train loss: 4.581e+02, Test loss: 1.552e+03, MSE(e): 2.477e-05, MSE(pi1): 1.127e-02, MSE(pi2): 1.043e-05, MSE(pi3): 9.772e-04\n",
      "Epoch 473500, Train loss: 2.560e+02, Test loss: 9.619e+02, MSE(e): 1.206e-05, MSE(pi1): 4.144e-03, MSE(pi2): 5.239e-06, MSE(pi3): 9.402e-04\n",
      "Epoch 473600, Train loss: 5.565e+02, Test loss: 1.114e+03, MSE(e): 2.374e-05, MSE(pi1): 2.327e-02, MSE(pi2): 9.337e-06, MSE(pi3): 8.638e-04\n",
      "Epoch 473700, Train loss: 1.639e+02, Test loss: 9.754e+02, MSE(e): 1.892e-06, MSE(pi1): 5.143e-03, MSE(pi2): 7.636e-07, MSE(pi3): 9.353e-04\n",
      "Epoch 473800, Train loss: 1.626e+02, Test loss: 9.748e+02, MSE(e): 1.607e-06, MSE(pi1): 5.721e-03, MSE(pi2): 5.564e-07, MSE(pi3): 8.930e-04\n",
      "Epoch 473900, Train loss: 5.800e+02, Test loss: 1.792e+03, MSE(e): 3.112e-05, MSE(pi1): 1.590e-02, MSE(pi2): 1.383e-05, MSE(pi3): 1.098e-03\n",
      "Epoch 474000, Train loss: 2.717e+02, Test loss: 1.195e+03, MSE(e): 8.696e-06, MSE(pi1): 8.798e-03, MSE(pi2): 4.520e-06, MSE(pi3): 9.676e-04\n",
      "Epoch 474100, Train loss: 2.119e+02, Test loss: 9.959e+02, MSE(e): 3.692e-06, MSE(pi1): 7.924e-03, MSE(pi2): 1.209e-06, MSE(pi3): 9.575e-04\n",
      "Epoch 474200, Train loss: 2.253e+02, Test loss: 1.029e+03, MSE(e): 3.637e-06, MSE(pi1): 1.019e-02, MSE(pi2): 1.414e-06, MSE(pi3): 8.712e-04\n",
      "Epoch 474300, Train loss: 1.630e+02, Test loss: 9.621e+02, MSE(e): 2.473e-06, MSE(pi1): 3.660e-03, MSE(pi2): 1.055e-06, MSE(pi3): 1.017e-03\n",
      "Epoch 474400, Train loss: 1.555e+02, Test loss: 1.036e+03, MSE(e): 2.349e-06, MSE(pi1): 3.579e-03, MSE(pi2): 1.114e-06, MSE(pi3): 9.622e-04\n",
      "Epoch 474500, Train loss: 2.979e+02, Test loss: 1.325e+03, MSE(e): 7.839e-06, MSE(pi1): 1.142e-02, MSE(pi2): 3.401e-06, MSE(pi3): 1.053e-03\n",
      "Epoch 474600, Train loss: 3.629e+02, Test loss: 1.186e+03, MSE(e): 1.308e-05, MSE(pi1): 1.336e-02, MSE(pi2): 5.142e-06, MSE(pi3): 9.844e-04\n",
      "Epoch 474700, Train loss: 2.567e+02, Test loss: 1.202e+03, MSE(e): 6.118e-06, MSE(pi1): 1.030e-02, MSE(pi2): 2.031e-06, MSE(pi3): 9.248e-04\n",
      "Epoch 474800, Train loss: 1.542e+02, Test loss: 9.475e+02, MSE(e): 1.784e-06, MSE(pi1): 4.237e-03, MSE(pi2): 8.251e-07, MSE(pi3): 9.394e-04\n",
      "Epoch 474900, Train loss: 1.454e+02, Test loss: 9.285e+02, MSE(e): 1.564e-06, MSE(pi1): 3.834e-03, MSE(pi2): 8.095e-07, MSE(pi3): 9.142e-04\n",
      "Epoch 475000, Train loss: 2.488e+02, Test loss: 9.210e+02, MSE(e): 1.142e-05, MSE(pi1): 4.217e-03, MSE(pi2): 5.638e-06, MSE(pi3): 9.243e-04\n",
      "Epoch 475100, Train loss: 1.214e+03, Test loss: 3.026e+03, MSE(e): 9.591e-05, MSE(pi1): 1.540e-02, MSE(pi2): 3.712e-05, MSE(pi3): 1.006e-03\n",
      "Epoch 475200, Train loss: 2.287e+03, Test loss: 4.766e+03, MSE(e): 2.046e-04, MSE(pi1): 1.194e-02, MSE(pi2): 1.004e-04, MSE(pi3): 1.216e-03\n",
      "Epoch 475300, Train loss: 2.112e+02, Test loss: 1.051e+03, MSE(e): 2.907e-06, MSE(pi1): 9.340e-03, MSE(pi2): 9.279e-07, MSE(pi3): 8.872e-04\n",
      "Epoch 475400, Train loss: 1.765e+03, Test loss: 2.999e+03, MSE(e): 1.615e-04, MSE(pi1): 4.059e-03, MSE(pi2): 7.603e-05, MSE(pi3): 1.092e-03\n",
      "Epoch 475500, Train loss: 2.033e+02, Test loss: 1.000e+03, MSE(e): 3.781e-06, MSE(pi1): 6.644e-03, MSE(pi2): 1.565e-06, MSE(pi3): 9.906e-04\n",
      "Epoch 475600, Train loss: 1.695e+02, Test loss: 1.041e+03, MSE(e): 1.673e-06, MSE(pi1): 6.211e-03, MSE(pi2): 6.277e-07, MSE(pi3): 9.067e-04\n",
      "Epoch 475700, Train loss: 3.472e+02, Test loss: 1.467e+03, MSE(e): 1.300e-05, MSE(pi1): 1.253e-02, MSE(pi2): 4.576e-06, MSE(pi3): 9.202e-04\n",
      "Epoch 475800, Train loss: 8.003e+02, Test loss: 2.030e+03, MSE(e): 5.565e-05, MSE(pi1): 1.258e-02, MSE(pi2): 2.409e-05, MSE(pi3): 1.180e-03\n",
      "Epoch 475900, Train loss: 2.749e+02, Test loss: 9.766e+02, MSE(e): 1.194e-05, MSE(pi1): 5.941e-03, MSE(pi2): 4.544e-06, MSE(pi3): 9.613e-04\n",
      "Epoch 476000, Train loss: 3.291e+02, Test loss: 1.347e+03, MSE(e): 1.650e-05, MSE(pi1): 6.487e-03, MSE(pi2): 7.677e-06, MSE(pi3): 9.929e-04\n",
      "Epoch 476100, Train loss: 1.984e+02, Test loss: 9.389e+02, MSE(e): 4.922e-06, MSE(pi1): 5.233e-03, MSE(pi2): 2.071e-06, MSE(pi3): 9.688e-04\n",
      "Epoch 476200, Train loss: 3.785e+02, Test loss: 1.013e+03, MSE(e): 1.139e-05, MSE(pi1): 1.558e-02, MSE(pi2): 4.443e-06, MSE(pi3): 1.088e-03\n",
      "Epoch 476300, Train loss: 2.120e+03, Test loss: 2.862e+03, MSE(e): 1.975e-04, MSE(pi1): 5.933e-03, MSE(pi2): 9.413e-05, MSE(pi3): 8.480e-04\n",
      "Epoch 476400, Train loss: 4.237e+02, Test loss: 1.523e+03, MSE(e): 2.400e-05, MSE(pi1): 9.222e-03, MSE(pi2): 1.051e-05, MSE(pi3): 9.145e-04\n",
      "Epoch 476500, Train loss: 4.840e+02, Test loss: 1.780e+03, MSE(e): 3.481e-05, MSE(pi1): 3.830e-03, MSE(pi2): 1.671e-05, MSE(pi3): 9.759e-04\n",
      "Epoch 476600, Train loss: 5.370e+02, Test loss: 1.628e+03, MSE(e): 1.622e-05, MSE(pi1): 2.428e-02, MSE(pi2): 6.166e-06, MSE(pi3): 1.319e-03\n",
      "Epoch 476700, Train loss: 1.590e+02, Test loss: 9.826e+02, MSE(e): 1.488e-06, MSE(pi1): 5.191e-03, MSE(pi2): 5.750e-07, MSE(pi3): 9.223e-04\n",
      "Epoch 476800, Train loss: 1.475e+02, Test loss: 9.304e+02, MSE(e): 1.600e-06, MSE(pi1): 4.129e-03, MSE(pi2): 8.016e-07, MSE(pi3): 9.016e-04\n",
      "Epoch 476900, Train loss: 1.663e+02, Test loss: 1.010e+03, MSE(e): 1.669e-06, MSE(pi1): 4.825e-03, MSE(pi2): 6.079e-07, MSE(pi3): 1.013e-03\n",
      "Epoch 477000, Train loss: 2.310e+02, Test loss: 1.171e+03, MSE(e): 3.996e-06, MSE(pi1): 9.544e-03, MSE(pi2): 1.301e-06, MSE(pi3): 9.563e-04\n",
      "Epoch 477100, Train loss: 1.395e+02, Test loss: 9.801e+02, MSE(e): 1.183e-06, MSE(pi1): 3.372e-03, MSE(pi2): 5.663e-07, MSE(pi3): 9.395e-04\n",
      "Epoch 477200, Train loss: 2.616e+02, Test loss: 1.120e+03, MSE(e): 4.091e-06, MSE(pi1): 1.126e-02, MSE(pi2): 1.156e-06, MSE(pi3): 1.081e-03\n",
      "Epoch 477300, Train loss: 1.634e+02, Test loss: 1.015e+03, MSE(e): 1.682e-06, MSE(pi1): 4.772e-03, MSE(pi2): 6.428e-07, MSE(pi3): 9.883e-04\n",
      "Epoch 477400, Train loss: 1.483e+02, Test loss: 1.009e+03, MSE(e): 1.245e-06, MSE(pi1): 4.342e-03, MSE(pi2): 5.325e-07, MSE(pi3): 9.242e-04\n",
      "Epoch 477500, Train loss: 2.193e+02, Test loss: 1.047e+03, MSE(e): 3.546e-06, MSE(pi1): 8.649e-03, MSE(pi2): 1.165e-06, MSE(pi3): 9.735e-04\n",
      "Epoch 477600, Train loss: 1.177e+03, Test loss: 1.379e+03, MSE(e): 9.793e-05, MSE(pi1): 1.015e-02, MSE(pi2): 4.394e-05, MSE(pi3): 9.626e-04\n",
      "Epoch 477700, Train loss: 6.819e+02, Test loss: 1.414e+03, MSE(e): 5.001e-05, MSE(pi1): 9.817e-03, MSE(pi2): 2.631e-05, MSE(pi3): 8.360e-04\n",
      "Epoch 477800, Train loss: 2.260e+02, Test loss: 9.632e+02, MSE(e): 8.213e-06, MSE(pi1): 4.731e-03, MSE(pi2): 3.562e-06, MSE(pi3): 9.651e-04\n",
      "Epoch 477900, Train loss: 2.360e+02, Test loss: 1.089e+03, MSE(e): 4.487e-06, MSE(pi1): 9.671e-03, MSE(pi2): 1.431e-06, MSE(pi3): 9.440e-04\n",
      "Epoch 478000, Train loss: 5.036e+02, Test loss: 1.131e+03, MSE(e): 2.989e-05, MSE(pi1): 1.203e-02, MSE(pi2): 1.479e-05, MSE(pi3): 8.440e-04\n",
      "Epoch 478100, Train loss: 1.882e+02, Test loss: 9.426e+02, MSE(e): 5.147e-06, MSE(pi1): 4.665e-03, MSE(pi2): 2.021e-06, MSE(pi3): 9.010e-04\n",
      "Epoch 478200, Train loss: 2.365e+02, Test loss: 9.866e+02, MSE(e): 6.840e-06, MSE(pi1): 8.329e-03, MSE(pi2): 3.165e-06, MSE(pi3): 8.483e-04\n",
      "Epoch 478300, Train loss: 3.080e+02, Test loss: 9.688e+02, MSE(e): 1.527e-05, MSE(pi1): 6.530e-03, MSE(pi2): 7.588e-06, MSE(pi3): 9.006e-04\n",
      "Epoch 478400, Train loss: 4.635e+02, Test loss: 1.193e+03, MSE(e): 1.973e-05, MSE(pi1): 1.801e-02, MSE(pi2): 8.994e-06, MSE(pi3): 8.611e-04\n",
      "Epoch 478500, Train loss: 1.969e+02, Test loss: 1.046e+03, MSE(e): 4.486e-06, MSE(pi1): 6.159e-03, MSE(pi2): 2.053e-06, MSE(pi3): 9.049e-04\n",
      "Epoch 478600, Train loss: 1.870e+03, Test loss: 3.430e+03, MSE(e): 1.717e-04, MSE(pi1): 4.010e-03, MSE(pi2): 8.157e-05, MSE(pi3): 1.120e-03\n",
      "Epoch 478700, Train loss: 7.298e+02, Test loss: 1.528e+03, MSE(e): 3.516e-05, MSE(pi1): 2.975e-02, MSE(pi2): 1.451e-05, MSE(pi3): 8.070e-04\n",
      "Epoch 478800, Train loss: 7.938e+02, Test loss: 2.343e+03, MSE(e): 6.408e-05, MSE(pi1): 4.636e-03, MSE(pi2): 2.900e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 478900, Train loss: 4.654e+02, Test loss: 1.129e+03, MSE(e): 2.344e-05, MSE(pi1): 1.320e-02, MSE(pi2): 1.085e-05, MSE(pi3): 9.899e-04\n",
      "Epoch 479000, Train loss: 2.307e+02, Test loss: 9.432e+02, MSE(e): 7.882e-06, MSE(pi1): 5.352e-03, MSE(pi2): 3.257e-06, MSE(pi3): 9.838e-04\n",
      "Epoch 479100, Train loss: 1.135e+03, Test loss: 1.749e+03, MSE(e): 8.901e-05, MSE(pi1): 1.548e-02, MSE(pi2): 4.371e-05, MSE(pi3): 9.033e-04\n",
      "Epoch 479200, Train loss: 5.928e+02, Test loss: 1.714e+03, MSE(e): 2.889e-05, MSE(pi1): 2.019e-02, MSE(pi2): 1.093e-05, MSE(pi3): 1.020e-03\n",
      "Epoch 479300, Train loss: 3.005e+02, Test loss: 1.172e+03, MSE(e): 4.945e-06, MSE(pi1): 1.403e-02, MSE(pi2): 1.141e-06, MSE(pi3): 1.108e-03\n",
      "Epoch 479400, Train loss: 1.924e+02, Test loss: 1.098e+03, MSE(e): 2.463e-06, MSE(pi1): 7.786e-03, MSE(pi2): 7.143e-07, MSE(pi3): 8.992e-04\n",
      "Epoch 479500, Train loss: 5.299e+02, Test loss: 1.668e+03, MSE(e): 3.070e-05, MSE(pi1): 1.136e-02, MSE(pi2): 1.458e-05, MSE(pi3): 1.093e-03\n",
      "Epoch 479600, Train loss: 1.858e+02, Test loss: 9.369e+02, MSE(e): 5.455e-06, MSE(pi1): 3.702e-03, MSE(pi2): 2.473e-06, MSE(pi3): 9.419e-04\n",
      "Epoch 479700, Train loss: 1.448e+02, Test loss: 9.917e+02, MSE(e): 1.202e-06, MSE(pi1): 4.320e-03, MSE(pi2): 5.081e-07, MSE(pi3): 8.954e-04\n",
      "Epoch 479800, Train loss: 1.576e+02, Test loss: 1.023e+03, MSE(e): 2.031e-06, MSE(pi1): 4.359e-03, MSE(pi2): 7.237e-07, MSE(pi3): 9.367e-04\n",
      "Epoch 479900, Train loss: 2.687e+02, Test loss: 1.192e+03, MSE(e): 4.125e-06, MSE(pi1): 1.162e-02, MSE(pi2): 1.240e-06, MSE(pi3): 1.113e-03\n",
      "Epoch 480000, Train loss: 2.895e+02, Test loss: 1.027e+03, MSE(e): 1.081e-05, MSE(pi1): 9.545e-03, MSE(pi2): 5.362e-06, MSE(pi3): 8.601e-04\n",
      "Epoch 480100, Train loss: 6.698e+02, Test loss: 1.271e+03, MSE(e): 4.425e-05, MSE(pi1): 1.396e-02, MSE(pi2): 2.192e-05, MSE(pi3): 8.765e-04\n",
      "Epoch 480200, Train loss: 2.375e+02, Test loss: 1.171e+03, MSE(e): 6.582e-06, MSE(pi1): 6.984e-03, MSE(pi2): 3.147e-06, MSE(pi3): 1.018e-03\n",
      "Epoch 480300, Train loss: 2.658e+02, Test loss: 1.119e+03, MSE(e): 5.551e-06, MSE(pi1): 1.130e-02, MSE(pi2): 1.775e-06, MSE(pi3): 9.727e-04\n",
      "Epoch 480400, Train loss: 1.456e+02, Test loss: 1.006e+03, MSE(e): 1.484e-06, MSE(pi1): 3.899e-03, MSE(pi2): 6.610e-07, MSE(pi3): 9.173e-04\n",
      "Epoch 480500, Train loss: 1.664e+02, Test loss: 1.046e+03, MSE(e): 2.251e-06, MSE(pi1): 5.226e-03, MSE(pi2): 8.682e-07, MSE(pi3): 9.166e-04\n",
      "Epoch 480600, Train loss: 3.095e+02, Test loss: 1.153e+03, MSE(e): 6.953e-06, MSE(pi1): 1.523e-02, MSE(pi2): 3.091e-06, MSE(pi3): 8.766e-04\n",
      "Epoch 480700, Train loss: 6.124e+02, Test loss: 1.299e+03, MSE(e): 3.709e-05, MSE(pi1): 1.552e-02, MSE(pi2): 1.683e-05, MSE(pi3): 8.625e-04\n",
      "Epoch 480800, Train loss: 2.962e+02, Test loss: 1.049e+03, MSE(e): 1.263e-05, MSE(pi1): 8.301e-03, MSE(pi2): 5.882e-06, MSE(pi3): 8.686e-04\n",
      "Epoch 480900, Train loss: 1.920e+02, Test loss: 1.053e+03, MSE(e): 2.286e-06, MSE(pi1): 6.792e-03, MSE(pi2): 7.162e-07, MSE(pi3): 1.012e-03\n",
      "Epoch 481000, Train loss: 2.952e+02, Test loss: 1.625e+03, MSE(e): 1.010e-05, MSE(pi1): 1.019e-02, MSE(pi2): 4.149e-06, MSE(pi3): 9.223e-04\n",
      "Epoch 481100, Train loss: 1.737e+03, Test loss: 2.924e+03, MSE(e): 1.429e-04, MSE(pi1): 2.202e-02, MSE(pi2): 6.859e-05, MSE(pi3): 8.740e-04\n",
      "Epoch 481200, Train loss: 4.112e+02, Test loss: 1.150e+03, MSE(e): 9.448e-06, MSE(pi1): 2.248e-02, MSE(pi2): 2.603e-06, MSE(pi3): 9.194e-04\n",
      "Epoch 481300, Train loss: 1.727e+02, Test loss: 9.417e+02, MSE(e): 3.713e-06, MSE(pi1): 4.158e-03, MSE(pi2): 1.839e-06, MSE(pi3): 9.394e-04\n",
      "Epoch 481400, Train loss: 3.634e+03, Test loss: 6.327e+03, MSE(e): 3.376e-04, MSE(pi1): 1.206e-02, MSE(pi2): 1.573e-04, MSE(pi3): 1.372e-03\n",
      "Epoch 481500, Train loss: 2.488e+02, Test loss: 1.171e+03, MSE(e): 3.563e-06, MSE(pi1): 1.047e-02, MSE(pi2): 8.823e-07, MSE(pi3): 1.084e-03\n",
      "Epoch 481600, Train loss: 2.338e+02, Test loss: 1.342e+03, MSE(e): 9.514e-06, MSE(pi1): 4.271e-03, MSE(pi2): 4.741e-06, MSE(pi3): 9.592e-04\n",
      "Epoch 481700, Train loss: 3.097e+02, Test loss: 1.376e+03, MSE(e): 1.677e-05, MSE(pi1): 4.721e-03, MSE(pi2): 7.129e-06, MSE(pi3): 9.475e-04\n",
      "Epoch 481800, Train loss: 1.988e+02, Test loss: 1.358e+03, MSE(e): 2.492e-06, MSE(pi1): 6.804e-03, MSE(pi2): 7.429e-07, MSE(pi3): 1.058e-03\n",
      "Epoch 481900, Train loss: 2.065e+02, Test loss: 1.109e+03, MSE(e): 5.255e-06, MSE(pi1): 5.899e-03, MSE(pi2): 2.229e-06, MSE(pi3): 9.492e-04\n",
      "Epoch 482000, Train loss: 3.450e+02, Test loss: 1.006e+03, MSE(e): 1.193e-05, MSE(pi1): 1.313e-02, MSE(pi2): 4.385e-06, MSE(pi3): 9.439e-04\n",
      "Epoch 482100, Train loss: 2.399e+02, Test loss: 1.176e+03, MSE(e): 5.904e-06, MSE(pi1): 9.167e-03, MSE(pi2): 1.978e-06, MSE(pi3): 8.916e-04\n",
      "Epoch 482200, Train loss: 2.060e+02, Test loss: 1.120e+03, MSE(e): 2.561e-06, MSE(pi1): 9.161e-03, MSE(pi2): 6.910e-07, MSE(pi3): 8.877e-04\n",
      "Epoch 482300, Train loss: 2.110e+02, Test loss: 1.090e+03, MSE(e): 2.919e-06, MSE(pi1): 7.821e-03, MSE(pi2): 8.047e-07, MSE(pi3): 1.036e-03\n",
      "Epoch 482400, Train loss: 1.607e+02, Test loss: 1.052e+03, MSE(e): 1.644e-06, MSE(pi1): 4.783e-03, MSE(pi2): 7.658e-07, MSE(pi3): 9.640e-04\n",
      "Epoch 482500, Train loss: 1.104e+03, Test loss: 2.324e+03, MSE(e): 7.042e-05, MSE(pi1): 3.208e-02, MSE(pi2): 3.405e-05, MSE(pi3): 7.934e-04\n",
      "Epoch 482600, Train loss: 1.729e+02, Test loss: 9.868e+02, MSE(e): 1.816e-06, MSE(pi1): 5.979e-03, MSE(pi2): 6.180e-07, MSE(pi3): 9.500e-04\n",
      "Epoch 482700, Train loss: 1.802e+02, Test loss: 1.223e+03, MSE(e): 4.110e-06, MSE(pi1): 4.078e-03, MSE(pi2): 1.953e-06, MSE(pi3): 9.834e-04\n",
      "Epoch 482800, Train loss: 4.841e+02, Test loss: 1.186e+03, MSE(e): 2.227e-05, MSE(pi1): 1.696e-02, MSE(pi2): 1.069e-05, MSE(pi3): 9.174e-04\n",
      "Epoch 482900, Train loss: 2.469e+02, Test loss: 1.091e+03, MSE(e): 8.195e-06, MSE(pi1): 7.589e-03, MSE(pi2): 3.073e-06, MSE(pi3): 8.904e-04\n",
      "Epoch 483000, Train loss: 8.182e+02, Test loss: 1.502e+03, MSE(e): 5.986e-05, MSE(pi1): 1.017e-02, MSE(pi2): 2.859e-05, MSE(pi3): 1.179e-03\n",
      "Epoch 483100, Train loss: 1.050e+03, Test loss: 1.613e+03, MSE(e): 8.291e-05, MSE(pi1): 1.379e-02, MSE(pi2): 3.967e-05, MSE(pi3): 8.322e-04\n",
      "Epoch 483200, Train loss: 2.779e+02, Test loss: 1.381e+03, MSE(e): 5.371e-06, MSE(pi1): 1.261e-02, MSE(pi2): 1.453e-06, MSE(pi3): 9.816e-04\n",
      "Epoch 483300, Train loss: 4.143e+02, Test loss: 1.397e+03, MSE(e): 2.510e-05, MSE(pi1): 7.284e-03, MSE(pi2): 1.119e-05, MSE(pi3): 9.049e-04\n",
      "Epoch 483400, Train loss: 3.581e+02, Test loss: 1.198e+03, MSE(e): 8.292e-06, MSE(pi1): 1.615e-02, MSE(pi2): 2.862e-06, MSE(pi3): 1.137e-03\n",
      "Epoch 483500, Train loss: 1.758e+02, Test loss: 9.365e+02, MSE(e): 2.603e-06, MSE(pi1): 5.856e-03, MSE(pi2): 1.353e-06, MSE(pi3): 9.116e-04\n",
      "Epoch 483600, Train loss: 2.860e+02, Test loss: 1.123e+03, MSE(e): 4.887e-06, MSE(pi1): 1.463e-02, MSE(pi2): 1.214e-06, MSE(pi3): 9.079e-04\n",
      "Epoch 483700, Train loss: 1.829e+03, Test loss: 2.620e+03, MSE(e): 1.540e-04, MSE(pi1): 2.075e-02, MSE(pi2): 7.488e-05, MSE(pi3): 8.116e-04\n",
      "Epoch 483800, Train loss: 7.496e+02, Test loss: 1.626e+03, MSE(e): 4.560e-05, MSE(pi1): 1.801e-02, MSE(pi2): 1.905e-05, MSE(pi3): 1.135e-03\n",
      "Epoch 483900, Train loss: 1.392e+03, Test loss: 3.570e+03, MSE(e): 1.217e-04, MSE(pi1): 6.828e-03, MSE(pi2): 5.831e-05, MSE(pi3): 1.072e-03\n",
      "Epoch 484000, Train loss: 1.866e+02, Test loss: 1.116e+03, MSE(e): 4.155e-06, MSE(pi1): 4.381e-03, MSE(pi2): 1.891e-06, MSE(pi3): 1.012e-03\n",
      "Epoch 484100, Train loss: 3.461e+02, Test loss: 1.015e+03, MSE(e): 1.329e-05, MSE(pi1): 1.200e-02, MSE(pi2): 5.465e-06, MSE(pi3): 9.322e-04\n",
      "Epoch 484200, Train loss: 2.186e+02, Test loss: 1.146e+03, MSE(e): 5.719e-06, MSE(pi1): 7.110e-03, MSE(pi2): 2.052e-06, MSE(pi3): 9.033e-04\n",
      "Epoch 484300, Train loss: 3.216e+02, Test loss: 1.236e+03, MSE(e): 5.158e-06, MSE(pi1): 1.845e-02, MSE(pi2): 1.146e-06, MSE(pi3): 8.554e-04\n",
      "Epoch 484400, Train loss: 2.817e+02, Test loss: 1.150e+03, MSE(e): 4.758e-06, MSE(pi1): 1.329e-02, MSE(pi2): 1.160e-06, MSE(pi3): 1.011e-03\n",
      "Epoch 484500, Train loss: 2.458e+02, Test loss: 9.788e+02, MSE(e): 8.570e-06, MSE(pi1): 6.866e-03, MSE(pi2): 3.911e-06, MSE(pi3): 9.142e-04\n",
      "Epoch 484600, Train loss: 3.697e+02, Test loss: 1.212e+03, MSE(e): 9.042e-06, MSE(pi1): 1.921e-02, MSE(pi2): 3.393e-06, MSE(pi3): 8.720e-04\n",
      "Epoch 484700, Train loss: 6.336e+02, Test loss: 1.399e+03, MSE(e): 4.702e-05, MSE(pi1): 7.755e-03, MSE(pi2): 2.406e-05, MSE(pi3): 8.580e-04\n",
      "Epoch 484800, Train loss: 1.798e+02, Test loss: 1.000e+03, MSE(e): 2.066e-06, MSE(pi1): 6.635e-03, MSE(pi2): 6.729e-07, MSE(pi3): 9.279e-04\n",
      "Epoch 484900, Train loss: 2.424e+02, Test loss: 1.202e+03, MSE(e): 7.934e-06, MSE(pi1): 5.207e-03, MSE(pi2): 3.564e-06, MSE(pi3): 1.110e-03\n",
      "Epoch 485000, Train loss: 2.666e+02, Test loss: 1.177e+03, MSE(e): 5.530e-06, MSE(pi1): 1.027e-02, MSE(pi2): 2.717e-06, MSE(pi3): 1.086e-03\n",
      "Epoch 485100, Train loss: 1.395e+02, Test loss: 9.308e+02, MSE(e): 1.013e-06, MSE(pi1): 3.968e-03, MSE(pi2): 4.778e-07, MSE(pi3): 8.970e-04\n",
      "Epoch 485200, Train loss: 2.992e+02, Test loss: 1.059e+03, MSE(e): 4.844e-06, MSE(pi1): 1.423e-02, MSE(pi2): 1.194e-06, MSE(pi3): 1.085e-03\n",
      "Epoch 485300, Train loss: 2.689e+02, Test loss: 1.020e+03, MSE(e): 8.207e-06, MSE(pi1): 1.012e-02, MSE(pi2): 3.709e-06, MSE(pi3): 8.564e-04\n",
      "Epoch 485400, Train loss: 5.884e+02, Test loss: 1.949e+03, MSE(e): 4.107e-05, MSE(pi1): 8.149e-03, MSE(pi2): 1.855e-05, MSE(pi3): 9.617e-04\n",
      "Epoch 485500, Train loss: 6.049e+02, Test loss: 1.082e+03, MSE(e): 3.882e-05, MSE(pi1): 1.186e-02, MSE(pi2): 1.879e-05, MSE(pi3): 9.806e-04\n",
      "Epoch 485600, Train loss: 1.748e+03, Test loss: 2.507e+03, MSE(e): 1.510e-04, MSE(pi1): 1.532e-02, MSE(pi2): 7.487e-05, MSE(pi3): 8.494e-04\n",
      "Epoch 485700, Train loss: 9.285e+02, Test loss: 1.698e+03, MSE(e): 6.194e-05, MSE(pi1): 1.957e-02, MSE(pi2): 2.718e-05, MSE(pi3): 1.133e-03\n",
      "Epoch 485800, Train loss: 2.471e+02, Test loss: 1.083e+03, MSE(e): 4.792e-06, MSE(pi1): 9.901e-03, MSE(pi2): 1.347e-06, MSE(pi3): 1.002e-03\n",
      "Epoch 485900, Train loss: 1.208e+03, Test loss: 1.740e+03, MSE(e): 9.237e-05, MSE(pi1): 2.025e-02, MSE(pi2): 4.523e-05, MSE(pi3): 8.144e-04\n",
      "Epoch 486000, Train loss: 3.182e+02, Test loss: 9.377e+02, MSE(e): 1.735e-05, MSE(pi1): 5.061e-03, MSE(pi2): 7.743e-06, MSE(pi3): 9.411e-04\n",
      "Epoch 486100, Train loss: 3.974e+02, Test loss: 1.176e+03, MSE(e): 1.173e-05, MSE(pi1): 1.922e-02, MSE(pi2): 4.712e-06, MSE(pi3): 8.793e-04\n",
      "Epoch 486200, Train loss: 2.862e+02, Test loss: 1.007e+03, MSE(e): 1.491e-05, MSE(pi1): 4.564e-03, MSE(pi2): 6.481e-06, MSE(pi3): 9.148e-04\n",
      "Epoch 486300, Train loss: 2.010e+02, Test loss: 9.786e+02, MSE(e): 4.354e-06, MSE(pi1): 6.213e-03, MSE(pi2): 1.597e-06, MSE(pi3): 9.536e-04\n",
      "Epoch 486400, Train loss: 1.928e+02, Test loss: 1.036e+03, MSE(e): 2.262e-06, MSE(pi1): 8.031e-03, MSE(pi2): 6.337e-07, MSE(pi3): 8.990e-04\n",
      "Epoch 486500, Train loss: 2.683e+02, Test loss: 1.017e+03, MSE(e): 5.887e-06, MSE(pi1): 1.210e-02, MSE(pi2): 3.048e-06, MSE(pi3): 8.850e-04\n",
      "Epoch 486600, Train loss: 5.742e+02, Test loss: 1.401e+03, MSE(e): 3.235e-05, MSE(pi1): 1.642e-02, MSE(pi2): 1.515e-05, MSE(pi3): 8.653e-04\n",
      "Epoch 486700, Train loss: 2.842e+02, Test loss: 1.188e+03, MSE(e): 4.438e-06, MSE(pi1): 1.324e-02, MSE(pi2): 1.192e-06, MSE(pi3): 1.074e-03\n",
      "Epoch 486800, Train loss: 2.602e+02, Test loss: 1.061e+03, MSE(e): 4.190e-06, MSE(pi1): 1.207e-02, MSE(pi2): 1.017e-06, MSE(pi3): 9.751e-04\n",
      "Epoch 486900, Train loss: 1.652e+02, Test loss: 9.861e+02, MSE(e): 2.347e-06, MSE(pi1): 4.349e-03, MSE(pi2): 8.484e-07, MSE(pi3): 9.824e-04\n",
      "Epoch 487000, Train loss: 3.247e+02, Test loss: 9.109e+02, MSE(e): 1.656e-05, MSE(pi1): 7.124e-03, MSE(pi2): 8.008e-06, MSE(pi3): 8.785e-04\n",
      "Epoch 487100, Train loss: 1.948e+02, Test loss: 1.073e+03, MSE(e): 2.446e-06, MSE(pi1): 6.442e-03, MSE(pi2): 7.361e-07, MSE(pi3): 1.060e-03\n",
      "Epoch 487200, Train loss: 3.752e+02, Test loss: 1.251e+03, MSE(e): 6.676e-06, MSE(pi1): 1.902e-02, MSE(pi2): 1.338e-06, MSE(pi3): 1.182e-03\n",
      "Epoch 487300, Train loss: 2.314e+02, Test loss: 9.696e+02, MSE(e): 6.038e-06, MSE(pi1): 8.071e-03, MSE(pi2): 2.947e-06, MSE(pi3): 9.031e-04\n",
      "Epoch 487400, Train loss: 2.400e+02, Test loss: 1.127e+03, MSE(e): 4.376e-06, MSE(pi1): 9.560e-03, MSE(pi2): 1.359e-06, MSE(pi3): 1.006e-03\n",
      "Epoch 487500, Train loss: 1.820e+02, Test loss: 1.032e+03, MSE(e): 2.029e-06, MSE(pi1): 6.119e-03, MSE(pi2): 6.494e-07, MSE(pi3): 1.005e-03\n",
      "Epoch 487600, Train loss: 1.370e+02, Test loss: 9.455e+02, MSE(e): 1.022e-06, MSE(pi1): 3.172e-03, MSE(pi2): 5.017e-07, MSE(pi3): 9.509e-04\n",
      "Epoch 487700, Train loss: 2.387e+02, Test loss: 1.069e+03, MSE(e): 9.000e-06, MSE(pi1): 4.858e-03, MSE(pi2): 4.083e-06, MSE(pi3): 1.001e-03\n",
      "Epoch 487800, Train loss: 1.004e+03, Test loss: 1.921e+03, MSE(e): 8.230e-05, MSE(pi1): 9.683e-03, MSE(pi2): 4.053e-05, MSE(pi3): 8.368e-04\n",
      "Epoch 487900, Train loss: 1.634e+02, Test loss: 9.384e+02, MSE(e): 1.902e-06, MSE(pi1): 4.556e-03, MSE(pi2): 8.139e-07, MSE(pi3): 9.881e-04\n",
      "Epoch 488000, Train loss: 4.291e+02, Test loss: 1.397e+03, MSE(e): 8.803e-06, MSE(pi1): 2.307e-02, MSE(pi2): 2.160e-06, MSE(pi3): 1.104e-03\n",
      "Epoch 488100, Train loss: 4.371e+02, Test loss: 1.601e+03, MSE(e): 2.460e-05, MSE(pi1): 8.052e-03, MSE(pi2): 1.198e-05, MSE(pi3): 1.106e-03\n",
      "Epoch 488200, Train loss: 2.293e+02, Test loss: 1.070e+03, MSE(e): 8.419e-06, MSE(pi1): 5.082e-03, MSE(pi2): 3.720e-06, MSE(pi3): 9.426e-04\n",
      "Epoch 488300, Train loss: 3.142e+02, Test loss: 1.034e+03, MSE(e): 8.955e-06, MSE(pi1): 1.211e-02, MSE(pi2): 3.111e-06, MSE(pi3): 1.035e-03\n",
      "Epoch 488400, Train loss: 1.401e+02, Test loss: 9.450e+02, MSE(e): 1.110e-06, MSE(pi1): 3.683e-03, MSE(pi2): 5.546e-07, MSE(pi3): 9.216e-04\n",
      "Epoch 488500, Train loss: 1.440e+02, Test loss: 9.508e+02, MSE(e): 1.117e-06, MSE(pi1): 4.046e-03, MSE(pi2): 4.780e-07, MSE(pi3): 9.234e-04\n",
      "Epoch 488600, Train loss: 1.454e+02, Test loss: 9.690e+02, MSE(e): 1.283e-06, MSE(pi1): 4.088e-03, MSE(pi2): 6.055e-07, MSE(pi3): 9.169e-04\n",
      "Epoch 488700, Train loss: 2.651e+02, Test loss: 1.125e+03, MSE(e): 4.657e-06, MSE(pi1): 1.148e-02, MSE(pi2): 1.388e-06, MSE(pi3): 1.037e-03\n",
      "Epoch 488800, Train loss: 3.362e+02, Test loss: 1.178e+03, MSE(e): 6.528e-06, MSE(pi1): 1.563e-02, MSE(pi2): 1.390e-06, MSE(pi3): 1.146e-03\n",
      "Epoch 488900, Train loss: 1.478e+02, Test loss: 9.676e+02, MSE(e): 1.168e-06, MSE(pi1): 4.513e-03, MSE(pi2): 4.933e-07, MSE(pi3): 9.102e-04\n",
      "Epoch 489000, Train loss: 2.257e+02, Test loss: 1.138e+03, MSE(e): 3.324e-06, MSE(pi1): 8.591e-03, MSE(pi2): 1.064e-06, MSE(pi3): 1.065e-03\n",
      "Epoch 489100, Train loss: 2.693e+02, Test loss: 1.114e+03, MSE(e): 4.484e-06, MSE(pi1): 1.352e-02, MSE(pi2): 1.054e-06, MSE(pi3): 8.923e-04\n",
      "Epoch 489200, Train loss: 2.838e+02, Test loss: 1.246e+03, MSE(e): 4.040e-06, MSE(pi1): 1.459e-02, MSE(pi2): 9.196e-07, MSE(pi3): 9.753e-04\n",
      "Epoch 489300, Train loss: 1.851e+02, Test loss: 1.072e+03, MSE(e): 3.304e-06, MSE(pi1): 5.610e-03, MSE(pi2): 1.289e-06, MSE(pi3): 9.594e-04\n",
      "Epoch 489400, Train loss: 1.619e+02, Test loss: 9.594e+02, MSE(e): 2.246e-06, MSE(pi1): 4.315e-03, MSE(pi2): 8.630e-07, MSE(pi3): 9.633e-04\n",
      "Epoch 489500, Train loss: 1.721e+02, Test loss: 1.059e+03, MSE(e): 2.471e-06, MSE(pi1): 5.325e-03, MSE(pi2): 1.038e-06, MSE(pi3): 9.419e-04\n",
      "Epoch 489600, Train loss: 2.114e+02, Test loss: 9.533e+02, MSE(e): 6.933e-06, MSE(pi1): 4.532e-03, MSE(pi2): 3.015e-06, MSE(pi3): 9.673e-04\n",
      "Epoch 489700, Train loss: 2.727e+02, Test loss: 9.835e+02, MSE(e): 5.559e-06, MSE(pi1): 1.060e-02, MSE(pi2): 1.765e-06, MSE(pi3): 1.110e-03\n",
      "Epoch 489800, Train loss: 2.614e+02, Test loss: 1.050e+03, MSE(e): 7.887e-06, MSE(pi1): 7.958e-03, MSE(pi2): 3.145e-06, MSE(pi3): 1.029e-03\n",
      "Epoch 489900, Train loss: 1.605e+03, Test loss: 3.721e+03, MSE(e): 1.443e-04, MSE(pi1): 5.472e-03, MSE(pi2): 7.013e-05, MSE(pi3): 1.070e-03\n",
      "Epoch 490000, Train loss: 1.755e+02, Test loss: 9.281e+02, MSE(e): 3.758e-06, MSE(pi1): 4.481e-03, MSE(pi2): 1.999e-06, MSE(pi3): 9.307e-04\n",
      "Epoch 490100, Train loss: 9.584e+02, Test loss: 2.275e+03, MSE(e): 8.014e-05, MSE(pi1): 5.900e-03, MSE(pi2): 3.683e-05, MSE(pi3): 9.791e-04\n",
      "Epoch 490200, Train loss: 5.998e+02, Test loss: 1.090e+03, MSE(e): 3.991e-05, MSE(pi1): 1.121e-02, MSE(pi2): 2.073e-05, MSE(pi3): 8.862e-04\n",
      "Epoch 490300, Train loss: 2.734e+02, Test loss: 1.178e+03, MSE(e): 4.238e-06, MSE(pi1): 1.430e-02, MSE(pi2): 9.411e-07, MSE(pi3): 8.802e-04\n",
      "Epoch 490400, Train loss: 1.759e+02, Test loss: 9.195e+02, MSE(e): 4.490e-06, MSE(pi1): 3.744e-03, MSE(pi2): 2.251e-06, MSE(pi3): 9.351e-04\n",
      "Epoch 490500, Train loss: 1.286e+03, Test loss: 3.014e+03, MSE(e): 1.098e-04, MSE(pi1): 9.450e-03, MSE(pi2): 5.006e-05, MSE(pi3): 9.370e-04\n",
      "Epoch 490600, Train loss: 3.374e+02, Test loss: 1.317e+03, MSE(e): 1.593e-05, MSE(pi1): 8.053e-03, MSE(pi2): 6.800e-06, MSE(pi3): 9.756e-04\n",
      "Epoch 490700, Train loss: 2.063e+02, Test loss: 1.092e+03, MSE(e): 4.294e-06, MSE(pi1): 6.550e-03, MSE(pi2): 1.678e-06, MSE(pi3): 9.781e-04\n",
      "Epoch 490800, Train loss: 5.310e+02, Test loss: 1.285e+03, MSE(e): 3.183e-05, MSE(pi1): 1.264e-02, MSE(pi2): 1.473e-05, MSE(pi3): 8.638e-04\n",
      "Epoch 490900, Train loss: 2.502e+02, Test loss: 1.087e+03, MSE(e): 3.720e-06, MSE(pi1): 1.267e-02, MSE(pi2): 8.696e-07, MSE(pi3): 8.637e-04\n",
      "Epoch 491000, Train loss: 1.790e+02, Test loss: 9.483e+02, MSE(e): 4.163e-06, MSE(pi1): 4.330e-03, MSE(pi2): 1.546e-06, MSE(pi3): 9.412e-04\n",
      "Epoch 491100, Train loss: 1.793e+02, Test loss: 1.016e+03, MSE(e): 2.290e-06, MSE(pi1): 6.394e-03, MSE(pi2): 7.191e-07, MSE(pi3): 9.246e-04\n",
      "Epoch 491200, Train loss: 1.657e+02, Test loss: 1.012e+03, MSE(e): 1.937e-06, MSE(pi1): 5.215e-03, MSE(pi2): 7.374e-07, MSE(pi3): 9.423e-04\n",
      "Epoch 491300, Train loss: 1.525e+02, Test loss: 9.360e+02, MSE(e): 1.537e-06, MSE(pi1): 4.083e-03, MSE(pi2): 6.840e-07, MSE(pi3): 9.634e-04\n",
      "Epoch 491400, Train loss: 1.472e+02, Test loss: 9.850e+02, MSE(e): 1.195e-06, MSE(pi1): 4.081e-03, MSE(pi2): 5.075e-07, MSE(pi3): 9.440e-04\n",
      "Epoch 491500, Train loss: 1.535e+02, Test loss: 1.015e+03, MSE(e): 1.793e-06, MSE(pi1): 3.682e-03, MSE(pi2): 7.530e-07, MSE(pi3): 9.872e-04\n",
      "Epoch 491600, Train loss: 2.173e+02, Test loss: 1.226e+03, MSE(e): 8.742e-06, MSE(pi1): 3.538e-03, MSE(pi2): 4.258e-06, MSE(pi3): 9.452e-04\n",
      "Epoch 491700, Train loss: 7.683e+02, Test loss: 2.053e+03, MSE(e): 6.281e-05, MSE(pi1): 3.843e-03, MSE(pi2): 3.021e-05, MSE(pi3): 1.018e-03\n",
      "Epoch 491800, Train loss: 4.905e+02, Test loss: 1.403e+03, MSE(e): 1.390e-05, MSE(pi1): 2.699e-02, MSE(pi2): 5.769e-06, MSE(pi3): 8.156e-04\n",
      "Epoch 491900, Train loss: 1.531e+02, Test loss: 1.030e+03, MSE(e): 1.595e-06, MSE(pi1): 4.668e-03, MSE(pi2): 6.770e-07, MSE(pi3): 9.044e-04\n",
      "Epoch 492000, Train loss: 2.826e+02, Test loss: 1.241e+03, MSE(e): 5.156e-06, MSE(pi1): 1.224e-02, MSE(pi2): 1.536e-06, MSE(pi3): 1.087e-03\n",
      "Epoch 492100, Train loss: 1.135e+03, Test loss: 1.833e+03, MSE(e): 9.744e-05, MSE(pi1): 7.774e-03, MSE(pi2): 4.714e-05, MSE(pi3): 8.274e-04\n",
      "Epoch 492200, Train loss: 1.414e+02, Test loss: 1.118e+03, MSE(e): 1.262e-06, MSE(pi1): 3.473e-03, MSE(pi2): 6.062e-07, MSE(pi3): 9.402e-04\n",
      "Epoch 492300, Train loss: 2.400e+02, Test loss: 1.133e+03, MSE(e): 6.389e-06, MSE(pi1): 6.949e-03, MSE(pi2): 2.477e-06, MSE(pi3): 1.066e-03\n",
      "Epoch 492400, Train loss: 4.513e+02, Test loss: 1.678e+03, MSE(e): 2.960e-05, MSE(pi1): 5.976e-03, MSE(pi2): 1.358e-05, MSE(pi3): 9.560e-04\n",
      "Epoch 492500, Train loss: 2.647e+03, Test loss: 5.441e+03, MSE(e): 2.419e-04, MSE(pi1): 1.061e-02, MSE(pi2): 1.187e-04, MSE(pi3): 1.224e-03\n",
      "Epoch 492600, Train loss: 1.632e+02, Test loss: 9.963e+02, MSE(e): 1.480e-06, MSE(pi1): 5.861e-03, MSE(pi2): 5.283e-07, MSE(pi3): 8.975e-04\n",
      "Epoch 492700, Train loss: 1.699e+02, Test loss: 1.062e+03, MSE(e): 2.412e-06, MSE(pi1): 4.779e-03, MSE(pi2): 1.255e-06, MSE(pi3): 9.798e-04\n",
      "Epoch 492800, Train loss: 1.782e+02, Test loss: 1.065e+03, MSE(e): 2.908e-06, MSE(pi1): 5.006e-03, MSE(pi2): 1.329e-06, MSE(pi3): 9.911e-04\n",
      "Epoch 492900, Train loss: 3.711e+02, Test loss: 1.497e+03, MSE(e): 1.834e-05, MSE(pi1): 8.793e-03, MSE(pi2): 8.426e-06, MSE(pi3): 9.971e-04\n",
      "Epoch 493000, Train loss: 4.836e+02, Test loss: 1.213e+03, MSE(e): 3.365e-05, MSE(pi1): 5.352e-03, MSE(pi2): 1.655e-05, MSE(pi3): 9.357e-04\n",
      "Epoch 493100, Train loss: 3.853e+02, Test loss: 1.439e+03, MSE(e): 8.037e-06, MSE(pi1): 1.925e-02, MSE(pi2): 2.464e-06, MSE(pi3): 1.124e-03\n",
      "Epoch 493200, Train loss: 1.882e+02, Test loss: 1.024e+03, MSE(e): 2.343e-06, MSE(pi1): 7.245e-03, MSE(pi2): 9.112e-07, MSE(pi3): 9.235e-04\n",
      "Epoch 493300, Train loss: 2.322e+02, Test loss: 1.065e+03, MSE(e): 4.084e-06, MSE(pi1): 8.254e-03, MSE(pi2): 1.507e-06, MSE(pi3): 1.088e-03\n",
      "Epoch 493400, Train loss: 2.877e+02, Test loss: 1.031e+03, MSE(e): 9.049e-06, MSE(pi1): 1.052e-02, MSE(pi2): 3.881e-06, MSE(pi3): 9.193e-04\n",
      "Epoch 493500, Train loss: 4.222e+02, Test loss: 1.598e+03, MSE(e): 1.598e-05, MSE(pi1): 1.462e-02, MSE(pi2): 6.981e-06, MSE(pi3): 1.161e-03\n",
      "Epoch 493600, Train loss: 2.836e+02, Test loss: 1.326e+03, MSE(e): 1.369e-05, MSE(pi1): 4.815e-03, MSE(pi2): 6.182e-06, MSE(pi3): 9.862e-04\n",
      "Epoch 493700, Train loss: 4.471e+02, Test loss: 1.594e+03, MSE(e): 8.446e-06, MSE(pi1): 2.621e-02, MSE(pi2): 1.718e-06, MSE(pi3): 1.005e-03\n",
      "Epoch 493800, Train loss: 1.812e+02, Test loss: 9.345e+02, MSE(e): 4.317e-06, MSE(pi1): 4.739e-03, MSE(pi2): 2.154e-06, MSE(pi3): 9.060e-04\n",
      "Epoch 493900, Train loss: 1.637e+02, Test loss: 9.844e+02, MSE(e): 1.730e-06, MSE(pi1): 5.499e-03, MSE(pi2): 7.229e-07, MSE(pi3): 9.139e-04\n",
      "Epoch 494000, Train loss: 2.295e+02, Test loss: 1.176e+03, MSE(e): 4.969e-06, MSE(pi1): 8.591e-03, MSE(pi2): 1.669e-06, MSE(pi3): 9.385e-04\n",
      "Epoch 494100, Train loss: 1.782e+03, Test loss: 2.196e+03, MSE(e): 1.617e-04, MSE(pi1): 7.893e-03, MSE(pi2): 7.733e-05, MSE(pi3): 8.599e-04\n",
      "Epoch 494200, Train loss: 1.373e+03, Test loss: 2.871e+03, MSE(e): 1.236e-04, MSE(pi1): 3.181e-03, MSE(pi2): 5.724e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 494300, Train loss: 3.153e+03, Test loss: 3.907e+03, MSE(e): 2.921e-04, MSE(pi1): 1.479e-02, MSE(pi2): 1.437e-04, MSE(pi3): 8.388e-04\n",
      "Epoch 494400, Train loss: 1.593e+02, Test loss: 9.764e+02, MSE(e): 1.461e-06, MSE(pi1): 5.474e-03, MSE(pi2): 5.237e-07, MSE(pi3): 8.992e-04\n",
      "Epoch 494500, Train loss: 2.994e+02, Test loss: 1.210e+03, MSE(e): 6.156e-06, MSE(pi1): 1.505e-02, MSE(pi2): 1.566e-06, MSE(pi3): 8.728e-04\n",
      "Epoch 494600, Train loss: 3.387e+02, Test loss: 1.262e+03, MSE(e): 5.523e-06, MSE(pi1): 1.684e-02, MSE(pi2): 1.158e-06, MSE(pi3): 1.150e-03\n",
      "Epoch 494700, Train loss: 1.974e+02, Test loss: 9.913e+02, MSE(e): 3.091e-06, MSE(pi1): 7.212e-03, MSE(pi2): 1.225e-06, MSE(pi3): 9.441e-04\n",
      "Epoch 494800, Train loss: 1.671e+02, Test loss: 9.796e+02, MSE(e): 1.983e-06, MSE(pi1): 5.884e-03, MSE(pi2): 6.396e-07, MSE(pi3): 8.843e-04\n",
      "Epoch 494900, Train loss: 4.162e+02, Test loss: 1.429e+03, MSE(e): 1.361e-05, MSE(pi1): 1.624e-02, MSE(pi2): 4.634e-06, MSE(pi3): 1.176e-03\n",
      "Epoch 495000, Train loss: 3.429e+02, Test loss: 1.154e+03, MSE(e): 6.994e-06, MSE(pi1): 1.594e-02, MSE(pi2): 1.651e-06, MSE(pi3): 1.136e-03\n",
      "Epoch 495100, Train loss: 1.397e+02, Test loss: 9.479e+02, MSE(e): 1.025e-06, MSE(pi1): 3.696e-03, MSE(pi2): 5.035e-07, MSE(pi3): 9.248e-04\n",
      "Epoch 495200, Train loss: 2.847e+02, Test loss: 1.174e+03, MSE(e): 4.847e-06, MSE(pi1): 1.284e-02, MSE(pi2): 1.088e-06, MSE(pi3): 1.078e-03\n",
      "Epoch 495300, Train loss: 2.674e+02, Test loss: 1.171e+03, MSE(e): 3.955e-06, MSE(pi1): 1.306e-02, MSE(pi2): 9.715e-07, MSE(pi3): 9.721e-04\n",
      "Epoch 495400, Train loss: 3.418e+02, Test loss: 1.266e+03, MSE(e): 6.202e-06, MSE(pi1): 1.801e-02, MSE(pi2): 1.447e-06, MSE(pi3): 9.969e-04\n",
      "Epoch 495500, Train loss: 3.651e+02, Test loss: 1.220e+03, MSE(e): 7.225e-06, MSE(pi1): 1.966e-02, MSE(pi2): 1.567e-06, MSE(pi3): 9.625e-04\n",
      "Epoch 495600, Train loss: 3.357e+02, Test loss: 1.312e+03, MSE(e): 5.455e-06, MSE(pi1): 1.826e-02, MSE(pi2): 1.106e-06, MSE(pi3): 9.853e-04\n",
      "Epoch 495700, Train loss: 3.713e+02, Test loss: 1.034e+03, MSE(e): 1.825e-05, MSE(pi1): 8.712e-03, MSE(pi2): 8.469e-06, MSE(pi3): 1.017e-03\n",
      "Epoch 495800, Train loss: 2.611e+02, Test loss: 1.100e+03, MSE(e): 7.238e-06, MSE(pi1): 9.229e-03, MSE(pi2): 2.440e-06, MSE(pi3): 9.648e-04\n",
      "Epoch 495900, Train loss: 2.294e+02, Test loss: 1.155e+03, MSE(e): 3.076e-06, MSE(pi1): 9.239e-03, MSE(pi2): 9.512e-07, MSE(pi3): 1.062e-03\n",
      "Epoch 496000, Train loss: 1.558e+02, Test loss: 9.418e+02, MSE(e): 1.546e-06, MSE(pi1): 4.598e-03, MSE(pi2): 6.280e-07, MSE(pi3): 9.439e-04\n",
      "Epoch 496100, Train loss: 2.755e+02, Test loss: 1.265e+03, MSE(e): 9.363e-06, MSE(pi1): 8.528e-03, MSE(pi2): 4.040e-06, MSE(pi3): 9.659e-04\n",
      "Epoch 496200, Train loss: 2.802e+02, Test loss: 1.037e+03, MSE(e): 1.053e-05, MSE(pi1): 7.861e-03, MSE(pi2): 4.714e-06, MSE(pi3): 9.633e-04\n",
      "Epoch 496300, Train loss: 6.144e+02, Test loss: 1.991e+03, MSE(e): 3.683e-05, MSE(pi1): 1.376e-02, MSE(pi2): 1.664e-05, MSE(pi3): 1.086e-03\n",
      "Epoch 496400, Train loss: 1.794e+02, Test loss: 9.212e+02, MSE(e): 3.948e-06, MSE(pi1): 4.256e-03, MSE(pi2): 1.814e-06, MSE(pi3): 9.739e-04\n",
      "Epoch 496500, Train loss: 6.252e+02, Test loss: 1.208e+03, MSE(e): 3.231e-05, MSE(pi1): 2.006e-02, MSE(pi2): 1.334e-05, MSE(pi3): 1.015e-03\n",
      "Epoch 496600, Train loss: 1.520e+02, Test loss: 9.784e+02, MSE(e): 1.398e-06, MSE(pi1): 4.753e-03, MSE(pi2): 5.483e-07, MSE(pi3): 9.053e-04\n",
      "Epoch 496700, Train loss: 1.890e+02, Test loss: 1.035e+03, MSE(e): 2.262e-06, MSE(pi1): 6.983e-03, MSE(pi2): 6.363e-07, MSE(pi3): 9.658e-04\n",
      "Epoch 496800, Train loss: 2.173e+02, Test loss: 1.115e+03, MSE(e): 3.256e-06, MSE(pi1): 9.698e-03, MSE(pi2): 9.546e-07, MSE(pi3): 8.776e-04\n",
      "Epoch 496900, Train loss: 1.728e+02, Test loss: 9.814e+02, MSE(e): 2.155e-06, MSE(pi1): 6.033e-03, MSE(pi2): 9.725e-07, MSE(pi3): 9.093e-04\n",
      "Epoch 497000, Train loss: 1.083e+03, Test loss: 2.214e+03, MSE(e): 8.532e-05, MSE(pi1): 1.270e-02, MSE(pi2): 4.079e-05, MSE(pi3): 1.025e-03\n",
      "Epoch 497100, Train loss: 2.684e+03, Test loss: 4.254e+03, MSE(e): 2.264e-04, MSE(pi1): 2.923e-02, MSE(pi2): 1.072e-04, MSE(pi3): 1.271e-03\n",
      "Epoch 497200, Train loss: 1.778e+02, Test loss: 9.913e+02, MSE(e): 2.859e-06, MSE(pi1): 5.491e-03, MSE(pi2): 8.555e-07, MSE(pi3): 9.426e-04\n",
      "Epoch 497300, Train loss: 2.986e+02, Test loss: 1.090e+03, MSE(e): 7.611e-06, MSE(pi1): 1.344e-02, MSE(pi2): 2.866e-06, MSE(pi3): 8.810e-04\n",
      "Epoch 497400, Train loss: 1.813e+02, Test loss: 9.400e+02, MSE(e): 4.546e-06, MSE(pi1): 4.559e-03, MSE(pi2): 2.108e-06, MSE(pi3): 9.024e-04\n",
      "Epoch 497500, Train loss: 1.444e+02, Test loss: 1.003e+03, MSE(e): 1.205e-06, MSE(pi1): 3.722e-03, MSE(pi2): 5.391e-07, MSE(pi3): 9.516e-04\n",
      "Epoch 497600, Train loss: 2.285e+02, Test loss: 1.065e+03, MSE(e): 3.078e-06, MSE(pi1): 1.085e-02, MSE(pi2): 7.431e-07, MSE(pi3): 8.918e-04\n",
      "Epoch 497700, Train loss: 2.419e+02, Test loss: 1.055e+03, MSE(e): 4.914e-06, MSE(pi1): 8.995e-03, MSE(pi2): 1.597e-06, MSE(pi3): 1.028e-03\n",
      "Epoch 497800, Train loss: 5.276e+02, Test loss: 1.622e+03, MSE(e): 9.371e-06, MSE(pi1): 3.051e-02, MSE(pi2): 2.151e-06, MSE(pi3): 1.288e-03\n",
      "Epoch 497900, Train loss: 6.494e+02, Test loss: 1.626e+03, MSE(e): 4.652e-05, MSE(pi1): 7.720e-03, MSE(pi2): 2.162e-05, MSE(pi3): 1.070e-03\n",
      "Epoch 498000, Train loss: 2.380e+02, Test loss: 9.324e+02, MSE(e): 1.014e-05, MSE(pi1): 4.553e-03, MSE(pi2): 4.596e-06, MSE(pi3): 9.106e-04\n",
      "Epoch 498100, Train loss: 2.047e+02, Test loss: 1.030e+03, MSE(e): 2.938e-06, MSE(pi1): 7.410e-03, MSE(pi2): 9.422e-07, MSE(pi3): 1.012e-03\n",
      "Epoch 498200, Train loss: 1.816e+02, Test loss: 1.119e+03, MSE(e): 5.252e-06, MSE(pi1): 3.605e-03, MSE(pi2): 2.533e-06, MSE(pi3): 9.300e-04\n",
      "Epoch 498300, Train loss: 4.365e+02, Test loss: 1.643e+03, MSE(e): 1.160e-05, MSE(pi1): 2.201e-02, MSE(pi2): 3.756e-06, MSE(pi3): 1.004e-03\n",
      "Epoch 498400, Train loss: 1.409e+02, Test loss: 9.917e+02, MSE(e): 1.168e-06, MSE(pi1): 3.689e-03, MSE(pi2): 5.343e-07, MSE(pi3): 9.230e-04\n",
      "Epoch 498500, Train loss: 2.776e+02, Test loss: 1.181e+03, MSE(e): 4.133e-06, MSE(pi1): 1.427e-02, MSE(pi2): 1.018e-06, MSE(pi3): 9.360e-04\n",
      "Epoch 498600, Train loss: 6.094e+02, Test loss: 1.866e+03, MSE(e): 2.983e-05, MSE(pi1): 2.021e-02, MSE(pi2): 1.264e-05, MSE(pi3): 1.090e-03\n",
      "Epoch 498700, Train loss: 2.589e+02, Test loss: 1.112e+03, MSE(e): 3.664e-06, MSE(pi1): 1.363e-02, MSE(pi2): 8.725e-07, MSE(pi3): 8.593e-04\n",
      "Epoch 498800, Train loss: 1.657e+03, Test loss: 3.590e+03, MSE(e): 1.321e-04, MSE(pi1): 2.022e-02, MSE(pi2): 6.539e-05, MSE(pi3): 1.338e-03\n",
      "Epoch 498900, Train loss: 1.157e+03, Test loss: 2.924e+03, MSE(e): 9.325e-05, MSE(pi1): 1.039e-02, MSE(pi2): 4.585e-05, MSE(pi3): 1.202e-03\n",
      "Epoch 499000, Train loss: 5.039e+02, Test loss: 1.156e+03, MSE(e): 3.131e-05, MSE(pi1): 1.005e-02, MSE(pi2): 1.520e-05, MSE(pi3): 9.026e-04\n",
      "Epoch 499100, Train loss: 2.297e+02, Test loss: 1.093e+03, MSE(e): 3.654e-06, MSE(pi1): 8.924e-03, MSE(pi2): 1.055e-06, MSE(pi3): 1.039e-03\n",
      "Epoch 499200, Train loss: 1.917e+02, Test loss: 1.102e+03, MSE(e): 3.378e-06, MSE(pi1): 5.533e-03, MSE(pi2): 1.590e-06, MSE(pi3): 1.026e-03\n",
      "Epoch 499300, Train loss: 1.792e+02, Test loss: 9.513e+02, MSE(e): 3.014e-06, MSE(pi1): 5.995e-03, MSE(pi2): 1.404e-06, MSE(pi3): 8.912e-04\n",
      "Epoch 499400, Train loss: 1.524e+02, Test loss: 9.574e+02, MSE(e): 1.781e-06, MSE(pi1): 3.941e-03, MSE(pi2): 7.327e-07, MSE(pi3): 9.515e-04\n",
      "Epoch 499500, Train loss: 4.968e+02, Test loss: 1.156e+03, MSE(e): 2.378e-05, MSE(pi1): 1.647e-02, MSE(pi2): 9.721e-06, MSE(pi3): 9.437e-04\n",
      "Epoch 499600, Train loss: 2.273e+02, Test loss: 9.568e+02, MSE(e): 8.602e-06, MSE(pi1): 5.264e-03, MSE(pi2): 4.334e-06, MSE(pi3): 8.866e-04\n",
      "Epoch 499700, Train loss: 3.034e+02, Test loss: 1.150e+03, MSE(e): 6.390e-06, MSE(pi1): 1.304e-02, MSE(pi2): 1.819e-06, MSE(pi3): 1.091e-03\n",
      "Epoch 499800, Train loss: 1.856e+02, Test loss: 1.060e+03, MSE(e): 2.094e-06, MSE(pi1): 6.364e-03, MSE(pi2): 6.812e-07, MSE(pi3): 1.010e-03\n",
      "Epoch 499900, Train loss: 2.841e+02, Test loss: 9.811e+02, MSE(e): 7.610e-06, MSE(pi1): 1.216e-02, MSE(pi2): 2.494e-06, MSE(pi3): 8.641e-04\n",
      "\n",
      "Proceso finalizado después de 500000 épocas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 275000\n",
    "n_epochs = 500000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 100\n",
    "\n",
    "second_lr = 3e-5\n",
    "\n",
    "train_loop(model, optimizer, n_checkpoints,\n",
    "           X_train, y_train, X_test, y_test, f_train, f_test,\n",
    "           D=D, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=device,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
