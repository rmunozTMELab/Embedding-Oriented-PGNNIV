{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/transfer_learning/results/non_linear\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/transfer_learning/results/non_linear/model_autoencoder_AE\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/transfer_learning/results/non_linear/model_autoencoder_NN\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/non_linear_100_0/non_linear_100_0.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/non_linear')\n",
    "MODEL_RESULTS_AE_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/non_linear/model_autoencoder_AE')\n",
    "MODEL_RESULTS_PGNNIV_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/non_linear/model_autoencoder_NN')\n",
    "\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_AE_PATH)\n",
    "create_folder(MODEL_RESULTS_PGNNIV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear_100_0/non_linear_100_0.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 80\n",
      "Validation dataset length: 20\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length for the autoencoder: 40\n",
      "Dataset length for the PGNNIV: 40\n"
     ]
    }
   ],
   "source": [
    "N_data_AE = len(X_train)//2\n",
    "N_data_NN = len(X_train) - len(X_train)//2\n",
    "prop_data_NN = 1 - N_data_AE/(N_data_NN + N_data_AE)\n",
    "\n",
    "print(\"Dataset length for the autoencoder:\", N_data_AE)\n",
    "print(\"Dataset length for the PGNNIV:\", N_data_NN)\n",
    "\n",
    "X_AE, X_NN, y_AE, y_NN, K_AE, K_NN, f_AE, f_NN = train_test_split(X_train, y_train, K_train, f_train, test_size=prop_data_NN, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos para el autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_AE, y_test_AE = train_test_split(y_AE, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train_AE = TensOps(y_train_AE.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test_AE = TensOps(y_test_AE.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos para la PGNNIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_NN, X_test_NN, y_train_NN, y_test_NN, K_train_NN, K_test_NN, f_train_NN, f_test_NN = train_test_split(X_NN, y_NN, K_NN, f_NN, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_NN = X_train_NN.to(DEVICE)\n",
    "X_test_NN = X_test_NN.to(DEVICE)\n",
    "\n",
    "y_train_NN = TensOps(y_train_NN.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test_NN = TensOps(y_test_NN.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train_NN = TensOps(K_train_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test_NN = TensOps(K_test_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train_NN = TensOps(f_train_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test_NN = TensOps(f_test_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Autoencoder\n",
    "from trainers.train import train_autoencoder_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = 10\n",
    "\n",
    "autoencoder_input_shape = y_train_AE.values[0].shape\n",
    "latent_space_dim = [20, 10, n_modes, 10, 20]\n",
    "autoencoder_output_shape = y_train_AE.values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = y_train_AE.values\n",
    "y_train = y_train_AE\n",
    "\n",
    "X_test = y_test_AE.values\n",
    "y_test = y_test_AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 5.222e+01, Test loss: 9.438e+01\n",
      "Epoch 100, Train loss: 3.445e+00, Test loss: 5.813e+00\n",
      "Epoch 200, Train loss: 1.843e+00, Test loss: 3.632e+00\n",
      "Epoch 300, Train loss: 1.722e+00, Test loss: 3.656e+00\n",
      "Epoch 400, Train loss: 1.381e+00, Test loss: 3.816e+00\n",
      "Epoch 500, Train loss: 1.044e+00, Test loss: 4.107e+00\n",
      "Epoch 600, Train loss: 9.062e-01, Test loss: 4.107e+00\n",
      "Epoch 700, Train loss: 8.623e-01, Test loss: 3.845e+00\n",
      "Epoch 800, Train loss: 8.157e-01, Test loss: 3.455e+00\n",
      "Epoch 900, Train loss: 6.949e-01, Test loss: 2.263e+00\n",
      "Epoch 1000, Train loss: 4.248e-01, Test loss: 1.213e+00\n",
      "Epoch 1100, Train loss: 3.574e-01, Test loss: 1.021e+00\n",
      "Epoch 1200, Train loss: 3.341e-01, Test loss: 9.774e-01\n",
      "Epoch 1300, Train loss: 3.204e-01, Test loss: 9.515e-01\n",
      "Epoch 1400, Train loss: 3.106e-01, Test loss: 9.304e-01\n",
      "Epoch 1500, Train loss: 3.000e-01, Test loss: 9.048e-01\n",
      "Epoch 1600, Train loss: 2.916e-01, Test loss: 8.802e-01\n",
      "Epoch 1700, Train loss: 2.845e-01, Test loss: 8.581e-01\n",
      "Epoch 1800, Train loss: 2.777e-01, Test loss: 8.349e-01\n",
      "Epoch 1900, Train loss: 2.714e-01, Test loss: 8.139e-01\n",
      "Epoch 2000, Train loss: 2.658e-01, Test loss: 7.945e-01\n",
      "Epoch 2100, Train loss: 2.610e-01, Test loss: 7.788e-01\n",
      "Epoch 2200, Train loss: 2.568e-01, Test loss: 7.656e-01\n",
      "Epoch 2300, Train loss: 2.530e-01, Test loss: 7.533e-01\n",
      "Epoch 2400, Train loss: 2.497e-01, Test loss: 7.420e-01\n",
      "Epoch 2500, Train loss: 2.468e-01, Test loss: 7.321e-01\n",
      "Epoch 2600, Train loss: 2.440e-01, Test loss: 7.231e-01\n",
      "Epoch 2700, Train loss: 2.416e-01, Test loss: 7.140e-01\n",
      "Epoch 2800, Train loss: 2.423e-01, Test loss: 7.010e-01\n",
      "Epoch 2900, Train loss: 2.375e-01, Test loss: 6.987e-01\n",
      "Epoch 3000, Train loss: 2.362e-01, Test loss: 6.875e-01\n",
      "Epoch 3100, Train loss: 2.342e-01, Test loss: 6.849e-01\n",
      "Epoch 3200, Train loss: 2.335e-01, Test loss: 6.826e-01\n",
      "Epoch 3300, Train loss: 2.315e-01, Test loss: 6.728e-01\n",
      "Epoch 3400, Train loss: 2.375e-01, Test loss: 6.609e-01\n",
      "Epoch 3500, Train loss: 2.294e-01, Test loss: 6.622e-01\n",
      "Epoch 3600, Train loss: 2.285e-01, Test loss: 6.574e-01\n",
      "Epoch 3700, Train loss: 2.277e-01, Test loss: 6.522e-01\n",
      "Epoch 3800, Train loss: 2.270e-01, Test loss: 6.488e-01\n",
      "Epoch 3900, Train loss: 2.264e-01, Test loss: 6.471e-01\n",
      "Epoch 4000, Train loss: 2.258e-01, Test loss: 6.412e-01\n",
      "Epoch 4100, Train loss: 2.252e-01, Test loss: 6.379e-01\n",
      "Epoch 4200, Train loss: 2.248e-01, Test loss: 6.342e-01\n",
      "Epoch 4300, Train loss: 2.243e-01, Test loss: 6.318e-01\n",
      "Epoch 4400, Train loss: 2.273e-01, Test loss: 6.328e-01\n",
      "Epoch 4500, Train loss: 2.235e-01, Test loss: 6.263e-01\n",
      "Epoch 4600, Train loss: 2.231e-01, Test loss: 6.238e-01\n",
      "Epoch 4700, Train loss: 2.228e-01, Test loss: 6.208e-01\n",
      "Epoch 4800, Train loss: 2.223e-01, Test loss: 6.186e-01\n",
      "Epoch 4900, Train loss: 2.220e-01, Test loss: 6.106e-01\n",
      "Epoch 5000, Train loss: 2.212e-01, Test loss: 6.125e-01\n",
      "Epoch 5100, Train loss: 2.204e-01, Test loss: 6.086e-01\n",
      "Epoch 5200, Train loss: 2.192e-01, Test loss: 6.034e-01\n",
      "Epoch 5300, Train loss: 2.172e-01, Test loss: 5.948e-01\n",
      "Epoch 5400, Train loss: 2.153e-01, Test loss: 5.738e-01\n",
      "Epoch 5500, Train loss: 2.070e-01, Test loss: 5.515e-01\n",
      "Epoch 5600, Train loss: 1.958e-01, Test loss: 5.008e-01\n",
      "Epoch 5700, Train loss: 1.835e-01, Test loss: 4.397e-01\n",
      "Epoch 5800, Train loss: 1.750e-01, Test loss: 4.016e-01\n",
      "Epoch 5900, Train loss: 1.691e-01, Test loss: 3.789e-01\n",
      "Epoch 6000, Train loss: 1.651e-01, Test loss: 3.656e-01\n",
      "Epoch 6100, Train loss: 1.619e-01, Test loss: 3.493e-01\n",
      "Epoch 6200, Train loss: 1.595e-01, Test loss: 3.472e-01\n",
      "Epoch 6300, Train loss: 1.576e-01, Test loss: 3.272e-01\n",
      "Epoch 6400, Train loss: 1.559e-01, Test loss: 3.181e-01\n",
      "Epoch 6500, Train loss: 1.542e-01, Test loss: 3.114e-01\n",
      "Epoch 6600, Train loss: 1.522e-01, Test loss: 3.033e-01\n",
      "Epoch 6700, Train loss: 1.498e-01, Test loss: 2.943e-01\n",
      "Epoch 6800, Train loss: 1.459e-01, Test loss: 2.913e-01\n",
      "Epoch 6900, Train loss: 1.399e-01, Test loss: 2.776e-01\n",
      "Epoch 7000, Train loss: 1.291e-01, Test loss: 2.727e-01\n",
      "Epoch 7100, Train loss: 1.134e-01, Test loss: 2.805e-01\n",
      "Epoch 7200, Train loss: 9.843e-02, Test loss: 3.014e-01\n",
      "Epoch 7300, Train loss: 8.814e-02, Test loss: 3.254e-01\n",
      "Epoch 7400, Train loss: 8.152e-02, Test loss: 3.426e-01\n",
      "Epoch 7500, Train loss: 7.772e-02, Test loss: 3.559e-01\n",
      "Epoch 7600, Train loss: 7.538e-02, Test loss: 3.641e-01\n",
      "Epoch 7700, Train loss: 7.374e-02, Test loss: 3.662e-01\n",
      "Epoch 7800, Train loss: 7.273e-02, Test loss: 3.663e-01\n",
      "Epoch 7900, Train loss: 7.207e-02, Test loss: 3.658e-01\n",
      "Epoch 8000, Train loss: 7.187e-02, Test loss: 3.672e-01\n",
      "Epoch 8100, Train loss: 7.126e-02, Test loss: 3.651e-01\n",
      "Epoch 8200, Train loss: 7.094e-02, Test loss: 3.642e-01\n",
      "Epoch 8300, Train loss: 7.065e-02, Test loss: 3.632e-01\n",
      "Epoch 8400, Train loss: 7.038e-02, Test loss: 3.624e-01\n",
      "Epoch 8500, Train loss: 7.013e-02, Test loss: 3.615e-01\n",
      "Epoch 8600, Train loss: 8.613e-02, Test loss: 3.865e-01\n",
      "Epoch 8700, Train loss: 6.972e-02, Test loss: 3.598e-01\n",
      "Epoch 8800, Train loss: 6.953e-02, Test loss: 3.588e-01\n",
      "Epoch 8900, Train loss: 7.077e-02, Test loss: 3.587e-01\n",
      "Epoch 9000, Train loss: 6.918e-02, Test loss: 3.568e-01\n",
      "Epoch 9100, Train loss: 6.901e-02, Test loss: 3.557e-01\n",
      "Epoch 9200, Train loss: 6.885e-02, Test loss: 3.546e-01\n",
      "Epoch 9300, Train loss: 6.867e-02, Test loss: 3.536e-01\n",
      "Epoch 9400, Train loss: 7.041e-02, Test loss: 3.523e-01\n",
      "Epoch 9500, Train loss: 6.828e-02, Test loss: 3.513e-01\n",
      "Epoch 9600, Train loss: 6.806e-02, Test loss: 3.503e-01\n",
      "Epoch 9700, Train loss: 6.806e-02, Test loss: 3.499e-01\n",
      "Epoch 9800, Train loss: 6.749e-02, Test loss: 3.476e-01\n",
      "Epoch 9900, Train loss: 6.712e-02, Test loss: 3.462e-01\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder(autoencoder_input_shape, latent_space_dim, autoencoder_output_shape).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "\n",
    "start_epoch = 0\n",
    "n_epochs = 10000\n",
    "batch_size = 64\n",
    "n_checkpoint = 3\n",
    "new_lr = None\n",
    "\n",
    "train_autoencoder_loop(autoencoder, optimizer, X_train, y_train, X_test, y_test,  \n",
    "                       n_checkpoint, start_epoch, n_epochs, batch_size, MODEL_RESULTS_AE_PATH, DEVICE, new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 9999.\n",
      "Epoch 10000, Train loss: 6.665e-02, Test loss: 3.442e-01\n",
      "Epoch 10100, Train loss: 6.657e-02, Test loss: 3.438e-01\n",
      "Epoch 10200, Train loss: 6.650e-02, Test loss: 3.436e-01\n",
      "Epoch 10300, Train loss: 6.644e-02, Test loss: 3.434e-01\n",
      "Epoch 10400, Train loss: 6.637e-02, Test loss: 3.432e-01\n",
      "Epoch 10500, Train loss: 6.629e-02, Test loss: 3.429e-01\n",
      "Epoch 10600, Train loss: 6.621e-02, Test loss: 3.426e-01\n",
      "Epoch 10700, Train loss: 6.612e-02, Test loss: 3.423e-01\n",
      "Epoch 10800, Train loss: 6.602e-02, Test loss: 3.419e-01\n",
      "Epoch 10900, Train loss: 6.591e-02, Test loss: 3.415e-01\n",
      "Epoch 11000, Train loss: 6.579e-02, Test loss: 3.411e-01\n",
      "Epoch 11100, Train loss: 6.566e-02, Test loss: 3.406e-01\n",
      "Epoch 11200, Train loss: 6.551e-02, Test loss: 3.400e-01\n",
      "Epoch 11300, Train loss: 6.535e-02, Test loss: 3.394e-01\n",
      "Epoch 11400, Train loss: 6.517e-02, Test loss: 3.387e-01\n",
      "Epoch 11500, Train loss: 6.496e-02, Test loss: 3.379e-01\n",
      "Epoch 11600, Train loss: 6.474e-02, Test loss: 3.371e-01\n",
      "Epoch 11700, Train loss: 6.448e-02, Test loss: 3.361e-01\n",
      "Epoch 11800, Train loss: 6.418e-02, Test loss: 3.349e-01\n",
      "Epoch 11900, Train loss: 6.384e-02, Test loss: 3.336e-01\n",
      "Epoch 12000, Train loss: 6.345e-02, Test loss: 3.321e-01\n",
      "Epoch 12100, Train loss: 6.299e-02, Test loss: 3.303e-01\n",
      "Epoch 12200, Train loss: 6.245e-02, Test loss: 3.281e-01\n",
      "Epoch 12300, Train loss: 6.181e-02, Test loss: 3.255e-01\n",
      "Epoch 12400, Train loss: 6.103e-02, Test loss: 3.223e-01\n",
      "Epoch 12500, Train loss: 6.009e-02, Test loss: 3.184e-01\n",
      "Epoch 12600, Train loss: 5.892e-02, Test loss: 3.135e-01\n",
      "Epoch 12700, Train loss: 5.745e-02, Test loss: 3.072e-01\n",
      "Epoch 12800, Train loss: 5.559e-02, Test loss: 2.990e-01\n",
      "Epoch 12900, Train loss: 5.319e-02, Test loss: 2.882e-01\n",
      "Epoch 13000, Train loss: 5.010e-02, Test loss: 2.738e-01\n",
      "Epoch 13100, Train loss: 4.614e-02, Test loss: 2.544e-01\n",
      "Epoch 13200, Train loss: 4.119e-02, Test loss: 2.288e-01\n",
      "Epoch 13300, Train loss: 3.536e-02, Test loss: 1.964e-01\n",
      "Epoch 13400, Train loss: 2.913e-02, Test loss: 1.593e-01\n",
      "Epoch 13500, Train loss: 2.321e-02, Test loss: 1.228e-01\n",
      "Epoch 13600, Train loss: 1.823e-02, Test loss: 9.229e-02\n",
      "Epoch 13700, Train loss: 1.440e-02, Test loss: 7.012e-02\n",
      "Epoch 13800, Train loss: 1.162e-02, Test loss: 5.563e-02\n",
      "Epoch 13900, Train loss: 9.687e-03, Test loss: 4.692e-02\n",
      "Epoch 14000, Train loss: 8.345e-03, Test loss: 4.202e-02\n",
      "Epoch 14100, Train loss: 7.400e-03, Test loss: 3.940e-02\n",
      "Epoch 14200, Train loss: 6.710e-03, Test loss: 3.804e-02\n",
      "Epoch 14300, Train loss: 6.182e-03, Test loss: 3.734e-02\n",
      "Epoch 14400, Train loss: 5.765e-03, Test loss: 3.697e-02\n",
      "Epoch 14500, Train loss: 5.423e-03, Test loss: 3.676e-02\n",
      "Epoch 14600, Train loss: 5.130e-03, Test loss: 3.666e-02\n",
      "Epoch 14700, Train loss: 4.877e-03, Test loss: 3.656e-02\n",
      "Epoch 14800, Train loss: 4.692e-03, Test loss: 3.787e-02\n",
      "Epoch 14900, Train loss: 4.441e-03, Test loss: 3.652e-02\n",
      "Epoch 15000, Train loss: 4.249e-03, Test loss: 3.671e-02\n",
      "Epoch 15100, Train loss: 4.074e-03, Test loss: 3.653e-02\n",
      "Epoch 15200, Train loss: 3.908e-03, Test loss: 3.665e-02\n",
      "Epoch 15300, Train loss: 3.756e-03, Test loss: 3.663e-02\n",
      "Epoch 15400, Train loss: 3.611e-03, Test loss: 3.665e-02\n",
      "Epoch 15500, Train loss: 3.478e-03, Test loss: 3.673e-02\n",
      "Epoch 15600, Train loss: 3.352e-03, Test loss: 3.674e-02\n",
      "Epoch 15700, Train loss: 3.236e-03, Test loss: 3.660e-02\n",
      "Epoch 15800, Train loss: 3.122e-03, Test loss: 3.681e-02\n",
      "Epoch 15900, Train loss: 3.066e-03, Test loss: 3.786e-02\n",
      "Epoch 16000, Train loss: 2.920e-03, Test loss: 3.686e-02\n",
      "Epoch 16100, Train loss: 2.947e-03, Test loss: 3.889e-02\n",
      "Epoch 16200, Train loss: 2.743e-03, Test loss: 3.687e-02\n",
      "Epoch 16300, Train loss: 2.661e-03, Test loss: 3.691e-02\n",
      "Epoch 16400, Train loss: 2.588e-03, Test loss: 3.688e-02\n",
      "Epoch 16500, Train loss: 2.518e-03, Test loss: 3.693e-02\n",
      "Epoch 16600, Train loss: 2.452e-03, Test loss: 3.717e-02\n",
      "Epoch 16700, Train loss: 2.391e-03, Test loss: 3.699e-02\n",
      "Epoch 16800, Train loss: 2.333e-03, Test loss: 3.720e-02\n",
      "Epoch 16900, Train loss: 2.279e-03, Test loss: 3.710e-02\n",
      "Epoch 17000, Train loss: 2.230e-03, Test loss: 3.715e-02\n",
      "Epoch 17100, Train loss: 2.181e-03, Test loss: 3.726e-02\n",
      "Epoch 17200, Train loss: 2.166e-03, Test loss: 3.853e-02\n",
      "Epoch 17300, Train loss: 2.094e-03, Test loss: 3.744e-02\n",
      "Epoch 17400, Train loss: 2.168e-03, Test loss: 3.594e-02\n",
      "Epoch 17500, Train loss: 2.017e-03, Test loss: 3.768e-02\n",
      "Epoch 17600, Train loss: 1.981e-03, Test loss: 3.767e-02\n",
      "Epoch 17700, Train loss: 1.948e-03, Test loss: 3.789e-02\n",
      "Epoch 17800, Train loss: 1.916e-03, Test loss: 3.803e-02\n",
      "Epoch 17900, Train loss: 1.886e-03, Test loss: 3.818e-02\n",
      "Epoch 18000, Train loss: 1.859e-03, Test loss: 3.826e-02\n",
      "Epoch 18100, Train loss: 1.831e-03, Test loss: 3.837e-02\n",
      "Epoch 18200, Train loss: 1.806e-03, Test loss: 3.844e-02\n",
      "Epoch 18300, Train loss: 1.781e-03, Test loss: 3.860e-02\n",
      "Epoch 18400, Train loss: 1.758e-03, Test loss: 3.805e-02\n",
      "Epoch 18500, Train loss: 1.737e-03, Test loss: 3.881e-02\n",
      "Epoch 18600, Train loss: 1.716e-03, Test loss: 3.890e-02\n",
      "Epoch 18700, Train loss: 1.696e-03, Test loss: 3.899e-02\n",
      "Epoch 18800, Train loss: 1.676e-03, Test loss: 3.903e-02\n",
      "Epoch 18900, Train loss: 1.658e-03, Test loss: 3.917e-02\n",
      "Epoch 19000, Train loss: 1.716e-03, Test loss: 3.909e-02\n",
      "Epoch 19100, Train loss: 1.624e-03, Test loss: 3.932e-02\n",
      "Epoch 19200, Train loss: 1.608e-03, Test loss: 3.941e-02\n",
      "Epoch 19300, Train loss: 1.592e-03, Test loss: 3.948e-02\n",
      "Epoch 19400, Train loss: 1.577e-03, Test loss: 3.958e-02\n",
      "Epoch 19500, Train loss: 1.562e-03, Test loss: 3.961e-02\n",
      "Epoch 19600, Train loss: 1.552e-03, Test loss: 3.996e-02\n",
      "Epoch 19700, Train loss: 1.535e-03, Test loss: 3.972e-02\n",
      "Epoch 19800, Train loss: 1.521e-03, Test loss: 3.977e-02\n",
      "Epoch 19900, Train loss: 1.510e-03, Test loss: 4.010e-02\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 9999\n",
    "n_epochs = 20000\n",
    "batch_size = 64\n",
    "n_checkpoint = 3\n",
    "new_lr = 1e-4\n",
    "\n",
    "train_autoencoder_loop(autoencoder, optimizer, X_train, y_train, X_test, y_test,  \n",
    "                       n_checkpoint, start_epoch, n_epochs, batch_size, MODEL_RESULTS_AE_PATH, DEVICE, new_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGNNIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from model.ae_nonlinear_model import AutoencoderNonlinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive network architecture\n",
    "input_shape = X_train_NN[0].shape\n",
    "predictive_layers = [20, 10, n_modes]\n",
    "predictive_output = y_train_NN.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train_NN)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train_NN)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1_layer.weight: requires_grad=False\n",
      "hidden1_layer.bias: requires_grad=False\n",
      "hidden2_layer.weight: requires_grad=False\n",
      "hidden2_layer.bias: requires_grad=False\n",
      "output_layer.weight: requires_grad=False\n",
      "output_layer.bias: requires_grad=False\n"
     ]
    }
   ],
   "source": [
    "pretrained_decoder = autoencoder.decoder\n",
    "\n",
    "for param in pretrained_decoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in pretrained_decoder.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 8.435e+10, Test loss: 1.184e+11, MSE(e): 8.433e+00, MSE(pi1): 1.116e+00, MSE(pi2): 3.999e+00, MSE(pi3): 1.032e-01\n",
      "Epoch 100, Train loss: 1.759e+10, Test loss: 1.596e+10, MSE(e): 1.757e+00, MSE(pi1): 1.035e+00, MSE(pi2): 8.104e-01, MSE(pi3): 1.021e-01\n",
      "Epoch 200, Train loss: 1.437e+10, Test loss: 1.273e+10, MSE(e): 1.435e+00, MSE(pi1): 9.642e-01, MSE(pi2): 6.718e-01, MSE(pi3): 9.879e-02\n",
      "Epoch 300, Train loss: 7.485e+09, Test loss: 8.098e+09, MSE(e): 7.471e-01, MSE(pi1): 6.569e-01, MSE(pi2): 3.821e-01, MSE(pi3): 7.673e-02\n",
      "Epoch 400, Train loss: 4.257e+09, Test loss: 8.362e+09, MSE(e): 4.247e-01, MSE(pi1): 4.899e-01, MSE(pi2): 2.433e-01, MSE(pi3): 4.563e-02\n",
      "Epoch 500, Train loss: 3.518e+09, Test loss: 6.709e+09, MSE(e): 3.509e-01, MSE(pi1): 5.031e-01, MSE(pi2): 2.098e-01, MSE(pi3): 4.386e-02\n",
      "Epoch 600, Train loss: 3.018e+09, Test loss: 5.471e+09, MSE(e): 3.009e-01, MSE(pi1): 5.053e-01, MSE(pi2): 1.837e-01, MSE(pi3): 4.059e-02\n",
      "Epoch 700, Train loss: 2.507e+09, Test loss: 4.650e+09, MSE(e): 2.498e-01, MSE(pi1): 4.941e-01, MSE(pi2): 1.535e-01, MSE(pi3): 3.499e-02\n",
      "Epoch 800, Train loss: 1.991e+09, Test loss: 3.955e+09, MSE(e): 1.984e-01, MSE(pi1): 4.748e-01, MSE(pi2): 1.219e-01, MSE(pi3): 2.840e-02\n",
      "Epoch 900, Train loss: 1.609e+09, Test loss: 3.593e+09, MSE(e): 1.602e-01, MSE(pi1): 4.544e-01, MSE(pi2): 9.906e-02, MSE(pi3): 2.355e-02\n",
      "Epoch 1000, Train loss: 1.380e+09, Test loss: 3.500e+09, MSE(e): 1.374e-01, MSE(pi1): 4.410e-01, MSE(pi2): 8.673e-02, MSE(pi3): 2.124e-02\n",
      "Epoch 1100, Train loss: 1.232e+09, Test loss: 3.458e+09, MSE(e): 1.225e-01, MSE(pi1): 4.357e-01, MSE(pi2): 7.951e-02, MSE(pi3): 2.038e-02\n",
      "Epoch 1200, Train loss: 1.122e+09, Test loss: 3.370e+09, MSE(e): 1.116e-01, MSE(pi1): 4.326e-01, MSE(pi2): 7.417e-02, MSE(pi3): 1.994e-02\n",
      "Epoch 1300, Train loss: 1.031e+09, Test loss: 3.219e+09, MSE(e): 1.025e-01, MSE(pi1): 4.274e-01, MSE(pi2): 6.941e-02, MSE(pi3): 1.949e-02\n",
      "Epoch 1400, Train loss: 9.438e+08, Test loss: 2.996e+09, MSE(e): 9.377e-02, MSE(pi1): 4.183e-01, MSE(pi2): 6.429e-02, MSE(pi3): 1.884e-02\n",
      "Epoch 1500, Train loss: 8.464e+08, Test loss: 2.683e+09, MSE(e): 8.406e-02, MSE(pi1): 4.035e-01, MSE(pi2): 5.797e-02, MSE(pi3): 1.782e-02\n",
      "Epoch 1600, Train loss: 7.282e+08, Test loss: 2.262e+09, MSE(e): 7.228e-02, MSE(pi1): 3.806e-01, MSE(pi2): 4.976e-02, MSE(pi3): 1.625e-02\n",
      "Epoch 1700, Train loss: 5.889e+08, Test loss: 1.764e+09, MSE(e): 5.839e-02, MSE(pi1): 3.496e-01, MSE(pi2): 3.982e-02, MSE(pi3): 1.419e-02\n",
      "Epoch 1800, Train loss: 4.459e+08, Test loss: 1.279e+09, MSE(e): 4.416e-02, MSE(pi1): 3.148e-01, MSE(pi2): 2.959e-02, MSE(pi3): 1.198e-02\n",
      "Epoch 1900, Train loss: 3.260e+08, Test loss: 8.993e+08, MSE(e): 3.221e-02, MSE(pi1): 2.833e-01, MSE(pi2): 2.109e-02, MSE(pi3): 1.007e-02\n",
      "Epoch 2000, Train loss: 2.434e+08, Test loss: 6.558e+08, MSE(e): 2.399e-02, MSE(pi1): 2.599e-01, MSE(pi2): 1.538e-02, MSE(pi3): 8.742e-03\n",
      "Epoch 2100, Train loss: 1.935e+08, Test loss: 5.170e+08, MSE(e): 1.903e-02, MSE(pi1): 2.448e-01, MSE(pi2): 1.208e-02, MSE(pi3): 7.921e-03\n",
      "Epoch 2200, Train loss: 1.641e+08, Test loss: 4.378e+08, MSE(e): 1.610e-02, MSE(pi1): 2.355e-01, MSE(pi2): 1.023e-02, MSE(pi3): 7.425e-03\n",
      "Epoch 2300, Train loss: 1.453e+08, Test loss: 3.883e+08, MSE(e): 1.423e-02, MSE(pi1): 2.296e-01, MSE(pi2): 9.089e-03, MSE(pi3): 7.105e-03\n",
      "Epoch 2400, Train loss: 1.316e+08, Test loss: 3.537e+08, MSE(e): 1.287e-02, MSE(pi1): 2.254e-01, MSE(pi2): 8.284e-03, MSE(pi3): 6.875e-03\n",
      "Epoch 2500, Train loss: 1.205e+08, Test loss: 3.277e+08, MSE(e): 1.176e-02, MSE(pi1): 2.221e-01, MSE(pi2): 7.645e-03, MSE(pi3): 6.690e-03\n",
      "Epoch 2600, Train loss: 1.110e+08, Test loss: 3.070e+08, MSE(e): 1.082e-02, MSE(pi1): 2.191e-01, MSE(pi2): 7.104e-03, MSE(pi3): 6.528e-03\n",
      "Epoch 2700, Train loss: 1.026e+08, Test loss: 2.898e+08, MSE(e): 9.980e-03, MSE(pi1): 2.162e-01, MSE(pi2): 6.632e-03, MSE(pi3): 6.381e-03\n",
      "Epoch 2800, Train loss: 9.512e+07, Test loss: 2.749e+08, MSE(e): 9.236e-03, MSE(pi1): 2.133e-01, MSE(pi2): 6.215e-03, MSE(pi3): 6.244e-03\n",
      "Epoch 2900, Train loss: 8.837e+07, Test loss: 2.614e+08, MSE(e): 8.566e-03, MSE(pi1): 2.106e-01, MSE(pi2): 5.841e-03, MSE(pi3): 6.117e-03\n",
      "Epoch 3000, Train loss: 8.225e+07, Test loss: 2.489e+08, MSE(e): 7.957e-03, MSE(pi1): 2.079e-01, MSE(pi2): 5.501e-03, MSE(pi3): 5.997e-03\n",
      "Epoch 3100, Train loss: 7.666e+07, Test loss: 2.372e+08, MSE(e): 7.402e-03, MSE(pi1): 2.052e-01, MSE(pi2): 5.187e-03, MSE(pi3): 5.882e-03\n",
      "Epoch 3200, Train loss: 7.153e+07, Test loss: 2.259e+08, MSE(e): 6.892e-03, MSE(pi1): 2.025e-01, MSE(pi2): 4.894e-03, MSE(pi3): 5.766e-03\n",
      "Epoch 3300, Train loss: 6.678e+07, Test loss: 2.151e+08, MSE(e): 6.422e-03, MSE(pi1): 1.998e-01, MSE(pi2): 4.619e-03, MSE(pi3): 5.649e-03\n",
      "Epoch 3400, Train loss: 6.237e+07, Test loss: 2.051e+08, MSE(e): 5.984e-03, MSE(pi1): 1.970e-01, MSE(pi2): 4.359e-03, MSE(pi3): 5.531e-03\n",
      "Epoch 3500, Train loss: 5.823e+07, Test loss: 1.961e+08, MSE(e): 5.574e-03, MSE(pi1): 1.942e-01, MSE(pi2): 4.110e-03, MSE(pi3): 5.410e-03\n",
      "Epoch 3600, Train loss: 5.432e+07, Test loss: 1.883e+08, MSE(e): 5.188e-03, MSE(pi1): 1.914e-01, MSE(pi2): 3.872e-03, MSE(pi3): 5.287e-03\n",
      "Epoch 3700, Train loss: 5.064e+07, Test loss: 1.823e+08, MSE(e): 4.824e-03, MSE(pi1): 1.881e-01, MSE(pi2): 3.647e-03, MSE(pi3): 5.187e-03\n",
      "Epoch 3800, Train loss: 4.716e+07, Test loss: 1.766e+08, MSE(e): 4.480e-03, MSE(pi1): 1.856e-01, MSE(pi2): 3.429e-03, MSE(pi3): 5.036e-03\n",
      "Epoch 3900, Train loss: 4.389e+07, Test loss: 1.725e+08, MSE(e): 4.157e-03, MSE(pi1): 1.827e-01, MSE(pi2): 3.224e-03, MSE(pi3): 4.909e-03\n",
      "Epoch 4000, Train loss: 4.085e+07, Test loss: 1.694e+08, MSE(e): 3.858e-03, MSE(pi1): 1.797e-01, MSE(pi2): 3.033e-03, MSE(pi3): 4.781e-03\n",
      "Epoch 4100, Train loss: 3.804e+07, Test loss: 1.669e+08, MSE(e): 3.581e-03, MSE(pi1): 1.767e-01, MSE(pi2): 2.856e-03, MSE(pi3): 4.656e-03\n",
      "Epoch 4200, Train loss: 3.548e+07, Test loss: 1.650e+08, MSE(e): 3.329e-03, MSE(pi1): 1.738e-01, MSE(pi2): 2.695e-03, MSE(pi3): 4.523e-03\n",
      "Epoch 4300, Train loss: 3.317e+07, Test loss: 1.633e+08, MSE(e): 3.102e-03, MSE(pi1): 1.708e-01, MSE(pi2): 2.549e-03, MSE(pi3): 4.395e-03\n",
      "Epoch 4400, Train loss: 3.111e+07, Test loss: 1.618e+08, MSE(e): 2.900e-03, MSE(pi1): 1.678e-01, MSE(pi2): 2.419e-03, MSE(pi3): 4.269e-03\n",
      "Epoch 4500, Train loss: 2.928e+07, Test loss: 1.599e+08, MSE(e): 2.722e-03, MSE(pi1): 1.647e-01, MSE(pi2): 2.304e-03, MSE(pi3): 4.149e-03\n",
      "Epoch 4600, Train loss: 2.887e+07, Test loss: 1.555e+08, MSE(e): 2.686e-03, MSE(pi1): 1.585e-01, MSE(pi2): 2.262e-03, MSE(pi3): 4.264e-03\n",
      "Epoch 4700, Train loss: 2.625e+07, Test loss: 1.560e+08, MSE(e): 2.427e-03, MSE(pi1): 1.585e-01, MSE(pi2): 2.113e-03, MSE(pi3): 3.916e-03\n",
      "Epoch 4800, Train loss: 2.501e+07, Test loss: 1.537e+08, MSE(e): 2.307e-03, MSE(pi1): 1.555e-01, MSE(pi2): 2.035e-03, MSE(pi3): 3.803e-03\n",
      "Epoch 4900, Train loss: 2.392e+07, Test loss: 1.511e+08, MSE(e): 2.203e-03, MSE(pi1): 1.523e-01, MSE(pi2): 1.968e-03, MSE(pi3): 3.701e-03\n",
      "Epoch 5000, Train loss: 2.297e+07, Test loss: 1.486e+08, MSE(e): 2.111e-03, MSE(pi1): 1.493e-01, MSE(pi2): 1.908e-03, MSE(pi3): 3.590e-03\n",
      "Epoch 5100, Train loss: 2.213e+07, Test loss: 1.462e+08, MSE(e): 2.032e-03, MSE(pi1): 1.462e-01, MSE(pi2): 1.857e-03, MSE(pi3): 3.488e-03\n",
      "Epoch 5200, Train loss: 2.139e+07, Test loss: 1.432e+08, MSE(e): 1.962e-03, MSE(pi1): 1.431e-01, MSE(pi2): 1.811e-03, MSE(pi3): 3.392e-03\n",
      "Epoch 5300, Train loss: 2.147e+07, Test loss: 1.424e+08, MSE(e): 1.974e-03, MSE(pi1): 1.422e-01, MSE(pi2): 1.799e-03, MSE(pi3): 3.165e-03\n",
      "Epoch 5400, Train loss: 2.016e+07, Test loss: 1.377e+08, MSE(e): 1.846e-03, MSE(pi1): 1.371e-01, MSE(pi2): 1.736e-03, MSE(pi3): 3.209e-03\n",
      "Epoch 5500, Train loss: 1.963e+07, Test loss: 1.352e+08, MSE(e): 1.798e-03, MSE(pi1): 1.342e-01, MSE(pi2): 1.705e-03, MSE(pi3): 3.122e-03\n",
      "Epoch 5600, Train loss: 1.917e+07, Test loss: 1.330e+08, MSE(e): 1.756e-03, MSE(pi1): 1.315e-01, MSE(pi2): 1.678e-03, MSE(pi3): 3.027e-03\n",
      "Epoch 5700, Train loss: 1.874e+07, Test loss: 1.303e+08, MSE(e): 1.716e-03, MSE(pi1): 1.284e-01, MSE(pi2): 1.652e-03, MSE(pi3): 2.960e-03\n",
      "Epoch 5800, Train loss: 1.838e+07, Test loss: 1.287e+08, MSE(e): 1.684e-03, MSE(pi1): 1.260e-01, MSE(pi2): 1.631e-03, MSE(pi3): 2.862e-03\n",
      "Epoch 5900, Train loss: 1.801e+07, Test loss: 1.261e+08, MSE(e): 1.649e-03, MSE(pi1): 1.229e-01, MSE(pi2): 1.609e-03, MSE(pi3): 2.812e-03\n",
      "Epoch 6000, Train loss: 1.768e+07, Test loss: 1.264e+08, MSE(e): 1.620e-03, MSE(pi1): 1.202e-01, MSE(pi2): 1.590e-03, MSE(pi3): 2.744e-03\n",
      "Epoch 6100, Train loss: 1.738e+07, Test loss: 1.224e+08, MSE(e): 1.594e-03, MSE(pi1): 1.177e-01, MSE(pi2): 1.573e-03, MSE(pi3): 2.678e-03\n",
      "Epoch 6200, Train loss: 1.718e+07, Test loss: 1.234e+08, MSE(e): 1.577e-03, MSE(pi1): 1.157e-01, MSE(pi2): 1.562e-03, MSE(pi3): 2.584e-03\n",
      "Epoch 6300, Train loss: 1.685e+07, Test loss: 1.194e+08, MSE(e): 1.547e-03, MSE(pi1): 1.128e-01, MSE(pi2): 1.543e-03, MSE(pi3): 2.558e-03\n",
      "Epoch 6400, Train loss: 1.661e+07, Test loss: 1.179e+08, MSE(e): 1.526e-03, MSE(pi1): 1.104e-01, MSE(pi2): 1.529e-03, MSE(pi3): 2.505e-03\n",
      "Epoch 6500, Train loss: 1.640e+07, Test loss: 1.172e+08, MSE(e): 1.507e-03, MSE(pi1): 1.083e-01, MSE(pi2): 1.517e-03, MSE(pi3): 2.448e-03\n",
      "Epoch 6600, Train loss: 1.619e+07, Test loss: 1.155e+08, MSE(e): 1.489e-03, MSE(pi1): 1.061e-01, MSE(pi2): 1.504e-03, MSE(pi3): 2.406e-03\n",
      "Epoch 6700, Train loss: 1.725e+07, Test loss: 1.125e+08, MSE(e): 1.598e-03, MSE(pi1): 1.022e-01, MSE(pi2): 1.533e-03, MSE(pi3): 2.489e-03\n",
      "Epoch 6800, Train loss: 1.582e+07, Test loss: 1.134e+08, MSE(e): 1.456e-03, MSE(pi1): 1.022e-01, MSE(pi2): 1.483e-03, MSE(pi3): 2.321e-03\n",
      "Epoch 6900, Train loss: 1.565e+07, Test loss: 1.125e+08, MSE(e): 1.442e-03, MSE(pi1): 1.004e-01, MSE(pi2): 1.473e-03, MSE(pi3): 2.282e-03\n",
      "Epoch 7000, Train loss: 1.553e+07, Test loss: 1.117e+08, MSE(e): 1.432e-03, MSE(pi1): 9.897e-02, MSE(pi2): 1.468e-03, MSE(pi3): 2.230e-03\n",
      "Epoch 7100, Train loss: 1.536e+07, Test loss: 1.108e+08, MSE(e): 1.416e-03, MSE(pi1): 9.711e-02, MSE(pi2): 1.456e-03, MSE(pi3): 2.214e-03\n",
      "Epoch 7200, Train loss: 1.522e+07, Test loss: 1.101e+08, MSE(e): 1.405e-03, MSE(pi1): 9.561e-02, MSE(pi2): 1.448e-03, MSE(pi3): 2.183e-03\n",
      "Epoch 7300, Train loss: 1.511e+07, Test loss: 1.095e+08, MSE(e): 1.395e-03, MSE(pi1): 9.434e-02, MSE(pi2): 1.443e-03, MSE(pi3): 2.149e-03\n",
      "Epoch 7400, Train loss: 1.499e+07, Test loss: 1.087e+08, MSE(e): 1.384e-03, MSE(pi1): 9.294e-02, MSE(pi2): 1.434e-03, MSE(pi3): 2.130e-03\n",
      "Epoch 7500, Train loss: 1.488e+07, Test loss: 1.080e+08, MSE(e): 1.375e-03, MSE(pi1): 9.173e-02, MSE(pi2): 1.428e-03, MSE(pi3): 2.106e-03\n",
      "Epoch 7600, Train loss: 1.479e+07, Test loss: 1.069e+08, MSE(e): 1.367e-03, MSE(pi1): 9.051e-02, MSE(pi2): 1.422e-03, MSE(pi3): 2.091e-03\n",
      "Epoch 7700, Train loss: 1.469e+07, Test loss: 1.068e+08, MSE(e): 1.359e-03, MSE(pi1): 8.957e-02, MSE(pi2): 1.417e-03, MSE(pi3): 2.065e-03\n",
      "Epoch 7800, Train loss: 1.671e+07, Test loss: 1.171e+08, MSE(e): 1.562e-03, MSE(pi1): 9.050e-02, MSE(pi2): 1.521e-03, MSE(pi3): 1.946e-03\n",
      "Epoch 7900, Train loss: 1.452e+07, Test loss: 1.057e+08, MSE(e): 1.344e-03, MSE(pi1): 8.772e-02, MSE(pi2): 1.408e-03, MSE(pi3): 2.030e-03\n",
      "Epoch 8000, Train loss: 1.445e+07, Test loss: 1.051e+08, MSE(e): 1.338e-03, MSE(pi1): 8.687e-02, MSE(pi2): 1.403e-03, MSE(pi3): 2.015e-03\n",
      "Epoch 8100, Train loss: 1.438e+07, Test loss: 1.052e+08, MSE(e): 1.332e-03, MSE(pi1): 8.614e-02, MSE(pi2): 1.400e-03, MSE(pi3): 1.998e-03\n",
      "Epoch 8200, Train loss: 1.432e+07, Test loss: 1.042e+08, MSE(e): 1.326e-03, MSE(pi1): 8.539e-02, MSE(pi2): 1.395e-03, MSE(pi3): 1.988e-03\n",
      "Epoch 8300, Train loss: 1.918e+07, Test loss: 9.784e+07, MSE(e): 1.815e-03, MSE(pi1): 8.222e-02, MSE(pi2): 1.551e-03, MSE(pi3): 2.170e-03\n",
      "Epoch 8400, Train loss: 1.420e+07, Test loss: 1.033e+08, MSE(e): 1.316e-03, MSE(pi1): 8.410e-02, MSE(pi2): 1.389e-03, MSE(pi3): 1.965e-03\n",
      "Epoch 8500, Train loss: 1.415e+07, Test loss: 1.027e+08, MSE(e): 1.312e-03, MSE(pi1): 8.352e-02, MSE(pi2): 1.386e-03, MSE(pi3): 1.955e-03\n",
      "Epoch 8600, Train loss: 1.416e+07, Test loss: 1.015e+08, MSE(e): 1.314e-03, MSE(pi1): 8.270e-02, MSE(pi2): 1.381e-03, MSE(pi3): 1.962e-03\n",
      "Epoch 8700, Train loss: 1.406e+07, Test loss: 1.018e+08, MSE(e): 1.304e-03, MSE(pi1): 8.248e-02, MSE(pi2): 1.380e-03, MSE(pi3): 1.937e-03\n",
      "Epoch 8800, Train loss: 1.401e+07, Test loss: 1.014e+08, MSE(e): 1.300e-03, MSE(pi1): 8.200e-02, MSE(pi2): 1.378e-03, MSE(pi3): 1.929e-03\n",
      "Epoch 8900, Train loss: 1.401e+07, Test loss: 1.000e+08, MSE(e): 1.300e-03, MSE(pi1): 8.134e-02, MSE(pi2): 1.373e-03, MSE(pi3): 1.935e-03\n",
      "Epoch 9000, Train loss: 1.393e+07, Test loss: 1.005e+08, MSE(e): 1.293e-03, MSE(pi1): 8.114e-02, MSE(pi2): 1.373e-03, MSE(pi3): 1.914e-03\n",
      "Epoch 9100, Train loss: 1.937e+07, Test loss: 1.268e+08, MSE(e): 1.836e-03, MSE(pi1): 8.334e-02, MSE(pi2): 1.641e-03, MSE(pi3): 1.788e-03\n",
      "Epoch 9200, Train loss: 1.387e+07, Test loss: 9.970e+07, MSE(e): 1.287e-03, MSE(pi1): 8.038e-02, MSE(pi2): 1.370e-03, MSE(pi3): 1.900e-03\n",
      "Epoch 9300, Train loss: 1.383e+07, Test loss: 9.914e+07, MSE(e): 1.284e-03, MSE(pi1): 8.001e-02, MSE(pi2): 1.368e-03, MSE(pi3): 1.896e-03\n",
      "Epoch 9400, Train loss: 1.381e+07, Test loss: 9.864e+07, MSE(e): 1.282e-03, MSE(pi1): 7.959e-02, MSE(pi2): 1.365e-03, MSE(pi3): 1.896e-03\n",
      "Epoch 9500, Train loss: 1.378e+07, Test loss: 9.828e+07, MSE(e): 1.279e-03, MSE(pi1): 7.936e-02, MSE(pi2): 1.365e-03, MSE(pi3): 1.885e-03\n",
      "Epoch 9600, Train loss: 1.618e+07, Test loss: 1.138e+08, MSE(e): 1.519e-03, MSE(pi1): 8.072e-02, MSE(pi2): 1.494e-03, MSE(pi3): 1.792e-03\n",
      "Epoch 9700, Train loss: 1.372e+07, Test loss: 9.738e+07, MSE(e): 1.275e-03, MSE(pi1): 7.876e-02, MSE(pi2): 1.362e-03, MSE(pi3): 1.876e-03\n",
      "Epoch 9800, Train loss: 1.370e+07, Test loss: 9.696e+07, MSE(e): 1.273e-03, MSE(pi1): 7.849e-02, MSE(pi2): 1.360e-03, MSE(pi3): 1.872e-03\n",
      "Epoch 9900, Train loss: 1.384e+07, Test loss: 9.513e+07, MSE(e): 1.287e-03, MSE(pi1): 7.783e-02, MSE(pi2): 1.358e-03, MSE(pi3): 1.894e-03\n",
      "Epoch 10000, Train loss: 1.366e+07, Test loss: 9.616e+07, MSE(e): 1.269e-03, MSE(pi1): 7.799e-02, MSE(pi2): 1.358e-03, MSE(pi3): 1.864e-03\n",
      "Epoch 10100, Train loss: 1.363e+07, Test loss: 9.569e+07, MSE(e): 1.267e-03, MSE(pi1): 7.775e-02, MSE(pi2): 1.357e-03, MSE(pi3): 1.861e-03\n",
      "Epoch 10200, Train loss: 1.407e+07, Test loss: 9.960e+07, MSE(e): 1.311e-03, MSE(pi1): 7.820e-02, MSE(pi2): 1.390e-03, MSE(pi3): 1.816e-03\n",
      "Epoch 10300, Train loss: 1.360e+07, Test loss: 9.489e+07, MSE(e): 1.264e-03, MSE(pi1): 7.730e-02, MSE(pi2): 1.355e-03, MSE(pi3): 1.854e-03\n",
      "Epoch 10400, Train loss: 1.358e+07, Test loss: 9.441e+07, MSE(e): 1.262e-03, MSE(pi1): 7.708e-02, MSE(pi2): 1.354e-03, MSE(pi3): 1.851e-03\n",
      "Epoch 10500, Train loss: 1.357e+07, Test loss: 9.350e+07, MSE(e): 1.262e-03, MSE(pi1): 7.678e-02, MSE(pi2): 1.351e-03, MSE(pi3): 1.854e-03\n",
      "Epoch 10600, Train loss: 1.354e+07, Test loss: 9.361e+07, MSE(e): 1.259e-03, MSE(pi1): 7.669e-02, MSE(pi2): 1.352e-03, MSE(pi3): 1.846e-03\n",
      "Epoch 10700, Train loss: 1.353e+07, Test loss: 9.289e+07, MSE(e): 1.258e-03, MSE(pi1): 7.647e-02, MSE(pi2): 1.351e-03, MSE(pi3): 1.845e-03\n",
      "Epoch 10800, Train loss: 1.352e+07, Test loss: 9.301e+07, MSE(e): 1.257e-03, MSE(pi1): 7.635e-02, MSE(pi2): 1.352e-03, MSE(pi3): 1.839e-03\n",
      "Epoch 10900, Train loss: 1.350e+07, Test loss: 9.240e+07, MSE(e): 1.255e-03, MSE(pi1): 7.615e-02, MSE(pi2): 1.350e-03, MSE(pi3): 1.838e-03\n",
      "Epoch 11000, Train loss: 1.362e+07, Test loss: 9.537e+07, MSE(e): 1.267e-03, MSE(pi1): 7.632e-02, MSE(pi2): 1.363e-03, MSE(pi3): 1.816e-03\n",
      "Epoch 11100, Train loss: 1.347e+07, Test loss: 9.171e+07, MSE(e): 1.253e-03, MSE(pi1): 7.583e-02, MSE(pi2): 1.349e-03, MSE(pi3): 1.833e-03\n",
      "Epoch 11200, Train loss: 1.346e+07, Test loss: 9.122e+07, MSE(e): 1.252e-03, MSE(pi1): 7.566e-02, MSE(pi2): 1.348e-03, MSE(pi3): 1.832e-03\n",
      "Epoch 11300, Train loss: 1.362e+07, Test loss: 8.649e+07, MSE(e): 1.268e-03, MSE(pi1): 7.508e-02, MSE(pi2): 1.345e-03, MSE(pi3): 1.860e-03\n",
      "Epoch 11400, Train loss: 1.344e+07, Test loss: 9.051e+07, MSE(e): 1.250e-03, MSE(pi1): 7.537e-02, MSE(pi2): 1.347e-03, MSE(pi3): 1.828e-03\n",
      "Epoch 11500, Train loss: 1.342e+07, Test loss: 9.008e+07, MSE(e): 1.249e-03, MSE(pi1): 7.523e-02, MSE(pi2): 1.346e-03, MSE(pi3): 1.826e-03\n",
      "Epoch 11600, Train loss: 1.343e+07, Test loss: 8.909e+07, MSE(e): 1.250e-03, MSE(pi1): 7.521e-02, MSE(pi2): 1.350e-03, MSE(pi3): 1.817e-03\n",
      "Epoch 11700, Train loss: 1.340e+07, Test loss: 8.940e+07, MSE(e): 1.247e-03, MSE(pi1): 7.496e-02, MSE(pi2): 1.345e-03, MSE(pi3): 1.823e-03\n",
      "Epoch 11800, Train loss: 1.339e+07, Test loss: 8.900e+07, MSE(e): 1.246e-03, MSE(pi1): 7.484e-02, MSE(pi2): 1.345e-03, MSE(pi3): 1.821e-03\n",
      "Epoch 11900, Train loss: 1.339e+07, Test loss: 8.926e+07, MSE(e): 1.246e-03, MSE(pi1): 7.477e-02, MSE(pi2): 1.346e-03, MSE(pi3): 1.816e-03\n",
      "Epoch 12000, Train loss: 1.337e+07, Test loss: 8.835e+07, MSE(e): 1.245e-03, MSE(pi1): 7.460e-02, MSE(pi2): 1.344e-03, MSE(pi3): 1.818e-03\n",
      "Epoch 12100, Train loss: 1.348e+07, Test loss: 8.567e+07, MSE(e): 1.255e-03, MSE(pi1): 7.418e-02, MSE(pi2): 1.340e-03, MSE(pi3): 1.837e-03\n",
      "Epoch 12200, Train loss: 1.336e+07, Test loss: 8.760e+07, MSE(e): 1.243e-03, MSE(pi1): 7.435e-02, MSE(pi2): 1.343e-03, MSE(pi3): 1.817e-03\n",
      "Epoch 12300, Train loss: 1.335e+07, Test loss: 8.734e+07, MSE(e): 1.242e-03, MSE(pi1): 7.426e-02, MSE(pi2): 1.343e-03, MSE(pi3): 1.814e-03\n",
      "Epoch 12400, Train loss: 1.357e+07, Test loss: 8.568e+07, MSE(e): 1.265e-03, MSE(pi1): 7.372e-02, MSE(pi2): 1.341e-03, MSE(pi3): 1.843e-03\n",
      "Epoch 12500, Train loss: 1.333e+07, Test loss: 8.675e+07, MSE(e): 1.241e-03, MSE(pi1): 7.406e-02, MSE(pi2): 1.342e-03, MSE(pi3): 1.812e-03\n",
      "Epoch 12600, Train loss: 1.350e+07, Test loss: 8.371e+07, MSE(e): 1.258e-03, MSE(pi1): 7.359e-02, MSE(pi2): 1.339e-03, MSE(pi3): 1.835e-03\n",
      "Epoch 12700, Train loss: 1.332e+07, Test loss: 8.631e+07, MSE(e): 1.240e-03, MSE(pi1): 7.388e-02, MSE(pi2): 1.342e-03, MSE(pi3): 1.808e-03\n",
      "Epoch 12800, Train loss: 1.331e+07, Test loss: 8.583e+07, MSE(e): 1.239e-03, MSE(pi1): 7.377e-02, MSE(pi2): 1.341e-03, MSE(pi3): 1.809e-03\n",
      "Epoch 12900, Train loss: 1.331e+07, Test loss: 8.660e+07, MSE(e): 1.239e-03, MSE(pi1): 7.374e-02, MSE(pi2): 1.342e-03, MSE(pi3): 1.804e-03\n",
      "Epoch 13000, Train loss: 1.330e+07, Test loss: 8.529e+07, MSE(e): 1.238e-03, MSE(pi1): 7.359e-02, MSE(pi2): 1.340e-03, MSE(pi3): 1.807e-03\n",
      "Epoch 13100, Train loss: 1.329e+07, Test loss: 9.224e+07, MSE(e): 1.238e-03, MSE(pi1): 7.356e-02, MSE(pi2): 1.341e-03, MSE(pi3): 1.804e-03\n",
      "Epoch 13200, Train loss: 1.328e+07, Test loss: 8.482e+07, MSE(e): 1.237e-03, MSE(pi1): 7.343e-02, MSE(pi2): 1.340e-03, MSE(pi3): 1.804e-03\n",
      "Epoch 13300, Train loss: 1.328e+07, Test loss: 8.449e+07, MSE(e): 1.236e-03, MSE(pi1): 7.334e-02, MSE(pi2): 1.339e-03, MSE(pi3): 1.804e-03\n",
      "Epoch 13400, Train loss: 1.330e+07, Test loss: 8.604e+07, MSE(e): 1.239e-03, MSE(pi1): 7.342e-02, MSE(pi2): 1.344e-03, MSE(pi3): 1.793e-03\n",
      "Epoch 13500, Train loss: 1.326e+07, Test loss: 8.405e+07, MSE(e): 1.235e-03, MSE(pi1): 7.319e-02, MSE(pi2): 1.339e-03, MSE(pi3): 1.802e-03\n",
      "Epoch 13600, Train loss: 1.326e+07, Test loss: 8.376e+07, MSE(e): 1.235e-03, MSE(pi1): 7.312e-02, MSE(pi2): 1.338e-03, MSE(pi3): 1.801e-03\n",
      "Epoch 13700, Train loss: 1.327e+07, Test loss: 8.285e+07, MSE(e): 1.236e-03, MSE(pi1): 7.291e-02, MSE(pi2): 1.335e-03, MSE(pi3): 1.807e-03\n",
      "Epoch 13800, Train loss: 1.325e+07, Test loss: 8.335e+07, MSE(e): 1.234e-03, MSE(pi1): 7.298e-02, MSE(pi2): 1.338e-03, MSE(pi3): 1.799e-03\n",
      "Epoch 13900, Train loss: 1.325e+07, Test loss: 8.321e+07, MSE(e): 1.234e-03, MSE(pi1): 7.289e-02, MSE(pi2): 1.337e-03, MSE(pi3): 1.794e-03\n",
      "Epoch 14000, Train loss: 1.324e+07, Test loss: 8.310e+07, MSE(e): 1.233e-03, MSE(pi1): 7.284e-02, MSE(pi2): 1.337e-03, MSE(pi3): 1.798e-03\n",
      "Epoch 14100, Train loss: 1.323e+07, Test loss: 8.272e+07, MSE(e): 1.232e-03, MSE(pi1): 7.278e-02, MSE(pi2): 1.337e-03, MSE(pi3): 1.797e-03\n",
      "Epoch 14200, Train loss: 1.454e+07, Test loss: 8.030e+07, MSE(e): 1.364e-03, MSE(pi1): 7.172e-02, MSE(pi2): 1.363e-03, MSE(pi3): 1.865e-03\n",
      "Epoch 14300, Train loss: 1.322e+07, Test loss: 8.240e+07, MSE(e): 1.232e-03, MSE(pi1): 7.266e-02, MSE(pi2): 1.337e-03, MSE(pi3): 1.795e-03\n",
      "Epoch 14400, Train loss: 1.322e+07, Test loss: 8.211e+07, MSE(e): 1.231e-03, MSE(pi1): 7.259e-02, MSE(pi2): 1.337e-03, MSE(pi3): 1.795e-03\n",
      "Epoch 14500, Train loss: 1.322e+07, Test loss: 8.295e+07, MSE(e): 1.232e-03, MSE(pi1): 7.262e-02, MSE(pi2): 1.339e-03, MSE(pi3): 1.788e-03\n",
      "Epoch 14600, Train loss: 1.321e+07, Test loss: 8.179e+07, MSE(e): 1.230e-03, MSE(pi1): 7.247e-02, MSE(pi2): 1.336e-03, MSE(pi3): 1.794e-03\n",
      "Epoch 14700, Train loss: 1.589e+07, Test loss: 1.013e+08, MSE(e): 1.498e-03, MSE(pi1): 7.391e-02, MSE(pi2): 1.486e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 14800, Train loss: 1.320e+07, Test loss: 8.153e+07, MSE(e): 1.230e-03, MSE(pi1): 7.237e-02, MSE(pi2): 1.336e-03, MSE(pi3): 1.792e-03\n",
      "Epoch 14900, Train loss: 1.319e+07, Test loss: 8.128e+07, MSE(e): 1.229e-03, MSE(pi1): 7.231e-02, MSE(pi2): 1.336e-03, MSE(pi3): 1.792e-03\n",
      "Epoch 15000, Train loss: 1.325e+07, Test loss: 8.314e+07, MSE(e): 1.234e-03, MSE(pi1): 7.245e-02, MSE(pi2): 1.344e-03, MSE(pi3): 1.781e-03\n",
      "Epoch 15100, Train loss: 1.319e+07, Test loss: 8.100e+07, MSE(e): 1.228e-03, MSE(pi1): 7.220e-02, MSE(pi2): 1.335e-03, MSE(pi3): 1.791e-03\n",
      "Epoch 15200, Train loss: 1.318e+07, Test loss: 8.094e+07, MSE(e): 1.228e-03, MSE(pi1): 7.216e-02, MSE(pi2): 1.335e-03, MSE(pi3): 1.789e-03\n",
      "Epoch 15300, Train loss: 1.318e+07, Test loss: 8.060e+07, MSE(e): 1.228e-03, MSE(pi1): 7.209e-02, MSE(pi2): 1.335e-03, MSE(pi3): 1.790e-03\n",
      "Epoch 15400, Train loss: 1.317e+07, Test loss: 8.056e+07, MSE(e): 1.227e-03, MSE(pi1): 7.205e-02, MSE(pi2): 1.335e-03, MSE(pi3): 1.789e-03\n",
      "Epoch 15500, Train loss: 1.347e+07, Test loss: 8.325e+07, MSE(e): 1.256e-03, MSE(pi1): 7.244e-02, MSE(pi2): 1.360e-03, MSE(pi3): 1.764e-03\n",
      "Epoch 15600, Train loss: 1.317e+07, Test loss: 8.033e+07, MSE(e): 1.227e-03, MSE(pi1): 7.195e-02, MSE(pi2): 1.334e-03, MSE(pi3): 1.788e-03\n",
      "Epoch 15700, Train loss: 1.316e+07, Test loss: 8.017e+07, MSE(e): 1.226e-03, MSE(pi1): 7.190e-02, MSE(pi2): 1.334e-03, MSE(pi3): 1.787e-03\n",
      "Epoch 15800, Train loss: 1.318e+07, Test loss: 7.941e+07, MSE(e): 1.228e-03, MSE(pi1): 7.173e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.794e-03\n",
      "Epoch 15900, Train loss: 1.315e+07, Test loss: 7.998e+07, MSE(e): 1.226e-03, MSE(pi1): 7.181e-02, MSE(pi2): 1.334e-03, MSE(pi3): 1.786e-03\n",
      "Epoch 16000, Train loss: 1.315e+07, Test loss: 7.984e+07, MSE(e): 1.225e-03, MSE(pi1): 7.177e-02, MSE(pi2): 1.334e-03, MSE(pi3): 1.786e-03\n",
      "Epoch 16100, Train loss: 1.315e+07, Test loss: 7.989e+07, MSE(e): 1.225e-03, MSE(pi1): 7.176e-02, MSE(pi2): 1.335e-03, MSE(pi3): 1.783e-03\n",
      "Epoch 16200, Train loss: 1.314e+07, Test loss: 7.966e+07, MSE(e): 1.225e-03, MSE(pi1): 7.168e-02, MSE(pi2): 1.333e-03, MSE(pi3): 1.785e-03\n",
      "Epoch 16300, Train loss: 1.314e+07, Test loss: 7.953e+07, MSE(e): 1.225e-03, MSE(pi1): 7.164e-02, MSE(pi2): 1.333e-03, MSE(pi3): 1.784e-03\n",
      "Epoch 16400, Train loss: 1.314e+07, Test loss: 7.902e+07, MSE(e): 1.225e-03, MSE(pi1): 7.156e-02, MSE(pi2): 1.332e-03, MSE(pi3): 1.786e-03\n",
      "Epoch 16500, Train loss: 1.313e+07, Test loss: 7.937e+07, MSE(e): 1.224e-03, MSE(pi1): 7.156e-02, MSE(pi2): 1.333e-03, MSE(pi3): 1.783e-03\n",
      "Epoch 16600, Train loss: 1.313e+07, Test loss: 7.887e+07, MSE(e): 1.224e-03, MSE(pi1): 7.147e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.785e-03\n",
      "Epoch 16700, Train loss: 1.313e+07, Test loss: 7.943e+07, MSE(e): 1.224e-03, MSE(pi1): 7.149e-02, MSE(pi2): 1.333e-03, MSE(pi3): 1.782e-03\n",
      "Epoch 16800, Train loss: 1.312e+07, Test loss: 7.914e+07, MSE(e): 1.223e-03, MSE(pi1): 7.144e-02, MSE(pi2): 1.332e-03, MSE(pi3): 1.782e-03\n",
      "Epoch 16900, Train loss: 1.312e+07, Test loss: 7.894e+07, MSE(e): 1.223e-03, MSE(pi1): 7.139e-02, MSE(pi2): 1.332e-03, MSE(pi3): 1.782e-03\n",
      "Epoch 17000, Train loss: 1.312e+07, Test loss: 7.876e+07, MSE(e): 1.223e-03, MSE(pi1): 7.133e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.783e-03\n",
      "Epoch 17100, Train loss: 1.312e+07, Test loss: 7.890e+07, MSE(e): 1.222e-03, MSE(pi1): 7.132e-02, MSE(pi2): 1.332e-03, MSE(pi3): 1.781e-03\n",
      "Epoch 17200, Train loss: 1.322e+07, Test loss: 7.957e+07, MSE(e): 1.233e-03, MSE(pi1): 7.157e-02, MSE(pi2): 1.344e-03, MSE(pi3): 1.764e-03\n",
      "Epoch 17300, Train loss: 1.311e+07, Test loss: 7.882e+07, MSE(e): 1.222e-03, MSE(pi1): 7.124e-02, MSE(pi2): 1.332e-03, MSE(pi3): 1.780e-03\n",
      "Epoch 17400, Train loss: 1.311e+07, Test loss: 7.873e+07, MSE(e): 1.222e-03, MSE(pi1): 7.121e-02, MSE(pi2): 1.332e-03, MSE(pi3): 1.780e-03\n",
      "Epoch 17500, Train loss: 1.310e+07, Test loss: 7.940e+07, MSE(e): 1.221e-03, MSE(pi1): 7.119e-02, MSE(pi2): 1.332e-03, MSE(pi3): 1.778e-03\n",
      "Epoch 17600, Train loss: 1.310e+07, Test loss: 7.866e+07, MSE(e): 1.221e-03, MSE(pi1): 7.114e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.779e-03\n",
      "Epoch 17700, Train loss: 1.349e+07, Test loss: 8.457e+07, MSE(e): 1.260e-03, MSE(pi1): 7.163e-02, MSE(pi2): 1.363e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 17800, Train loss: 1.310e+07, Test loss: 7.871e+07, MSE(e): 1.221e-03, MSE(pi1): 7.108e-02, MSE(pi2): 1.332e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 17900, Train loss: 1.309e+07, Test loss: 7.853e+07, MSE(e): 1.220e-03, MSE(pi1): 7.103e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.778e-03\n",
      "Epoch 18000, Train loss: 1.325e+07, Test loss: 8.432e+07, MSE(e): 1.236e-03, MSE(pi1): 7.130e-02, MSE(pi2): 1.348e-03, MSE(pi3): 1.763e-03\n",
      "Epoch 18100, Train loss: 1.309e+07, Test loss: 7.851e+07, MSE(e): 1.220e-03, MSE(pi1): 7.096e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 18200, Train loss: 1.308e+07, Test loss: 7.845e+07, MSE(e): 1.220e-03, MSE(pi1): 7.092e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 18300, Train loss: 1.351e+07, Test loss: 7.694e+07, MSE(e): 1.262e-03, MSE(pi1): 7.034e-02, MSE(pi2): 1.332e-03, MSE(pi3): 1.811e-03\n",
      "Epoch 18400, Train loss: 1.308e+07, Test loss: 7.840e+07, MSE(e): 1.219e-03, MSE(pi1): 7.085e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 18500, Train loss: 1.308e+07, Test loss: 7.846e+07, MSE(e): 1.219e-03, MSE(pi1): 7.083e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.775e-03\n",
      "Epoch 18600, Train loss: 1.308e+07, Test loss: 7.840e+07, MSE(e): 1.219e-03, MSE(pi1): 7.080e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.774e-03\n",
      "Epoch 18700, Train loss: 1.307e+07, Test loss: 7.834e+07, MSE(e): 1.219e-03, MSE(pi1): 7.075e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.775e-03\n",
      "Epoch 18800, Train loss: 1.313e+07, Test loss: 7.832e+07, MSE(e): 1.225e-03, MSE(pi1): 7.051e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.786e-03\n",
      "Epoch 18900, Train loss: 1.307e+07, Test loss: 7.834e+07, MSE(e): 1.218e-03, MSE(pi1): 7.068e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.774e-03\n",
      "Epoch 19000, Train loss: 1.306e+07, Test loss: 7.838e+07, MSE(e): 1.218e-03, MSE(pi1): 7.066e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.773e-03\n",
      "Epoch 19100, Train loss: 1.306e+07, Test loss: 7.850e+07, MSE(e): 1.218e-03, MSE(pi1): 7.061e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.773e-03\n",
      "Epoch 19200, Train loss: 1.306e+07, Test loss: 7.832e+07, MSE(e): 1.218e-03, MSE(pi1): 7.058e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.773e-03\n",
      "Epoch 19300, Train loss: 1.985e+07, Test loss: 7.727e+07, MSE(e): 1.897e-03, MSE(pi1): 6.858e-02, MSE(pi2): 1.542e-03, MSE(pi3): 1.931e-03\n",
      "Epoch 19400, Train loss: 1.306e+07, Test loss: 7.828e+07, MSE(e): 1.217e-03, MSE(pi1): 7.050e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.773e-03\n",
      "Epoch 19500, Train loss: 1.305e+07, Test loss: 7.832e+07, MSE(e): 1.217e-03, MSE(pi1): 7.048e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.772e-03\n",
      "Epoch 19600, Train loss: 1.354e+07, Test loss: 8.435e+07, MSE(e): 1.266e-03, MSE(pi1): 7.101e-02, MSE(pi2): 1.367e-03, MSE(pi3): 1.745e-03\n",
      "Epoch 19700, Train loss: 1.305e+07, Test loss: 7.832e+07, MSE(e): 1.217e-03, MSE(pi1): 7.041e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.772e-03\n",
      "Epoch 19800, Train loss: 1.305e+07, Test loss: 7.870e+07, MSE(e): 1.217e-03, MSE(pi1): 7.042e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.769e-03\n",
      "Epoch 19900, Train loss: 1.305e+07, Test loss: 7.831e+07, MSE(e): 1.216e-03, MSE(pi1): 7.033e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.772e-03\n",
      "\n",
      "Training process finished after 20000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoencoderNonlinearModel(input_shape, predictive_layers, pretrained_decoder, predictive_output, explanatory_input,\n",
    "                                   explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 20000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(model, optimizer, X_train_NN, y_train_NN, f_train_NN, X_test_NN, y_test_NN, f_test_NN,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PGNNIV_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 18000.\n",
      "Epoch 18000, Train loss: 1.369e+07, Test loss: 8.295e+07, MSE(e): 1.280e-03, MSE(pi1): 7.035e-02, MSE(pi2): 1.336e-03, MSE(pi3): 1.816e-03\n",
      "Epoch 18100, Train loss: 1.309e+07, Test loss: 7.856e+07, MSE(e): 1.220e-03, MSE(pi1): 7.098e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 18200, Train loss: 1.309e+07, Test loss: 7.854e+07, MSE(e): 1.220e-03, MSE(pi1): 7.098e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 18300, Train loss: 1.309e+07, Test loss: 7.853e+07, MSE(e): 1.220e-03, MSE(pi1): 7.098e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 18400, Train loss: 1.309e+07, Test loss: 7.853e+07, MSE(e): 1.220e-03, MSE(pi1): 7.097e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 18500, Train loss: 1.309e+07, Test loss: 7.852e+07, MSE(e): 1.220e-03, MSE(pi1): 7.097e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 18600, Train loss: 1.309e+07, Test loss: 7.851e+07, MSE(e): 1.220e-03, MSE(pi1): 7.097e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 18700, Train loss: 1.309e+07, Test loss: 7.850e+07, MSE(e): 1.220e-03, MSE(pi1): 7.096e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 18800, Train loss: 1.309e+07, Test loss: 7.849e+07, MSE(e): 1.220e-03, MSE(pi1): 7.096e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 18900, Train loss: 1.309e+07, Test loss: 7.848e+07, MSE(e): 1.220e-03, MSE(pi1): 7.095e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 19000, Train loss: 1.309e+07, Test loss: 7.847e+07, MSE(e): 1.220e-03, MSE(pi1): 7.095e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 19100, Train loss: 1.309e+07, Test loss: 7.846e+07, MSE(e): 1.220e-03, MSE(pi1): 7.095e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 19200, Train loss: 1.309e+07, Test loss: 7.845e+07, MSE(e): 1.220e-03, MSE(pi1): 7.094e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 19300, Train loss: 1.309e+07, Test loss: 7.844e+07, MSE(e): 1.220e-03, MSE(pi1): 7.093e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 19400, Train loss: 1.308e+07, Test loss: 7.843e+07, MSE(e): 1.220e-03, MSE(pi1): 7.093e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.777e-03\n",
      "Epoch 19500, Train loss: 1.308e+07, Test loss: 7.842e+07, MSE(e): 1.220e-03, MSE(pi1): 7.092e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 19600, Train loss: 1.308e+07, Test loss: 7.841e+07, MSE(e): 1.220e-03, MSE(pi1): 7.091e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 19700, Train loss: 1.308e+07, Test loss: 7.840e+07, MSE(e): 1.220e-03, MSE(pi1): 7.091e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 19800, Train loss: 1.308e+07, Test loss: 7.838e+07, MSE(e): 1.220e-03, MSE(pi1): 7.090e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 19900, Train loss: 1.308e+07, Test loss: 7.837e+07, MSE(e): 1.220e-03, MSE(pi1): 7.089e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 20000, Train loss: 1.308e+07, Test loss: 7.836e+07, MSE(e): 1.219e-03, MSE(pi1): 7.088e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 20100, Train loss: 1.308e+07, Test loss: 7.835e+07, MSE(e): 1.219e-03, MSE(pi1): 7.087e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 20200, Train loss: 1.308e+07, Test loss: 7.833e+07, MSE(e): 1.219e-03, MSE(pi1): 7.087e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 20300, Train loss: 1.308e+07, Test loss: 7.832e+07, MSE(e): 1.219e-03, MSE(pi1): 7.086e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 20400, Train loss: 1.308e+07, Test loss: 7.831e+07, MSE(e): 1.219e-03, MSE(pi1): 7.085e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 20500, Train loss: 1.308e+07, Test loss: 7.829e+07, MSE(e): 1.219e-03, MSE(pi1): 7.084e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 20600, Train loss: 1.308e+07, Test loss: 7.828e+07, MSE(e): 1.219e-03, MSE(pi1): 7.083e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.776e-03\n",
      "Epoch 20700, Train loss: 1.308e+07, Test loss: 7.826e+07, MSE(e): 1.219e-03, MSE(pi1): 7.081e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.775e-03\n",
      "Epoch 20800, Train loss: 1.308e+07, Test loss: 7.825e+07, MSE(e): 1.219e-03, MSE(pi1): 7.080e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.775e-03\n",
      "Epoch 20900, Train loss: 1.307e+07, Test loss: 7.823e+07, MSE(e): 1.219e-03, MSE(pi1): 7.079e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.775e-03\n",
      "Epoch 21000, Train loss: 1.307e+07, Test loss: 7.822e+07, MSE(e): 1.219e-03, MSE(pi1): 7.078e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.775e-03\n",
      "Epoch 21100, Train loss: 1.307e+07, Test loss: 7.820e+07, MSE(e): 1.219e-03, MSE(pi1): 7.076e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.775e-03\n",
      "Epoch 21200, Train loss: 1.307e+07, Test loss: 7.819e+07, MSE(e): 1.219e-03, MSE(pi1): 7.075e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.775e-03\n",
      "Epoch 21300, Train loss: 1.307e+07, Test loss: 7.817e+07, MSE(e): 1.219e-03, MSE(pi1): 7.073e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.775e-03\n",
      "Epoch 21400, Train loss: 1.307e+07, Test loss: 7.816e+07, MSE(e): 1.218e-03, MSE(pi1): 7.072e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.775e-03\n",
      "Epoch 21500, Train loss: 1.307e+07, Test loss: 7.814e+07, MSE(e): 1.218e-03, MSE(pi1): 7.070e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.774e-03\n",
      "Epoch 21600, Train loss: 1.307e+07, Test loss: 7.813e+07, MSE(e): 1.218e-03, MSE(pi1): 7.068e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.774e-03\n",
      "Epoch 21700, Train loss: 1.306e+07, Test loss: 7.811e+07, MSE(e): 1.218e-03, MSE(pi1): 7.067e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.774e-03\n",
      "Epoch 21800, Train loss: 1.306e+07, Test loss: 7.810e+07, MSE(e): 1.218e-03, MSE(pi1): 7.065e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.774e-03\n",
      "Epoch 21900, Train loss: 1.306e+07, Test loss: 7.809e+07, MSE(e): 1.218e-03, MSE(pi1): 7.063e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.774e-03\n",
      "Epoch 22000, Train loss: 1.306e+07, Test loss: 7.807e+07, MSE(e): 1.218e-03, MSE(pi1): 7.061e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.773e-03\n",
      "Epoch 22100, Train loss: 1.306e+07, Test loss: 7.806e+07, MSE(e): 1.218e-03, MSE(pi1): 7.058e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.773e-03\n",
      "Epoch 22200, Train loss: 1.306e+07, Test loss: 7.805e+07, MSE(e): 1.217e-03, MSE(pi1): 7.056e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.773e-03\n",
      "Epoch 22300, Train loss: 1.306e+07, Test loss: 7.804e+07, MSE(e): 1.217e-03, MSE(pi1): 7.054e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.773e-03\n",
      "Epoch 22400, Train loss: 1.305e+07, Test loss: 7.804e+07, MSE(e): 1.217e-03, MSE(pi1): 7.051e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.773e-03\n",
      "Epoch 22500, Train loss: 1.305e+07, Test loss: 7.803e+07, MSE(e): 1.217e-03, MSE(pi1): 7.049e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.772e-03\n",
      "Epoch 22600, Train loss: 1.305e+07, Test loss: 7.802e+07, MSE(e): 1.217e-03, MSE(pi1): 7.046e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.772e-03\n",
      "Epoch 22700, Train loss: 1.305e+07, Test loss: 7.802e+07, MSE(e): 1.217e-03, MSE(pi1): 7.043e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.772e-03\n",
      "Epoch 22800, Train loss: 1.305e+07, Test loss: 7.802e+07, MSE(e): 1.216e-03, MSE(pi1): 7.040e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.771e-03\n",
      "Epoch 22900, Train loss: 1.304e+07, Test loss: 7.791e+07, MSE(e): 1.216e-03, MSE(pi1): 7.036e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.772e-03\n",
      "Epoch 23000, Train loss: 1.304e+07, Test loss: 7.803e+07, MSE(e): 1.216e-03, MSE(pi1): 7.034e-02, MSE(pi2): 1.329e-03, MSE(pi3): 1.771e-03\n",
      "Epoch 23100, Train loss: 1.304e+07, Test loss: 7.799e+07, MSE(e): 1.216e-03, MSE(pi1): 7.029e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.772e-03\n",
      "Epoch 23200, Train loss: 1.304e+07, Test loss: 7.803e+07, MSE(e): 1.216e-03, MSE(pi1): 7.028e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.770e-03\n",
      "Epoch 23300, Train loss: 1.304e+07, Test loss: 7.778e+07, MSE(e): 1.216e-03, MSE(pi1): 7.025e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.770e-03\n",
      "Epoch 23400, Train loss: 1.303e+07, Test loss: 7.805e+07, MSE(e): 1.215e-03, MSE(pi1): 7.022e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.770e-03\n",
      "Epoch 23500, Train loss: 1.304e+07, Test loss: 7.871e+07, MSE(e): 1.216e-03, MSE(pi1): 7.027e-02, MSE(pi2): 1.331e-03, MSE(pi3): 1.765e-03\n",
      "Epoch 23600, Train loss: 1.303e+07, Test loss: 7.807e+07, MSE(e): 1.215e-03, MSE(pi1): 7.016e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.769e-03\n",
      "Epoch 23700, Train loss: 1.303e+07, Test loss: 7.812e+07, MSE(e): 1.215e-03, MSE(pi1): 7.013e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.769e-03\n",
      "Epoch 23800, Train loss: 1.303e+07, Test loss: 7.809e+07, MSE(e): 1.215e-03, MSE(pi1): 7.010e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.769e-03\n",
      "Epoch 23900, Train loss: 1.302e+07, Test loss: 7.811e+07, MSE(e): 1.215e-03, MSE(pi1): 7.007e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.768e-03\n",
      "Epoch 24000, Train loss: 1.302e+07, Test loss: 7.809e+07, MSE(e): 1.215e-03, MSE(pi1): 7.004e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.768e-03\n",
      "Epoch 24100, Train loss: 1.302e+07, Test loss: 7.813e+07, MSE(e): 1.214e-03, MSE(pi1): 7.001e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.768e-03\n",
      "Epoch 24200, Train loss: 1.302e+07, Test loss: 7.793e+07, MSE(e): 1.214e-03, MSE(pi1): 6.997e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.768e-03\n",
      "Epoch 24300, Train loss: 1.302e+07, Test loss: 7.816e+07, MSE(e): 1.214e-03, MSE(pi1): 6.995e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.767e-03\n",
      "Epoch 24400, Train loss: 1.302e+07, Test loss: 7.826e+07, MSE(e): 1.214e-03, MSE(pi1): 6.994e-02, MSE(pi2): 1.328e-03, MSE(pi3): 1.766e-03\n",
      "Epoch 24500, Train loss: 1.301e+07, Test loss: 7.819e+07, MSE(e): 1.214e-03, MSE(pi1): 6.989e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.767e-03\n",
      "Epoch 24600, Train loss: 1.302e+07, Test loss: 7.771e+07, MSE(e): 1.215e-03, MSE(pi1): 6.978e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.771e-03\n",
      "Epoch 24700, Train loss: 1.301e+07, Test loss: 7.823e+07, MSE(e): 1.214e-03, MSE(pi1): 6.983e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.766e-03\n",
      "Epoch 24800, Train loss: 1.306e+07, Test loss: 7.961e+07, MSE(e): 1.218e-03, MSE(pi1): 6.998e-02, MSE(pi2): 1.335e-03, MSE(pi3): 1.757e-03\n",
      "Epoch 24900, Train loss: 1.301e+07, Test loss: 7.827e+07, MSE(e): 1.213e-03, MSE(pi1): 6.978e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.766e-03\n",
      "Epoch 25000, Train loss: 1.301e+07, Test loss: 7.838e+07, MSE(e): 1.213e-03, MSE(pi1): 6.976e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.765e-03\n",
      "Epoch 25100, Train loss: 1.300e+07, Test loss: 7.830e+07, MSE(e): 1.213e-03, MSE(pi1): 6.972e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.765e-03\n",
      "Epoch 25200, Train loss: 1.300e+07, Test loss: 7.835e+07, MSE(e): 1.213e-03, MSE(pi1): 6.969e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.765e-03\n",
      "Epoch 25300, Train loss: 1.300e+07, Test loss: 7.839e+07, MSE(e): 1.213e-03, MSE(pi1): 6.966e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.764e-03\n",
      "Epoch 25400, Train loss: 1.300e+07, Test loss: 7.839e+07, MSE(e): 1.213e-03, MSE(pi1): 6.963e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.764e-03\n",
      "Epoch 25500, Train loss: 1.300e+07, Test loss: 7.837e+07, MSE(e): 1.212e-03, MSE(pi1): 6.960e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.764e-03\n",
      "Epoch 25600, Train loss: 1.300e+07, Test loss: 7.843e+07, MSE(e): 1.212e-03, MSE(pi1): 6.958e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.764e-03\n",
      "Epoch 25700, Train loss: 1.300e+07, Test loss: 7.828e+07, MSE(e): 1.213e-03, MSE(pi1): 6.950e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.766e-03\n",
      "Epoch 25800, Train loss: 1.299e+07, Test loss: 7.849e+07, MSE(e): 1.212e-03, MSE(pi1): 6.952e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.763e-03\n",
      "Epoch 25900, Train loss: 1.299e+07, Test loss: 7.834e+07, MSE(e): 1.212e-03, MSE(pi1): 6.949e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.763e-03\n",
      "Epoch 26000, Train loss: 1.299e+07, Test loss: 7.853e+07, MSE(e): 1.212e-03, MSE(pi1): 6.946e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.763e-03\n",
      "Epoch 26100, Train loss: 1.299e+07, Test loss: 7.877e+07, MSE(e): 1.212e-03, MSE(pi1): 6.947e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.761e-03\n",
      "Epoch 26200, Train loss: 1.299e+07, Test loss: 7.860e+07, MSE(e): 1.212e-03, MSE(pi1): 6.941e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.762e-03\n",
      "Epoch 26300, Train loss: 1.299e+07, Test loss: 7.859e+07, MSE(e): 1.212e-03, MSE(pi1): 6.938e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.763e-03\n",
      "Epoch 26400, Train loss: 1.298e+07, Test loss: 7.864e+07, MSE(e): 1.211e-03, MSE(pi1): 6.935e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.762e-03\n",
      "Epoch 26500, Train loss: 1.298e+07, Test loss: 7.868e+07, MSE(e): 1.211e-03, MSE(pi1): 6.933e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.762e-03\n",
      "Epoch 26600, Train loss: 1.298e+07, Test loss: 7.871e+07, MSE(e): 1.211e-03, MSE(pi1): 6.930e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.762e-03\n",
      "Epoch 26700, Train loss: 1.298e+07, Test loss: 7.872e+07, MSE(e): 1.211e-03, MSE(pi1): 6.928e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.761e-03\n",
      "Epoch 26800, Train loss: 1.298e+07, Test loss: 7.878e+07, MSE(e): 1.211e-03, MSE(pi1): 6.925e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.761e-03\n",
      "Epoch 26900, Train loss: 1.298e+07, Test loss: 7.884e+07, MSE(e): 1.211e-03, MSE(pi1): 6.923e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.761e-03\n",
      "Epoch 27000, Train loss: 1.298e+07, Test loss: 7.882e+07, MSE(e): 1.211e-03, MSE(pi1): 6.920e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.761e-03\n",
      "Epoch 27100, Train loss: 1.297e+07, Test loss: 7.889e+07, MSE(e): 1.211e-03, MSE(pi1): 6.918e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.760e-03\n",
      "Epoch 27200, Train loss: 1.297e+07, Test loss: 7.891e+07, MSE(e): 1.211e-03, MSE(pi1): 6.915e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.760e-03\n",
      "Epoch 27300, Train loss: 1.297e+07, Test loss: 7.885e+07, MSE(e): 1.210e-03, MSE(pi1): 6.911e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.761e-03\n",
      "Epoch 27400, Train loss: 1.297e+07, Test loss: 7.897e+07, MSE(e): 1.210e-03, MSE(pi1): 6.910e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.760e-03\n",
      "Epoch 27500, Train loss: 1.297e+07, Test loss: 7.934e+07, MSE(e): 1.211e-03, MSE(pi1): 6.903e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.762e-03\n",
      "Epoch 27600, Train loss: 1.297e+07, Test loss: 7.905e+07, MSE(e): 1.210e-03, MSE(pi1): 6.905e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.760e-03\n",
      "Epoch 27700, Train loss: 1.297e+07, Test loss: 7.908e+07, MSE(e): 1.210e-03, MSE(pi1): 6.903e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.760e-03\n",
      "Epoch 27800, Train loss: 1.297e+07, Test loss: 7.870e+07, MSE(e): 1.211e-03, MSE(pi1): 6.893e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.763e-03\n",
      "Epoch 27900, Train loss: 1.296e+07, Test loss: 7.915e+07, MSE(e): 1.210e-03, MSE(pi1): 6.898e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.759e-03\n",
      "Epoch 28000, Train loss: 1.296e+07, Test loss: 7.918e+07, MSE(e): 1.210e-03, MSE(pi1): 6.896e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.759e-03\n",
      "Epoch 28100, Train loss: 1.296e+07, Test loss: 7.919e+07, MSE(e): 1.210e-03, MSE(pi1): 6.893e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.759e-03\n",
      "Epoch 28200, Train loss: 1.296e+07, Test loss: 7.926e+07, MSE(e): 1.210e-03, MSE(pi1): 6.891e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.759e-03\n",
      "Epoch 28300, Train loss: 1.296e+07, Test loss: 7.919e+07, MSE(e): 1.209e-03, MSE(pi1): 6.888e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.759e-03\n",
      "Epoch 28400, Train loss: 1.296e+07, Test loss: 7.934e+07, MSE(e): 1.209e-03, MSE(pi1): 6.887e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.758e-03\n",
      "Epoch 28500, Train loss: 1.296e+07, Test loss: 7.948e+07, MSE(e): 1.209e-03, MSE(pi1): 6.886e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.758e-03\n",
      "Epoch 28600, Train loss: 1.296e+07, Test loss: 7.943e+07, MSE(e): 1.209e-03, MSE(pi1): 6.883e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.758e-03\n",
      "Epoch 28700, Train loss: 1.296e+07, Test loss: 8.000e+07, MSE(e): 1.210e-03, MSE(pi1): 6.887e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.754e-03\n",
      "Epoch 28800, Train loss: 1.295e+07, Test loss: 7.950e+07, MSE(e): 1.209e-03, MSE(pi1): 6.878e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.758e-03\n",
      "Epoch 28900, Train loss: 1.296e+07, Test loss: 7.927e+07, MSE(e): 1.209e-03, MSE(pi1): 6.872e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.760e-03\n",
      "Epoch 29000, Train loss: 1.295e+07, Test loss: 7.957e+07, MSE(e): 1.209e-03, MSE(pi1): 6.874e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.758e-03\n",
      "Epoch 29100, Train loss: 1.295e+07, Test loss: 7.970e+07, MSE(e): 1.209e-03, MSE(pi1): 6.873e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.757e-03\n",
      "Epoch 29200, Train loss: 1.295e+07, Test loss: 7.968e+07, MSE(e): 1.209e-03, MSE(pi1): 6.870e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.757e-03\n",
      "Epoch 29300, Train loss: 1.295e+07, Test loss: 7.971e+07, MSE(e): 1.209e-03, MSE(pi1): 6.868e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.757e-03\n",
      "Epoch 29400, Train loss: 1.295e+07, Test loss: 8.023e+07, MSE(e): 1.209e-03, MSE(pi1): 6.871e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.754e-03\n",
      "Epoch 29500, Train loss: 1.295e+07, Test loss: 7.979e+07, MSE(e): 1.208e-03, MSE(pi1): 6.864e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.757e-03\n",
      "Epoch 29600, Train loss: 1.299e+07, Test loss: 7.864e+07, MSE(e): 1.213e-03, MSE(pi1): 6.845e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.766e-03\n",
      "Epoch 29700, Train loss: 1.294e+07, Test loss: 7.986e+07, MSE(e): 1.208e-03, MSE(pi1): 6.859e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.757e-03\n",
      "Epoch 29800, Train loss: 1.295e+07, Test loss: 7.921e+07, MSE(e): 1.209e-03, MSE(pi1): 6.850e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.761e-03\n",
      "Epoch 29900, Train loss: 1.294e+07, Test loss: 7.995e+07, MSE(e): 1.208e-03, MSE(pi1): 6.856e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.757e-03\n",
      "Epoch 30000, Train loss: 1.295e+07, Test loss: 8.073e+07, MSE(e): 1.209e-03, MSE(pi1): 6.860e-02, MSE(pi2): 1.327e-03, MSE(pi3): 1.753e-03\n",
      "Epoch 30100, Train loss: 1.294e+07, Test loss: 8.004e+07, MSE(e): 1.208e-03, MSE(pi1): 6.852e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.756e-03\n",
      "Epoch 30200, Train loss: 1.294e+07, Test loss: 8.030e+07, MSE(e): 1.208e-03, MSE(pi1): 6.850e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.756e-03\n",
      "Epoch 30300, Train loss: 1.294e+07, Test loss: 8.013e+07, MSE(e): 1.208e-03, MSE(pi1): 6.848e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.756e-03\n",
      "Epoch 30400, Train loss: 1.294e+07, Test loss: 8.005e+07, MSE(e): 1.208e-03, MSE(pi1): 6.844e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.757e-03\n",
      "Epoch 30500, Train loss: 1.294e+07, Test loss: 8.022e+07, MSE(e): 1.208e-03, MSE(pi1): 6.844e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.756e-03\n",
      "Epoch 30600, Train loss: 1.294e+07, Test loss: 8.036e+07, MSE(e): 1.208e-03, MSE(pi1): 6.844e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.755e-03\n",
      "Epoch 30700, Train loss: 1.293e+07, Test loss: 8.030e+07, MSE(e): 1.207e-03, MSE(pi1): 6.840e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.756e-03\n",
      "Epoch 30800, Train loss: 1.294e+07, Test loss: 8.071e+07, MSE(e): 1.208e-03, MSE(pi1): 6.843e-02, MSE(pi2): 1.326e-03, MSE(pi3): 1.753e-03\n",
      "Epoch 30900, Train loss: 1.293e+07, Test loss: 8.039e+07, MSE(e): 1.207e-03, MSE(pi1): 6.837e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.756e-03\n",
      "Epoch 31000, Train loss: 1.293e+07, Test loss: 8.040e+07, MSE(e): 1.207e-03, MSE(pi1): 6.833e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.756e-03\n",
      "Epoch 31100, Train loss: 1.293e+07, Test loss: 8.048e+07, MSE(e): 1.207e-03, MSE(pi1): 6.833e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.755e-03\n",
      "Epoch 31200, Train loss: 1.293e+07, Test loss: 8.037e+07, MSE(e): 1.207e-03, MSE(pi1): 6.828e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.757e-03\n",
      "Epoch 31300, Train loss: 1.293e+07, Test loss: 8.057e+07, MSE(e): 1.207e-03, MSE(pi1): 6.829e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.755e-03\n",
      "Epoch 31400, Train loss: 1.293e+07, Test loss: 8.017e+07, MSE(e): 1.208e-03, MSE(pi1): 6.822e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.758e-03\n",
      "Epoch 31500, Train loss: 1.293e+07, Test loss: 8.066e+07, MSE(e): 1.207e-03, MSE(pi1): 6.826e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.755e-03\n",
      "Epoch 31600, Train loss: 1.293e+07, Test loss: 8.068e+07, MSE(e): 1.207e-03, MSE(pi1): 6.824e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.755e-03\n",
      "Epoch 31700, Train loss: 1.293e+07, Test loss: 8.074e+07, MSE(e): 1.207e-03, MSE(pi1): 6.822e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.755e-03\n",
      "Epoch 31800, Train loss: 1.292e+07, Test loss: 8.076e+07, MSE(e): 1.207e-03, MSE(pi1): 6.820e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.755e-03\n",
      "Epoch 31900, Train loss: 1.292e+07, Test loss: 8.082e+07, MSE(e): 1.207e-03, MSE(pi1): 6.819e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.755e-03\n",
      "Epoch 32000, Train loss: 1.292e+07, Test loss: 8.089e+07, MSE(e): 1.207e-03, MSE(pi1): 6.817e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.754e-03\n",
      "Epoch 32100, Train loss: 1.292e+07, Test loss: 8.092e+07, MSE(e): 1.207e-03, MSE(pi1): 6.815e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.754e-03\n",
      "Epoch 32200, Train loss: 1.292e+07, Test loss: 8.093e+07, MSE(e): 1.206e-03, MSE(pi1): 6.813e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.755e-03\n",
      "Epoch 32300, Train loss: 1.292e+07, Test loss: 8.101e+07, MSE(e): 1.206e-03, MSE(pi1): 6.812e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.754e-03\n",
      "Epoch 32400, Train loss: 1.292e+07, Test loss: 8.092e+07, MSE(e): 1.206e-03, MSE(pi1): 6.809e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.755e-03\n",
      "Epoch 32500, Train loss: 1.292e+07, Test loss: 8.110e+07, MSE(e): 1.206e-03, MSE(pi1): 6.808e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.754e-03\n",
      "Epoch 32600, Train loss: 1.292e+07, Test loss: 8.119e+07, MSE(e): 1.206e-03, MSE(pi1): 6.807e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.754e-03\n",
      "Epoch 32700, Train loss: 1.292e+07, Test loss: 8.120e+07, MSE(e): 1.206e-03, MSE(pi1): 6.805e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.754e-03\n",
      "Epoch 32800, Train loss: 1.292e+07, Test loss: 8.123e+07, MSE(e): 1.206e-03, MSE(pi1): 6.803e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.754e-03\n",
      "Epoch 32900, Train loss: 1.292e+07, Test loss: 8.124e+07, MSE(e): 1.206e-03, MSE(pi1): 6.801e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.754e-03\n",
      "Epoch 33000, Train loss: 1.291e+07, Test loss: 8.131e+07, MSE(e): 1.206e-03, MSE(pi1): 6.800e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.754e-03\n",
      "Epoch 33100, Train loss: 1.291e+07, Test loss: 8.141e+07, MSE(e): 1.206e-03, MSE(pi1): 6.798e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.753e-03\n",
      "Epoch 33200, Train loss: 1.291e+07, Test loss: 8.140e+07, MSE(e): 1.206e-03, MSE(pi1): 6.797e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.753e-03\n",
      "Epoch 33300, Train loss: 1.291e+07, Test loss: 8.172e+07, MSE(e): 1.206e-03, MSE(pi1): 6.798e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 33400, Train loss: 1.291e+07, Test loss: 8.148e+07, MSE(e): 1.206e-03, MSE(pi1): 6.793e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.753e-03\n",
      "Epoch 33500, Train loss: 1.291e+07, Test loss: 8.132e+07, MSE(e): 1.206e-03, MSE(pi1): 6.788e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.755e-03\n",
      "Epoch 33600, Train loss: 1.291e+07, Test loss: 8.157e+07, MSE(e): 1.206e-03, MSE(pi1): 6.790e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.753e-03\n",
      "Epoch 33700, Train loss: 1.291e+07, Test loss: 8.178e+07, MSE(e): 1.206e-03, MSE(pi1): 6.789e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 33800, Train loss: 1.291e+07, Test loss: 8.165e+07, MSE(e): 1.205e-03, MSE(pi1): 6.787e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.753e-03\n",
      "Epoch 33900, Train loss: 1.291e+07, Test loss: 8.169e+07, MSE(e): 1.205e-03, MSE(pi1): 6.785e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.753e-03\n",
      "Epoch 34000, Train loss: 1.291e+07, Test loss: 8.173e+07, MSE(e): 1.205e-03, MSE(pi1): 6.784e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.753e-03\n",
      "Epoch 34100, Train loss: 1.291e+07, Test loss: 8.184e+07, MSE(e): 1.205e-03, MSE(pi1): 6.783e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 34200, Train loss: 1.291e+07, Test loss: 8.180e+07, MSE(e): 1.205e-03, MSE(pi1): 6.780e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 34300, Train loss: 1.291e+07, Test loss: 8.185e+07, MSE(e): 1.205e-03, MSE(pi1): 6.778e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 34400, Train loss: 1.290e+07, Test loss: 8.191e+07, MSE(e): 1.205e-03, MSE(pi1): 6.777e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 34500, Train loss: 1.290e+07, Test loss: 8.192e+07, MSE(e): 1.205e-03, MSE(pi1): 6.775e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 34600, Train loss: 1.290e+07, Test loss: 8.199e+07, MSE(e): 1.205e-03, MSE(pi1): 6.774e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 34700, Train loss: 1.290e+07, Test loss: 8.207e+07, MSE(e): 1.205e-03, MSE(pi1): 6.773e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 34800, Train loss: 1.290e+07, Test loss: 8.207e+07, MSE(e): 1.205e-03, MSE(pi1): 6.771e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 34900, Train loss: 1.290e+07, Test loss: 8.205e+07, MSE(e): 1.205e-03, MSE(pi1): 6.768e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 35000, Train loss: 1.290e+07, Test loss: 8.215e+07, MSE(e): 1.205e-03, MSE(pi1): 6.768e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 35100, Train loss: 1.290e+07, Test loss: 8.227e+07, MSE(e): 1.205e-03, MSE(pi1): 6.766e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 35200, Train loss: 1.290e+07, Test loss: 8.223e+07, MSE(e): 1.205e-03, MSE(pi1): 6.764e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 35300, Train loss: 1.290e+07, Test loss: 8.231e+07, MSE(e): 1.205e-03, MSE(pi1): 6.764e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 35400, Train loss: 1.290e+07, Test loss: 8.233e+07, MSE(e): 1.205e-03, MSE(pi1): 6.761e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 35500, Train loss: 1.290e+07, Test loss: 8.234e+07, MSE(e): 1.205e-03, MSE(pi1): 6.759e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 35600, Train loss: 1.290e+07, Test loss: 8.243e+07, MSE(e): 1.205e-03, MSE(pi1): 6.758e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 35700, Train loss: 1.290e+07, Test loss: 8.246e+07, MSE(e): 1.204e-03, MSE(pi1): 6.757e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 35800, Train loss: 1.289e+07, Test loss: 8.247e+07, MSE(e): 1.204e-03, MSE(pi1): 6.755e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 35900, Train loss: 1.290e+07, Test loss: 8.239e+07, MSE(e): 1.205e-03, MSE(pi1): 6.750e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 36000, Train loss: 1.289e+07, Test loss: 8.255e+07, MSE(e): 1.204e-03, MSE(pi1): 6.752e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.750e-03\n",
      "Epoch 36100, Train loss: 1.290e+07, Test loss: 8.223e+07, MSE(e): 1.205e-03, MSE(pi1): 6.747e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.752e-03\n",
      "Epoch 36200, Train loss: 1.289e+07, Test loss: 8.264e+07, MSE(e): 1.204e-03, MSE(pi1): 6.749e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.750e-03\n",
      "Epoch 36300, Train loss: 1.289e+07, Test loss: 8.267e+07, MSE(e): 1.204e-03, MSE(pi1): 6.748e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.750e-03\n",
      "Epoch 36400, Train loss: 1.289e+07, Test loss: 8.264e+07, MSE(e): 1.204e-03, MSE(pi1): 6.744e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 36500, Train loss: 1.289e+07, Test loss: 8.274e+07, MSE(e): 1.204e-03, MSE(pi1): 6.744e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.750e-03\n",
      "Epoch 36600, Train loss: 1.289e+07, Test loss: 8.301e+07, MSE(e): 1.204e-03, MSE(pi1): 6.742e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.750e-03\n",
      "Epoch 36700, Train loss: 1.289e+07, Test loss: 8.282e+07, MSE(e): 1.204e-03, MSE(pi1): 6.741e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.750e-03\n",
      "Epoch 36800, Train loss: 1.290e+07, Test loss: 8.312e+07, MSE(e): 1.205e-03, MSE(pi1): 6.746e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.746e-03\n",
      "Epoch 36900, Train loss: 1.289e+07, Test loss: 8.290e+07, MSE(e): 1.204e-03, MSE(pi1): 6.739e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.749e-03\n",
      "Epoch 37000, Train loss: 1.289e+07, Test loss: 8.315e+07, MSE(e): 1.204e-03, MSE(pi1): 6.738e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.749e-03\n",
      "Epoch 37100, Train loss: 1.289e+07, Test loss: 8.297e+07, MSE(e): 1.204e-03, MSE(pi1): 6.735e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.749e-03\n",
      "Epoch 37200, Train loss: 1.289e+07, Test loss: 8.354e+07, MSE(e): 1.204e-03, MSE(pi1): 6.738e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.747e-03\n",
      "Epoch 37300, Train loss: 1.289e+07, Test loss: 8.304e+07, MSE(e): 1.204e-03, MSE(pi1): 6.732e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.749e-03\n",
      "Epoch 37400, Train loss: 1.289e+07, Test loss: 8.261e+07, MSE(e): 1.204e-03, MSE(pi1): 6.726e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.751e-03\n",
      "Epoch 37500, Train loss: 1.288e+07, Test loss: 8.312e+07, MSE(e): 1.204e-03, MSE(pi1): 6.730e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.749e-03\n",
      "Epoch 37600, Train loss: 1.288e+07, Test loss: 8.312e+07, MSE(e): 1.204e-03, MSE(pi1): 6.729e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.748e-03\n",
      "Epoch 37700, Train loss: 1.288e+07, Test loss: 8.319e+07, MSE(e): 1.204e-03, MSE(pi1): 6.727e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.748e-03\n",
      "Epoch 37800, Train loss: 1.288e+07, Test loss: 8.314e+07, MSE(e): 1.204e-03, MSE(pi1): 6.723e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.749e-03\n",
      "Epoch 37900, Train loss: 1.288e+07, Test loss: 8.326e+07, MSE(e): 1.203e-03, MSE(pi1): 6.724e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.748e-03\n",
      "Epoch 38000, Train loss: 1.290e+07, Test loss: 8.297e+07, MSE(e): 1.205e-03, MSE(pi1): 6.713e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.753e-03\n",
      "Epoch 38100, Train loss: 1.288e+07, Test loss: 8.334e+07, MSE(e): 1.203e-03, MSE(pi1): 6.721e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.748e-03\n",
      "Epoch 38200, Train loss: 1.288e+07, Test loss: 8.337e+07, MSE(e): 1.203e-03, MSE(pi1): 6.719e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.748e-03\n",
      "Epoch 38300, Train loss: 1.288e+07, Test loss: 8.370e+07, MSE(e): 1.204e-03, MSE(pi1): 6.723e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.745e-03\n",
      "Epoch 38400, Train loss: 1.288e+07, Test loss: 8.344e+07, MSE(e): 1.203e-03, MSE(pi1): 6.717e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.748e-03\n",
      "Epoch 38500, Train loss: 1.289e+07, Test loss: 8.431e+07, MSE(e): 1.204e-03, MSE(pi1): 6.723e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 38600, Train loss: 1.288e+07, Test loss: 8.350e+07, MSE(e): 1.203e-03, MSE(pi1): 6.713e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.747e-03\n",
      "Epoch 38700, Train loss: 1.294e+07, Test loss: 8.494e+07, MSE(e): 1.209e-03, MSE(pi1): 6.730e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.738e-03\n",
      "Epoch 38800, Train loss: 1.288e+07, Test loss: 8.357e+07, MSE(e): 1.203e-03, MSE(pi1): 6.711e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.747e-03\n",
      "Epoch 38900, Train loss: 1.288e+07, Test loss: 8.361e+07, MSE(e): 1.203e-03, MSE(pi1): 6.709e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.747e-03\n",
      "Epoch 39000, Train loss: 1.288e+07, Test loss: 8.356e+07, MSE(e): 1.203e-03, MSE(pi1): 6.707e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.747e-03\n",
      "Epoch 39100, Train loss: 1.288e+07, Test loss: 8.367e+07, MSE(e): 1.203e-03, MSE(pi1): 6.707e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.747e-03\n",
      "Epoch 39200, Train loss: 1.287e+07, Test loss: 8.380e+07, MSE(e): 1.203e-03, MSE(pi1): 6.704e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.747e-03\n",
      "Epoch 39300, Train loss: 1.287e+07, Test loss: 8.374e+07, MSE(e): 1.203e-03, MSE(pi1): 6.703e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.747e-03\n",
      "Epoch 39400, Train loss: 1.287e+07, Test loss: 8.365e+07, MSE(e): 1.203e-03, MSE(pi1): 6.702e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.747e-03\n",
      "Epoch 39500, Train loss: 1.287e+07, Test loss: 8.381e+07, MSE(e): 1.203e-03, MSE(pi1): 6.701e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.746e-03\n",
      "Epoch 39600, Train loss: 1.287e+07, Test loss: 8.370e+07, MSE(e): 1.203e-03, MSE(pi1): 6.698e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.747e-03\n",
      "Epoch 39700, Train loss: 1.287e+07, Test loss: 8.387e+07, MSE(e): 1.203e-03, MSE(pi1): 6.698e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.746e-03\n",
      "Epoch 39800, Train loss: 1.288e+07, Test loss: 8.437e+07, MSE(e): 1.203e-03, MSE(pi1): 6.701e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 39900, Train loss: 1.287e+07, Test loss: 8.394e+07, MSE(e): 1.203e-03, MSE(pi1): 6.695e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.746e-03\n",
      "Epoch 40000, Train loss: 1.288e+07, Test loss: 8.455e+07, MSE(e): 1.203e-03, MSE(pi1): 6.699e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 40100, Train loss: 1.287e+07, Test loss: 8.398e+07, MSE(e): 1.203e-03, MSE(pi1): 6.692e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.746e-03\n",
      "Epoch 40200, Train loss: 1.287e+07, Test loss: 8.403e+07, MSE(e): 1.203e-03, MSE(pi1): 6.691e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.745e-03\n",
      "Epoch 40300, Train loss: 1.287e+07, Test loss: 8.406e+07, MSE(e): 1.203e-03, MSE(pi1): 6.690e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.745e-03\n",
      "Epoch 40400, Train loss: 1.287e+07, Test loss: 8.446e+07, MSE(e): 1.203e-03, MSE(pi1): 6.692e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 40500, Train loss: 1.287e+07, Test loss: 8.411e+07, MSE(e): 1.202e-03, MSE(pi1): 6.687e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.745e-03\n",
      "Epoch 40600, Train loss: 1.287e+07, Test loss: 8.429e+07, MSE(e): 1.203e-03, MSE(pi1): 6.689e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 40700, Train loss: 1.287e+07, Test loss: 8.417e+07, MSE(e): 1.202e-03, MSE(pi1): 6.684e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.745e-03\n",
      "Epoch 40800, Train loss: 1.287e+07, Test loss: 8.423e+07, MSE(e): 1.202e-03, MSE(pi1): 6.682e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.745e-03\n",
      "Epoch 40900, Train loss: 1.287e+07, Test loss: 8.423e+07, MSE(e): 1.202e-03, MSE(pi1): 6.681e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.745e-03\n",
      "Epoch 41000, Train loss: 1.287e+07, Test loss: 8.430e+07, MSE(e): 1.202e-03, MSE(pi1): 6.683e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 41100, Train loss: 1.286e+07, Test loss: 8.430e+07, MSE(e): 1.202e-03, MSE(pi1): 6.679e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.744e-03\n",
      "Epoch 41200, Train loss: 1.287e+07, Test loss: 8.451e+07, MSE(e): 1.202e-03, MSE(pi1): 6.680e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 41300, Train loss: 1.286e+07, Test loss: 8.435e+07, MSE(e): 1.202e-03, MSE(pi1): 6.676e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.744e-03\n",
      "Epoch 41400, Train loss: 1.286e+07, Test loss: 8.450e+07, MSE(e): 1.202e-03, MSE(pi1): 6.676e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 41500, Train loss: 1.286e+07, Test loss: 8.441e+07, MSE(e): 1.202e-03, MSE(pi1): 6.673e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.744e-03\n",
      "Epoch 41600, Train loss: 1.286e+07, Test loss: 8.437e+07, MSE(e): 1.202e-03, MSE(pi1): 6.671e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.744e-03\n",
      "Epoch 41700, Train loss: 1.286e+07, Test loss: 8.438e+07, MSE(e): 1.202e-03, MSE(pi1): 6.670e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.744e-03\n",
      "Epoch 41800, Train loss: 1.286e+07, Test loss: 8.449e+07, MSE(e): 1.202e-03, MSE(pi1): 6.669e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 41900, Train loss: 1.286e+07, Test loss: 8.460e+07, MSE(e): 1.202e-03, MSE(pi1): 6.672e-02, MSE(pi2): 1.323e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 42000, Train loss: 1.286e+07, Test loss: 8.454e+07, MSE(e): 1.202e-03, MSE(pi1): 6.666e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 42100, Train loss: 1.286e+07, Test loss: 8.447e+07, MSE(e): 1.202e-03, MSE(pi1): 6.664e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.744e-03\n",
      "Epoch 42200, Train loss: 1.286e+07, Test loss: 8.460e+07, MSE(e): 1.202e-03, MSE(pi1): 6.664e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 42300, Train loss: 1.286e+07, Test loss: 8.469e+07, MSE(e): 1.202e-03, MSE(pi1): 6.663e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.742e-03\n",
      "Epoch 42400, Train loss: 1.286e+07, Test loss: 8.465e+07, MSE(e): 1.202e-03, MSE(pi1): 6.661e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.743e-03\n",
      "Epoch 42500, Train loss: 1.286e+07, Test loss: 8.450e+07, MSE(e): 1.202e-03, MSE(pi1): 6.661e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.742e-03\n",
      "Epoch 42600, Train loss: 1.286e+07, Test loss: 8.471e+07, MSE(e): 1.202e-03, MSE(pi1): 6.658e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.742e-03\n",
      "Epoch 42700, Train loss: 1.286e+07, Test loss: 8.450e+07, MSE(e): 1.202e-03, MSE(pi1): 6.658e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.742e-03\n",
      "Epoch 42800, Train loss: 1.286e+07, Test loss: 8.476e+07, MSE(e): 1.202e-03, MSE(pi1): 6.656e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.742e-03\n",
      "Epoch 42900, Train loss: 1.287e+07, Test loss: 8.501e+07, MSE(e): 1.203e-03, MSE(pi1): 6.664e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.737e-03\n",
      "Epoch 43000, Train loss: 1.286e+07, Test loss: 8.480e+07, MSE(e): 1.202e-03, MSE(pi1): 6.653e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.742e-03\n",
      "Epoch 43100, Train loss: 1.285e+07, Test loss: 8.483e+07, MSE(e): 1.202e-03, MSE(pi1): 6.652e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.742e-03\n",
      "Epoch 43200, Train loss: 1.285e+07, Test loss: 8.490e+07, MSE(e): 1.202e-03, MSE(pi1): 6.651e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 43300, Train loss: 1.285e+07, Test loss: 8.488e+07, MSE(e): 1.201e-03, MSE(pi1): 6.649e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 43400, Train loss: 1.285e+07, Test loss: 8.496e+07, MSE(e): 1.201e-03, MSE(pi1): 6.648e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 43500, Train loss: 1.285e+07, Test loss: 8.493e+07, MSE(e): 1.201e-03, MSE(pi1): 6.647e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 43600, Train loss: 1.285e+07, Test loss: 8.498e+07, MSE(e): 1.201e-03, MSE(pi1): 6.646e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 43700, Train loss: 1.285e+07, Test loss: 8.499e+07, MSE(e): 1.201e-03, MSE(pi1): 6.644e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 43800, Train loss: 1.285e+07, Test loss: 8.500e+07, MSE(e): 1.201e-03, MSE(pi1): 6.643e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 43900, Train loss: 1.285e+07, Test loss: 8.499e+07, MSE(e): 1.201e-03, MSE(pi1): 6.641e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 44000, Train loss: 1.285e+07, Test loss: 8.505e+07, MSE(e): 1.201e-03, MSE(pi1): 6.641e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.740e-03\n",
      "Epoch 44100, Train loss: 1.285e+07, Test loss: 8.495e+07, MSE(e): 1.201e-03, MSE(pi1): 6.637e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 44200, Train loss: 1.285e+07, Test loss: 8.509e+07, MSE(e): 1.201e-03, MSE(pi1): 6.638e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.740e-03\n",
      "Epoch 44300, Train loss: 1.285e+07, Test loss: 8.502e+07, MSE(e): 1.201e-03, MSE(pi1): 6.635e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 44400, Train loss: 1.285e+07, Test loss: 8.514e+07, MSE(e): 1.201e-03, MSE(pi1): 6.636e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.740e-03\n",
      "Epoch 44500, Train loss: 1.285e+07, Test loss: 8.479e+07, MSE(e): 1.201e-03, MSE(pi1): 6.631e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.741e-03\n",
      "Epoch 44600, Train loss: 1.285e+07, Test loss: 8.519e+07, MSE(e): 1.201e-03, MSE(pi1): 6.633e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.739e-03\n",
      "Epoch 44700, Train loss: 1.291e+07, Test loss: 8.676e+07, MSE(e): 1.207e-03, MSE(pi1): 6.650e-02, MSE(pi2): 1.330e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 44800, Train loss: 1.285e+07, Test loss: 8.522e+07, MSE(e): 1.201e-03, MSE(pi1): 6.631e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.739e-03\n",
      "Epoch 44900, Train loss: 1.285e+07, Test loss: 8.525e+07, MSE(e): 1.201e-03, MSE(pi1): 6.630e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.739e-03\n",
      "Epoch 45000, Train loss: 1.285e+07, Test loss: 8.539e+07, MSE(e): 1.201e-03, MSE(pi1): 6.630e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.738e-03\n",
      "Epoch 45100, Train loss: 1.285e+07, Test loss: 8.530e+07, MSE(e): 1.201e-03, MSE(pi1): 6.627e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.739e-03\n",
      "Epoch 45200, Train loss: 1.285e+07, Test loss: 8.536e+07, MSE(e): 1.201e-03, MSE(pi1): 6.627e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.738e-03\n",
      "Epoch 45300, Train loss: 1.285e+07, Test loss: 8.534e+07, MSE(e): 1.201e-03, MSE(pi1): 6.625e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.738e-03\n",
      "Epoch 45400, Train loss: 1.284e+07, Test loss: 8.541e+07, MSE(e): 1.201e-03, MSE(pi1): 6.624e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.738e-03\n",
      "Epoch 45500, Train loss: 1.284e+07, Test loss: 8.539e+07, MSE(e): 1.201e-03, MSE(pi1): 6.622e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.738e-03\n",
      "Epoch 45600, Train loss: 1.284e+07, Test loss: 8.553e+07, MSE(e): 1.201e-03, MSE(pi1): 6.622e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.737e-03\n",
      "Epoch 45700, Train loss: 1.284e+07, Test loss: 8.543e+07, MSE(e): 1.201e-03, MSE(pi1): 6.620e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.738e-03\n",
      "Epoch 45800, Train loss: 1.284e+07, Test loss: 8.558e+07, MSE(e): 1.201e-03, MSE(pi1): 6.622e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.736e-03\n",
      "Epoch 45900, Train loss: 1.284e+07, Test loss: 8.547e+07, MSE(e): 1.201e-03, MSE(pi1): 6.618e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.737e-03\n",
      "Epoch 46000, Train loss: 1.284e+07, Test loss: 8.533e+07, MSE(e): 1.201e-03, MSE(pi1): 6.613e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.739e-03\n",
      "Epoch 46100, Train loss: 1.284e+07, Test loss: 8.551e+07, MSE(e): 1.201e-03, MSE(pi1): 6.616e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.737e-03\n",
      "Epoch 46200, Train loss: 1.289e+07, Test loss: 8.417e+07, MSE(e): 1.205e-03, MSE(pi1): 6.600e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.745e-03\n",
      "Epoch 46300, Train loss: 1.284e+07, Test loss: 8.556e+07, MSE(e): 1.201e-03, MSE(pi1): 6.613e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.737e-03\n",
      "Epoch 46400, Train loss: 1.284e+07, Test loss: 8.558e+07, MSE(e): 1.201e-03, MSE(pi1): 6.612e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.737e-03\n",
      "Epoch 46500, Train loss: 1.284e+07, Test loss: 8.552e+07, MSE(e): 1.201e-03, MSE(pi1): 6.610e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.737e-03\n",
      "Epoch 46600, Train loss: 1.284e+07, Test loss: 8.563e+07, MSE(e): 1.201e-03, MSE(pi1): 6.610e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.736e-03\n",
      "Epoch 46700, Train loss: 1.284e+07, Test loss: 8.566e+07, MSE(e): 1.200e-03, MSE(pi1): 6.609e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.736e-03\n",
      "Epoch 46800, Train loss: 1.284e+07, Test loss: 8.567e+07, MSE(e): 1.200e-03, MSE(pi1): 6.608e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.736e-03\n",
      "Epoch 46900, Train loss: 1.284e+07, Test loss: 8.571e+07, MSE(e): 1.200e-03, MSE(pi1): 6.607e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.736e-03\n",
      "Epoch 47000, Train loss: 1.284e+07, Test loss: 8.570e+07, MSE(e): 1.200e-03, MSE(pi1): 6.606e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.736e-03\n",
      "Epoch 47100, Train loss: 1.284e+07, Test loss: 8.579e+07, MSE(e): 1.200e-03, MSE(pi1): 6.606e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.735e-03\n",
      "Epoch 47200, Train loss: 1.284e+07, Test loss: 8.574e+07, MSE(e): 1.200e-03, MSE(pi1): 6.604e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.736e-03\n",
      "Epoch 47300, Train loss: 1.284e+07, Test loss: 8.608e+07, MSE(e): 1.201e-03, MSE(pi1): 6.607e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.733e-03\n",
      "Epoch 47400, Train loss: 1.284e+07, Test loss: 8.578e+07, MSE(e): 1.200e-03, MSE(pi1): 6.602e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.735e-03\n",
      "Epoch 47500, Train loss: 1.284e+07, Test loss: 8.589e+07, MSE(e): 1.200e-03, MSE(pi1): 6.601e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.735e-03\n",
      "Epoch 47600, Train loss: 1.284e+07, Test loss: 8.582e+07, MSE(e): 1.200e-03, MSE(pi1): 6.600e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.735e-03\n",
      "Epoch 47700, Train loss: 1.284e+07, Test loss: 8.568e+07, MSE(e): 1.200e-03, MSE(pi1): 6.597e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.736e-03\n",
      "Epoch 47800, Train loss: 1.284e+07, Test loss: 8.586e+07, MSE(e): 1.200e-03, MSE(pi1): 6.598e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.735e-03\n",
      "Epoch 47900, Train loss: 1.284e+07, Test loss: 8.585e+07, MSE(e): 1.200e-03, MSE(pi1): 6.596e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.735e-03\n",
      "Epoch 48000, Train loss: 1.283e+07, Test loss: 8.590e+07, MSE(e): 1.200e-03, MSE(pi1): 6.596e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.735e-03\n",
      "Epoch 48100, Train loss: 1.285e+07, Test loss: 8.569e+07, MSE(e): 1.202e-03, MSE(pi1): 6.586e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.740e-03\n",
      "Epoch 48200, Train loss: 1.283e+07, Test loss: 8.595e+07, MSE(e): 1.200e-03, MSE(pi1): 6.594e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 48300, Train loss: 1.283e+07, Test loss: 8.596e+07, MSE(e): 1.200e-03, MSE(pi1): 6.593e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 48400, Train loss: 1.283e+07, Test loss: 8.598e+07, MSE(e): 1.200e-03, MSE(pi1): 6.592e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 48500, Train loss: 1.283e+07, Test loss: 8.599e+07, MSE(e): 1.200e-03, MSE(pi1): 6.591e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 48600, Train loss: 1.283e+07, Test loss: 8.603e+07, MSE(e): 1.200e-03, MSE(pi1): 6.591e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 48700, Train loss: 1.283e+07, Test loss: 8.604e+07, MSE(e): 1.200e-03, MSE(pi1): 6.590e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 48800, Train loss: 1.283e+07, Test loss: 8.611e+07, MSE(e): 1.200e-03, MSE(pi1): 6.589e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.733e-03\n",
      "Epoch 48900, Train loss: 1.283e+07, Test loss: 8.608e+07, MSE(e): 1.200e-03, MSE(pi1): 6.588e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 49000, Train loss: 1.283e+07, Test loss: 8.609e+07, MSE(e): 1.200e-03, MSE(pi1): 6.587e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.733e-03\n",
      "Epoch 49100, Train loss: 1.283e+07, Test loss: 8.608e+07, MSE(e): 1.200e-03, MSE(pi1): 6.585e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 49200, Train loss: 1.283e+07, Test loss: 8.613e+07, MSE(e): 1.200e-03, MSE(pi1): 6.585e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.733e-03\n",
      "Epoch 49300, Train loss: 1.285e+07, Test loss: 8.513e+07, MSE(e): 1.202e-03, MSE(pi1): 6.575e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.739e-03\n",
      "Epoch 49400, Train loss: 1.283e+07, Test loss: 8.617e+07, MSE(e): 1.200e-03, MSE(pi1): 6.584e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.733e-03\n",
      "Epoch 49500, Train loss: 1.283e+07, Test loss: 8.619e+07, MSE(e): 1.200e-03, MSE(pi1): 6.583e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.733e-03\n",
      "Epoch 49600, Train loss: 1.283e+07, Test loss: 8.607e+07, MSE(e): 1.200e-03, MSE(pi1): 6.580e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 49700, Train loss: 1.283e+07, Test loss: 8.622e+07, MSE(e): 1.200e-03, MSE(pi1): 6.581e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.733e-03\n",
      "Epoch 49800, Train loss: 1.283e+07, Test loss: 8.656e+07, MSE(e): 1.200e-03, MSE(pi1): 6.583e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 49900, Train loss: 1.283e+07, Test loss: 8.626e+07, MSE(e): 1.200e-03, MSE(pi1): 6.579e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.733e-03\n",
      "Epoch 50000, Train loss: 1.283e+07, Test loss: 8.631e+07, MSE(e): 1.200e-03, MSE(pi1): 6.576e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 50100, Train loss: 1.283e+07, Test loss: 8.629e+07, MSE(e): 1.200e-03, MSE(pi1): 6.578e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 50200, Train loss: 1.283e+07, Test loss: 8.619e+07, MSE(e): 1.200e-03, MSE(pi1): 6.576e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.733e-03\n",
      "Epoch 50300, Train loss: 1.283e+07, Test loss: 8.633e+07, MSE(e): 1.200e-03, MSE(pi1): 6.576e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 50400, Train loss: 1.283e+07, Test loss: 8.667e+07, MSE(e): 1.200e-03, MSE(pi1): 6.581e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 50500, Train loss: 1.283e+07, Test loss: 8.637e+07, MSE(e): 1.200e-03, MSE(pi1): 6.574e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 50600, Train loss: 1.283e+07, Test loss: 8.639e+07, MSE(e): 1.200e-03, MSE(pi1): 6.574e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 50700, Train loss: 1.283e+07, Test loss: 8.559e+07, MSE(e): 1.200e-03, MSE(pi1): 6.568e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 50800, Train loss: 1.282e+07, Test loss: 8.642e+07, MSE(e): 1.199e-03, MSE(pi1): 6.572e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 50900, Train loss: 1.282e+07, Test loss: 8.644e+07, MSE(e): 1.199e-03, MSE(pi1): 6.571e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 51000, Train loss: 1.282e+07, Test loss: 8.645e+07, MSE(e): 1.199e-03, MSE(pi1): 6.570e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 51100, Train loss: 1.282e+07, Test loss: 8.645e+07, MSE(e): 1.199e-03, MSE(pi1): 6.569e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 51200, Train loss: 1.282e+07, Test loss: 8.649e+07, MSE(e): 1.199e-03, MSE(pi1): 6.569e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 51300, Train loss: 1.282e+07, Test loss: 8.666e+07, MSE(e): 1.199e-03, MSE(pi1): 6.569e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 51400, Train loss: 1.282e+07, Test loss: 8.652e+07, MSE(e): 1.199e-03, MSE(pi1): 6.567e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 51500, Train loss: 1.282e+07, Test loss: 8.655e+07, MSE(e): 1.199e-03, MSE(pi1): 6.567e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 51600, Train loss: 1.283e+07, Test loss: 8.539e+07, MSE(e): 1.200e-03, MSE(pi1): 6.558e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.735e-03\n",
      "Epoch 51700, Train loss: 1.282e+07, Test loss: 8.658e+07, MSE(e): 1.199e-03, MSE(pi1): 6.565e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 51800, Train loss: 1.282e+07, Test loss: 8.660e+07, MSE(e): 1.199e-03, MSE(pi1): 6.564e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 51900, Train loss: 1.282e+07, Test loss: 8.662e+07, MSE(e): 1.199e-03, MSE(pi1): 6.564e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 52000, Train loss: 1.282e+07, Test loss: 8.637e+07, MSE(e): 1.199e-03, MSE(pi1): 6.564e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 52100, Train loss: 1.282e+07, Test loss: 8.665e+07, MSE(e): 1.199e-03, MSE(pi1): 6.562e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 52200, Train loss: 1.282e+07, Test loss: 8.667e+07, MSE(e): 1.199e-03, MSE(pi1): 6.561e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 52300, Train loss: 1.282e+07, Test loss: 8.669e+07, MSE(e): 1.199e-03, MSE(pi1): 6.561e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 52400, Train loss: 1.282e+07, Test loss: 8.673e+07, MSE(e): 1.199e-03, MSE(pi1): 6.560e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 52500, Train loss: 1.282e+07, Test loss: 8.672e+07, MSE(e): 1.199e-03, MSE(pi1): 6.559e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 52600, Train loss: 1.282e+07, Test loss: 8.651e+07, MSE(e): 1.199e-03, MSE(pi1): 6.558e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 52700, Train loss: 1.282e+07, Test loss: 8.676e+07, MSE(e): 1.199e-03, MSE(pi1): 6.558e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 52800, Train loss: 1.282e+07, Test loss: 8.677e+07, MSE(e): 1.199e-03, MSE(pi1): 6.557e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 52900, Train loss: 1.282e+07, Test loss: 8.684e+07, MSE(e): 1.199e-03, MSE(pi1): 6.555e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.731e-03\n",
      "Epoch 53000, Train loss: 1.282e+07, Test loss: 8.681e+07, MSE(e): 1.199e-03, MSE(pi1): 6.555e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 53100, Train loss: 1.282e+07, Test loss: 8.687e+07, MSE(e): 1.199e-03, MSE(pi1): 6.555e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 53200, Train loss: 1.282e+07, Test loss: 8.682e+07, MSE(e): 1.199e-03, MSE(pi1): 6.554e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 53300, Train loss: 1.282e+07, Test loss: 8.687e+07, MSE(e): 1.199e-03, MSE(pi1): 6.553e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 53400, Train loss: 1.282e+07, Test loss: 8.636e+07, MSE(e): 1.199e-03, MSE(pi1): 6.548e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.732e-03\n",
      "Epoch 53500, Train loss: 1.282e+07, Test loss: 8.688e+07, MSE(e): 1.199e-03, MSE(pi1): 6.551e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 53600, Train loss: 1.282e+07, Test loss: 8.692e+07, MSE(e): 1.199e-03, MSE(pi1): 6.551e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 53700, Train loss: 1.282e+07, Test loss: 8.690e+07, MSE(e): 1.199e-03, MSE(pi1): 6.550e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 53800, Train loss: 1.282e+07, Test loss: 8.695e+07, MSE(e): 1.199e-03, MSE(pi1): 6.549e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 53900, Train loss: 1.282e+07, Test loss: 8.699e+07, MSE(e): 1.199e-03, MSE(pi1): 6.550e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 54000, Train loss: 1.282e+07, Test loss: 8.698e+07, MSE(e): 1.199e-03, MSE(pi1): 6.548e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 54100, Train loss: 1.281e+07, Test loss: 8.704e+07, MSE(e): 1.199e-03, MSE(pi1): 6.548e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 54200, Train loss: 1.281e+07, Test loss: 8.702e+07, MSE(e): 1.199e-03, MSE(pi1): 6.547e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 54300, Train loss: 1.281e+07, Test loss: 8.699e+07, MSE(e): 1.199e-03, MSE(pi1): 6.545e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 54400, Train loss: 1.281e+07, Test loss: 8.705e+07, MSE(e): 1.199e-03, MSE(pi1): 6.545e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 54500, Train loss: 1.281e+07, Test loss: 8.719e+07, MSE(e): 1.199e-03, MSE(pi1): 6.546e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.728e-03\n",
      "Epoch 54600, Train loss: 1.281e+07, Test loss: 8.709e+07, MSE(e): 1.199e-03, MSE(pi1): 6.544e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 54700, Train loss: 1.281e+07, Test loss: 8.724e+07, MSE(e): 1.199e-03, MSE(pi1): 6.543e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 54800, Train loss: 1.281e+07, Test loss: 8.712e+07, MSE(e): 1.199e-03, MSE(pi1): 6.542e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 54900, Train loss: 1.281e+07, Test loss: 8.698e+07, MSE(e): 1.199e-03, MSE(pi1): 6.540e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 55000, Train loss: 1.281e+07, Test loss: 8.715e+07, MSE(e): 1.199e-03, MSE(pi1): 6.541e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 55100, Train loss: 1.281e+07, Test loss: 8.717e+07, MSE(e): 1.198e-03, MSE(pi1): 6.540e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 55200, Train loss: 1.281e+07, Test loss: 8.690e+07, MSE(e): 1.199e-03, MSE(pi1): 6.536e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 55300, Train loss: 1.281e+07, Test loss: 8.721e+07, MSE(e): 1.198e-03, MSE(pi1): 6.539e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.728e-03\n",
      "Epoch 55400, Train loss: 1.283e+07, Test loss: 8.811e+07, MSE(e): 1.201e-03, MSE(pi1): 6.549e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 55500, Train loss: 1.281e+07, Test loss: 8.724e+07, MSE(e): 1.198e-03, MSE(pi1): 6.537e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.728e-03\n",
      "Epoch 55600, Train loss: 1.281e+07, Test loss: 8.729e+07, MSE(e): 1.198e-03, MSE(pi1): 6.537e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.728e-03\n",
      "Epoch 55700, Train loss: 1.281e+07, Test loss: 8.728e+07, MSE(e): 1.198e-03, MSE(pi1): 6.536e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.728e-03\n",
      "Epoch 55800, Train loss: 1.281e+07, Test loss: 8.729e+07, MSE(e): 1.198e-03, MSE(pi1): 6.535e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.728e-03\n",
      "Epoch 55900, Train loss: 1.281e+07, Test loss: 8.737e+07, MSE(e): 1.198e-03, MSE(pi1): 6.535e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.728e-03\n",
      "Epoch 56000, Train loss: 1.281e+07, Test loss: 8.733e+07, MSE(e): 1.198e-03, MSE(pi1): 6.534e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.728e-03\n",
      "Epoch 56100, Train loss: 1.281e+07, Test loss: 8.725e+07, MSE(e): 1.198e-03, MSE(pi1): 6.532e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.729e-03\n",
      "Epoch 56200, Train loss: 1.281e+07, Test loss: 8.736e+07, MSE(e): 1.198e-03, MSE(pi1): 6.532e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.728e-03\n",
      "Epoch 56300, Train loss: 1.281e+07, Test loss: 8.738e+07, MSE(e): 1.198e-03, MSE(pi1): 6.532e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.727e-03\n",
      "Epoch 56400, Train loss: 1.281e+07, Test loss: 8.684e+07, MSE(e): 1.199e-03, MSE(pi1): 6.526e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 56500, Train loss: 1.281e+07, Test loss: 8.741e+07, MSE(e): 1.198e-03, MSE(pi1): 6.530e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.727e-03\n",
      "Epoch 56600, Train loss: 1.281e+07, Test loss: 8.705e+07, MSE(e): 1.198e-03, MSE(pi1): 6.531e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.727e-03\n",
      "Epoch 56700, Train loss: 1.281e+07, Test loss: 8.746e+07, MSE(e): 1.198e-03, MSE(pi1): 6.529e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.727e-03\n",
      "Epoch 56800, Train loss: 1.281e+07, Test loss: 8.741e+07, MSE(e): 1.198e-03, MSE(pi1): 6.528e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.727e-03\n",
      "Epoch 56900, Train loss: 1.281e+07, Test loss: 8.751e+07, MSE(e): 1.198e-03, MSE(pi1): 6.528e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.727e-03\n",
      "Epoch 57000, Train loss: 1.281e+07, Test loss: 8.798e+07, MSE(e): 1.198e-03, MSE(pi1): 6.531e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 57100, Train loss: 1.281e+07, Test loss: 8.751e+07, MSE(e): 1.198e-03, MSE(pi1): 6.526e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.727e-03\n",
      "Epoch 57200, Train loss: 1.281e+07, Test loss: 8.776e+07, MSE(e): 1.198e-03, MSE(pi1): 6.527e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.726e-03\n",
      "Epoch 57300, Train loss: 1.281e+07, Test loss: 8.755e+07, MSE(e): 1.198e-03, MSE(pi1): 6.525e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.727e-03\n",
      "Epoch 57400, Train loss: 1.281e+07, Test loss: 8.767e+07, MSE(e): 1.198e-03, MSE(pi1): 6.525e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.726e-03\n",
      "Epoch 57500, Train loss: 1.280e+07, Test loss: 8.761e+07, MSE(e): 1.198e-03, MSE(pi1): 6.524e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.727e-03\n",
      "Epoch 57600, Train loss: 1.281e+07, Test loss: 8.737e+07, MSE(e): 1.198e-03, MSE(pi1): 6.521e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.728e-03\n",
      "Epoch 57700, Train loss: 1.280e+07, Test loss: 8.762e+07, MSE(e): 1.198e-03, MSE(pi1): 6.522e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.727e-03\n",
      "Epoch 57800, Train loss: 1.280e+07, Test loss: 8.810e+07, MSE(e): 1.198e-03, MSE(pi1): 6.523e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 57900, Train loss: 1.280e+07, Test loss: 8.766e+07, MSE(e): 1.198e-03, MSE(pi1): 6.521e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.726e-03\n",
      "Epoch 58000, Train loss: 1.281e+07, Test loss: 8.787e+07, MSE(e): 1.198e-03, MSE(pi1): 6.524e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 58100, Train loss: 1.280e+07, Test loss: 8.770e+07, MSE(e): 1.198e-03, MSE(pi1): 6.520e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.726e-03\n",
      "Epoch 58200, Train loss: 1.284e+07, Test loss: 8.641e+07, MSE(e): 1.202e-03, MSE(pi1): 6.504e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.734e-03\n",
      "Epoch 58300, Train loss: 1.280e+07, Test loss: 8.774e+07, MSE(e): 1.198e-03, MSE(pi1): 6.518e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.726e-03\n",
      "Epoch 58400, Train loss: 1.280e+07, Test loss: 8.786e+07, MSE(e): 1.198e-03, MSE(pi1): 6.518e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 58500, Train loss: 1.280e+07, Test loss: 8.777e+07, MSE(e): 1.198e-03, MSE(pi1): 6.517e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.726e-03\n",
      "Epoch 58600, Train loss: 1.281e+07, Test loss: 8.861e+07, MSE(e): 1.198e-03, MSE(pi1): 6.522e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 58700, Train loss: 1.280e+07, Test loss: 8.781e+07, MSE(e): 1.198e-03, MSE(pi1): 6.515e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.726e-03\n",
      "Epoch 58800, Train loss: 1.280e+07, Test loss: 8.769e+07, MSE(e): 1.198e-03, MSE(pi1): 6.514e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.726e-03\n",
      "Epoch 58900, Train loss: 1.280e+07, Test loss: 8.784e+07, MSE(e): 1.198e-03, MSE(pi1): 6.514e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.726e-03\n",
      "Epoch 59000, Train loss: 1.280e+07, Test loss: 8.786e+07, MSE(e): 1.198e-03, MSE(pi1): 6.513e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 59100, Train loss: 1.280e+07, Test loss: 8.798e+07, MSE(e): 1.198e-03, MSE(pi1): 6.514e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 59200, Train loss: 1.280e+07, Test loss: 8.789e+07, MSE(e): 1.198e-03, MSE(pi1): 6.512e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 59300, Train loss: 1.280e+07, Test loss: 8.782e+07, MSE(e): 1.198e-03, MSE(pi1): 6.510e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.726e-03\n",
      "Epoch 59400, Train loss: 1.280e+07, Test loss: 8.793e+07, MSE(e): 1.198e-03, MSE(pi1): 6.511e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 59500, Train loss: 1.280e+07, Test loss: 8.797e+07, MSE(e): 1.198e-03, MSE(pi1): 6.511e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 59600, Train loss: 1.280e+07, Test loss: 8.793e+07, MSE(e): 1.198e-03, MSE(pi1): 6.509e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 59700, Train loss: 1.280e+07, Test loss: 8.796e+07, MSE(e): 1.198e-03, MSE(pi1): 6.509e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 59800, Train loss: 1.284e+07, Test loss: 8.938e+07, MSE(e): 1.201e-03, MSE(pi1): 6.522e-02, MSE(pi2): 1.325e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 59900, Train loss: 1.280e+07, Test loss: 8.801e+07, MSE(e): 1.198e-03, MSE(pi1): 6.507e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 60000, Train loss: 1.280e+07, Test loss: 8.840e+07, MSE(e): 1.198e-03, MSE(pi1): 6.506e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 60100, Train loss: 1.280e+07, Test loss: 8.806e+07, MSE(e): 1.197e-03, MSE(pi1): 6.506e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 60200, Train loss: 1.280e+07, Test loss: 8.798e+07, MSE(e): 1.197e-03, MSE(pi1): 6.505e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.725e-03\n",
      "Epoch 60300, Train loss: 1.280e+07, Test loss: 8.810e+07, MSE(e): 1.197e-03, MSE(pi1): 6.505e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 60400, Train loss: 1.280e+07, Test loss: 8.811e+07, MSE(e): 1.197e-03, MSE(pi1): 6.504e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 60500, Train loss: 1.280e+07, Test loss: 8.822e+07, MSE(e): 1.198e-03, MSE(pi1): 6.507e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 60600, Train loss: 1.280e+07, Test loss: 8.814e+07, MSE(e): 1.197e-03, MSE(pi1): 6.503e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 60700, Train loss: 1.280e+07, Test loss: 8.832e+07, MSE(e): 1.197e-03, MSE(pi1): 6.504e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 60800, Train loss: 1.280e+07, Test loss: 8.819e+07, MSE(e): 1.197e-03, MSE(pi1): 6.502e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 60900, Train loss: 1.280e+07, Test loss: 8.820e+07, MSE(e): 1.197e-03, MSE(pi1): 6.501e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 61000, Train loss: 1.280e+07, Test loss: 8.826e+07, MSE(e): 1.197e-03, MSE(pi1): 6.501e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 61100, Train loss: 1.280e+07, Test loss: 8.823e+07, MSE(e): 1.197e-03, MSE(pi1): 6.500e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 61200, Train loss: 1.280e+07, Test loss: 8.850e+07, MSE(e): 1.198e-03, MSE(pi1): 6.503e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 61300, Train loss: 1.279e+07, Test loss: 8.827e+07, MSE(e): 1.197e-03, MSE(pi1): 6.499e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 61400, Train loss: 1.279e+07, Test loss: 8.824e+07, MSE(e): 1.197e-03, MSE(pi1): 6.498e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 61500, Train loss: 1.279e+07, Test loss: 8.831e+07, MSE(e): 1.197e-03, MSE(pi1): 6.497e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 61600, Train loss: 1.279e+07, Test loss: 8.846e+07, MSE(e): 1.197e-03, MSE(pi1): 6.498e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 61700, Train loss: 1.279e+07, Test loss: 8.834e+07, MSE(e): 1.197e-03, MSE(pi1): 6.496e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 61800, Train loss: 1.279e+07, Test loss: 8.852e+07, MSE(e): 1.197e-03, MSE(pi1): 6.497e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 61900, Train loss: 1.279e+07, Test loss: 8.838e+07, MSE(e): 1.197e-03, MSE(pi1): 6.495e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 62000, Train loss: 1.279e+07, Test loss: 8.808e+07, MSE(e): 1.197e-03, MSE(pi1): 6.493e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 62100, Train loss: 1.279e+07, Test loss: 8.841e+07, MSE(e): 1.197e-03, MSE(pi1): 6.493e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 62200, Train loss: 1.283e+07, Test loss: 8.725e+07, MSE(e): 1.200e-03, MSE(pi1): 6.480e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.730e-03\n",
      "Epoch 62300, Train loss: 1.279e+07, Test loss: 8.846e+07, MSE(e): 1.197e-03, MSE(pi1): 6.492e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 62400, Train loss: 1.280e+07, Test loss: 8.806e+07, MSE(e): 1.198e-03, MSE(pi1): 6.484e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.727e-03\n",
      "Epoch 62500, Train loss: 1.279e+07, Test loss: 8.848e+07, MSE(e): 1.197e-03, MSE(pi1): 6.491e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 62600, Train loss: 1.280e+07, Test loss: 8.906e+07, MSE(e): 1.197e-03, MSE(pi1): 6.495e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 62700, Train loss: 1.279e+07, Test loss: 8.852e+07, MSE(e): 1.197e-03, MSE(pi1): 6.490e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 62800, Train loss: 1.279e+07, Test loss: 8.851e+07, MSE(e): 1.197e-03, MSE(pi1): 6.489e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 62900, Train loss: 1.279e+07, Test loss: 8.857e+07, MSE(e): 1.197e-03, MSE(pi1): 6.488e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 63000, Train loss: 1.279e+07, Test loss: 8.869e+07, MSE(e): 1.197e-03, MSE(pi1): 6.489e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 63100, Train loss: 1.279e+07, Test loss: 8.860e+07, MSE(e): 1.197e-03, MSE(pi1): 6.487e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 63200, Train loss: 1.279e+07, Test loss: 8.893e+07, MSE(e): 1.197e-03, MSE(pi1): 6.486e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 63300, Train loss: 1.279e+07, Test loss: 8.863e+07, MSE(e): 1.197e-03, MSE(pi1): 6.486e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 63400, Train loss: 1.280e+07, Test loss: 8.940e+07, MSE(e): 1.198e-03, MSE(pi1): 6.492e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 63500, Train loss: 1.279e+07, Test loss: 8.866e+07, MSE(e): 1.197e-03, MSE(pi1): 6.484e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 63600, Train loss: 1.279e+07, Test loss: 8.867e+07, MSE(e): 1.197e-03, MSE(pi1): 6.484e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 63700, Train loss: 1.279e+07, Test loss: 8.866e+07, MSE(e): 1.197e-03, MSE(pi1): 6.483e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 63800, Train loss: 1.279e+07, Test loss: 8.871e+07, MSE(e): 1.197e-03, MSE(pi1): 6.483e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 63900, Train loss: 1.279e+07, Test loss: 8.876e+07, MSE(e): 1.197e-03, MSE(pi1): 6.482e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 64000, Train loss: 1.279e+07, Test loss: 8.875e+07, MSE(e): 1.197e-03, MSE(pi1): 6.481e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 64100, Train loss: 1.279e+07, Test loss: 8.854e+07, MSE(e): 1.197e-03, MSE(pi1): 6.480e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 64200, Train loss: 1.279e+07, Test loss: 8.879e+07, MSE(e): 1.197e-03, MSE(pi1): 6.480e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.721e-03\n",
      "Epoch 64300, Train loss: 1.279e+07, Test loss: 8.919e+07, MSE(e): 1.197e-03, MSE(pi1): 6.483e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 64400, Train loss: 1.279e+07, Test loss: 8.882e+07, MSE(e): 1.197e-03, MSE(pi1): 6.479e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.721e-03\n",
      "Epoch 64500, Train loss: 1.279e+07, Test loss: 8.846e+07, MSE(e): 1.197e-03, MSE(pi1): 6.474e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 64600, Train loss: 1.279e+07, Test loss: 8.885e+07, MSE(e): 1.197e-03, MSE(pi1): 6.478e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.721e-03\n",
      "Epoch 64700, Train loss: 1.279e+07, Test loss: 8.888e+07, MSE(e): 1.197e-03, MSE(pi1): 6.477e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.721e-03\n",
      "Epoch 64800, Train loss: 1.279e+07, Test loss: 8.893e+07, MSE(e): 1.197e-03, MSE(pi1): 6.477e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.721e-03\n",
      "Epoch 64900, Train loss: 1.279e+07, Test loss: 8.891e+07, MSE(e): 1.197e-03, MSE(pi1): 6.476e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.721e-03\n",
      "Epoch 65000, Train loss: 1.279e+07, Test loss: 8.903e+07, MSE(e): 1.197e-03, MSE(pi1): 6.477e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 65100, Train loss: 1.278e+07, Test loss: 8.895e+07, MSE(e): 1.197e-03, MSE(pi1): 6.475e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.721e-03\n",
      "Epoch 65200, Train loss: 1.278e+07, Test loss: 8.881e+07, MSE(e): 1.197e-03, MSE(pi1): 6.473e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.721e-03\n",
      "Epoch 65300, Train loss: 1.278e+07, Test loss: 8.898e+07, MSE(e): 1.196e-03, MSE(pi1): 6.473e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.721e-03\n",
      "Epoch 65400, Train loss: 1.278e+07, Test loss: 8.916e+07, MSE(e): 1.196e-03, MSE(pi1): 6.473e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 65500, Train loss: 1.278e+07, Test loss: 8.901e+07, MSE(e): 1.196e-03, MSE(pi1): 6.472e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 65600, Train loss: 1.278e+07, Test loss: 8.896e+07, MSE(e): 1.196e-03, MSE(pi1): 6.473e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 65700, Train loss: 1.278e+07, Test loss: 8.905e+07, MSE(e): 1.196e-03, MSE(pi1): 6.471e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 65800, Train loss: 1.278e+07, Test loss: 8.898e+07, MSE(e): 1.196e-03, MSE(pi1): 6.470e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 65900, Train loss: 1.278e+07, Test loss: 8.909e+07, MSE(e): 1.196e-03, MSE(pi1): 6.470e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 66000, Train loss: 1.278e+07, Test loss: 8.910e+07, MSE(e): 1.196e-03, MSE(pi1): 6.469e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 66100, Train loss: 1.278e+07, Test loss: 8.892e+07, MSE(e): 1.196e-03, MSE(pi1): 6.466e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.721e-03\n",
      "Epoch 66200, Train loss: 1.278e+07, Test loss: 8.913e+07, MSE(e): 1.196e-03, MSE(pi1): 6.468e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 66300, Train loss: 1.278e+07, Test loss: 8.909e+07, MSE(e): 1.196e-03, MSE(pi1): 6.467e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 66400, Train loss: 1.278e+07, Test loss: 8.915e+07, MSE(e): 1.196e-03, MSE(pi1): 6.466e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 66500, Train loss: 1.278e+07, Test loss: 8.919e+07, MSE(e): 1.196e-03, MSE(pi1): 6.466e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 66600, Train loss: 1.278e+07, Test loss: 8.908e+07, MSE(e): 1.196e-03, MSE(pi1): 6.463e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.721e-03\n",
      "Epoch 66700, Train loss: 1.278e+07, Test loss: 8.922e+07, MSE(e): 1.196e-03, MSE(pi1): 6.465e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 66800, Train loss: 1.278e+07, Test loss: 8.965e+07, MSE(e): 1.196e-03, MSE(pi1): 6.466e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 66900, Train loss: 1.278e+07, Test loss: 8.926e+07, MSE(e): 1.196e-03, MSE(pi1): 6.463e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 67000, Train loss: 1.279e+07, Test loss: 8.892e+07, MSE(e): 1.198e-03, MSE(pi1): 6.454e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 67100, Train loss: 1.278e+07, Test loss: 8.929e+07, MSE(e): 1.196e-03, MSE(pi1): 6.462e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 67200, Train loss: 1.278e+07, Test loss: 9.006e+07, MSE(e): 1.197e-03, MSE(pi1): 6.467e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.716e-03\n",
      "Epoch 67300, Train loss: 1.278e+07, Test loss: 8.932e+07, MSE(e): 1.196e-03, MSE(pi1): 6.461e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 67400, Train loss: 1.278e+07, Test loss: 8.969e+07, MSE(e): 1.196e-03, MSE(pi1): 6.462e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 67500, Train loss: 1.278e+07, Test loss: 8.936e+07, MSE(e): 1.196e-03, MSE(pi1): 6.460e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 67600, Train loss: 1.278e+07, Test loss: 8.934e+07, MSE(e): 1.196e-03, MSE(pi1): 6.459e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 67700, Train loss: 1.279e+07, Test loss: 8.848e+07, MSE(e): 1.198e-03, MSE(pi1): 6.449e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.724e-03\n",
      "Epoch 67800, Train loss: 1.278e+07, Test loss: 8.942e+07, MSE(e): 1.196e-03, MSE(pi1): 6.458e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 67900, Train loss: 1.278e+07, Test loss: 8.912e+07, MSE(e): 1.196e-03, MSE(pi1): 6.454e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.720e-03\n",
      "Epoch 68000, Train loss: 1.278e+07, Test loss: 8.944e+07, MSE(e): 1.196e-03, MSE(pi1): 6.457e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 68100, Train loss: 1.278e+07, Test loss: 8.925e+07, MSE(e): 1.196e-03, MSE(pi1): 6.454e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 68200, Train loss: 1.278e+07, Test loss: 8.948e+07, MSE(e): 1.196e-03, MSE(pi1): 6.456e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 68300, Train loss: 1.278e+07, Test loss: 8.955e+07, MSE(e): 1.196e-03, MSE(pi1): 6.455e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 68400, Train loss: 1.278e+07, Test loss: 8.957e+07, MSE(e): 1.196e-03, MSE(pi1): 6.455e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 68500, Train loss: 1.278e+07, Test loss: 8.951e+07, MSE(e): 1.196e-03, MSE(pi1): 6.454e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 68600, Train loss: 1.279e+07, Test loss: 8.876e+07, MSE(e): 1.197e-03, MSE(pi1): 6.446e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.722e-03\n",
      "Epoch 68700, Train loss: 1.278e+07, Test loss: 8.955e+07, MSE(e): 1.196e-03, MSE(pi1): 6.452e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 68800, Train loss: 1.278e+07, Test loss: 8.960e+07, MSE(e): 1.196e-03, MSE(pi1): 6.452e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 68900, Train loss: 1.278e+07, Test loss: 8.957e+07, MSE(e): 1.196e-03, MSE(pi1): 6.451e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 69000, Train loss: 1.278e+07, Test loss: 8.961e+07, MSE(e): 1.196e-03, MSE(pi1): 6.451e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 69100, Train loss: 1.277e+07, Test loss: 8.966e+07, MSE(e): 1.196e-03, MSE(pi1): 6.450e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 69200, Train loss: 1.277e+07, Test loss: 8.964e+07, MSE(e): 1.196e-03, MSE(pi1): 6.449e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 69300, Train loss: 1.278e+07, Test loss: 8.931e+07, MSE(e): 1.196e-03, MSE(pi1): 6.447e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 69400, Train loss: 1.277e+07, Test loss: 8.968e+07, MSE(e): 1.196e-03, MSE(pi1): 6.448e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 69500, Train loss: 1.277e+07, Test loss: 8.986e+07, MSE(e): 1.196e-03, MSE(pi1): 6.449e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 69600, Train loss: 1.277e+07, Test loss: 8.972e+07, MSE(e): 1.196e-03, MSE(pi1): 6.447e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 69700, Train loss: 1.280e+07, Test loss: 8.866e+07, MSE(e): 1.198e-03, MSE(pi1): 6.436e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.723e-03\n",
      "Epoch 69800, Train loss: 1.277e+07, Test loss: 8.975e+07, MSE(e): 1.196e-03, MSE(pi1): 6.446e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 69900, Train loss: 1.282e+07, Test loss: 8.859e+07, MSE(e): 1.201e-03, MSE(pi1): 6.429e-02, MSE(pi2): 1.314e-03, MSE(pi3): 1.726e-03\n",
      "Epoch 70000, Train loss: 1.277e+07, Test loss: 8.977e+07, MSE(e): 1.196e-03, MSE(pi1): 6.445e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 70100, Train loss: 1.277e+07, Test loss: 8.976e+07, MSE(e): 1.196e-03, MSE(pi1): 6.444e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 70200, Train loss: 1.277e+07, Test loss: 8.978e+07, MSE(e): 1.196e-03, MSE(pi1): 6.443e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 70300, Train loss: 1.279e+07, Test loss: 9.096e+07, MSE(e): 1.198e-03, MSE(pi1): 6.453e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 70400, Train loss: 1.277e+07, Test loss: 8.984e+07, MSE(e): 1.196e-03, MSE(pi1): 6.442e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 70500, Train loss: 1.277e+07, Test loss: 9.018e+07, MSE(e): 1.196e-03, MSE(pi1): 6.444e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 70600, Train loss: 1.277e+07, Test loss: 8.986e+07, MSE(e): 1.196e-03, MSE(pi1): 6.441e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 70700, Train loss: 1.277e+07, Test loss: 9.018e+07, MSE(e): 1.196e-03, MSE(pi1): 6.443e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 70800, Train loss: 1.277e+07, Test loss: 8.992e+07, MSE(e): 1.196e-03, MSE(pi1): 6.440e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.716e-03\n",
      "Epoch 70900, Train loss: 1.277e+07, Test loss: 8.971e+07, MSE(e): 1.195e-03, MSE(pi1): 6.439e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.716e-03\n",
      "Epoch 71000, Train loss: 1.277e+07, Test loss: 8.993e+07, MSE(e): 1.195e-03, MSE(pi1): 6.439e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.716e-03\n",
      "Epoch 71100, Train loss: 1.277e+07, Test loss: 8.941e+07, MSE(e): 1.196e-03, MSE(pi1): 6.433e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 71200, Train loss: 1.277e+07, Test loss: 8.996e+07, MSE(e): 1.195e-03, MSE(pi1): 6.437e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.716e-03\n",
      "Epoch 71300, Train loss: 1.277e+07, Test loss: 8.998e+07, MSE(e): 1.195e-03, MSE(pi1): 6.437e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.716e-03\n",
      "Epoch 71400, Train loss: 1.277e+07, Test loss: 8.999e+07, MSE(e): 1.195e-03, MSE(pi1): 6.436e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.716e-03\n",
      "Epoch 71500, Train loss: 1.277e+07, Test loss: 9.001e+07, MSE(e): 1.195e-03, MSE(pi1): 6.436e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.716e-03\n",
      "Epoch 71600, Train loss: 1.277e+07, Test loss: 8.992e+07, MSE(e): 1.195e-03, MSE(pi1): 6.433e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 71700, Train loss: 1.277e+07, Test loss: 9.005e+07, MSE(e): 1.195e-03, MSE(pi1): 6.434e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.716e-03\n",
      "Epoch 71800, Train loss: 1.277e+07, Test loss: 9.028e+07, MSE(e): 1.195e-03, MSE(pi1): 6.434e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 71900, Train loss: 1.277e+07, Test loss: 9.007e+07, MSE(e): 1.195e-03, MSE(pi1): 6.433e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.716e-03\n",
      "Epoch 72000, Train loss: 1.277e+07, Test loss: 8.987e+07, MSE(e): 1.195e-03, MSE(pi1): 6.431e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 72100, Train loss: 1.277e+07, Test loss: 9.011e+07, MSE(e): 1.195e-03, MSE(pi1): 6.432e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 72200, Train loss: 1.277e+07, Test loss: 9.081e+07, MSE(e): 1.196e-03, MSE(pi1): 6.436e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.713e-03\n",
      "Epoch 72300, Train loss: 1.277e+07, Test loss: 9.014e+07, MSE(e): 1.195e-03, MSE(pi1): 6.431e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 72400, Train loss: 1.278e+07, Test loss: 9.084e+07, MSE(e): 1.196e-03, MSE(pi1): 6.437e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 72500, Train loss: 1.277e+07, Test loss: 9.017e+07, MSE(e): 1.195e-03, MSE(pi1): 6.430e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 72600, Train loss: 1.277e+07, Test loss: 9.083e+07, MSE(e): 1.196e-03, MSE(pi1): 6.435e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 72700, Train loss: 1.277e+07, Test loss: 9.019e+07, MSE(e): 1.195e-03, MSE(pi1): 6.428e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 72800, Train loss: 1.278e+07, Test loss: 8.944e+07, MSE(e): 1.196e-03, MSE(pi1): 6.421e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.719e-03\n",
      "Epoch 72900, Train loss: 1.277e+07, Test loss: 9.023e+07, MSE(e): 1.195e-03, MSE(pi1): 6.427e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 73000, Train loss: 1.278e+07, Test loss: 9.106e+07, MSE(e): 1.196e-03, MSE(pi1): 6.435e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 73100, Train loss: 1.277e+07, Test loss: 9.027e+07, MSE(e): 1.195e-03, MSE(pi1): 6.426e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 73200, Train loss: 1.276e+07, Test loss: 9.042e+07, MSE(e): 1.195e-03, MSE(pi1): 6.425e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 73300, Train loss: 1.276e+07, Test loss: 9.029e+07, MSE(e): 1.195e-03, MSE(pi1): 6.425e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 73400, Train loss: 1.277e+07, Test loss: 9.011e+07, MSE(e): 1.195e-03, MSE(pi1): 6.421e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 73500, Train loss: 1.276e+07, Test loss: 9.032e+07, MSE(e): 1.195e-03, MSE(pi1): 6.424e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 73600, Train loss: 1.276e+07, Test loss: 9.022e+07, MSE(e): 1.195e-03, MSE(pi1): 6.423e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.714e-03\n",
      "Epoch 73700, Train loss: 1.276e+07, Test loss: 9.036e+07, MSE(e): 1.195e-03, MSE(pi1): 6.423e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.714e-03\n",
      "Epoch 73800, Train loss: 1.276e+07, Test loss: 9.027e+07, MSE(e): 1.195e-03, MSE(pi1): 6.422e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.714e-03\n",
      "Epoch 73900, Train loss: 1.276e+07, Test loss: 9.038e+07, MSE(e): 1.195e-03, MSE(pi1): 6.421e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.714e-03\n",
      "Epoch 74000, Train loss: 1.276e+07, Test loss: 9.037e+07, MSE(e): 1.195e-03, MSE(pi1): 6.421e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.714e-03\n",
      "Epoch 74100, Train loss: 1.276e+07, Test loss: 9.042e+07, MSE(e): 1.195e-03, MSE(pi1): 6.420e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.714e-03\n",
      "Epoch 74200, Train loss: 1.276e+07, Test loss: 9.065e+07, MSE(e): 1.195e-03, MSE(pi1): 6.423e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 74300, Train loss: 1.276e+07, Test loss: 9.044e+07, MSE(e): 1.195e-03, MSE(pi1): 6.419e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.714e-03\n",
      "Epoch 74400, Train loss: 1.277e+07, Test loss: 8.988e+07, MSE(e): 1.196e-03, MSE(pi1): 6.411e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.718e-03\n",
      "Epoch 74500, Train loss: 1.276e+07, Test loss: 9.047e+07, MSE(e): 1.195e-03, MSE(pi1): 6.418e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.714e-03\n",
      "Epoch 74600, Train loss: 1.280e+07, Test loss: 9.192e+07, MSE(e): 1.199e-03, MSE(pi1): 6.431e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 74700, Train loss: 1.276e+07, Test loss: 9.050e+07, MSE(e): 1.195e-03, MSE(pi1): 6.416e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.714e-03\n",
      "Epoch 74800, Train loss: 1.277e+07, Test loss: 8.977e+07, MSE(e): 1.196e-03, MSE(pi1): 6.409e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.717e-03\n",
      "Epoch 74900, Train loss: 1.276e+07, Test loss: 9.053e+07, MSE(e): 1.195e-03, MSE(pi1): 6.415e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.714e-03\n",
      "Epoch 75000, Train loss: 1.276e+07, Test loss: 9.055e+07, MSE(e): 1.195e-03, MSE(pi1): 6.413e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.714e-03\n",
      "Epoch 75100, Train loss: 1.276e+07, Test loss: 9.056e+07, MSE(e): 1.195e-03, MSE(pi1): 6.414e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.713e-03\n",
      "Epoch 75200, Train loss: 1.276e+07, Test loss: 9.070e+07, MSE(e): 1.195e-03, MSE(pi1): 6.411e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.715e-03\n",
      "Epoch 75300, Train loss: 1.276e+07, Test loss: 9.059e+07, MSE(e): 1.195e-03, MSE(pi1): 6.413e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.713e-03\n",
      "Epoch 75400, Train loss: 1.276e+07, Test loss: 9.060e+07, MSE(e): 1.195e-03, MSE(pi1): 6.412e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.713e-03\n",
      "Epoch 75500, Train loss: 1.276e+07, Test loss: 9.060e+07, MSE(e): 1.195e-03, MSE(pi1): 6.411e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.713e-03\n",
      "Epoch 75600, Train loss: 1.276e+07, Test loss: 9.062e+07, MSE(e): 1.195e-03, MSE(pi1): 6.411e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.713e-03\n",
      "Epoch 75700, Train loss: 1.276e+07, Test loss: 9.063e+07, MSE(e): 1.195e-03, MSE(pi1): 6.410e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.713e-03\n",
      "Epoch 75800, Train loss: 1.276e+07, Test loss: 9.080e+07, MSE(e): 1.195e-03, MSE(pi1): 6.411e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 75900, Train loss: 1.276e+07, Test loss: 9.068e+07, MSE(e): 1.195e-03, MSE(pi1): 6.410e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.713e-03\n",
      "Epoch 76000, Train loss: 1.276e+07, Test loss: 9.075e+07, MSE(e): 1.195e-03, MSE(pi1): 6.409e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 76100, Train loss: 1.276e+07, Test loss: 9.070e+07, MSE(e): 1.195e-03, MSE(pi1): 6.408e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.713e-03\n",
      "Epoch 76200, Train loss: 1.276e+07, Test loss: 9.089e+07, MSE(e): 1.195e-03, MSE(pi1): 6.409e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 76300, Train loss: 1.276e+07, Test loss: 9.075e+07, MSE(e): 1.195e-03, MSE(pi1): 6.407e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 76400, Train loss: 1.276e+07, Test loss: 9.105e+07, MSE(e): 1.195e-03, MSE(pi1): 6.409e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 76500, Train loss: 1.276e+07, Test loss: 9.078e+07, MSE(e): 1.195e-03, MSE(pi1): 6.406e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 76600, Train loss: 1.276e+07, Test loss: 9.078e+07, MSE(e): 1.195e-03, MSE(pi1): 6.405e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 76700, Train loss: 1.276e+07, Test loss: 9.081e+07, MSE(e): 1.195e-03, MSE(pi1): 6.404e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 76800, Train loss: 1.276e+07, Test loss: 9.080e+07, MSE(e): 1.194e-03, MSE(pi1): 6.404e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 76900, Train loss: 1.276e+07, Test loss: 9.102e+07, MSE(e): 1.195e-03, MSE(pi1): 6.406e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 77000, Train loss: 1.276e+07, Test loss: 9.084e+07, MSE(e): 1.194e-03, MSE(pi1): 6.403e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 77100, Train loss: 1.276e+07, Test loss: 9.126e+07, MSE(e): 1.195e-03, MSE(pi1): 6.406e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 77200, Train loss: 1.276e+07, Test loss: 9.086e+07, MSE(e): 1.194e-03, MSE(pi1): 6.402e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 77300, Train loss: 1.276e+07, Test loss: 9.100e+07, MSE(e): 1.194e-03, MSE(pi1): 6.402e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 77400, Train loss: 1.276e+07, Test loss: 9.088e+07, MSE(e): 1.194e-03, MSE(pi1): 6.400e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 77500, Train loss: 1.275e+07, Test loss: 9.090e+07, MSE(e): 1.194e-03, MSE(pi1): 6.400e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 77600, Train loss: 1.275e+07, Test loss: 9.094e+07, MSE(e): 1.194e-03, MSE(pi1): 6.399e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 77700, Train loss: 1.275e+07, Test loss: 9.093e+07, MSE(e): 1.194e-03, MSE(pi1): 6.399e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 77800, Train loss: 1.275e+07, Test loss: 9.089e+07, MSE(e): 1.194e-03, MSE(pi1): 6.400e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 77900, Train loss: 1.275e+07, Test loss: 9.095e+07, MSE(e): 1.194e-03, MSE(pi1): 6.398e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 78000, Train loss: 1.276e+07, Test loss: 9.132e+07, MSE(e): 1.194e-03, MSE(pi1): 6.400e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 78100, Train loss: 1.275e+07, Test loss: 9.097e+07, MSE(e): 1.194e-03, MSE(pi1): 6.396e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 78200, Train loss: 1.275e+07, Test loss: 9.098e+07, MSE(e): 1.194e-03, MSE(pi1): 6.396e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 78300, Train loss: 1.275e+07, Test loss: 9.103e+07, MSE(e): 1.194e-03, MSE(pi1): 6.395e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 78400, Train loss: 1.275e+07, Test loss: 9.102e+07, MSE(e): 1.194e-03, MSE(pi1): 6.395e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 78500, Train loss: 1.275e+07, Test loss: 9.101e+07, MSE(e): 1.194e-03, MSE(pi1): 6.395e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 78600, Train loss: 1.275e+07, Test loss: 9.104e+07, MSE(e): 1.194e-03, MSE(pi1): 6.393e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 78700, Train loss: 1.275e+07, Test loss: 9.129e+07, MSE(e): 1.194e-03, MSE(pi1): 6.395e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 78800, Train loss: 1.275e+07, Test loss: 9.107e+07, MSE(e): 1.194e-03, MSE(pi1): 6.392e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 78900, Train loss: 1.275e+07, Test loss: 9.105e+07, MSE(e): 1.194e-03, MSE(pi1): 6.392e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 79000, Train loss: 1.275e+07, Test loss: 9.109e+07, MSE(e): 1.194e-03, MSE(pi1): 6.391e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 79100, Train loss: 1.275e+07, Test loss: 9.083e+07, MSE(e): 1.194e-03, MSE(pi1): 6.389e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 79200, Train loss: 1.275e+07, Test loss: 9.112e+07, MSE(e): 1.194e-03, MSE(pi1): 6.390e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 79300, Train loss: 1.275e+07, Test loss: 9.113e+07, MSE(e): 1.194e-03, MSE(pi1): 6.389e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 79400, Train loss: 1.275e+07, Test loss: 9.111e+07, MSE(e): 1.194e-03, MSE(pi1): 6.389e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 79500, Train loss: 1.275e+07, Test loss: 9.115e+07, MSE(e): 1.194e-03, MSE(pi1): 6.388e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 79600, Train loss: 1.275e+07, Test loss: 9.116e+07, MSE(e): 1.194e-03, MSE(pi1): 6.388e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 79700, Train loss: 1.275e+07, Test loss: 9.113e+07, MSE(e): 1.194e-03, MSE(pi1): 6.387e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 79800, Train loss: 1.275e+07, Test loss: 9.119e+07, MSE(e): 1.194e-03, MSE(pi1): 6.387e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 79900, Train loss: 1.275e+07, Test loss: 9.125e+07, MSE(e): 1.194e-03, MSE(pi1): 6.387e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 80000, Train loss: 1.275e+07, Test loss: 9.122e+07, MSE(e): 1.194e-03, MSE(pi1): 6.385e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 80100, Train loss: 1.275e+07, Test loss: 9.122e+07, MSE(e): 1.194e-03, MSE(pi1): 6.384e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 80200, Train loss: 1.275e+07, Test loss: 9.099e+07, MSE(e): 1.194e-03, MSE(pi1): 6.382e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 80300, Train loss: 1.275e+07, Test loss: 9.125e+07, MSE(e): 1.194e-03, MSE(pi1): 6.383e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 80400, Train loss: 1.275e+07, Test loss: 9.140e+07, MSE(e): 1.194e-03, MSE(pi1): 6.387e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.707e-03\n",
      "Epoch 80500, Train loss: 1.275e+07, Test loss: 9.127e+07, MSE(e): 1.194e-03, MSE(pi1): 6.382e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 80600, Train loss: 1.276e+07, Test loss: 9.085e+07, MSE(e): 1.195e-03, MSE(pi1): 6.376e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.713e-03\n",
      "Epoch 80700, Train loss: 1.275e+07, Test loss: 9.130e+07, MSE(e): 1.194e-03, MSE(pi1): 6.381e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 80800, Train loss: 1.275e+07, Test loss: 9.161e+07, MSE(e): 1.194e-03, MSE(pi1): 6.386e-02, MSE(pi2): 1.319e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 80900, Train loss: 1.275e+07, Test loss: 9.131e+07, MSE(e): 1.194e-03, MSE(pi1): 6.380e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 81000, Train loss: 1.275e+07, Test loss: 9.085e+07, MSE(e): 1.194e-03, MSE(pi1): 6.375e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.711e-03\n",
      "Epoch 81100, Train loss: 1.275e+07, Test loss: 9.133e+07, MSE(e): 1.194e-03, MSE(pi1): 6.379e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 81200, Train loss: 1.275e+07, Test loss: 9.138e+07, MSE(e): 1.194e-03, MSE(pi1): 6.379e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 81300, Train loss: 1.275e+07, Test loss: 9.136e+07, MSE(e): 1.194e-03, MSE(pi1): 6.378e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 81400, Train loss: 1.275e+07, Test loss: 9.154e+07, MSE(e): 1.194e-03, MSE(pi1): 6.378e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 81500, Train loss: 1.275e+07, Test loss: 9.137e+07, MSE(e): 1.194e-03, MSE(pi1): 6.376e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 81600, Train loss: 1.275e+07, Test loss: 9.138e+07, MSE(e): 1.194e-03, MSE(pi1): 6.376e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 81700, Train loss: 1.274e+07, Test loss: 9.142e+07, MSE(e): 1.194e-03, MSE(pi1): 6.376e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 81800, Train loss: 1.274e+07, Test loss: 9.141e+07, MSE(e): 1.194e-03, MSE(pi1): 6.375e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 81900, Train loss: 1.274e+07, Test loss: 9.142e+07, MSE(e): 1.194e-03, MSE(pi1): 6.374e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 82000, Train loss: 1.274e+07, Test loss: 9.143e+07, MSE(e): 1.194e-03, MSE(pi1): 6.373e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 82100, Train loss: 1.274e+07, Test loss: 9.138e+07, MSE(e): 1.194e-03, MSE(pi1): 6.372e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 82200, Train loss: 1.274e+07, Test loss: 9.144e+07, MSE(e): 1.194e-03, MSE(pi1): 6.372e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 82300, Train loss: 1.274e+07, Test loss: 9.143e+07, MSE(e): 1.194e-03, MSE(pi1): 6.371e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 82400, Train loss: 1.274e+07, Test loss: 9.149e+07, MSE(e): 1.194e-03, MSE(pi1): 6.371e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 82500, Train loss: 1.274e+07, Test loss: 9.146e+07, MSE(e): 1.194e-03, MSE(pi1): 6.370e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 82600, Train loss: 1.274e+07, Test loss: 9.151e+07, MSE(e): 1.194e-03, MSE(pi1): 6.370e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 82700, Train loss: 1.274e+07, Test loss: 9.153e+07, MSE(e): 1.193e-03, MSE(pi1): 6.370e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 82800, Train loss: 1.274e+07, Test loss: 9.152e+07, MSE(e): 1.193e-03, MSE(pi1): 6.369e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 82900, Train loss: 1.274e+07, Test loss: 9.150e+07, MSE(e): 1.193e-03, MSE(pi1): 6.368e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 83000, Train loss: 1.274e+07, Test loss: 9.153e+07, MSE(e): 1.193e-03, MSE(pi1): 6.368e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 83100, Train loss: 1.274e+07, Test loss: 9.153e+07, MSE(e): 1.193e-03, MSE(pi1): 6.367e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.708e-03\n",
      "Epoch 83200, Train loss: 1.274e+07, Test loss: 9.156e+07, MSE(e): 1.193e-03, MSE(pi1): 6.366e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.707e-03\n",
      "Epoch 83300, Train loss: 1.274e+07, Test loss: 9.184e+07, MSE(e): 1.193e-03, MSE(pi1): 6.368e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 83400, Train loss: 1.274e+07, Test loss: 9.157e+07, MSE(e): 1.193e-03, MSE(pi1): 6.365e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.707e-03\n",
      "Epoch 83500, Train loss: 1.274e+07, Test loss: 9.182e+07, MSE(e): 1.193e-03, MSE(pi1): 6.367e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 83600, Train loss: 1.274e+07, Test loss: 9.159e+07, MSE(e): 1.193e-03, MSE(pi1): 6.364e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.707e-03\n",
      "Epoch 83700, Train loss: 1.274e+07, Test loss: 9.137e+07, MSE(e): 1.194e-03, MSE(pi1): 6.360e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 83800, Train loss: 1.274e+07, Test loss: 9.161e+07, MSE(e): 1.193e-03, MSE(pi1): 6.363e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.707e-03\n",
      "Epoch 83900, Train loss: 1.275e+07, Test loss: 9.220e+07, MSE(e): 1.195e-03, MSE(pi1): 6.371e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 84000, Train loss: 1.274e+07, Test loss: 9.162e+07, MSE(e): 1.193e-03, MSE(pi1): 6.362e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.707e-03\n",
      "Epoch 84100, Train loss: 1.274e+07, Test loss: 9.158e+07, MSE(e): 1.194e-03, MSE(pi1): 6.357e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 84200, Train loss: 1.274e+07, Test loss: 9.164e+07, MSE(e): 1.193e-03, MSE(pi1): 6.361e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.707e-03\n",
      "Epoch 84300, Train loss: 1.277e+07, Test loss: 9.232e+07, MSE(e): 1.196e-03, MSE(pi1): 6.372e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 84400, Train loss: 1.274e+07, Test loss: 9.167e+07, MSE(e): 1.193e-03, MSE(pi1): 6.359e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.707e-03\n",
      "Epoch 84500, Train loss: 1.274e+07, Test loss: 9.170e+07, MSE(e): 1.193e-03, MSE(pi1): 6.359e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 84600, Train loss: 1.274e+07, Test loss: 9.166e+07, MSE(e): 1.193e-03, MSE(pi1): 6.358e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.707e-03\n",
      "Epoch 84700, Train loss: 1.274e+07, Test loss: 9.165e+07, MSE(e): 1.193e-03, MSE(pi1): 6.357e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.707e-03\n",
      "Epoch 84800, Train loss: 1.274e+07, Test loss: 9.168e+07, MSE(e): 1.193e-03, MSE(pi1): 6.357e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 84900, Train loss: 1.274e+07, Test loss: 9.172e+07, MSE(e): 1.193e-03, MSE(pi1): 6.357e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 85000, Train loss: 1.274e+07, Test loss: 9.172e+07, MSE(e): 1.193e-03, MSE(pi1): 6.356e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 85100, Train loss: 1.274e+07, Test loss: 9.174e+07, MSE(e): 1.193e-03, MSE(pi1): 6.355e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 85200, Train loss: 1.274e+07, Test loss: 9.171e+07, MSE(e): 1.193e-03, MSE(pi1): 6.355e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 85300, Train loss: 1.274e+07, Test loss: 9.177e+07, MSE(e): 1.193e-03, MSE(pi1): 6.354e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 85400, Train loss: 1.274e+07, Test loss: 9.173e+07, MSE(e): 1.193e-03, MSE(pi1): 6.353e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 85500, Train loss: 1.274e+07, Test loss: 9.172e+07, MSE(e): 1.193e-03, MSE(pi1): 6.353e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 85600, Train loss: 1.274e+07, Test loss: 9.176e+07, MSE(e): 1.193e-03, MSE(pi1): 6.352e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 85700, Train loss: 1.274e+07, Test loss: 9.107e+07, MSE(e): 1.194e-03, MSE(pi1): 6.346e-02, MSE(pi2): 1.314e-03, MSE(pi3): 1.709e-03\n",
      "Epoch 85800, Train loss: 1.274e+07, Test loss: 9.177e+07, MSE(e): 1.193e-03, MSE(pi1): 6.351e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 85900, Train loss: 1.274e+07, Test loss: 9.137e+07, MSE(e): 1.193e-03, MSE(pi1): 6.349e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 86000, Train loss: 1.273e+07, Test loss: 9.180e+07, MSE(e): 1.193e-03, MSE(pi1): 6.350e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.705e-03\n",
      "Epoch 86100, Train loss: 1.275e+07, Test loss: 9.249e+07, MSE(e): 1.194e-03, MSE(pi1): 6.358e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 86200, Train loss: 1.273e+07, Test loss: 9.181e+07, MSE(e): 1.193e-03, MSE(pi1): 6.349e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.705e-03\n",
      "Epoch 86300, Train loss: 1.274e+07, Test loss: 9.208e+07, MSE(e): 1.193e-03, MSE(pi1): 6.352e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 86400, Train loss: 1.273e+07, Test loss: 9.182e+07, MSE(e): 1.193e-03, MSE(pi1): 6.347e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.705e-03\n",
      "Epoch 86500, Train loss: 1.273e+07, Test loss: 9.179e+07, MSE(e): 1.193e-03, MSE(pi1): 6.345e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 86600, Train loss: 1.273e+07, Test loss: 9.184e+07, MSE(e): 1.193e-03, MSE(pi1): 6.346e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.705e-03\n",
      "Epoch 86700, Train loss: 1.273e+07, Test loss: 9.181e+07, MSE(e): 1.193e-03, MSE(pi1): 6.346e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.705e-03\n",
      "Epoch 86800, Train loss: 1.273e+07, Test loss: 9.185e+07, MSE(e): 1.193e-03, MSE(pi1): 6.345e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.705e-03\n",
      "Epoch 86900, Train loss: 1.273e+07, Test loss: 9.191e+07, MSE(e): 1.193e-03, MSE(pi1): 6.346e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.704e-03\n",
      "Epoch 87000, Train loss: 1.273e+07, Test loss: 9.187e+07, MSE(e): 1.193e-03, MSE(pi1): 6.344e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.705e-03\n",
      "Epoch 87100, Train loss: 1.274e+07, Test loss: 9.232e+07, MSE(e): 1.193e-03, MSE(pi1): 6.347e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 87200, Train loss: 1.273e+07, Test loss: 9.188e+07, MSE(e): 1.193e-03, MSE(pi1): 6.343e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.705e-03\n",
      "Epoch 87300, Train loss: 1.274e+07, Test loss: 9.242e+07, MSE(e): 1.193e-03, MSE(pi1): 6.347e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 87400, Train loss: 1.273e+07, Test loss: 9.190e+07, MSE(e): 1.193e-03, MSE(pi1): 6.342e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.704e-03\n",
      "Epoch 87500, Train loss: 1.277e+07, Test loss: 9.339e+07, MSE(e): 1.196e-03, MSE(pi1): 6.354e-02, MSE(pi2): 1.322e-03, MSE(pi3): 1.697e-03\n",
      "Epoch 87600, Train loss: 1.273e+07, Test loss: 9.190e+07, MSE(e): 1.193e-03, MSE(pi1): 6.340e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.704e-03\n",
      "Epoch 87700, Train loss: 1.277e+07, Test loss: 9.071e+07, MSE(e): 1.197e-03, MSE(pi1): 6.325e-02, MSE(pi2): 1.313e-03, MSE(pi3): 1.712e-03\n",
      "Epoch 87800, Train loss: 1.273e+07, Test loss: 9.191e+07, MSE(e): 1.193e-03, MSE(pi1): 6.339e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.704e-03\n",
      "Epoch 87900, Train loss: 1.275e+07, Test loss: 9.309e+07, MSE(e): 1.194e-03, MSE(pi1): 6.348e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 88000, Train loss: 1.273e+07, Test loss: 9.194e+07, MSE(e): 1.193e-03, MSE(pi1): 6.338e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.704e-03\n",
      "Epoch 88100, Train loss: 1.273e+07, Test loss: 9.212e+07, MSE(e): 1.193e-03, MSE(pi1): 6.339e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 88200, Train loss: 1.273e+07, Test loss: 9.196e+07, MSE(e): 1.193e-03, MSE(pi1): 6.337e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.704e-03\n",
      "Epoch 88300, Train loss: 1.274e+07, Test loss: 9.219e+07, MSE(e): 1.193e-03, MSE(pi1): 6.341e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 88400, Train loss: 1.273e+07, Test loss: 9.196e+07, MSE(e): 1.193e-03, MSE(pi1): 6.336e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.704e-03\n",
      "Epoch 88500, Train loss: 1.275e+07, Test loss: 9.253e+07, MSE(e): 1.194e-03, MSE(pi1): 6.345e-02, MSE(pi2): 1.320e-03, MSE(pi3): 1.698e-03\n",
      "Epoch 88600, Train loss: 1.273e+07, Test loss: 9.197e+07, MSE(e): 1.193e-03, MSE(pi1): 6.334e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.704e-03\n",
      "Epoch 88700, Train loss: 1.273e+07, Test loss: 9.225e+07, MSE(e): 1.193e-03, MSE(pi1): 6.339e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 88800, Train loss: 1.273e+07, Test loss: 9.198e+07, MSE(e): 1.192e-03, MSE(pi1): 6.333e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 88900, Train loss: 1.273e+07, Test loss: 9.228e+07, MSE(e): 1.192e-03, MSE(pi1): 6.333e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 89000, Train loss: 1.273e+07, Test loss: 9.199e+07, MSE(e): 1.192e-03, MSE(pi1): 6.332e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 89100, Train loss: 1.273e+07, Test loss: 9.187e+07, MSE(e): 1.192e-03, MSE(pi1): 6.330e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.704e-03\n",
      "Epoch 89200, Train loss: 1.273e+07, Test loss: 9.200e+07, MSE(e): 1.192e-03, MSE(pi1): 6.331e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 89300, Train loss: 1.273e+07, Test loss: 9.195e+07, MSE(e): 1.192e-03, MSE(pi1): 6.330e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 89400, Train loss: 1.273e+07, Test loss: 9.203e+07, MSE(e): 1.192e-03, MSE(pi1): 6.330e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 89500, Train loss: 1.273e+07, Test loss: 9.195e+07, MSE(e): 1.192e-03, MSE(pi1): 6.329e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 89600, Train loss: 1.273e+07, Test loss: 9.202e+07, MSE(e): 1.192e-03, MSE(pi1): 6.329e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 89700, Train loss: 1.273e+07, Test loss: 9.202e+07, MSE(e): 1.192e-03, MSE(pi1): 6.328e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 89800, Train loss: 1.273e+07, Test loss: 9.202e+07, MSE(e): 1.192e-03, MSE(pi1): 6.328e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 89900, Train loss: 1.273e+07, Test loss: 9.203e+07, MSE(e): 1.192e-03, MSE(pi1): 6.327e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 90000, Train loss: 1.273e+07, Test loss: 9.147e+07, MSE(e): 1.193e-03, MSE(pi1): 6.321e-02, MSE(pi2): 1.314e-03, MSE(pi3): 1.705e-03\n",
      "Epoch 90100, Train loss: 1.273e+07, Test loss: 9.204e+07, MSE(e): 1.192e-03, MSE(pi1): 6.325e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 90200, Train loss: 1.273e+07, Test loss: 9.204e+07, MSE(e): 1.192e-03, MSE(pi1): 6.325e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 90300, Train loss: 1.272e+07, Test loss: 9.207e+07, MSE(e): 1.192e-03, MSE(pi1): 6.324e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 90400, Train loss: 1.272e+07, Test loss: 9.205e+07, MSE(e): 1.192e-03, MSE(pi1): 6.324e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 90500, Train loss: 1.273e+07, Test loss: 9.153e+07, MSE(e): 1.193e-03, MSE(pi1): 6.319e-02, MSE(pi2): 1.314e-03, MSE(pi3): 1.705e-03\n",
      "Epoch 90600, Train loss: 1.272e+07, Test loss: 9.205e+07, MSE(e): 1.192e-03, MSE(pi1): 6.322e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 90700, Train loss: 1.275e+07, Test loss: 9.286e+07, MSE(e): 1.195e-03, MSE(pi1): 6.333e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.696e-03\n",
      "Epoch 90800, Train loss: 1.272e+07, Test loss: 9.207e+07, MSE(e): 1.192e-03, MSE(pi1): 6.321e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 90900, Train loss: 1.272e+07, Test loss: 9.150e+07, MSE(e): 1.192e-03, MSE(pi1): 6.319e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 91000, Train loss: 1.272e+07, Test loss: 9.207e+07, MSE(e): 1.192e-03, MSE(pi1): 6.320e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 91100, Train loss: 1.272e+07, Test loss: 9.228e+07, MSE(e): 1.192e-03, MSE(pi1): 6.321e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 91200, Train loss: 1.272e+07, Test loss: 9.209e+07, MSE(e): 1.192e-03, MSE(pi1): 6.319e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 91300, Train loss: 1.272e+07, Test loss: 9.209e+07, MSE(e): 1.192e-03, MSE(pi1): 6.318e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 91400, Train loss: 1.272e+07, Test loss: 9.209e+07, MSE(e): 1.192e-03, MSE(pi1): 6.317e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 91500, Train loss: 1.272e+07, Test loss: 9.208e+07, MSE(e): 1.192e-03, MSE(pi1): 6.317e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 91600, Train loss: 1.272e+07, Test loss: 9.208e+07, MSE(e): 1.192e-03, MSE(pi1): 6.316e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 91700, Train loss: 1.272e+07, Test loss: 9.210e+07, MSE(e): 1.192e-03, MSE(pi1): 6.316e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 91800, Train loss: 1.272e+07, Test loss: 9.213e+07, MSE(e): 1.192e-03, MSE(pi1): 6.315e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 91900, Train loss: 1.272e+07, Test loss: 9.211e+07, MSE(e): 1.192e-03, MSE(pi1): 6.315e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 92000, Train loss: 1.272e+07, Test loss: 9.218e+07, MSE(e): 1.192e-03, MSE(pi1): 6.315e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 92100, Train loss: 1.272e+07, Test loss: 9.211e+07, MSE(e): 1.192e-03, MSE(pi1): 6.313e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 92200, Train loss: 1.272e+07, Test loss: 9.223e+07, MSE(e): 1.192e-03, MSE(pi1): 6.314e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.700e-03\n",
      "Epoch 92300, Train loss: 1.272e+07, Test loss: 9.212e+07, MSE(e): 1.192e-03, MSE(pi1): 6.312e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 92400, Train loss: 1.272e+07, Test loss: 9.195e+07, MSE(e): 1.192e-03, MSE(pi1): 6.309e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.702e-03\n",
      "Epoch 92500, Train loss: 1.272e+07, Test loss: 9.213e+07, MSE(e): 1.192e-03, MSE(pi1): 6.311e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 92600, Train loss: 1.272e+07, Test loss: 9.227e+07, MSE(e): 1.192e-03, MSE(pi1): 6.315e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.698e-03\n",
      "Epoch 92700, Train loss: 1.272e+07, Test loss: 9.213e+07, MSE(e): 1.192e-03, MSE(pi1): 6.310e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 92800, Train loss: 1.272e+07, Test loss: 9.148e+07, MSE(e): 1.192e-03, MSE(pi1): 6.305e-02, MSE(pi2): 1.314e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 92900, Train loss: 1.272e+07, Test loss: 9.214e+07, MSE(e): 1.192e-03, MSE(pi1): 6.309e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.700e-03\n",
      "Epoch 93000, Train loss: 1.272e+07, Test loss: 9.214e+07, MSE(e): 1.192e-03, MSE(pi1): 6.307e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 93100, Train loss: 1.272e+07, Test loss: 9.214e+07, MSE(e): 1.192e-03, MSE(pi1): 6.307e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.700e-03\n",
      "Epoch 93200, Train loss: 1.272e+07, Test loss: 9.211e+07, MSE(e): 1.192e-03, MSE(pi1): 6.306e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 93300, Train loss: 1.272e+07, Test loss: 9.200e+07, MSE(e): 1.192e-03, MSE(pi1): 6.305e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 93400, Train loss: 1.272e+07, Test loss: 9.213e+07, MSE(e): 1.192e-03, MSE(pi1): 6.305e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.700e-03\n",
      "Epoch 93500, Train loss: 1.272e+07, Test loss: 9.166e+07, MSE(e): 1.192e-03, MSE(pi1): 6.304e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 93600, Train loss: 1.272e+07, Test loss: 9.215e+07, MSE(e): 1.192e-03, MSE(pi1): 6.304e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.700e-03\n",
      "Epoch 93700, Train loss: 1.272e+07, Test loss: 9.196e+07, MSE(e): 1.192e-03, MSE(pi1): 6.302e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.701e-03\n",
      "Epoch 93800, Train loss: 1.272e+07, Test loss: 9.215e+07, MSE(e): 1.192e-03, MSE(pi1): 6.303e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.700e-03\n",
      "Epoch 93900, Train loss: 1.272e+07, Test loss: 9.208e+07, MSE(e): 1.192e-03, MSE(pi1): 6.302e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.700e-03\n",
      "Epoch 94000, Train loss: 1.272e+07, Test loss: 9.213e+07, MSE(e): 1.192e-03, MSE(pi1): 6.302e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.700e-03\n",
      "Epoch 94100, Train loss: 1.272e+07, Test loss: 9.211e+07, MSE(e): 1.192e-03, MSE(pi1): 6.301e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.700e-03\n",
      "Epoch 94200, Train loss: 1.272e+07, Test loss: 9.216e+07, MSE(e): 1.192e-03, MSE(pi1): 6.301e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 94300, Train loss: 1.273e+07, Test loss: 9.315e+07, MSE(e): 1.193e-03, MSE(pi1): 6.308e-02, MSE(pi2): 1.318e-03, MSE(pi3): 1.695e-03\n",
      "Epoch 94400, Train loss: 1.272e+07, Test loss: 9.217e+07, MSE(e): 1.192e-03, MSE(pi1): 6.299e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 94500, Train loss: 1.278e+07, Test loss: 9.406e+07, MSE(e): 1.198e-03, MSE(pi1): 6.316e-02, MSE(pi2): 1.324e-03, MSE(pi3): 1.690e-03\n",
      "Epoch 94600, Train loss: 1.271e+07, Test loss: 9.215e+07, MSE(e): 1.191e-03, MSE(pi1): 6.298e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 94700, Train loss: 1.271e+07, Test loss: 9.216e+07, MSE(e): 1.191e-03, MSE(pi1): 6.298e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 94800, Train loss: 1.271e+07, Test loss: 9.205e+07, MSE(e): 1.191e-03, MSE(pi1): 6.297e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 94900, Train loss: 1.271e+07, Test loss: 9.216e+07, MSE(e): 1.191e-03, MSE(pi1): 6.296e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 95000, Train loss: 1.271e+07, Test loss: 9.216e+07, MSE(e): 1.191e-03, MSE(pi1): 6.296e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 95100, Train loss: 1.271e+07, Test loss: 9.216e+07, MSE(e): 1.191e-03, MSE(pi1): 6.295e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.698e-03\n",
      "Epoch 95200, Train loss: 1.271e+07, Test loss: 9.216e+07, MSE(e): 1.191e-03, MSE(pi1): 6.295e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 95300, Train loss: 1.271e+07, Test loss: 9.217e+07, MSE(e): 1.191e-03, MSE(pi1): 6.294e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.698e-03\n",
      "Epoch 95400, Train loss: 1.271e+07, Test loss: 9.215e+07, MSE(e): 1.191e-03, MSE(pi1): 6.293e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.698e-03\n",
      "Epoch 95500, Train loss: 1.271e+07, Test loss: 9.216e+07, MSE(e): 1.191e-03, MSE(pi1): 6.293e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.698e-03\n",
      "Epoch 95600, Train loss: 1.271e+07, Test loss: 9.210e+07, MSE(e): 1.191e-03, MSE(pi1): 6.291e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 95700, Train loss: 1.271e+07, Test loss: 9.216e+07, MSE(e): 1.191e-03, MSE(pi1): 6.291e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.698e-03\n",
      "Epoch 95800, Train loss: 1.271e+07, Test loss: 9.192e+07, MSE(e): 1.191e-03, MSE(pi1): 6.293e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.697e-03\n",
      "Epoch 95900, Train loss: 1.271e+07, Test loss: 9.217e+07, MSE(e): 1.191e-03, MSE(pi1): 6.290e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.698e-03\n",
      "Epoch 96000, Train loss: 1.271e+07, Test loss: 9.233e+07, MSE(e): 1.191e-03, MSE(pi1): 6.291e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.697e-03\n",
      "Epoch 96100, Train loss: 1.271e+07, Test loss: 9.215e+07, MSE(e): 1.191e-03, MSE(pi1): 6.289e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.698e-03\n",
      "Epoch 96200, Train loss: 1.275e+07, Test loss: 9.104e+07, MSE(e): 1.195e-03, MSE(pi1): 6.274e-02, MSE(pi2): 1.312e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 96300, Train loss: 1.271e+07, Test loss: 9.215e+07, MSE(e): 1.191e-03, MSE(pi1): 6.288e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.698e-03\n",
      "Epoch 96400, Train loss: 1.275e+07, Test loss: 9.360e+07, MSE(e): 1.195e-03, MSE(pi1): 6.301e-02, MSE(pi2): 1.321e-03, MSE(pi3): 1.690e-03\n",
      "Epoch 96500, Train loss: 1.271e+07, Test loss: 9.215e+07, MSE(e): 1.191e-03, MSE(pi1): 6.286e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.697e-03\n",
      "Epoch 96600, Train loss: 1.276e+07, Test loss: 9.116e+07, MSE(e): 1.196e-03, MSE(pi1): 6.271e-02, MSE(pi2): 1.312e-03, MSE(pi3): 1.706e-03\n",
      "Epoch 96700, Train loss: 1.271e+07, Test loss: 9.216e+07, MSE(e): 1.191e-03, MSE(pi1): 6.285e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.697e-03\n",
      "Epoch 96800, Train loss: 1.271e+07, Test loss: 9.215e+07, MSE(e): 1.191e-03, MSE(pi1): 6.285e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.697e-03\n",
      "Epoch 96900, Train loss: 1.271e+07, Test loss: 9.208e+07, MSE(e): 1.191e-03, MSE(pi1): 6.283e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.697e-03\n",
      "Epoch 97000, Train loss: 1.271e+07, Test loss: 9.215e+07, MSE(e): 1.191e-03, MSE(pi1): 6.283e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.697e-03\n",
      "Epoch 97100, Train loss: 1.271e+07, Test loss: 9.226e+07, MSE(e): 1.191e-03, MSE(pi1): 6.284e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.696e-03\n",
      "Epoch 97200, Train loss: 1.271e+07, Test loss: 9.215e+07, MSE(e): 1.191e-03, MSE(pi1): 6.282e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.697e-03\n",
      "Epoch 97300, Train loss: 1.271e+07, Test loss: 9.302e+07, MSE(e): 1.191e-03, MSE(pi1): 6.286e-02, MSE(pi2): 1.317e-03, MSE(pi3): 1.694e-03\n",
      "Epoch 97400, Train loss: 1.271e+07, Test loss: 9.216e+07, MSE(e): 1.191e-03, MSE(pi1): 6.281e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.697e-03\n",
      "Epoch 97500, Train loss: 1.271e+07, Test loss: 9.156e+07, MSE(e): 1.191e-03, MSE(pi1): 6.276e-02, MSE(pi2): 1.313e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 97600, Train loss: 1.271e+07, Test loss: 9.213e+07, MSE(e): 1.191e-03, MSE(pi1): 6.280e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.696e-03\n",
      "Epoch 97700, Train loss: 1.271e+07, Test loss: 9.208e+07, MSE(e): 1.191e-03, MSE(pi1): 6.278e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.697e-03\n",
      "Epoch 97800, Train loss: 1.271e+07, Test loss: 9.216e+07, MSE(e): 1.191e-03, MSE(pi1): 6.279e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.696e-03\n",
      "Epoch 97900, Train loss: 1.271e+07, Test loss: 9.170e+07, MSE(e): 1.191e-03, MSE(pi1): 6.274e-02, MSE(pi2): 1.314e-03, MSE(pi3): 1.698e-03\n",
      "Epoch 98000, Train loss: 1.271e+07, Test loss: 9.215e+07, MSE(e): 1.191e-03, MSE(pi1): 6.277e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.696e-03\n",
      "Epoch 98100, Train loss: 1.271e+07, Test loss: 9.267e+07, MSE(e): 1.191e-03, MSE(pi1): 6.281e-02, MSE(pi2): 1.316e-03, MSE(pi3): 1.694e-03\n",
      "Epoch 98200, Train loss: 1.271e+07, Test loss: 9.212e+07, MSE(e): 1.191e-03, MSE(pi1): 6.276e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.696e-03\n",
      "Epoch 98300, Train loss: 1.271e+07, Test loss: 9.242e+07, MSE(e): 1.191e-03, MSE(pi1): 6.276e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.696e-03\n",
      "Epoch 98400, Train loss: 1.271e+07, Test loss: 9.212e+07, MSE(e): 1.191e-03, MSE(pi1): 6.275e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.696e-03\n",
      "Epoch 98500, Train loss: 1.271e+07, Test loss: 9.150e+07, MSE(e): 1.192e-03, MSE(pi1): 6.267e-02, MSE(pi2): 1.313e-03, MSE(pi3): 1.699e-03\n",
      "Epoch 98600, Train loss: 1.270e+07, Test loss: 9.211e+07, MSE(e): 1.191e-03, MSE(pi1): 6.273e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.696e-03\n",
      "Epoch 98700, Train loss: 1.274e+07, Test loss: 9.066e+07, MSE(e): 1.194e-03, MSE(pi1): 6.260e-02, MSE(pi2): 1.312e-03, MSE(pi3): 1.703e-03\n",
      "Epoch 98800, Train loss: 1.270e+07, Test loss: 9.210e+07, MSE(e): 1.191e-03, MSE(pi1): 6.272e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.695e-03\n",
      "Epoch 98900, Train loss: 1.270e+07, Test loss: 9.211e+07, MSE(e): 1.191e-03, MSE(pi1): 6.271e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.695e-03\n",
      "Epoch 99000, Train loss: 1.270e+07, Test loss: 9.207e+07, MSE(e): 1.191e-03, MSE(pi1): 6.271e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.695e-03\n",
      "Epoch 99100, Train loss: 1.270e+07, Test loss: 9.209e+07, MSE(e): 1.191e-03, MSE(pi1): 6.270e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.695e-03\n",
      "Epoch 99200, Train loss: 1.270e+07, Test loss: 9.212e+07, MSE(e): 1.191e-03, MSE(pi1): 6.270e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.695e-03\n",
      "Epoch 99300, Train loss: 1.270e+07, Test loss: 9.210e+07, MSE(e): 1.191e-03, MSE(pi1): 6.269e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.695e-03\n",
      "Epoch 99400, Train loss: 1.270e+07, Test loss: 9.212e+07, MSE(e): 1.191e-03, MSE(pi1): 6.268e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.695e-03\n",
      "Epoch 99500, Train loss: 1.270e+07, Test loss: 9.208e+07, MSE(e): 1.191e-03, MSE(pi1): 6.268e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.695e-03\n",
      "Epoch 99600, Train loss: 1.270e+07, Test loss: 9.197e+07, MSE(e): 1.191e-03, MSE(pi1): 6.266e-02, MSE(pi2): 1.314e-03, MSE(pi3): 1.695e-03\n",
      "Epoch 99700, Train loss: 1.270e+07, Test loss: 9.208e+07, MSE(e): 1.191e-03, MSE(pi1): 6.266e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.694e-03\n",
      "Epoch 99800, Train loss: 1.270e+07, Test loss: 9.194e+07, MSE(e): 1.191e-03, MSE(pi1): 6.263e-02, MSE(pi2): 1.314e-03, MSE(pi3): 1.696e-03\n",
      "Epoch 99900, Train loss: 1.270e+07, Test loss: 9.207e+07, MSE(e): 1.191e-03, MSE(pi1): 6.265e-02, MSE(pi2): 1.315e-03, MSE(pi3): 1.694e-03\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 18000\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64 \n",
    "n_checkpoints = 100\n",
    "\n",
    "second_lr = 1e-4\n",
    "\n",
    "train_loop(model, optimizer, X_train_NN, y_train_NN, f_train_NN, X_test_NN, y_test_NN, f_test_NN,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PGNNIV_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
