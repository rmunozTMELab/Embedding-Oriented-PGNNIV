{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from model.FFT import FFTNonlinearModel\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from vecopsciml.operators.zero_order import Mx, My"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear/spectral_model\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/non_linear_1000_0/non_linear_1000_0.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/non_linear')\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/non_linear/spectral_model')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear_1000_0/non_linear_1000_0.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data splitting in train/test\n",
    "X = torch.tensor(dataset['X_train'], dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(dataset['y_train'], dtype=torch.float32).unsqueeze(1)\n",
    "K = torch.tensor(dataset['k_train'], dtype=torch.float32).unsqueeze(1)\n",
    "f = torch.tensor(dataset['f_train'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X, y, K, f, test_size=0.3, random_state=42)\n",
    "\n",
    "# Data processing and adequacy with our TensOps library\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "# Loading and processing validation data\n",
    "X_val = torch.tensor(dataset['X_val'], dtype=torch.float32).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_modes = 20  # número total de funciones base deseadas\n",
    "device = y_train.values[0].device\n",
    "\n",
    "X_mesh = torch.tensor(dataset['X_mesh'], device=device)\n",
    "Y_mesh = torch.tensor(dataset['Y_mesh'], device=device)\n",
    "\n",
    "deg2rad = torch.pi / 180\n",
    "deg2rad = 1\n",
    "\n",
    "base = []\n",
    "mode_idx = 0\n",
    "max_order = 2 * int(torch.sqrt(torch.tensor(num_modes))) + 1\n",
    "\n",
    "max_m = max_n = int(torch.sqrt(torch.tensor(num_modes))) + 1\n",
    "\n",
    "for s in range(max_order):  # s = m + n\n",
    "    for m in range(s + 1):\n",
    "        n = s - m\n",
    "\n",
    "        if mode_idx == 0:\n",
    "            base.append(torch.ones_like(X_mesh))\n",
    "            mode_idx += 1\n",
    "            if mode_idx >= num_modes:\n",
    "                break\n",
    "\n",
    "        if m > 0 and n > 0:\n",
    "            # A_mn\n",
    "            base.append(torch.cos(2 * torch.pi * m * deg2rad * X_mesh / (max_m - 1) + 2 * torch.pi * n * deg2rad * Y_mesh / (max_n - 1)))\n",
    "            mode_idx += 1\n",
    "            if mode_idx >= num_modes:\n",
    "                break\n",
    "\n",
    "            # B_mn\n",
    "            base.append(torch.sin(2 * torch.pi * m * deg2rad * X_mesh / (max_m - 1) + 2 * torch.pi * n * deg2rad * Y_mesh / (max_n - 1)))\n",
    "            mode_idx += 1\n",
    "            if mode_idx >= num_modes:\n",
    "                break\n",
    "\n",
    "    if mode_idx >= num_modes:\n",
    "        break\n",
    "\n",
    "base = torch.stack(base, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, num_modes]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters \n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 1.229e+08, Test loss: 1.827e+08, MSE(e): 1.063e+01, MSE(pi1): 1.390e+03, MSE(pi2): 9.324e+00, MSE(pi3): 2.719e+01\n",
      "Epoch 100, Train loss: 1.180e+06, Test loss: 1.853e+06, MSE(e): 1.141e-01, MSE(pi1): 2.015e+00, MSE(pi2): 9.504e-02, MSE(pi3): 1.862e-01\n",
      "Epoch 200, Train loss: 4.175e+05, Test loss: 5.530e+05, MSE(e): 3.784e-02, MSE(pi1): 1.976e+00, MSE(pi2): 3.205e-02, MSE(pi3): 1.925e-01\n",
      "Epoch 300, Train loss: 2.728e+05, Test loss: 3.577e+05, MSE(e): 2.341e-02, MSE(pi1): 1.959e+00, MSE(pi2): 1.807e-02, MSE(pi3): 1.909e-01\n",
      "Epoch 400, Train loss: 1.936e+05, Test loss: 2.076e+05, MSE(e): 1.563e-02, MSE(pi1): 1.886e+00, MSE(pi2): 1.193e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 500, Train loss: 1.482e+05, Test loss: 1.631e+05, MSE(e): 1.158e-02, MSE(pi1): 1.631e+00, MSE(pi2): 8.186e-03, MSE(pi3): 1.617e-01\n",
      "Epoch 600, Train loss: 1.103e+05, Test loss: 1.254e+05, MSE(e): 9.077e-03, MSE(pi1): 1.013e+00, MSE(pi2): 6.675e-03, MSE(pi3): 9.359e-02\n",
      "Epoch 700, Train loss: 8.323e+04, Test loss: 9.513e+04, MSE(e): 7.159e-03, MSE(pi1): 6.916e-01, MSE(pi2): 5.321e-03, MSE(pi3): 4.719e-02\n",
      "Epoch 800, Train loss: 7.002e+04, Test loss: 8.339e+04, MSE(e): 6.074e-03, MSE(pi1): 5.975e-01, MSE(pi2): 4.657e-03, MSE(pi3): 3.307e-02\n",
      "Epoch 900, Train loss: 6.974e+04, Test loss: 6.991e+04, MSE(e): 6.144e-03, MSE(pi1): 5.567e-01, MSE(pi2): 4.453e-03, MSE(pi3): 2.732e-02\n",
      "Epoch 1000, Train loss: 7.693e+04, Test loss: 6.689e+04, MSE(e): 6.916e-03, MSE(pi1): 5.327e-01, MSE(pi2): 4.536e-03, MSE(pi3): 2.437e-02\n",
      "Epoch 1100, Train loss: 5.512e+04, Test loss: 6.175e+04, MSE(e): 4.836e-03, MSE(pi1): 4.635e-01, MSE(pi2): 3.670e-03, MSE(pi3): 2.131e-02\n",
      "Epoch 1200, Train loss: 4.798e+04, Test loss: 6.278e+04, MSE(e): 4.163e-03, MSE(pi1): 4.358e-01, MSE(pi2): 3.351e-03, MSE(pi3): 1.986e-02\n",
      "Epoch 1300, Train loss: 4.769e+04, Test loss: 5.584e+04, MSE(e): 4.162e-03, MSE(pi1): 4.208e-01, MSE(pi2): 3.244e-03, MSE(pi3): 1.861e-02\n",
      "Epoch 1400, Train loss: 4.599e+04, Test loss: 4.664e+04, MSE(e): 4.012e-03, MSE(pi1): 4.071e-01, MSE(pi2): 3.102e-03, MSE(pi3): 1.796e-02\n",
      "Epoch 1500, Train loss: 4.239e+04, Test loss: 4.711e+04, MSE(e): 3.679e-03, MSE(pi1): 3.823e-01, MSE(pi2): 2.946e-03, MSE(pi3): 1.772e-02\n",
      "Epoch 1600, Train loss: 4.817e+04, Test loss: 5.313e+04, MSE(e): 4.277e-03, MSE(pi1): 3.738e-01, MSE(pi2): 3.114e-03, MSE(pi3): 1.663e-02\n",
      "Epoch 1700, Train loss: 4.122e+04, Test loss: 5.528e+04, MSE(e): 3.611e-03, MSE(pi1): 3.497e-01, MSE(pi2): 2.784e-03, MSE(pi3): 1.608e-02\n",
      "Epoch 1800, Train loss: 4.365e+04, Test loss: 4.127e+04, MSE(e): 3.862e-03, MSE(pi1): 3.446e-01, MSE(pi2): 2.773e-03, MSE(pi3): 1.579e-02\n",
      "Epoch 1900, Train loss: 3.885e+04, Test loss: 3.976e+04, MSE(e): 3.409e-03, MSE(pi1): 3.258e-01, MSE(pi2): 2.574e-03, MSE(pi3): 1.500e-02\n",
      "Epoch 2000, Train loss: 3.921e+04, Test loss: 3.776e+04, MSE(e): 3.459e-03, MSE(pi1): 3.156e-01, MSE(pi2): 2.512e-03, MSE(pi3): 1.464e-02\n",
      "Epoch 2100, Train loss: 4.238e+04, Test loss: 3.879e+04, MSE(e): 3.779e-03, MSE(pi1): 3.151e-01, MSE(pi2): 2.607e-03, MSE(pi3): 1.433e-02\n",
      "Epoch 2200, Train loss: 3.840e+04, Test loss: 3.744e+04, MSE(e): 3.398e-03, MSE(pi1): 2.999e-01, MSE(pi2): 2.451e-03, MSE(pi3): 1.418e-02\n",
      "Epoch 2300, Train loss: 3.328e+04, Test loss: 3.471e+04, MSE(e): 2.907e-03, MSE(pi1): 2.868e-01, MSE(pi2): 2.292e-03, MSE(pi3): 1.336e-02\n",
      "Epoch 2400, Train loss: 3.697e+04, Test loss: 3.425e+04, MSE(e): 3.290e-03, MSE(pi1): 2.761e-01, MSE(pi2): 2.283e-03, MSE(pi3): 1.313e-02\n",
      "Epoch 2500, Train loss: 3.125e+04, Test loss: 3.289e+04, MSE(e): 2.734e-03, MSE(pi1): 2.659e-01, MSE(pi2): 2.151e-03, MSE(pi3): 1.241e-02\n",
      "Epoch 2600, Train loss: 3.052e+04, Test loss: 4.305e+04, MSE(e): 2.666e-03, MSE(pi1): 2.566e-01, MSE(pi2): 2.099e-03, MSE(pi3): 1.291e-02\n",
      "Epoch 2700, Train loss: 7.372e+04, Test loss: 3.454e+04, MSE(e): 6.983e-03, MSE(pi1): 2.711e-01, MSE(pi2): 2.939e-03, MSE(pi3): 1.171e-02\n",
      "Epoch 2800, Train loss: 2.985e+04, Test loss: 3.067e+04, MSE(e): 2.628e-03, MSE(pi1): 2.407e-01, MSE(pi2): 2.000e-03, MSE(pi3): 1.160e-02\n",
      "Epoch 2900, Train loss: 3.353e+04, Test loss: 3.093e+04, MSE(e): 3.007e-03, MSE(pi1): 2.349e-01, MSE(pi2): 2.059e-03, MSE(pi3): 1.109e-02\n",
      "Epoch 3000, Train loss: 2.714e+04, Test loss: 2.920e+04, MSE(e): 2.379e-03, MSE(pi1): 2.256e-01, MSE(pi2): 1.898e-03, MSE(pi3): 1.094e-02\n",
      "Epoch 3100, Train loss: 4.623e+04, Test loss: 4.032e+04, MSE(e): 4.288e-03, MSE(pi1): 2.269e-01, MSE(pi2): 2.233e-03, MSE(pi3): 1.079e-02\n",
      "Epoch 3200, Train loss: 2.567e+04, Test loss: 2.808e+04, MSE(e): 2.253e-03, MSE(pi1): 2.110e-01, MSE(pi2): 1.795e-03, MSE(pi3): 1.033e-02\n",
      "Epoch 3300, Train loss: 2.475e+04, Test loss: 2.725e+04, MSE(e): 2.171e-03, MSE(pi1): 2.045e-01, MSE(pi2): 1.749e-03, MSE(pi3): 9.997e-03\n",
      "Epoch 3400, Train loss: 2.424e+04, Test loss: 2.676e+04, MSE(e): 2.128e-03, MSE(pi1): 1.976e-01, MSE(pi2): 1.709e-03, MSE(pi3): 9.797e-03\n",
      "Epoch 3500, Train loss: 3.124e+04, Test loss: 3.497e+04, MSE(e): 2.821e-03, MSE(pi1): 2.065e-01, MSE(pi2): 1.828e-03, MSE(pi3): 9.621e-03\n",
      "Epoch 3600, Train loss: 2.634e+04, Test loss: 3.359e+04, MSE(e): 2.355e-03, MSE(pi1): 1.853e-01, MSE(pi2): 1.687e-03, MSE(pi3): 9.317e-03\n",
      "Epoch 3700, Train loss: 3.450e+04, Test loss: 2.709e+04, MSE(e): 3.159e-03, MSE(pi1): 1.980e-01, MSE(pi2): 1.874e-03, MSE(pi3): 9.214e-03\n",
      "Epoch 3800, Train loss: 2.659e+04, Test loss: 3.169e+04, MSE(e): 2.392e-03, MSE(pi1): 1.765e-01, MSE(pi2): 1.662e-03, MSE(pi3): 9.026e-03\n",
      "Epoch 3900, Train loss: 2.233e+04, Test loss: 2.523e+04, MSE(e): 1.977e-03, MSE(pi1): 1.725e-01, MSE(pi2): 1.527e-03, MSE(pi3): 8.334e-03\n",
      "Epoch 4000, Train loss: 2.133e+04, Test loss: 2.369e+04, MSE(e): 1.883e-03, MSE(pi1): 1.662e-01, MSE(pi2): 1.469e-03, MSE(pi3): 8.352e-03\n",
      "Epoch 4100, Train loss: 2.041e+04, Test loss: 2.323e+04, MSE(e): 1.797e-03, MSE(pi1): 1.623e-01, MSE(pi2): 1.436e-03, MSE(pi3): 8.160e-03\n",
      "Epoch 4200, Train loss: 1.983e+04, Test loss: 2.288e+04, MSE(e): 1.744e-03, MSE(pi1): 1.611e-01, MSE(pi2): 1.402e-03, MSE(pi3): 7.760e-03\n",
      "Epoch 4300, Train loss: 1.968e+04, Test loss: 2.237e+04, MSE(e): 1.735e-03, MSE(pi1): 1.560e-01, MSE(pi2): 1.364e-03, MSE(pi3): 7.690e-03\n",
      "Epoch 4400, Train loss: 3.186e+04, Test loss: 4.594e+04, MSE(e): 2.928e-03, MSE(pi1): 1.717e-01, MSE(pi2): 1.624e-03, MSE(pi3): 8.615e-03\n",
      "Epoch 4500, Train loss: 2.652e+04, Test loss: 2.575e+04, MSE(e): 2.423e-03, MSE(pi1): 1.526e-01, MSE(pi2): 1.474e-03, MSE(pi3): 7.655e-03\n",
      "Epoch 4600, Train loss: 1.887e+04, Test loss: 2.542e+04, MSE(e): 1.667e-03, MSE(pi1): 1.456e-01, MSE(pi2): 1.276e-03, MSE(pi3): 7.427e-03\n",
      "Epoch 4700, Train loss: 2.952e+04, Test loss: 2.636e+04, MSE(e): 2.728e-03, MSE(pi1): 1.502e-01, MSE(pi2): 1.494e-03, MSE(pi3): 7.371e-03\n",
      "Epoch 4800, Train loss: 1.803e+04, Test loss: 2.095e+04, MSE(e): 1.588e-03, MSE(pi1): 1.463e-01, MSE(pi2): 1.224e-03, MSE(pi3): 6.910e-03\n",
      "Epoch 4900, Train loss: 4.373e+04, Test loss: 3.190e+04, MSE(e): 4.149e-03, MSE(pi1): 1.542e-01, MSE(pi2): 1.706e-03, MSE(pi3): 6.953e-03\n",
      "Epoch 5000, Train loss: 1.665e+04, Test loss: 2.031e+04, MSE(e): 1.460e-03, MSE(pi1): 1.384e-01, MSE(pi2): 1.152e-03, MSE(pi3): 6.658e-03\n",
      "Epoch 5100, Train loss: 1.632e+04, Test loss: 1.969e+04, MSE(e): 1.429e-03, MSE(pi1): 1.372e-01, MSE(pi2): 1.135e-03, MSE(pi3): 6.571e-03\n",
      "Epoch 5200, Train loss: 1.683e+04, Test loss: 2.179e+04, MSE(e): 1.483e-03, MSE(pi1): 1.355e-01, MSE(pi2): 1.119e-03, MSE(pi3): 6.415e-03\n",
      "Epoch 5300, Train loss: 1.955e+04, Test loss: 1.913e+04, MSE(e): 1.753e-03, MSE(pi1): 1.389e-01, MSE(pi2): 1.165e-03, MSE(pi3): 6.376e-03\n",
      "Epoch 5400, Train loss: 1.520e+04, Test loss: 2.032e+04, MSE(e): 1.322e-03, MSE(pi1): 1.356e-01, MSE(pi2): 1.057e-03, MSE(pi3): 6.247e-03\n",
      "Epoch 5500, Train loss: 1.593e+04, Test loss: 1.945e+04, MSE(e): 1.394e-03, MSE(pi1): 1.378e-01, MSE(pi2): 1.063e-03, MSE(pi3): 6.057e-03\n",
      "Epoch 5600, Train loss: 1.650e+04, Test loss: 2.378e+04, MSE(e): 1.452e-03, MSE(pi1): 1.345e-01, MSE(pi2): 1.084e-03, MSE(pi3): 6.251e-03\n",
      "Epoch 5700, Train loss: 1.462e+04, Test loss: 1.803e+04, MSE(e): 1.267e-03, MSE(pi1): 1.355e-01, MSE(pi2): 9.996e-04, MSE(pi3): 5.902e-03\n",
      "Epoch 5800, Train loss: 1.585e+04, Test loss: 1.776e+04, MSE(e): 1.391e-03, MSE(pi1): 1.358e-01, MSE(pi2): 1.029e-03, MSE(pi3): 5.872e-03\n",
      "Epoch 5900, Train loss: 1.827e+04, Test loss: 1.911e+04, MSE(e): 1.634e-03, MSE(pi1): 1.331e-01, MSE(pi2): 1.068e-03, MSE(pi3): 5.938e-03\n",
      "Epoch 6000, Train loss: 1.491e+04, Test loss: 1.743e+04, MSE(e): 1.302e-03, MSE(pi1): 1.321e-01, MSE(pi2): 9.746e-04, MSE(pi3): 5.692e-03\n",
      "Epoch 6100, Train loss: 1.551e+04, Test loss: 1.877e+04, MSE(e): 1.364e-03, MSE(pi1): 1.321e-01, MSE(pi2): 9.788e-04, MSE(pi3): 5.542e-03\n",
      "Epoch 6200, Train loss: 2.088e+04, Test loss: 2.933e+04, MSE(e): 1.894e-03, MSE(pi1): 1.352e-01, MSE(pi2): 1.128e-03, MSE(pi3): 5.846e-03\n",
      "Epoch 6300, Train loss: 2.092e+04, Test loss: 1.801e+04, MSE(e): 1.899e-03, MSE(pi1): 1.389e-01, MSE(pi2): 1.085e-03, MSE(pi3): 5.417e-03\n",
      "Epoch 6400, Train loss: 1.678e+04, Test loss: 1.675e+04, MSE(e): 1.491e-03, MSE(pi1): 1.324e-01, MSE(pi2): 9.901e-04, MSE(pi3): 5.512e-03\n",
      "Epoch 6500, Train loss: 1.362e+04, Test loss: 1.648e+04, MSE(e): 1.177e-03, MSE(pi1): 1.310e-01, MSE(pi2): 9.042e-04, MSE(pi3): 5.370e-03\n",
      "Epoch 6600, Train loss: 1.622e+04, Test loss: 1.671e+04, MSE(e): 1.434e-03, MSE(pi1): 1.346e-01, MSE(pi2): 9.459e-04, MSE(pi3): 5.311e-03\n",
      "Epoch 6700, Train loss: 1.549e+04, Test loss: 2.265e+04, MSE(e): 1.359e-03, MSE(pi1): 1.364e-01, MSE(pi2): 9.439e-04, MSE(pi3): 5.414e-03\n",
      "Epoch 6800, Train loss: 1.556e+04, Test loss: 1.617e+04, MSE(e): 1.372e-03, MSE(pi1): 1.304e-01, MSE(pi2): 9.281e-04, MSE(pi3): 5.311e-03\n",
      "Epoch 6900, Train loss: 1.468e+04, Test loss: 1.795e+04, MSE(e): 1.284e-03, MSE(pi1): 1.323e-01, MSE(pi2): 9.391e-04, MSE(pi3): 5.084e-03\n",
      "Epoch 7000, Train loss: 1.407e+04, Test loss: 1.897e+04, MSE(e): 1.225e-03, MSE(pi1): 1.304e-01, MSE(pi2): 8.605e-04, MSE(pi3): 5.159e-03\n",
      "Epoch 7100, Train loss: 1.529e+04, Test loss: 1.707e+04, MSE(e): 1.344e-03, MSE(pi1): 1.337e-01, MSE(pi2): 9.139e-04, MSE(pi3): 5.083e-03\n",
      "Epoch 7200, Train loss: 1.217e+04, Test loss: 1.600e+04, MSE(e): 1.039e-03, MSE(pi1): 1.278e-01, MSE(pi2): 8.227e-04, MSE(pi3): 4.976e-03\n",
      "Epoch 7300, Train loss: 1.755e+04, Test loss: 1.861e+04, MSE(e): 1.561e-03, MSE(pi1): 1.425e-01, MSE(pi2): 9.366e-04, MSE(pi3): 5.066e-03\n",
      "Epoch 7400, Train loss: 1.476e+04, Test loss: 1.553e+04, MSE(e): 1.291e-03, MSE(pi1): 1.362e-01, MSE(pi2): 8.597e-04, MSE(pi3): 4.861e-03\n",
      "Epoch 7500, Train loss: 1.674e+04, Test loss: 1.762e+04, MSE(e): 1.485e-03, MSE(pi1): 1.397e-01, MSE(pi2): 9.001e-04, MSE(pi3): 4.841e-03\n",
      "Epoch 7600, Train loss: 1.724e+04, Test loss: 1.697e+04, MSE(e): 1.534e-03, MSE(pi1): 1.400e-01, MSE(pi2): 9.413e-04, MSE(pi3): 5.038e-03\n",
      "Epoch 7700, Train loss: 1.308e+04, Test loss: 1.652e+04, MSE(e): 1.129e-03, MSE(pi1): 1.309e-01, MSE(pi2): 8.060e-04, MSE(pi3): 4.800e-03\n",
      "Epoch 7800, Train loss: 1.315e+04, Test loss: 1.695e+04, MSE(e): 1.137e-03, MSE(pi1): 1.300e-01, MSE(pi2): 8.037e-04, MSE(pi3): 4.760e-03\n",
      "Epoch 7900, Train loss: 1.247e+04, Test loss: 1.671e+04, MSE(e): 1.071e-03, MSE(pi1): 1.283e-01, MSE(pi2): 7.831e-04, MSE(pi3): 4.710e-03\n",
      "Epoch 8000, Train loss: 1.285e+04, Test loss: 1.610e+04, MSE(e): 1.110e-03, MSE(pi1): 1.280e-01, MSE(pi2): 7.945e-04, MSE(pi3): 4.682e-03\n",
      "Epoch 8100, Train loss: 1.217e+04, Test loss: 1.605e+04, MSE(e): 1.043e-03, MSE(pi1): 1.273e-01, MSE(pi2): 7.656e-04, MSE(pi3): 4.644e-03\n",
      "Epoch 8200, Train loss: 1.323e+04, Test loss: 1.468e+04, MSE(e): 1.146e-03, MSE(pi1): 1.295e-01, MSE(pi2): 7.654e-04, MSE(pi3): 4.680e-03\n",
      "Epoch 8300, Train loss: 1.622e+04, Test loss: 1.744e+04, MSE(e): 1.440e-03, MSE(pi1): 1.351e-01, MSE(pi2): 8.586e-04, MSE(pi3): 4.681e-03\n",
      "Epoch 8400, Train loss: 2.071e+04, Test loss: 1.433e+04, MSE(e): 1.895e-03, MSE(pi1): 1.286e-01, MSE(pi2): 9.926e-04, MSE(pi3): 4.723e-03\n",
      "Epoch 8500, Train loss: 1.356e+04, Test loss: 1.404e+04, MSE(e): 1.183e-03, MSE(pi1): 1.283e-01, MSE(pi2): 7.977e-04, MSE(pi3): 4.492e-03\n",
      "Epoch 8600, Train loss: 1.241e+04, Test loss: 1.486e+04, MSE(e): 1.071e-03, MSE(pi1): 1.257e-01, MSE(pi2): 7.588e-04, MSE(pi3): 4.445e-03\n",
      "Epoch 8700, Train loss: 1.249e+04, Test loss: 1.438e+04, MSE(e): 1.078e-03, MSE(pi1): 1.253e-01, MSE(pi2): 7.288e-04, MSE(pi3): 4.538e-03\n",
      "Epoch 8800, Train loss: 1.741e+04, Test loss: 1.545e+04, MSE(e): 1.569e-03, MSE(pi1): 1.248e-01, MSE(pi2): 9.097e-04, MSE(pi3): 4.662e-03\n",
      "Epoch 8900, Train loss: 1.260e+04, Test loss: 1.370e+04, MSE(e): 1.091e-03, MSE(pi1): 1.257e-01, MSE(pi2): 7.585e-04, MSE(pi3): 4.348e-03\n",
      "Epoch 9000, Train loss: 1.166e+04, Test loss: 1.490e+04, MSE(e): 1.001e-03, MSE(pi1): 1.216e-01, MSE(pi2): 7.261e-04, MSE(pi3): 4.383e-03\n",
      "Epoch 9100, Train loss: 1.761e+04, Test loss: 1.455e+04, MSE(e): 1.591e-03, MSE(pi1): 1.243e-01, MSE(pi2): 9.070e-04, MSE(pi3): 4.553e-03\n",
      "Epoch 9200, Train loss: 1.130e+04, Test loss: 1.459e+04, MSE(e): 9.686e-04, MSE(pi1): 1.188e-01, MSE(pi2): 7.176e-04, MSE(pi3): 4.274e-03\n",
      "Epoch 9300, Train loss: 1.169e+04, Test loss: 1.357e+04, MSE(e): 1.010e-03, MSE(pi1): 1.154e-01, MSE(pi2): 7.271e-04, MSE(pi3): 4.392e-03\n",
      "Epoch 9400, Train loss: 1.081e+04, Test loss: 1.330e+04, MSE(e): 9.202e-04, MSE(pi1): 1.201e-01, MSE(pi2): 6.911e-04, MSE(pi3): 4.058e-03\n",
      "Epoch 9500, Train loss: 1.089e+04, Test loss: 1.649e+04, MSE(e): 9.303e-04, MSE(pi1): 1.178e-01, MSE(pi2): 6.989e-04, MSE(pi3): 4.055e-03\n",
      "Epoch 9600, Train loss: 1.157e+04, Test loss: 1.344e+04, MSE(e): 1.001e-03, MSE(pi1): 1.111e-01, MSE(pi2): 7.007e-04, MSE(pi3): 4.448e-03\n",
      "Epoch 9700, Train loss: 1.097e+04, Test loss: 1.327e+04, MSE(e): 9.398e-04, MSE(pi1): 1.134e-01, MSE(pi2): 7.102e-04, MSE(pi3): 4.375e-03\n",
      "Epoch 9800, Train loss: 1.000e+04, Test loss: 1.431e+04, MSE(e): 8.422e-04, MSE(pi1): 1.170e-01, MSE(pi2): 6.525e-04, MSE(pi3): 4.096e-03\n",
      "Epoch 9900, Train loss: 1.389e+04, Test loss: 1.257e+04, MSE(e): 1.234e-03, MSE(pi1): 1.127e-01, MSE(pi2): 7.634e-04, MSE(pi3): 4.205e-03\n",
      "Epoch 10000, Train loss: 1.120e+04, Test loss: 1.436e+04, MSE(e): 9.678e-04, MSE(pi1): 1.081e-01, MSE(pi2): 7.027e-04, MSE(pi3): 4.390e-03\n",
      "Epoch 10100, Train loss: 1.097e+04, Test loss: 1.325e+04, MSE(e): 9.448e-04, MSE(pi1): 1.124e-01, MSE(pi2): 6.818e-04, MSE(pi3): 3.962e-03\n",
      "Epoch 10200, Train loss: 9.982e+03, Test loss: 1.237e+04, MSE(e): 8.467e-04, MSE(pi1): 1.109e-01, MSE(pi2): 6.361e-04, MSE(pi3): 4.058e-03\n",
      "Epoch 10300, Train loss: 1.018e+04, Test loss: 1.314e+04, MSE(e): 8.681e-04, MSE(pi1): 1.105e-01, MSE(pi2): 6.537e-04, MSE(pi3): 3.904e-03\n",
      "Epoch 10400, Train loss: 1.249e+04, Test loss: 1.190e+04, MSE(e): 1.098e-03, MSE(pi1): 1.104e-01, MSE(pi2): 7.084e-04, MSE(pi3): 4.030e-03\n",
      "Epoch 10500, Train loss: 1.002e+04, Test loss: 1.280e+04, MSE(e): 8.521e-04, MSE(pi1): 1.113e-01, MSE(pi2): 6.443e-04, MSE(pi3): 3.905e-03\n",
      "Epoch 10600, Train loss: 1.024e+04, Test loss: 1.464e+04, MSE(e): 8.734e-04, MSE(pi1): 1.062e-01, MSE(pi2): 6.514e-04, MSE(pi3): 4.491e-03\n",
      "Epoch 10700, Train loss: 1.051e+04, Test loss: 1.230e+04, MSE(e): 9.017e-04, MSE(pi1): 1.095e-01, MSE(pi2): 6.334e-04, MSE(pi3): 3.959e-03\n",
      "Epoch 10800, Train loss: 1.030e+04, Test loss: 1.182e+04, MSE(e): 8.802e-04, MSE(pi1): 1.106e-01, MSE(pi2): 6.356e-04, MSE(pi3): 3.936e-03\n",
      "Epoch 10900, Train loss: 1.951e+04, Test loss: 1.548e+04, MSE(e): 1.795e-03, MSE(pi1): 1.133e-01, MSE(pi2): 8.714e-04, MSE(pi3): 4.240e-03\n",
      "Epoch 11000, Train loss: 9.085e+03, Test loss: 1.137e+04, MSE(e): 7.618e-04, MSE(pi1): 1.079e-01, MSE(pi2): 5.936e-04, MSE(pi3): 3.880e-03\n",
      "Epoch 11100, Train loss: 1.036e+04, Test loss: 1.183e+04, MSE(e): 8.899e-04, MSE(pi1): 1.068e-01, MSE(pi2): 6.397e-04, MSE(pi3): 3.880e-03\n",
      "Epoch 11200, Train loss: 1.012e+04, Test loss: 1.131e+04, MSE(e): 8.666e-04, MSE(pi1): 1.062e-01, MSE(pi2): 6.283e-04, MSE(pi3): 3.869e-03\n",
      "Epoch 11300, Train loss: 9.108e+03, Test loss: 1.104e+04, MSE(e): 7.673e-04, MSE(pi1): 1.052e-01, MSE(pi2): 5.978e-04, MSE(pi3): 3.831e-03\n",
      "Epoch 11400, Train loss: 9.223e+03, Test loss: 1.152e+04, MSE(e): 7.784e-04, MSE(pi1): 1.054e-01, MSE(pi2): 6.033e-04, MSE(pi3): 3.834e-03\n",
      "Epoch 11500, Train loss: 9.503e+03, Test loss: 1.125e+04, MSE(e): 8.006e-04, MSE(pi1): 1.160e-01, MSE(pi2): 5.795e-04, MSE(pi3): 3.356e-03\n",
      "Epoch 11600, Train loss: 8.942e+03, Test loss: 1.102e+04, MSE(e): 7.507e-04, MSE(pi1): 1.084e-01, MSE(pi2): 5.861e-04, MSE(pi3): 3.507e-03\n",
      "Epoch 11700, Train loss: 1.346e+04, Test loss: 1.082e+04, MSE(e): 1.203e-03, MSE(pi1): 1.049e-01, MSE(pi2): 7.003e-04, MSE(pi3): 3.769e-03\n",
      "Epoch 11800, Train loss: 9.387e+03, Test loss: 1.097e+04, MSE(e): 7.979e-04, MSE(pi1): 1.037e-01, MSE(pi2): 5.946e-04, MSE(pi3): 3.708e-03\n",
      "Epoch 11900, Train loss: 1.184e+04, Test loss: 1.079e+04, MSE(e): 1.042e-03, MSE(pi1): 1.053e-01, MSE(pi2): 6.527e-04, MSE(pi3): 3.699e-03\n",
      "Epoch 12000, Train loss: 8.769e+03, Test loss: 1.139e+04, MSE(e): 7.366e-04, MSE(pi1): 1.042e-01, MSE(pi2): 5.568e-04, MSE(pi3): 3.607e-03\n",
      "Epoch 12100, Train loss: 1.114e+04, Test loss: 1.188e+04, MSE(e): 9.747e-04, MSE(pi1): 9.980e-02, MSE(pi2): 6.309e-04, MSE(pi3): 3.964e-03\n",
      "Epoch 12200, Train loss: 2.269e+04, Test loss: 1.100e+04, MSE(e): 2.120e-03, MSE(pi1): 1.106e-01, MSE(pi2): 9.318e-04, MSE(pi3): 3.824e-03\n",
      "Epoch 12300, Train loss: 9.322e+03, Test loss: 1.081e+04, MSE(e): 7.933e-04, MSE(pi1): 1.025e-01, MSE(pi2): 5.875e-04, MSE(pi3): 3.639e-03\n",
      "Epoch 12400, Train loss: 1.187e+04, Test loss: 1.033e+04, MSE(e): 1.048e-03, MSE(pi1): 1.019e-01, MSE(pi2): 6.457e-04, MSE(pi3): 3.653e-03\n",
      "Epoch 12500, Train loss: 8.606e+03, Test loss: 1.028e+04, MSE(e): 7.216e-04, MSE(pi1): 1.031e-01, MSE(pi2): 5.583e-04, MSE(pi3): 3.583e-03\n",
      "Epoch 12600, Train loss: 8.495e+03, Test loss: 1.043e+04, MSE(e): 7.123e-04, MSE(pi1): 1.013e-01, MSE(pi2): 5.466e-04, MSE(pi3): 3.583e-03\n",
      "Epoch 12700, Train loss: 8.540e+03, Test loss: 1.014e+04, MSE(e): 7.168e-04, MSE(pi1): 1.012e-01, MSE(pi2): 5.543e-04, MSE(pi3): 3.593e-03\n",
      "Epoch 12800, Train loss: 1.671e+04, Test loss: 1.027e+04, MSE(e): 1.524e-03, MSE(pi1): 1.098e-01, MSE(pi2): 7.940e-04, MSE(pi3): 3.735e-03\n",
      "Epoch 12900, Train loss: 9.185e+03, Test loss: 1.021e+04, MSE(e): 7.804e-04, MSE(pi1): 1.018e-01, MSE(pi2): 5.649e-04, MSE(pi3): 3.625e-03\n",
      "Epoch 13000, Train loss: 1.179e+04, Test loss: 1.002e+04, MSE(e): 1.037e-03, MSE(pi1): 1.053e-01, MSE(pi2): 6.196e-04, MSE(pi3): 3.644e-03\n",
      "Epoch 13100, Train loss: 8.269e+03, Test loss: 1.018e+04, MSE(e): 6.926e-04, MSE(pi1): 9.877e-02, MSE(pi2): 5.365e-04, MSE(pi3): 3.553e-03\n",
      "Epoch 13200, Train loss: 1.115e+04, Test loss: 1.040e+04, MSE(e): 9.787e-04, MSE(pi1): 1.000e-01, MSE(pi2): 6.167e-04, MSE(pi3): 3.576e-03\n",
      "Epoch 13300, Train loss: 8.103e+03, Test loss: 9.939e+03, MSE(e): 6.750e-04, MSE(pi1): 1.008e-01, MSE(pi2): 5.278e-04, MSE(pi3): 3.446e-03\n",
      "Epoch 13400, Train loss: 8.093e+03, Test loss: 9.801e+03, MSE(e): 6.751e-04, MSE(pi1): 9.952e-02, MSE(pi2): 5.203e-04, MSE(pi3): 3.469e-03\n",
      "Epoch 13500, Train loss: 8.507e+03, Test loss: 9.952e+03, MSE(e): 7.155e-04, MSE(pi1): 9.996e-02, MSE(pi2): 5.215e-04, MSE(pi3): 3.526e-03\n",
      "Epoch 13600, Train loss: 8.623e+03, Test loss: 1.181e+04, MSE(e): 7.291e-04, MSE(pi1): 9.951e-02, MSE(pi2): 5.220e-04, MSE(pi3): 3.368e-03\n",
      "Epoch 13700, Train loss: 7.947e+03, Test loss: 1.020e+04, MSE(e): 6.615e-04, MSE(pi1): 9.856e-02, MSE(pi2): 5.124e-04, MSE(pi3): 3.457e-03\n",
      "Epoch 13800, Train loss: 8.942e+03, Test loss: 1.011e+04, MSE(e): 7.625e-04, MSE(pi1): 9.605e-02, MSE(pi2): 5.456e-04, MSE(pi3): 3.559e-03\n",
      "Epoch 13900, Train loss: 9.978e+03, Test loss: 1.114e+04, MSE(e): 8.624e-04, MSE(pi1): 1.033e-01, MSE(pi2): 5.658e-04, MSE(pi3): 3.207e-03\n",
      "Epoch 14000, Train loss: 1.310e+04, Test loss: 1.163e+04, MSE(e): 1.179e-03, MSE(pi1): 9.613e-02, MSE(pi2): 6.515e-04, MSE(pi3): 3.541e-03\n",
      "Epoch 14100, Train loss: 8.785e+03, Test loss: 1.198e+04, MSE(e): 7.481e-04, MSE(pi1): 9.505e-02, MSE(pi2): 5.271e-04, MSE(pi3): 3.523e-03\n",
      "Epoch 14200, Train loss: 1.626e+04, Test loss: 9.656e+03, MSE(e): 1.483e-03, MSE(pi1): 1.075e-01, MSE(pi2): 7.534e-04, MSE(pi3): 3.547e-03\n",
      "Epoch 14300, Train loss: 8.149e+03, Test loss: 9.515e+03, MSE(e): 6.834e-04, MSE(pi1): 9.786e-02, MSE(pi2): 5.081e-04, MSE(pi3): 3.364e-03\n",
      "Epoch 14400, Train loss: 7.927e+03, Test loss: 9.672e+03, MSE(e): 6.613e-04, MSE(pi1): 9.980e-02, MSE(pi2): 4.991e-04, MSE(pi3): 3.157e-03\n",
      "Epoch 14500, Train loss: 9.477e+03, Test loss: 9.590e+03, MSE(e): 8.175e-04, MSE(pi1): 9.672e-02, MSE(pi2): 5.469e-04, MSE(pi3): 3.342e-03\n",
      "Epoch 14600, Train loss: 1.345e+04, Test loss: 9.891e+03, MSE(e): 1.213e-03, MSE(pi1): 9.834e-02, MSE(pi2): 6.529e-04, MSE(pi3): 3.400e-03\n",
      "Epoch 14700, Train loss: 9.498e+03, Test loss: 1.055e+04, MSE(e): 8.219e-04, MSE(pi1): 9.261e-02, MSE(pi2): 5.580e-04, MSE(pi3): 3.528e-03\n",
      "Epoch 14800, Train loss: 8.525e+03, Test loss: 9.498e+03, MSE(e): 7.229e-04, MSE(pi1): 9.720e-02, MSE(pi2): 5.112e-04, MSE(pi3): 3.229e-03\n",
      "Epoch 14900, Train loss: 7.671e+03, Test loss: 9.435e+03, MSE(e): 6.384e-04, MSE(pi1): 9.578e-02, MSE(pi2): 4.883e-04, MSE(pi3): 3.285e-03\n",
      "Epoch 15000, Train loss: 8.462e+03, Test loss: 9.741e+03, MSE(e): 7.151e-04, MSE(pi1): 9.757e-02, MSE(pi2): 4.969e-04, MSE(pi3): 3.341e-03\n",
      "Epoch 15100, Train loss: 8.857e+03, Test loss: 1.112e+04, MSE(e): 7.568e-04, MSE(pi1): 9.642e-02, MSE(pi2): 5.012e-04, MSE(pi3): 3.239e-03\n",
      "Epoch 15200, Train loss: 8.050e+03, Test loss: 9.384e+03, MSE(e): 6.753e-04, MSE(pi1): 9.756e-02, MSE(pi2): 4.869e-04, MSE(pi3): 3.210e-03\n",
      "Epoch 15300, Train loss: 1.401e+04, Test loss: 1.457e+04, MSE(e): 1.266e-03, MSE(pi1): 1.016e-01, MSE(pi2): 6.089e-04, MSE(pi3): 3.353e-03\n",
      "Epoch 15400, Train loss: 7.578e+03, Test loss: 9.162e+03, MSE(e): 6.290e-04, MSE(pi1): 9.763e-02, MSE(pi2): 4.743e-04, MSE(pi3): 3.108e-03\n",
      "Epoch 15500, Train loss: 7.676e+03, Test loss: 9.005e+03, MSE(e): 6.396e-04, MSE(pi1): 9.472e-02, MSE(pi2): 4.813e-04, MSE(pi3): 3.323e-03\n",
      "Epoch 15600, Train loss: 7.448e+03, Test loss: 9.385e+03, MSE(e): 6.164e-04, MSE(pi1): 9.468e-02, MSE(pi2): 4.694e-04, MSE(pi3): 3.362e-03\n",
      "Epoch 15700, Train loss: 2.804e+04, Test loss: 1.090e+04, MSE(e): 2.659e-03, MSE(pi1): 1.071e-01, MSE(pi2): 1.067e-03, MSE(pi3): 3.830e-03\n",
      "Epoch 15800, Train loss: 7.440e+03, Test loss: 8.919e+03, MSE(e): 6.163e-04, MSE(pi1): 9.541e-02, MSE(pi2): 4.586e-04, MSE(pi3): 3.217e-03\n",
      "Epoch 15900, Train loss: 8.849e+03, Test loss: 8.975e+03, MSE(e): 7.564e-04, MSE(pi1): 9.644e-02, MSE(pi2): 5.109e-04, MSE(pi3): 3.204e-03\n",
      "Epoch 16000, Train loss: 7.165e+03, Test loss: 8.896e+03, MSE(e): 5.897e-04, MSE(pi1): 9.487e-02, MSE(pi2): 4.584e-04, MSE(pi3): 3.190e-03\n",
      "Epoch 16100, Train loss: 9.573e+03, Test loss: 1.275e+04, MSE(e): 8.273e-04, MSE(pi1): 9.824e-02, MSE(pi2): 5.183e-04, MSE(pi3): 3.170e-03\n",
      "Epoch 16200, Train loss: 7.318e+03, Test loss: 9.070e+03, MSE(e): 6.053e-04, MSE(pi1): 9.474e-02, MSE(pi2): 4.648e-04, MSE(pi3): 3.168e-03\n",
      "Epoch 16300, Train loss: 1.700e+04, Test loss: 9.413e+03, MSE(e): 1.566e-03, MSE(pi1): 1.009e-01, MSE(pi2): 7.555e-04, MSE(pi3): 3.349e-03\n",
      "Epoch 16400, Train loss: 8.447e+03, Test loss: 1.422e+04, MSE(e): 7.186e-04, MSE(pi1): 9.201e-02, MSE(pi2): 4.994e-04, MSE(pi3): 3.398e-03\n",
      "Epoch 16500, Train loss: 7.179e+03, Test loss: 8.931e+03, MSE(e): 5.926e-04, MSE(pi1): 9.361e-02, MSE(pi2): 4.562e-04, MSE(pi3): 3.161e-03\n",
      "Epoch 16600, Train loss: 7.776e+03, Test loss: 9.169e+03, MSE(e): 6.526e-04, MSE(pi1): 9.353e-02, MSE(pi2): 4.669e-04, MSE(pi3): 3.140e-03\n",
      "Epoch 16700, Train loss: 1.130e+04, Test loss: 9.105e+03, MSE(e): 1.004e-03, MSE(pi1): 9.339e-02, MSE(pi2): 5.572e-04, MSE(pi3): 3.305e-03\n",
      "Epoch 16800, Train loss: 9.872e+03, Test loss: 1.481e+04, MSE(e): 8.632e-04, MSE(pi1): 8.934e-02, MSE(pi2): 5.508e-04, MSE(pi3): 3.463e-03\n",
      "Epoch 16900, Train loss: 1.402e+04, Test loss: 1.070e+04, MSE(e): 1.276e-03, MSE(pi1): 9.425e-02, MSE(pi2): 6.342e-04, MSE(pi3): 3.189e-03\n",
      "Epoch 17000, Train loss: 8.495e+03, Test loss: 8.671e+03, MSE(e): 7.235e-04, MSE(pi1): 9.509e-02, MSE(pi2): 4.965e-04, MSE(pi3): 3.082e-03\n",
      "Epoch 17100, Train loss: 7.284e+03, Test loss: 8.734e+03, MSE(e): 6.038e-04, MSE(pi1): 9.422e-02, MSE(pi2): 4.468e-04, MSE(pi3): 3.026e-03\n",
      "Epoch 17200, Train loss: 7.175e+03, Test loss: 8.728e+03, MSE(e): 5.929e-04, MSE(pi1): 9.305e-02, MSE(pi2): 4.496e-04, MSE(pi3): 3.145e-03\n",
      "Epoch 17300, Train loss: 8.805e+03, Test loss: 1.517e+04, MSE(e): 7.509e-04, MSE(pi1): 9.734e-02, MSE(pi2): 4.664e-04, MSE(pi3): 3.224e-03\n",
      "Epoch 17400, Train loss: 8.572e+03, Test loss: 9.005e+03, MSE(e): 7.310e-04, MSE(pi1): 9.506e-02, MSE(pi2): 4.736e-04, MSE(pi3): 3.112e-03\n",
      "Epoch 17500, Train loss: 7.186e+03, Test loss: 9.144e+03, MSE(e): 5.952e-04, MSE(pi1): 9.080e-02, MSE(pi2): 4.417e-04, MSE(pi3): 3.252e-03\n",
      "Epoch 17600, Train loss: 7.392e+03, Test loss: 8.504e+03, MSE(e): 6.150e-04, MSE(pi1): 9.379e-02, MSE(pi2): 4.515e-04, MSE(pi3): 3.040e-03\n",
      "Epoch 17700, Train loss: 1.114e+04, Test loss: 8.652e+03, MSE(e): 9.878e-04, MSE(pi1): 9.502e-02, MSE(pi2): 5.591e-04, MSE(pi3): 3.125e-03\n",
      "Epoch 17800, Train loss: 8.271e+03, Test loss: 9.175e+03, MSE(e): 7.034e-04, MSE(pi1): 9.240e-02, MSE(pi2): 4.785e-04, MSE(pi3): 3.130e-03\n",
      "Epoch 17900, Train loss: 1.218e+04, Test loss: 9.112e+03, MSE(e): 1.093e-03, MSE(pi1): 9.402e-02, MSE(pi2): 5.784e-04, MSE(pi3): 3.090e-03\n",
      "Epoch 18000, Train loss: 7.156e+03, Test loss: 8.491e+03, MSE(e): 5.917e-04, MSE(pi1): 9.393e-02, MSE(pi2): 4.362e-04, MSE(pi3): 2.991e-03\n",
      "Epoch 18100, Train loss: 7.192e+03, Test loss: 8.725e+03, MSE(e): 5.978e-04, MSE(pi1): 9.097e-02, MSE(pi2): 4.613e-04, MSE(pi3): 3.038e-03\n",
      "Epoch 18200, Train loss: 8.148e+03, Test loss: 8.457e+03, MSE(e): 6.925e-04, MSE(pi1): 9.101e-02, MSE(pi2): 4.723e-04, MSE(pi3): 3.122e-03\n",
      "Epoch 18300, Train loss: 7.410e+03, Test loss: 8.461e+03, MSE(e): 6.173e-04, MSE(pi1): 9.334e-02, MSE(pi2): 4.379e-04, MSE(pi3): 3.030e-03\n",
      "Epoch 18400, Train loss: 7.084e+03, Test loss: 8.858e+03, MSE(e): 5.857e-04, MSE(pi1): 9.098e-02, MSE(pi2): 4.544e-04, MSE(pi3): 3.176e-03\n",
      "Epoch 18500, Train loss: 8.209e+03, Test loss: 1.008e+04, MSE(e): 6.955e-04, MSE(pi1): 9.252e-02, MSE(pi2): 4.849e-04, MSE(pi3): 3.281e-03\n",
      "Epoch 18600, Train loss: 7.756e+03, Test loss: 8.823e+03, MSE(e): 6.524e-04, MSE(pi1): 9.357e-02, MSE(pi2): 4.550e-04, MSE(pi3): 2.965e-03\n",
      "Epoch 18700, Train loss: 7.200e+03, Test loss: 8.765e+03, MSE(e): 5.980e-04, MSE(pi1): 9.128e-02, MSE(pi2): 4.522e-04, MSE(pi3): 3.068e-03\n",
      "Epoch 18800, Train loss: 7.002e+03, Test loss: 8.354e+03, MSE(e): 5.786e-04, MSE(pi1): 9.062e-02, MSE(pi2): 4.431e-04, MSE(pi3): 3.092e-03\n",
      "Epoch 18900, Train loss: 7.030e+03, Test loss: 8.355e+03, MSE(e): 5.813e-04, MSE(pi1): 9.142e-02, MSE(pi2): 4.312e-04, MSE(pi3): 3.030e-03\n",
      "Epoch 19000, Train loss: 7.841e+03, Test loss: 8.659e+03, MSE(e): 6.624e-04, MSE(pi1): 9.083e-02, MSE(pi2): 4.501e-04, MSE(pi3): 3.083e-03\n",
      "Epoch 19100, Train loss: 7.893e+03, Test loss: 8.201e+03, MSE(e): 6.677e-04, MSE(pi1): 9.178e-02, MSE(pi2): 4.554e-04, MSE(pi3): 2.981e-03\n",
      "Epoch 19200, Train loss: 9.111e+03, Test loss: 8.213e+03, MSE(e): 7.864e-04, MSE(pi1): 9.373e-02, MSE(pi2): 4.660e-04, MSE(pi3): 3.096e-03\n",
      "Epoch 19300, Train loss: 7.498e+03, Test loss: 8.633e+03, MSE(e): 6.281e-04, MSE(pi1): 9.172e-02, MSE(pi2): 4.275e-04, MSE(pi3): 2.994e-03\n",
      "Epoch 19400, Train loss: 7.248e+03, Test loss: 8.546e+03, MSE(e): 6.004e-04, MSE(pi1): 9.467e-02, MSE(pi2): 4.157e-04, MSE(pi3): 2.964e-03\n",
      "Epoch 19500, Train loss: 7.662e+03, Test loss: 8.475e+03, MSE(e): 6.457e-04, MSE(pi1): 8.906e-02, MSE(pi2): 4.503e-04, MSE(pi3): 3.144e-03\n",
      "Epoch 19600, Train loss: 6.976e+03, Test loss: 8.241e+03, MSE(e): 5.768e-04, MSE(pi1): 9.091e-02, MSE(pi2): 4.164e-04, MSE(pi3): 2.979e-03\n",
      "Epoch 19700, Train loss: 9.021e+03, Test loss: 8.315e+03, MSE(e): 7.823e-04, MSE(pi1): 8.854e-02, MSE(pi2): 5.222e-04, MSE(pi3): 3.123e-03\n",
      "Epoch 19800, Train loss: 7.127e+03, Test loss: 8.105e+03, MSE(e): 5.905e-04, MSE(pi1): 9.108e-02, MSE(pi2): 4.285e-04, MSE(pi3): 3.109e-03\n",
      "Epoch 19900, Train loss: 8.453e+03, Test loss: 8.484e+03, MSE(e): 7.218e-04, MSE(pi1): 9.527e-02, MSE(pi2): 4.518e-04, MSE(pi3): 2.824e-03\n",
      "Epoch 20000, Train loss: 8.684e+03, Test loss: 8.636e+03, MSE(e): 7.458e-04, MSE(pi1): 9.279e-02, MSE(pi2): 4.481e-04, MSE(pi3): 2.980e-03\n",
      "Epoch 20100, Train loss: 7.260e+03, Test loss: 7.925e+03, MSE(e): 6.063e-04, MSE(pi1): 8.923e-02, MSE(pi2): 4.569e-04, MSE(pi3): 3.036e-03\n",
      "Epoch 20200, Train loss: 7.253e+03, Test loss: 8.040e+03, MSE(e): 6.038e-04, MSE(pi1): 9.254e-02, MSE(pi2): 4.318e-04, MSE(pi3): 2.894e-03\n",
      "Epoch 20300, Train loss: 6.846e+03, Test loss: 8.369e+03, MSE(e): 5.645e-04, MSE(pi1): 9.006e-02, MSE(pi2): 4.046e-04, MSE(pi3): 3.005e-03\n",
      "Epoch 20400, Train loss: 7.009e+03, Test loss: 8.427e+03, MSE(e): 5.797e-04, MSE(pi1): 9.134e-02, MSE(pi2): 4.036e-04, MSE(pi3): 2.977e-03\n",
      "Epoch 20500, Train loss: 7.927e+03, Test loss: 8.209e+03, MSE(e): 6.718e-04, MSE(pi1): 9.122e-02, MSE(pi2): 4.548e-04, MSE(pi3): 2.965e-03\n",
      "Epoch 20600, Train loss: 6.952e+03, Test loss: 8.076e+03, MSE(e): 5.743e-04, MSE(pi1): 9.220e-02, MSE(pi2): 3.948e-04, MSE(pi3): 2.870e-03\n",
      "Epoch 20700, Train loss: 7.104e+03, Test loss: 8.572e+03, MSE(e): 5.905e-04, MSE(pi1): 9.208e-02, MSE(pi2): 4.395e-04, MSE(pi3): 2.772e-03\n",
      "Epoch 20800, Train loss: 7.145e+03, Test loss: 9.058e+03, MSE(e): 5.936e-04, MSE(pi1): 9.217e-02, MSE(pi2): 4.196e-04, MSE(pi3): 2.867e-03\n",
      "Epoch 20900, Train loss: 9.907e+03, Test loss: 8.116e+03, MSE(e): 8.688e-04, MSE(pi1): 9.078e-02, MSE(pi2): 5.167e-04, MSE(pi3): 3.114e-03\n",
      "Epoch 21000, Train loss: 8.850e+03, Test loss: 8.507e+03, MSE(e): 7.630e-04, MSE(pi1): 9.115e-02, MSE(pi2): 4.667e-04, MSE(pi3): 3.081e-03\n",
      "Epoch 21100, Train loss: 6.896e+03, Test loss: 8.558e+03, MSE(e): 5.691e-04, MSE(pi1): 9.226e-02, MSE(pi2): 4.050e-04, MSE(pi3): 2.817e-03\n",
      "Epoch 21200, Train loss: 7.440e+03, Test loss: 7.964e+03, MSE(e): 6.237e-04, MSE(pi1): 9.079e-02, MSE(pi2): 4.271e-04, MSE(pi3): 2.948e-03\n",
      "Epoch 21300, Train loss: 6.730e+03, Test loss: 7.937e+03, MSE(e): 5.539e-04, MSE(pi1): 8.874e-02, MSE(pi2): 4.023e-04, MSE(pi3): 3.034e-03\n",
      "Epoch 21400, Train loss: 7.168e+03, Test loss: 7.865e+03, MSE(e): 5.977e-04, MSE(pi1): 9.032e-02, MSE(pi2): 4.259e-04, MSE(pi3): 2.866e-03\n",
      "Epoch 21500, Train loss: 7.409e+03, Test loss: 8.062e+03, MSE(e): 6.208e-04, MSE(pi1): 9.130e-02, MSE(pi2): 4.291e-04, MSE(pi3): 2.880e-03\n",
      "Epoch 21600, Train loss: 7.478e+03, Test loss: 9.693e+03, MSE(e): 6.238e-04, MSE(pi1): 9.050e-02, MSE(pi2): 4.355e-04, MSE(pi3): 3.345e-03\n",
      "Epoch 21700, Train loss: 6.914e+03, Test loss: 9.600e+03, MSE(e): 5.733e-04, MSE(pi1): 8.859e-02, MSE(pi2): 4.160e-04, MSE(pi3): 2.945e-03\n",
      "Epoch 21800, Train loss: 7.998e+03, Test loss: 8.582e+03, MSE(e): 6.796e-04, MSE(pi1): 8.959e-02, MSE(pi2): 4.329e-04, MSE(pi3): 3.061e-03\n",
      "Epoch 21900, Train loss: 6.574e+03, Test loss: 8.003e+03, MSE(e): 5.387e-04, MSE(pi1): 8.928e-02, MSE(pi2): 3.880e-04, MSE(pi3): 2.945e-03\n",
      "Epoch 22000, Train loss: 7.936e+03, Test loss: 8.181e+03, MSE(e): 6.743e-04, MSE(pi1): 8.950e-02, MSE(pi2): 4.439e-04, MSE(pi3): 2.975e-03\n",
      "Epoch 22100, Train loss: 7.550e+03, Test loss: 7.819e+03, MSE(e): 6.347e-04, MSE(pi1): 8.995e-02, MSE(pi2): 4.097e-04, MSE(pi3): 3.027e-03\n",
      "Epoch 22200, Train loss: 6.912e+03, Test loss: 9.212e+03, MSE(e): 5.723e-04, MSE(pi1): 8.665e-02, MSE(pi2): 4.110e-04, MSE(pi3): 3.217e-03\n",
      "Epoch 22300, Train loss: 8.087e+03, Test loss: 8.290e+03, MSE(e): 6.873e-04, MSE(pi1): 9.374e-02, MSE(pi2): 4.261e-04, MSE(pi3): 2.766e-03\n",
      "Epoch 22400, Train loss: 6.644e+03, Test loss: 8.003e+03, MSE(e): 5.464e-04, MSE(pi1): 8.848e-02, MSE(pi2): 3.897e-04, MSE(pi3): 2.944e-03\n",
      "Epoch 22500, Train loss: 6.968e+03, Test loss: 7.889e+03, MSE(e): 5.782e-04, MSE(pi1): 8.940e-02, MSE(pi2): 4.144e-04, MSE(pi3): 2.916e-03\n",
      "Epoch 22600, Train loss: 6.750e+03, Test loss: 7.580e+03, MSE(e): 5.563e-04, MSE(pi1): 8.819e-02, MSE(pi2): 3.946e-04, MSE(pi3): 3.044e-03\n",
      "Epoch 22700, Train loss: 6.808e+03, Test loss: 7.670e+03, MSE(e): 5.617e-04, MSE(pi1): 9.146e-02, MSE(pi2): 4.094e-04, MSE(pi3): 2.761e-03\n",
      "Epoch 22800, Train loss: 7.090e+03, Test loss: 7.525e+03, MSE(e): 5.900e-04, MSE(pi1): 8.756e-02, MSE(pi2): 4.151e-04, MSE(pi3): 3.143e-03\n",
      "Epoch 22900, Train loss: 7.281e+03, Test loss: 7.707e+03, MSE(e): 6.099e-04, MSE(pi1): 8.894e-02, MSE(pi2): 4.265e-04, MSE(pi3): 2.918e-03\n",
      "Epoch 23000, Train loss: 6.613e+03, Test loss: 7.664e+03, MSE(e): 5.434e-04, MSE(pi1): 8.838e-02, MSE(pi2): 3.829e-04, MSE(pi3): 2.954e-03\n",
      "Epoch 23100, Train loss: 6.993e+03, Test loss: 8.168e+03, MSE(e): 5.806e-04, MSE(pi1): 9.038e-02, MSE(pi2): 4.307e-04, MSE(pi3): 2.831e-03\n",
      "Epoch 23200, Train loss: 6.944e+03, Test loss: 7.328e+03, MSE(e): 5.769e-04, MSE(pi1): 8.697e-02, MSE(pi2): 4.189e-04, MSE(pi3): 3.052e-03\n",
      "Epoch 23300, Train loss: 7.750e+03, Test loss: 8.010e+03, MSE(e): 6.544e-04, MSE(pi1): 9.045e-02, MSE(pi2): 4.579e-04, MSE(pi3): 3.015e-03\n",
      "Epoch 23400, Train loss: 7.379e+03, Test loss: 8.290e+03, MSE(e): 6.191e-04, MSE(pi1): 8.700e-02, MSE(pi2): 4.397e-04, MSE(pi3): 3.178e-03\n",
      "Epoch 23500, Train loss: 7.836e+03, Test loss: 7.512e+03, MSE(e): 6.635e-04, MSE(pi1): 9.041e-02, MSE(pi2): 4.065e-04, MSE(pi3): 2.968e-03\n",
      "Epoch 23600, Train loss: 7.066e+03, Test loss: 7.517e+03, MSE(e): 5.887e-04, MSE(pi1): 8.938e-02, MSE(pi2): 4.110e-04, MSE(pi3): 2.847e-03\n",
      "Epoch 23700, Train loss: 6.298e+03, Test loss: 7.232e+03, MSE(e): 5.117e-04, MSE(pi1): 8.804e-02, MSE(pi2): 3.846e-04, MSE(pi3): 3.004e-03\n",
      "Epoch 23800, Train loss: 7.854e+03, Test loss: 7.857e+03, MSE(e): 6.667e-04, MSE(pi1): 8.951e-02, MSE(pi2): 4.267e-04, MSE(pi3): 2.914e-03\n",
      "Epoch 23900, Train loss: 8.137e+03, Test loss: 8.254e+03, MSE(e): 6.939e-04, MSE(pi1): 9.074e-02, MSE(pi2): 4.242e-04, MSE(pi3): 2.909e-03\n",
      "Epoch 24000, Train loss: 8.305e+03, Test loss: 8.255e+03, MSE(e): 7.124e-04, MSE(pi1): 8.810e-02, MSE(pi2): 4.455e-04, MSE(pi3): 3.004e-03\n",
      "Epoch 24100, Train loss: 6.789e+03, Test loss: 7.372e+03, MSE(e): 5.612e-04, MSE(pi1): 8.760e-02, MSE(pi2): 3.891e-04, MSE(pi3): 3.007e-03\n",
      "Epoch 24200, Train loss: 6.611e+03, Test loss: 7.120e+03, MSE(e): 5.441e-04, MSE(pi1): 8.793e-02, MSE(pi2): 3.967e-04, MSE(pi3): 2.909e-03\n",
      "Epoch 24300, Train loss: 8.327e+03, Test loss: 7.513e+03, MSE(e): 7.129e-04, MSE(pi1): 8.961e-02, MSE(pi2): 4.127e-04, MSE(pi3): 3.010e-03\n",
      "Epoch 24400, Train loss: 6.970e+03, Test loss: 7.728e+03, MSE(e): 5.789e-04, MSE(pi1): 8.886e-02, MSE(pi2): 4.073e-04, MSE(pi3): 2.925e-03\n",
      "Epoch 24500, Train loss: 7.504e+03, Test loss: 7.773e+03, MSE(e): 6.312e-04, MSE(pi1): 8.839e-02, MSE(pi2): 4.275e-04, MSE(pi3): 3.079e-03\n",
      "Epoch 24600, Train loss: 6.546e+03, Test loss: 7.968e+03, MSE(e): 5.366e-04, MSE(pi1): 8.928e-02, MSE(pi2): 3.854e-04, MSE(pi3): 2.870e-03\n",
      "Epoch 24700, Train loss: 6.457e+03, Test loss: 8.051e+03, MSE(e): 5.282e-04, MSE(pi1): 8.871e-02, MSE(pi2): 3.858e-04, MSE(pi3): 2.872e-03\n",
      "Epoch 24800, Train loss: 7.476e+03, Test loss: 8.954e+03, MSE(e): 6.308e-04, MSE(pi1): 8.677e-02, MSE(pi2): 4.176e-04, MSE(pi3): 2.996e-03\n",
      "Epoch 24900, Train loss: 6.366e+03, Test loss: 7.681e+03, MSE(e): 5.189e-04, MSE(pi1): 8.935e-02, MSE(pi2): 3.865e-04, MSE(pi3): 2.832e-03\n",
      "Epoch 25000, Train loss: 7.744e+03, Test loss: 7.098e+03, MSE(e): 6.570e-04, MSE(pi1): 8.765e-02, MSE(pi2): 4.312e-04, MSE(pi3): 2.973e-03\n",
      "Epoch 25100, Train loss: 1.023e+04, Test loss: 7.285e+03, MSE(e): 9.044e-04, MSE(pi1): 8.715e-02, MSE(pi2): 5.118e-04, MSE(pi3): 3.101e-03\n",
      "Epoch 25200, Train loss: 8.350e+03, Test loss: 7.536e+03, MSE(e): 7.175e-04, MSE(pi1): 8.748e-02, MSE(pi2): 4.551e-04, MSE(pi3): 2.995e-03\n",
      "Epoch 25300, Train loss: 6.517e+03, Test loss: 7.571e+03, MSE(e): 5.340e-04, MSE(pi1): 8.829e-02, MSE(pi2): 3.850e-04, MSE(pi3): 2.939e-03\n",
      "Epoch 25400, Train loss: 7.167e+03, Test loss: 7.742e+03, MSE(e): 5.983e-04, MSE(pi1): 9.045e-02, MSE(pi2): 4.012e-04, MSE(pi3): 2.793e-03\n",
      "Epoch 25500, Train loss: 7.311e+03, Test loss: 8.997e+03, MSE(e): 6.120e-04, MSE(pi1): 8.676e-02, MSE(pi2): 4.240e-04, MSE(pi3): 3.225e-03\n",
      "Epoch 25600, Train loss: 9.641e+03, Test loss: 7.769e+03, MSE(e): 8.454e-04, MSE(pi1): 8.675e-02, MSE(pi2): 5.053e-04, MSE(pi3): 3.191e-03\n",
      "Epoch 25700, Train loss: 7.113e+03, Test loss: 7.620e+03, MSE(e): 5.939e-04, MSE(pi1): 8.651e-02, MSE(pi2): 4.177e-04, MSE(pi3): 3.092e-03\n",
      "Epoch 25800, Train loss: 8.593e+03, Test loss: 7.328e+03, MSE(e): 7.415e-04, MSE(pi1): 8.717e-02, MSE(pi2): 4.647e-04, MSE(pi3): 3.065e-03\n",
      "Epoch 25900, Train loss: 7.447e+03, Test loss: 7.460e+03, MSE(e): 6.265e-04, MSE(pi1): 8.774e-02, MSE(pi2): 4.156e-04, MSE(pi3): 3.045e-03\n",
      "Epoch 26000, Train loss: 6.596e+03, Test loss: 7.138e+03, MSE(e): 5.426e-04, MSE(pi1): 8.778e-02, MSE(pi2): 3.705e-04, MSE(pi3): 2.922e-03\n",
      "Epoch 26100, Train loss: 7.766e+03, Test loss: 8.845e+03, MSE(e): 6.583e-04, MSE(pi1): 8.549e-02, MSE(pi2): 4.329e-04, MSE(pi3): 3.272e-03\n",
      "Epoch 26200, Train loss: 6.752e+03, Test loss: 7.254e+03, MSE(e): 5.569e-04, MSE(pi1): 8.839e-02, MSE(pi2): 3.775e-04, MSE(pi3): 2.994e-03\n",
      "Epoch 26300, Train loss: 6.174e+03, Test loss: 7.027e+03, MSE(e): 5.011e-04, MSE(pi1): 8.773e-02, MSE(pi2): 3.629e-04, MSE(pi3): 2.857e-03\n",
      "Epoch 26400, Train loss: 8.726e+03, Test loss: 7.905e+03, MSE(e): 7.536e-04, MSE(pi1): 9.072e-02, MSE(pi2): 4.299e-04, MSE(pi3): 2.827e-03\n",
      "Epoch 26500, Train loss: 7.819e+03, Test loss: 7.272e+03, MSE(e): 6.647e-04, MSE(pi1): 8.777e-02, MSE(pi2): 4.194e-04, MSE(pi3): 2.945e-03\n",
      "Epoch 26600, Train loss: 7.600e+03, Test loss: 6.984e+03, MSE(e): 6.423e-04, MSE(pi1): 8.771e-02, MSE(pi2): 4.203e-04, MSE(pi3): 2.987e-03\n",
      "Epoch 26700, Train loss: 6.557e+03, Test loss: 7.683e+03, MSE(e): 5.399e-04, MSE(pi1): 8.687e-02, MSE(pi2): 3.789e-04, MSE(pi3): 2.891e-03\n",
      "Epoch 26800, Train loss: 7.346e+03, Test loss: 7.997e+03, MSE(e): 6.187e-04, MSE(pi1): 8.673e-02, MSE(pi2): 3.969e-04, MSE(pi3): 2.915e-03\n",
      "Epoch 26900, Train loss: 6.156e+03, Test loss: 7.036e+03, MSE(e): 4.993e-04, MSE(pi1): 8.784e-02, MSE(pi2): 3.649e-04, MSE(pi3): 2.849e-03\n",
      "Epoch 27000, Train loss: 5.979e+03, Test loss: 6.908e+03, MSE(e): 4.814e-04, MSE(pi1): 8.770e-02, MSE(pi2): 3.536e-04, MSE(pi3): 2.878e-03\n",
      "Epoch 27100, Train loss: 6.395e+03, Test loss: 6.893e+03, MSE(e): 5.229e-04, MSE(pi1): 8.758e-02, MSE(pi2): 3.701e-04, MSE(pi3): 2.903e-03\n",
      "Epoch 27200, Train loss: 6.415e+03, Test loss: 6.833e+03, MSE(e): 5.244e-04, MSE(pi1): 8.752e-02, MSE(pi2): 3.734e-04, MSE(pi3): 2.954e-03\n",
      "Epoch 27300, Train loss: 1.301e+04, Test loss: 7.464e+03, MSE(e): 1.181e-03, MSE(pi1): 8.954e-02, MSE(pi2): 5.336e-04, MSE(pi3): 3.006e-03\n",
      "Epoch 27400, Train loss: 6.091e+03, Test loss: 6.778e+03, MSE(e): 4.928e-04, MSE(pi1): 8.713e-02, MSE(pi2): 3.629e-04, MSE(pi3): 2.912e-03\n",
      "Epoch 27500, Train loss: 6.141e+03, Test loss: 6.936e+03, MSE(e): 4.974e-04, MSE(pi1): 8.776e-02, MSE(pi2): 3.570e-04, MSE(pi3): 2.886e-03\n",
      "Epoch 27600, Train loss: 6.284e+03, Test loss: 7.449e+03, MSE(e): 5.122e-04, MSE(pi1): 8.691e-02, MSE(pi2): 3.750e-04, MSE(pi3): 2.928e-03\n",
      "Epoch 27700, Train loss: 6.848e+03, Test loss: 8.175e+03, MSE(e): 5.678e-04, MSE(pi1): 8.715e-02, MSE(pi2): 3.968e-04, MSE(pi3): 2.974e-03\n",
      "Epoch 27800, Train loss: 6.112e+03, Test loss: 6.916e+03, MSE(e): 4.955e-04, MSE(pi1): 8.700e-02, MSE(pi2): 3.599e-04, MSE(pi3): 2.867e-03\n",
      "Epoch 27900, Train loss: 6.214e+03, Test loss: 7.287e+03, MSE(e): 5.042e-04, MSE(pi1): 8.747e-02, MSE(pi2): 3.651e-04, MSE(pi3): 2.968e-03\n",
      "Epoch 28000, Train loss: 5.974e+03, Test loss: 6.893e+03, MSE(e): 4.809e-04, MSE(pi1): 8.694e-02, MSE(pi2): 3.568e-04, MSE(pi3): 2.954e-03\n",
      "Epoch 28100, Train loss: 6.207e+03, Test loss: 8.598e+03, MSE(e): 5.036e-04, MSE(pi1): 8.903e-02, MSE(pi2): 3.442e-04, MSE(pi3): 2.795e-03\n",
      "Epoch 28200, Train loss: 6.159e+03, Test loss: 7.219e+03, MSE(e): 4.999e-04, MSE(pi1): 8.727e-02, MSE(pi2): 3.554e-04, MSE(pi3): 2.872e-03\n",
      "Epoch 28300, Train loss: 5.960e+03, Test loss: 6.934e+03, MSE(e): 4.799e-04, MSE(pi1): 8.614e-02, MSE(pi2): 3.582e-04, MSE(pi3): 2.998e-03\n",
      "Epoch 28400, Train loss: 6.950e+03, Test loss: 9.410e+03, MSE(e): 5.790e-04, MSE(pi1): 8.704e-02, MSE(pi2): 4.097e-04, MSE(pi3): 2.891e-03\n",
      "Epoch 28500, Train loss: 6.297e+03, Test loss: 7.233e+03, MSE(e): 5.123e-04, MSE(pi1): 8.835e-02, MSE(pi2): 3.582e-04, MSE(pi3): 2.908e-03\n",
      "Epoch 28600, Train loss: 9.500e+03, Test loss: 7.635e+03, MSE(e): 8.300e-04, MSE(pi1): 9.115e-02, MSE(pi2): 4.392e-04, MSE(pi3): 2.886e-03\n",
      "Epoch 28700, Train loss: 6.058e+03, Test loss: 6.781e+03, MSE(e): 4.891e-04, MSE(pi1): 8.779e-02, MSE(pi2): 3.508e-04, MSE(pi3): 2.889e-03\n",
      "Epoch 28800, Train loss: 5.963e+03, Test loss: 7.260e+03, MSE(e): 4.797e-04, MSE(pi1): 8.858e-02, MSE(pi2): 3.430e-04, MSE(pi3): 2.803e-03\n",
      "Epoch 28900, Train loss: 6.118e+03, Test loss: 6.830e+03, MSE(e): 4.951e-04, MSE(pi1): 8.807e-02, MSE(pi2): 3.507e-04, MSE(pi3): 2.864e-03\n",
      "Epoch 29000, Train loss: 8.233e+03, Test loss: 1.041e+04, MSE(e): 7.040e-04, MSE(pi1): 9.067e-02, MSE(pi2): 3.744e-04, MSE(pi3): 2.860e-03\n",
      "Epoch 29100, Train loss: 6.036e+03, Test loss: 6.924e+03, MSE(e): 4.868e-04, MSE(pi1): 8.720e-02, MSE(pi2): 3.534e-04, MSE(pi3): 2.953e-03\n",
      "Epoch 29200, Train loss: 6.291e+03, Test loss: 6.927e+03, MSE(e): 5.120e-04, MSE(pi1): 8.832e-02, MSE(pi2): 3.550e-04, MSE(pi3): 2.874e-03\n",
      "Epoch 29300, Train loss: 1.648e+04, Test loss: 8.042e+03, MSE(e): 1.528e-03, MSE(pi1): 9.054e-02, MSE(pi2): 5.934e-04, MSE(pi3): 2.977e-03\n",
      "Epoch 29400, Train loss: 6.918e+03, Test loss: 7.573e+03, MSE(e): 5.747e-04, MSE(pi1): 8.849e-02, MSE(pi2): 3.723e-04, MSE(pi3): 2.862e-03\n",
      "Epoch 29500, Train loss: 6.956e+03, Test loss: 8.129e+03, MSE(e): 5.790e-04, MSE(pi1): 8.811e-02, MSE(pi2): 3.946e-04, MSE(pi3): 2.848e-03\n",
      "Epoch 29600, Train loss: 5.824e+03, Test loss: 6.738e+03, MSE(e): 4.663e-04, MSE(pi1): 8.736e-02, MSE(pi2): 3.449e-04, MSE(pi3): 2.874e-03\n",
      "Epoch 29700, Train loss: 8.661e+03, Test loss: 7.766e+03, MSE(e): 7.477e-04, MSE(pi1): 8.980e-02, MSE(pi2): 4.342e-04, MSE(pi3): 2.857e-03\n",
      "Epoch 29800, Train loss: 7.029e+03, Test loss: 1.086e+04, MSE(e): 5.845e-04, MSE(pi1): 8.940e-02, MSE(pi2): 3.427e-04, MSE(pi3): 2.892e-03\n",
      "Epoch 29900, Train loss: 7.056e+03, Test loss: 8.248e+03, MSE(e): 5.897e-04, MSE(pi1): 8.623e-02, MSE(pi2): 3.961e-04, MSE(pi3): 2.961e-03\n",
      "Epoch 30000, Train loss: 6.619e+03, Test loss: 6.934e+03, MSE(e): 5.439e-04, MSE(pi1): 8.796e-02, MSE(pi2): 3.600e-04, MSE(pi3): 3.003e-03\n",
      "Epoch 30100, Train loss: 6.998e+03, Test loss: 7.654e+03, MSE(e): 5.832e-04, MSE(pi1): 8.757e-02, MSE(pi2): 3.932e-04, MSE(pi3): 2.907e-03\n",
      "Epoch 30200, Train loss: 6.616e+03, Test loss: 6.741e+03, MSE(e): 5.442e-04, MSE(pi1): 8.766e-02, MSE(pi2): 3.625e-04, MSE(pi3): 2.976e-03\n",
      "Epoch 30300, Train loss: 6.261e+03, Test loss: 8.038e+03, MSE(e): 5.101e-04, MSE(pi1): 8.553e-02, MSE(pi2): 3.506e-04, MSE(pi3): 3.049e-03\n",
      "Epoch 30400, Train loss: 6.108e+03, Test loss: 7.104e+03, MSE(e): 4.938e-04, MSE(pi1): 8.582e-02, MSE(pi2): 3.560e-04, MSE(pi3): 3.110e-03\n",
      "Epoch 30500, Train loss: 6.257e+03, Test loss: 7.651e+03, MSE(e): 5.100e-04, MSE(pi1): 8.760e-02, MSE(pi2): 3.446e-04, MSE(pi3): 2.803e-03\n",
      "Epoch 30600, Train loss: 6.046e+03, Test loss: 7.336e+03, MSE(e): 4.892e-04, MSE(pi1): 8.662e-02, MSE(pi2): 3.602e-04, MSE(pi3): 2.874e-03\n",
      "Epoch 30700, Train loss: 6.526e+03, Test loss: 6.927e+03, MSE(e): 5.354e-04, MSE(pi1): 8.786e-02, MSE(pi2): 3.442e-04, MSE(pi3): 2.930e-03\n",
      "Epoch 30800, Train loss: 6.565e+03, Test loss: 6.766e+03, MSE(e): 5.393e-04, MSE(pi1): 8.811e-02, MSE(pi2): 3.521e-04, MSE(pi3): 2.901e-03\n",
      "Epoch 30900, Train loss: 6.734e+03, Test loss: 7.159e+03, MSE(e): 5.562e-04, MSE(pi1): 8.716e-02, MSE(pi2): 3.529e-04, MSE(pi3): 2.999e-03\n",
      "Epoch 31000, Train loss: 5.747e+03, Test loss: 6.678e+03, MSE(e): 4.587e-04, MSE(pi1): 8.664e-02, MSE(pi2): 3.349e-04, MSE(pi3): 2.926e-03\n",
      "Epoch 31100, Train loss: 8.480e+03, Test loss: 1.020e+04, MSE(e): 7.301e-04, MSE(pi1): 8.801e-02, MSE(pi2): 3.918e-04, MSE(pi3): 2.985e-03\n",
      "Epoch 31200, Train loss: 5.890e+03, Test loss: 6.814e+03, MSE(e): 4.732e-04, MSE(pi1): 8.776e-02, MSE(pi2): 3.350e-04, MSE(pi3): 2.800e-03\n",
      "Epoch 31300, Train loss: 5.849e+03, Test loss: 7.130e+03, MSE(e): 4.703e-04, MSE(pi1): 8.610e-02, MSE(pi2): 3.593e-04, MSE(pi3): 2.852e-03\n",
      "Epoch 31400, Train loss: 6.792e+03, Test loss: 7.891e+03, MSE(e): 5.619e-04, MSE(pi1): 8.838e-02, MSE(pi2): 3.496e-04, MSE(pi3): 2.888e-03\n",
      "Epoch 31500, Train loss: 5.755e+03, Test loss: 6.944e+03, MSE(e): 4.592e-04, MSE(pi1): 8.746e-02, MSE(pi2): 3.328e-04, MSE(pi3): 2.876e-03\n",
      "Epoch 31600, Train loss: 6.265e+03, Test loss: 7.419e+03, MSE(e): 5.111e-04, MSE(pi1): 8.595e-02, MSE(pi2): 3.479e-04, MSE(pi3): 2.942e-03\n",
      "Epoch 31700, Train loss: 5.743e+03, Test loss: 6.654e+03, MSE(e): 4.591e-04, MSE(pi1): 8.603e-02, MSE(pi2): 3.352e-04, MSE(pi3): 2.920e-03\n",
      "Epoch 31800, Train loss: 5.975e+03, Test loss: 6.756e+03, MSE(e): 4.817e-04, MSE(pi1): 8.613e-02, MSE(pi2): 3.382e-04, MSE(pi3): 2.968e-03\n",
      "Epoch 31900, Train loss: 1.042e+04, Test loss: 8.537e+03, MSE(e): 9.253e-04, MSE(pi1): 8.562e-02, MSE(pi2): 4.443e-04, MSE(pi3): 3.088e-03\n",
      "Epoch 32000, Train loss: 7.424e+03, Test loss: 6.627e+03, MSE(e): 6.233e-04, MSE(pi1): 9.019e-02, MSE(pi2): 3.834e-04, MSE(pi3): 2.894e-03\n",
      "Epoch 32100, Train loss: 6.577e+03, Test loss: 7.835e+03, MSE(e): 5.424e-04, MSE(pi1): 8.709e-02, MSE(pi2): 3.646e-04, MSE(pi3): 2.824e-03\n",
      "Epoch 32200, Train loss: 8.627e+03, Test loss: 7.512e+03, MSE(e): 7.457e-04, MSE(pi1): 8.895e-02, MSE(pi2): 4.202e-04, MSE(pi3): 2.804e-03\n",
      "Epoch 32300, Train loss: 5.895e+03, Test loss: 6.901e+03, MSE(e): 4.735e-04, MSE(pi1): 8.627e-02, MSE(pi2): 3.354e-04, MSE(pi3): 2.972e-03\n",
      "Epoch 32400, Train loss: 1.058e+04, Test loss: 9.793e+03, MSE(e): 9.382e-04, MSE(pi1): 9.083e-02, MSE(pi2): 4.930e-04, MSE(pi3): 2.922e-03\n",
      "Epoch 32500, Train loss: 6.672e+03, Test loss: 6.856e+03, MSE(e): 5.510e-04, MSE(pi1): 8.820e-02, MSE(pi2): 3.636e-04, MSE(pi3): 2.793e-03\n",
      "Epoch 32600, Train loss: 6.192e+03, Test loss: 6.919e+03, MSE(e): 5.029e-04, MSE(pi1): 8.745e-02, MSE(pi2): 3.287e-04, MSE(pi3): 2.890e-03\n",
      "Epoch 32700, Train loss: 5.637e+03, Test loss: 6.603e+03, MSE(e): 4.483e-04, MSE(pi1): 8.703e-02, MSE(pi2): 3.251e-04, MSE(pi3): 2.833e-03\n",
      "Epoch 32800, Train loss: 1.227e+04, Test loss: 9.080e+03, MSE(e): 1.109e-03, MSE(pi1): 9.007e-02, MSE(pi2): 4.763e-04, MSE(pi3): 2.829e-03\n",
      "Epoch 32900, Train loss: 9.919e+03, Test loss: 7.876e+03, MSE(e): 8.755e-04, MSE(pi1): 8.539e-02, MSE(pi2): 4.301e-04, MSE(pi3): 3.094e-03\n",
      "Epoch 33000, Train loss: 6.191e+03, Test loss: 9.348e+03, MSE(e): 5.007e-04, MSE(pi1): 8.574e-02, MSE(pi2): 3.310e-04, MSE(pi3): 3.264e-03\n",
      "Epoch 33100, Train loss: 6.252e+03, Test loss: 6.598e+03, MSE(e): 5.094e-04, MSE(pi1): 8.777e-02, MSE(pi2): 3.593e-04, MSE(pi3): 2.805e-03\n",
      "Epoch 33200, Train loss: 8.486e+03, Test loss: 7.468e+03, MSE(e): 7.313e-04, MSE(pi1): 9.032e-02, MSE(pi2): 4.104e-04, MSE(pi3): 2.689e-03\n",
      "Epoch 33300, Train loss: 5.756e+03, Test loss: 6.802e+03, MSE(e): 4.606e-04, MSE(pi1): 8.505e-02, MSE(pi2): 3.459e-04, MSE(pi3): 2.994e-03\n",
      "Epoch 33400, Train loss: 6.111e+03, Test loss: 7.511e+03, MSE(e): 4.964e-04, MSE(pi1): 8.484e-02, MSE(pi2): 3.337e-04, MSE(pi3): 2.984e-03\n",
      "Epoch 33500, Train loss: 6.038e+03, Test loss: 9.223e+03, MSE(e): 4.891e-04, MSE(pi1): 8.602e-02, MSE(pi2): 3.135e-04, MSE(pi3): 2.874e-03\n",
      "Epoch 33600, Train loss: 7.288e+03, Test loss: 6.979e+03, MSE(e): 6.108e-04, MSE(pi1): 8.947e-02, MSE(pi2): 3.730e-04, MSE(pi3): 2.855e-03\n",
      "Epoch 33700, Train loss: 5.884e+03, Test loss: 6.612e+03, MSE(e): 4.735e-04, MSE(pi1): 8.659e-02, MSE(pi2): 3.304e-04, MSE(pi3): 2.832e-03\n",
      "Epoch 33800, Train loss: 5.958e+03, Test loss: 7.016e+03, MSE(e): 4.802e-04, MSE(pi1): 8.686e-02, MSE(pi2): 3.189e-04, MSE(pi3): 2.870e-03\n",
      "Epoch 33900, Train loss: 6.185e+03, Test loss: 6.740e+03, MSE(e): 5.042e-04, MSE(pi1): 8.576e-02, MSE(pi2): 3.519e-04, MSE(pi3): 2.851e-03\n",
      "Epoch 34000, Train loss: 6.378e+03, Test loss: 6.857e+03, MSE(e): 5.212e-04, MSE(pi1): 8.666e-02, MSE(pi2): 3.515e-04, MSE(pi3): 2.993e-03\n",
      "Epoch 34100, Train loss: 6.255e+03, Test loss: 6.949e+03, MSE(e): 5.092e-04, MSE(pi1): 8.826e-02, MSE(pi2): 3.251e-04, MSE(pi3): 2.800e-03\n",
      "Epoch 34200, Train loss: 5.951e+03, Test loss: 7.160e+03, MSE(e): 4.799e-04, MSE(pi1): 8.857e-02, MSE(pi2): 3.378e-04, MSE(pi3): 2.657e-03\n",
      "Epoch 34300, Train loss: 1.216e+04, Test loss: 7.375e+03, MSE(e): 1.095e-03, MSE(pi1): 9.126e-02, MSE(pi2): 4.733e-04, MSE(pi3): 2.966e-03\n",
      "Epoch 34400, Train loss: 5.693e+03, Test loss: 6.505e+03, MSE(e): 4.547e-04, MSE(pi1): 8.623e-02, MSE(pi2): 3.303e-04, MSE(pi3): 2.838e-03\n",
      "Epoch 34500, Train loss: 6.410e+03, Test loss: 6.787e+03, MSE(e): 5.261e-04, MSE(pi1): 8.651e-02, MSE(pi2): 3.326e-04, MSE(pi3): 2.835e-03\n",
      "Epoch 34600, Train loss: 7.699e+03, Test loss: 7.247e+03, MSE(e): 6.515e-04, MSE(pi1): 8.933e-02, MSE(pi2): 3.897e-04, MSE(pi3): 2.906e-03\n",
      "Epoch 34700, Train loss: 6.453e+03, Test loss: 7.197e+03, MSE(e): 5.305e-04, MSE(pi1): 8.786e-02, MSE(pi2): 3.448e-04, MSE(pi3): 2.689e-03\n",
      "Epoch 34800, Train loss: 6.595e+03, Test loss: 1.388e+04, MSE(e): 5.450e-04, MSE(pi1): 8.527e-02, MSE(pi2): 3.686e-04, MSE(pi3): 2.920e-03\n",
      "Epoch 34900, Train loss: 6.109e+03, Test loss: 6.814e+03, MSE(e): 4.960e-04, MSE(pi1): 8.710e-02, MSE(pi2): 3.476e-04, MSE(pi3): 2.777e-03\n",
      "Epoch 35000, Train loss: 6.336e+03, Test loss: 6.999e+03, MSE(e): 5.183e-04, MSE(pi1): 8.615e-02, MSE(pi2): 3.237e-04, MSE(pi3): 2.909e-03\n",
      "Epoch 35100, Train loss: 5.699e+03, Test loss: 7.574e+03, MSE(e): 4.552e-04, MSE(pi1): 8.492e-02, MSE(pi2): 3.127e-04, MSE(pi3): 2.970e-03\n",
      "Epoch 35200, Train loss: 6.015e+03, Test loss: 6.693e+03, MSE(e): 4.874e-04, MSE(pi1): 8.477e-02, MSE(pi2): 3.327e-04, MSE(pi3): 2.934e-03\n",
      "Epoch 35300, Train loss: 6.406e+03, Test loss: 6.584e+03, MSE(e): 5.253e-04, MSE(pi1): 8.713e-02, MSE(pi2): 3.496e-04, MSE(pi3): 2.810e-03\n",
      "Epoch 35400, Train loss: 5.753e+03, Test loss: 7.046e+03, MSE(e): 4.607e-04, MSE(pi1): 8.604e-02, MSE(pi2): 3.149e-04, MSE(pi3): 2.851e-03\n",
      "Epoch 35500, Train loss: 5.597e+03, Test loss: 6.523e+03, MSE(e): 4.452e-04, MSE(pi1): 8.661e-02, MSE(pi2): 3.168e-04, MSE(pi3): 2.794e-03\n",
      "Epoch 35600, Train loss: 5.956e+03, Test loss: 7.312e+03, MSE(e): 4.806e-04, MSE(pi1): 8.451e-02, MSE(pi2): 3.402e-04, MSE(pi3): 3.048e-03\n",
      "Epoch 35700, Train loss: 5.847e+03, Test loss: 6.875e+03, MSE(e): 4.696e-04, MSE(pi1): 8.547e-02, MSE(pi2): 3.237e-04, MSE(pi3): 2.962e-03\n",
      "Epoch 35800, Train loss: 8.864e+03, Test loss: 8.935e+03, MSE(e): 7.707e-04, MSE(pi1): 8.539e-02, MSE(pi2): 3.902e-04, MSE(pi3): 3.025e-03\n",
      "Epoch 35900, Train loss: 5.533e+03, Test loss: 6.662e+03, MSE(e): 4.395e-04, MSE(pi1): 8.487e-02, MSE(pi2): 3.169e-04, MSE(pi3): 2.890e-03\n",
      "Epoch 36000, Train loss: 5.635e+03, Test loss: 7.286e+03, MSE(e): 4.494e-04, MSE(pi1): 8.675e-02, MSE(pi2): 3.199e-04, MSE(pi3): 2.732e-03\n",
      "Epoch 36100, Train loss: 9.505e+03, Test loss: 1.000e+04, MSE(e): 8.339e-04, MSE(pi1): 8.615e-02, MSE(pi2): 4.156e-04, MSE(pi3): 3.046e-03\n",
      "Epoch 36200, Train loss: 5.996e+03, Test loss: 7.084e+03, MSE(e): 4.851e-04, MSE(pi1): 8.618e-02, MSE(pi2): 3.103e-04, MSE(pi3): 2.834e-03\n",
      "Epoch 36300, Train loss: 5.622e+03, Test loss: 6.494e+03, MSE(e): 4.482e-04, MSE(pi1): 8.618e-02, MSE(pi2): 3.179e-04, MSE(pi3): 2.779e-03\n",
      "Epoch 36400, Train loss: 6.257e+03, Test loss: 6.645e+03, MSE(e): 5.114e-04, MSE(pi1): 8.707e-02, MSE(pi2): 3.355e-04, MSE(pi3): 2.718e-03\n",
      "Epoch 36500, Train loss: 5.810e+03, Test loss: 6.870e+03, MSE(e): 4.672e-04, MSE(pi1): 8.620e-02, MSE(pi2): 3.221e-04, MSE(pi3): 2.764e-03\n",
      "Epoch 36600, Train loss: 1.165e+04, Test loss: 7.408e+03, MSE(e): 1.048e-03, MSE(pi1): 8.819e-02, MSE(pi2): 4.456e-04, MSE(pi3): 2.875e-03\n",
      "Epoch 36700, Train loss: 5.677e+03, Test loss: 7.493e+03, MSE(e): 4.537e-04, MSE(pi1): 8.490e-02, MSE(pi2): 3.044e-04, MSE(pi3): 2.915e-03\n",
      "Epoch 36800, Train loss: 1.174e+04, Test loss: 9.549e+03, MSE(e): 1.058e-03, MSE(pi1): 8.647e-02, MSE(pi2): 4.382e-04, MSE(pi3): 2.972e-03\n",
      "Epoch 36900, Train loss: 6.110e+03, Test loss: 6.400e+03, MSE(e): 4.980e-04, MSE(pi1): 8.438e-02, MSE(pi2): 3.335e-04, MSE(pi3): 2.853e-03\n",
      "Epoch 37000, Train loss: 7.600e+03, Test loss: 8.019e+03, MSE(e): 6.430e-04, MSE(pi1): 8.574e-02, MSE(pi2): 3.897e-04, MSE(pi3): 3.125e-03\n",
      "Epoch 37100, Train loss: 6.103e+03, Test loss: 8.582e+03, MSE(e): 4.971e-04, MSE(pi1): 8.378e-02, MSE(pi2): 3.121e-04, MSE(pi3): 2.936e-03\n",
      "Epoch 37200, Train loss: 6.651e+03, Test loss: 7.081e+03, MSE(e): 5.513e-04, MSE(pi1): 8.715e-02, MSE(pi2): 3.399e-04, MSE(pi3): 2.663e-03\n",
      "Epoch 37300, Train loss: 6.090e+03, Test loss: 6.713e+03, MSE(e): 4.942e-04, MSE(pi1): 8.663e-02, MSE(pi2): 3.217e-04, MSE(pi3): 2.811e-03\n",
      "Epoch 37400, Train loss: 5.483e+03, Test loss: 6.918e+03, MSE(e): 4.347e-04, MSE(pi1): 8.564e-02, MSE(pi2): 3.017e-04, MSE(pi3): 2.799e-03\n",
      "Epoch 37500, Train loss: 6.819e+03, Test loss: 8.718e+03, MSE(e): 5.675e-04, MSE(pi1): 8.642e-02, MSE(pi2): 3.161e-04, MSE(pi3): 2.796e-03\n",
      "Epoch 37600, Train loss: 7.247e+03, Test loss: 7.144e+03, MSE(e): 6.088e-04, MSE(pi1): 8.637e-02, MSE(pi2): 3.653e-04, MSE(pi3): 2.947e-03\n",
      "Epoch 37700, Train loss: 6.162e+03, Test loss: 6.979e+03, MSE(e): 5.026e-04, MSE(pi1): 8.697e-02, MSE(pi2): 3.503e-04, MSE(pi3): 2.658e-03\n",
      "Epoch 37800, Train loss: 5.919e+03, Test loss: 6.784e+03, MSE(e): 4.780e-04, MSE(pi1): 8.642e-02, MSE(pi2): 3.140e-04, MSE(pi3): 2.745e-03\n",
      "Epoch 37900, Train loss: 9.261e+03, Test loss: 9.121e+03, MSE(e): 8.109e-04, MSE(pi1): 8.780e-02, MSE(pi2): 4.507e-04, MSE(pi3): 2.731e-03\n",
      "Epoch 38000, Train loss: 5.923e+03, Test loss: 6.638e+03, MSE(e): 4.776e-04, MSE(pi1): 8.610e-02, MSE(pi2): 3.189e-04, MSE(pi3): 2.852e-03\n",
      "Epoch 38100, Train loss: 8.776e+03, Test loss: 7.258e+03, MSE(e): 7.606e-04, MSE(pi1): 8.965e-02, MSE(pi2): 3.684e-04, MSE(pi3): 2.735e-03\n",
      "Epoch 38200, Train loss: 6.062e+03, Test loss: 6.684e+03, MSE(e): 4.933e-04, MSE(pi1): 8.340e-02, MSE(pi2): 3.426e-04, MSE(pi3): 2.947e-03\n",
      "Epoch 38300, Train loss: 5.729e+03, Test loss: 6.535e+03, MSE(e): 4.601e-04, MSE(pi1): 8.481e-02, MSE(pi2): 3.350e-04, MSE(pi3): 2.796e-03\n",
      "Epoch 38400, Train loss: 6.269e+03, Test loss: 6.678e+03, MSE(e): 5.135e-04, MSE(pi1): 8.619e-02, MSE(pi2): 3.474e-04, MSE(pi3): 2.721e-03\n",
      "Epoch 38500, Train loss: 5.617e+03, Test loss: 6.608e+03, MSE(e): 4.486e-04, MSE(pi1): 8.481e-02, MSE(pi2): 3.171e-04, MSE(pi3): 2.829e-03\n",
      "Epoch 38600, Train loss: 6.218e+03, Test loss: 8.310e+03, MSE(e): 5.069e-04, MSE(pi1): 8.658e-02, MSE(pi2): 3.622e-04, MSE(pi3): 2.826e-03\n",
      "Epoch 38700, Train loss: 6.013e+03, Test loss: 6.600e+03, MSE(e): 4.886e-04, MSE(pi1): 8.478e-02, MSE(pi2): 3.266e-04, MSE(pi3): 2.796e-03\n",
      "Epoch 38800, Train loss: 6.097e+03, Test loss: 6.331e+03, MSE(e): 4.959e-04, MSE(pi1): 8.694e-02, MSE(pi2): 3.404e-04, MSE(pi3): 2.681e-03\n",
      "Epoch 38900, Train loss: 5.588e+03, Test loss: 6.518e+03, MSE(e): 4.458e-04, MSE(pi1): 8.572e-02, MSE(pi2): 3.282e-04, MSE(pi3): 2.715e-03\n",
      "Epoch 39000, Train loss: 6.169e+03, Test loss: 6.354e+03, MSE(e): 5.042e-04, MSE(pi1): 8.495e-02, MSE(pi2): 3.526e-04, MSE(pi3): 2.772e-03\n",
      "Epoch 39100, Train loss: 6.208e+03, Test loss: 7.294e+03, MSE(e): 5.085e-04, MSE(pi1): 8.564e-02, MSE(pi2): 3.055e-04, MSE(pi3): 2.669e-03\n",
      "Epoch 39200, Train loss: 5.582e+03, Test loss: 6.419e+03, MSE(e): 4.461e-04, MSE(pi1): 8.462e-02, MSE(pi2): 3.101e-04, MSE(pi3): 2.749e-03\n",
      "Epoch 39300, Train loss: 5.572e+03, Test loss: 6.907e+03, MSE(e): 4.438e-04, MSE(pi1): 8.468e-02, MSE(pi2): 3.179e-04, MSE(pi3): 2.866e-03\n",
      "Epoch 39400, Train loss: 5.639e+03, Test loss: 6.429e+03, MSE(e): 4.511e-04, MSE(pi1): 8.601e-02, MSE(pi2): 3.145e-04, MSE(pi3): 2.679e-03\n",
      "Epoch 39500, Train loss: 5.973e+03, Test loss: 6.405e+03, MSE(e): 4.835e-04, MSE(pi1): 8.631e-02, MSE(pi2): 3.431e-04, MSE(pi3): 2.750e-03\n",
      "Epoch 39600, Train loss: 5.425e+03, Test loss: 6.465e+03, MSE(e): 4.305e-04, MSE(pi1): 8.492e-02, MSE(pi2): 3.053e-04, MSE(pi3): 2.708e-03\n",
      "Epoch 39700, Train loss: 5.588e+03, Test loss: 6.376e+03, MSE(e): 4.469e-04, MSE(pi1): 8.509e-02, MSE(pi2): 3.263e-04, MSE(pi3): 2.677e-03\n",
      "Epoch 39800, Train loss: 5.452e+03, Test loss: 6.457e+03, MSE(e): 4.329e-04, MSE(pi1): 8.428e-02, MSE(pi2): 3.188e-04, MSE(pi3): 2.798e-03\n",
      "Epoch 39900, Train loss: 5.589e+03, Test loss: 6.653e+03, MSE(e): 4.458e-04, MSE(pi1): 8.349e-02, MSE(pi2): 3.304e-04, MSE(pi3): 2.952e-03\n",
      "Epoch 40000, Train loss: 7.211e+03, Test loss: 7.233e+03, MSE(e): 6.083e-04, MSE(pi1): 8.582e-02, MSE(pi2): 3.736e-04, MSE(pi3): 2.696e-03\n",
      "Epoch 40100, Train loss: 5.710e+03, Test loss: 6.461e+03, MSE(e): 4.588e-04, MSE(pi1): 8.535e-02, MSE(pi2): 3.209e-04, MSE(pi3): 2.681e-03\n",
      "Epoch 40200, Train loss: 9.766e+03, Test loss: 7.373e+03, MSE(e): 8.620e-04, MSE(pi1): 8.438e-02, MSE(pi2): 4.689e-04, MSE(pi3): 3.009e-03\n",
      "Epoch 40300, Train loss: 5.951e+03, Test loss: 8.081e+03, MSE(e): 4.828e-04, MSE(pi1): 8.421e-02, MSE(pi2): 3.026e-04, MSE(pi3): 2.809e-03\n",
      "Epoch 40400, Train loss: 7.214e+03, Test loss: 7.150e+03, MSE(e): 6.073e-04, MSE(pi1): 8.739e-02, MSE(pi2): 4.006e-04, MSE(pi3): 2.673e-03\n",
      "Epoch 40500, Train loss: 5.782e+03, Test loss: 6.870e+03, MSE(e): 4.656e-04, MSE(pi1): 8.479e-02, MSE(pi2): 3.329e-04, MSE(pi3): 2.774e-03\n",
      "Epoch 40600, Train loss: 8.089e+03, Test loss: 8.809e+03, MSE(e): 6.969e-04, MSE(pi1): 8.463e-02, MSE(pi2): 3.554e-04, MSE(pi3): 2.742e-03\n",
      "Epoch 40700, Train loss: 5.392e+03, Test loss: 6.756e+03, MSE(e): 4.275e-04, MSE(pi1): 8.552e-02, MSE(pi2): 3.060e-04, MSE(pi3): 2.608e-03\n",
      "Epoch 40800, Train loss: 5.369e+03, Test loss: 7.122e+03, MSE(e): 4.255e-04, MSE(pi1): 8.494e-02, MSE(pi2): 2.967e-04, MSE(pi3): 2.643e-03\n",
      "Epoch 40900, Train loss: 6.168e+03, Test loss: 7.012e+03, MSE(e): 5.047e-04, MSE(pi1): 8.417e-02, MSE(pi2): 3.197e-04, MSE(pi3): 2.781e-03\n",
      "Epoch 41000, Train loss: 7.105e+03, Test loss: 6.863e+03, MSE(e): 5.967e-04, MSE(pi1): 8.516e-02, MSE(pi2): 3.587e-04, MSE(pi3): 2.863e-03\n",
      "Epoch 41100, Train loss: 6.231e+03, Test loss: 7.830e+03, MSE(e): 5.119e-04, MSE(pi1): 8.481e-02, MSE(pi2): 3.165e-04, MSE(pi3): 2.642e-03\n",
      "Epoch 41200, Train loss: 5.493e+03, Test loss: 6.485e+03, MSE(e): 4.374e-04, MSE(pi1): 8.459e-02, MSE(pi2): 2.999e-04, MSE(pi3): 2.723e-03\n",
      "Epoch 41300, Train loss: 5.879e+03, Test loss: 8.648e+03, MSE(e): 4.744e-04, MSE(pi1): 8.469e-02, MSE(pi2): 3.367e-04, MSE(pi3): 2.879e-03\n",
      "Epoch 41400, Train loss: 5.388e+03, Test loss: 6.737e+03, MSE(e): 4.272e-04, MSE(pi1): 8.472e-02, MSE(pi2): 2.981e-04, MSE(pi3): 2.688e-03\n",
      "Epoch 41500, Train loss: 5.526e+03, Test loss: 6.341e+03, MSE(e): 4.411e-04, MSE(pi1): 8.479e-02, MSE(pi2): 3.135e-04, MSE(pi3): 2.670e-03\n",
      "Epoch 41600, Train loss: 5.436e+03, Test loss: 6.612e+03, MSE(e): 4.330e-04, MSE(pi1): 8.536e-02, MSE(pi2): 3.212e-04, MSE(pi3): 2.524e-03\n",
      "Epoch 41700, Train loss: 5.493e+03, Test loss: 6.612e+03, MSE(e): 4.374e-04, MSE(pi1): 8.281e-02, MSE(pi2): 3.247e-04, MSE(pi3): 2.906e-03\n",
      "Epoch 41800, Train loss: 5.636e+03, Test loss: 6.779e+03, MSE(e): 4.518e-04, MSE(pi1): 8.240e-02, MSE(pi2): 3.228e-04, MSE(pi3): 2.935e-03\n",
      "Epoch 41900, Train loss: 5.521e+03, Test loss: 6.559e+03, MSE(e): 4.405e-04, MSE(pi1): 8.475e-02, MSE(pi2): 2.994e-04, MSE(pi3): 2.686e-03\n",
      "Epoch 42000, Train loss: 5.513e+03, Test loss: 6.368e+03, MSE(e): 4.406e-04, MSE(pi1): 8.526e-02, MSE(pi2): 3.165e-04, MSE(pi3): 2.538e-03\n",
      "Epoch 42100, Train loss: 5.577e+03, Test loss: 6.970e+03, MSE(e): 4.462e-04, MSE(pi1): 8.642e-02, MSE(pi2): 3.163e-04, MSE(pi3): 2.500e-03\n",
      "Epoch 42200, Train loss: 7.453e+03, Test loss: 7.761e+03, MSE(e): 6.316e-04, MSE(pi1): 8.854e-02, MSE(pi2): 3.308e-04, MSE(pi3): 2.511e-03\n",
      "Epoch 42300, Train loss: 8.448e+03, Test loss: 8.367e+03, MSE(e): 7.276e-04, MSE(pi1): 8.793e-02, MSE(pi2): 4.085e-04, MSE(pi3): 2.932e-03\n",
      "Epoch 42400, Train loss: 5.652e+03, Test loss: 6.354e+03, MSE(e): 4.539e-04, MSE(pi1): 8.494e-02, MSE(pi2): 3.049e-04, MSE(pi3): 2.633e-03\n",
      "Epoch 42500, Train loss: 5.497e+03, Test loss: 6.513e+03, MSE(e): 4.383e-04, MSE(pi1): 8.440e-02, MSE(pi2): 2.990e-04, MSE(pi3): 2.696e-03\n",
      "Epoch 42600, Train loss: 5.625e+03, Test loss: 6.341e+03, MSE(e): 4.518e-04, MSE(pi1): 8.457e-02, MSE(pi2): 3.336e-04, MSE(pi3): 2.609e-03\n",
      "Epoch 42700, Train loss: 5.802e+03, Test loss: 7.183e+03, MSE(e): 4.689e-04, MSE(pi1): 8.564e-02, MSE(pi2): 3.115e-04, MSE(pi3): 2.562e-03\n",
      "Epoch 42800, Train loss: 5.607e+03, Test loss: 6.147e+03, MSE(e): 4.500e-04, MSE(pi1): 8.341e-02, MSE(pi2): 3.203e-04, MSE(pi3): 2.729e-03\n",
      "Epoch 42900, Train loss: 5.560e+03, Test loss: 7.161e+03, MSE(e): 4.448e-04, MSE(pi1): 8.677e-02, MSE(pi2): 3.167e-04, MSE(pi3): 2.450e-03\n",
      "Epoch 43000, Train loss: 9.314e+03, Test loss: 7.954e+03, MSE(e): 8.175e-04, MSE(pi1): 8.840e-02, MSE(pi2): 3.858e-04, MSE(pi3): 2.545e-03\n",
      "Epoch 43100, Train loss: 6.166e+03, Test loss: 6.730e+03, MSE(e): 5.047e-04, MSE(pi1): 8.443e-02, MSE(pi2): 3.102e-04, MSE(pi3): 2.746e-03\n",
      "Epoch 43200, Train loss: 5.383e+03, Test loss: 6.339e+03, MSE(e): 4.274e-04, MSE(pi1): 8.458e-02, MSE(pi2): 3.063e-04, MSE(pi3): 2.632e-03\n",
      "Epoch 43300, Train loss: 5.394e+03, Test loss: 6.397e+03, MSE(e): 4.290e-04, MSE(pi1): 8.278e-02, MSE(pi2): 3.169e-04, MSE(pi3): 2.760e-03\n",
      "Epoch 43400, Train loss: 5.378e+03, Test loss: 6.308e+03, MSE(e): 4.274e-04, MSE(pi1): 8.437e-02, MSE(pi2): 2.991e-04, MSE(pi3): 2.599e-03\n",
      "Epoch 43500, Train loss: 1.271e+04, Test loss: 7.204e+03, MSE(e): 1.156e-03, MSE(pi1): 8.716e-02, MSE(pi2): 4.647e-04, MSE(pi3): 2.750e-03\n",
      "Epoch 43600, Train loss: 5.277e+03, Test loss: 6.647e+03, MSE(e): 4.172e-04, MSE(pi1): 8.462e-02, MSE(pi2): 2.995e-04, MSE(pi3): 2.578e-03\n",
      "Epoch 43700, Train loss: 5.445e+03, Test loss: 6.670e+03, MSE(e): 4.329e-04, MSE(pi1): 8.326e-02, MSE(pi2): 3.106e-04, MSE(pi3): 2.829e-03\n",
      "Epoch 43800, Train loss: 6.470e+03, Test loss: 6.314e+03, MSE(e): 5.347e-04, MSE(pi1): 8.587e-02, MSE(pi2): 3.600e-04, MSE(pi3): 2.640e-03\n",
      "Epoch 43900, Train loss: 5.427e+03, Test loss: 6.888e+03, MSE(e): 4.309e-04, MSE(pi1): 8.416e-02, MSE(pi2): 2.970e-04, MSE(pi3): 2.763e-03\n",
      "Epoch 44000, Train loss: 5.499e+03, Test loss: 6.850e+03, MSE(e): 4.395e-04, MSE(pi1): 8.529e-02, MSE(pi2): 3.261e-04, MSE(pi3): 2.505e-03\n",
      "Epoch 44100, Train loss: 6.044e+03, Test loss: 6.881e+03, MSE(e): 4.939e-04, MSE(pi1): 8.429e-02, MSE(pi2): 3.049e-04, MSE(pi3): 2.618e-03\n",
      "Epoch 44200, Train loss: 5.597e+03, Test loss: 6.462e+03, MSE(e): 4.492e-04, MSE(pi1): 8.361e-02, MSE(pi2): 3.285e-04, MSE(pi3): 2.685e-03\n",
      "Epoch 44300, Train loss: 7.460e+03, Test loss: 6.261e+03, MSE(e): 6.335e-04, MSE(pi1): 8.762e-02, MSE(pi2): 3.893e-04, MSE(pi3): 2.479e-03\n",
      "Epoch 44400, Train loss: 7.390e+03, Test loss: 7.206e+03, MSE(e): 6.260e-04, MSE(pi1): 8.587e-02, MSE(pi2): 3.401e-04, MSE(pi3): 2.708e-03\n",
      "Epoch 44500, Train loss: 5.369e+03, Test loss: 6.550e+03, MSE(e): 4.256e-04, MSE(pi1): 8.393e-02, MSE(pi2): 3.185e-04, MSE(pi3): 2.728e-03\n",
      "Epoch 44600, Train loss: 5.582e+03, Test loss: 6.608e+03, MSE(e): 4.456e-04, MSE(pi1): 8.528e-02, MSE(pi2): 3.239e-04, MSE(pi3): 2.727e-03\n",
      "Epoch 44700, Train loss: 5.678e+03, Test loss: 6.361e+03, MSE(e): 4.570e-04, MSE(pi1): 8.566e-02, MSE(pi2): 3.141e-04, MSE(pi3): 2.519e-03\n",
      "Epoch 44800, Train loss: 5.257e+03, Test loss: 6.224e+03, MSE(e): 4.158e-04, MSE(pi1): 8.410e-02, MSE(pi2): 3.001e-04, MSE(pi3): 2.584e-03\n",
      "Epoch 44900, Train loss: 5.526e+03, Test loss: 7.027e+03, MSE(e): 4.421e-04, MSE(pi1): 8.633e-02, MSE(pi2): 3.143e-04, MSE(pi3): 2.417e-03\n",
      "Epoch 45000, Train loss: 6.483e+03, Test loss: 6.816e+03, MSE(e): 5.361e-04, MSE(pi1): 8.560e-02, MSE(pi2): 3.165e-04, MSE(pi3): 2.654e-03\n",
      "Epoch 45100, Train loss: 5.674e+03, Test loss: 6.744e+03, MSE(e): 4.571e-04, MSE(pi1): 8.500e-02, MSE(pi2): 3.265e-04, MSE(pi3): 2.527e-03\n",
      "Epoch 45200, Train loss: 5.265e+03, Test loss: 6.089e+03, MSE(e): 4.168e-04, MSE(pi1): 8.455e-02, MSE(pi2): 3.014e-04, MSE(pi3): 2.517e-03\n",
      "Epoch 45300, Train loss: 5.543e+03, Test loss: 6.685e+03, MSE(e): 4.436e-04, MSE(pi1): 8.648e-02, MSE(pi2): 3.191e-04, MSE(pi3): 2.422e-03\n",
      "Epoch 45400, Train loss: 5.457e+03, Test loss: 6.649e+03, MSE(e): 4.350e-04, MSE(pi1): 8.652e-02, MSE(pi2): 3.096e-04, MSE(pi3): 2.422e-03\n",
      "Epoch 45500, Train loss: 5.520e+03, Test loss: 6.837e+03, MSE(e): 4.423e-04, MSE(pi1): 8.488e-02, MSE(pi2): 3.279e-04, MSE(pi3): 2.479e-03\n",
      "Epoch 45600, Train loss: 5.659e+03, Test loss: 7.368e+03, MSE(e): 4.546e-04, MSE(pi1): 8.383e-02, MSE(pi2): 2.873e-04, MSE(pi3): 2.741e-03\n",
      "Epoch 45700, Train loss: 5.678e+03, Test loss: 6.416e+03, MSE(e): 4.572e-04, MSE(pi1): 8.512e-02, MSE(pi2): 3.046e-04, MSE(pi3): 2.541e-03\n",
      "Epoch 45800, Train loss: 6.081e+03, Test loss: 6.753e+03, MSE(e): 4.983e-04, MSE(pi1): 8.532e-02, MSE(pi2): 3.410e-04, MSE(pi3): 2.440e-03\n",
      "Epoch 45900, Train loss: 5.396e+03, Test loss: 6.794e+03, MSE(e): 4.302e-04, MSE(pi1): 8.504e-02, MSE(pi2): 3.130e-04, MSE(pi3): 2.432e-03\n",
      "Epoch 46000, Train loss: 5.450e+03, Test loss: 6.125e+03, MSE(e): 4.357e-04, MSE(pi1): 8.341e-02, MSE(pi2): 3.154e-04, MSE(pi3): 2.586e-03\n",
      "Epoch 46100, Train loss: 7.196e+03, Test loss: 7.450e+03, MSE(e): 6.080e-04, MSE(pi1): 8.669e-02, MSE(pi2): 3.279e-04, MSE(pi3): 2.483e-03\n",
      "Epoch 46200, Train loss: 6.605e+03, Test loss: 6.365e+03, MSE(e): 5.489e-04, MSE(pi1): 8.597e-02, MSE(pi2): 3.354e-04, MSE(pi3): 2.552e-03\n",
      "Epoch 46300, Train loss: 5.413e+03, Test loss: 6.697e+03, MSE(e): 4.311e-04, MSE(pi1): 8.331e-02, MSE(pi2): 3.078e-04, MSE(pi3): 2.692e-03\n",
      "Epoch 46400, Train loss: 7.800e+03, Test loss: 7.709e+03, MSE(e): 6.663e-04, MSE(pi1): 8.686e-02, MSE(pi2): 3.839e-04, MSE(pi3): 2.682e-03\n",
      "Epoch 46500, Train loss: 5.399e+03, Test loss: 6.124e+03, MSE(e): 4.298e-04, MSE(pi1): 8.475e-02, MSE(pi2): 2.900e-04, MSE(pi3): 2.526e-03\n",
      "Epoch 46600, Train loss: 7.509e+03, Test loss: 6.117e+03, MSE(e): 6.389e-04, MSE(pi1): 8.747e-02, MSE(pi2): 3.813e-04, MSE(pi3): 2.443e-03\n",
      "Epoch 46700, Train loss: 5.524e+03, Test loss: 6.245e+03, MSE(e): 4.432e-04, MSE(pi1): 8.311e-02, MSE(pi2): 3.001e-04, MSE(pi3): 2.602e-03\n",
      "Epoch 46800, Train loss: 5.368e+03, Test loss: 6.221e+03, MSE(e): 4.273e-04, MSE(pi1): 8.490e-02, MSE(pi2): 2.929e-04, MSE(pi3): 2.457e-03\n",
      "Epoch 46900, Train loss: 5.383e+03, Test loss: 6.395e+03, MSE(e): 4.290e-04, MSE(pi1): 8.491e-02, MSE(pi2): 3.096e-04, MSE(pi3): 2.434e-03\n",
      "Epoch 47000, Train loss: 5.298e+03, Test loss: 6.793e+03, MSE(e): 4.201e-04, MSE(pi1): 8.509e-02, MSE(pi2): 2.975e-04, MSE(pi3): 2.458e-03\n",
      "Epoch 47100, Train loss: 5.616e+03, Test loss: 8.226e+03, MSE(e): 4.528e-04, MSE(pi1): 8.355e-02, MSE(pi2): 2.918e-04, MSE(pi3): 2.521e-03\n",
      "Epoch 47200, Train loss: 7.079e+03, Test loss: 8.290e+03, MSE(e): 5.948e-04, MSE(pi1): 8.611e-02, MSE(pi2): 3.601e-04, MSE(pi3): 2.689e-03\n",
      "Epoch 47300, Train loss: 9.866e+03, Test loss: 8.630e+03, MSE(e): 8.774e-04, MSE(pi1): 8.194e-02, MSE(pi2): 4.527e-04, MSE(pi3): 2.719e-03\n",
      "Epoch 47400, Train loss: 6.280e+03, Test loss: 7.007e+03, MSE(e): 5.185e-04, MSE(pi1): 8.241e-02, MSE(pi2): 3.180e-04, MSE(pi3): 2.706e-03\n",
      "Epoch 47500, Train loss: 5.484e+03, Test loss: 6.178e+03, MSE(e): 4.386e-04, MSE(pi1): 8.472e-02, MSE(pi2): 2.901e-04, MSE(pi3): 2.504e-03\n",
      "Epoch 47600, Train loss: 5.362e+03, Test loss: 6.818e+03, MSE(e): 4.277e-04, MSE(pi1): 8.374e-02, MSE(pi2): 3.163e-04, MSE(pi3): 2.480e-03\n",
      "Epoch 47700, Train loss: 5.152e+03, Test loss: 6.138e+03, MSE(e): 4.067e-04, MSE(pi1): 8.433e-02, MSE(pi2): 2.997e-04, MSE(pi3): 2.417e-03\n",
      "Epoch 47800, Train loss: 5.653e+03, Test loss: 6.574e+03, MSE(e): 4.547e-04, MSE(pi1): 8.224e-02, MSE(pi2): 3.198e-04, MSE(pi3): 2.832e-03\n",
      "Epoch 47900, Train loss: 5.274e+03, Test loss: 6.463e+03, MSE(e): 4.182e-04, MSE(pi1): 8.402e-02, MSE(pi2): 3.055e-04, MSE(pi3): 2.515e-03\n",
      "Epoch 48000, Train loss: 5.176e+03, Test loss: 7.028e+03, MSE(e): 4.088e-04, MSE(pi1): 8.412e-02, MSE(pi2): 2.772e-04, MSE(pi3): 2.467e-03\n",
      "Epoch 48100, Train loss: 6.019e+03, Test loss: 6.608e+03, MSE(e): 4.911e-04, MSE(pi1): 8.515e-02, MSE(pi2): 2.957e-04, MSE(pi3): 2.563e-03\n",
      "Epoch 48200, Train loss: 6.233e+03, Test loss: 7.862e+03, MSE(e): 5.120e-04, MSE(pi1): 8.453e-02, MSE(pi2): 2.974e-04, MSE(pi3): 2.672e-03\n",
      "Epoch 48300, Train loss: 5.916e+03, Test loss: 6.730e+03, MSE(e): 4.831e-04, MSE(pi1): 8.414e-02, MSE(pi2): 3.196e-04, MSE(pi3): 2.435e-03\n",
      "Epoch 48400, Train loss: 7.677e+03, Test loss: 7.821e+03, MSE(e): 6.574e-04, MSE(pi1): 8.581e-02, MSE(pi2): 3.447e-04, MSE(pi3): 2.451e-03\n",
      "Epoch 48500, Train loss: 5.781e+03, Test loss: 7.182e+03, MSE(e): 4.679e-04, MSE(pi1): 8.484e-02, MSE(pi2): 3.313e-04, MSE(pi3): 2.536e-03\n",
      "Epoch 48600, Train loss: 6.036e+03, Test loss: 6.412e+03, MSE(e): 4.940e-04, MSE(pi1): 8.338e-02, MSE(pi2): 3.319e-04, MSE(pi3): 2.614e-03\n",
      "Epoch 48700, Train loss: 5.109e+03, Test loss: 6.110e+03, MSE(e): 4.011e-04, MSE(pi1): 8.399e-02, MSE(pi2): 2.835e-04, MSE(pi3): 2.577e-03\n",
      "Epoch 48800, Train loss: 5.355e+03, Test loss: 6.481e+03, MSE(e): 4.247e-04, MSE(pi1): 8.399e-02, MSE(pi2): 2.834e-04, MSE(pi3): 2.669e-03\n",
      "Epoch 48900, Train loss: 5.350e+03, Test loss: 6.613e+03, MSE(e): 4.244e-04, MSE(pi1): 8.253e-02, MSE(pi2): 3.021e-04, MSE(pi3): 2.799e-03\n",
      "Epoch 49000, Train loss: 5.300e+03, Test loss: 6.312e+03, MSE(e): 4.215e-04, MSE(pi1): 8.386e-02, MSE(pi2): 2.870e-04, MSE(pi3): 2.469e-03\n",
      "Epoch 49100, Train loss: 5.648e+03, Test loss: 1.030e+04, MSE(e): 4.545e-04, MSE(pi1): 8.532e-02, MSE(pi2): 2.702e-04, MSE(pi3): 2.497e-03\n",
      "Epoch 49200, Train loss: 5.939e+03, Test loss: 6.638e+03, MSE(e): 4.852e-04, MSE(pi1): 8.148e-02, MSE(pi2): 3.368e-04, MSE(pi3): 2.725e-03\n",
      "Epoch 49300, Train loss: 5.652e+03, Test loss: 8.357e+03, MSE(e): 4.544e-04, MSE(pi1): 8.170e-02, MSE(pi2): 2.979e-04, MSE(pi3): 2.904e-03\n",
      "Epoch 49400, Train loss: 6.070e+03, Test loss: 6.690e+03, MSE(e): 4.966e-04, MSE(pi1): 8.585e-02, MSE(pi2): 3.296e-04, MSE(pi3): 2.443e-03\n",
      "Epoch 49500, Train loss: 5.304e+03, Test loss: 7.379e+03, MSE(e): 4.215e-04, MSE(pi1): 8.436e-02, MSE(pi2): 2.736e-04, MSE(pi3): 2.445e-03\n",
      "Epoch 49600, Train loss: 5.914e+03, Test loss: 7.017e+03, MSE(e): 4.804e-04, MSE(pi1): 8.310e-02, MSE(pi2): 3.152e-04, MSE(pi3): 2.793e-03\n",
      "Epoch 49700, Train loss: 6.291e+03, Test loss: 7.079e+03, MSE(e): 5.190e-04, MSE(pi1): 8.322e-02, MSE(pi2): 3.090e-04, MSE(pi3): 2.684e-03\n",
      "Epoch 49800, Train loss: 5.058e+03, Test loss: 6.149e+03, MSE(e): 3.961e-04, MSE(pi1): 8.350e-02, MSE(pi2): 2.766e-04, MSE(pi3): 2.610e-03\n",
      "Epoch 49900, Train loss: 5.260e+03, Test loss: 6.467e+03, MSE(e): 4.177e-04, MSE(pi1): 8.388e-02, MSE(pi2): 2.822e-04, MSE(pi3): 2.440e-03\n",
      "Epoch 50000, Train loss: 5.908e+03, Test loss: 6.534e+03, MSE(e): 4.808e-04, MSE(pi1): 8.544e-02, MSE(pi2): 2.870e-04, MSE(pi3): 2.462e-03\n",
      "Epoch 50100, Train loss: 5.225e+03, Test loss: 5.878e+03, MSE(e): 4.139e-04, MSE(pi1): 8.378e-02, MSE(pi2): 2.929e-04, MSE(pi3): 2.478e-03\n",
      "Epoch 50200, Train loss: 5.492e+03, Test loss: 7.382e+03, MSE(e): 4.390e-04, MSE(pi1): 8.356e-02, MSE(pi2): 3.127e-04, MSE(pi3): 2.656e-03\n",
      "Epoch 50300, Train loss: 5.321e+03, Test loss: 6.480e+03, MSE(e): 4.240e-04, MSE(pi1): 8.307e-02, MSE(pi2): 3.078e-04, MSE(pi3): 2.491e-03\n",
      "Epoch 50400, Train loss: 5.225e+03, Test loss: 6.455e+03, MSE(e): 4.138e-04, MSE(pi1): 8.518e-02, MSE(pi2): 3.092e-04, MSE(pi3): 2.341e-03\n",
      "Epoch 50500, Train loss: 5.399e+03, Test loss: 6.857e+03, MSE(e): 4.302e-04, MSE(pi1): 8.192e-02, MSE(pi2): 2.978e-04, MSE(pi3): 2.777e-03\n",
      "Epoch 50600, Train loss: 5.448e+03, Test loss: 6.292e+03, MSE(e): 4.366e-04, MSE(pi1): 8.333e-02, MSE(pi2): 3.067e-04, MSE(pi3): 2.477e-03\n",
      "Epoch 50700, Train loss: 5.216e+03, Test loss: 6.610e+03, MSE(e): 4.128e-04, MSE(pi1): 8.431e-02, MSE(pi2): 2.877e-04, MSE(pi3): 2.441e-03\n",
      "Epoch 50800, Train loss: 5.825e+03, Test loss: 7.173e+03, MSE(e): 4.725e-04, MSE(pi1): 8.314e-02, MSE(pi2): 2.837e-04, MSE(pi3): 2.686e-03\n",
      "Epoch 50900, Train loss: 5.516e+03, Test loss: 6.245e+03, MSE(e): 4.426e-04, MSE(pi1): 8.295e-02, MSE(pi2): 3.179e-04, MSE(pi3): 2.598e-03\n",
      "Epoch 51000, Train loss: 5.346e+03, Test loss: 6.533e+03, MSE(e): 4.269e-04, MSE(pi1): 8.381e-02, MSE(pi2): 3.027e-04, MSE(pi3): 2.390e-03\n",
      "Epoch 51100, Train loss: 6.183e+03, Test loss: 7.181e+03, MSE(e): 5.098e-04, MSE(pi1): 8.442e-02, MSE(pi2): 3.176e-04, MSE(pi3): 2.403e-03\n",
      "Epoch 51200, Train loss: 5.192e+03, Test loss: 6.120e+03, MSE(e): 4.103e-04, MSE(pi1): 8.291e-02, MSE(pi2): 3.004e-04, MSE(pi3): 2.591e-03\n",
      "Epoch 51300, Train loss: 5.173e+03, Test loss: 6.006e+03, MSE(e): 4.083e-04, MSE(pi1): 8.354e-02, MSE(pi2): 2.742e-04, MSE(pi3): 2.545e-03\n",
      "Epoch 51400, Train loss: 5.137e+03, Test loss: 6.773e+03, MSE(e): 4.059e-04, MSE(pi1): 8.402e-02, MSE(pi2): 3.018e-04, MSE(pi3): 2.374e-03\n",
      "Epoch 51500, Train loss: 5.613e+03, Test loss: 7.829e+03, MSE(e): 4.522e-04, MSE(pi1): 8.223e-02, MSE(pi2): 2.801e-04, MSE(pi3): 2.687e-03\n",
      "Epoch 51600, Train loss: 4.997e+03, Test loss: 5.945e+03, MSE(e): 3.920e-04, MSE(pi1): 8.330e-02, MSE(pi2): 2.846e-04, MSE(pi3): 2.444e-03\n",
      "Epoch 51700, Train loss: 5.235e+03, Test loss: 6.439e+03, MSE(e): 4.148e-04, MSE(pi1): 8.490e-02, MSE(pi2): 2.839e-04, MSE(pi3): 2.372e-03\n",
      "Epoch 51800, Train loss: 5.612e+03, Test loss: 6.012e+03, MSE(e): 4.522e-04, MSE(pi1): 8.450e-02, MSE(pi2): 2.999e-04, MSE(pi3): 2.443e-03\n",
      "Epoch 51900, Train loss: 5.567e+03, Test loss: 7.067e+03, MSE(e): 4.493e-04, MSE(pi1): 8.319e-02, MSE(pi2): 3.015e-04, MSE(pi3): 2.413e-03\n",
      "Epoch 52000, Train loss: 5.919e+03, Test loss: 6.880e+03, MSE(e): 4.824e-04, MSE(pi1): 8.597e-02, MSE(pi2): 2.907e-04, MSE(pi3): 2.344e-03\n",
      "Epoch 52100, Train loss: 5.347e+03, Test loss: 6.710e+03, MSE(e): 4.259e-04, MSE(pi1): 8.211e-02, MSE(pi2): 3.156e-04, MSE(pi3): 2.671e-03\n",
      "Epoch 52200, Train loss: 5.215e+03, Test loss: 5.927e+03, MSE(e): 4.131e-04, MSE(pi1): 8.422e-02, MSE(pi2): 2.781e-04, MSE(pi3): 2.409e-03\n",
      "Epoch 52300, Train loss: 5.305e+03, Test loss: 6.626e+03, MSE(e): 4.213e-04, MSE(pi1): 8.398e-02, MSE(pi2): 2.738e-04, MSE(pi3): 2.522e-03\n",
      "Epoch 52400, Train loss: 5.468e+03, Test loss: 6.927e+03, MSE(e): 4.375e-04, MSE(pi1): 8.565e-02, MSE(pi2): 2.866e-04, MSE(pi3): 2.367e-03\n",
      "Epoch 52500, Train loss: 7.303e+03, Test loss: 6.971e+03, MSE(e): 6.212e-04, MSE(pi1): 8.522e-02, MSE(pi2): 3.423e-04, MSE(pi3): 2.379e-03\n",
      "Epoch 52600, Train loss: 5.466e+03, Test loss: 6.324e+03, MSE(e): 4.381e-04, MSE(pi1): 8.449e-02, MSE(pi2): 2.756e-04, MSE(pi3): 2.401e-03\n",
      "Epoch 52700, Train loss: 5.109e+03, Test loss: 6.553e+03, MSE(e): 4.026e-04, MSE(pi1): 8.208e-02, MSE(pi2): 2.831e-04, MSE(pi3): 2.618e-03\n",
      "Epoch 52800, Train loss: 6.358e+03, Test loss: 6.528e+03, MSE(e): 5.245e-04, MSE(pi1): 8.400e-02, MSE(pi2): 3.309e-04, MSE(pi3): 2.725e-03\n",
      "Epoch 52900, Train loss: 5.153e+03, Test loss: 5.889e+03, MSE(e): 4.074e-04, MSE(pi1): 8.382e-02, MSE(pi2): 2.752e-04, MSE(pi3): 2.409e-03\n",
      "Epoch 53000, Train loss: 6.107e+03, Test loss: 9.135e+03, MSE(e): 5.018e-04, MSE(pi1): 8.462e-02, MSE(pi2): 3.374e-04, MSE(pi3): 2.423e-03\n",
      "Epoch 53100, Train loss: 5.081e+03, Test loss: 6.302e+03, MSE(e): 3.993e-04, MSE(pi1): 8.315e-02, MSE(pi2): 2.687e-04, MSE(pi3): 2.560e-03\n",
      "Epoch 53200, Train loss: 5.390e+03, Test loss: 5.825e+03, MSE(e): 4.304e-04, MSE(pi1): 8.330e-02, MSE(pi2): 2.888e-04, MSE(pi3): 2.521e-03\n",
      "Epoch 53300, Train loss: 6.023e+03, Test loss: 6.163e+03, MSE(e): 4.923e-04, MSE(pi1): 8.368e-02, MSE(pi2): 3.066e-04, MSE(pi3): 2.622e-03\n",
      "Epoch 53400, Train loss: 4.980e+03, Test loss: 6.873e+03, MSE(e): 3.903e-04, MSE(pi1): 8.376e-02, MSE(pi2): 2.607e-04, MSE(pi3): 2.392e-03\n",
      "Epoch 53500, Train loss: 5.092e+03, Test loss: 5.910e+03, MSE(e): 4.004e-04, MSE(pi1): 8.397e-02, MSE(pi2): 2.808e-04, MSE(pi3): 2.472e-03\n",
      "Epoch 53600, Train loss: 6.197e+03, Test loss: 8.437e+03, MSE(e): 5.128e-04, MSE(pi1): 8.170e-02, MSE(pi2): 3.219e-04, MSE(pi3): 2.516e-03\n",
      "Epoch 53700, Train loss: 5.526e+03, Test loss: 6.818e+03, MSE(e): 4.419e-04, MSE(pi1): 8.336e-02, MSE(pi2): 3.080e-04, MSE(pi3): 2.727e-03\n",
      "Epoch 53800, Train loss: 5.007e+03, Test loss: 6.466e+03, MSE(e): 3.933e-04, MSE(pi1): 8.341e-02, MSE(pi2): 2.707e-04, MSE(pi3): 2.401e-03\n",
      "Epoch 53900, Train loss: 5.063e+03, Test loss: 6.997e+03, MSE(e): 3.984e-04, MSE(pi1): 8.392e-02, MSE(pi2): 2.588e-04, MSE(pi3): 2.394e-03\n",
      "Epoch 54000, Train loss: 5.373e+03, Test loss: 6.443e+03, MSE(e): 4.283e-04, MSE(pi1): 8.298e-02, MSE(pi2): 2.898e-04, MSE(pi3): 2.605e-03\n",
      "Epoch 54100, Train loss: 5.298e+03, Test loss: 6.250e+03, MSE(e): 4.210e-04, MSE(pi1): 8.157e-02, MSE(pi2): 2.940e-04, MSE(pi3): 2.717e-03\n",
      "Epoch 54200, Train loss: 5.141e+03, Test loss: 5.676e+03, MSE(e): 4.062e-04, MSE(pi1): 8.359e-02, MSE(pi2): 2.770e-04, MSE(pi3): 2.420e-03\n",
      "Epoch 54300, Train loss: 5.372e+03, Test loss: 6.651e+03, MSE(e): 4.289e-04, MSE(pi1): 8.438e-02, MSE(pi2): 2.659e-04, MSE(pi3): 2.387e-03\n",
      "Epoch 54400, Train loss: 5.653e+03, Test loss: 8.203e+03, MSE(e): 4.545e-04, MSE(pi1): 8.296e-02, MSE(pi2): 2.781e-04, MSE(pi3): 2.781e-03\n",
      "Epoch 54500, Train loss: 5.258e+03, Test loss: 6.135e+03, MSE(e): 4.167e-04, MSE(pi1): 8.273e-02, MSE(pi2): 2.918e-04, MSE(pi3): 2.633e-03\n",
      "Epoch 54600, Train loss: 5.239e+03, Test loss: 6.080e+03, MSE(e): 4.167e-04, MSE(pi1): 8.321e-02, MSE(pi2): 2.856e-04, MSE(pi3): 2.393e-03\n",
      "Epoch 54700, Train loss: 5.442e+03, Test loss: 5.711e+03, MSE(e): 4.354e-04, MSE(pi1): 8.348e-02, MSE(pi2): 2.772e-04, MSE(pi3): 2.525e-03\n",
      "Epoch 54800, Train loss: 9.010e+03, Test loss: 6.910e+03, MSE(e): 7.872e-04, MSE(pi1): 8.751e-02, MSE(pi2): 3.433e-04, MSE(pi3): 2.624e-03\n",
      "Epoch 54900, Train loss: 4.866e+03, Test loss: 5.690e+03, MSE(e): 3.791e-04, MSE(pi1): 8.234e-02, MSE(pi2): 2.675e-04, MSE(pi3): 2.516e-03\n",
      "Epoch 55000, Train loss: 5.112e+03, Test loss: 7.030e+03, MSE(e): 4.042e-04, MSE(pi1): 8.342e-02, MSE(pi2): 2.954e-04, MSE(pi3): 2.358e-03\n",
      "Epoch 55100, Train loss: 5.066e+03, Test loss: 6.886e+03, MSE(e): 3.986e-04, MSE(pi1): 8.335e-02, MSE(pi2): 2.495e-04, MSE(pi3): 2.463e-03\n",
      "Epoch 55200, Train loss: 5.216e+03, Test loss: 6.252e+03, MSE(e): 4.141e-04, MSE(pi1): 8.082e-02, MSE(pi2): 3.041e-04, MSE(pi3): 2.663e-03\n",
      "Epoch 55300, Train loss: 6.897e+03, Test loss: 8.532e+03, MSE(e): 5.779e-04, MSE(pi1): 8.324e-02, MSE(pi2): 2.960e-04, MSE(pi3): 2.854e-03\n",
      "Epoch 55400, Train loss: 5.025e+03, Test loss: 6.193e+03, MSE(e): 3.944e-04, MSE(pi1): 8.377e-02, MSE(pi2): 2.530e-04, MSE(pi3): 2.425e-03\n",
      "Epoch 55500, Train loss: 5.098e+03, Test loss: 6.057e+03, MSE(e): 4.021e-04, MSE(pi1): 8.372e-02, MSE(pi2): 2.793e-04, MSE(pi3): 2.396e-03\n",
      "Epoch 55600, Train loss: 5.313e+03, Test loss: 5.738e+03, MSE(e): 4.237e-04, MSE(pi1): 8.290e-02, MSE(pi2): 2.743e-04, MSE(pi3): 2.471e-03\n",
      "Epoch 55700, Train loss: 4.939e+03, Test loss: 6.663e+03, MSE(e): 3.867e-04, MSE(pi1): 8.291e-02, MSE(pi2): 2.565e-04, MSE(pi3): 2.421e-03\n",
      "Epoch 55800, Train loss: 5.034e+03, Test loss: 6.507e+03, MSE(e): 3.969e-04, MSE(pi1): 8.251e-02, MSE(pi2): 2.879e-04, MSE(pi3): 2.400e-03\n",
      "Epoch 55900, Train loss: 5.226e+03, Test loss: 6.588e+03, MSE(e): 4.141e-04, MSE(pi1): 8.515e-02, MSE(pi2): 2.689e-04, MSE(pi3): 2.329e-03\n",
      "Epoch 56000, Train loss: 5.221e+03, Test loss: 5.964e+03, MSE(e): 4.148e-04, MSE(pi1): 8.375e-02, MSE(pi2): 2.809e-04, MSE(pi3): 2.350e-03\n",
      "Epoch 56100, Train loss: 5.266e+03, Test loss: 5.936e+03, MSE(e): 4.190e-04, MSE(pi1): 8.231e-02, MSE(pi2): 2.897e-04, MSE(pi3): 2.525e-03\n",
      "Epoch 56200, Train loss: 5.016e+03, Test loss: 7.087e+03, MSE(e): 3.933e-04, MSE(pi1): 8.115e-02, MSE(pi2): 2.624e-04, MSE(pi3): 2.708e-03\n",
      "Epoch 56300, Train loss: 4.926e+03, Test loss: 5.712e+03, MSE(e): 3.852e-04, MSE(pi1): 8.317e-02, MSE(pi2): 2.557e-04, MSE(pi3): 2.427e-03\n",
      "Epoch 56400, Train loss: 4.804e+03, Test loss: 5.601e+03, MSE(e): 3.731e-04, MSE(pi1): 8.284e-02, MSE(pi2): 2.589e-04, MSE(pi3): 2.438e-03\n",
      "Epoch 56500, Train loss: 5.979e+03, Test loss: 6.371e+03, MSE(e): 4.886e-04, MSE(pi1): 8.336e-02, MSE(pi2): 3.232e-04, MSE(pi3): 2.585e-03\n",
      "Epoch 56600, Train loss: 4.884e+03, Test loss: 5.863e+03, MSE(e): 3.810e-04, MSE(pi1): 8.241e-02, MSE(pi2): 2.552e-04, MSE(pi3): 2.497e-03\n",
      "Epoch 56700, Train loss: 1.005e+04, Test loss: 9.609e+03, MSE(e): 8.907e-04, MSE(pi1): 8.557e-02, MSE(pi2): 3.792e-04, MSE(pi3): 2.881e-03\n",
      "Epoch 56800, Train loss: 4.905e+03, Test loss: 6.122e+03, MSE(e): 3.836e-04, MSE(pi1): 8.195e-02, MSE(pi2): 2.497e-04, MSE(pi3): 2.496e-03\n",
      "Epoch 56900, Train loss: 4.880e+03, Test loss: 6.203e+03, MSE(e): 3.814e-04, MSE(pi1): 8.242e-02, MSE(pi2): 2.620e-04, MSE(pi3): 2.417e-03\n",
      "Epoch 57000, Train loss: 4.850e+03, Test loss: 5.581e+03, MSE(e): 3.775e-04, MSE(pi1): 8.236e-02, MSE(pi2): 2.648e-04, MSE(pi3): 2.509e-03\n",
      "Epoch 57100, Train loss: 5.415e+03, Test loss: 6.683e+03, MSE(e): 4.348e-04, MSE(pi1): 8.272e-02, MSE(pi2): 2.750e-04, MSE(pi3): 2.390e-03\n",
      "Epoch 57200, Train loss: 5.174e+03, Test loss: 7.389e+03, MSE(e): 4.091e-04, MSE(pi1): 8.479e-02, MSE(pi2): 2.591e-04, MSE(pi3): 2.341e-03\n",
      "Epoch 57300, Train loss: 5.073e+03, Test loss: 6.160e+03, MSE(e): 4.007e-04, MSE(pi1): 8.062e-02, MSE(pi2): 3.023e-04, MSE(pi3): 2.603e-03\n",
      "Epoch 57400, Train loss: 5.971e+03, Test loss: 6.840e+03, MSE(e): 4.910e-04, MSE(pi1): 7.889e-02, MSE(pi2): 3.573e-04, MSE(pi3): 2.717e-03\n",
      "Epoch 57500, Train loss: 5.386e+03, Test loss: 6.223e+03, MSE(e): 4.317e-04, MSE(pi1): 8.164e-02, MSE(pi2): 2.858e-04, MSE(pi3): 2.522e-03\n",
      "Epoch 57600, Train loss: 5.126e+03, Test loss: 5.779e+03, MSE(e): 4.057e-04, MSE(pi1): 8.175e-02, MSE(pi2): 2.859e-04, MSE(pi3): 2.509e-03\n",
      "Epoch 57700, Train loss: 5.503e+03, Test loss: 6.683e+03, MSE(e): 4.441e-04, MSE(pi1): 8.202e-02, MSE(pi2): 2.903e-04, MSE(pi3): 2.414e-03\n",
      "Epoch 57800, Train loss: 5.974e+03, Test loss: 6.140e+03, MSE(e): 4.894e-04, MSE(pi1): 8.268e-02, MSE(pi2): 3.060e-04, MSE(pi3): 2.534e-03\n",
      "Epoch 57900, Train loss: 5.046e+03, Test loss: 5.842e+03, MSE(e): 3.980e-04, MSE(pi1): 8.299e-02, MSE(pi2): 2.640e-04, MSE(pi3): 2.357e-03\n",
      "Epoch 58000, Train loss: 4.960e+03, Test loss: 6.833e+03, MSE(e): 3.898e-04, MSE(pi1): 8.246e-02, MSE(pi2): 2.854e-04, MSE(pi3): 2.368e-03\n",
      "Epoch 58100, Train loss: 5.515e+03, Test loss: 6.561e+03, MSE(e): 4.426e-04, MSE(pi1): 8.509e-02, MSE(pi2): 2.680e-04, MSE(pi3): 2.376e-03\n",
      "Epoch 58200, Train loss: 5.262e+03, Test loss: 5.853e+03, MSE(e): 4.189e-04, MSE(pi1): 8.177e-02, MSE(pi2): 2.909e-04, MSE(pi3): 2.552e-03\n",
      "Epoch 58300, Train loss: 5.036e+03, Test loss: 5.592e+03, MSE(e): 3.962e-04, MSE(pi1): 8.273e-02, MSE(pi2): 2.639e-04, MSE(pi3): 2.465e-03\n",
      "Epoch 58400, Train loss: 5.019e+03, Test loss: 6.384e+03, MSE(e): 3.945e-04, MSE(pi1): 8.391e-02, MSE(pi2): 2.533e-04, MSE(pi3): 2.346e-03\n",
      "Epoch 58500, Train loss: 7.425e+03, Test loss: 7.490e+03, MSE(e): 6.351e-04, MSE(pi1): 8.340e-02, MSE(pi2): 3.420e-04, MSE(pi3): 2.397e-03\n",
      "Epoch 58600, Train loss: 7.281e+03, Test loss: 1.145e+04, MSE(e): 6.195e-04, MSE(pi1): 8.177e-02, MSE(pi2): 2.913e-04, MSE(pi3): 2.679e-03\n",
      "Epoch 58700, Train loss: 5.071e+03, Test loss: 6.009e+03, MSE(e): 3.998e-04, MSE(pi1): 8.197e-02, MSE(pi2): 2.583e-04, MSE(pi3): 2.536e-03\n",
      "Epoch 58800, Train loss: 4.914e+03, Test loss: 5.821e+03, MSE(e): 3.842e-04, MSE(pi1): 8.312e-02, MSE(pi2): 2.495e-04, MSE(pi3): 2.402e-03\n",
      "Epoch 58900, Train loss: 5.433e+03, Test loss: 6.054e+03, MSE(e): 4.368e-04, MSE(pi1): 8.215e-02, MSE(pi2): 2.963e-04, MSE(pi3): 2.436e-03\n",
      "Epoch 59000, Train loss: 4.919e+03, Test loss: 6.154e+03, MSE(e): 3.847e-04, MSE(pi1): 8.345e-02, MSE(pi2): 2.492e-04, MSE(pi3): 2.372e-03\n",
      "Epoch 59100, Train loss: 5.250e+03, Test loss: 5.903e+03, MSE(e): 4.181e-04, MSE(pi1): 8.133e-02, MSE(pi2): 2.889e-04, MSE(pi3): 2.555e-03\n",
      "Epoch 59200, Train loss: 4.880e+03, Test loss: 6.043e+03, MSE(e): 3.817e-04, MSE(pi1): 8.251e-02, MSE(pi2): 2.677e-04, MSE(pi3): 2.370e-03\n",
      "Epoch 59300, Train loss: 5.143e+03, Test loss: 6.763e+03, MSE(e): 4.081e-04, MSE(pi1): 8.155e-02, MSE(pi2): 2.643e-04, MSE(pi3): 2.466e-03\n",
      "Epoch 59400, Train loss: 5.277e+03, Test loss: 6.337e+03, MSE(e): 4.197e-04, MSE(pi1): 8.127e-02, MSE(pi2): 2.688e-04, MSE(pi3): 2.670e-03\n",
      "Epoch 59500, Train loss: 5.064e+03, Test loss: 6.812e+03, MSE(e): 3.998e-04, MSE(pi1): 8.043e-02, MSE(pi2): 2.589e-04, MSE(pi3): 2.622e-03\n",
      "Epoch 59600, Train loss: 4.895e+03, Test loss: 6.045e+03, MSE(e): 3.833e-04, MSE(pi1): 8.257e-02, MSE(pi2): 2.682e-04, MSE(pi3): 2.356e-03\n",
      "Epoch 59700, Train loss: 6.106e+03, Test loss: 8.099e+03, MSE(e): 5.015e-04, MSE(pi1): 8.216e-02, MSE(pi2): 3.385e-04, MSE(pi3): 2.687e-03\n",
      "Epoch 59800, Train loss: 5.272e+03, Test loss: 6.030e+03, MSE(e): 4.204e-04, MSE(pi1): 8.244e-02, MSE(pi2): 2.646e-04, MSE(pi3): 2.429e-03\n",
      "Epoch 59900, Train loss: 5.048e+03, Test loss: 5.624e+03, MSE(e): 3.979e-04, MSE(pi1): 8.135e-02, MSE(pi2): 2.637e-04, MSE(pi3): 2.553e-03\n",
      "Epoch 60000, Train loss: 5.204e+03, Test loss: 5.954e+03, MSE(e): 4.140e-04, MSE(pi1): 7.994e-02, MSE(pi2): 3.096e-04, MSE(pi3): 2.645e-03\n",
      "Epoch 60100, Train loss: 6.205e+03, Test loss: 9.167e+03, MSE(e): 5.117e-04, MSE(pi1): 8.073e-02, MSE(pi2): 2.775e-04, MSE(pi3): 2.801e-03\n",
      "Epoch 60200, Train loss: 9.274e+03, Test loss: 6.789e+03, MSE(e): 8.189e-04, MSE(pi1): 8.347e-02, MSE(pi2): 3.565e-04, MSE(pi3): 2.494e-03\n",
      "Epoch 60300, Train loss: 5.405e+03, Test loss: 5.622e+03, MSE(e): 4.339e-04, MSE(pi1): 8.276e-02, MSE(pi2): 2.732e-04, MSE(pi3): 2.380e-03\n",
      "Epoch 60400, Train loss: 5.920e+03, Test loss: 5.976e+03, MSE(e): 4.851e-04, MSE(pi1): 8.152e-02, MSE(pi2): 2.851e-04, MSE(pi3): 2.537e-03\n",
      "Epoch 60500, Train loss: 4.923e+03, Test loss: 5.506e+03, MSE(e): 3.857e-04, MSE(pi1): 8.163e-02, MSE(pi2): 2.688e-04, MSE(pi3): 2.497e-03\n",
      "Epoch 60600, Train loss: 6.580e+03, Test loss: 7.088e+03, MSE(e): 5.509e-04, MSE(pi1): 8.322e-02, MSE(pi2): 3.112e-04, MSE(pi3): 2.383e-03\n",
      "Epoch 60700, Train loss: 4.811e+03, Test loss: 5.641e+03, MSE(e): 3.752e-04, MSE(pi1): 8.225e-02, MSE(pi2): 2.541e-04, MSE(pi3): 2.367e-03\n",
      "Epoch 60800, Train loss: 6.010e+03, Test loss: 7.017e+03, MSE(e): 4.937e-04, MSE(pi1): 8.462e-02, MSE(pi2): 3.141e-04, MSE(pi3): 2.272e-03\n",
      "Epoch 60900, Train loss: 6.244e+03, Test loss: 6.710e+03, MSE(e): 5.163e-04, MSE(pi1): 8.379e-02, MSE(pi2): 2.665e-04, MSE(pi3): 2.427e-03\n",
      "Epoch 61000, Train loss: 5.934e+03, Test loss: 6.292e+03, MSE(e): 4.865e-04, MSE(pi1): 8.166e-02, MSE(pi2): 3.064e-04, MSE(pi3): 2.518e-03\n",
      "Epoch 61100, Train loss: 4.994e+03, Test loss: 7.249e+03, MSE(e): 3.920e-04, MSE(pi1): 8.096e-02, MSE(pi2): 2.497e-04, MSE(pi3): 2.637e-03\n",
      "Epoch 61200, Train loss: 5.208e+03, Test loss: 6.143e+03, MSE(e): 4.132e-04, MSE(pi1): 8.437e-02, MSE(pi2): 2.617e-04, MSE(pi3): 2.319e-03\n",
      "Epoch 61300, Train loss: 4.806e+03, Test loss: 5.562e+03, MSE(e): 3.744e-04, MSE(pi1): 8.188e-02, MSE(pi2): 2.501e-04, MSE(pi3): 2.424e-03\n",
      "Epoch 61400, Train loss: 5.206e+03, Test loss: 5.736e+03, MSE(e): 4.136e-04, MSE(pi1): 8.169e-02, MSE(pi2): 2.856e-04, MSE(pi3): 2.533e-03\n",
      "Epoch 61500, Train loss: 6.129e+03, Test loss: 6.261e+03, MSE(e): 5.047e-04, MSE(pi1): 8.109e-02, MSE(pi2): 2.875e-04, MSE(pi3): 2.702e-03\n",
      "Epoch 61600, Train loss: 5.749e+03, Test loss: 5.849e+03, MSE(e): 4.675e-04, MSE(pi1): 8.325e-02, MSE(pi2): 2.983e-04, MSE(pi3): 2.404e-03\n",
      "Epoch 61700, Train loss: 5.123e+03, Test loss: 6.400e+03, MSE(e): 4.059e-04, MSE(pi1): 8.329e-02, MSE(pi2): 2.804e-04, MSE(pi3): 2.310e-03\n",
      "Epoch 61800, Train loss: 4.779e+03, Test loss: 5.537e+03, MSE(e): 3.718e-04, MSE(pi1): 8.153e-02, MSE(pi2): 2.511e-04, MSE(pi3): 2.456e-03\n",
      "Epoch 61900, Train loss: 5.848e+03, Test loss: 8.236e+03, MSE(e): 4.765e-04, MSE(pi1): 8.185e-02, MSE(pi2): 2.500e-04, MSE(pi3): 2.642e-03\n",
      "Epoch 62000, Train loss: 5.888e+03, Test loss: 6.711e+03, MSE(e): 4.812e-04, MSE(pi1): 8.361e-02, MSE(pi2): 2.509e-04, MSE(pi3): 2.401e-03\n",
      "Epoch 62100, Train loss: 5.101e+03, Test loss: 6.549e+03, MSE(e): 4.046e-04, MSE(pi1): 8.175e-02, MSE(pi2): 2.807e-04, MSE(pi3): 2.373e-03\n",
      "Epoch 62200, Train loss: 5.004e+03, Test loss: 5.796e+03, MSE(e): 3.949e-04, MSE(pi1): 8.169e-02, MSE(pi2): 2.704e-04, MSE(pi3): 2.381e-03\n",
      "Epoch 62300, Train loss: 5.770e+03, Test loss: 6.347e+03, MSE(e): 4.696e-04, MSE(pi1): 8.485e-02, MSE(pi2): 3.104e-04, MSE(pi3): 2.253e-03\n",
      "Epoch 62400, Train loss: 5.668e+03, Test loss: 6.776e+03, MSE(e): 4.591e-04, MSE(pi1): 8.074e-02, MSE(pi2): 2.802e-04, MSE(pi3): 2.695e-03\n",
      "Epoch 62500, Train loss: 4.796e+03, Test loss: 5.914e+03, MSE(e): 3.739e-04, MSE(pi1): 8.104e-02, MSE(pi2): 2.383e-04, MSE(pi3): 2.466e-03\n",
      "Epoch 62600, Train loss: 5.018e+03, Test loss: 6.021e+03, MSE(e): 3.946e-04, MSE(pi1): 8.128e-02, MSE(pi2): 2.568e-04, MSE(pi3): 2.586e-03\n",
      "Epoch 62700, Train loss: 4.772e+03, Test loss: 5.855e+03, MSE(e): 3.718e-04, MSE(pi1): 8.170e-02, MSE(pi2): 2.615e-04, MSE(pi3): 2.370e-03\n",
      "Epoch 62800, Train loss: 5.771e+03, Test loss: 5.728e+03, MSE(e): 4.699e-04, MSE(pi1): 8.240e-02, MSE(pi2): 2.882e-04, MSE(pi3): 2.485e-03\n",
      "Epoch 62900, Train loss: 5.439e+03, Test loss: 6.748e+03, MSE(e): 4.361e-04, MSE(pi1): 8.080e-02, MSE(pi2): 3.210e-04, MSE(pi3): 2.702e-03\n",
      "Epoch 63000, Train loss: 4.767e+03, Test loss: 5.916e+03, MSE(e): 3.709e-04, MSE(pi1): 8.098e-02, MSE(pi2): 2.371e-04, MSE(pi3): 2.479e-03\n",
      "Epoch 63100, Train loss: 6.237e+03, Test loss: 8.765e+03, MSE(e): 5.145e-04, MSE(pi1): 8.157e-02, MSE(pi2): 2.713e-04, MSE(pi3): 2.762e-03\n",
      "Epoch 63200, Train loss: 5.116e+03, Test loss: 6.648e+03, MSE(e): 4.053e-04, MSE(pi1): 7.984e-02, MSE(pi2): 2.780e-04, MSE(pi3): 2.652e-03\n",
      "Epoch 63300, Train loss: 4.834e+03, Test loss: 5.661e+03, MSE(e): 3.776e-04, MSE(pi1): 8.082e-02, MSE(pi2): 2.756e-04, MSE(pi3): 2.504e-03\n",
      "Epoch 63400, Train loss: 4.859e+03, Test loss: 5.576e+03, MSE(e): 3.795e-04, MSE(pi1): 8.150e-02, MSE(pi2): 2.661e-04, MSE(pi3): 2.479e-03\n",
      "Epoch 63500, Train loss: 5.150e+03, Test loss: 6.234e+03, MSE(e): 4.083e-04, MSE(pi1): 8.064e-02, MSE(pi2): 3.085e-04, MSE(pi3): 2.606e-03\n",
      "Epoch 63600, Train loss: 6.388e+03, Test loss: 9.295e+03, MSE(e): 5.269e-04, MSE(pi1): 8.341e-02, MSE(pi2): 2.710e-04, MSE(pi3): 2.852e-03\n",
      "Epoch 63700, Train loss: 4.867e+03, Test loss: 5.727e+03, MSE(e): 3.808e-04, MSE(pi1): 8.029e-02, MSE(pi2): 2.822e-04, MSE(pi3): 2.550e-03\n",
      "Epoch 63800, Train loss: 4.984e+03, Test loss: 5.740e+03, MSE(e): 3.919e-04, MSE(pi1): 8.301e-02, MSE(pi2): 2.493e-04, MSE(pi3): 2.350e-03\n",
      "Epoch 63900, Train loss: 5.033e+03, Test loss: 6.255e+03, MSE(e): 3.964e-04, MSE(pi1): 8.368e-02, MSE(pi2): 2.546e-04, MSE(pi3): 2.320e-03\n",
      "Epoch 64000, Train loss: 5.371e+03, Test loss: 6.274e+03, MSE(e): 4.314e-04, MSE(pi1): 7.891e-02, MSE(pi2): 3.260e-04, MSE(pi3): 2.675e-03\n",
      "Epoch 64100, Train loss: 5.071e+03, Test loss: 6.010e+03, MSE(e): 4.006e-04, MSE(pi1): 8.017e-02, MSE(pi2): 2.693e-04, MSE(pi3): 2.636e-03\n",
      "Epoch 64200, Train loss: 5.151e+03, Test loss: 5.875e+03, MSE(e): 4.104e-04, MSE(pi1): 8.058e-02, MSE(pi2): 2.919e-04, MSE(pi3): 2.407e-03\n",
      "Epoch 64300, Train loss: 5.182e+03, Test loss: 5.694e+03, MSE(e): 4.129e-04, MSE(pi1): 8.148e-02, MSE(pi2): 2.729e-04, MSE(pi3): 2.377e-03\n",
      "Epoch 64400, Train loss: 5.067e+03, Test loss: 6.900e+03, MSE(e): 4.006e-04, MSE(pi1): 8.042e-02, MSE(pi2): 2.410e-04, MSE(pi3): 2.574e-03\n",
      "Epoch 64500, Train loss: 5.034e+03, Test loss: 5.451e+03, MSE(e): 3.973e-04, MSE(pi1): 8.094e-02, MSE(pi2): 2.512e-04, MSE(pi3): 2.523e-03\n",
      "Epoch 64600, Train loss: 4.901e+03, Test loss: 6.295e+03, MSE(e): 3.845e-04, MSE(pi1): 8.096e-02, MSE(pi2): 2.323e-04, MSE(pi3): 2.465e-03\n",
      "Epoch 64700, Train loss: 4.958e+03, Test loss: 5.876e+03, MSE(e): 3.892e-04, MSE(pi1): 8.062e-02, MSE(pi2): 2.637e-04, MSE(pi3): 2.599e-03\n",
      "Epoch 64800, Train loss: 5.732e+03, Test loss: 6.121e+03, MSE(e): 4.677e-04, MSE(pi1): 7.841e-02, MSE(pi2): 3.442e-04, MSE(pi3): 2.714e-03\n",
      "Epoch 64900, Train loss: 6.341e+03, Test loss: 8.000e+03, MSE(e): 5.275e-04, MSE(pi1): 8.372e-02, MSE(pi2): 3.193e-04, MSE(pi3): 2.288e-03\n",
      "Epoch 65000, Train loss: 4.696e+03, Test loss: 5.464e+03, MSE(e): 3.649e-04, MSE(pi1): 8.085e-02, MSE(pi2): 2.681e-04, MSE(pi3): 2.389e-03\n",
      "Epoch 65100, Train loss: 5.301e+03, Test loss: 5.960e+03, MSE(e): 4.238e-04, MSE(pi1): 8.168e-02, MSE(pi2): 2.877e-04, MSE(pi3): 2.465e-03\n",
      "Epoch 65200, Train loss: 4.961e+03, Test loss: 6.233e+03, MSE(e): 3.905e-04, MSE(pi1): 7.990e-02, MSE(pi2): 2.577e-04, MSE(pi3): 2.574e-03\n",
      "Epoch 65300, Train loss: 4.894e+03, Test loss: 5.541e+03, MSE(e): 3.842e-04, MSE(pi1): 8.075e-02, MSE(pi2): 2.522e-04, MSE(pi3): 2.439e-03\n",
      "Epoch 65400, Train loss: 5.067e+03, Test loss: 5.699e+03, MSE(e): 4.019e-04, MSE(pi1): 8.051e-02, MSE(pi2): 2.608e-04, MSE(pi3): 2.424e-03\n",
      "Epoch 65500, Train loss: 5.551e+03, Test loss: 7.119e+03, MSE(e): 4.480e-04, MSE(pi1): 8.287e-02, MSE(pi2): 2.426e-04, MSE(pi3): 2.420e-03\n",
      "Epoch 65600, Train loss: 4.949e+03, Test loss: 6.215e+03, MSE(e): 3.889e-04, MSE(pi1): 8.106e-02, MSE(pi2): 2.402e-04, MSE(pi3): 2.488e-03\n",
      "Epoch 65700, Train loss: 4.783e+03, Test loss: 6.125e+03, MSE(e): 3.739e-04, MSE(pi1): 8.051e-02, MSE(pi2): 2.723e-04, MSE(pi3): 2.387e-03\n",
      "Epoch 65800, Train loss: 5.112e+03, Test loss: 6.144e+03, MSE(e): 4.047e-04, MSE(pi1): 8.312e-02, MSE(pi2): 2.490e-04, MSE(pi3): 2.337e-03\n",
      "Epoch 65900, Train loss: 5.346e+03, Test loss: 5.597e+03, MSE(e): 4.292e-04, MSE(pi1): 8.043e-02, MSE(pi2): 2.763e-04, MSE(pi3): 2.495e-03\n",
      "Epoch 66000, Train loss: 5.409e+03, Test loss: 5.453e+03, MSE(e): 4.347e-04, MSE(pi1): 8.041e-02, MSE(pi2): 2.704e-04, MSE(pi3): 2.572e-03\n",
      "Epoch 66100, Train loss: 5.027e+03, Test loss: 5.717e+03, MSE(e): 3.969e-04, MSE(pi1): 8.212e-02, MSE(pi2): 2.463e-04, MSE(pi3): 2.367e-03\n",
      "Epoch 66200, Train loss: 5.398e+03, Test loss: 5.741e+03, MSE(e): 4.346e-04, MSE(pi1): 8.064e-02, MSE(pi2): 2.553e-04, MSE(pi3): 2.454e-03\n",
      "Epoch 66300, Train loss: 4.936e+03, Test loss: 5.781e+03, MSE(e): 3.881e-04, MSE(pi1): 8.203e-02, MSE(pi2): 2.523e-04, MSE(pi3): 2.339e-03\n",
      "Epoch 66400, Train loss: 5.194e+03, Test loss: 6.043e+03, MSE(e): 4.147e-04, MSE(pi1): 7.949e-02, MSE(pi2): 3.119e-04, MSE(pi3): 2.519e-03\n",
      "Epoch 66500, Train loss: 4.986e+03, Test loss: 5.772e+03, MSE(e): 3.929e-04, MSE(pi1): 8.174e-02, MSE(pi2): 2.380e-04, MSE(pi3): 2.400e-03\n",
      "Epoch 66600, Train loss: 7.645e+03, Test loss: 7.519e+03, MSE(e): 6.568e-04, MSE(pi1): 7.988e-02, MSE(pi2): 3.120e-04, MSE(pi3): 2.777e-03\n",
      "Epoch 66700, Train loss: 5.475e+03, Test loss: 6.535e+03, MSE(e): 4.401e-04, MSE(pi1): 8.361e-02, MSE(pi2): 2.457e-04, MSE(pi3): 2.371e-03\n",
      "Epoch 66800, Train loss: 4.755e+03, Test loss: 5.443e+03, MSE(e): 3.707e-04, MSE(pi1): 8.061e-02, MSE(pi2): 2.464e-04, MSE(pi3): 2.421e-03\n",
      "Epoch 66900, Train loss: 4.969e+03, Test loss: 5.785e+03, MSE(e): 3.909e-04, MSE(pi1): 8.005e-02, MSE(pi2): 2.482e-04, MSE(pi3): 2.589e-03\n",
      "Epoch 67000, Train loss: 5.079e+03, Test loss: 6.255e+03, MSE(e): 4.025e-04, MSE(pi1): 7.957e-02, MSE(pi2): 2.556e-04, MSE(pi3): 2.573e-03\n",
      "Epoch 67100, Train loss: 5.449e+03, Test loss: 6.814e+03, MSE(e): 4.393e-04, MSE(pi1): 7.822e-02, MSE(pi2): 2.738e-04, MSE(pi3): 2.740e-03\n",
      "Epoch 67200, Train loss: 5.143e+03, Test loss: 6.488e+03, MSE(e): 4.084e-04, MSE(pi1): 8.245e-02, MSE(pi2): 2.416e-04, MSE(pi3): 2.344e-03\n",
      "Epoch 67300, Train loss: 4.917e+03, Test loss: 5.611e+03, MSE(e): 3.865e-04, MSE(pi1): 7.994e-02, MSE(pi2): 2.414e-04, MSE(pi3): 2.524e-03\n",
      "Epoch 67400, Train loss: 4.861e+03, Test loss: 5.895e+03, MSE(e): 3.806e-04, MSE(pi1): 8.166e-02, MSE(pi2): 2.429e-04, MSE(pi3): 2.378e-03\n",
      "Epoch 67500, Train loss: 5.831e+03, Test loss: 8.377e+03, MSE(e): 4.746e-04, MSE(pi1): 8.005e-02, MSE(pi2): 2.640e-04, MSE(pi3): 2.843e-03\n",
      "Epoch 67600, Train loss: 5.058e+03, Test loss: 5.563e+03, MSE(e): 4.013e-04, MSE(pi1): 7.994e-02, MSE(pi2): 2.614e-04, MSE(pi3): 2.456e-03\n",
      "Epoch 67700, Train loss: 4.807e+03, Test loss: 5.988e+03, MSE(e): 3.763e-04, MSE(pi1): 8.091e-02, MSE(pi2): 2.591e-04, MSE(pi3): 2.347e-03\n",
      "Epoch 67800, Train loss: 4.944e+03, Test loss: 5.641e+03, MSE(e): 3.897e-04, MSE(pi1): 8.076e-02, MSE(pi2): 2.471e-04, MSE(pi3): 2.401e-03\n",
      "Epoch 67900, Train loss: 5.248e+03, Test loss: 5.608e+03, MSE(e): 4.204e-04, MSE(pi1): 8.031e-02, MSE(pi2): 2.932e-04, MSE(pi3): 2.408e-03\n",
      "Epoch 68000, Train loss: 6.777e+03, Test loss: 6.422e+03, MSE(e): 5.715e-04, MSE(pi1): 8.258e-02, MSE(pi2): 2.923e-04, MSE(pi3): 2.358e-03\n",
      "Epoch 68100, Train loss: 4.965e+03, Test loss: 5.842e+03, MSE(e): 3.905e-04, MSE(pi1): 7.950e-02, MSE(pi2): 2.925e-04, MSE(pi3): 2.648e-03\n",
      "Epoch 68200, Train loss: 5.001e+03, Test loss: 5.743e+03, MSE(e): 3.956e-04, MSE(pi1): 8.086e-02, MSE(pi2): 2.544e-04, MSE(pi3): 2.368e-03\n",
      "Epoch 68300, Train loss: 5.875e+03, Test loss: 6.341e+03, MSE(e): 4.834e-04, MSE(pi1): 7.852e-02, MSE(pi2): 3.370e-04, MSE(pi3): 2.554e-03\n",
      "Epoch 68400, Train loss: 4.931e+03, Test loss: 5.861e+03, MSE(e): 3.877e-04, MSE(pi1): 8.149e-02, MSE(pi2): 2.498e-04, MSE(pi3): 2.392e-03\n",
      "Epoch 68500, Train loss: 4.802e+03, Test loss: 5.870e+03, MSE(e): 3.752e-04, MSE(pi1): 8.179e-02, MSE(pi2): 2.547e-04, MSE(pi3): 2.320e-03\n",
      "Epoch 68600, Train loss: 4.810e+03, Test loss: 5.605e+03, MSE(e): 3.764e-04, MSE(pi1): 8.036e-02, MSE(pi2): 2.473e-04, MSE(pi3): 2.416e-03\n",
      "Epoch 68700, Train loss: 5.421e+03, Test loss: 6.960e+03, MSE(e): 4.361e-04, MSE(pi1): 7.838e-02, MSE(pi2): 3.253e-04, MSE(pi3): 2.761e-03\n",
      "Epoch 68800, Train loss: 7.946e+03, Test loss: 6.496e+03, MSE(e): 6.854e-04, MSE(pi1): 8.499e-02, MSE(pi2): 3.253e-04, MSE(pi3): 2.414e-03\n",
      "Epoch 68900, Train loss: 5.549e+03, Test loss: 6.500e+03, MSE(e): 4.477e-04, MSE(pi1): 7.950e-02, MSE(pi2): 3.029e-04, MSE(pi3): 2.762e-03\n",
      "Epoch 69000, Train loss: 4.668e+03, Test loss: 5.423e+03, MSE(e): 3.632e-04, MSE(pi1): 7.981e-02, MSE(pi2): 2.719e-04, MSE(pi3): 2.373e-03\n",
      "Epoch 69100, Train loss: 6.232e+03, Test loss: 7.720e+03, MSE(e): 5.160e-04, MSE(pi1): 8.265e-02, MSE(pi2): 2.767e-04, MSE(pi3): 2.456e-03\n",
      "Epoch 69200, Train loss: 5.257e+03, Test loss: 5.882e+03, MSE(e): 4.201e-04, MSE(pi1): 8.002e-02, MSE(pi2): 2.857e-04, MSE(pi3): 2.560e-03\n",
      "Epoch 69300, Train loss: 6.286e+03, Test loss: 7.941e+03, MSE(e): 5.185e-04, MSE(pi1): 8.162e-02, MSE(pi2): 2.779e-04, MSE(pi3): 2.851e-03\n",
      "Epoch 69400, Train loss: 4.682e+03, Test loss: 5.446e+03, MSE(e): 3.640e-04, MSE(pi1): 8.045e-02, MSE(pi2): 2.500e-04, MSE(pi3): 2.373e-03\n",
      "Epoch 69500, Train loss: 5.040e+03, Test loss: 6.215e+03, MSE(e): 3.992e-04, MSE(pi1): 7.856e-02, MSE(pi2): 2.814e-04, MSE(pi3): 2.628e-03\n",
      "Epoch 69600, Train loss: 4.927e+03, Test loss: 5.752e+03, MSE(e): 3.875e-04, MSE(pi1): 7.978e-02, MSE(pi2): 2.702e-04, MSE(pi3): 2.541e-03\n",
      "Epoch 69700, Train loss: 5.192e+03, Test loss: 5.810e+03, MSE(e): 4.138e-04, MSE(pi1): 8.176e-02, MSE(pi2): 2.350e-04, MSE(pi3): 2.361e-03\n",
      "Epoch 69800, Train loss: 4.757e+03, Test loss: 5.345e+03, MSE(e): 3.714e-04, MSE(pi1): 7.987e-02, MSE(pi2): 2.762e-04, MSE(pi3): 2.438e-03\n",
      "Epoch 69900, Train loss: 4.721e+03, Test loss: 6.140e+03, MSE(e): 3.686e-04, MSE(pi1): 7.979e-02, MSE(pi2): 2.648e-04, MSE(pi3): 2.365e-03\n",
      "Epoch 70000, Train loss: 4.763e+03, Test loss: 5.783e+03, MSE(e): 3.712e-04, MSE(pi1): 7.946e-02, MSE(pi2): 2.577e-04, MSE(pi3): 2.562e-03\n",
      "Epoch 70100, Train loss: 5.546e+03, Test loss: 5.992e+03, MSE(e): 4.501e-04, MSE(pi1): 8.020e-02, MSE(pi2): 2.883e-04, MSE(pi3): 2.424e-03\n",
      "Epoch 70200, Train loss: 5.268e+03, Test loss: 5.921e+03, MSE(e): 4.212e-04, MSE(pi1): 8.241e-02, MSE(pi2): 2.613e-04, MSE(pi3): 2.322e-03\n",
      "Epoch 70300, Train loss: 5.084e+03, Test loss: 5.854e+03, MSE(e): 4.042e-04, MSE(pi1): 7.829e-02, MSE(pi2): 2.843e-04, MSE(pi3): 2.594e-03\n",
      "Epoch 70400, Train loss: 4.896e+03, Test loss: 5.761e+03, MSE(e): 3.851e-04, MSE(pi1): 7.914e-02, MSE(pi2): 2.414e-04, MSE(pi3): 2.527e-03\n",
      "Epoch 70500, Train loss: 4.951e+03, Test loss: 6.092e+03, MSE(e): 3.898e-04, MSE(pi1): 8.164e-02, MSE(pi2): 2.356e-04, MSE(pi3): 2.362e-03\n",
      "Epoch 70600, Train loss: 5.299e+03, Test loss: 6.606e+03, MSE(e): 4.238e-04, MSE(pi1): 8.245e-02, MSE(pi2): 2.459e-04, MSE(pi3): 2.361e-03\n",
      "Epoch 70700, Train loss: 4.967e+03, Test loss: 7.202e+03, MSE(e): 3.914e-04, MSE(pi1): 7.906e-02, MSE(pi2): 2.817e-04, MSE(pi3): 2.622e-03\n",
      "Epoch 70800, Train loss: 4.657e+03, Test loss: 5.340e+03, MSE(e): 3.618e-04, MSE(pi1): 7.939e-02, MSE(pi2): 2.569e-04, MSE(pi3): 2.450e-03\n",
      "Epoch 70900, Train loss: 4.754e+03, Test loss: 6.028e+03, MSE(e): 3.712e-04, MSE(pi1): 7.978e-02, MSE(pi2): 2.266e-04, MSE(pi3): 2.440e-03\n",
      "Epoch 71000, Train loss: 4.897e+03, Test loss: 6.002e+03, MSE(e): 3.852e-04, MSE(pi1): 8.154e-02, MSE(pi2): 2.663e-04, MSE(pi3): 2.301e-03\n",
      "Epoch 71100, Train loss: 5.426e+03, Test loss: 5.723e+03, MSE(e): 4.384e-04, MSE(pi1): 8.100e-02, MSE(pi2): 2.959e-04, MSE(pi3): 2.314e-03\n",
      "Epoch 71200, Train loss: 4.948e+03, Test loss: 5.724e+03, MSE(e): 3.900e-04, MSE(pi1): 7.917e-02, MSE(pi2): 2.479e-04, MSE(pi3): 2.559e-03\n",
      "Epoch 71300, Train loss: 5.298e+03, Test loss: 5.370e+03, MSE(e): 4.255e-04, MSE(pi1): 8.079e-02, MSE(pi2): 2.846e-04, MSE(pi3): 2.353e-03\n",
      "Epoch 71400, Train loss: 4.761e+03, Test loss: 5.382e+03, MSE(e): 3.723e-04, MSE(pi1): 7.863e-02, MSE(pi2): 2.698e-04, MSE(pi3): 2.518e-03\n",
      "Epoch 71500, Train loss: 6.340e+03, Test loss: 6.692e+03, MSE(e): 5.270e-04, MSE(pi1): 8.256e-02, MSE(pi2): 2.624e-04, MSE(pi3): 2.446e-03\n",
      "Epoch 71600, Train loss: 5.016e+03, Test loss: 5.897e+03, MSE(e): 3.967e-04, MSE(pi1): 7.933e-02, MSE(pi2): 2.393e-04, MSE(pi3): 2.554e-03\n",
      "Epoch 71700, Train loss: 5.407e+03, Test loss: 5.914e+03, MSE(e): 4.358e-04, MSE(pi1): 8.187e-02, MSE(pi2): 2.829e-04, MSE(pi3): 2.299e-03\n",
      "Epoch 71800, Train loss: 4.806e+03, Test loss: 5.611e+03, MSE(e): 3.764e-04, MSE(pi1): 8.009e-02, MSE(pi2): 2.440e-04, MSE(pi3): 2.405e-03\n",
      "Epoch 71900, Train loss: 6.367e+03, Test loss: 5.787e+03, MSE(e): 5.297e-04, MSE(pi1): 8.350e-02, MSE(pi2): 3.206e-04, MSE(pi3): 2.342e-03\n",
      "Epoch 72000, Train loss: 4.971e+03, Test loss: 6.121e+03, MSE(e): 3.919e-04, MSE(pi1): 7.849e-02, MSE(pi2): 2.511e-04, MSE(pi3): 2.671e-03\n",
      "Epoch 72100, Train loss: 5.163e+03, Test loss: 7.539e+03, MSE(e): 4.116e-04, MSE(pi1): 7.973e-02, MSE(pi2): 2.286e-04, MSE(pi3): 2.490e-03\n",
      "Epoch 72200, Train loss: 6.624e+03, Test loss: 7.938e+03, MSE(e): 5.593e-04, MSE(pi1): 7.648e-02, MSE(pi2): 3.615e-04, MSE(pi3): 2.652e-03\n",
      "Epoch 72300, Train loss: 5.907e+03, Test loss: 6.221e+03, MSE(e): 4.851e-04, MSE(pi1): 8.244e-02, MSE(pi2): 2.868e-04, MSE(pi3): 2.305e-03\n",
      "Epoch 72400, Train loss: 4.751e+03, Test loss: 5.462e+03, MSE(e): 3.706e-04, MSE(pi1): 7.979e-02, MSE(pi2): 2.500e-04, MSE(pi3): 2.473e-03\n",
      "Epoch 72500, Train loss: 8.424e+03, Test loss: 8.507e+03, MSE(e): 7.308e-04, MSE(pi1): 8.324e-02, MSE(pi2): 3.939e-04, MSE(pi3): 2.837e-03\n",
      "Epoch 72600, Train loss: 4.898e+03, Test loss: 6.409e+03, MSE(e): 3.853e-04, MSE(pi1): 8.120e-02, MSE(pi2): 2.714e-04, MSE(pi3): 2.327e-03\n",
      "Epoch 72700, Train loss: 5.243e+03, Test loss: 6.811e+03, MSE(e): 4.183e-04, MSE(pi1): 7.852e-02, MSE(pi2): 2.828e-04, MSE(pi3): 2.746e-03\n",
      "Epoch 72800, Train loss: 5.363e+03, Test loss: 6.063e+03, MSE(e): 4.325e-04, MSE(pi1): 8.019e-02, MSE(pi2): 2.769e-04, MSE(pi3): 2.362e-03\n",
      "Epoch 72900, Train loss: 4.746e+03, Test loss: 5.525e+03, MSE(e): 3.704e-04, MSE(pi1): 7.875e-02, MSE(pi2): 2.613e-04, MSE(pi3): 2.541e-03\n",
      "Epoch 73000, Train loss: 4.898e+03, Test loss: 5.942e+03, MSE(e): 3.855e-04, MSE(pi1): 7.774e-02, MSE(pi2): 2.703e-04, MSE(pi3): 2.649e-03\n",
      "Epoch 73100, Train loss: 4.851e+03, Test loss: 5.888e+03, MSE(e): 3.811e-04, MSE(pi1): 7.921e-02, MSE(pi2): 2.295e-04, MSE(pi3): 2.479e-03\n",
      "Epoch 73200, Train loss: 6.110e+03, Test loss: 7.276e+03, MSE(e): 5.051e-04, MSE(pi1): 8.145e-02, MSE(pi2): 2.598e-04, MSE(pi3): 2.440e-03\n",
      "Epoch 73300, Train loss: 4.670e+03, Test loss: 5.411e+03, MSE(e): 3.632e-04, MSE(pi1): 7.918e-02, MSE(pi2): 2.511e-04, MSE(pi3): 2.461e-03\n",
      "Epoch 73400, Train loss: 4.880e+03, Test loss: 5.894e+03, MSE(e): 3.835e-04, MSE(pi1): 7.882e-02, MSE(pi2): 2.294e-04, MSE(pi3): 2.570e-03\n",
      "Epoch 73500, Train loss: 4.853e+03, Test loss: 6.002e+03, MSE(e): 3.822e-04, MSE(pi1): 7.968e-02, MSE(pi2): 2.705e-04, MSE(pi3): 2.345e-03\n",
      "Epoch 73600, Train loss: 4.838e+03, Test loss: 5.373e+03, MSE(e): 3.801e-04, MSE(pi1): 8.003e-02, MSE(pi2): 2.532e-04, MSE(pi3): 2.368e-03\n",
      "Epoch 73700, Train loss: 5.057e+03, Test loss: 5.813e+03, MSE(e): 4.010e-04, MSE(pi1): 8.057e-02, MSE(pi2): 2.318e-04, MSE(pi3): 2.408e-03\n",
      "Epoch 73800, Train loss: 4.690e+03, Test loss: 5.256e+03, MSE(e): 3.651e-04, MSE(pi1): 7.933e-02, MSE(pi2): 2.607e-04, MSE(pi3): 2.452e-03\n",
      "Epoch 73900, Train loss: 4.635e+03, Test loss: 5.280e+03, MSE(e): 3.603e-04, MSE(pi1): 7.917e-02, MSE(pi2): 2.576e-04, MSE(pi3): 2.396e-03\n",
      "Epoch 74000, Train loss: 5.441e+03, Test loss: 6.046e+03, MSE(e): 4.395e-04, MSE(pi1): 8.105e-02, MSE(pi2): 2.721e-04, MSE(pi3): 2.347e-03\n",
      "Epoch 74100, Train loss: 7.349e+03, Test loss: 7.076e+03, MSE(e): 6.290e-04, MSE(pi1): 8.195e-02, MSE(pi2): 2.977e-04, MSE(pi3): 2.398e-03\n",
      "Epoch 74200, Train loss: 4.890e+03, Test loss: 5.889e+03, MSE(e): 3.843e-04, MSE(pi1): 7.884e-02, MSE(pi2): 2.227e-04, MSE(pi3): 2.582e-03\n",
      "Epoch 74300, Train loss: 5.143e+03, Test loss: 5.918e+03, MSE(e): 4.096e-04, MSE(pi1): 8.082e-02, MSE(pi2): 2.387e-04, MSE(pi3): 2.389e-03\n",
      "Epoch 74400, Train loss: 5.480e+03, Test loss: 5.327e+03, MSE(e): 4.431e-04, MSE(pi1): 7.996e-02, MSE(pi2): 2.698e-04, MSE(pi3): 2.493e-03\n",
      "Epoch 74500, Train loss: 5.659e+03, Test loss: 6.725e+03, MSE(e): 4.611e-04, MSE(pi1): 7.952e-02, MSE(pi2): 2.379e-04, MSE(pi3): 2.533e-03\n",
      "Epoch 74600, Train loss: 4.596e+03, Test loss: 5.526e+03, MSE(e): 3.562e-04, MSE(pi1): 7.997e-02, MSE(pi2): 2.509e-04, MSE(pi3): 2.337e-03\n",
      "Epoch 74700, Train loss: 4.617e+03, Test loss: 5.371e+03, MSE(e): 3.582e-04, MSE(pi1): 7.886e-02, MSE(pi2): 2.488e-04, MSE(pi3): 2.461e-03\n",
      "Epoch 74800, Train loss: 4.630e+03, Test loss: 5.356e+03, MSE(e): 3.591e-04, MSE(pi1): 7.886e-02, MSE(pi2): 2.426e-04, MSE(pi3): 2.505e-03\n",
      "Epoch 74900, Train loss: 5.008e+03, Test loss: 6.068e+03, MSE(e): 3.960e-04, MSE(pi1): 7.839e-02, MSE(pi2): 2.407e-04, MSE(pi3): 2.635e-03\n",
      "Epoch 75000, Train loss: 4.668e+03, Test loss: 5.626e+03, MSE(e): 3.637e-04, MSE(pi1): 7.966e-02, MSE(pi2): 2.686e-04, MSE(pi3): 2.345e-03\n",
      "Epoch 75100, Train loss: 6.007e+03, Test loss: 8.373e+03, MSE(e): 4.941e-04, MSE(pi1): 8.169e-02, MSE(pi2): 2.421e-04, MSE(pi3): 2.488e-03\n",
      "Epoch 75200, Train loss: 5.284e+03, Test loss: 6.274e+03, MSE(e): 4.235e-04, MSE(pi1): 7.825e-02, MSE(pi2): 2.531e-04, MSE(pi3): 2.660e-03\n",
      "Epoch 75300, Train loss: 4.661e+03, Test loss: 5.202e+03, MSE(e): 3.631e-04, MSE(pi1): 7.932e-02, MSE(pi2): 2.638e-04, MSE(pi3): 2.363e-03\n",
      "Epoch 75400, Train loss: 4.755e+03, Test loss: 5.859e+03, MSE(e): 3.710e-04, MSE(pi1): 7.812e-02, MSE(pi2): 2.527e-04, MSE(pi3): 2.629e-03\n",
      "Epoch 75500, Train loss: 5.051e+03, Test loss: 5.830e+03, MSE(e): 4.017e-04, MSE(pi1): 7.989e-02, MSE(pi2): 2.743e-04, MSE(pi3): 2.353e-03\n",
      "Epoch 75600, Train loss: 5.059e+03, Test loss: 6.108e+03, MSE(e): 4.022e-04, MSE(pi1): 8.004e-02, MSE(pi2): 2.595e-04, MSE(pi3): 2.369e-03\n",
      "Epoch 75700, Train loss: 4.708e+03, Test loss: 5.849e+03, MSE(e): 3.666e-04, MSE(pi1): 7.827e-02, MSE(pi2): 2.537e-04, MSE(pi3): 2.591e-03\n",
      "Epoch 75800, Train loss: 5.479e+03, Test loss: 8.112e+03, MSE(e): 4.428e-04, MSE(pi1): 7.703e-02, MSE(pi2): 3.181e-04, MSE(pi3): 2.805e-03\n",
      "Epoch 75900, Train loss: 4.860e+03, Test loss: 6.164e+03, MSE(e): 3.815e-04, MSE(pi1): 8.103e-02, MSE(pi2): 2.390e-04, MSE(pi3): 2.342e-03\n",
      "Epoch 76000, Train loss: 5.206e+03, Test loss: 5.532e+03, MSE(e): 4.170e-04, MSE(pi1): 7.951e-02, MSE(pi2): 2.902e-04, MSE(pi3): 2.404e-03\n",
      "Epoch 76100, Train loss: 4.709e+03, Test loss: 5.454e+03, MSE(e): 3.671e-04, MSE(pi1): 7.868e-02, MSE(pi2): 2.537e-04, MSE(pi3): 2.515e-03\n",
      "Epoch 76200, Train loss: 4.724e+03, Test loss: 6.422e+03, MSE(e): 3.694e-04, MSE(pi1): 7.941e-02, MSE(pi2): 2.677e-04, MSE(pi3): 2.362e-03\n",
      "Epoch 76300, Train loss: 5.627e+03, Test loss: 6.105e+03, MSE(e): 4.582e-04, MSE(pi1): 8.103e-02, MSE(pi2): 2.706e-04, MSE(pi3): 2.343e-03\n",
      "Epoch 76400, Train loss: 4.996e+03, Test loss: 5.936e+03, MSE(e): 3.945e-04, MSE(pi1): 7.885e-02, MSE(pi2): 2.638e-04, MSE(pi3): 2.624e-03\n",
      "Epoch 76500, Train loss: 4.652e+03, Test loss: 5.802e+03, MSE(e): 3.632e-04, MSE(pi1): 7.822e-02, MSE(pi2): 2.799e-04, MSE(pi3): 2.378e-03\n",
      "Epoch 76600, Train loss: 5.883e+03, Test loss: 6.210e+03, MSE(e): 4.820e-04, MSE(pi1): 7.866e-02, MSE(pi2): 2.751e-04, MSE(pi3): 2.762e-03\n",
      "Epoch 76700, Train loss: 4.623e+03, Test loss: 5.562e+03, MSE(e): 3.591e-04, MSE(pi1): 7.978e-02, MSE(pi2): 2.504e-04, MSE(pi3): 2.345e-03\n",
      "Epoch 76800, Train loss: 5.069e+03, Test loss: 6.004e+03, MSE(e): 4.029e-04, MSE(pi1): 7.835e-02, MSE(pi2): 2.321e-04, MSE(pi3): 2.566e-03\n",
      "Epoch 76900, Train loss: 4.751e+03, Test loss: 5.720e+03, MSE(e): 3.709e-04, MSE(pi1): 7.846e-02, MSE(pi2): 2.595e-04, MSE(pi3): 2.570e-03\n",
      "Epoch 77000, Train loss: 5.154e+03, Test loss: 5.515e+03, MSE(e): 4.121e-04, MSE(pi1): 7.997e-02, MSE(pi2): 2.845e-04, MSE(pi3): 2.328e-03\n",
      "Epoch 77100, Train loss: 5.254e+03, Test loss: 5.814e+03, MSE(e): 4.207e-04, MSE(pi1): 7.915e-02, MSE(pi2): 2.331e-04, MSE(pi3): 2.549e-03\n",
      "Epoch 77200, Train loss: 4.817e+03, Test loss: 6.008e+03, MSE(e): 3.774e-04, MSE(pi1): 7.764e-02, MSE(pi2): 2.573e-04, MSE(pi3): 2.667e-03\n",
      "Epoch 77300, Train loss: 4.997e+03, Test loss: 5.549e+03, MSE(e): 3.961e-04, MSE(pi1): 7.821e-02, MSE(pi2): 2.461e-04, MSE(pi3): 2.540e-03\n",
      "Epoch 77400, Train loss: 4.892e+03, Test loss: 5.392e+03, MSE(e): 3.859e-04, MSE(pi1): 7.920e-02, MSE(pi2): 2.596e-04, MSE(pi3): 2.407e-03\n",
      "Epoch 77500, Train loss: 4.789e+03, Test loss: 5.845e+03, MSE(e): 3.751e-04, MSE(pi1): 7.796e-02, MSE(pi2): 2.573e-04, MSE(pi3): 2.579e-03\n",
      "Epoch 77600, Train loss: 4.897e+03, Test loss: 5.490e+03, MSE(e): 3.860e-04, MSE(pi1): 7.909e-02, MSE(pi2): 2.581e-04, MSE(pi3): 2.460e-03\n",
      "Epoch 77700, Train loss: 4.818e+03, Test loss: 5.534e+03, MSE(e): 3.784e-04, MSE(pi1): 8.016e-02, MSE(pi2): 2.614e-04, MSE(pi3): 2.319e-03\n",
      "Epoch 77800, Train loss: 4.954e+03, Test loss: 5.636e+03, MSE(e): 3.921e-04, MSE(pi1): 7.870e-02, MSE(pi2): 2.623e-04, MSE(pi3): 2.455e-03\n",
      "Epoch 77900, Train loss: 4.820e+03, Test loss: 5.720e+03, MSE(e): 3.781e-04, MSE(pi1): 7.818e-02, MSE(pi2): 2.357e-04, MSE(pi3): 2.571e-03\n",
      "Epoch 78000, Train loss: 5.566e+03, Test loss: 7.197e+03, MSE(e): 4.509e-04, MSE(pi1): 8.147e-02, MSE(pi2): 2.418e-04, MSE(pi3): 2.425e-03\n",
      "Epoch 78100, Train loss: 4.801e+03, Test loss: 5.871e+03, MSE(e): 3.760e-04, MSE(pi1): 7.815e-02, MSE(pi2): 2.370e-04, MSE(pi3): 2.596e-03\n",
      "Epoch 78200, Train loss: 4.609e+03, Test loss: 5.499e+03, MSE(e): 3.571e-04, MSE(pi1): 7.833e-02, MSE(pi2): 2.377e-04, MSE(pi3): 2.548e-03\n",
      "Epoch 78300, Train loss: 4.770e+03, Test loss: 5.521e+03, MSE(e): 3.741e-04, MSE(pi1): 7.895e-02, MSE(pi2): 2.607e-04, MSE(pi3): 2.389e-03\n",
      "Epoch 78400, Train loss: 4.995e+03, Test loss: 5.581e+03, MSE(e): 3.944e-04, MSE(pi1): 7.954e-02, MSE(pi2): 2.650e-04, MSE(pi3): 2.559e-03\n",
      "Epoch 78500, Train loss: 4.683e+03, Test loss: 5.361e+03, MSE(e): 3.649e-04, MSE(pi1): 7.819e-02, MSE(pi2): 2.428e-04, MSE(pi3): 2.516e-03\n",
      "Epoch 78600, Train loss: 4.871e+03, Test loss: 5.943e+03, MSE(e): 3.837e-04, MSE(pi1): 7.966e-02, MSE(pi2): 2.432e-04, MSE(pi3): 2.371e-03\n",
      "Epoch 78700, Train loss: 4.955e+03, Test loss: 5.148e+03, MSE(e): 3.920e-04, MSE(pi1): 7.994e-02, MSE(pi2): 2.695e-04, MSE(pi3): 2.355e-03\n",
      "Epoch 78800, Train loss: 4.700e+03, Test loss: 5.797e+03, MSE(e): 3.663e-04, MSE(pi1): 7.795e-02, MSE(pi2): 2.476e-04, MSE(pi3): 2.571e-03\n",
      "Epoch 78900, Train loss: 4.767e+03, Test loss: 5.918e+03, MSE(e): 3.731e-04, MSE(pi1): 8.025e-02, MSE(pi2): 2.466e-04, MSE(pi3): 2.337e-03\n",
      "Epoch 79000, Train loss: 5.863e+03, Test loss: 6.356e+03, MSE(e): 4.809e-04, MSE(pi1): 8.161e-02, MSE(pi2): 2.633e-04, MSE(pi3): 2.379e-03\n",
      "Epoch 79100, Train loss: 5.248e+03, Test loss: 7.535e+03, MSE(e): 4.204e-04, MSE(pi1): 7.712e-02, MSE(pi2): 3.031e-04, MSE(pi3): 2.723e-03\n",
      "Epoch 79200, Train loss: 4.849e+03, Test loss: 5.613e+03, MSE(e): 3.820e-04, MSE(pi1): 7.933e-02, MSE(pi2): 2.625e-04, MSE(pi3): 2.356e-03\n",
      "Epoch 79300, Train loss: 4.995e+03, Test loss: 6.881e+03, MSE(e): 3.961e-04, MSE(pi1): 7.931e-02, MSE(pi2): 2.416e-04, MSE(pi3): 2.407e-03\n",
      "Epoch 79400, Train loss: 5.000e+03, Test loss: 6.523e+03, MSE(e): 3.956e-04, MSE(pi1): 7.822e-02, MSE(pi2): 2.152e-04, MSE(pi3): 2.610e-03\n",
      "Epoch 79500, Train loss: 5.060e+03, Test loss: 5.535e+03, MSE(e): 4.032e-04, MSE(pi1): 7.786e-02, MSE(pi2): 2.629e-04, MSE(pi3): 2.491e-03\n",
      "Epoch 79600, Train loss: 5.130e+03, Test loss: 6.374e+03, MSE(e): 4.086e-04, MSE(pi1): 8.105e-02, MSE(pi2): 2.711e-04, MSE(pi3): 2.332e-03\n",
      "Epoch 79700, Train loss: 5.196e+03, Test loss: 5.875e+03, MSE(e): 4.160e-04, MSE(pi1): 8.026e-02, MSE(pi2): 2.643e-04, MSE(pi3): 2.329e-03\n",
      "Epoch 79800, Train loss: 4.806e+03, Test loss: 6.034e+03, MSE(e): 3.770e-04, MSE(pi1): 7.822e-02, MSE(pi2): 2.627e-04, MSE(pi3): 2.542e-03\n",
      "Epoch 79900, Train loss: 6.472e+03, Test loss: 6.806e+03, MSE(e): 5.416e-04, MSE(pi1): 7.878e-02, MSE(pi2): 2.595e-04, MSE(pi3): 2.675e-03\n",
      "Epoch 80000, Train loss: 4.679e+03, Test loss: 5.869e+03, MSE(e): 3.650e-04, MSE(pi1): 7.958e-02, MSE(pi2): 2.629e-04, MSE(pi3): 2.324e-03\n",
      "Epoch 80100, Train loss: 4.540e+03, Test loss: 5.316e+03, MSE(e): 3.518e-04, MSE(pi1): 7.827e-02, MSE(pi2): 2.598e-04, MSE(pi3): 2.385e-03\n",
      "Epoch 80200, Train loss: 5.879e+03, Test loss: 6.266e+03, MSE(e): 4.825e-04, MSE(pi1): 7.772e-02, MSE(pi2): 2.539e-04, MSE(pi3): 2.763e-03\n",
      "Epoch 80300, Train loss: 4.685e+03, Test loss: 5.627e+03, MSE(e): 3.657e-04, MSE(pi1): 7.889e-02, MSE(pi2): 2.407e-04, MSE(pi3): 2.387e-03\n",
      "Epoch 80400, Train loss: 7.748e+03, Test loss: 5.541e+03, MSE(e): 6.686e-04, MSE(pi1): 8.230e-02, MSE(pi2): 3.602e-04, MSE(pi3): 2.387e-03\n",
      "Epoch 80500, Train loss: 7.019e+03, Test loss: 6.954e+03, MSE(e): 5.954e-04, MSE(pi1): 7.888e-02, MSE(pi2): 2.762e-04, MSE(pi3): 2.767e-03\n",
      "Epoch 80600, Train loss: 4.929e+03, Test loss: 5.707e+03, MSE(e): 3.897e-04, MSE(pi1): 7.882e-02, MSE(pi2): 2.376e-04, MSE(pi3): 2.433e-03\n",
      "Epoch 80700, Train loss: 5.698e+03, Test loss: 6.854e+03, MSE(e): 4.651e-04, MSE(pi1): 7.816e-02, MSE(pi2): 2.353e-04, MSE(pi3): 2.652e-03\n",
      "Epoch 80800, Train loss: 4.831e+03, Test loss: 5.567e+03, MSE(e): 3.799e-04, MSE(pi1): 7.727e-02, MSE(pi2): 2.292e-04, MSE(pi3): 2.592e-03\n",
      "Epoch 80900, Train loss: 4.737e+03, Test loss: 5.447e+03, MSE(e): 3.702e-04, MSE(pi1): 7.801e-02, MSE(pi2): 2.315e-04, MSE(pi3): 2.553e-03\n",
      "Epoch 81000, Train loss: 5.225e+03, Test loss: 6.289e+03, MSE(e): 4.197e-04, MSE(pi1): 7.658e-02, MSE(pi2): 3.003e-04, MSE(pi3): 2.618e-03\n",
      "Epoch 81100, Train loss: 6.183e+03, Test loss: 6.077e+03, MSE(e): 5.140e-04, MSE(pi1): 7.842e-02, MSE(pi2): 2.560e-04, MSE(pi3): 2.590e-03\n",
      "Epoch 81200, Train loss: 4.558e+03, Test loss: 5.148e+03, MSE(e): 3.532e-04, MSE(pi1): 7.845e-02, MSE(pi2): 2.485e-04, MSE(pi3): 2.407e-03\n",
      "Epoch 81300, Train loss: 4.830e+03, Test loss: 5.945e+03, MSE(e): 3.788e-04, MSE(pi1): 7.770e-02, MSE(pi2): 2.532e-04, MSE(pi3): 2.653e-03\n",
      "Epoch 81400, Train loss: 4.984e+03, Test loss: 5.950e+03, MSE(e): 3.950e-04, MSE(pi1): 7.992e-02, MSE(pi2): 2.609e-04, MSE(pi3): 2.339e-03\n",
      "Epoch 81500, Train loss: 5.229e+03, Test loss: 6.029e+03, MSE(e): 4.190e-04, MSE(pi1): 7.774e-02, MSE(pi2): 2.465e-04, MSE(pi3): 2.614e-03\n",
      "Epoch 81600, Train loss: 6.174e+03, Test loss: 5.941e+03, MSE(e): 5.138e-04, MSE(pi1): 7.995e-02, MSE(pi2): 2.798e-04, MSE(pi3): 2.366e-03\n",
      "Epoch 81700, Train loss: 5.141e+03, Test loss: 5.833e+03, MSE(e): 4.101e-04, MSE(pi1): 7.799e-02, MSE(pi2): 2.236e-04, MSE(pi3): 2.603e-03\n",
      "Epoch 81800, Train loss: 4.576e+03, Test loss: 5.253e+03, MSE(e): 3.553e-04, MSE(pi1): 7.874e-02, MSE(pi2): 2.667e-04, MSE(pi3): 2.350e-03\n",
      "Epoch 81900, Train loss: 5.715e+03, Test loss: 5.681e+03, MSE(e): 4.671e-04, MSE(pi1): 7.990e-02, MSE(pi2): 2.499e-04, MSE(pi3): 2.455e-03\n",
      "Epoch 82000, Train loss: 5.304e+03, Test loss: 6.482e+03, MSE(e): 4.260e-04, MSE(pi1): 8.087e-02, MSE(pi2): 2.497e-04, MSE(pi3): 2.356e-03\n",
      "Epoch 82100, Train loss: 4.869e+03, Test loss: 6.420e+03, MSE(e): 3.845e-04, MSE(pi1): 7.754e-02, MSE(pi2): 2.743e-04, MSE(pi3): 2.479e-03\n",
      "Epoch 82200, Train loss: 4.705e+03, Test loss: 5.858e+03, MSE(e): 3.670e-04, MSE(pi1): 8.030e-02, MSE(pi2): 2.555e-04, MSE(pi3): 2.314e-03\n",
      "Epoch 82300, Train loss: 4.816e+03, Test loss: 5.617e+03, MSE(e): 3.793e-04, MSE(pi1): 7.745e-02, MSE(pi2): 2.774e-04, MSE(pi3): 2.478e-03\n",
      "Epoch 82400, Train loss: 4.954e+03, Test loss: 5.798e+03, MSE(e): 3.926e-04, MSE(pi1): 7.883e-02, MSE(pi2): 2.432e-04, MSE(pi3): 2.391e-03\n",
      "Epoch 82500, Train loss: 4.663e+03, Test loss: 5.266e+03, MSE(e): 3.637e-04, MSE(pi1): 7.840e-02, MSE(pi2): 2.491e-04, MSE(pi3): 2.414e-03\n",
      "Epoch 82600, Train loss: 4.599e+03, Test loss: 5.520e+03, MSE(e): 3.573e-04, MSE(pi1): 7.909e-02, MSE(pi2): 2.457e-04, MSE(pi3): 2.351e-03\n",
      "Epoch 82700, Train loss: 5.166e+03, Test loss: 5.565e+03, MSE(e): 4.134e-04, MSE(pi1): 7.900e-02, MSE(pi2): 2.389e-04, MSE(pi3): 2.419e-03\n",
      "Epoch 82800, Train loss: 5.835e+03, Test loss: 6.075e+03, MSE(e): 4.803e-04, MSE(pi1): 7.871e-02, MSE(pi2): 2.600e-04, MSE(pi3): 2.443e-03\n",
      "Epoch 82900, Train loss: 5.066e+03, Test loss: 6.043e+03, MSE(e): 4.044e-04, MSE(pi1): 7.834e-02, MSE(pi2): 2.877e-04, MSE(pi3): 2.386e-03\n",
      "Epoch 83000, Train loss: 4.683e+03, Test loss: 5.582e+03, MSE(e): 3.650e-04, MSE(pi1): 7.860e-02, MSE(pi2): 2.318e-04, MSE(pi3): 2.467e-03\n",
      "Epoch 83100, Train loss: 5.006e+03, Test loss: 5.991e+03, MSE(e): 3.974e-04, MSE(pi1): 7.767e-02, MSE(pi2): 2.721e-04, MSE(pi3): 2.550e-03\n",
      "Epoch 83200, Train loss: 5.041e+03, Test loss: 6.023e+03, MSE(e): 4.004e-04, MSE(pi1): 8.067e-02, MSE(pi2): 2.666e-04, MSE(pi3): 2.295e-03\n",
      "Epoch 83300, Train loss: 4.904e+03, Test loss: 5.496e+03, MSE(e): 3.874e-04, MSE(pi1): 7.862e-02, MSE(pi2): 2.341e-04, MSE(pi3): 2.432e-03\n",
      "Epoch 83400, Train loss: 5.472e+03, Test loss: 6.059e+03, MSE(e): 4.417e-04, MSE(pi1): 7.947e-02, MSE(pi2): 2.586e-04, MSE(pi3): 2.595e-03\n",
      "Epoch 83500, Train loss: 5.625e+03, Test loss: 5.474e+03, MSE(e): 4.592e-04, MSE(pi1): 7.945e-02, MSE(pi2): 2.797e-04, MSE(pi3): 2.381e-03\n",
      "Epoch 83600, Train loss: 5.135e+03, Test loss: 6.286e+03, MSE(e): 4.093e-04, MSE(pi1): 7.760e-02, MSE(pi2): 2.276e-04, MSE(pi3): 2.661e-03\n",
      "Epoch 83700, Train loss: 4.606e+03, Test loss: 5.285e+03, MSE(e): 3.582e-04, MSE(pi1): 7.858e-02, MSE(pi2): 2.655e-04, MSE(pi3): 2.379e-03\n",
      "Epoch 83800, Train loss: 4.912e+03, Test loss: 5.720e+03, MSE(e): 3.885e-04, MSE(pi1): 7.744e-02, MSE(pi2): 2.649e-04, MSE(pi3): 2.524e-03\n",
      "Epoch 83900, Train loss: 4.926e+03, Test loss: 6.034e+03, MSE(e): 3.897e-04, MSE(pi1): 7.830e-02, MSE(pi2): 2.218e-04, MSE(pi3): 2.457e-03\n",
      "Epoch 84000, Train loss: 4.523e+03, Test loss: 5.240e+03, MSE(e): 3.500e-04, MSE(pi1): 7.851e-02, MSE(pi2): 2.412e-04, MSE(pi3): 2.377e-03\n",
      "Epoch 84100, Train loss: 4.865e+03, Test loss: 5.720e+03, MSE(e): 3.828e-04, MSE(pi1): 7.747e-02, MSE(pi2): 2.241e-04, MSE(pi3): 2.622e-03\n",
      "Epoch 84200, Train loss: 5.033e+03, Test loss: 5.637e+03, MSE(e): 4.010e-04, MSE(pi1): 7.712e-02, MSE(pi2): 2.708e-04, MSE(pi3): 2.520e-03\n",
      "Epoch 84300, Train loss: 5.677e+03, Test loss: 7.105e+03, MSE(e): 4.651e-04, MSE(pi1): 7.972e-02, MSE(pi2): 3.176e-04, MSE(pi3): 2.286e-03\n",
      "Epoch 84400, Train loss: 5.172e+03, Test loss: 5.779e+03, MSE(e): 4.133e-04, MSE(pi1): 7.784e-02, MSE(pi2): 2.210e-04, MSE(pi3): 2.608e-03\n",
      "Epoch 84500, Train loss: 5.394e+03, Test loss: 5.832e+03, MSE(e): 4.365e-04, MSE(pi1): 7.910e-02, MSE(pi2): 2.632e-04, MSE(pi3): 2.380e-03\n",
      "Epoch 84600, Train loss: 4.657e+03, Test loss: 5.373e+03, MSE(e): 3.645e-04, MSE(pi1): 7.794e-02, MSE(pi2): 2.859e-04, MSE(pi3): 2.327e-03\n",
      "Epoch 84700, Train loss: 4.603e+03, Test loss: 5.702e+03, MSE(e): 3.573e-04, MSE(pi1): 7.705e-02, MSE(pi2): 2.320e-04, MSE(pi3): 2.586e-03\n",
      "Epoch 84800, Train loss: 5.348e+03, Test loss: 7.373e+03, MSE(e): 4.301e-04, MSE(pi1): 8.036e-02, MSE(pi2): 2.339e-04, MSE(pi3): 2.430e-03\n",
      "Epoch 84900, Train loss: 4.967e+03, Test loss: 5.769e+03, MSE(e): 3.939e-04, MSE(pi1): 7.865e-02, MSE(pi2): 2.370e-04, MSE(pi3): 2.407e-03\n",
      "Epoch 85000, Train loss: 4.845e+03, Test loss: 5.325e+03, MSE(e): 3.822e-04, MSE(pi1): 7.817e-02, MSE(pi2): 2.719e-04, MSE(pi3): 2.413e-03\n",
      "Epoch 85100, Train loss: 4.721e+03, Test loss: 5.977e+03, MSE(e): 3.700e-04, MSE(pi1): 7.708e-02, MSE(pi2): 2.615e-04, MSE(pi3): 2.501e-03\n",
      "Epoch 85200, Train loss: 8.180e+03, Test loss: 6.017e+03, MSE(e): 7.130e-04, MSE(pi1): 8.144e-02, MSE(pi2): 3.344e-04, MSE(pi3): 2.349e-03\n",
      "Epoch 85300, Train loss: 4.560e+03, Test loss: 5.334e+03, MSE(e): 3.540e-04, MSE(pi1): 7.858e-02, MSE(pi2): 2.604e-04, MSE(pi3): 2.339e-03\n",
      "Epoch 85400, Train loss: 4.775e+03, Test loss: 5.843e+03, MSE(e): 3.745e-04, MSE(pi1): 7.955e-02, MSE(pi2): 2.430e-04, MSE(pi3): 2.344e-03\n",
      "Epoch 85500, Train loss: 4.930e+03, Test loss: 6.247e+03, MSE(e): 3.899e-04, MSE(pi1): 7.608e-02, MSE(pi2): 2.265e-04, MSE(pi3): 2.699e-03\n",
      "Epoch 85600, Train loss: 4.777e+03, Test loss: 5.313e+03, MSE(e): 3.752e-04, MSE(pi1): 7.749e-02, MSE(pi2): 2.592e-04, MSE(pi3): 2.496e-03\n",
      "Epoch 85700, Train loss: 4.691e+03, Test loss: 5.245e+03, MSE(e): 3.669e-04, MSE(pi1): 7.844e-02, MSE(pi2): 2.481e-04, MSE(pi3): 2.380e-03\n",
      "Epoch 85800, Train loss: 7.443e+03, Test loss: 6.527e+03, MSE(e): 6.390e-04, MSE(pi1): 7.962e-02, MSE(pi2): 2.871e-04, MSE(pi3): 2.568e-03\n",
      "Epoch 85900, Train loss: 4.625e+03, Test loss: 5.117e+03, MSE(e): 3.598e-04, MSE(pi1): 7.815e-02, MSE(pi2): 2.546e-04, MSE(pi3): 2.449e-03\n",
      "Epoch 86000, Train loss: 5.431e+03, Test loss: 6.156e+03, MSE(e): 4.399e-04, MSE(pi1): 7.668e-02, MSE(pi2): 2.402e-04, MSE(pi3): 2.647e-03\n",
      "Epoch 86100, Train loss: 4.611e+03, Test loss: 5.212e+03, MSE(e): 3.592e-04, MSE(pi1): 7.865e-02, MSE(pi2): 2.706e-04, MSE(pi3): 2.315e-03\n",
      "Epoch 86200, Train loss: 5.224e+03, Test loss: 6.055e+03, MSE(e): 4.178e-04, MSE(pi1): 7.834e-02, MSE(pi2): 2.609e-04, MSE(pi3): 2.615e-03\n",
      "Epoch 86300, Train loss: 5.372e+03, Test loss: 6.024e+03, MSE(e): 4.340e-04, MSE(pi1): 7.571e-02, MSE(pi2): 2.392e-04, MSE(pi3): 2.746e-03\n",
      "Epoch 86400, Train loss: 5.175e+03, Test loss: 5.772e+03, MSE(e): 4.140e-04, MSE(pi1): 8.024e-02, MSE(pi2): 2.580e-04, MSE(pi3): 2.325e-03\n",
      "Epoch 86500, Train loss: 5.328e+03, Test loss: 5.758e+03, MSE(e): 4.290e-04, MSE(pi1): 7.769e-02, MSE(pi2): 2.246e-04, MSE(pi3): 2.612e-03\n",
      "Epoch 86600, Train loss: 4.869e+03, Test loss: 6.147e+03, MSE(e): 3.826e-04, MSE(pi1): 7.729e-02, MSE(pi2): 2.532e-04, MSE(pi3): 2.702e-03\n",
      "Epoch 86700, Train loss: 4.628e+03, Test loss: 5.836e+03, MSE(e): 3.599e-04, MSE(pi1): 7.718e-02, MSE(pi2): 2.516e-04, MSE(pi3): 2.563e-03\n",
      "Epoch 86800, Train loss: 4.545e+03, Test loss: 5.376e+03, MSE(e): 3.521e-04, MSE(pi1): 7.700e-02, MSE(pi2): 2.389e-04, MSE(pi3): 2.542e-03\n",
      "Epoch 86900, Train loss: 4.602e+03, Test loss: 5.330e+03, MSE(e): 3.581e-04, MSE(pi1): 7.797e-02, MSE(pi2): 2.403e-04, MSE(pi3): 2.409e-03\n",
      "Epoch 87000, Train loss: 4.623e+03, Test loss: 5.371e+03, MSE(e): 3.598e-04, MSE(pi1): 7.902e-02, MSE(pi2): 2.355e-04, MSE(pi3): 2.343e-03\n",
      "Epoch 87100, Train loss: 4.666e+03, Test loss: 5.654e+03, MSE(e): 3.643e-04, MSE(pi1): 7.727e-02, MSE(pi2): 2.319e-04, MSE(pi3): 2.503e-03\n",
      "Epoch 87200, Train loss: 4.690e+03, Test loss: 5.691e+03, MSE(e): 3.670e-04, MSE(pi1): 7.915e-02, MSE(pi2): 2.752e-04, MSE(pi3): 2.282e-03\n",
      "Epoch 87300, Train loss: 4.979e+03, Test loss: 5.836e+03, MSE(e): 3.963e-04, MSE(pi1): 7.776e-02, MSE(pi2): 2.864e-04, MSE(pi3): 2.383e-03\n",
      "Epoch 87400, Train loss: 4.782e+03, Test loss: 5.895e+03, MSE(e): 3.755e-04, MSE(pi1): 7.927e-02, MSE(pi2): 2.474e-04, MSE(pi3): 2.333e-03\n",
      "Epoch 87500, Train loss: 5.042e+03, Test loss: 6.477e+03, MSE(e): 4.018e-04, MSE(pi1): 7.719e-02, MSE(pi2): 2.260e-04, MSE(pi3): 2.522e-03\n",
      "Epoch 87600, Train loss: 5.363e+03, Test loss: 5.984e+03, MSE(e): 4.332e-04, MSE(pi1): 7.980e-02, MSE(pi2): 3.021e-04, MSE(pi3): 2.331e-03\n",
      "Epoch 87700, Train loss: 4.696e+03, Test loss: 5.799e+03, MSE(e): 3.672e-04, MSE(pi1): 7.694e-02, MSE(pi2): 2.215e-04, MSE(pi3): 2.541e-03\n",
      "Epoch 87800, Train loss: 5.041e+03, Test loss: 6.782e+03, MSE(e): 4.014e-04, MSE(pi1): 7.814e-02, MSE(pi2): 2.229e-04, MSE(pi3): 2.453e-03\n",
      "Epoch 87900, Train loss: 5.499e+03, Test loss: 6.485e+03, MSE(e): 4.462e-04, MSE(pi1): 7.540e-02, MSE(pi2): 2.420e-04, MSE(pi3): 2.823e-03\n",
      "Epoch 88000, Train loss: 4.785e+03, Test loss: 5.798e+03, MSE(e): 3.749e-04, MSE(pi1): 7.754e-02, MSE(pi2): 2.414e-04, MSE(pi3): 2.599e-03\n",
      "Epoch 88100, Train loss: 5.085e+03, Test loss: 6.382e+03, MSE(e): 4.062e-04, MSE(pi1): 7.777e-02, MSE(pi2): 2.334e-04, MSE(pi3): 2.454e-03\n",
      "Epoch 88200, Train loss: 4.871e+03, Test loss: 5.777e+03, MSE(e): 3.839e-04, MSE(pi1): 7.702e-02, MSE(pi2): 2.182e-04, MSE(pi3): 2.622e-03\n",
      "Epoch 88300, Train loss: 4.619e+03, Test loss: 5.398e+03, MSE(e): 3.601e-04, MSE(pi1): 7.850e-02, MSE(pi2): 2.572e-04, MSE(pi3): 2.328e-03\n",
      "Epoch 88400, Train loss: 4.493e+03, Test loss: 5.219e+03, MSE(e): 3.473e-04, MSE(pi1): 7.798e-02, MSE(pi2): 2.438e-04, MSE(pi3): 2.402e-03\n",
      "Epoch 88500, Train loss: 4.865e+03, Test loss: 5.516e+03, MSE(e): 3.844e-04, MSE(pi1): 7.873e-02, MSE(pi2): 2.650e-04, MSE(pi3): 2.331e-03\n",
      "Epoch 88600, Train loss: 4.669e+03, Test loss: 5.475e+03, MSE(e): 3.649e-04, MSE(pi1): 7.706e-02, MSE(pi2): 2.642e-04, MSE(pi3): 2.499e-03\n",
      "Epoch 88700, Train loss: 5.336e+03, Test loss: 6.041e+03, MSE(e): 4.298e-04, MSE(pi1): 7.890e-02, MSE(pi2): 2.264e-04, MSE(pi3): 2.491e-03\n",
      "Epoch 88800, Train loss: 4.962e+03, Test loss: 5.463e+03, MSE(e): 3.933e-04, MSE(pi1): 7.743e-02, MSE(pi2): 2.235e-04, MSE(pi3): 2.543e-03\n",
      "Epoch 88900, Train loss: 5.678e+03, Test loss: 6.594e+03, MSE(e): 4.635e-04, MSE(pi1): 7.735e-02, MSE(pi2): 2.299e-04, MSE(pi3): 2.688e-03\n",
      "Epoch 89000, Train loss: 4.765e+03, Test loss: 5.254e+03, MSE(e): 3.754e-04, MSE(pi1): 7.638e-02, MSE(pi2): 2.760e-04, MSE(pi3): 2.468e-03\n",
      "Epoch 89100, Train loss: 4.612e+03, Test loss: 5.407e+03, MSE(e): 3.593e-04, MSE(pi1): 7.802e-02, MSE(pi2): 2.397e-04, MSE(pi3): 2.378e-03\n",
      "Epoch 89200, Train loss: 4.897e+03, Test loss: 6.000e+03, MSE(e): 3.867e-04, MSE(pi1): 7.865e-02, MSE(pi2): 2.305e-04, MSE(pi3): 2.427e-03\n",
      "Epoch 89300, Train loss: 4.998e+03, Test loss: 5.859e+03, MSE(e): 3.970e-04, MSE(pi1): 7.698e-02, MSE(pi2): 2.588e-04, MSE(pi3): 2.580e-03\n",
      "Epoch 89400, Train loss: 5.297e+03, Test loss: 6.593e+03, MSE(e): 4.258e-04, MSE(pi1): 7.656e-02, MSE(pi2): 2.230e-04, MSE(pi3): 2.730e-03\n",
      "Epoch 89500, Train loss: 4.617e+03, Test loss: 5.237e+03, MSE(e): 3.599e-04, MSE(pi1): 7.795e-02, MSE(pi2): 2.660e-04, MSE(pi3): 2.384e-03\n",
      "Epoch 89600, Train loss: 5.155e+03, Test loss: 5.648e+03, MSE(e): 4.135e-04, MSE(pi1): 7.809e-02, MSE(pi2): 2.752e-04, MSE(pi3): 2.383e-03\n",
      "Epoch 89700, Train loss: 4.901e+03, Test loss: 6.143e+03, MSE(e): 3.876e-04, MSE(pi1): 7.853e-02, MSE(pi2): 2.342e-04, MSE(pi3): 2.393e-03\n",
      "Epoch 89800, Train loss: 5.951e+03, Test loss: 7.445e+03, MSE(e): 4.914e-04, MSE(pi1): 7.984e-02, MSE(pi2): 2.611e-04, MSE(pi3): 2.390e-03\n",
      "Epoch 89900, Train loss: 5.355e+03, Test loss: 7.564e+03, MSE(e): 4.327e-04, MSE(pi1): 7.732e-02, MSE(pi2): 2.251e-04, MSE(pi3): 2.547e-03\n",
      "Epoch 90000, Train loss: 5.143e+03, Test loss: 7.338e+03, MSE(e): 4.112e-04, MSE(pi1): 8.008e-02, MSE(pi2): 2.908e-04, MSE(pi3): 2.296e-03\n",
      "Epoch 90100, Train loss: 4.750e+03, Test loss: 5.509e+03, MSE(e): 3.730e-04, MSE(pi1): 7.902e-02, MSE(pi2): 2.653e-04, MSE(pi3): 2.298e-03\n",
      "Epoch 90200, Train loss: 4.693e+03, Test loss: 5.592e+03, MSE(e): 3.674e-04, MSE(pi1): 7.852e-02, MSE(pi2): 2.514e-04, MSE(pi3): 2.341e-03\n",
      "Epoch 90300, Train loss: 5.044e+03, Test loss: 5.986e+03, MSE(e): 4.022e-04, MSE(pi1): 7.696e-02, MSE(pi2): 2.378e-04, MSE(pi3): 2.526e-03\n",
      "Epoch 90400, Train loss: 4.870e+03, Test loss: 6.188e+03, MSE(e): 3.847e-04, MSE(pi1): 7.822e-02, MSE(pi2): 2.341e-04, MSE(pi3): 2.397e-03\n",
      "Epoch 90500, Train loss: 5.148e+03, Test loss: 5.863e+03, MSE(e): 4.118e-04, MSE(pi1): 7.815e-02, MSE(pi2): 2.591e-04, MSE(pi3): 2.476e-03\n",
      "Epoch 90600, Train loss: 5.755e+03, Test loss: 6.481e+03, MSE(e): 4.724e-04, MSE(pi1): 8.022e-02, MSE(pi2): 2.818e-04, MSE(pi3): 2.287e-03\n",
      "Epoch 90700, Train loss: 4.704e+03, Test loss: 5.506e+03, MSE(e): 3.677e-04, MSE(pi1): 7.676e-02, MSE(pi2): 2.209e-04, MSE(pi3): 2.594e-03\n",
      "Epoch 90800, Train loss: 4.734e+03, Test loss: 5.346e+03, MSE(e): 3.700e-04, MSE(pi1): 7.785e-02, MSE(pi2): 2.446e-04, MSE(pi3): 2.550e-03\n",
      "Epoch 90900, Train loss: 4.569e+03, Test loss: 5.493e+03, MSE(e): 3.550e-04, MSE(pi1): 7.678e-02, MSE(pi2): 2.540e-04, MSE(pi3): 2.511e-03\n",
      "Epoch 91000, Train loss: 4.691e+03, Test loss: 5.129e+03, MSE(e): 3.679e-04, MSE(pi1): 7.653e-02, MSE(pi2): 2.688e-04, MSE(pi3): 2.463e-03\n",
      "Epoch 91100, Train loss: 4.602e+03, Test loss: 5.525e+03, MSE(e): 3.572e-04, MSE(pi1): 7.699e-02, MSE(pi2): 2.308e-04, MSE(pi3): 2.596e-03\n",
      "Epoch 91200, Train loss: 5.524e+03, Test loss: 5.915e+03, MSE(e): 4.495e-04, MSE(pi1): 7.925e-02, MSE(pi2): 2.532e-04, MSE(pi3): 2.363e-03\n",
      "Epoch 91300, Train loss: 4.720e+03, Test loss: 5.283e+03, MSE(e): 3.698e-04, MSE(pi1): 7.817e-02, MSE(pi2): 2.540e-04, MSE(pi3): 2.404e-03\n",
      "Epoch 91400, Train loss: 4.584e+03, Test loss: 5.382e+03, MSE(e): 3.563e-04, MSE(pi1): 7.881e-02, MSE(pi2): 2.502e-04, MSE(pi3): 2.327e-03\n",
      "Epoch 91500, Train loss: 4.672e+03, Test loss: 5.767e+03, MSE(e): 3.659e-04, MSE(pi1): 7.711e-02, MSE(pi2): 2.680e-04, MSE(pi3): 2.412e-03\n",
      "Epoch 91600, Train loss: 4.815e+03, Test loss: 5.762e+03, MSE(e): 3.807e-04, MSE(pi1): 7.614e-02, MSE(pi2): 2.778e-04, MSE(pi3): 2.465e-03\n",
      "Epoch 91700, Train loss: 4.753e+03, Test loss: 5.400e+03, MSE(e): 3.728e-04, MSE(pi1): 7.792e-02, MSE(pi2): 2.212e-04, MSE(pi3): 2.450e-03\n",
      "Epoch 91800, Train loss: 4.981e+03, Test loss: 5.538e+03, MSE(e): 3.948e-04, MSE(pi1): 7.647e-02, MSE(pi2): 2.174e-04, MSE(pi3): 2.682e-03\n",
      "Epoch 91900, Train loss: 5.714e+03, Test loss: 7.104e+03, MSE(e): 4.688e-04, MSE(pi1): 7.696e-02, MSE(pi2): 2.398e-04, MSE(pi3): 2.569e-03\n",
      "Epoch 92000, Train loss: 4.572e+03, Test loss: 5.330e+03, MSE(e): 3.554e-04, MSE(pi1): 7.810e-02, MSE(pi2): 2.409e-04, MSE(pi3): 2.366e-03\n",
      "Epoch 92100, Train loss: 5.263e+03, Test loss: 5.957e+03, MSE(e): 4.251e-04, MSE(pi1): 7.838e-02, MSE(pi2): 3.144e-04, MSE(pi3): 2.282e-03\n",
      "Epoch 92200, Train loss: 4.701e+03, Test loss: 5.693e+03, MSE(e): 3.670e-04, MSE(pi1): 7.674e-02, MSE(pi2): 2.427e-04, MSE(pi3): 2.627e-03\n",
      "Epoch 92300, Train loss: 4.523e+03, Test loss: 4.995e+03, MSE(e): 3.508e-04, MSE(pi1): 7.769e-02, MSE(pi2): 2.532e-04, MSE(pi3): 2.377e-03\n",
      "Epoch 92400, Train loss: 5.408e+03, Test loss: 7.163e+03, MSE(e): 4.376e-04, MSE(pi1): 8.023e-02, MSE(pi2): 3.014e-04, MSE(pi3): 2.295e-03\n",
      "Epoch 92500, Train loss: 4.680e+03, Test loss: 5.078e+03, MSE(e): 3.654e-04, MSE(pi1): 7.726e-02, MSE(pi2): 2.377e-04, MSE(pi3): 2.530e-03\n",
      "Epoch 92600, Train loss: 4.693e+03, Test loss: 5.185e+03, MSE(e): 3.673e-04, MSE(pi1): 7.690e-02, MSE(pi2): 2.259e-04, MSE(pi3): 2.507e-03\n",
      "Epoch 92700, Train loss: 5.047e+03, Test loss: 5.471e+03, MSE(e): 4.023e-04, MSE(pi1): 7.703e-02, MSE(pi2): 2.414e-04, MSE(pi3): 2.535e-03\n",
      "Epoch 92800, Train loss: 4.760e+03, Test loss: 5.327e+03, MSE(e): 3.744e-04, MSE(pi1): 7.773e-02, MSE(pi2): 2.389e-04, MSE(pi3): 2.385e-03\n",
      "Epoch 92900, Train loss: 4.765e+03, Test loss: 5.494e+03, MSE(e): 3.750e-04, MSE(pi1): 7.779e-02, MSE(pi2): 2.639e-04, MSE(pi3): 2.367e-03\n",
      "Epoch 93000, Train loss: 4.695e+03, Test loss: 5.399e+03, MSE(e): 3.678e-04, MSE(pi1): 7.712e-02, MSE(pi2): 2.699e-04, MSE(pi3): 2.460e-03\n",
      "Epoch 93100, Train loss: 4.611e+03, Test loss: 5.390e+03, MSE(e): 3.594e-04, MSE(pi1): 7.856e-02, MSE(pi2): 2.516e-04, MSE(pi3): 2.317e-03\n",
      "Epoch 93200, Train loss: 5.645e+03, Test loss: 6.542e+03, MSE(e): 4.602e-04, MSE(pi1): 7.726e-02, MSE(pi2): 2.277e-04, MSE(pi3): 2.704e-03\n",
      "Epoch 93300, Train loss: 4.853e+03, Test loss: 4.776e+03, MSE(e): 3.831e-04, MSE(pi1): 7.841e-02, MSE(pi2): 2.647e-04, MSE(pi3): 2.375e-03\n",
      "Epoch 93400, Train loss: 5.263e+03, Test loss: 6.947e+03, MSE(e): 4.237e-04, MSE(pi1): 7.736e-02, MSE(pi2): 2.302e-04, MSE(pi3): 2.521e-03\n",
      "Epoch 93500, Train loss: 5.804e+03, Test loss: 5.348e+03, MSE(e): 4.767e-04, MSE(pi1): 7.841e-02, MSE(pi2): 2.794e-04, MSE(pi3): 2.521e-03\n",
      "Epoch 93600, Train loss: 5.883e+03, Test loss: 5.294e+03, MSE(e): 4.850e-04, MSE(pi1): 7.933e-02, MSE(pi2): 2.738e-04, MSE(pi3): 2.387e-03\n",
      "Epoch 93700, Train loss: 4.550e+03, Test loss: 4.972e+03, MSE(e): 3.540e-04, MSE(pi1): 7.748e-02, MSE(pi2): 2.695e-04, MSE(pi3): 2.348e-03\n",
      "Epoch 93800, Train loss: 4.810e+03, Test loss: 5.608e+03, MSE(e): 3.790e-04, MSE(pi1): 7.881e-02, MSE(pi2): 2.524e-04, MSE(pi3): 2.321e-03\n",
      "Epoch 93900, Train loss: 5.128e+03, Test loss: 5.419e+03, MSE(e): 4.102e-04, MSE(pi1): 7.705e-02, MSE(pi2): 2.210e-04, MSE(pi3): 2.552e-03\n",
      "Epoch 94000, Train loss: 5.007e+03, Test loss: 6.306e+03, MSE(e): 3.987e-04, MSE(pi1): 7.737e-02, MSE(pi2): 2.273e-04, MSE(pi3): 2.461e-03\n",
      "Epoch 94100, Train loss: 5.944e+03, Test loss: 7.983e+03, MSE(e): 4.922e-04, MSE(pi1): 7.881e-02, MSE(pi2): 3.210e-04, MSE(pi3): 2.337e-03\n",
      "Epoch 94200, Train loss: 4.981e+03, Test loss: 5.988e+03, MSE(e): 3.964e-04, MSE(pi1): 7.748e-02, MSE(pi2): 2.419e-04, MSE(pi3): 2.418e-03\n",
      "Epoch 94300, Train loss: 4.721e+03, Test loss: 5.533e+03, MSE(e): 3.702e-04, MSE(pi1): 7.844e-02, MSE(pi2): 2.506e-04, MSE(pi3): 2.338e-03\n",
      "Epoch 94400, Train loss: 4.723e+03, Test loss: 5.711e+03, MSE(e): 3.696e-04, MSE(pi1): 7.580e-02, MSE(pi2): 2.250e-04, MSE(pi3): 2.686e-03\n",
      "Epoch 94500, Train loss: 4.579e+03, Test loss: 5.155e+03, MSE(e): 3.566e-04, MSE(pi1): 7.696e-02, MSE(pi2): 2.618e-04, MSE(pi3): 2.433e-03\n",
      "Epoch 94600, Train loss: 5.064e+03, Test loss: 6.648e+03, MSE(e): 4.045e-04, MSE(pi1): 7.597e-02, MSE(pi2): 2.162e-04, MSE(pi3): 2.588e-03\n",
      "Epoch 94700, Train loss: 6.141e+03, Test loss: 5.527e+03, MSE(e): 5.103e-04, MSE(pi1): 7.912e-02, MSE(pi2): 2.970e-04, MSE(pi3): 2.462e-03\n",
      "Epoch 94800, Train loss: 4.477e+03, Test loss: 5.198e+03, MSE(e): 3.465e-04, MSE(pi1): 7.733e-02, MSE(pi2): 2.305e-04, MSE(pi3): 2.390e-03\n",
      "Epoch 94900, Train loss: 5.512e+03, Test loss: 5.401e+03, MSE(e): 4.481e-04, MSE(pi1): 7.987e-02, MSE(pi2): 2.661e-04, MSE(pi3): 2.325e-03\n",
      "Epoch 95000, Train loss: 4.591e+03, Test loss: 5.553e+03, MSE(e): 3.584e-04, MSE(pi1): 7.627e-02, MSE(pi2): 2.565e-04, MSE(pi3): 2.437e-03\n",
      "Epoch 95100, Train loss: 4.597e+03, Test loss: 4.923e+03, MSE(e): 3.581e-04, MSE(pi1): 7.750e-02, MSE(pi2): 2.573e-04, MSE(pi3): 2.408e-03\n",
      "Epoch 95200, Train loss: 4.841e+03, Test loss: 6.815e+03, MSE(e): 3.830e-04, MSE(pi1): 7.647e-02, MSE(pi2): 2.292e-04, MSE(pi3): 2.461e-03\n",
      "Epoch 95300, Train loss: 5.208e+03, Test loss: 7.516e+03, MSE(e): 4.178e-04, MSE(pi1): 7.855e-02, MSE(pi2): 2.308e-04, MSE(pi3): 2.444e-03\n",
      "Epoch 95400, Train loss: 5.301e+03, Test loss: 6.721e+03, MSE(e): 4.264e-04, MSE(pi1): 7.567e-02, MSE(pi2): 2.235e-04, MSE(pi3): 2.807e-03\n",
      "Epoch 95500, Train loss: 4.631e+03, Test loss: 5.799e+03, MSE(e): 3.620e-04, MSE(pi1): 7.698e-02, MSE(pi2): 2.266e-04, MSE(pi3): 2.408e-03\n",
      "Epoch 95600, Train loss: 4.488e+03, Test loss: 5.357e+03, MSE(e): 3.477e-04, MSE(pi1): 7.749e-02, MSE(pi2): 2.380e-04, MSE(pi3): 2.359e-03\n",
      "Epoch 95700, Train loss: 5.089e+03, Test loss: 5.566e+03, MSE(e): 4.058e-04, MSE(pi1): 7.602e-02, MSE(pi2): 2.328e-04, MSE(pi3): 2.706e-03\n",
      "Epoch 95800, Train loss: 5.503e+03, Test loss: 5.503e+03, MSE(e): 4.499e-04, MSE(pi1): 7.541e-02, MSE(pi2): 2.882e-04, MSE(pi3): 2.501e-03\n",
      "Epoch 95900, Train loss: 4.528e+03, Test loss: 5.311e+03, MSE(e): 3.514e-04, MSE(pi1): 7.631e-02, MSE(pi2): 2.536e-04, MSE(pi3): 2.513e-03\n",
      "Epoch 96000, Train loss: 4.721e+03, Test loss: 5.078e+03, MSE(e): 3.702e-04, MSE(pi1): 7.660e-02, MSE(pi2): 2.153e-04, MSE(pi3): 2.533e-03\n",
      "Epoch 96100, Train loss: 5.455e+03, Test loss: 6.168e+03, MSE(e): 4.424e-04, MSE(pi1): 7.784e-02, MSE(pi2): 2.260e-04, MSE(pi3): 2.530e-03\n",
      "Epoch 96200, Train loss: 6.996e+03, Test loss: 6.973e+03, MSE(e): 5.954e-04, MSE(pi1): 8.067e-02, MSE(pi2): 3.221e-04, MSE(pi3): 2.340e-03\n",
      "Epoch 96300, Train loss: 5.066e+03, Test loss: 6.059e+03, MSE(e): 4.041e-04, MSE(pi1): 7.929e-02, MSE(pi2): 2.531e-04, MSE(pi3): 2.317e-03\n",
      "Epoch 96400, Train loss: 5.347e+03, Test loss: 5.426e+03, MSE(e): 4.312e-04, MSE(pi1): 7.760e-02, MSE(pi2): 2.575e-04, MSE(pi3): 2.590e-03\n",
      "Epoch 96500, Train loss: 5.009e+03, Test loss: 5.332e+03, MSE(e): 3.983e-04, MSE(pi1): 7.650e-02, MSE(pi2): 2.140e-04, MSE(pi3): 2.606e-03\n",
      "Epoch 96600, Train loss: 4.865e+03, Test loss: 4.875e+03, MSE(e): 3.851e-04, MSE(pi1): 7.801e-02, MSE(pi2): 2.586e-04, MSE(pi3): 2.344e-03\n",
      "Epoch 96700, Train loss: 4.611e+03, Test loss: 5.127e+03, MSE(e): 3.597e-04, MSE(pi1): 7.745e-02, MSE(pi2): 2.509e-04, MSE(pi3): 2.399e-03\n",
      "Epoch 96800, Train loss: 4.739e+03, Test loss: 5.340e+03, MSE(e): 3.718e-04, MSE(pi1): 7.707e-02, MSE(pi2): 2.389e-04, MSE(pi3): 2.501e-03\n",
      "Epoch 96900, Train loss: 4.480e+03, Test loss: 4.954e+03, MSE(e): 3.464e-04, MSE(pi1): 7.713e-02, MSE(pi2): 2.271e-04, MSE(pi3): 2.437e-03\n",
      "Epoch 97000, Train loss: 7.281e+03, Test loss: 6.402e+03, MSE(e): 6.246e-04, MSE(pi1): 8.029e-02, MSE(pi2): 3.072e-04, MSE(pi3): 2.319e-03\n",
      "Epoch 97100, Train loss: 5.130e+03, Test loss: 5.481e+03, MSE(e): 4.115e-04, MSE(pi1): 7.769e-02, MSE(pi2): 2.565e-04, MSE(pi3): 2.379e-03\n",
      "Epoch 97200, Train loss: 4.935e+03, Test loss: 4.813e+03, MSE(e): 3.920e-04, MSE(pi1): 7.721e-02, MSE(pi2): 2.390e-04, MSE(pi3): 2.426e-03\n",
      "Epoch 97300, Train loss: 1.099e+04, Test loss: 7.784e+03, MSE(e): 9.922e-04, MSE(pi1): 7.923e-02, MSE(pi2): 4.087e-04, MSE(pi3): 2.769e-03\n",
      "Epoch 97400, Train loss: 4.824e+03, Test loss: 5.987e+03, MSE(e): 3.814e-04, MSE(pi1): 7.575e-02, MSE(pi2): 2.676e-04, MSE(pi3): 2.517e-03\n",
      "Epoch 97500, Train loss: 4.468e+03, Test loss: 5.217e+03, MSE(e): 3.458e-04, MSE(pi1): 7.701e-02, MSE(pi2): 2.359e-04, MSE(pi3): 2.399e-03\n",
      "Epoch 97600, Train loss: 4.604e+03, Test loss: 5.583e+03, MSE(e): 3.591e-04, MSE(pi1): 7.784e-02, MSE(pi2): 2.428e-04, MSE(pi3): 2.345e-03\n",
      "Epoch 97700, Train loss: 5.763e+03, Test loss: 7.437e+03, MSE(e): 4.737e-04, MSE(pi1): 7.584e-02, MSE(pi2): 2.428e-04, MSE(pi3): 2.672e-03\n",
      "Epoch 97800, Train loss: 5.069e+03, Test loss: 6.173e+03, MSE(e): 4.047e-04, MSE(pi1): 7.743e-02, MSE(pi2): 2.241e-04, MSE(pi3): 2.471e-03\n",
      "Epoch 97900, Train loss: 5.395e+03, Test loss: 6.517e+03, MSE(e): 4.378e-04, MSE(pi1): 7.688e-02, MSE(pi2): 2.370e-04, MSE(pi3): 2.481e-03\n",
      "Epoch 98000, Train loss: 5.030e+03, Test loss: 6.294e+03, MSE(e): 4.017e-04, MSE(pi1): 7.686e-02, MSE(pi2): 2.323e-04, MSE(pi3): 2.448e-03\n",
      "Epoch 98100, Train loss: 4.785e+03, Test loss: 5.048e+03, MSE(e): 3.776e-04, MSE(pi1): 7.623e-02, MSE(pi2): 2.655e-04, MSE(pi3): 2.456e-03\n",
      "Epoch 98200, Train loss: 4.468e+03, Test loss: 4.731e+03, MSE(e): 3.454e-04, MSE(pi1): 7.686e-02, MSE(pi2): 2.256e-04, MSE(pi3): 2.455e-03\n",
      "Epoch 98300, Train loss: 5.153e+03, Test loss: 4.975e+03, MSE(e): 4.133e-04, MSE(pi1): 7.931e-02, MSE(pi2): 2.872e-04, MSE(pi3): 2.270e-03\n",
      "Epoch 98400, Train loss: 4.860e+03, Test loss: 5.494e+03, MSE(e): 3.849e-04, MSE(pi1): 7.776e-02, MSE(pi2): 2.769e-04, MSE(pi3): 2.331e-03\n",
      "Epoch 98500, Train loss: 4.825e+03, Test loss: 5.273e+03, MSE(e): 3.804e-04, MSE(pi1): 7.627e-02, MSE(pi2): 2.101e-04, MSE(pi3): 2.580e-03\n",
      "Epoch 98600, Train loss: 5.243e+03, Test loss: 7.256e+03, MSE(e): 4.227e-04, MSE(pi1): 7.952e-02, MSE(pi2): 2.924e-04, MSE(pi3): 2.205e-03\n",
      "Epoch 98700, Train loss: 5.488e+03, Test loss: 5.774e+03, MSE(e): 4.469e-04, MSE(pi1): 7.731e-02, MSE(pi2): 2.466e-04, MSE(pi3): 2.456e-03\n",
      "Epoch 98800, Train loss: 4.833e+03, Test loss: 5.832e+03, MSE(e): 3.827e-04, MSE(pi1): 7.575e-02, MSE(pi2): 2.577e-04, MSE(pi3): 2.486e-03\n",
      "Epoch 98900, Train loss: 5.097e+03, Test loss: 5.004e+03, MSE(e): 4.086e-04, MSE(pi1): 7.683e-02, MSE(pi2): 2.508e-04, MSE(pi3): 2.424e-03\n",
      "Epoch 99000, Train loss: 4.951e+03, Test loss: 5.661e+03, MSE(e): 3.925e-04, MSE(pi1): 7.506e-02, MSE(pi2): 2.230e-04, MSE(pi3): 2.753e-03\n",
      "Epoch 99100, Train loss: 4.419e+03, Test loss: 4.797e+03, MSE(e): 3.404e-04, MSE(pi1): 7.693e-02, MSE(pi2): 2.306e-04, MSE(pi3): 2.457e-03\n",
      "Epoch 99200, Train loss: 5.350e+03, Test loss: 5.328e+03, MSE(e): 4.334e-04, MSE(pi1): 7.715e-02, MSE(pi2): 2.418e-04, MSE(pi3): 2.444e-03\n",
      "Epoch 99300, Train loss: 4.651e+03, Test loss: 4.749e+03, MSE(e): 3.637e-04, MSE(pi1): 7.740e-02, MSE(pi2): 2.506e-04, MSE(pi3): 2.399e-03\n",
      "Epoch 99400, Train loss: 6.389e+03, Test loss: 8.801e+03, MSE(e): 5.360e-04, MSE(pi1): 7.723e-02, MSE(pi2): 2.604e-04, MSE(pi3): 2.565e-03\n",
      "Epoch 99500, Train loss: 4.982e+03, Test loss: 6.802e+03, MSE(e): 3.965e-04, MSE(pi1): 7.801e-02, MSE(pi2): 2.345e-04, MSE(pi3): 2.373e-03\n",
      "Epoch 99600, Train loss: 4.883e+03, Test loss: 5.901e+03, MSE(e): 3.878e-04, MSE(pi1): 7.569e-02, MSE(pi2): 2.557e-04, MSE(pi3): 2.477e-03\n",
      "Epoch 99700, Train loss: 4.519e+03, Test loss: 4.702e+03, MSE(e): 3.508e-04, MSE(pi1): 7.710e-02, MSE(pi2): 2.395e-04, MSE(pi3): 2.397e-03\n",
      "Epoch 99800, Train loss: 4.812e+03, Test loss: 6.325e+03, MSE(e): 3.797e-04, MSE(pi1): 7.694e-02, MSE(pi2): 2.194e-04, MSE(pi3): 2.457e-03\n",
      "Epoch 99900, Train loss: 4.782e+03, Test loss: 6.320e+03, MSE(e): 3.772e-04, MSE(pi1): 7.764e-02, MSE(pi2): 2.441e-04, MSE(pi3): 2.335e-03\n",
      "Epoch 100000, Train loss: 5.286e+03, Test loss: 6.057e+03, MSE(e): 4.272e-04, MSE(pi1): 7.705e-02, MSE(pi2): 2.522e-04, MSE(pi3): 2.436e-03\n",
      "Epoch 100100, Train loss: 4.694e+03, Test loss: 5.898e+03, MSE(e): 3.687e-04, MSE(pi1): 7.614e-02, MSE(pi2): 2.189e-04, MSE(pi3): 2.448e-03\n",
      "Epoch 100200, Train loss: 5.163e+03, Test loss: 5.938e+03, MSE(e): 4.148e-04, MSE(pi1): 7.805e-02, MSE(pi2): 2.478e-04, MSE(pi3): 2.346e-03\n",
      "Epoch 100300, Train loss: 4.857e+03, Test loss: 5.451e+03, MSE(e): 3.849e-04, MSE(pi1): 7.624e-02, MSE(pi2): 2.268e-04, MSE(pi3): 2.454e-03\n",
      "Epoch 100400, Train loss: 4.552e+03, Test loss: 5.368e+03, MSE(e): 3.549e-04, MSE(pi1): 7.615e-02, MSE(pi2): 2.534e-04, MSE(pi3): 2.421e-03\n",
      "Epoch 100500, Train loss: 4.578e+03, Test loss: 5.625e+03, MSE(e): 3.567e-04, MSE(pi1): 7.715e-02, MSE(pi2): 2.308e-04, MSE(pi3): 2.396e-03\n",
      "Epoch 100600, Train loss: 4.465e+03, Test loss: 4.898e+03, MSE(e): 3.453e-04, MSE(pi1): 7.699e-02, MSE(pi2): 2.303e-04, MSE(pi3): 2.416e-03\n",
      "Epoch 100700, Train loss: 5.029e+03, Test loss: 6.353e+03, MSE(e): 4.017e-04, MSE(pi1): 7.678e-02, MSE(pi2): 2.346e-04, MSE(pi3): 2.436e-03\n",
      "Epoch 100800, Train loss: 4.566e+03, Test loss: 5.078e+03, MSE(e): 3.555e-04, MSE(pi1): 7.691e-02, MSE(pi2): 2.283e-04, MSE(pi3): 2.407e-03\n",
      "Epoch 100900, Train loss: 4.705e+03, Test loss: 5.298e+03, MSE(e): 3.695e-04, MSE(pi1): 7.726e-02, MSE(pi2): 2.656e-04, MSE(pi3): 2.368e-03\n",
      "Epoch 101000, Train loss: 4.654e+03, Test loss: 5.622e+03, MSE(e): 3.639e-04, MSE(pi1): 7.852e-02, MSE(pi2): 2.506e-04, MSE(pi3): 2.292e-03\n",
      "Epoch 101100, Train loss: 5.224e+03, Test loss: 6.271e+03, MSE(e): 4.209e-04, MSE(pi1): 7.734e-02, MSE(pi2): 2.528e-04, MSE(pi3): 2.420e-03\n",
      "Epoch 101200, Train loss: 4.892e+03, Test loss: 5.580e+03, MSE(e): 3.877e-04, MSE(pi1): 7.628e-02, MSE(pi2): 2.148e-04, MSE(pi3): 2.522e-03\n",
      "Epoch 101300, Train loss: 4.742e+03, Test loss: 6.013e+03, MSE(e): 3.723e-04, MSE(pi1): 7.937e-02, MSE(pi2): 2.655e-04, MSE(pi3): 2.246e-03\n",
      "Epoch 101400, Train loss: 4.793e+03, Test loss: 4.975e+03, MSE(e): 3.783e-04, MSE(pi1): 7.631e-02, MSE(pi2): 2.496e-04, MSE(pi3): 2.471e-03\n",
      "Epoch 101500, Train loss: 5.413e+03, Test loss: 6.439e+03, MSE(e): 4.404e-04, MSE(pi1): 7.716e-02, MSE(pi2): 2.508e-04, MSE(pi3): 2.372e-03\n",
      "Epoch 101600, Train loss: 6.010e+03, Test loss: 6.261e+03, MSE(e): 4.972e-04, MSE(pi1): 7.548e-02, MSE(pi2): 2.408e-04, MSE(pi3): 2.823e-03\n",
      "Epoch 101700, Train loss: 4.733e+03, Test loss: 4.777e+03, MSE(e): 3.720e-04, MSE(pi1): 7.701e-02, MSE(pi2): 2.361e-04, MSE(pi3): 2.423e-03\n",
      "Epoch 101800, Train loss: 4.452e+03, Test loss: 4.757e+03, MSE(e): 3.443e-04, MSE(pi1): 7.613e-02, MSE(pi2): 2.397e-04, MSE(pi3): 2.477e-03\n",
      "Epoch 101900, Train loss: 4.709e+03, Test loss: 4.876e+03, MSE(e): 3.698e-04, MSE(pi1): 7.713e-02, MSE(pi2): 2.573e-04, MSE(pi3): 2.400e-03\n",
      "Epoch 102000, Train loss: 5.102e+03, Test loss: 5.914e+03, MSE(e): 4.085e-04, MSE(pi1): 7.870e-02, MSE(pi2): 2.769e-04, MSE(pi3): 2.305e-03\n",
      "Epoch 102100, Train loss: 4.930e+03, Test loss: 5.281e+03, MSE(e): 3.908e-04, MSE(pi1): 7.512e-02, MSE(pi2): 2.193e-04, MSE(pi3): 2.698e-03\n",
      "Epoch 102200, Train loss: 4.786e+03, Test loss: 5.193e+03, MSE(e): 3.776e-04, MSE(pi1): 7.711e-02, MSE(pi2): 2.614e-04, MSE(pi3): 2.384e-03\n",
      "Epoch 102300, Train loss: 5.160e+03, Test loss: 4.836e+03, MSE(e): 4.141e-04, MSE(pi1): 7.780e-02, MSE(pi2): 2.516e-04, MSE(pi3): 2.409e-03\n",
      "Epoch 102400, Train loss: 4.469e+03, Test loss: 5.207e+03, MSE(e): 3.453e-04, MSE(pi1): 7.581e-02, MSE(pi2): 2.270e-04, MSE(pi3): 2.578e-03\n",
      "Epoch 102500, Train loss: 4.807e+03, Test loss: 5.613e+03, MSE(e): 3.786e-04, MSE(pi1): 7.540e-02, MSE(pi2): 2.255e-04, MSE(pi3): 2.670e-03\n",
      "Epoch 102600, Train loss: 4.540e+03, Test loss: 4.719e+03, MSE(e): 3.526e-04, MSE(pi1): 7.645e-02, MSE(pi2): 2.200e-04, MSE(pi3): 2.493e-03\n",
      "Epoch 102700, Train loss: 5.233e+03, Test loss: 6.395e+03, MSE(e): 4.215e-04, MSE(pi1): 7.812e-02, MSE(pi2): 2.644e-04, MSE(pi3): 2.370e-03\n",
      "Epoch 102800, Train loss: 4.616e+03, Test loss: 5.126e+03, MSE(e): 3.608e-04, MSE(pi1): 7.660e-02, MSE(pi2): 2.302e-04, MSE(pi3): 2.424e-03\n",
      "Epoch 102900, Train loss: 4.647e+03, Test loss: 5.103e+03, MSE(e): 3.638e-04, MSE(pi1): 7.736e-02, MSE(pi2): 2.466e-04, MSE(pi3): 2.360e-03\n",
      "Epoch 103000, Train loss: 4.632e+03, Test loss: 5.596e+03, MSE(e): 3.634e-04, MSE(pi1): 7.614e-02, MSE(pi2): 2.796e-04, MSE(pi3): 2.363e-03\n",
      "Epoch 103100, Train loss: 6.230e+03, Test loss: 5.610e+03, MSE(e): 5.208e-04, MSE(pi1): 7.840e-02, MSE(pi2): 2.826e-04, MSE(pi3): 2.381e-03\n",
      "Epoch 103200, Train loss: 5.463e+03, Test loss: 5.971e+03, MSE(e): 4.448e-04, MSE(pi1): 7.763e-02, MSE(pi2): 2.792e-04, MSE(pi3): 2.384e-03\n",
      "Epoch 103300, Train loss: 4.559e+03, Test loss: 5.401e+03, MSE(e): 3.555e-04, MSE(pi1): 7.687e-02, MSE(pi2): 2.410e-04, MSE(pi3): 2.356e-03\n",
      "Epoch 103400, Train loss: 4.825e+03, Test loss: 6.226e+03, MSE(e): 3.809e-04, MSE(pi1): 7.500e-02, MSE(pi2): 2.102e-04, MSE(pi3): 2.661e-03\n",
      "Epoch 103500, Train loss: 4.901e+03, Test loss: 5.095e+03, MSE(e): 3.889e-04, MSE(pi1): 7.638e-02, MSE(pi2): 2.229e-04, MSE(pi3): 2.476e-03\n",
      "Epoch 103600, Train loss: 5.448e+03, Test loss: 5.493e+03, MSE(e): 4.434e-04, MSE(pi1): 7.702e-02, MSE(pi2): 2.712e-04, MSE(pi3): 2.427e-03\n",
      "Epoch 103700, Train loss: 4.994e+03, Test loss: 5.254e+03, MSE(e): 3.981e-04, MSE(pi1): 7.780e-02, MSE(pi2): 2.377e-04, MSE(pi3): 2.354e-03\n",
      "Epoch 103800, Train loss: 4.481e+03, Test loss: 5.156e+03, MSE(e): 3.476e-04, MSE(pi1): 7.640e-02, MSE(pi2): 2.306e-04, MSE(pi3): 2.409e-03\n",
      "Epoch 103900, Train loss: 4.992e+03, Test loss: 6.566e+03, MSE(e): 3.985e-04, MSE(pi1): 7.620e-02, MSE(pi2): 2.314e-04, MSE(pi3): 2.447e-03\n",
      "Epoch 104000, Train loss: 4.918e+03, Test loss: 5.477e+03, MSE(e): 3.897e-04, MSE(pi1): 7.962e-02, MSE(pi2): 2.845e-04, MSE(pi3): 2.251e-03\n",
      "Epoch 104100, Train loss: 4.769e+03, Test loss: 4.648e+03, MSE(e): 3.766e-04, MSE(pi1): 7.622e-02, MSE(pi2): 2.593e-04, MSE(pi3): 2.405e-03\n",
      "Epoch 104200, Train loss: 4.759e+03, Test loss: 6.022e+03, MSE(e): 3.750e-04, MSE(pi1): 7.619e-02, MSE(pi2): 2.338e-04, MSE(pi3): 2.465e-03\n",
      "Epoch 104300, Train loss: 4.577e+03, Test loss: 5.119e+03, MSE(e): 3.575e-04, MSE(pi1): 7.536e-02, MSE(pi2): 2.339e-04, MSE(pi3): 2.490e-03\n",
      "Epoch 104400, Train loss: 5.047e+03, Test loss: 5.181e+03, MSE(e): 4.034e-04, MSE(pi1): 7.825e-02, MSE(pi2): 2.577e-04, MSE(pi3): 2.299e-03\n",
      "Epoch 104500, Train loss: 4.965e+03, Test loss: 6.304e+03, MSE(e): 3.958e-04, MSE(pi1): 7.682e-02, MSE(pi2): 2.356e-04, MSE(pi3): 2.387e-03\n",
      "Epoch 104600, Train loss: 4.541e+03, Test loss: 4.873e+03, MSE(e): 3.533e-04, MSE(pi1): 7.564e-02, MSE(pi2): 2.310e-04, MSE(pi3): 2.516e-03\n",
      "Epoch 104700, Train loss: 4.677e+03, Test loss: 5.670e+03, MSE(e): 3.666e-04, MSE(pi1): 7.761e-02, MSE(pi2): 2.422e-04, MSE(pi3): 2.353e-03\n",
      "Epoch 104800, Train loss: 4.739e+03, Test loss: 4.981e+03, MSE(e): 3.726e-04, MSE(pi1): 7.671e-02, MSE(pi2): 2.334e-04, MSE(pi3): 2.458e-03\n",
      "Epoch 104900, Train loss: 5.139e+03, Test loss: 5.645e+03, MSE(e): 4.130e-04, MSE(pi1): 7.701e-02, MSE(pi2): 2.803e-04, MSE(pi3): 2.381e-03\n",
      "Epoch 105000, Train loss: 5.038e+03, Test loss: 6.117e+03, MSE(e): 4.034e-04, MSE(pi1): 7.732e-02, MSE(pi2): 3.110e-04, MSE(pi3): 2.306e-03\n",
      "Epoch 105100, Train loss: 4.623e+03, Test loss: 5.179e+03, MSE(e): 3.612e-04, MSE(pi1): 7.840e-02, MSE(pi2): 2.644e-04, MSE(pi3): 2.262e-03\n",
      "Epoch 105200, Train loss: 4.544e+03, Test loss: 4.901e+03, MSE(e): 3.539e-04, MSE(pi1): 7.605e-02, MSE(pi2): 2.423e-04, MSE(pi3): 2.441e-03\n",
      "Epoch 105300, Train loss: 4.920e+03, Test loss: 7.511e+03, MSE(e): 3.915e-04, MSE(pi1): 7.785e-02, MSE(pi2): 2.718e-04, MSE(pi3): 2.262e-03\n",
      "Epoch 105400, Train loss: 4.790e+03, Test loss: 5.595e+03, MSE(e): 3.779e-04, MSE(pi1): 7.613e-02, MSE(pi2): 2.180e-04, MSE(pi3): 2.495e-03\n",
      "Epoch 105500, Train loss: 5.762e+03, Test loss: 6.734e+03, MSE(e): 4.749e-04, MSE(pi1): 7.642e-02, MSE(pi2): 2.371e-04, MSE(pi3): 2.487e-03\n",
      "Epoch 105600, Train loss: 4.948e+03, Test loss: 6.136e+03, MSE(e): 3.922e-04, MSE(pi1): 7.514e-02, MSE(pi2): 2.250e-04, MSE(pi3): 2.739e-03\n",
      "Epoch 105700, Train loss: 4.752e+03, Test loss: 6.645e+03, MSE(e): 3.739e-04, MSE(pi1): 7.533e-02, MSE(pi2): 2.547e-04, MSE(pi3): 2.590e-03\n",
      "Epoch 105800, Train loss: 4.742e+03, Test loss: 5.654e+03, MSE(e): 3.735e-04, MSE(pi1): 7.454e-02, MSE(pi2): 2.322e-04, MSE(pi3): 2.614e-03\n",
      "Epoch 105900, Train loss: 4.468e+03, Test loss: 4.855e+03, MSE(e): 3.469e-04, MSE(pi1): 7.647e-02, MSE(pi2): 2.540e-04, MSE(pi3): 2.347e-03\n",
      "Epoch 106000, Train loss: 4.957e+03, Test loss: 5.296e+03, MSE(e): 3.947e-04, MSE(pi1): 7.661e-02, MSE(pi2): 2.413e-04, MSE(pi3): 2.436e-03\n",
      "Epoch 106100, Train loss: 4.554e+03, Test loss: 4.997e+03, MSE(e): 3.548e-04, MSE(pi1): 7.686e-02, MSE(pi2): 2.354e-04, MSE(pi3): 2.367e-03\n",
      "Epoch 106200, Train loss: 4.601e+03, Test loss: 5.370e+03, MSE(e): 3.590e-04, MSE(pi1): 7.590e-02, MSE(pi2): 2.249e-04, MSE(pi3): 2.518e-03\n",
      "Epoch 106300, Train loss: 4.922e+03, Test loss: 7.298e+03, MSE(e): 3.909e-04, MSE(pi1): 7.548e-02, MSE(pi2): 2.451e-04, MSE(pi3): 2.579e-03\n",
      "Epoch 106400, Train loss: 5.361e+03, Test loss: 5.888e+03, MSE(e): 4.352e-04, MSE(pi1): 7.747e-02, MSE(pi2): 2.616e-04, MSE(pi3): 2.335e-03\n",
      "Epoch 106500, Train loss: 5.004e+03, Test loss: 5.899e+03, MSE(e): 3.994e-04, MSE(pi1): 7.526e-02, MSE(pi2): 2.415e-04, MSE(pi3): 2.576e-03\n",
      "Epoch 106600, Train loss: 4.862e+03, Test loss: 5.869e+03, MSE(e): 3.854e-04, MSE(pi1): 7.430e-02, MSE(pi2): 2.329e-04, MSE(pi3): 2.645e-03\n",
      "Epoch 106700, Train loss: 4.758e+03, Test loss: 5.279e+03, MSE(e): 3.753e-04, MSE(pi1): 7.684e-02, MSE(pi2): 2.428e-04, MSE(pi3): 2.363e-03\n",
      "Epoch 106800, Train loss: 5.066e+03, Test loss: 6.538e+03, MSE(e): 4.050e-04, MSE(pi1): 7.883e-02, MSE(pi2): 2.594e-04, MSE(pi3): 2.276e-03\n",
      "Epoch 106900, Train loss: 6.751e+03, Test loss: 6.072e+03, MSE(e): 5.710e-04, MSE(pi1): 7.807e-02, MSE(pi2): 2.846e-04, MSE(pi3): 2.602e-03\n",
      "Epoch 107000, Train loss: 5.095e+03, Test loss: 7.098e+03, MSE(e): 4.090e-04, MSE(pi1): 7.685e-02, MSE(pi2): 2.466e-04, MSE(pi3): 2.362e-03\n",
      "Epoch 107100, Train loss: 4.525e+03, Test loss: 4.675e+03, MSE(e): 3.519e-04, MSE(pi1): 7.695e-02, MSE(pi2): 2.462e-04, MSE(pi3): 2.363e-03\n",
      "Epoch 107200, Train loss: 5.194e+03, Test loss: 5.596e+03, MSE(e): 4.182e-04, MSE(pi1): 7.656e-02, MSE(pi2): 2.300e-04, MSE(pi3): 2.462e-03\n",
      "Epoch 107300, Train loss: 4.849e+03, Test loss: 5.520e+03, MSE(e): 3.840e-04, MSE(pi1): 7.579e-02, MSE(pi2): 2.144e-04, MSE(pi3): 2.511e-03\n",
      "Epoch 107400, Train loss: 4.747e+03, Test loss: 5.052e+03, MSE(e): 3.736e-04, MSE(pi1): 7.683e-02, MSE(pi2): 2.344e-04, MSE(pi3): 2.428e-03\n",
      "Epoch 107500, Train loss: 4.760e+03, Test loss: 4.833e+03, MSE(e): 3.747e-04, MSE(pi1): 7.623e-02, MSE(pi2): 2.133e-04, MSE(pi3): 2.506e-03\n",
      "Epoch 107600, Train loss: 5.247e+03, Test loss: 5.339e+03, MSE(e): 4.229e-04, MSE(pi1): 7.675e-02, MSE(pi2): 2.586e-04, MSE(pi3): 2.502e-03\n",
      "Epoch 107700, Train loss: 4.666e+03, Test loss: 6.069e+03, MSE(e): 3.657e-04, MSE(pi1): 7.718e-02, MSE(pi2): 2.226e-04, MSE(pi3): 2.369e-03\n",
      "Epoch 107800, Train loss: 4.773e+03, Test loss: 5.371e+03, MSE(e): 3.767e-04, MSE(pi1): 7.810e-02, MSE(pi2): 2.754e-04, MSE(pi3): 2.249e-03\n",
      "Epoch 107900, Train loss: 4.908e+03, Test loss: 6.251e+03, MSE(e): 3.897e-04, MSE(pi1): 7.565e-02, MSE(pi2): 2.169e-04, MSE(pi3): 2.545e-03\n",
      "Epoch 108000, Train loss: 4.624e+03, Test loss: 5.322e+03, MSE(e): 3.622e-04, MSE(pi1): 7.497e-02, MSE(pi2): 2.683e-04, MSE(pi3): 2.515e-03\n",
      "Epoch 108100, Train loss: 4.747e+03, Test loss: 4.885e+03, MSE(e): 3.729e-04, MSE(pi1): 7.572e-02, MSE(pi2): 2.147e-04, MSE(pi3): 2.600e-03\n",
      "Epoch 108200, Train loss: 4.919e+03, Test loss: 5.587e+03, MSE(e): 3.911e-04, MSE(pi1): 7.585e-02, MSE(pi2): 2.481e-04, MSE(pi3): 2.489e-03\n",
      "Epoch 108300, Train loss: 4.667e+03, Test loss: 5.252e+03, MSE(e): 3.651e-04, MSE(pi1): 7.849e-02, MSE(pi2): 2.499e-04, MSE(pi3): 2.309e-03\n",
      "Epoch 108400, Train loss: 4.923e+03, Test loss: 5.799e+03, MSE(e): 3.911e-04, MSE(pi1): 7.668e-02, MSE(pi2): 2.246e-04, MSE(pi3): 2.448e-03\n",
      "Epoch 108500, Train loss: 4.527e+03, Test loss: 4.791e+03, MSE(e): 3.525e-04, MSE(pi1): 7.661e-02, MSE(pi2): 2.547e-04, MSE(pi3): 2.359e-03\n",
      "Epoch 108600, Train loss: 4.460e+03, Test loss: 4.619e+03, MSE(e): 3.454e-04, MSE(pi1): 7.731e-02, MSE(pi2): 2.488e-04, MSE(pi3): 2.328e-03\n",
      "Epoch 108700, Train loss: 5.153e+03, Test loss: 7.207e+03, MSE(e): 4.151e-04, MSE(pi1): 7.602e-02, MSE(pi2): 2.440e-04, MSE(pi3): 2.413e-03\n",
      "Epoch 108800, Train loss: 4.737e+03, Test loss: 5.526e+03, MSE(e): 3.726e-04, MSE(pi1): 7.534e-02, MSE(pi2): 2.070e-04, MSE(pi3): 2.567e-03\n",
      "Epoch 108900, Train loss: 4.591e+03, Test loss: 5.326e+03, MSE(e): 3.582e-04, MSE(pi1): 7.457e-02, MSE(pi2): 2.226e-04, MSE(pi3): 2.635e-03\n",
      "Epoch 109000, Train loss: 4.776e+03, Test loss: 5.746e+03, MSE(e): 3.748e-04, MSE(pi1): 7.586e-02, MSE(pi2): 2.126e-04, MSE(pi3): 2.692e-03\n",
      "Epoch 109100, Train loss: 4.669e+03, Test loss: 5.339e+03, MSE(e): 3.656e-04, MSE(pi1): 7.595e-02, MSE(pi2): 2.343e-04, MSE(pi3): 2.539e-03\n",
      "Epoch 109200, Train loss: 4.509e+03, Test loss: 5.112e+03, MSE(e): 3.498e-04, MSE(pi1): 7.517e-02, MSE(pi2): 2.296e-04, MSE(pi3): 2.591e-03\n",
      "Epoch 109300, Train loss: 4.819e+03, Test loss: 4.973e+03, MSE(e): 3.814e-04, MSE(pi1): 7.677e-02, MSE(pi2): 2.406e-04, MSE(pi3): 2.379e-03\n",
      "Epoch 109400, Train loss: 4.651e+03, Test loss: 5.189e+03, MSE(e): 3.650e-04, MSE(pi1): 7.530e-02, MSE(pi2): 2.480e-04, MSE(pi3): 2.477e-03\n",
      "Epoch 109500, Train loss: 5.271e+03, Test loss: 5.685e+03, MSE(e): 4.258e-04, MSE(pi1): 7.756e-02, MSE(pi2): 2.450e-04, MSE(pi3): 2.372e-03\n",
      "Epoch 109600, Train loss: 5.022e+03, Test loss: 6.369e+03, MSE(e): 4.009e-04, MSE(pi1): 7.759e-02, MSE(pi2): 2.628e-04, MSE(pi3): 2.368e-03\n",
      "Epoch 109700, Train loss: 4.847e+03, Test loss: 5.453e+03, MSE(e): 3.835e-04, MSE(pi1): 7.800e-02, MSE(pi2): 2.526e-04, MSE(pi3): 2.321e-03\n",
      "Epoch 109800, Train loss: 4.651e+03, Test loss: 5.411e+03, MSE(e): 3.642e-04, MSE(pi1): 7.725e-02, MSE(pi2): 2.398e-04, MSE(pi3): 2.364e-03\n",
      "Epoch 109900, Train loss: 5.004e+03, Test loss: 5.652e+03, MSE(e): 3.978e-04, MSE(pi1): 7.601e-02, MSE(pi2): 2.370e-04, MSE(pi3): 2.657e-03\n",
      "\n",
      "Training process finished after 110000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = FFTNonlinearModel(input_shape, predictive_layers, base, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory, DEVICE).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 110000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "        D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "        model_results_path=MODEL_RESULTS_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 100000.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear/spectral_model/epoch_100000.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m n_checkpoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      8\u001b[0m second_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3e-4\u001b[39m\n\u001b[0;32m---> 11\u001b[0m train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n\u001b[1;32m     12\u001b[0m         D,  n_checkpoints, start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch, n_epochs\u001b[38;5;241m=\u001b[39mn_epochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[1;32m     13\u001b[0m         model_results_path\u001b[38;5;241m=\u001b[39mMODEL_RESULTS_PATH, device\u001b[38;5;241m=\u001b[39mDEVICE, new_lr\u001b[38;5;241m=\u001b[39msecond_lr)\n",
      "File \u001b[0;32m~/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/models/spectrum/trainers/train.py:101\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test, D, n_checkpoints, start_epoch, n_epochs, batch_size, model_results_path, device, new_lr)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting training from a checkpoint. Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    100\u001b[0m resume_epoch \u001b[38;5;241m=\u001b[39m start_epoch\n\u001b[0;32m--> 101\u001b[0m model, optimizer, lists \u001b[38;5;241m=\u001b[39m load_checkpoint(model, optimizer, resume_epoch, model_results_path)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Update learning rate if a new one is specified\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_lr \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/models/spectrum/utils/checkpoints.py:27\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[0;34m(model, optimizer, epoch, folder_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(model, optimizer, epoch, folder_path):\n\u001b[1;32m     26\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(epoch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(filename, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     30\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear/spectral_model/epoch_100000.pth'"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 100000\n",
    "n_epochs = 150000\n",
    "\n",
    "batch_size = 64 \n",
    "n_checkpoints = 10\n",
    "\n",
    "second_lr = 3e-4\n",
    "\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "        D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "        model_results_path=MODEL_RESULTS_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
