{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "# Own library imports\n",
    "from utilities.utils import TensOps\n",
    "from utilities.operators.zero_order import Mx, My\n",
    "from utilities.kernels.derivative import DerivativeKernels\n",
    "from utilities.operators import zero_order as zo\n",
    "from utilities.algebra import zero_order as azo\n",
    "\n",
    "# Function from this project\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from utils.checkpoints import load_results\n",
    "from trainers.train import train_loop\n",
    "from utils.fourier_base import compute_fourier_base\n",
    "\n",
    "# Import model\n",
    "from architectures.pgnniv_fourier import PGNNIVFourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = 'non_linear'\n",
    "N_data = 1000\n",
    "noise = 0\n",
    "\n",
    "data_name = dataset + '_' + str(N_data) + '_' + str(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = 'fourier'\n",
    "n_modes = 50\n",
    "\n",
    "model_name = model + '_model_' + str(n_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/', data_name, data_name) + '.pkl'\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/', data_name)\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/', data_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data splitting in train/test\n",
    "X = torch.tensor(dataset['X_train'], dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(dataset['y_train'], dtype=torch.float32).unsqueeze(1)\n",
    "K = torch.tensor(dataset['k_train'], dtype=torch.float32).unsqueeze(1)\n",
    "f = torch.tensor(dataset['f_train'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X, y, K, f, test_size=0.3, random_state=42)\n",
    "\n",
    "# Data processing and adequacy with our TensOps library\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "# Loading and processing validation data\n",
    "X_val = torch.tensor(dataset['X_val'], dtype=torch.float32).unsqueeze(1).to(DEVICE)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mesh = torch.tensor(dataset['X_mesh'])\n",
    "Y_mesh = torch.tensor(dataset['Y_mesh'])\n",
    "\n",
    "base = compute_fourier_base(n_modes, X_mesh, Y_mesh).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and optimizer\n",
    "model = PGNNIVFourier(input_shape, predictive_layers, base, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory, device=DEVICE).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "model, optimizer, lists = load_results(model, optimizer, MODEL_RESULTS_PATH, map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_loss_list = lists['train_total_loss_list']\n",
    "train_e_loss_list = lists['train_e_loss_list']\n",
    "train_pi1_loss_list = lists['train_pi1_loss_list']\n",
    "train_pi2_loss_list = lists['train_pi2_loss_list']\n",
    "train_pi3_loss_list = lists['train_pi3_loss_list']\n",
    "\n",
    "test_total_loss_list = lists['test_total_loss_list']\n",
    "test_e_loss_list = lists['test_e_loss_list']\n",
    "test_pi1_loss_list = lists['test_pi1_loss_list']\n",
    "test_pi2_loss_list = lists['test_pi2_loss_list']\n",
    "test_pi3_loss_list = lists['test_pi3_loss_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(data, window_size=200):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, window, mode='valid')\n",
    "\n",
    "def cm_to_in(cm):\n",
    "    return cm * 0.393701\n",
    "\n",
    "def normalize_list(lst):\n",
    "    max_value = np.max(lst)\n",
    "    return [x / max_value for x in lst]\n",
    "\n",
    "linewidth = 1.5  \n",
    "title_fontsize = 14  \n",
    "label_fontsize = 14  \n",
    "legend_fontsize = 12 \n",
    "tick_fontsize = 11  \n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "posX = cm_to_in(10) # position of the lower left corner of the image in X\n",
    "posY = cm_to_in(10) # position of the lower left corner of the image in Y\n",
    "width = cm_to_in(12)  # image width\n",
    "height = cm_to_in(8) # image height\n",
    "\n",
    "color = [0.1, 0, 0.8]  # RGB triplet, values between 0 and 1\n",
    "subplot_adjust_left = cm_to_in(0.15)\n",
    "subplot_adjust_bottom = cm_to_in(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(smooth_curve(train_total_loss_list), label='Total MSE train', color='blue', linestyle='-')\n",
    "plt.plot(smooth_curve(test_total_loss_list), label='Total MSE test', color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(normalize_list(smooth_curve(train_e_loss_list)), label=r'MSE(e) ', color='green', linestyle='-')\n",
    "plt.plot(normalize_list(smooth_curve(train_pi1_loss_list)), label=r'MSE($\\pi_1$) ', color='green', linestyle='--')\n",
    "plt.plot(normalize_list(smooth_curve(train_pi2_loss_list)), label=r'MSE($\\pi_2$) ', color='green', linestyle='-.')\n",
    "plt.plot(normalize_list(smooth_curve(train_pi3_loss_list)), label=r'MSE($\\pi_3$) ', color='green', linestyle=':')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Normalized Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error_stats(validation, prediction, dx=dx, dy=dy):\n",
    "\n",
    "    validation = validation.cpu().numpy()\n",
    "    prediction = prediction.cpu().numpy()\n",
    "\n",
    "    prediction_error = np.sqrt((np.trapz(np.trapz((validation - prediction)**2, dx=dy), dx=dx) /\n",
    "                                np.trapz(np.trapz((validation)**2, dx=dy), dx=dx)))\n",
    "\n",
    "    minimum = np.min(prediction_error)\n",
    "    maximum = np.max(prediction_error)\n",
    "    first_quartile = np.percentile(prediction_error, 25)\n",
    "    median = np.percentile(prediction_error, 50)\n",
    "    third_quartile = np.percentile(prediction_error, 75)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Minimum: {minimum:.2e}\")\n",
    "    print(f\"First quartile (Q1): {first_quartile:.2e}\")\n",
    "    print(f\"Median (Q2): {median:.2e}\")\n",
    "    print(f\"Third quartile (Q3): {third_quartile:.2e}\")\n",
    "    print(f\"Maximum: {maximum:.2e}\")\n",
    "\n",
    "def absolute_error_stats(validation, prediction, dx=dx, dy=dy):\n",
    "\n",
    "    validation = validation.cpu().numpy()\n",
    "    prediction = prediction.cpu().numpy()\n",
    "\n",
    "    prediction_error = np.sqrt((np.trapz(np.trapz((validation - prediction)**2, dx=dy), dx=dx)))\n",
    "\n",
    "    minimum = np.min(prediction_error)\n",
    "    maximum = np.max(prediction_error)\n",
    "    first_quartile = np.percentile(prediction_error, 25)\n",
    "    median = np.percentile(prediction_error, 50)\n",
    "    third_quartile = np.percentile(prediction_error, 75)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Minimum: {minimum:.2e}\")\n",
    "    print(f\"First quartile (Q1): {first_quartile:.2e}\")\n",
    "    print(f\"Median (Q2): {median:.2e}\")\n",
    "    print(f\"Third quartile (Q3): {third_quartile:.2e}\")\n",
    "    print(f\"Maximum: {maximum:.2e}\")\n",
    "\n",
    "\n",
    "def relative_error_return_Q(validation, prediction, dx=dx, dy=dy):\n",
    "\n",
    "    validation = validation.numpy()\n",
    "    prediction = prediction.numpy()\n",
    "\n",
    "    prediction_error = np.sqrt((np.trapz(np.trapz((validation - prediction)**2, dx=dy), dx=dx)/\n",
    "                                np.trapz(np.trapz((validation)**2, dx=dy), dx=dx)))\n",
    "    third_quartile = np.percentile(prediction_error, 75)\n",
    "\n",
    "    Q_bool = prediction_error <= third_quartile\n",
    "\n",
    "    return Q_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, K_pred = model(X_val)\n",
    "\n",
    "y_pred = TensOps(y_pred, space_dimension=2, contravariance=0, covariance=0)\n",
    "K_pred = TensOps(K_pred, space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution $u(x,y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_validation = y_val.values.detach()\n",
    "u_prediction = y_pred.values.detach()\n",
    "\n",
    "relative_error_stats(u_validation, u_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "u_diff = torch.mean(torch.abs(u_prediction - u_validation), axis=0).squeeze().cpu()\n",
    "plt.imshow(u_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "\n",
    "# Get the automatically generated ticks\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.000005)\n",
    "cbar.set_ticks(new_ticks[1:-1])\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_validation = zo.Mx(zo.My(y_val)).values.detach()\n",
    "um_prediction = zo.Mx(zo.My(y_pred)).values.detach()\n",
    "\n",
    "relative_error_stats(um_validation, um_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusivity $K(u) = u(1-u)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_validation = zo.My(zo.Mx(K_val)).values.detach()\n",
    "K_prediction = K_pred.values.detach()\n",
    "\n",
    "relative_error_stats(K_validation, K_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "K_diff = torch.mean(torch.abs(K_prediction - K_validation), axis=0).squeeze().cpu()\n",
    "plt.imshow(K_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "\n",
    "# Get the automatically generated ticks\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.0005)\n",
    "cbar.set_ticks(new_ticks[1:-1])\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_min = y_val.values.flatten().min()\n",
    "u_max = y_val.values.flatten().max()\n",
    "steps = 1000\n",
    "\n",
    "u_for_validating = torch.linspace(u_min, u_max, steps=steps).view(steps, 1, 1, 1)\n",
    "K_for_validating = (u_for_validating*(1-u_for_validating)).detach().cpu().numpy()\n",
    "K_predicted_for_validating = model.explanatory(u_for_validating.to(DEVICE)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = cm_to_in(12)  # image width\n",
    "height = cm_to_in(8) # image height\n",
    "\n",
    "plt.figure(figsize=(height, height))\n",
    "plt.scatter(u_for_validating.flatten(), K_predicted_for_validating.flatten(), label='Prediction', color='red', s=5, alpha=0.3)\n",
    "plt.scatter(u_for_validating.flatten(), K_for_validating.flatten(), label='Validation', color='black', s=3, alpha=0.5)\n",
    "\n",
    "plt.xlabel('$u(x, y)$', fontsize=label_fontsize)\n",
    "plt.ylabel('$k(u)$', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "# Get the current legend and change the order\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [1, 0]  # Change the order of the labels here (Validation first, Prediction second)\n",
    "plt.legend([handles[idx] for idx in order], [labels[idx] for idx in order], loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "min = torch.min(u_for_validating.flatten()) - 0.1*(torch.max(u_for_validating.flatten() - torch.min(u_for_validating.flatten())))\n",
    "max = torch.max(u_for_validating.flatten()) + 0.1*(torch.max(u_for_validating.flatten() - torch.min(u_for_validating.flatten())))\n",
    "\n",
    "plt.xlim(min, max)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time_seconds = np.cumsum(lists[\"time_list\"])[-1]\n",
    "total_time_minutes = total_time_seconds / 60\n",
    "\n",
    "print(f\"Total training time: {total_time_seconds:.2f} seconds\")\n",
    "print(f\"Total training time: {total_time_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_squared = (K_predicted_for_validating - K_for_validating) ** 2\n",
    "true_squared = K_for_validating ** 2\n",
    "\n",
    "u_vals = u_for_validating.numpy().flatten()\n",
    "\n",
    "er = (np.sqrt(np.trapz(diff_squared.flatten(), u_vals))) / (np.sqrt(np.trapz(true_squared.flatten(), u_vals)))\n",
    "\n",
    "print(\"Explanatory error:\")\n",
    "print(f\" er(K): {er:.2e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
