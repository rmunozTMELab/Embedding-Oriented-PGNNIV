{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Own library imports\n",
    "from vecopsciml.utils import TensOps\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "\n",
    "# Function from this project\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "from utils.checkpoints import load_results\n",
    "\n",
    "# Import model\n",
    "from architectures.autoencoder import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = 'non_linear'\n",
    "N_data = 10\n",
    "noise = 0\n",
    "\n",
    "data_name = dataset + '_' + str(N_data) + '_' + str(noise)\n",
    "print(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = 'autoencoder'\n",
    "n_modes = 5\n",
    "\n",
    "model_name = model + '_model_' + str(n_modes)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/', data_name, data_name) + '.pkl'\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/', data_name)\n",
    "\n",
    "MODEL_RESULTS_AE_PATH = os.path.join(ROOT_PATH, r'results/', data_name, model_name) + '_AE'\n",
    "MODEL_RESULTS_PGNNIV_PATH = os.path.join(ROOT_PATH, r'results/', data_name, model_name) + '_NN'\n",
    "\n",
    "# Create folders (if necessary)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_AE_PATH)\n",
    "create_folder(MODEL_RESULTS_PGNNIV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_data_AE = len(X_train)//4\n",
    "N_data_NN = len(X_train) - len(X_train)//4\n",
    "prop_data_NN = 1 - N_data_AE/(N_data_NN + N_data_AE)\n",
    "\n",
    "print(\"Dataset length for the autoencoder:\", N_data_AE)\n",
    "print(\"Dataset length for the PGNNIV:\", N_data_NN)\n",
    "\n",
    "X_AE, X_NN, y_AE, y_NN, K_AE, K_NN, f_AE, f_NN = train_test_split(X_train, y_train, K_train, f_train, test_size=prop_data_NN, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_AE, y_test_AE = train_test_split(y_AE, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train_AE = TensOps(y_train_AE.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test_AE = TensOps(y_test_AE.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_input_shape = y_train_AE.values[0].shape\n",
    "latent_space_dim = [20, 10, n_modes, 10, 20]\n",
    "autoencoder_output_shape = y_train_AE.values[0].shape\n",
    "\n",
    "model = Autoencoder(autoencoder_input_shape, latent_space_dim, autoencoder_output_shape).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model, optimizer, lists = load_results(model, optimizer, MODEL_RESULTS_AE_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_loss_list = lists['train_total_loss_list']\n",
    "test_total_loss_list = lists['test_total_loss_list']\n",
    "time_list = lists['time_list'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(data, window_size=100):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, window, mode='valid')\n",
    "\n",
    "def cm_to_in(cm):\n",
    "    return cm * 0.393701\n",
    "\n",
    "def normalize_list(lst):\n",
    "    max_value = np.max(lst)\n",
    "    return [x / max_value for x in lst]\n",
    "\n",
    "linewidth = 1.5  \n",
    "title_fontsize = 14  \n",
    "label_fontsize = 14  \n",
    "legend_fontsize = 12 \n",
    "tick_fontsize = 11  \n",
    "\n",
    "# plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "posX = cm_to_in(10) \n",
    "posY = cm_to_in(10)\n",
    "width = cm_to_in(12)\n",
    "height = cm_to_in(8)\n",
    "\n",
    "color = [0.1, 0, 0.8]\n",
    "subplot_adjust_left = cm_to_in(0.15)\n",
    "subplot_adjust_bottom = cm_to_in(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(smooth_curve(train_total_loss_list), label='Total MSE train', color='blue', linestyle='-')\n",
    "plt.plot(smooth_curve(test_total_loss_list), label='Total MSE test', color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error_stats(validation, prediction, dx=dx, dy=dy):\n",
    "    validation = validation.numpy()\n",
    "    prediction = prediction.numpy()\n",
    "\n",
    "    prediction_error = np.sqrt((np.trapz(np.trapz((validation - prediction)**2, dx=dy), dx=dx) /\n",
    "                                np.trapz(np.trapz((validation)**2, dx=dy), dx=dx)))\n",
    "\n",
    "    minimum = np.min(prediction_error)\n",
    "    maximum = np.max(prediction_error)\n",
    "    first_quartile = np.percentile(prediction_error, 25)\n",
    "    median = np.percentile(prediction_error, 50)\n",
    "    third_quartile = np.percentile(prediction_error, 75)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Minimum: {minimum:.2e}\")\n",
    "    print(f\"First quartile (Q1): {first_quartile:.2e}\")\n",
    "    print(f\"Median (Q2): {median:.2e}\")\n",
    "    print(f\"Third quartile (Q3): {third_quartile:.2e}\")\n",
    "    print(f\"Maximum: {maximum:.2e}\")\n",
    "\n",
    "\n",
    "def relative_error_return_Q(validation, prediction, dx=dx, dy=dy):\n",
    "    validation = validation.numpy()\n",
    "    prediction = prediction.numpy()\n",
    "\n",
    "    prediction_error = np.sqrt((np.trapz(np.trapz((validation - prediction)**2, dx=dy), dx=dx)/\n",
    "                                np.trapz(np.trapz((validation)**2, dx=dy), dx=dx)))\n",
    "    third_quartile = np.percentile(prediction_error, 75)\n",
    "\n",
    "    Q_bool = prediction_error <= third_quartile\n",
    "\n",
    "    return Q_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = y_val.values\n",
    "\n",
    "y_pred = TensOps(model(X_val), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution $u(x,y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_validation = y_val.values.detach()\n",
    "u_prediction = y_pred.values.detach()\n",
    "\n",
    "relative_error_stats(u_validation, u_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "u_diff = torch.mean(torch.abs(u_prediction - u_validation), axis=0).squeeze()\n",
    "plt.imshow(u_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "\n",
    "# Get automatically generated ticks\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.00005)\n",
    "cbar.set_ticks(new_ticks[1:-1])\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = cm_to_in(12)  # image width\n",
    "height = cm_to_in(8) # image height\n",
    "\n",
    "plt.figure(figsize=(height, height))\n",
    "plt.scatter(u_prediction.flatten(), u_validation.flatten(), label='Prediction', color='red', s=5, alpha=0.3)\n",
    "plt.scatter(u_validation.flatten(), u_validation.flatten(), label='Validation', color='black', s=5, alpha=0.3)\n",
    "\n",
    "plt.xlabel('$u(x, y)$', fontsize=label_fontsize)\n",
    "plt.ylabel('$u(x, y)$', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "# Get the current legend and change the order\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [1, 0]  # Change the order of the labels here (Validation first, Prediction second)\n",
    "plt.legend(loc='upper left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "min = torch.min(u_validation.flatten()) - 0.1*(torch.max(u_validation.flatten() - torch.min(u_validation.flatten())))\n",
    "max = torch.max(u_validation.flatten()) + 0.1*(torch.max(u_validation.flatten() - torch.min(u_validation.flatten())))\n",
    "\n",
    "plt.xlim(min, max)\n",
    "plt.ylim(0, 1.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
