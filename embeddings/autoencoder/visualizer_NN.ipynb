{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "# Own library imports\n",
    "from utilities.utils import TensOps\n",
    "from utilities.operators.zero_order import Mx, My\n",
    "from utilities.kernels.derivative import DerivativeKernels\n",
    "from utilities.operators import zero_order as zo\n",
    "from utilities.algebra import zero_order as azo\n",
    "\n",
    "# Function from this project\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "from utils.checkpoints import load_results\n",
    "\n",
    "# Import model\n",
    "from architectures.autoencoder import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = 'non_linear'\n",
    "N_data = 1000\n",
    "noise = 1\n",
    "\n",
    "data_name = dataset + '_' + str(N_data) + '_' + str(noise)\n",
    "print(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = 'autoencoder'\n",
    "n_modes = 10\n",
    "\n",
    "model_name = model + '_model_' + str(n_modes)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/', data_name, data_name) + '.pkl'\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/', data_name)\n",
    "\n",
    "MODEL_RESULTS_AE_PATH = os.path.join(ROOT_PATH, r'results/', data_name, model_name) + '_AE'\n",
    "MODEL_RESULTS_PGNNIV_PATH = os.path.join(ROOT_PATH, r'results/', data_name, model_name) + '_NN'\n",
    "\n",
    "# Create necessary folders (if already created, a message will be shown)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_AE_PATH)\n",
    "create_folder(MODEL_RESULTS_PGNNIV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1).to(torch.float32)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1).to(torch.float32)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1).to(torch.float32)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).to(torch.float32).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_data_AE = len(X_train)//4\n",
    "N_data_NN = len(X_train) - len(X_train)//4\n",
    "prop_data_NN = 1 - N_data_AE/(N_data_NN + N_data_AE)\n",
    "\n",
    "print(\"Dataset length for the autoencoder:\", N_data_AE)\n",
    "print(\"Dataset length for the PGNNIV:\", N_data_NN)\n",
    "\n",
    "X_AE, X_NN, y_AE, y_NN, K_AE, K_NN, f_AE, f_NN = train_test_split(X_train, y_train, K_train, f_train, test_size=prop_data_NN, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_NN, X_test_NN, y_train_NN, y_test_NN, K_train_NN, K_test_NN, f_train_NN, f_test_NN = train_test_split(X_NN, y_NN, K_NN, f_NN, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_NN = X_train_NN.to(DEVICE)\n",
    "X_test_NN = X_test_NN.to(DEVICE)\n",
    "\n",
    "y_train_NN = TensOps(y_train_NN.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test_NN = TensOps(y_test_NN.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train_NN = TensOps(K_train_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test_NN = TensOps(K_test_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train_NN = TensOps(f_train_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test_NN = TensOps(f_test_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive network architecture\n",
    "input_shape = X_train_NN[0].shape\n",
    "predictive_layers =  [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train_NN.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train_NN)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train_NN)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures.autoencoder import Autoencoder\n",
    "from architectures.pgnniv_decoder import PGNNIVAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_AE, y_test_AE = train_test_split(y_AE, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train_AE = TensOps(y_train_AE.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test_AE = TensOps(y_test_AE.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_input_shape = y_train_AE.values[0].shape\n",
    "latent_space_dim = [20, 10, n_modes, 10, 20]\n",
    "autoencoder_output_shape = y_train_AE.values[0].shape\n",
    "\n",
    "autoencoder = Autoencoder(autoencoder_input_shape, latent_space_dim, autoencoder_output_shape).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-4)\n",
    "\n",
    "autoencoder, optimizer, lists = load_results(autoencoder, optimizer, MODEL_RESULTS_AE_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_encoder = autoencoder.encoder\n",
    "pretrained_decoder = autoencoder.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se carga el modelo y el optimizador\n",
    "pgnniv_model = PGNNIVAutoencoder(input_shape, predictive_layers, pretrained_decoder, predictive_output, explanatory_input,\n",
    "                                   explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(pgnniv_model.parameters(), lr=1e-4)\n",
    "\n",
    "model, optimizer, lists = load_results(pgnniv_model, optimizer, MODEL_RESULTS_PGNNIV_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = lists['time_list']\n",
    "\n",
    "train_total_loss_list = lists['train_total_loss_list']\n",
    "train_e_loss_list = lists['train_e_loss_list']\n",
    "train_pi1_loss_list = lists['train_pi1_loss_list']\n",
    "train_pi2_loss_list = lists['train_pi2_loss_list']\n",
    "train_pi3_loss_list = lists['train_pi3_loss_list']\n",
    "\n",
    "test_total_loss_list = lists['test_total_loss_list']\n",
    "test_e_loss_list = lists['test_e_loss_list']\n",
    "test_pi1_loss_list = lists['test_pi1_loss_list']\n",
    "test_pi2_loss_list = lists['test_pi2_loss_list']\n",
    "test_pi3_loss_list = lists['test_pi3_loss_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(data, window_size=100):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, window, mode='valid')\n",
    "\n",
    "def cm_to_in(cm):\n",
    "    return cm * 0.393701\n",
    "\n",
    "def normalize_list(lst):\n",
    "    max_value = np.max(lst)\n",
    "    return [x / max_value for x in lst]\n",
    "\n",
    "linewidth = 1.5  \n",
    "title_fontsize = 14  \n",
    "label_fontsize = 14  \n",
    "legend_fontsize = 12 \n",
    "tick_fontsize = 11  \n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "posX = cm_to_in(10) # position of the lower left corner of the image in X\n",
    "posY = cm_to_in(10) # position of the lower left corner of the image in Y\n",
    "width = cm_to_in(12)  # image width\n",
    "height = cm_to_in(8) # image height\n",
    "\n",
    "color = [0.1, 0, 0.8]  # RGB triplet, values between 0 and 1\n",
    "subplot_adjust_left = cm_to_in(0.15)\n",
    "subplot_adjust_bottom = cm_to_in(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(smooth_curve(train_total_loss_list), label='Total MSE train', color='blue', linestyle='-')\n",
    "plt.plot(smooth_curve(test_total_loss_list), label='Total MSE test', color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(normalize_list(smooth_curve(train_e_loss_list)), label=r'MSE(e) ', color='green', linestyle='-')\n",
    "plt.plot(normalize_list(smooth_curve(train_pi1_loss_list)), label=r'MSE($\\pi_1$) ', color='green', linestyle='--')\n",
    "plt.plot(normalize_list(smooth_curve(train_pi2_loss_list)), label=r'MSE($\\pi_2$) ', color='green', linestyle='-.')\n",
    "plt.plot(normalize_list(smooth_curve(train_pi3_loss_list)), label=r'MSE($\\pi_3$) ', color='green', linestyle=':')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Normalized Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error_stats(validation, prediction, dx=dx, dy=dy):\n",
    "\n",
    "    validation = validation.numpy()\n",
    "    prediction = prediction.numpy()\n",
    "\n",
    "    prediction_error = np.sqrt((np.trapz(np.trapz((validation - prediction)**2, dx=dy), dx=dx) /\n",
    "                                np.trapz(np.trapz((validation)**2, dx=dy), dx=dx)))\n",
    "\n",
    "    minimum = np.min(prediction_error)\n",
    "    maximum = np.max(prediction_error)\n",
    "    first_quartile = np.percentile(prediction_error, 25)\n",
    "    median = np.percentile(prediction_error, 50)\n",
    "    third_quartile = np.percentile(prediction_error, 75)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Minimum: {minimum:.2e}\")\n",
    "    print(f\"First quartile (Q1): {first_quartile:.2e}\")\n",
    "    print(f\"Median (Q2): {median:.2e}\")\n",
    "    print(f\"Third quartile (Q3): {third_quartile:.2e}\")\n",
    "    print(f\"Maximum: {maximum:.2e}\")\n",
    "\n",
    "\n",
    "def relative_error_return_Q(validation, prediction, dx=dx, dy=dy):\n",
    "\n",
    "    validation = validation.numpy()\n",
    "    prediction = prediction.numpy()\n",
    "\n",
    "    prediction_error = np.sqrt((np.trapz(np.trapz((validation - prediction)**2, dx=dy), dx=dx)/\n",
    "                                np.trapz(np.trapz((validation)**2, dx=dy), dx=dx)))\n",
    "    third_quartile = np.percentile(prediction_error, 75)\n",
    "\n",
    "    Q_bool = prediction_error <= third_quartile\n",
    "\n",
    "    return Q_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, K_pred = model(X_val)\n",
    "\n",
    "y_pred = TensOps(y_pred, space_dimension=2, contravariance=0, covariance=0)\n",
    "K_pred = TensOps(K_pred, space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution $u(x,y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_validation = y_val.values.detach()\n",
    "u_prediction = y_pred.values.detach()\n",
    "\n",
    "relative_error_stats(u_validation, u_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "u_diff = torch.mean(torch.abs(u_prediction - u_validation), axis=0).squeeze()\n",
    "plt.imshow(u_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "\n",
    "# Get automatically generated ticks\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.00005)\n",
    "cbar.set_ticks(new_ticks[1:-1])\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_validation = zo.Mx(zo.My(y_val)).values.detach()\n",
    "um_prediction = zo.Mx(zo.My(y_pred)).values.detach()\n",
    "\n",
    "relative_error_stats(um_validation, um_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusivity $K(u) = u(1-u)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_validation = zo.My(zo.Mx(K_val)).values.detach()\n",
    "K_prediction = K_pred.values.detach()\n",
    "\n",
    "relative_error_stats(K_validation, K_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "K_diff = torch.mean(torch.abs(K_prediction - K_validation), axis=0).squeeze()\n",
    "plt.imshow(K_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "\n",
    "# Get automatically generated ticks\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.0005)\n",
    "cbar.set_ticks(new_ticks[1:-1])\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux $q_x(x, y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qx_validation = zo.Mx(zo.My(TensOps(torch.Tensor(dataset['qx_val']).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0))).values.detach()\n",
    "qx_prediction = azo.scalar_product(K_pred, zo.Dx(y_pred, D)).values.detach()\n",
    "\n",
    "relative_error_stats(qx_validation, qx_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "qx_diff = torch.mean(torch.abs(qx_prediction - qx_validation), axis=0).squeeze()\n",
    "plt.imshow(qx_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "\n",
    "# Get automatically generated ticks\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.00005)\n",
    "cbar.set_ticks(new_ticks[1:-1])\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux $q_y(x, y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qy_validation = zo.Mx(zo.My(TensOps(torch.Tensor(dataset['qy_val']).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0))).values.detach()\n",
    "qy_prediction = azo.scalar_product(K_pred, zo.Dy(y_pred, D)).values.detach()\n",
    "\n",
    "relative_error_stats(qy_validation, qy_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "qy_diff = torch.mean(torch.abs(qy_prediction - qy_validation), axis=0).squeeze()\n",
    "plt.imshow(qy_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "\n",
    "# Get automatically generated ticks\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.00005)\n",
    "cbar.set_ticks(new_ticks[1:-1])\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_min = um_validation.flatten().min()\n",
    "u_max = um_validation.flatten().max()\n",
    "steps = 1000\n",
    "\n",
    "u_for_validating = torch.linspace(u_min, u_max, steps=steps).view(steps, 1, 1, 1)\n",
    "K_for_validating = (u_for_validating*(1-u_for_validating)).detach().cpu().numpy()\n",
    "K_predicted_for_validating = model.explanatory(u_for_validating.to(DEVICE)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = cm_to_in(12)  # image width\n",
    "height = cm_to_in(8) # image height\n",
    "\n",
    "plt.figure(figsize=(height, height))\n",
    "plt.scatter(u_for_validating.flatten(), K_predicted_for_validating.flatten(), label='Prediction', color='red', s=5, alpha=0.3)\n",
    "plt.scatter(u_for_validating.flatten(), K_for_validating.flatten(), label='Validation', color='black', s=3, alpha=0.5)\n",
    "\n",
    "plt.xlabel('$u(x, y)$', fontsize=label_fontsize)\n",
    "plt.ylabel('$k(u)$', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "# Get the current legend and change the order\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [1, 0]  # Change the order of the labels here (Validation first, Prediction second)\n",
    "plt.legend([handles[idx] for idx in order], [labels[idx] for idx in order], loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "min = torch.min(u_for_validating.flatten()) - 0.1*(torch.max(u_for_validating.flatten() - torch.min(u_for_validating.flatten())))\n",
    "max = torch.max(u_for_validating.flatten()) + 0.1*(torch.max(u_for_validating.flatten() - torch.min(u_for_validating.flatten())))\n",
    "\n",
    "plt.xlim(min, max)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time_seconds = np.cumsum(lists[\"time_list\"])[-1]\n",
    "total_time_minutes = total_time_seconds / 60\n",
    "\n",
    "print(f\"Total training time: {total_time_seconds:.2f} seconds\")\n",
    "print(f\"Total training time: {total_time_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_squared = (K_predicted_for_validating - K_for_validating) ** 2\n",
    "true_squared = K_for_validating ** 2\n",
    "\n",
    "u_vals = u_for_validating.numpy().flatten()\n",
    "\n",
    "er = (np.sqrt(np.trapz(diff_squared.flatten(), u_vals))) / (np.sqrt(np.trapz(true_squared.flatten(), u_vals)))\n",
    "\n",
    "print(\"Explanatory error:\")\n",
    "print(f\" er(K): {er:.2e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
