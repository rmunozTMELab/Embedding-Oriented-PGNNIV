{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Own library imports\n",
    "from vecopsciml.utils import TensOps\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "\n",
    "# Function from this project\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "# Import model\n",
    "from architectures.pgnniv_baseline import PGNNIVBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = 'non_linear'\n",
    "N_data = 100\n",
    "noise = 1\n",
    "\n",
    "data_name = dataset + '_' + str(N_data) + '_' + str(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = 'baseline'\n",
    "n_modes = 10\n",
    "\n",
    "model_name = model + '_model_' + str(n_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/', data_name, data_name) + '.pkl'\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/', data_name)\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/', data_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear_100_1/non_linear_100_1.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data splitting in train/test\n",
    "X = torch.tensor(dataset['X_train'], dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(dataset['y_train'], dtype=torch.float32).unsqueeze(1)\n",
    "K = torch.tensor(dataset['k_train'], dtype=torch.float32).unsqueeze(1)\n",
    "f = torch.tensor(dataset['f_train'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X, y, K, f, test_size=0.3, random_state=42)\n",
    "\n",
    "# Data processing and adequacy with our TensOps library\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "# Loading and processing validation data\n",
    "X_val = torch.tensor(dataset['X_val'], dtype=torch.float32).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load model and the optimizer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m BaselineNonlinearModel(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Parametros de entrenamiento\u001b[39;00m\n\u001b[1;32m      6\u001b[0m start_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/torch/optim/adam.py:73\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     62\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m     63\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     fused\u001b[38;5;241m=\u001b[39mfused,\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(params, defaults)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/torch/optim/optimizer.py:367\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    364\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_param_group(cast(\u001b[38;5;28mdict\u001b[39m, param_group))\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/torch/_compile.py:26\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m disable_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dynamo_disable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     29\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/torch/_dynamo/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:48\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _disable_current_modes\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m format_traceback_short\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, exc, trace_rules\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompilerFn\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_dead_code, remove_pointless_jumps\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/torch/_dynamo/exc.py:12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m counters\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexportdb_error_message\u001b[39m(case_name):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor more information about this error, see: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/generated/exportdb/index.html#\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;241m+\u001b[39m case_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/torch/_dynamo/utils.py:1063\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[1;32m   1047\u001b[0m common_constant_types \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     torch\u001b[38;5;241m.\u001b[39mlayout,\n\u001b[1;32m   1061\u001b[0m }\n\u001b[0;32m-> 1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_triton_package():\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m     common_constant_types\u001b[38;5;241m.\u001b[39madd(triton\u001b[38;5;241m.\u001b[39mlanguage\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/torch/utils/_triton.py:9\u001b[0m, in \u001b[0;36mhas_triton_package\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_triton_package\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m triton \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/triton/__init__.py:8\u001b[0m\n\u001b[1;32m      2\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# ---------------------------------------\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Note: import order is significant here.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# submodules\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruntime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     autotune,\n\u001b[1;32m     10\u001b[0m     Config,\n\u001b[1;32m     11\u001b[0m     heuristics,\n\u001b[1;32m     12\u001b[0m     JITFunction,\n\u001b[1;32m     13\u001b[0m     KernelInterface,\n\u001b[1;32m     14\u001b[0m     reinterpret,\n\u001b[1;32m     15\u001b[0m     TensorWrapper,\n\u001b[1;32m     16\u001b[0m     OutOfResources,\n\u001b[1;32m     17\u001b[0m     InterpreterError,\n\u001b[1;32m     18\u001b[0m     MockTensor,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m, CompilationError\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/triton/runtime/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautotuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Autotuner, Config, Heuristics, autotune, heuristics)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RedisRemoteCacheBackend, RemoteCacheBackend\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdriver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m driver\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/triton/runtime/autotuner.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m do_bench, do_bench_cudagraph\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelInterface\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutOfResources\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/triton/testing.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m language \u001b[38;5;28;01mas\u001b[39;00m tl\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnvsmi\u001b[39m(attrs):\n\u001b[1;32m     11\u001b[0m     attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(attrs)\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/triton/language/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"isort:skip_file\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Import order is significant here.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m math\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extra\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstandard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     argmax,\n\u001b[1;32m      8\u001b[0m     argmin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     zeros_like,\n\u001b[1;32m     25\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/triton/language/math.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m semantic\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wraps\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/triton/language/core.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union, Callable, List, Sequence, TypeVar, Optional\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbuiltins\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/triton/runtime/jit.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cached_property\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Generic, Iterable, Optional, TypeVar, Union, overload, Dict, Any, Tuple\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdriver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m driver\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleType\n\u001b[1;32m     15\u001b[0m TRITON_MODULE \u001b[38;5;241m=\u001b[39m \u001b[38;5;18m__name__\u001b[39m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.runtime.jit\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/envs/SciML_test_env/lib/python3.12/site-packages/triton/runtime/driver.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backends\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DriverBase\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_driver\u001b[39m():\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1349\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = BaselineNonlinearModel(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 20000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 18000.\n",
      "Epoch 18000, Train loss: 1.903e+06, Test loss: 1.401e+07, MSE(e): 1.860e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.538e-02, MSE(pi3): 1.877e-01\n",
      "Epoch 18100, Train loss: 1.819e+06, Test loss: 1.373e+07, MSE(e): 1.777e-01, MSE(pi1): 2.419e+00, MSE(pi2): 7.211e-02, MSE(pi3): 1.847e-01\n",
      "Epoch 18200, Train loss: 1.819e+06, Test loss: 1.374e+07, MSE(e): 1.777e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.211e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 18300, Train loss: 1.819e+06, Test loss: 1.374e+07, MSE(e): 1.777e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.210e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 18400, Train loss: 1.819e+06, Test loss: 1.375e+07, MSE(e): 1.777e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.210e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 18500, Train loss: 1.819e+06, Test loss: 1.376e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.210e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 18600, Train loss: 1.819e+06, Test loss: 1.376e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.209e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 18700, Train loss: 1.819e+06, Test loss: 1.377e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.209e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 18800, Train loss: 1.819e+06, Test loss: 1.377e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.209e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 18900, Train loss: 1.819e+06, Test loss: 1.378e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.209e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 19000, Train loss: 1.819e+06, Test loss: 1.378e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.208e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 19100, Train loss: 1.819e+06, Test loss: 1.378e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.208e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 19200, Train loss: 1.819e+06, Test loss: 1.379e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.208e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 19300, Train loss: 1.819e+06, Test loss: 1.379e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.208e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 19400, Train loss: 1.819e+06, Test loss: 1.380e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.208e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 19500, Train loss: 1.819e+06, Test loss: 1.380e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.207e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 19600, Train loss: 1.819e+06, Test loss: 1.381e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.207e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 19700, Train loss: 1.819e+06, Test loss: 1.381e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.207e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 19800, Train loss: 1.819e+06, Test loss: 1.382e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.207e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 19900, Train loss: 1.819e+06, Test loss: 1.382e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.206e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 20000, Train loss: 1.819e+06, Test loss: 1.383e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.206e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 20100, Train loss: 1.818e+06, Test loss: 1.383e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.206e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 20200, Train loss: 1.818e+06, Test loss: 1.384e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.206e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 20300, Train loss: 1.818e+06, Test loss: 1.384e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.205e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 20400, Train loss: 1.818e+06, Test loss: 1.385e+07, MSE(e): 1.776e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.205e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 20500, Train loss: 1.818e+06, Test loss: 1.386e+07, MSE(e): 1.775e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.205e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 20600, Train loss: 1.818e+06, Test loss: 1.386e+07, MSE(e): 1.775e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.204e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 20700, Train loss: 1.818e+06, Test loss: 1.387e+07, MSE(e): 1.775e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.204e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 20800, Train loss: 1.818e+06, Test loss: 1.387e+07, MSE(e): 1.775e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.204e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 20900, Train loss: 1.818e+06, Test loss: 1.388e+07, MSE(e): 1.775e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.203e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 21000, Train loss: 1.818e+06, Test loss: 1.389e+07, MSE(e): 1.775e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.203e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 21100, Train loss: 1.818e+06, Test loss: 1.389e+07, MSE(e): 1.775e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.202e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 21200, Train loss: 1.818e+06, Test loss: 1.390e+07, MSE(e): 1.775e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.202e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 21300, Train loss: 1.818e+06, Test loss: 1.391e+07, MSE(e): 1.775e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.202e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 21400, Train loss: 1.817e+06, Test loss: 1.392e+07, MSE(e): 1.775e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.201e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 21500, Train loss: 1.817e+06, Test loss: 1.392e+07, MSE(e): 1.775e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.201e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 21600, Train loss: 1.817e+06, Test loss: 1.393e+07, MSE(e): 1.774e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.200e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 21700, Train loss: 1.817e+06, Test loss: 1.394e+07, MSE(e): 1.774e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.200e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 21800, Train loss: 1.817e+06, Test loss: 1.395e+07, MSE(e): 1.774e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.199e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 21900, Train loss: 1.817e+06, Test loss: 1.396e+07, MSE(e): 1.774e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.199e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 22000, Train loss: 1.817e+06, Test loss: 1.397e+07, MSE(e): 1.774e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.198e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 22100, Train loss: 1.817e+06, Test loss: 1.398e+07, MSE(e): 1.774e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.197e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 22200, Train loss: 1.816e+06, Test loss: 1.399e+07, MSE(e): 1.774e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.197e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 22300, Train loss: 1.816e+06, Test loss: 1.400e+07, MSE(e): 1.774e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.196e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 22400, Train loss: 1.816e+06, Test loss: 1.401e+07, MSE(e): 1.773e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.195e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 22500, Train loss: 1.816e+06, Test loss: 1.402e+07, MSE(e): 1.773e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.195e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 22600, Train loss: 1.816e+06, Test loss: 1.403e+07, MSE(e): 1.773e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.194e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 22700, Train loss: 1.816e+06, Test loss: 1.404e+07, MSE(e): 1.773e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.193e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 22800, Train loss: 1.815e+06, Test loss: 1.405e+07, MSE(e): 1.773e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.192e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 22900, Train loss: 1.815e+06, Test loss: 1.406e+07, MSE(e): 1.773e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.191e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 23000, Train loss: 1.815e+06, Test loss: 1.407e+07, MSE(e): 1.772e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.190e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 23100, Train loss: 1.815e+06, Test loss: 1.409e+07, MSE(e): 1.772e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.189e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 23200, Train loss: 1.815e+06, Test loss: 1.410e+07, MSE(e): 1.772e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.188e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 23300, Train loss: 1.814e+06, Test loss: 1.411e+07, MSE(e): 1.772e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.187e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 23400, Train loss: 1.814e+06, Test loss: 1.413e+07, MSE(e): 1.771e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.186e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 23500, Train loss: 1.814e+06, Test loss: 1.414e+07, MSE(e): 1.771e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.185e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 23600, Train loss: 1.814e+06, Test loss: 1.416e+07, MSE(e): 1.771e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.184e-02, MSE(pi3): 1.846e-01\n",
      "Epoch 23700, Train loss: 1.813e+06, Test loss: 1.417e+07, MSE(e): 1.771e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.182e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 23800, Train loss: 1.813e+06, Test loss: 1.419e+07, MSE(e): 1.770e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.181e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 23900, Train loss: 1.813e+06, Test loss: 1.420e+07, MSE(e): 1.770e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.180e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 24000, Train loss: 1.812e+06, Test loss: 1.422e+07, MSE(e): 1.770e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.178e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 24100, Train loss: 1.812e+06, Test loss: 1.424e+07, MSE(e): 1.769e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.177e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 24200, Train loss: 1.812e+06, Test loss: 1.426e+07, MSE(e): 1.769e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.175e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 24300, Train loss: 1.811e+06, Test loss: 1.427e+07, MSE(e): 1.769e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.174e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 24400, Train loss: 1.811e+06, Test loss: 1.429e+07, MSE(e): 1.768e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.172e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 24500, Train loss: 1.811e+06, Test loss: 1.431e+07, MSE(e): 1.768e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.170e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 24600, Train loss: 1.810e+06, Test loss: 1.433e+07, MSE(e): 1.768e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.168e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 24700, Train loss: 1.810e+06, Test loss: 1.436e+07, MSE(e): 1.767e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.166e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 24800, Train loss: 1.809e+06, Test loss: 1.438e+07, MSE(e): 1.767e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.164e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 24900, Train loss: 1.809e+06, Test loss: 1.440e+07, MSE(e): 1.766e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.162e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 25000, Train loss: 1.808e+06, Test loss: 1.442e+07, MSE(e): 1.766e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.160e-02, MSE(pi3): 1.845e-01\n",
      "Epoch 25100, Train loss: 1.808e+06, Test loss: 1.445e+07, MSE(e): 1.765e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.158e-02, MSE(pi3): 1.844e-01\n",
      "Epoch 25200, Train loss: 1.807e+06, Test loss: 1.448e+07, MSE(e): 1.765e-01, MSE(pi1): 2.421e+00, MSE(pi2): 7.156e-02, MSE(pi3): 1.844e-01\n",
      "Epoch 25300, Train loss: 1.807e+06, Test loss: 1.450e+07, MSE(e): 1.764e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.153e-02, MSE(pi3): 1.844e-01\n",
      "Epoch 25400, Train loss: 1.806e+06, Test loss: 1.453e+07, MSE(e): 1.764e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.150e-02, MSE(pi3): 1.844e-01\n",
      "Epoch 25500, Train loss: 1.806e+06, Test loss: 1.456e+07, MSE(e): 1.763e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.148e-02, MSE(pi3): 1.844e-01\n",
      "Epoch 25600, Train loss: 1.805e+06, Test loss: 1.459e+07, MSE(e): 1.762e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.145e-02, MSE(pi3): 1.844e-01\n",
      "Epoch 25700, Train loss: 1.804e+06, Test loss: 1.462e+07, MSE(e): 1.762e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.141e-02, MSE(pi3): 1.844e-01\n",
      "Epoch 25800, Train loss: 1.804e+06, Test loss: 1.465e+07, MSE(e): 1.761e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.138e-02, MSE(pi3): 1.843e-01\n",
      "Epoch 25900, Train loss: 1.803e+06, Test loss: 1.469e+07, MSE(e): 1.760e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.135e-02, MSE(pi3): 1.843e-01\n",
      "Epoch 26000, Train loss: 1.802e+06, Test loss: 1.472e+07, MSE(e): 1.760e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.131e-02, MSE(pi3): 1.843e-01\n",
      "Epoch 26100, Train loss: 1.801e+06, Test loss: 1.476e+07, MSE(e): 1.759e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.128e-02, MSE(pi3): 1.843e-01\n",
      "Epoch 26200, Train loss: 1.801e+06, Test loss: 1.479e+07, MSE(e): 1.758e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.124e-02, MSE(pi3): 1.843e-01\n",
      "Epoch 26300, Train loss: 1.800e+06, Test loss: 1.483e+07, MSE(e): 1.757e-01, MSE(pi1): 2.420e+00, MSE(pi2): 7.120e-02, MSE(pi3): 1.842e-01\n",
      "Epoch 26400, Train loss: 1.799e+06, Test loss: 1.486e+07, MSE(e): 1.756e-01, MSE(pi1): 2.419e+00, MSE(pi2): 7.116e-02, MSE(pi3): 1.842e-01\n",
      "Epoch 26500, Train loss: 1.798e+06, Test loss: 1.490e+07, MSE(e): 1.755e-01, MSE(pi1): 2.419e+00, MSE(pi2): 7.112e-02, MSE(pi3): 1.842e-01\n",
      "Epoch 26600, Train loss: 1.797e+06, Test loss: 1.493e+07, MSE(e): 1.755e-01, MSE(pi1): 2.419e+00, MSE(pi2): 7.108e-02, MSE(pi3): 1.842e-01\n",
      "Epoch 26700, Train loss: 1.796e+06, Test loss: 1.497e+07, MSE(e): 1.754e-01, MSE(pi1): 2.419e+00, MSE(pi2): 7.104e-02, MSE(pi3): 1.841e-01\n",
      "Epoch 26800, Train loss: 1.795e+06, Test loss: 1.501e+07, MSE(e): 1.753e-01, MSE(pi1): 2.419e+00, MSE(pi2): 7.100e-02, MSE(pi3): 1.841e-01\n",
      "Epoch 26900, Train loss: 1.794e+06, Test loss: 1.504e+07, MSE(e): 1.752e-01, MSE(pi1): 2.419e+00, MSE(pi2): 7.095e-02, MSE(pi3): 1.841e-01\n",
      "Epoch 27000, Train loss: 1.793e+06, Test loss: 1.507e+07, MSE(e): 1.751e-01, MSE(pi1): 2.419e+00, MSE(pi2): 7.091e-02, MSE(pi3): 1.841e-01\n",
      "Epoch 27100, Train loss: 1.792e+06, Test loss: 1.511e+07, MSE(e): 1.750e-01, MSE(pi1): 2.419e+00, MSE(pi2): 7.086e-02, MSE(pi3): 1.841e-01\n",
      "Epoch 27200, Train loss: 1.791e+06, Test loss: 1.514e+07, MSE(e): 1.749e-01, MSE(pi1): 2.418e+00, MSE(pi2): 7.082e-02, MSE(pi3): 1.840e-01\n",
      "Epoch 27300, Train loss: 1.791e+06, Test loss: 1.518e+07, MSE(e): 1.748e-01, MSE(pi1): 2.418e+00, MSE(pi2): 7.077e-02, MSE(pi3): 1.840e-01\n",
      "Epoch 27400, Train loss: 1.790e+06, Test loss: 1.521e+07, MSE(e): 1.747e-01, MSE(pi1): 2.418e+00, MSE(pi2): 7.073e-02, MSE(pi3): 1.840e-01\n",
      "Epoch 27500, Train loss: 1.789e+06, Test loss: 1.524e+07, MSE(e): 1.746e-01, MSE(pi1): 2.418e+00, MSE(pi2): 7.068e-02, MSE(pi3): 1.839e-01\n",
      "Epoch 27600, Train loss: 1.788e+06, Test loss: 1.527e+07, MSE(e): 1.745e-01, MSE(pi1): 2.418e+00, MSE(pi2): 7.063e-02, MSE(pi3): 1.839e-01\n",
      "Epoch 27700, Train loss: 1.787e+06, Test loss: 1.531e+07, MSE(e): 1.744e-01, MSE(pi1): 2.418e+00, MSE(pi2): 7.058e-02, MSE(pi3): 1.839e-01\n",
      "Epoch 27800, Train loss: 1.786e+06, Test loss: 1.534e+07, MSE(e): 1.743e-01, MSE(pi1): 2.418e+00, MSE(pi2): 7.053e-02, MSE(pi3): 1.838e-01\n",
      "Epoch 27900, Train loss: 1.785e+06, Test loss: 1.536e+07, MSE(e): 1.742e-01, MSE(pi1): 2.417e+00, MSE(pi2): 7.047e-02, MSE(pi3): 1.838e-01\n",
      "Epoch 28000, Train loss: 1.784e+06, Test loss: 1.539e+07, MSE(e): 1.741e-01, MSE(pi1): 2.417e+00, MSE(pi2): 7.043e-02, MSE(pi3): 1.838e-01\n",
      "Epoch 28100, Train loss: 1.783e+06, Test loss: 1.542e+07, MSE(e): 1.741e-01, MSE(pi1): 2.417e+00, MSE(pi2): 7.037e-02, MSE(pi3): 1.838e-01\n",
      "Epoch 28200, Train loss: 1.782e+06, Test loss: 1.545e+07, MSE(e): 1.740e-01, MSE(pi1): 2.417e+00, MSE(pi2): 7.033e-02, MSE(pi3): 1.838e-01\n",
      "Epoch 28300, Train loss: 1.782e+06, Test loss: 1.548e+07, MSE(e): 1.739e-01, MSE(pi1): 2.417e+00, MSE(pi2): 7.027e-02, MSE(pi3): 1.837e-01\n",
      "Epoch 28400, Train loss: 1.781e+06, Test loss: 1.551e+07, MSE(e): 1.738e-01, MSE(pi1): 2.417e+00, MSE(pi2): 7.022e-02, MSE(pi3): 1.837e-01\n",
      "Epoch 28500, Train loss: 1.780e+06, Test loss: 1.553e+07, MSE(e): 1.737e-01, MSE(pi1): 2.417e+00, MSE(pi2): 7.017e-02, MSE(pi3): 1.837e-01\n",
      "Epoch 28600, Train loss: 1.779e+06, Test loss: 1.556e+07, MSE(e): 1.736e-01, MSE(pi1): 2.416e+00, MSE(pi2): 7.011e-02, MSE(pi3): 1.837e-01\n",
      "Epoch 28700, Train loss: 1.778e+06, Test loss: 1.558e+07, MSE(e): 1.736e-01, MSE(pi1): 2.416e+00, MSE(pi2): 7.006e-02, MSE(pi3): 1.836e-01\n",
      "Epoch 28800, Train loss: 1.777e+06, Test loss: 1.560e+07, MSE(e): 1.735e-01, MSE(pi1): 2.416e+00, MSE(pi2): 7.001e-02, MSE(pi3): 1.836e-01\n",
      "Epoch 28900, Train loss: 1.777e+06, Test loss: 1.563e+07, MSE(e): 1.734e-01, MSE(pi1): 2.416e+00, MSE(pi2): 6.995e-02, MSE(pi3): 1.836e-01\n",
      "Epoch 29000, Train loss: 1.776e+06, Test loss: 1.565e+07, MSE(e): 1.733e-01, MSE(pi1): 2.416e+00, MSE(pi2): 6.990e-02, MSE(pi3): 1.836e-01\n",
      "Epoch 29100, Train loss: 1.775e+06, Test loss: 1.568e+07, MSE(e): 1.733e-01, MSE(pi1): 2.416e+00, MSE(pi2): 6.985e-02, MSE(pi3): 1.835e-01\n",
      "Epoch 29200, Train loss: 1.774e+06, Test loss: 1.570e+07, MSE(e): 1.732e-01, MSE(pi1): 2.416e+00, MSE(pi2): 6.979e-02, MSE(pi3): 1.835e-01\n",
      "Epoch 29300, Train loss: 1.774e+06, Test loss: 1.572e+07, MSE(e): 1.731e-01, MSE(pi1): 2.416e+00, MSE(pi2): 6.974e-02, MSE(pi3): 1.835e-01\n",
      "Epoch 29400, Train loss: 1.773e+06, Test loss: 1.574e+07, MSE(e): 1.730e-01, MSE(pi1): 2.416e+00, MSE(pi2): 6.968e-02, MSE(pi3): 1.835e-01\n",
      "Epoch 29500, Train loss: 1.772e+06, Test loss: 1.577e+07, MSE(e): 1.730e-01, MSE(pi1): 2.415e+00, MSE(pi2): 6.963e-02, MSE(pi3): 1.834e-01\n",
      "Epoch 29600, Train loss: 1.771e+06, Test loss: 1.579e+07, MSE(e): 1.729e-01, MSE(pi1): 2.415e+00, MSE(pi2): 6.958e-02, MSE(pi3): 1.834e-01\n",
      "Epoch 29700, Train loss: 1.771e+06, Test loss: 1.581e+07, MSE(e): 1.728e-01, MSE(pi1): 2.415e+00, MSE(pi2): 6.953e-02, MSE(pi3): 1.834e-01\n",
      "Epoch 29800, Train loss: 1.770e+06, Test loss: 1.583e+07, MSE(e): 1.727e-01, MSE(pi1): 2.415e+00, MSE(pi2): 6.947e-02, MSE(pi3): 1.834e-01\n",
      "Epoch 29900, Train loss: 1.769e+06, Test loss: 1.585e+07, MSE(e): 1.727e-01, MSE(pi1): 2.415e+00, MSE(pi2): 6.942e-02, MSE(pi3): 1.833e-01\n",
      "Epoch 30000, Train loss: 1.769e+06, Test loss: 1.587e+07, MSE(e): 1.726e-01, MSE(pi1): 2.415e+00, MSE(pi2): 6.937e-02, MSE(pi3): 1.833e-01\n",
      "Epoch 30100, Train loss: 1.768e+06, Test loss: 1.589e+07, MSE(e): 1.725e-01, MSE(pi1): 2.415e+00, MSE(pi2): 6.931e-02, MSE(pi3): 1.833e-01\n",
      "Epoch 30200, Train loss: 1.767e+06, Test loss: 1.591e+07, MSE(e): 1.725e-01, MSE(pi1): 2.415e+00, MSE(pi2): 6.926e-02, MSE(pi3): 1.833e-01\n",
      "Epoch 30300, Train loss: 1.766e+06, Test loss: 1.593e+07, MSE(e): 1.724e-01, MSE(pi1): 2.415e+00, MSE(pi2): 6.921e-02, MSE(pi3): 1.832e-01\n",
      "Epoch 30400, Train loss: 1.766e+06, Test loss: 1.595e+07, MSE(e): 1.723e-01, MSE(pi1): 2.415e+00, MSE(pi2): 6.916e-02, MSE(pi3): 1.832e-01\n",
      "Epoch 30500, Train loss: 1.765e+06, Test loss: 1.597e+07, MSE(e): 1.723e-01, MSE(pi1): 2.415e+00, MSE(pi2): 6.911e-02, MSE(pi3): 1.832e-01\n",
      "Epoch 30600, Train loss: 1.765e+06, Test loss: 1.599e+07, MSE(e): 1.722e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.905e-02, MSE(pi3): 1.832e-01\n",
      "Epoch 30700, Train loss: 1.764e+06, Test loss: 1.601e+07, MSE(e): 1.721e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.899e-02, MSE(pi3): 1.832e-01\n",
      "Epoch 30800, Train loss: 1.763e+06, Test loss: 1.603e+07, MSE(e): 1.721e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.895e-02, MSE(pi3): 1.832e-01\n",
      "Epoch 30900, Train loss: 1.763e+06, Test loss: 1.605e+07, MSE(e): 1.720e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.889e-02, MSE(pi3): 1.831e-01\n",
      "Epoch 31000, Train loss: 1.762e+06, Test loss: 1.607e+07, MSE(e): 1.719e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.884e-02, MSE(pi3): 1.831e-01\n",
      "Epoch 31100, Train loss: 1.761e+06, Test loss: 1.610e+07, MSE(e): 1.719e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.880e-02, MSE(pi3): 1.830e-01\n",
      "Epoch 31200, Train loss: 1.761e+06, Test loss: 1.612e+07, MSE(e): 1.718e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.874e-02, MSE(pi3): 1.830e-01\n",
      "Epoch 31300, Train loss: 1.760e+06, Test loss: 1.614e+07, MSE(e): 1.718e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.869e-02, MSE(pi3): 1.830e-01\n",
      "Epoch 31400, Train loss: 1.759e+06, Test loss: 1.617e+07, MSE(e): 1.717e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.864e-02, MSE(pi3): 1.830e-01\n",
      "Epoch 31500, Train loss: 1.759e+06, Test loss: 1.619e+07, MSE(e): 1.716e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.859e-02, MSE(pi3): 1.830e-01\n",
      "Epoch 31600, Train loss: 1.758e+06, Test loss: 1.622e+07, MSE(e): 1.716e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.854e-02, MSE(pi3): 1.830e-01\n",
      "Epoch 31700, Train loss: 1.758e+06, Test loss: 1.624e+07, MSE(e): 1.715e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.849e-02, MSE(pi3): 1.830e-01\n",
      "Epoch 31800, Train loss: 1.757e+06, Test loss: 1.627e+07, MSE(e): 1.715e-01, MSE(pi1): 2.414e+00, MSE(pi2): 6.844e-02, MSE(pi3): 1.829e-01\n",
      "Epoch 31900, Train loss: 1.757e+06, Test loss: 1.629e+07, MSE(e): 1.714e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.840e-02, MSE(pi3): 1.830e-01\n",
      "Epoch 32000, Train loss: 1.756e+06, Test loss: 1.632e+07, MSE(e): 1.713e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.835e-02, MSE(pi3): 1.829e-01\n",
      "Epoch 32100, Train loss: 1.755e+06, Test loss: 1.635e+07, MSE(e): 1.713e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.830e-02, MSE(pi3): 1.829e-01\n",
      "Epoch 32200, Train loss: 1.755e+06, Test loss: 1.638e+07, MSE(e): 1.712e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.825e-02, MSE(pi3): 1.829e-01\n",
      "Epoch 32300, Train loss: 1.754e+06, Test loss: 1.641e+07, MSE(e): 1.712e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.821e-02, MSE(pi3): 1.828e-01\n",
      "Epoch 32400, Train loss: 1.754e+06, Test loss: 1.644e+07, MSE(e): 1.711e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.817e-02, MSE(pi3): 1.828e-01\n",
      "Epoch 32500, Train loss: 1.753e+06, Test loss: 1.647e+07, MSE(e): 1.711e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.812e-02, MSE(pi3): 1.828e-01\n",
      "Epoch 32600, Train loss: 1.753e+06, Test loss: 1.650e+07, MSE(e): 1.710e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.808e-02, MSE(pi3): 1.828e-01\n",
      "Epoch 32700, Train loss: 1.752e+06, Test loss: 1.653e+07, MSE(e): 1.710e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.803e-02, MSE(pi3): 1.828e-01\n",
      "Epoch 32800, Train loss: 1.751e+06, Test loss: 1.657e+07, MSE(e): 1.709e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.799e-02, MSE(pi3): 1.828e-01\n",
      "Epoch 32900, Train loss: 1.751e+06, Test loss: 1.660e+07, MSE(e): 1.708e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.795e-02, MSE(pi3): 1.828e-01\n",
      "Epoch 33000, Train loss: 1.750e+06, Test loss: 1.663e+07, MSE(e): 1.708e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.791e-02, MSE(pi3): 1.827e-01\n",
      "Epoch 33100, Train loss: 1.750e+06, Test loss: 1.666e+07, MSE(e): 1.707e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.787e-02, MSE(pi3): 1.827e-01\n",
      "Epoch 33200, Train loss: 1.749e+06, Test loss: 1.669e+07, MSE(e): 1.707e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.783e-02, MSE(pi3): 1.827e-01\n",
      "Epoch 33300, Train loss: 1.749e+06, Test loss: 1.673e+07, MSE(e): 1.706e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.779e-02, MSE(pi3): 1.827e-01\n",
      "Epoch 33400, Train loss: 1.748e+06, Test loss: 1.675e+07, MSE(e): 1.706e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.774e-02, MSE(pi3): 1.827e-01\n",
      "Epoch 33500, Train loss: 1.748e+06, Test loss: 1.679e+07, MSE(e): 1.705e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.770e-02, MSE(pi3): 1.827e-01\n",
      "Epoch 33600, Train loss: 1.747e+06, Test loss: 1.682e+07, MSE(e): 1.705e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.766e-02, MSE(pi3): 1.827e-01\n",
      "Epoch 33700, Train loss: 1.747e+06, Test loss: 1.685e+07, MSE(e): 1.705e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.762e-02, MSE(pi3): 1.827e-01\n",
      "Epoch 33800, Train loss: 1.746e+06, Test loss: 1.688e+07, MSE(e): 1.704e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.759e-02, MSE(pi3): 1.826e-01\n",
      "Epoch 33900, Train loss: 1.746e+06, Test loss: 1.691e+07, MSE(e): 1.704e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.755e-02, MSE(pi3): 1.826e-01\n",
      "Epoch 34000, Train loss: 1.746e+06, Test loss: 1.695e+07, MSE(e): 1.703e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.751e-02, MSE(pi3): 1.826e-01\n",
      "Epoch 34100, Train loss: 1.745e+06, Test loss: 1.698e+07, MSE(e): 1.703e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.748e-02, MSE(pi3): 1.826e-01\n",
      "Epoch 34200, Train loss: 1.745e+06, Test loss: 1.701e+07, MSE(e): 1.702e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.745e-02, MSE(pi3): 1.826e-01\n",
      "Epoch 34300, Train loss: 1.744e+06, Test loss: 1.704e+07, MSE(e): 1.702e-01, MSE(pi1): 2.413e+00, MSE(pi2): 6.741e-02, MSE(pi3): 1.826e-01\n",
      "Epoch 34400, Train loss: 1.744e+06, Test loss: 1.707e+07, MSE(e): 1.701e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.738e-02, MSE(pi3): 1.825e-01\n",
      "Epoch 34500, Train loss: 1.743e+06, Test loss: 1.710e+07, MSE(e): 1.701e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.734e-02, MSE(pi3): 1.825e-01\n",
      "Epoch 34600, Train loss: 1.743e+06, Test loss: 1.713e+07, MSE(e): 1.700e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.731e-02, MSE(pi3): 1.825e-01\n",
      "Epoch 34700, Train loss: 1.742e+06, Test loss: 1.716e+07, MSE(e): 1.700e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.728e-02, MSE(pi3): 1.825e-01\n",
      "Epoch 34800, Train loss: 1.742e+06, Test loss: 1.719e+07, MSE(e): 1.699e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.724e-02, MSE(pi3): 1.825e-01\n",
      "Epoch 34900, Train loss: 1.741e+06, Test loss: 1.722e+07, MSE(e): 1.699e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.721e-02, MSE(pi3): 1.825e-01\n",
      "Epoch 35000, Train loss: 1.741e+06, Test loss: 1.724e+07, MSE(e): 1.699e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.718e-02, MSE(pi3): 1.825e-01\n",
      "Epoch 35100, Train loss: 1.741e+06, Test loss: 1.728e+07, MSE(e): 1.698e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.716e-02, MSE(pi3): 1.825e-01\n",
      "Epoch 35200, Train loss: 1.740e+06, Test loss: 1.729e+07, MSE(e): 1.698e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.712e-02, MSE(pi3): 1.825e-01\n",
      "Epoch 35300, Train loss: 1.740e+06, Test loss: 1.733e+07, MSE(e): 1.697e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.709e-02, MSE(pi3): 1.824e-01\n",
      "Epoch 35400, Train loss: 1.739e+06, Test loss: 1.736e+07, MSE(e): 1.697e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.706e-02, MSE(pi3): 1.824e-01\n",
      "Epoch 35500, Train loss: 1.739e+06, Test loss: 1.739e+07, MSE(e): 1.696e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.704e-02, MSE(pi3): 1.824e-01\n",
      "Epoch 35600, Train loss: 1.738e+06, Test loss: 1.741e+07, MSE(e): 1.696e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.701e-02, MSE(pi3): 1.824e-01\n",
      "Epoch 35700, Train loss: 1.738e+06, Test loss: 1.744e+07, MSE(e): 1.696e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.698e-02, MSE(pi3): 1.824e-01\n",
      "Epoch 35800, Train loss: 1.738e+06, Test loss: 1.747e+07, MSE(e): 1.695e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.695e-02, MSE(pi3): 1.824e-01\n",
      "Epoch 35900, Train loss: 1.737e+06, Test loss: 1.749e+07, MSE(e): 1.695e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.693e-02, MSE(pi3): 1.824e-01\n",
      "Epoch 36000, Train loss: 1.737e+06, Test loss: 1.752e+07, MSE(e): 1.694e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.690e-02, MSE(pi3): 1.823e-01\n",
      "Epoch 36100, Train loss: 1.736e+06, Test loss: 1.754e+07, MSE(e): 1.694e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.687e-02, MSE(pi3): 1.823e-01\n",
      "Epoch 36200, Train loss: 1.736e+06, Test loss: 1.756e+07, MSE(e): 1.694e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.685e-02, MSE(pi3): 1.823e-01\n",
      "Epoch 36300, Train loss: 1.736e+06, Test loss: 1.759e+07, MSE(e): 1.693e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.682e-02, MSE(pi3): 1.823e-01\n",
      "Epoch 36400, Train loss: 1.735e+06, Test loss: 1.761e+07, MSE(e): 1.693e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.679e-02, MSE(pi3): 1.823e-01\n",
      "Epoch 36500, Train loss: 1.735e+06, Test loss: 1.764e+07, MSE(e): 1.692e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.678e-02, MSE(pi3): 1.823e-01\n",
      "Epoch 36600, Train loss: 1.735e+06, Test loss: 1.764e+07, MSE(e): 1.692e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.675e-02, MSE(pi3): 1.823e-01\n",
      "Epoch 36700, Train loss: 1.734e+06, Test loss: 1.768e+07, MSE(e): 1.692e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.672e-02, MSE(pi3): 1.823e-01\n",
      "Epoch 36800, Train loss: 1.734e+06, Test loss: 1.771e+07, MSE(e): 1.691e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.671e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 36900, Train loss: 1.733e+06, Test loss: 1.773e+07, MSE(e): 1.691e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.668e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 37000, Train loss: 1.733e+06, Test loss: 1.775e+07, MSE(e): 1.691e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.666e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 37100, Train loss: 1.733e+06, Test loss: 1.777e+07, MSE(e): 1.690e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.664e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 37200, Train loss: 1.732e+06, Test loss: 1.781e+07, MSE(e): 1.690e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.663e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 37300, Train loss: 1.732e+06, Test loss: 1.782e+07, MSE(e): 1.690e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.660e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 37400, Train loss: 1.732e+06, Test loss: 1.783e+07, MSE(e): 1.689e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.658e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 37500, Train loss: 1.731e+06, Test loss: 1.786e+07, MSE(e): 1.689e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.655e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 37600, Train loss: 1.731e+06, Test loss: 1.788e+07, MSE(e): 1.689e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.654e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 37700, Train loss: 1.731e+06, Test loss: 1.790e+07, MSE(e): 1.688e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.652e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 37800, Train loss: 1.730e+06, Test loss: 1.792e+07, MSE(e): 1.688e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.650e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 37900, Train loss: 1.730e+06, Test loss: 1.793e+07, MSE(e): 1.688e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.648e-02, MSE(pi3): 1.822e-01\n",
      "Epoch 38000, Train loss: 1.730e+06, Test loss: 1.798e+07, MSE(e): 1.687e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.647e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 38100, Train loss: 1.729e+06, Test loss: 1.799e+07, MSE(e): 1.687e-01, MSE(pi1): 2.412e+00, MSE(pi2): 6.644e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 38200, Train loss: 1.729e+06, Test loss: 1.801e+07, MSE(e): 1.687e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.643e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 38300, Train loss: 1.729e+06, Test loss: 1.803e+07, MSE(e): 1.686e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.641e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 38400, Train loss: 1.728e+06, Test loss: 1.805e+07, MSE(e): 1.686e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.640e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 38500, Train loss: 1.728e+06, Test loss: 1.807e+07, MSE(e): 1.686e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.637e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 38600, Train loss: 1.728e+06, Test loss: 1.809e+07, MSE(e): 1.685e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.636e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 38700, Train loss: 1.727e+06, Test loss: 1.812e+07, MSE(e): 1.685e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.635e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 38800, Train loss: 1.727e+06, Test loss: 1.814e+07, MSE(e): 1.685e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.633e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 38900, Train loss: 1.727e+06, Test loss: 1.817e+07, MSE(e): 1.684e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.632e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 39000, Train loss: 1.726e+06, Test loss: 1.818e+07, MSE(e): 1.684e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.629e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 39100, Train loss: 1.726e+06, Test loss: 1.821e+07, MSE(e): 1.684e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.628e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 39200, Train loss: 1.726e+06, Test loss: 1.823e+07, MSE(e): 1.683e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.627e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 39300, Train loss: 1.726e+06, Test loss: 1.825e+07, MSE(e): 1.683e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.625e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 39400, Train loss: 1.725e+06, Test loss: 1.828e+07, MSE(e): 1.683e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.623e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 39500, Train loss: 1.725e+06, Test loss: 1.829e+07, MSE(e): 1.683e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.622e-02, MSE(pi3): 1.821e-01\n",
      "Epoch 39600, Train loss: 1.725e+06, Test loss: 1.832e+07, MSE(e): 1.682e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.620e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 39700, Train loss: 1.724e+06, Test loss: 1.834e+07, MSE(e): 1.682e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.619e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 39800, Train loss: 1.724e+06, Test loss: 1.837e+07, MSE(e): 1.682e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.618e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 39900, Train loss: 1.724e+06, Test loss: 1.839e+07, MSE(e): 1.681e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.616e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 40000, Train loss: 1.723e+06, Test loss: 1.842e+07, MSE(e): 1.681e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.615e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 40100, Train loss: 1.723e+06, Test loss: 1.844e+07, MSE(e): 1.681e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.613e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 40200, Train loss: 1.723e+06, Test loss: 1.847e+07, MSE(e): 1.681e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.612e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 40300, Train loss: 1.723e+06, Test loss: 1.849e+07, MSE(e): 1.680e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.611e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 40400, Train loss: 1.722e+06, Test loss: 1.851e+07, MSE(e): 1.680e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.610e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 40500, Train loss: 1.722e+06, Test loss: 1.854e+07, MSE(e): 1.680e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.608e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 40600, Train loss: 1.722e+06, Test loss: 1.856e+07, MSE(e): 1.679e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.607e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 40700, Train loss: 1.722e+06, Test loss: 1.859e+07, MSE(e): 1.679e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.606e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 40800, Train loss: 1.721e+06, Test loss: 1.862e+07, MSE(e): 1.679e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.604e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 40900, Train loss: 1.721e+06, Test loss: 1.864e+07, MSE(e): 1.679e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.603e-02, MSE(pi3): 1.820e-01\n",
      "Epoch 41000, Train loss: 1.721e+06, Test loss: 1.867e+07, MSE(e): 1.678e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.602e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 41100, Train loss: 1.721e+06, Test loss: 1.869e+07, MSE(e): 1.678e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.600e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 41200, Train loss: 1.720e+06, Test loss: 1.872e+07, MSE(e): 1.678e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.599e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 41300, Train loss: 1.720e+06, Test loss: 1.875e+07, MSE(e): 1.678e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.598e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 41400, Train loss: 1.720e+06, Test loss: 1.878e+07, MSE(e): 1.677e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.597e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 41500, Train loss: 1.719e+06, Test loss: 1.880e+07, MSE(e): 1.677e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.596e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 41600, Train loss: 1.719e+06, Test loss: 1.883e+07, MSE(e): 1.677e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.594e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 41700, Train loss: 1.719e+06, Test loss: 1.885e+07, MSE(e): 1.677e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.593e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 41800, Train loss: 1.719e+06, Test loss: 1.888e+07, MSE(e): 1.676e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.592e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 41900, Train loss: 1.718e+06, Test loss: 1.891e+07, MSE(e): 1.676e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.590e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 42000, Train loss: 1.718e+06, Test loss: 1.894e+07, MSE(e): 1.676e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.590e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 42100, Train loss: 1.718e+06, Test loss: 1.897e+07, MSE(e): 1.676e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.589e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 42200, Train loss: 1.718e+06, Test loss: 1.900e+07, MSE(e): 1.675e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.587e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 42300, Train loss: 1.717e+06, Test loss: 1.902e+07, MSE(e): 1.675e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.586e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 42400, Train loss: 1.717e+06, Test loss: 1.905e+07, MSE(e): 1.675e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.585e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 42500, Train loss: 1.717e+06, Test loss: 1.908e+07, MSE(e): 1.675e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.584e-02, MSE(pi3): 1.819e-01\n",
      "Epoch 42600, Train loss: 1.717e+06, Test loss: 1.911e+07, MSE(e): 1.674e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.584e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 42700, Train loss: 1.716e+06, Test loss: 1.914e+07, MSE(e): 1.674e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.582e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 42800, Train loss: 1.716e+06, Test loss: 1.917e+07, MSE(e): 1.674e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.580e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 42900, Train loss: 1.716e+06, Test loss: 1.920e+07, MSE(e): 1.674e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.579e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 43000, Train loss: 1.716e+06, Test loss: 1.923e+07, MSE(e): 1.673e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.578e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 43100, Train loss: 1.716e+06, Test loss: 1.926e+07, MSE(e): 1.673e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.577e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 43200, Train loss: 1.715e+06, Test loss: 1.929e+07, MSE(e): 1.673e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.576e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 43300, Train loss: 1.715e+06, Test loss: 1.931e+07, MSE(e): 1.673e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.574e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 43400, Train loss: 1.715e+06, Test loss: 1.935e+07, MSE(e): 1.672e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.574e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 43500, Train loss: 1.715e+06, Test loss: 1.938e+07, MSE(e): 1.672e-01, MSE(pi1): 2.411e+00, MSE(pi2): 6.573e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 43600, Train loss: 1.714e+06, Test loss: 1.941e+07, MSE(e): 1.672e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.572e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 43700, Train loss: 1.714e+06, Test loss: 1.943e+07, MSE(e): 1.672e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.570e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 43800, Train loss: 1.714e+06, Test loss: 1.947e+07, MSE(e): 1.672e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.569e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 43900, Train loss: 1.714e+06, Test loss: 1.950e+07, MSE(e): 1.671e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.568e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 44000, Train loss: 1.713e+06, Test loss: 1.952e+07, MSE(e): 1.671e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.567e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 44100, Train loss: 1.713e+06, Test loss: 1.956e+07, MSE(e): 1.671e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.566e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 44200, Train loss: 1.713e+06, Test loss: 1.959e+07, MSE(e): 1.671e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.565e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 44300, Train loss: 1.713e+06, Test loss: 1.962e+07, MSE(e): 1.670e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.564e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 44400, Train loss: 1.713e+06, Test loss: 1.965e+07, MSE(e): 1.670e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.563e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 44500, Train loss: 1.712e+06, Test loss: 1.968e+07, MSE(e): 1.670e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.562e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 44600, Train loss: 1.712e+06, Test loss: 1.971e+07, MSE(e): 1.670e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.561e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 44700, Train loss: 1.712e+06, Test loss: 1.974e+07, MSE(e): 1.670e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.560e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 44800, Train loss: 1.712e+06, Test loss: 1.977e+07, MSE(e): 1.669e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.559e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 44900, Train loss: 1.711e+06, Test loss: 1.980e+07, MSE(e): 1.669e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.558e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 45000, Train loss: 1.711e+06, Test loss: 1.981e+07, MSE(e): 1.669e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.558e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 45100, Train loss: 1.711e+06, Test loss: 1.986e+07, MSE(e): 1.669e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.556e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 45200, Train loss: 1.711e+06, Test loss: 1.990e+07, MSE(e): 1.669e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.556e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 45300, Train loss: 1.711e+06, Test loss: 1.992e+07, MSE(e): 1.668e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.554e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 45400, Train loss: 1.710e+06, Test loss: 1.995e+07, MSE(e): 1.668e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.553e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 45500, Train loss: 1.710e+06, Test loss: 1.998e+07, MSE(e): 1.668e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.552e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 45600, Train loss: 1.710e+06, Test loss: 2.001e+07, MSE(e): 1.668e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.551e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 45700, Train loss: 1.710e+06, Test loss: 2.004e+07, MSE(e): 1.667e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.551e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 45800, Train loss: 1.710e+06, Test loss: 2.007e+07, MSE(e): 1.667e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.549e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 45900, Train loss: 1.709e+06, Test loss: 2.010e+07, MSE(e): 1.667e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.548e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 46000, Train loss: 1.709e+06, Test loss: 2.013e+07, MSE(e): 1.667e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.547e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 46100, Train loss: 1.709e+06, Test loss: 2.016e+07, MSE(e): 1.667e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.546e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 46200, Train loss: 1.709e+06, Test loss: 2.019e+07, MSE(e): 1.666e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.545e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 46300, Train loss: 1.709e+06, Test loss: 2.022e+07, MSE(e): 1.666e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.544e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 46400, Train loss: 1.708e+06, Test loss: 2.025e+07, MSE(e): 1.666e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.543e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 46500, Train loss: 1.708e+06, Test loss: 2.028e+07, MSE(e): 1.666e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.542e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 46600, Train loss: 1.708e+06, Test loss: 2.030e+07, MSE(e): 1.666e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.542e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 46700, Train loss: 1.708e+06, Test loss: 2.033e+07, MSE(e): 1.665e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.541e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 46800, Train loss: 1.708e+06, Test loss: 2.036e+07, MSE(e): 1.665e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.540e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 46900, Train loss: 1.707e+06, Test loss: 2.039e+07, MSE(e): 1.665e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.539e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 47000, Train loss: 1.707e+06, Test loss: 2.042e+07, MSE(e): 1.665e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.538e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 47100, Train loss: 1.707e+06, Test loss: 2.045e+07, MSE(e): 1.665e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.537e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 47200, Train loss: 1.707e+06, Test loss: 2.047e+07, MSE(e): 1.664e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.536e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 47300, Train loss: 1.707e+06, Test loss: 2.052e+07, MSE(e): 1.664e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.537e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 47400, Train loss: 1.706e+06, Test loss: 2.053e+07, MSE(e): 1.664e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.535e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 47500, Train loss: 1.706e+06, Test loss: 2.056e+07, MSE(e): 1.664e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.534e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 47600, Train loss: 1.706e+06, Test loss: 2.059e+07, MSE(e): 1.664e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.533e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 47700, Train loss: 1.706e+06, Test loss: 2.061e+07, MSE(e): 1.663e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.532e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 47800, Train loss: 1.706e+06, Test loss: 2.066e+07, MSE(e): 1.664e-01, MSE(pi1): 2.410e+00, MSE(pi2): 6.535e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 47900, Train loss: 1.705e+06, Test loss: 2.067e+07, MSE(e): 1.663e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.530e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 48000, Train loss: 1.705e+06, Test loss: 2.069e+07, MSE(e): 1.663e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.530e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 48100, Train loss: 1.705e+06, Test loss: 2.073e+07, MSE(e): 1.663e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.529e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 48200, Train loss: 1.705e+06, Test loss: 2.075e+07, MSE(e): 1.663e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.528e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 48300, Train loss: 1.705e+06, Test loss: 2.078e+07, MSE(e): 1.662e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.527e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 48400, Train loss: 1.704e+06, Test loss: 2.080e+07, MSE(e): 1.662e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.526e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 48500, Train loss: 1.704e+06, Test loss: 2.083e+07, MSE(e): 1.662e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.526e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 48600, Train loss: 1.704e+06, Test loss: 2.085e+07, MSE(e): 1.662e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.525e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 48700, Train loss: 1.704e+06, Test loss: 2.088e+07, MSE(e): 1.662e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.524e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 48800, Train loss: 1.704e+06, Test loss: 2.090e+07, MSE(e): 1.661e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.523e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 48900, Train loss: 1.704e+06, Test loss: 2.092e+07, MSE(e): 1.661e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.523e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 49000, Train loss: 1.703e+06, Test loss: 2.095e+07, MSE(e): 1.661e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.522e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 49100, Train loss: 1.703e+06, Test loss: 2.098e+07, MSE(e): 1.661e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.521e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 49200, Train loss: 1.703e+06, Test loss: 2.101e+07, MSE(e): 1.661e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.520e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 49300, Train loss: 1.703e+06, Test loss: 2.103e+07, MSE(e): 1.661e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.520e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 49400, Train loss: 1.703e+06, Test loss: 2.105e+07, MSE(e): 1.660e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.519e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 49500, Train loss: 1.702e+06, Test loss: 2.108e+07, MSE(e): 1.660e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.518e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 49600, Train loss: 1.702e+06, Test loss: 2.110e+07, MSE(e): 1.660e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.518e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 49700, Train loss: 1.702e+06, Test loss: 2.113e+07, MSE(e): 1.660e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.517e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 49800, Train loss: 1.702e+06, Test loss: 2.115e+07, MSE(e): 1.660e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.516e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 49900, Train loss: 1.702e+06, Test loss: 2.118e+07, MSE(e): 1.660e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.517e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 50000, Train loss: 1.702e+06, Test loss: 2.120e+07, MSE(e): 1.659e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.515e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 50100, Train loss: 1.701e+06, Test loss: 2.122e+07, MSE(e): 1.659e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.514e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 50200, Train loss: 1.701e+06, Test loss: 2.124e+07, MSE(e): 1.659e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.513e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 50300, Train loss: 1.701e+06, Test loss: 2.126e+07, MSE(e): 1.659e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.513e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 50400, Train loss: 1.701e+06, Test loss: 2.129e+07, MSE(e): 1.659e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.511e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 50500, Train loss: 1.701e+06, Test loss: 2.131e+07, MSE(e): 1.658e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.511e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 50600, Train loss: 1.701e+06, Test loss: 2.133e+07, MSE(e): 1.658e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.510e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 50700, Train loss: 1.700e+06, Test loss: 2.136e+07, MSE(e): 1.658e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.510e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 50800, Train loss: 1.700e+06, Test loss: 2.137e+07, MSE(e): 1.658e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.509e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 50900, Train loss: 1.700e+06, Test loss: 2.140e+07, MSE(e): 1.658e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.509e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 51000, Train loss: 1.700e+06, Test loss: 2.142e+07, MSE(e): 1.658e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.508e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 51100, Train loss: 1.700e+06, Test loss: 2.144e+07, MSE(e): 1.657e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.507e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 51200, Train loss: 1.699e+06, Test loss: 2.147e+07, MSE(e): 1.657e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.507e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 51300, Train loss: 1.699e+06, Test loss: 2.148e+07, MSE(e): 1.657e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.506e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 51400, Train loss: 1.699e+06, Test loss: 2.151e+07, MSE(e): 1.657e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.505e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 51500, Train loss: 1.699e+06, Test loss: 2.153e+07, MSE(e): 1.657e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.505e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 51600, Train loss: 1.699e+06, Test loss: 2.155e+07, MSE(e): 1.656e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.504e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 51700, Train loss: 1.699e+06, Test loss: 2.157e+07, MSE(e): 1.656e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.503e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 51800, Train loss: 1.699e+06, Test loss: 2.159e+07, MSE(e): 1.656e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.503e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 51900, Train loss: 1.698e+06, Test loss: 2.160e+07, MSE(e): 1.656e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.502e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 52000, Train loss: 1.698e+06, Test loss: 2.163e+07, MSE(e): 1.656e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.501e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 52100, Train loss: 1.698e+06, Test loss: 2.165e+07, MSE(e): 1.656e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.501e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 52200, Train loss: 1.698e+06, Test loss: 2.167e+07, MSE(e): 1.655e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.500e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 52300, Train loss: 1.698e+06, Test loss: 2.169e+07, MSE(e): 1.655e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.500e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 52400, Train loss: 1.697e+06, Test loss: 2.171e+07, MSE(e): 1.655e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.499e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 52500, Train loss: 1.697e+06, Test loss: 2.173e+07, MSE(e): 1.655e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.498e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 52600, Train loss: 1.697e+06, Test loss: 2.174e+07, MSE(e): 1.655e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.498e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 52700, Train loss: 1.697e+06, Test loss: 2.176e+07, MSE(e): 1.655e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.497e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 52800, Train loss: 1.697e+06, Test loss: 2.178e+07, MSE(e): 1.654e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.497e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 52900, Train loss: 1.697e+06, Test loss: 2.180e+07, MSE(e): 1.654e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.496e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 53000, Train loss: 1.696e+06, Test loss: 2.182e+07, MSE(e): 1.654e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.495e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 53100, Train loss: 1.696e+06, Test loss: 2.184e+07, MSE(e): 1.654e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.495e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 53200, Train loss: 1.696e+06, Test loss: 2.186e+07, MSE(e): 1.654e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.494e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 53300, Train loss: 1.696e+06, Test loss: 2.188e+07, MSE(e): 1.654e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.494e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 53400, Train loss: 1.696e+06, Test loss: 2.189e+07, MSE(e): 1.653e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.493e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 53500, Train loss: 1.696e+06, Test loss: 2.191e+07, MSE(e): 1.653e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.493e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 53600, Train loss: 1.696e+06, Test loss: 2.194e+07, MSE(e): 1.653e-01, MSE(pi1): 2.409e+00, MSE(pi2): 6.494e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 53700, Train loss: 1.695e+06, Test loss: 2.195e+07, MSE(e): 1.653e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.491e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 53800, Train loss: 1.695e+06, Test loss: 2.197e+07, MSE(e): 1.653e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.491e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 53900, Train loss: 1.695e+06, Test loss: 2.198e+07, MSE(e): 1.653e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.490e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 54000, Train loss: 1.695e+06, Test loss: 2.200e+07, MSE(e): 1.653e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.490e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 54100, Train loss: 1.695e+06, Test loss: 2.202e+07, MSE(e): 1.652e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.489e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 54200, Train loss: 1.694e+06, Test loss: 2.203e+07, MSE(e): 1.652e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.489e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 54300, Train loss: 1.694e+06, Test loss: 2.205e+07, MSE(e): 1.652e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.488e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 54400, Train loss: 1.694e+06, Test loss: 2.207e+07, MSE(e): 1.652e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.487e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 54500, Train loss: 1.694e+06, Test loss: 2.208e+07, MSE(e): 1.652e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.487e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 54600, Train loss: 1.694e+06, Test loss: 2.210e+07, MSE(e): 1.652e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.486e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 54700, Train loss: 1.694e+06, Test loss: 2.212e+07, MSE(e): 1.651e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.486e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 54800, Train loss: 1.694e+06, Test loss: 2.213e+07, MSE(e): 1.651e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.485e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 54900, Train loss: 1.693e+06, Test loss: 2.215e+07, MSE(e): 1.651e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.485e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 55000, Train loss: 1.693e+06, Test loss: 2.216e+07, MSE(e): 1.651e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.484e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 55100, Train loss: 1.693e+06, Test loss: 2.218e+07, MSE(e): 1.651e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.484e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 55200, Train loss: 1.693e+06, Test loss: 2.220e+07, MSE(e): 1.651e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.483e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 55300, Train loss: 1.693e+06, Test loss: 2.221e+07, MSE(e): 1.650e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.483e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 55400, Train loss: 1.693e+06, Test loss: 2.223e+07, MSE(e): 1.650e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.482e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 55500, Train loss: 1.692e+06, Test loss: 2.224e+07, MSE(e): 1.650e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.482e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 55600, Train loss: 1.692e+06, Test loss: 2.226e+07, MSE(e): 1.650e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.481e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 55700, Train loss: 1.692e+06, Test loss: 2.228e+07, MSE(e): 1.650e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.480e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 55800, Train loss: 1.692e+06, Test loss: 2.229e+07, MSE(e): 1.650e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.480e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 55900, Train loss: 1.692e+06, Test loss: 2.231e+07, MSE(e): 1.649e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.479e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 56000, Train loss: 1.692e+06, Test loss: 2.232e+07, MSE(e): 1.649e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.479e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 56100, Train loss: 1.691e+06, Test loss: 2.234e+07, MSE(e): 1.649e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.478e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 56200, Train loss: 1.691e+06, Test loss: 2.235e+07, MSE(e): 1.649e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.478e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 56300, Train loss: 1.691e+06, Test loss: 2.237e+07, MSE(e): 1.649e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.477e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 56400, Train loss: 1.691e+06, Test loss: 2.238e+07, MSE(e): 1.649e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.477e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 56500, Train loss: 1.691e+06, Test loss: 2.240e+07, MSE(e): 1.649e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.476e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 56600, Train loss: 1.691e+06, Test loss: 2.242e+07, MSE(e): 1.648e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.477e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 56700, Train loss: 1.691e+06, Test loss: 2.243e+07, MSE(e): 1.648e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.476e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 56800, Train loss: 1.690e+06, Test loss: 2.245e+07, MSE(e): 1.648e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.475e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 56900, Train loss: 1.690e+06, Test loss: 2.246e+07, MSE(e): 1.648e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.474e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 57000, Train loss: 1.690e+06, Test loss: 2.247e+07, MSE(e): 1.648e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.474e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 57100, Train loss: 1.690e+06, Test loss: 2.249e+07, MSE(e): 1.648e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.473e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 57200, Train loss: 1.690e+06, Test loss: 2.250e+07, MSE(e): 1.647e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.473e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 57300, Train loss: 1.690e+06, Test loss: 2.252e+07, MSE(e): 1.647e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.472e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 57400, Train loss: 1.689e+06, Test loss: 2.253e+07, MSE(e): 1.647e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.472e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 57500, Train loss: 1.689e+06, Test loss: 2.255e+07, MSE(e): 1.647e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.472e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 57600, Train loss: 1.689e+06, Test loss: 2.257e+07, MSE(e): 1.647e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.472e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 57700, Train loss: 1.689e+06, Test loss: 2.258e+07, MSE(e): 1.647e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.471e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 57800, Train loss: 1.689e+06, Test loss: 2.259e+07, MSE(e): 1.646e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.470e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 57900, Train loss: 1.689e+06, Test loss: 2.261e+07, MSE(e): 1.646e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.470e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 58000, Train loss: 1.688e+06, Test loss: 2.262e+07, MSE(e): 1.646e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.469e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 58100, Train loss: 1.688e+06, Test loss: 2.264e+07, MSE(e): 1.646e-01, MSE(pi1): 2.408e+00, MSE(pi2): 6.469e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 58200, Train loss: 1.688e+06, Test loss: 2.265e+07, MSE(e): 1.646e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.468e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 58300, Train loss: 1.688e+06, Test loss: 2.267e+07, MSE(e): 1.646e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.468e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 58400, Train loss: 1.688e+06, Test loss: 2.268e+07, MSE(e): 1.646e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.467e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 58500, Train loss: 1.688e+06, Test loss: 2.269e+07, MSE(e): 1.645e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.467e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 58600, Train loss: 1.688e+06, Test loss: 2.271e+07, MSE(e): 1.645e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.466e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 58700, Train loss: 1.687e+06, Test loss: 2.272e+07, MSE(e): 1.645e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.466e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 58800, Train loss: 1.687e+06, Test loss: 2.274e+07, MSE(e): 1.645e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.465e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 58900, Train loss: 1.687e+06, Test loss: 2.276e+07, MSE(e): 1.645e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.465e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 59000, Train loss: 1.687e+06, Test loss: 2.277e+07, MSE(e): 1.645e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.464e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 59100, Train loss: 1.687e+06, Test loss: 2.278e+07, MSE(e): 1.644e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.464e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 59200, Train loss: 1.687e+06, Test loss: 2.280e+07, MSE(e): 1.644e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.463e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 59300, Train loss: 1.686e+06, Test loss: 2.282e+07, MSE(e): 1.644e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.463e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 59400, Train loss: 1.686e+06, Test loss: 2.283e+07, MSE(e): 1.644e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.463e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 59500, Train loss: 1.686e+06, Test loss: 2.285e+07, MSE(e): 1.644e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.462e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 59600, Train loss: 1.686e+06, Test loss: 2.286e+07, MSE(e): 1.644e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.462e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 59700, Train loss: 1.686e+06, Test loss: 2.288e+07, MSE(e): 1.644e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.461e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 59800, Train loss: 1.686e+06, Test loss: 2.289e+07, MSE(e): 1.643e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.461e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 59900, Train loss: 1.686e+06, Test loss: 2.291e+07, MSE(e): 1.643e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.460e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 60000, Train loss: 1.685e+06, Test loss: 2.292e+07, MSE(e): 1.643e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.460e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 60100, Train loss: 1.685e+06, Test loss: 2.294e+07, MSE(e): 1.643e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.460e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 60200, Train loss: 1.685e+06, Test loss: 2.295e+07, MSE(e): 1.643e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.459e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 60300, Train loss: 1.685e+06, Test loss: 2.297e+07, MSE(e): 1.643e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.459e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 60400, Train loss: 1.685e+06, Test loss: 2.299e+07, MSE(e): 1.642e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.458e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 60500, Train loss: 1.685e+06, Test loss: 2.300e+07, MSE(e): 1.642e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.458e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 60600, Train loss: 1.685e+06, Test loss: 2.302e+07, MSE(e): 1.642e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.458e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 60700, Train loss: 1.684e+06, Test loss: 2.303e+07, MSE(e): 1.642e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.457e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 60800, Train loss: 1.684e+06, Test loss: 2.306e+07, MSE(e): 1.642e-01, MSE(pi1): 2.407e+00, MSE(pi2): 6.458e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 60900, Train loss: 1.684e+06, Test loss: 2.306e+07, MSE(e): 1.642e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.456e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 61000, Train loss: 1.684e+06, Test loss: 2.308e+07, MSE(e): 1.642e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.456e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 61100, Train loss: 1.684e+06, Test loss: 2.310e+07, MSE(e): 1.641e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.456e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 61200, Train loss: 1.684e+06, Test loss: 2.311e+07, MSE(e): 1.641e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.455e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 61300, Train loss: 1.683e+06, Test loss: 2.313e+07, MSE(e): 1.641e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.455e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 61400, Train loss: 1.683e+06, Test loss: 2.314e+07, MSE(e): 1.641e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.454e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 61500, Train loss: 1.683e+06, Test loss: 2.316e+07, MSE(e): 1.641e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.454e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 61600, Train loss: 1.683e+06, Test loss: 2.316e+07, MSE(e): 1.641e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.455e-02, MSE(pi3): 1.818e-01\n",
      "Epoch 61700, Train loss: 1.683e+06, Test loss: 2.319e+07, MSE(e): 1.641e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.453e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 61800, Train loss: 1.683e+06, Test loss: 2.320e+07, MSE(e): 1.640e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.452e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 61900, Train loss: 1.683e+06, Test loss: 2.322e+07, MSE(e): 1.640e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.452e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 62000, Train loss: 1.682e+06, Test loss: 2.324e+07, MSE(e): 1.640e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.452e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 62100, Train loss: 1.682e+06, Test loss: 2.326e+07, MSE(e): 1.640e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.452e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 62200, Train loss: 1.682e+06, Test loss: 2.327e+07, MSE(e): 1.640e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.451e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 62300, Train loss: 1.682e+06, Test loss: 2.329e+07, MSE(e): 1.640e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.451e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 62400, Train loss: 1.682e+06, Test loss: 2.330e+07, MSE(e): 1.640e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.451e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 62500, Train loss: 1.682e+06, Test loss: 2.331e+07, MSE(e): 1.639e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.450e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 62600, Train loss: 1.682e+06, Test loss: 2.333e+07, MSE(e): 1.639e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.450e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 62700, Train loss: 1.681e+06, Test loss: 2.335e+07, MSE(e): 1.639e-01, MSE(pi1): 2.406e+00, MSE(pi2): 6.450e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 62800, Train loss: 1.681e+06, Test loss: 2.336e+07, MSE(e): 1.639e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.449e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 62900, Train loss: 1.681e+06, Test loss: 2.339e+07, MSE(e): 1.639e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.449e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 63000, Train loss: 1.681e+06, Test loss: 2.340e+07, MSE(e): 1.639e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.448e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 63100, Train loss: 1.681e+06, Test loss: 2.342e+07, MSE(e): 1.639e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.449e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 63200, Train loss: 1.681e+06, Test loss: 2.343e+07, MSE(e): 1.638e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.448e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 63300, Train loss: 1.681e+06, Test loss: 2.344e+07, MSE(e): 1.638e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.447e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 63400, Train loss: 1.680e+06, Test loss: 2.346e+07, MSE(e): 1.638e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.447e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 63500, Train loss: 1.680e+06, Test loss: 2.348e+07, MSE(e): 1.638e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.447e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 63600, Train loss: 1.680e+06, Test loss: 2.351e+07, MSE(e): 1.638e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.448e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 63700, Train loss: 1.680e+06, Test loss: 2.351e+07, MSE(e): 1.638e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.446e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 63800, Train loss: 1.680e+06, Test loss: 2.354e+07, MSE(e): 1.638e-01, MSE(pi1): 2.405e+00, MSE(pi2): 6.447e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 63900, Train loss: 1.680e+06, Test loss: 2.354e+07, MSE(e): 1.637e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.445e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 64000, Train loss: 1.680e+06, Test loss: 2.355e+07, MSE(e): 1.637e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.445e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 64100, Train loss: 1.679e+06, Test loss: 2.358e+07, MSE(e): 1.637e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.446e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 64200, Train loss: 1.679e+06, Test loss: 2.358e+07, MSE(e): 1.637e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.444e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 64300, Train loss: 1.679e+06, Test loss: 2.360e+07, MSE(e): 1.637e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.444e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 64400, Train loss: 1.679e+06, Test loss: 2.361e+07, MSE(e): 1.637e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.444e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 64500, Train loss: 1.679e+06, Test loss: 2.363e+07, MSE(e): 1.637e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.444e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 64600, Train loss: 1.679e+06, Test loss: 2.365e+07, MSE(e): 1.637e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.444e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 64700, Train loss: 1.679e+06, Test loss: 2.366e+07, MSE(e): 1.636e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.443e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 64800, Train loss: 1.678e+06, Test loss: 2.367e+07, MSE(e): 1.636e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.443e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 64900, Train loss: 1.678e+06, Test loss: 2.369e+07, MSE(e): 1.636e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.442e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 65000, Train loss: 1.678e+06, Test loss: 2.371e+07, MSE(e): 1.636e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.443e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 65100, Train loss: 1.678e+06, Test loss: 2.372e+07, MSE(e): 1.636e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.442e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 65200, Train loss: 1.678e+06, Test loss: 2.373e+07, MSE(e): 1.636e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.442e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 65300, Train loss: 1.678e+06, Test loss: 2.375e+07, MSE(e): 1.636e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.441e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 65400, Train loss: 1.678e+06, Test loss: 2.376e+07, MSE(e): 1.635e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.441e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 65500, Train loss: 1.678e+06, Test loss: 2.378e+07, MSE(e): 1.635e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.441e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 65600, Train loss: 1.677e+06, Test loss: 2.379e+07, MSE(e): 1.635e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.440e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 65700, Train loss: 1.677e+06, Test loss: 2.380e+07, MSE(e): 1.635e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.440e-02, MSE(pi3): 1.817e-01\n",
      "Epoch 65800, Train loss: 1.677e+06, Test loss: 2.382e+07, MSE(e): 1.635e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.440e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 65900, Train loss: 1.677e+06, Test loss: 2.383e+07, MSE(e): 1.635e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.439e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 66000, Train loss: 1.677e+06, Test loss: 2.385e+07, MSE(e): 1.635e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.439e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 66100, Train loss: 1.677e+06, Test loss: 2.386e+07, MSE(e): 1.634e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.439e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 66200, Train loss: 1.677e+06, Test loss: 2.387e+07, MSE(e): 1.634e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.438e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 66300, Train loss: 1.676e+06, Test loss: 2.389e+07, MSE(e): 1.634e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.438e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 66400, Train loss: 1.676e+06, Test loss: 2.390e+07, MSE(e): 1.634e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.438e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 66500, Train loss: 1.676e+06, Test loss: 2.390e+07, MSE(e): 1.634e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.437e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 66600, Train loss: 1.676e+06, Test loss: 2.393e+07, MSE(e): 1.634e-01, MSE(pi1): 2.404e+00, MSE(pi2): 6.437e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 66700, Train loss: 1.676e+06, Test loss: 2.394e+07, MSE(e): 1.634e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.437e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 66800, Train loss: 1.676e+06, Test loss: 2.395e+07, MSE(e): 1.634e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.437e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 66900, Train loss: 1.676e+06, Test loss: 2.397e+07, MSE(e): 1.633e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.436e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 67000, Train loss: 1.676e+06, Test loss: 2.398e+07, MSE(e): 1.633e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.436e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 67100, Train loss: 1.675e+06, Test loss: 2.400e+07, MSE(e): 1.633e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.436e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 67200, Train loss: 1.675e+06, Test loss: 2.401e+07, MSE(e): 1.633e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.436e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 67300, Train loss: 1.675e+06, Test loss: 2.402e+07, MSE(e): 1.633e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.435e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 67400, Train loss: 1.675e+06, Test loss: 2.403e+07, MSE(e): 1.633e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.435e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 67500, Train loss: 1.675e+06, Test loss: 2.405e+07, MSE(e): 1.633e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.435e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 67600, Train loss: 1.675e+06, Test loss: 2.406e+07, MSE(e): 1.633e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.434e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 67700, Train loss: 1.675e+06, Test loss: 2.407e+07, MSE(e): 1.632e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.434e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 67800, Train loss: 1.675e+06, Test loss: 2.408e+07, MSE(e): 1.632e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.434e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 67900, Train loss: 1.674e+06, Test loss: 2.409e+07, MSE(e): 1.632e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.434e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 68000, Train loss: 1.674e+06, Test loss: 2.411e+07, MSE(e): 1.632e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.433e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 68100, Train loss: 1.674e+06, Test loss: 2.412e+07, MSE(e): 1.632e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.433e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 68200, Train loss: 1.674e+06, Test loss: 2.413e+07, MSE(e): 1.632e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.433e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 68300, Train loss: 1.674e+06, Test loss: 2.414e+07, MSE(e): 1.632e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.433e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 68400, Train loss: 1.674e+06, Test loss: 2.416e+07, MSE(e): 1.632e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.433e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 68500, Train loss: 1.674e+06, Test loss: 2.418e+07, MSE(e): 1.632e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.433e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 68600, Train loss: 1.674e+06, Test loss: 2.417e+07, MSE(e): 1.631e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.432e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 68700, Train loss: 1.674e+06, Test loss: 2.419e+07, MSE(e): 1.631e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.432e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 68800, Train loss: 1.673e+06, Test loss: 2.420e+07, MSE(e): 1.631e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.431e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 68900, Train loss: 1.673e+06, Test loss: 2.422e+07, MSE(e): 1.631e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.431e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 69000, Train loss: 1.673e+06, Test loss: 2.423e+07, MSE(e): 1.631e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.431e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 69100, Train loss: 1.673e+06, Test loss: 2.424e+07, MSE(e): 1.631e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.431e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 69200, Train loss: 1.673e+06, Test loss: 2.425e+07, MSE(e): 1.631e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.430e-02, MSE(pi3): 1.816e-01\n",
      "Epoch 69300, Train loss: 1.673e+06, Test loss: 2.426e+07, MSE(e): 1.631e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.430e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 69400, Train loss: 1.673e+06, Test loss: 2.427e+07, MSE(e): 1.631e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.430e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 69500, Train loss: 1.673e+06, Test loss: 2.428e+07, MSE(e): 1.630e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.430e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 69600, Train loss: 1.673e+06, Test loss: 2.429e+07, MSE(e): 1.630e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.429e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 69700, Train loss: 1.672e+06, Test loss: 2.431e+07, MSE(e): 1.630e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.429e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 69800, Train loss: 1.672e+06, Test loss: 2.432e+07, MSE(e): 1.630e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.429e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 69900, Train loss: 1.672e+06, Test loss: 2.432e+07, MSE(e): 1.630e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.428e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 70000, Train loss: 1.672e+06, Test loss: 2.433e+07, MSE(e): 1.630e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.429e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 70100, Train loss: 1.672e+06, Test loss: 2.435e+07, MSE(e): 1.630e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.428e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 70200, Train loss: 1.672e+06, Test loss: 2.436e+07, MSE(e): 1.630e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.428e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 70300, Train loss: 1.672e+06, Test loss: 2.437e+07, MSE(e): 1.629e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.427e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 70400, Train loss: 1.672e+06, Test loss: 2.439e+07, MSE(e): 1.630e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.428e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 70500, Train loss: 1.672e+06, Test loss: 2.439e+07, MSE(e): 1.629e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.427e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 70600, Train loss: 1.671e+06, Test loss: 2.441e+07, MSE(e): 1.629e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.427e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 70700, Train loss: 1.671e+06, Test loss: 2.442e+07, MSE(e): 1.629e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.427e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 70800, Train loss: 1.671e+06, Test loss: 2.443e+07, MSE(e): 1.629e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.426e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 70900, Train loss: 1.671e+06, Test loss: 2.444e+07, MSE(e): 1.629e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.426e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 71000, Train loss: 1.671e+06, Test loss: 2.445e+07, MSE(e): 1.629e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.426e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 71100, Train loss: 1.671e+06, Test loss: 2.446e+07, MSE(e): 1.629e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.426e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 71200, Train loss: 1.671e+06, Test loss: 2.447e+07, MSE(e): 1.629e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.425e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 71300, Train loss: 1.671e+06, Test loss: 2.448e+07, MSE(e): 1.628e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.425e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 71400, Train loss: 1.671e+06, Test loss: 2.449e+07, MSE(e): 1.628e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.425e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 71500, Train loss: 1.670e+06, Test loss: 2.450e+07, MSE(e): 1.628e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.425e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 71600, Train loss: 1.670e+06, Test loss: 2.451e+07, MSE(e): 1.628e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.424e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 71700, Train loss: 1.670e+06, Test loss: 2.452e+07, MSE(e): 1.628e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.424e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 71800, Train loss: 1.670e+06, Test loss: 2.454e+07, MSE(e): 1.628e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.425e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 71900, Train loss: 1.670e+06, Test loss: 2.454e+07, MSE(e): 1.628e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.424e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 72000, Train loss: 1.670e+06, Test loss: 2.455e+07, MSE(e): 1.628e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.424e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 72100, Train loss: 1.670e+06, Test loss: 2.456e+07, MSE(e): 1.628e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.423e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 72200, Train loss: 1.670e+06, Test loss: 2.457e+07, MSE(e): 1.627e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.423e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 72300, Train loss: 1.670e+06, Test loss: 2.458e+07, MSE(e): 1.627e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.423e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 72400, Train loss: 1.670e+06, Test loss: 2.459e+07, MSE(e): 1.627e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.423e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 72500, Train loss: 1.669e+06, Test loss: 2.460e+07, MSE(e): 1.627e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.422e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 72600, Train loss: 1.669e+06, Test loss: 2.461e+07, MSE(e): 1.627e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.422e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 72700, Train loss: 1.669e+06, Test loss: 2.461e+07, MSE(e): 1.627e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.422e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 72800, Train loss: 1.669e+06, Test loss: 2.463e+07, MSE(e): 1.627e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.422e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 72900, Train loss: 1.669e+06, Test loss: 2.464e+07, MSE(e): 1.627e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.422e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 73000, Train loss: 1.669e+06, Test loss: 2.465e+07, MSE(e): 1.627e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.421e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 73100, Train loss: 1.669e+06, Test loss: 2.466e+07, MSE(e): 1.627e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.421e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 73200, Train loss: 1.669e+06, Test loss: 2.467e+07, MSE(e): 1.626e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.421e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 73300, Train loss: 1.669e+06, Test loss: 2.468e+07, MSE(e): 1.626e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.421e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 73400, Train loss: 1.669e+06, Test loss: 2.469e+07, MSE(e): 1.626e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.420e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 73500, Train loss: 1.668e+06, Test loss: 2.470e+07, MSE(e): 1.626e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.421e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 73600, Train loss: 1.668e+06, Test loss: 2.471e+07, MSE(e): 1.626e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.420e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 73700, Train loss: 1.668e+06, Test loss: 2.471e+07, MSE(e): 1.626e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.419e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 73800, Train loss: 1.668e+06, Test loss: 2.473e+07, MSE(e): 1.626e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.420e-02, MSE(pi3): 1.815e-01\n",
      "Epoch 73900, Train loss: 1.668e+06, Test loss: 2.474e+07, MSE(e): 1.626e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.420e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 74000, Train loss: 1.668e+06, Test loss: 2.475e+07, MSE(e): 1.626e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.419e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 74100, Train loss: 1.668e+06, Test loss: 2.475e+07, MSE(e): 1.626e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.419e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 74200, Train loss: 1.668e+06, Test loss: 2.476e+07, MSE(e): 1.625e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.419e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 74300, Train loss: 1.668e+06, Test loss: 2.477e+07, MSE(e): 1.625e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.419e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 74400, Train loss: 1.668e+06, Test loss: 2.477e+07, MSE(e): 1.625e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.418e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 74500, Train loss: 1.667e+06, Test loss: 2.479e+07, MSE(e): 1.625e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.418e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 74600, Train loss: 1.667e+06, Test loss: 2.480e+07, MSE(e): 1.625e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.418e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 74700, Train loss: 1.667e+06, Test loss: 2.481e+07, MSE(e): 1.625e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.418e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 74800, Train loss: 1.668e+06, Test loss: 2.480e+07, MSE(e): 1.625e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.419e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 74900, Train loss: 1.667e+06, Test loss: 2.483e+07, MSE(e): 1.625e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.417e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 75000, Train loss: 1.667e+06, Test loss: 2.484e+07, MSE(e): 1.625e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.417e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 75100, Train loss: 1.667e+06, Test loss: 2.485e+07, MSE(e): 1.625e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.417e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 75200, Train loss: 1.667e+06, Test loss: 2.485e+07, MSE(e): 1.625e-01, MSE(pi1): 2.403e+00, MSE(pi2): 6.417e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 75300, Train loss: 1.667e+06, Test loss: 2.486e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.417e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 75400, Train loss: 1.667e+06, Test loss: 2.487e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.416e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 75500, Train loss: 1.667e+06, Test loss: 2.488e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.416e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 75600, Train loss: 1.666e+06, Test loss: 2.490e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.416e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 75700, Train loss: 1.666e+06, Test loss: 2.490e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.416e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 75800, Train loss: 1.666e+06, Test loss: 2.491e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.416e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 75900, Train loss: 1.666e+06, Test loss: 2.490e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.416e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 76000, Train loss: 1.666e+06, Test loss: 2.493e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.416e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 76100, Train loss: 1.666e+06, Test loss: 2.493e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.415e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 76200, Train loss: 1.666e+06, Test loss: 2.492e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.417e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 76300, Train loss: 1.666e+06, Test loss: 2.495e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.415e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 76400, Train loss: 1.666e+06, Test loss: 2.495e+07, MSE(e): 1.624e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.415e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 76500, Train loss: 1.666e+06, Test loss: 2.497e+07, MSE(e): 1.623e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.414e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 76600, Train loss: 1.666e+06, Test loss: 2.498e+07, MSE(e): 1.623e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.414e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 76700, Train loss: 1.665e+06, Test loss: 2.499e+07, MSE(e): 1.623e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.414e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 76800, Train loss: 1.665e+06, Test loss: 2.500e+07, MSE(e): 1.623e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.414e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 76900, Train loss: 1.665e+06, Test loss: 2.501e+07, MSE(e): 1.623e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.414e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 77000, Train loss: 1.665e+06, Test loss: 2.501e+07, MSE(e): 1.623e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.414e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 77100, Train loss: 1.665e+06, Test loss: 2.501e+07, MSE(e): 1.623e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.412e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 77200, Train loss: 1.665e+06, Test loss: 2.503e+07, MSE(e): 1.623e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.413e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 77300, Train loss: 1.665e+06, Test loss: 2.504e+07, MSE(e): 1.623e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.413e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 77400, Train loss: 1.665e+06, Test loss: 2.505e+07, MSE(e): 1.623e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.413e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 77500, Train loss: 1.665e+06, Test loss: 2.506e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.413e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 77600, Train loss: 1.665e+06, Test loss: 2.507e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.412e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 77700, Train loss: 1.665e+06, Test loss: 2.508e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.413e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 77800, Train loss: 1.664e+06, Test loss: 2.508e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.412e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 77900, Train loss: 1.664e+06, Test loss: 2.509e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.412e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 78000, Train loss: 1.664e+06, Test loss: 2.510e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.412e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 78100, Train loss: 1.664e+06, Test loss: 2.511e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.412e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 78200, Train loss: 1.664e+06, Test loss: 2.513e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.412e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 78300, Train loss: 1.664e+06, Test loss: 2.512e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.411e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 78400, Train loss: 1.664e+06, Test loss: 2.514e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.411e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 78500, Train loss: 1.664e+06, Test loss: 2.514e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.411e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 78600, Train loss: 1.664e+06, Test loss: 2.515e+07, MSE(e): 1.622e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.411e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 78700, Train loss: 1.664e+06, Test loss: 2.516e+07, MSE(e): 1.621e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.410e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 78800, Train loss: 1.664e+06, Test loss: 2.517e+07, MSE(e): 1.621e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.410e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 78900, Train loss: 1.664e+06, Test loss: 2.518e+07, MSE(e): 1.621e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.410e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 79000, Train loss: 1.663e+06, Test loss: 2.519e+07, MSE(e): 1.621e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.410e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 79100, Train loss: 1.663e+06, Test loss: 2.519e+07, MSE(e): 1.621e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.410e-02, MSE(pi3): 1.814e-01\n",
      "Epoch 79200, Train loss: 1.663e+06, Test loss: 2.520e+07, MSE(e): 1.621e-01, MSE(pi1): 2.402e+00, MSE(pi2): 6.409e-02, MSE(pi3): 1.814e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m n_checkpoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      8\u001b[0m second_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m\n\u001b[0;32m---> 10\u001b[0m train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n\u001b[1;32m     11\u001b[0m            D,  n_checkpoints, start_epoch\u001b[38;5;241m=\u001b[39mstart_epoch, n_epochs\u001b[38;5;241m=\u001b[39mn_epochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[1;32m     12\u001b[0m            model_results_path\u001b[38;5;241m=\u001b[39mMODEL_RESULTS_PATH, device\u001b[38;5;241m=\u001b[39mDEVICE, new_lr\u001b[38;5;241m=\u001b[39msecond_lr)\n",
      "File \u001b[0;32m~/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/models/baseline/trainers/train.py:173\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test, D, n_checkpoints, start_epoch, n_epochs, batch_size, model_results_path, device, new_lr)\u001b[0m\n\u001b[1;32m    170\u001b[0m train_pi3_loss_list\u001b[38;5;241m.\u001b[39mappend(pi3_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39mbatch_size)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Evaluate model on the test dataset at the end of each epoch\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m loss_test, e_loss_test, pi1_loss_test, pi2_loss_test, pi3_loss_test \u001b[38;5;241m=\u001b[39m test_epoch(model, X_test, y_test, f_test, D)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Record average test losses\u001b[39;00m\n\u001b[1;32m    176\u001b[0m test_total_loss_list\u001b[38;5;241m.\u001b[39mappend(loss_test\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39mN_test)\n",
      "File \u001b[0;32m~/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/models/baseline/trainers/train.py:63\u001b[0m, in \u001b[0;36mtest_epoch\u001b[0;34m(model, X_test, y_test, f_test, D)\u001b[0m\n\u001b[1;32m     60\u001b[0m y_pred, K_pred \u001b[38;5;241m=\u001b[39m model(X_test)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Compute the total loss and its components for the test data.\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m loss, e_loss, pi1_loss, pi2_loss, pi3_loss \u001b[38;5;241m=\u001b[39m loss_function(X_test, y_test, y_pred, K_pred, f_test, D)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Return the total loss and its components.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, e_loss, pi1_loss, pi2_loss, pi3_loss\n",
      "File \u001b[0;32m~/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/models/baseline/trainers/eval.py:164\u001b[0m, in \u001b[0;36mloss_function\u001b[0;34m(X_true, y_true, y_pred, K_pred, f_true, D)\u001b[0m\n\u001b[1;32m    162\u001b[0m e \u001b[38;5;241m=\u001b[39m MSE(e_constraint(y_true, y_pred))  \n\u001b[1;32m    163\u001b[0m pi1 \u001b[38;5;241m=\u001b[39m MSE(pi1_constraint(y_pred, K_pred, f_true, D))  \n\u001b[0;32m--> 164\u001b[0m pi2 \u001b[38;5;241m=\u001b[39m MSE(pi2_constraint(X_true, y_pred))  \n\u001b[1;32m    165\u001b[0m pi3 \u001b[38;5;241m=\u001b[39m MSE(pi3_constraint(X_true, y_pred, K_pred, D))\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Combine individual losses into a total loss with specific weighting factors.\u001b[39;00m\n",
      "File \u001b[0;32m~/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/models/baseline/trainers/eval.py:73\u001b[0m, in \u001b[0;36mpi2_constraint\u001b[0;34m(X_true, y_pred)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03mComputes a constraint that obtains the difference between the predicted and true boundary conditions.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m   (torch.Tensor): Differences between predicted and true boundary values evaluated along the edges of the domain.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Returns the difference between the boundary values of the prediction y_pred and corresponding true values.\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mconcat([y_pred[:, :, :, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m X_true[:, :, :, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     74\u001b[0m                      y_pred[:, :, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m X_true[:, :, :, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), \n\u001b[1;32m     75\u001b[0m                      y_pred[:, :, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m X_true[:, :, :, \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     76\u001b[0m                      y_pred[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m X_true[:, :, :, \u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     77\u001b[0m                      ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 18000\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "second_lr = 1e-4\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
