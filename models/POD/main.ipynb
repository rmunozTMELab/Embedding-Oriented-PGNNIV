{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from models.POD import PODNonlinearModel\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear/POD_model\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/non_linear/non_linear_1000.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/non_linear')\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/non_linear/POD_model')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya est치n creadas se avisar치 de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear/non_linear_1000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data splitting in train/test\n",
    "X = torch.tensor(dataset['X_train'], dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(dataset['y_train'], dtype=torch.float32).unsqueeze(1)\n",
    "K = torch.tensor(dataset['k_train'], dtype=torch.float32).unsqueeze(1)\n",
    "f = torch.tensor(dataset['f_train'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X, y, K, f, test_size=0.3, random_state=42)\n",
    "\n",
    "# Data processing and adequacy with our TensOps library\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "# Loading and processing validation data\n",
    "X_val = torch.tensor(dataset['X_val'], dtype=torch.float32).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> 0.0\n",
      "1 --> 0.9013104\n",
      "2 --> 0.9483088\n",
      "3 --> 0.9913872\n",
      "4 --> 0.9943512\n",
      "5 --> 0.99668187\n",
      "6 --> 0.99855953\n",
      "7 --> 0.99899775\n",
      "8 --> 0.99935037\n",
      "9 --> 0.99957174\n",
      "10 --> 0.99974585\n",
      "11 --> 0.99981904\n",
      "12 --> 0.9998786\n",
      "13 --> 0.9999184\n",
      "14 --> 0.9999416\n",
      "15 --> 0.99995726\n",
      "16 --> 0.99997175\n",
      "17 --> 0.99997973\n",
      "18 --> 0.9999863\n",
      "19 --> 0.99999046\n"
     ]
    }
   ],
   "source": [
    "U_train, S_train, Vt_train = torch.linalg.svd(y_train.values.detach().squeeze().to('cpu').view(y_train.values.detach().shape[0], -1).T, full_matrices=False)\n",
    "\n",
    "error = []\n",
    "for mode_i in range(len(S_train)):\n",
    "    error.append((sum(S_train[:mode_i])/sum(S_train)).numpy())\n",
    "    if mode_i < 20:\n",
    "        print(mode_i, '-->', error[mode_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci칩n: 0.019629 segundos\n"
     ]
    }
   ],
   "source": [
    "num_modes = 13\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "U_train, S_train, Vt_train = torch.linalg.svd(y_train.values.detach().squeeze().to('cpu').view(y_train.values.detach().shape[0], -1).T, full_matrices=False)\n",
    "\n",
    "U_reduced_train = U_train[:, :num_modes]\n",
    "S_reduced_train = S_train[:num_modes]\n",
    "Vt_reduced_train = Vt_train[:num_modes, :]\n",
    "\n",
    "POD_base = torch.mm(U_reduced_train, torch.diag(S_reduced_train)).to(DEVICE)\n",
    "# y_train = Vt_reduced_train.T\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Tiempo de ejecuci칩n: {end_time - start_time:.6f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, num_modes]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 3.460e+09, Test loss: 1.675e+09, MSE(e): 3.410e+02, MSE(pi1): 4.040e+03, MSE(pi2): 1.359e+02, MSE(pi3): 8.631e+01\n",
      "Epoch 100, Train loss: 4.206e+06, Test loss: 4.721e+06, MSE(e): 4.108e-01, MSE(pi1): 8.381e+00, MSE(pi2): 2.934e-01, MSE(pi3): 1.441e-01\n",
      "Epoch 200, Train loss: 3.398e+06, Test loss: 3.890e+06, MSE(e): 3.354e-01, MSE(pi1): 3.123e+00, MSE(pi2): 2.413e-01, MSE(pi3): 1.225e-01\n",
      "Epoch 300, Train loss: 1.177e+06, Test loss: 1.615e+06, MSE(e): 1.153e-01, MSE(pi1): 1.421e+00, MSE(pi2): 8.267e-02, MSE(pi3): 9.623e-02\n",
      "Epoch 400, Train loss: 1.899e+05, Test loss: 2.377e+05, MSE(e): 1.791e-02, MSE(pi1): 3.074e-01, MSE(pi2): 1.116e-02, MSE(pi3): 7.701e-02\n",
      "Epoch 500, Train loss: 1.395e+05, Test loss: 2.003e+05, MSE(e): 1.313e-02, MSE(pi1): 1.216e-01, MSE(pi2): 8.314e-03, MSE(pi3): 7.031e-02\n",
      "Epoch 600, Train loss: 8.185e+04, Test loss: 1.638e+05, MSE(e): 7.435e-03, MSE(pi1): 1.107e-01, MSE(pi2): 4.728e-03, MSE(pi3): 6.389e-02\n",
      "Epoch 700, Train loss: 2.184e+05, Test loss: 1.530e+05, MSE(e): 2.115e-02, MSE(pi1): 1.062e-01, MSE(pi2): 9.951e-03, MSE(pi3): 5.752e-02\n",
      "Epoch 800, Train loss: 1.094e+06, Test loss: 2.451e+05, MSE(e): 1.088e-01, MSE(pi1): 1.421e-01, MSE(pi2): 4.555e-02, MSE(pi3): 4.864e-02\n",
      "Epoch 900, Train loss: 7.524e+04, Test loss: 1.003e+05, MSE(e): 7.066e-03, MSE(pi1): 1.016e-01, MSE(pi2): 4.404e-03, MSE(pi3): 3.557e-02\n",
      "Epoch 1000, Train loss: 7.972e+04, Test loss: 1.227e+05, MSE(e): 7.597e-03, MSE(pi1): 1.113e-01, MSE(pi2): 4.695e-03, MSE(pi3): 2.633e-02\n",
      "Epoch 1100, Train loss: 6.270e+04, Test loss: 1.013e+05, MSE(e): 5.902e-03, MSE(pi1): 1.730e-01, MSE(pi2): 3.580e-03, MSE(pi3): 1.948e-02\n",
      "Epoch 1200, Train loss: 7.757e+04, Test loss: 1.116e+05, MSE(e): 7.510e-03, MSE(pi1): 6.250e-02, MSE(pi2): 4.471e-03, MSE(pi3): 1.835e-02\n",
      "Epoch 1300, Train loss: 8.226e+04, Test loss: 1.084e+05, MSE(e): 8.048e-03, MSE(pi1): 5.144e-02, MSE(pi2): 4.687e-03, MSE(pi3): 1.266e-02\n",
      "Epoch 1400, Train loss: 3.849e+05, Test loss: 1.984e+06, MSE(e): 3.823e-02, MSE(pi1): 9.620e-02, MSE(pi2): 1.721e-02, MSE(pi3): 1.663e-02\n",
      "Epoch 1500, Train loss: 9.431e+04, Test loss: 8.682e+04, MSE(e): 9.279e-03, MSE(pi1): 5.720e-02, MSE(pi2): 4.526e-03, MSE(pi3): 9.458e-03\n",
      "Epoch 1600, Train loss: 9.595e+04, Test loss: 8.432e+04, MSE(e): 9.474e-03, MSE(pi1): 3.882e-02, MSE(pi2): 4.505e-03, MSE(pi3): 8.171e-03\n",
      "Epoch 1700, Train loss: 1.658e+06, Test loss: 6.749e+05, MSE(e): 1.655e-01, MSE(pi1): 9.304e-02, MSE(pi2): 6.775e-02, MSE(pi3): 1.399e-02\n",
      "Epoch 1800, Train loss: 5.645e+05, Test loss: 1.683e+05, MSE(e): 5.626e-02, MSE(pi1): 7.864e-02, MSE(pi2): 2.365e-02, MSE(pi3): 1.022e-02\n",
      "Epoch 1900, Train loss: 4.243e+04, Test loss: 6.109e+04, MSE(e): 4.135e-03, MSE(pi1): 3.423e-02, MSE(pi2): 2.493e-03, MSE(pi3): 7.446e-03\n",
      "Epoch 2000, Train loss: 3.740e+04, Test loss: 4.646e+04, MSE(e): 3.646e-03, MSE(pi1): 3.101e-02, MSE(pi2): 2.103e-03, MSE(pi3): 6.217e-03\n",
      "Epoch 2100, Train loss: 5.566e+05, Test loss: 1.907e+05, MSE(e): 5.550e-02, MSE(pi1): 1.012e-01, MSE(pi2): 2.565e-02, MSE(pi3): 6.320e-03\n",
      "Epoch 2200, Train loss: 3.130e+04, Test loss: 4.025e+04, MSE(e): 2.972e-03, MSE(pi1): 3.250e-02, MSE(pi2): 1.678e-03, MSE(pi3): 1.247e-02\n",
      "Epoch 2300, Train loss: 3.150e+04, Test loss: 3.610e+04, MSE(e): 3.038e-03, MSE(pi1): 3.064e-02, MSE(pi2): 1.518e-03, MSE(pi3): 8.156e-03\n",
      "Epoch 2400, Train loss: 2.236e+05, Test loss: 9.662e+04, MSE(e): 2.221e-02, MSE(pi1): 9.215e-02, MSE(pi2): 8.271e-03, MSE(pi3): 6.339e-03\n",
      "Epoch 2500, Train loss: 2.501e+04, Test loss: 3.072e+04, MSE(e): 2.424e-03, MSE(pi1): 3.496e-02, MSE(pi2): 1.223e-03, MSE(pi3): 4.162e-03\n",
      "Epoch 2600, Train loss: 6.247e+04, Test loss: 6.883e+04, MSE(e): 6.152e-03, MSE(pi1): 5.786e-02, MSE(pi2): 3.425e-03, MSE(pi3): 3.765e-03\n",
      "Epoch 2700, Train loss: 3.007e+05, Test loss: 2.250e+05, MSE(e): 2.998e-02, MSE(pi1): 6.344e-02, MSE(pi2): 1.203e-02, MSE(pi3): 2.625e-03\n",
      "Epoch 2800, Train loss: 2.188e+04, Test loss: 2.534e+04, MSE(e): 2.151e-03, MSE(pi1): 1.592e-02, MSE(pi2): 1.068e-03, MSE(pi3): 2.064e-03\n",
      "Epoch 2900, Train loss: 3.828e+05, Test loss: 4.915e+04, MSE(e): 3.821e-02, MSE(pi1): 3.393e-02, MSE(pi2): 1.463e-02, MSE(pi3): 3.452e-03\n",
      "Epoch 3000, Train loss: 4.479e+04, Test loss: 5.805e+04, MSE(e): 4.402e-03, MSE(pi1): 5.037e-02, MSE(pi2): 3.112e-03, MSE(pi3): 2.610e-03\n",
      "Epoch 3100, Train loss: 1.845e+04, Test loss: 2.544e+04, MSE(e): 1.786e-03, MSE(pi1): 1.969e-02, MSE(pi2): 9.313e-04, MSE(pi3): 3.870e-03\n",
      "Epoch 3200, Train loss: 1.669e+05, Test loss: 1.027e+05, MSE(e): 1.662e-02, MSE(pi1): 3.457e-02, MSE(pi2): 6.579e-03, MSE(pi3): 2.603e-03\n",
      "Epoch 3300, Train loss: 3.873e+05, Test loss: 1.136e+05, MSE(e): 3.868e-02, MSE(pi1): 3.253e-02, MSE(pi2): 1.526e-02, MSE(pi3): 1.802e-03\n",
      "Epoch 3400, Train loss: 1.376e+04, Test loss: 2.551e+04, MSE(e): 1.350e-03, MSE(pi1): 1.347e-02, MSE(pi2): 7.796e-04, MSE(pi3): 1.230e-03\n",
      "Epoch 3500, Train loss: 1.123e+04, Test loss: 2.175e+04, MSE(e): 1.101e-03, MSE(pi1): 8.496e-03, MSE(pi2): 6.505e-04, MSE(pi3): 1.334e-03\n",
      "Epoch 3600, Train loss: 5.592e+04, Test loss: 3.648e+04, MSE(e): 5.535e-03, MSE(pi1): 2.751e-02, MSE(pi2): 3.923e-03, MSE(pi3): 2.919e-03\n",
      "Epoch 3700, Train loss: 1.379e+04, Test loss: 1.759e+04, MSE(e): 1.361e-03, MSE(pi1): 7.299e-03, MSE(pi2): 7.343e-04, MSE(pi3): 1.034e-03\n",
      "Epoch 3800, Train loss: 8.740e+03, Test loss: 1.540e+04, MSE(e): 8.559e-04, MSE(pi1): 6.353e-03, MSE(pi2): 5.286e-04, MSE(pi3): 1.171e-03\n",
      "Epoch 3900, Train loss: 8.883e+03, Test loss: 1.355e+04, MSE(e): 8.712e-04, MSE(pi1): 6.588e-03, MSE(pi2): 5.217e-04, MSE(pi3): 1.047e-03\n",
      "Epoch 4000, Train loss: 1.697e+04, Test loss: 1.271e+04, MSE(e): 1.678e-03, MSE(pi1): 5.577e-03, MSE(pi2): 8.132e-04, MSE(pi3): 1.288e-03\n",
      "Epoch 4100, Train loss: 6.835e+03, Test loss: 1.411e+04, MSE(e): 6.658e-04, MSE(pi1): 7.533e-03, MSE(pi2): 4.068e-04, MSE(pi3): 1.006e-03\n",
      "Epoch 4200, Train loss: 2.557e+04, Test loss: 2.505e+05, MSE(e): 2.527e-03, MSE(pi1): 1.444e-02, MSE(pi2): 1.268e-03, MSE(pi3): 1.518e-03\n",
      "Epoch 4300, Train loss: 6.165e+04, Test loss: 8.689e+04, MSE(e): 6.140e-03, MSE(pi1): 1.274e-02, MSE(pi2): 2.537e-03, MSE(pi3): 1.226e-03\n",
      "Epoch 4400, Train loss: 9.108e+04, Test loss: 8.439e+04, MSE(e): 9.053e-03, MSE(pi1): 3.114e-02, MSE(pi2): 4.571e-03, MSE(pi3): 2.411e-03\n",
      "Epoch 4500, Train loss: 7.053e+03, Test loss: 1.248e+04, MSE(e): 6.886e-04, MSE(pi1): 5.508e-03, MSE(pi2): 4.009e-04, MSE(pi3): 1.119e-03\n",
      "Epoch 4600, Train loss: 1.230e+04, Test loss: 1.904e+04, MSE(e): 1.208e-03, MSE(pi1): 9.405e-03, MSE(pi2): 6.700e-04, MSE(pi3): 1.275e-03\n",
      "Epoch 4700, Train loss: 1.218e+04, Test loss: 2.008e+04, MSE(e): 1.199e-03, MSE(pi1): 8.350e-03, MSE(pi2): 7.036e-04, MSE(pi3): 1.070e-03\n",
      "Epoch 4800, Train loss: 1.564e+04, Test loss: 3.568e+04, MSE(e): 1.542e-03, MSE(pi1): 9.747e-03, MSE(pi2): 8.473e-04, MSE(pi3): 1.253e-03\n",
      "Epoch 4900, Train loss: 2.798e+04, Test loss: 5.456e+04, MSE(e): 2.777e-03, MSE(pi1): 9.208e-03, MSE(pi2): 1.226e-03, MSE(pi3): 1.135e-03\n",
      "Epoch 5000, Train loss: 5.143e+04, Test loss: 7.088e+04, MSE(e): 5.117e-03, MSE(pi1): 1.365e-02, MSE(pi2): 2.251e-03, MSE(pi3): 1.190e-03\n",
      "Epoch 5100, Train loss: 8.942e+03, Test loss: 1.254e+04, MSE(e): 8.767e-04, MSE(pi1): 5.291e-03, MSE(pi2): 4.849e-04, MSE(pi3): 1.221e-03\n",
      "Epoch 5200, Train loss: 2.440e+04, Test loss: 1.016e+04, MSE(e): 2.422e-03, MSE(pi1): 6.895e-03, MSE(pi2): 1.116e-03, MSE(pi3): 1.046e-03\n",
      "Epoch 5300, Train loss: 6.939e+03, Test loss: 9.630e+03, MSE(e): 6.770e-04, MSE(pi1): 4.276e-03, MSE(pi2): 4.109e-04, MSE(pi3): 1.266e-03\n",
      "Epoch 5400, Train loss: 1.333e+04, Test loss: 1.122e+04, MSE(e): 1.311e-03, MSE(pi1): 3.932e-03, MSE(pi2): 7.755e-04, MSE(pi3): 1.743e-03\n",
      "Epoch 5500, Train loss: 3.724e+04, Test loss: 1.935e+04, MSE(e): 3.570e-03, MSE(pi1): 1.299e-01, MSE(pi2): 1.676e-03, MSE(pi3): 2.360e-03\n",
      "Epoch 5600, Train loss: 1.381e+04, Test loss: 1.008e+04, MSE(e): 1.362e-03, MSE(pi1): 3.256e-03, MSE(pi2): 7.339e-04, MSE(pi3): 1.527e-03\n",
      "Epoch 5700, Train loss: 5.890e+04, Test loss: 2.199e+05, MSE(e): 5.850e-03, MSE(pi1): 4.941e-03, MSE(pi2): 2.634e-03, MSE(pi3): 3.495e-03\n",
      "Epoch 5800, Train loss: 1.796e+04, Test loss: 2.895e+04, MSE(e): 1.781e-03, MSE(pi1): 4.229e-03, MSE(pi2): 8.859e-04, MSE(pi3): 1.066e-03\n",
      "Epoch 5900, Train loss: 1.196e+05, Test loss: 2.757e+04, MSE(e): 1.194e-02, MSE(pi1): 6.025e-03, MSE(pi2): 5.124e-03, MSE(pi3): 1.042e-03\n",
      "Epoch 6000, Train loss: 2.058e+04, Test loss: 1.247e+04, MSE(e): 2.043e-03, MSE(pi1): 4.085e-03, MSE(pi2): 9.253e-04, MSE(pi3): 1.102e-03\n",
      "Epoch 6100, Train loss: 5.956e+03, Test loss: 1.157e+04, MSE(e): 5.744e-04, MSE(pi1): 7.781e-03, MSE(pi2): 3.534e-04, MSE(pi3): 1.345e-03\n",
      "Epoch 6200, Train loss: 9.459e+03, Test loss: 1.098e+04, MSE(e): 9.320e-04, MSE(pi1): 3.951e-03, MSE(pi2): 5.257e-04, MSE(pi3): 9.943e-04\n",
      "Epoch 6300, Train loss: 1.732e+04, Test loss: 2.244e+04, MSE(e): 1.719e-03, MSE(pi1): 6.399e-03, MSE(pi2): 7.879e-04, MSE(pi3): 6.635e-04\n",
      "Epoch 6400, Train loss: 6.035e+03, Test loss: 1.823e+04, MSE(e): 5.904e-04, MSE(pi1): 4.788e-03, MSE(pi2): 3.513e-04, MSE(pi3): 8.374e-04\n",
      "Epoch 6500, Train loss: 1.248e+04, Test loss: 1.900e+04, MSE(e): 1.235e-03, MSE(pi1): 2.987e-03, MSE(pi2): 6.126e-04, MSE(pi3): 1.035e-03\n",
      "Epoch 6600, Train loss: 1.770e+04, Test loss: 1.259e+05, MSE(e): 1.754e-03, MSE(pi1): 6.587e-03, MSE(pi2): 1.009e-03, MSE(pi3): 9.861e-04\n",
      "Epoch 6700, Train loss: 2.076e+05, Test loss: 3.886e+04, MSE(e): 2.072e-02, MSE(pi1): 1.707e-02, MSE(pi2): 8.468e-03, MSE(pi3): 2.053e-03\n",
      "Epoch 6800, Train loss: 1.186e+04, Test loss: 2.969e+04, MSE(e): 1.165e-03, MSE(pi1): 6.802e-03, MSE(pi2): 7.200e-04, MSE(pi3): 1.434e-03\n",
      "Epoch 6900, Train loss: 9.302e+04, Test loss: 4.790e+04, MSE(e): 9.270e-03, MSE(pi1): 1.321e-02, MSE(pi2): 3.887e-03, MSE(pi3): 1.818e-03\n",
      "Epoch 7000, Train loss: 1.200e+04, Test loss: 3.337e+04, MSE(e): 1.185e-03, MSE(pi1): 5.667e-03, MSE(pi2): 5.953e-04, MSE(pi3): 9.062e-04\n",
      "Epoch 7100, Train loss: 1.719e+04, Test loss: 9.046e+03, MSE(e): 1.707e-03, MSE(pi1): 4.300e-03, MSE(pi2): 8.019e-04, MSE(pi3): 7.378e-04\n",
      "Epoch 7200, Train loss: 1.403e+04, Test loss: 2.686e+04, MSE(e): 1.383e-03, MSE(pi1): 4.585e-03, MSE(pi2): 7.312e-04, MSE(pi3): 1.456e-03\n",
      "Epoch 7300, Train loss: 8.255e+03, Test loss: 7.695e+03, MSE(e): 8.131e-04, MSE(pi1): 5.315e-03, MSE(pi2): 4.462e-04, MSE(pi3): 7.093e-04\n",
      "Epoch 7400, Train loss: 3.360e+05, Test loss: 8.838e+04, MSE(e): 3.355e-02, MSE(pi1): 9.532e-03, MSE(pi2): 1.349e-02, MSE(pi3): 4.603e-03\n",
      "Epoch 7500, Train loss: 1.617e+04, Test loss: 2.295e+04, MSE(e): 1.604e-03, MSE(pi1): 4.503e-03, MSE(pi2): 7.817e-04, MSE(pi3): 8.273e-04\n",
      "Epoch 7600, Train loss: 6.248e+03, Test loss: 6.473e+04, MSE(e): 6.111e-04, MSE(pi1): 3.159e-03, MSE(pi2): 3.885e-04, MSE(pi3): 1.056e-03\n",
      "Epoch 7700, Train loss: 5.496e+03, Test loss: 3.563e+04, MSE(e): 5.352e-04, MSE(pi1): 5.186e-03, MSE(pi2): 4.266e-04, MSE(pi3): 9.219e-04\n",
      "Epoch 7800, Train loss: 8.446e+03, Test loss: 3.714e+04, MSE(e): 8.316e-04, MSE(pi1): 3.910e-03, MSE(pi2): 4.514e-04, MSE(pi3): 9.060e-04\n",
      "Epoch 7900, Train loss: 3.472e+03, Test loss: 1.579e+04, MSE(e): 3.356e-04, MSE(pi1): 2.448e-03, MSE(pi2): 2.359e-04, MSE(pi3): 9.102e-04\n",
      "Epoch 8000, Train loss: 3.671e+04, Test loss: 4.560e+04, MSE(e): 3.655e-03, MSE(pi1): 7.164e-03, MSE(pi2): 1.862e-03, MSE(pi3): 9.431e-04\n",
      "Epoch 8100, Train loss: 2.561e+04, Test loss: 2.713e+04, MSE(e): 2.545e-03, MSE(pi1): 6.439e-03, MSE(pi2): 1.149e-03, MSE(pi3): 9.339e-04\n",
      "Epoch 8200, Train loss: 1.199e+04, Test loss: 5.858e+04, MSE(e): 1.183e-03, MSE(pi1): 4.459e-03, MSE(pi2): 5.570e-04, MSE(pi3): 1.172e-03\n",
      "Epoch 8300, Train loss: 1.636e+04, Test loss: 3.308e+04, MSE(e): 1.619e-03, MSE(pi1): 7.322e-03, MSE(pi2): 9.269e-04, MSE(pi3): 9.655e-04\n",
      "Epoch 8400, Train loss: 4.846e+03, Test loss: 2.192e+04, MSE(e): 4.724e-04, MSE(pi1): 5.391e-03, MSE(pi2): 2.684e-04, MSE(pi3): 6.773e-04\n",
      "Epoch 8500, Train loss: 8.019e+04, Test loss: 1.164e+05, MSE(e): 7.981e-03, MSE(pi1): 1.652e-02, MSE(pi2): 4.408e-03, MSE(pi3): 2.160e-03\n",
      "Epoch 8600, Train loss: 3.969e+03, Test loss: 2.498e+04, MSE(e): 3.848e-04, MSE(pi1): 4.440e-03, MSE(pi2): 2.578e-04, MSE(pi3): 7.629e-04\n",
      "Epoch 8700, Train loss: 4.864e+04, Test loss: 7.850e+04, MSE(e): 4.843e-03, MSE(pi1): 7.715e-03, MSE(pi2): 2.306e-03, MSE(pi3): 1.317e-03\n",
      "Epoch 8800, Train loss: 1.483e+04, Test loss: 1.764e+04, MSE(e): 1.471e-03, MSE(pi1): 4.354e-03, MSE(pi2): 6.609e-04, MSE(pi3): 7.689e-04\n",
      "Epoch 8900, Train loss: 8.535e+04, Test loss: 8.782e+04, MSE(e): 8.517e-03, MSE(pi1): 7.472e-03, MSE(pi2): 3.764e-03, MSE(pi3): 1.053e-03\n",
      "Epoch 9000, Train loss: 7.679e+03, Test loss: 6.485e+04, MSE(e): 7.553e-04, MSE(pi1): 2.827e-03, MSE(pi2): 4.785e-04, MSE(pi3): 9.733e-04\n",
      "Epoch 9100, Train loss: 8.460e+03, Test loss: 2.104e+04, MSE(e): 8.329e-04, MSE(pi1): 3.051e-03, MSE(pi2): 4.297e-04, MSE(pi3): 1.004e-03\n",
      "Epoch 9200, Train loss: 1.263e+04, Test loss: 4.260e+04, MSE(e): 1.247e-03, MSE(pi1): 6.202e-03, MSE(pi2): 6.431e-04, MSE(pi3): 9.103e-04\n",
      "Epoch 9300, Train loss: 1.068e+04, Test loss: 4.312e+04, MSE(e): 1.055e-03, MSE(pi1): 4.449e-03, MSE(pi2): 5.060e-04, MSE(pi3): 8.435e-04\n",
      "Epoch 9400, Train loss: 8.002e+03, Test loss: 3.462e+04, MSE(e): 7.884e-04, MSE(pi1): 3.033e-03, MSE(pi2): 4.164e-04, MSE(pi3): 8.726e-04\n",
      "Epoch 9500, Train loss: 1.658e+04, Test loss: 3.011e+04, MSE(e): 1.646e-03, MSE(pi1): 3.358e-03, MSE(pi2): 8.350e-04, MSE(pi3): 8.413e-04\n",
      "Epoch 9600, Train loss: 3.969e+04, Test loss: 5.150e+04, MSE(e): 3.955e-03, MSE(pi1): 3.725e-03, MSE(pi2): 1.900e-03, MSE(pi3): 1.013e-03\n",
      "Epoch 9700, Train loss: 4.384e+04, Test loss: 6.538e+04, MSE(e): 4.369e-03, MSE(pi1): 3.747e-03, MSE(pi2): 2.151e-03, MSE(pi3): 1.157e-03\n",
      "Epoch 9800, Train loss: 1.167e+04, Test loss: 6.836e+04, MSE(e): 1.153e-03, MSE(pi1): 6.789e-03, MSE(pi2): 6.282e-04, MSE(pi3): 7.128e-04\n",
      "Epoch 9900, Train loss: 4.240e+03, Test loss: 5.636e+04, MSE(e): 4.122e-04, MSE(pi1): 2.942e-03, MSE(pi2): 2.367e-04, MSE(pi3): 8.812e-04\n",
      "\n",
      "Training process finished after 10000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = PODNonlinearModel(input_shape, predictive_layers, POD_base, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 10000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 9000.\n",
      "Epoch 9000, Train loss: 5.559e+03, Test loss: 1.590e+04, MSE(e): 5.442e-04, MSE(pi1): 3.397e-03, MSE(pi2): 3.075e-04, MSE(pi3): 8.206e-04\n",
      "Epoch 9100, Train loss: 2.247e+03, Test loss: 1.661e+04, MSE(e): 2.139e-04, MSE(pi1): 2.850e-03, MSE(pi2): 1.610e-04, MSE(pi3): 7.891e-04\n",
      "Epoch 9200, Train loss: 2.209e+03, Test loss: 1.658e+04, MSE(e): 2.102e-04, MSE(pi1): 2.838e-03, MSE(pi2): 1.590e-04, MSE(pi3): 7.849e-04\n",
      "Epoch 9300, Train loss: 2.180e+03, Test loss: 1.650e+04, MSE(e): 2.073e-04, MSE(pi1): 2.825e-03, MSE(pi2): 1.571e-04, MSE(pi3): 7.831e-04\n",
      "Epoch 9400, Train loss: 2.164e+03, Test loss: 1.638e+04, MSE(e): 2.058e-04, MSE(pi1): 2.821e-03, MSE(pi2): 1.558e-04, MSE(pi3): 7.817e-04\n",
      "Epoch 9500, Train loss: 2.175e+03, Test loss: 1.621e+04, MSE(e): 2.069e-04, MSE(pi1): 2.842e-03, MSE(pi2): 1.560e-04, MSE(pi3): 7.783e-04\n",
      "Epoch 9600, Train loss: 2.257e+03, Test loss: 1.604e+04, MSE(e): 2.151e-04, MSE(pi1): 2.895e-03, MSE(pi2): 1.598e-04, MSE(pi3): 7.720e-04\n",
      "Epoch 9700, Train loss: 2.060e+03, Test loss: 1.613e+04, MSE(e): 1.954e-04, MSE(pi1): 2.798e-03, MSE(pi2): 1.503e-04, MSE(pi3): 7.788e-04\n",
      "Epoch 9800, Train loss: 2.026e+03, Test loss: 1.587e+04, MSE(e): 1.920e-04, MSE(pi1): 2.791e-03, MSE(pi2): 1.485e-04, MSE(pi3): 7.776e-04\n",
      "Epoch 9900, Train loss: 1.999e+03, Test loss: 1.563e+04, MSE(e): 1.893e-04, MSE(pi1): 2.790e-03, MSE(pi2): 1.474e-04, MSE(pi3): 7.759e-04\n",
      "Epoch 10000, Train loss: 1.971e+03, Test loss: 1.540e+04, MSE(e): 1.866e-04, MSE(pi1): 2.786e-03, MSE(pi2): 1.464e-04, MSE(pi3): 7.744e-04\n",
      "Epoch 10100, Train loss: 1.945e+03, Test loss: 1.516e+04, MSE(e): 1.840e-04, MSE(pi1): 2.782e-03, MSE(pi2): 1.454e-04, MSE(pi3): 7.731e-04\n",
      "Epoch 10200, Train loss: 1.921e+03, Test loss: 1.493e+04, MSE(e): 1.816e-04, MSE(pi1): 2.777e-03, MSE(pi2): 1.445e-04, MSE(pi3): 7.719e-04\n",
      "Epoch 10300, Train loss: 1.899e+03, Test loss: 1.469e+04, MSE(e): 1.794e-04, MSE(pi1): 2.772e-03, MSE(pi2): 1.437e-04, MSE(pi3): 7.707e-04\n",
      "Epoch 10400, Train loss: 1.878e+03, Test loss: 1.446e+04, MSE(e): 1.773e-04, MSE(pi1): 2.768e-03, MSE(pi2): 1.429e-04, MSE(pi3): 7.696e-04\n",
      "Epoch 10500, Train loss: 1.858e+03, Test loss: 1.424e+04, MSE(e): 1.754e-04, MSE(pi1): 2.764e-03, MSE(pi2): 1.422e-04, MSE(pi3): 7.686e-04\n",
      "Epoch 10600, Train loss: 1.840e+03, Test loss: 1.401e+04, MSE(e): 1.736e-04, MSE(pi1): 2.760e-03, MSE(pi2): 1.414e-04, MSE(pi3): 7.675e-04\n",
      "Epoch 10700, Train loss: 1.823e+03, Test loss: 1.380e+04, MSE(e): 1.719e-04, MSE(pi1): 2.757e-03, MSE(pi2): 1.407e-04, MSE(pi3): 7.665e-04\n",
      "Epoch 10800, Train loss: 1.807e+03, Test loss: 1.359e+04, MSE(e): 1.702e-04, MSE(pi1): 2.754e-03, MSE(pi2): 1.400e-04, MSE(pi3): 7.655e-04\n",
      "Epoch 10900, Train loss: 1.791e+03, Test loss: 1.338e+04, MSE(e): 1.687e-04, MSE(pi1): 2.752e-03, MSE(pi2): 1.393e-04, MSE(pi3): 7.646e-04\n",
      "Epoch 11000, Train loss: 1.776e+03, Test loss: 1.318e+04, MSE(e): 1.672e-04, MSE(pi1): 2.749e-03, MSE(pi2): 1.386e-04, MSE(pi3): 7.636e-04\n",
      "Epoch 11100, Train loss: 1.761e+03, Test loss: 1.299e+04, MSE(e): 1.657e-04, MSE(pi1): 2.747e-03, MSE(pi2): 1.379e-04, MSE(pi3): 7.627e-04\n",
      "Epoch 11200, Train loss: 1.747e+03, Test loss: 1.280e+04, MSE(e): 1.643e-04, MSE(pi1): 2.745e-03, MSE(pi2): 1.372e-04, MSE(pi3): 7.618e-04\n",
      "Epoch 11300, Train loss: 1.733e+03, Test loss: 1.261e+04, MSE(e): 1.629e-04, MSE(pi1): 2.743e-03, MSE(pi2): 1.366e-04, MSE(pi3): 7.609e-04\n",
      "Epoch 11400, Train loss: 1.720e+03, Test loss: 1.243e+04, MSE(e): 1.616e-04, MSE(pi1): 2.741e-03, MSE(pi2): 1.359e-04, MSE(pi3): 7.601e-04\n",
      "Epoch 11500, Train loss: 1.707e+03, Test loss: 1.225e+04, MSE(e): 1.604e-04, MSE(pi1): 2.739e-03, MSE(pi2): 1.352e-04, MSE(pi3): 7.592e-04\n",
      "Epoch 11600, Train loss: 1.695e+03, Test loss: 1.205e+04, MSE(e): 1.591e-04, MSE(pi1): 2.737e-03, MSE(pi2): 1.346e-04, MSE(pi3): 7.584e-04\n",
      "Epoch 11700, Train loss: 1.682e+03, Test loss: 1.183e+04, MSE(e): 1.579e-04, MSE(pi1): 2.735e-03, MSE(pi2): 1.340e-04, MSE(pi3): 7.576e-04\n",
      "Epoch 11800, Train loss: 1.671e+03, Test loss: 1.156e+04, MSE(e): 1.567e-04, MSE(pi1): 2.734e-03, MSE(pi2): 1.333e-04, MSE(pi3): 7.568e-04\n",
      "Epoch 11900, Train loss: 1.659e+03, Test loss: 1.121e+04, MSE(e): 1.556e-04, MSE(pi1): 2.733e-03, MSE(pi2): 1.327e-04, MSE(pi3): 7.560e-04\n",
      "Epoch 12000, Train loss: 1.649e+03, Test loss: 1.077e+04, MSE(e): 1.546e-04, MSE(pi1): 2.734e-03, MSE(pi2): 1.321e-04, MSE(pi3): 7.551e-04\n",
      "Epoch 12100, Train loss: 1.639e+03, Test loss: 1.034e+04, MSE(e): 1.536e-04, MSE(pi1): 2.736e-03, MSE(pi2): 1.315e-04, MSE(pi3): 7.540e-04\n",
      "Epoch 12200, Train loss: 1.630e+03, Test loss: 1.002e+04, MSE(e): 1.527e-04, MSE(pi1): 2.739e-03, MSE(pi2): 1.310e-04, MSE(pi3): 7.529e-04\n",
      "Epoch 12300, Train loss: 1.621e+03, Test loss: 9.810e+03, MSE(e): 1.518e-04, MSE(pi1): 2.740e-03, MSE(pi2): 1.304e-04, MSE(pi3): 7.520e-04\n",
      "Epoch 12400, Train loss: 1.612e+03, Test loss: 9.647e+03, MSE(e): 1.509e-04, MSE(pi1): 2.739e-03, MSE(pi2): 1.299e-04, MSE(pi3): 7.512e-04\n",
      "Epoch 12500, Train loss: 1.602e+03, Test loss: 9.504e+03, MSE(e): 1.499e-04, MSE(pi1): 2.737e-03, MSE(pi2): 1.293e-04, MSE(pi3): 7.505e-04\n",
      "Epoch 12600, Train loss: 1.592e+03, Test loss: 9.372e+03, MSE(e): 1.490e-04, MSE(pi1): 2.734e-03, MSE(pi2): 1.288e-04, MSE(pi3): 7.499e-04\n",
      "Epoch 12700, Train loss: 1.583e+03, Test loss: 9.248e+03, MSE(e): 1.480e-04, MSE(pi1): 2.732e-03, MSE(pi2): 1.282e-04, MSE(pi3): 7.493e-04\n",
      "Epoch 12800, Train loss: 1.573e+03, Test loss: 9.130e+03, MSE(e): 1.471e-04, MSE(pi1): 2.729e-03, MSE(pi2): 1.277e-04, MSE(pi3): 7.487e-04\n",
      "Epoch 12900, Train loss: 1.564e+03, Test loss: 9.017e+03, MSE(e): 1.461e-04, MSE(pi1): 2.727e-03, MSE(pi2): 1.271e-04, MSE(pi3): 7.481e-04\n",
      "Epoch 13000, Train loss: 1.554e+03, Test loss: 8.908e+03, MSE(e): 1.452e-04, MSE(pi1): 2.725e-03, MSE(pi2): 1.266e-04, MSE(pi3): 7.475e-04\n",
      "Epoch 13100, Train loss: 1.545e+03, Test loss: 8.804e+03, MSE(e): 1.443e-04, MSE(pi1): 2.723e-03, MSE(pi2): 1.260e-04, MSE(pi3): 7.470e-04\n",
      "Epoch 13200, Train loss: 1.536e+03, Test loss: 8.704e+03, MSE(e): 1.434e-04, MSE(pi1): 2.721e-03, MSE(pi2): 1.255e-04, MSE(pi3): 7.464e-04\n",
      "Epoch 13300, Train loss: 1.527e+03, Test loss: 8.608e+03, MSE(e): 1.425e-04, MSE(pi1): 2.719e-03, MSE(pi2): 1.249e-04, MSE(pi3): 7.459e-04\n",
      "Epoch 13400, Train loss: 1.518e+03, Test loss: 8.515e+03, MSE(e): 1.416e-04, MSE(pi1): 2.718e-03, MSE(pi2): 1.244e-04, MSE(pi3): 7.454e-04\n",
      "Epoch 13500, Train loss: 1.510e+03, Test loss: 8.425e+03, MSE(e): 1.408e-04, MSE(pi1): 2.716e-03, MSE(pi2): 1.239e-04, MSE(pi3): 7.449e-04\n",
      "Epoch 13600, Train loss: 1.501e+03, Test loss: 8.339e+03, MSE(e): 1.399e-04, MSE(pi1): 2.714e-03, MSE(pi2): 1.233e-04, MSE(pi3): 7.444e-04\n",
      "Epoch 13700, Train loss: 1.493e+03, Test loss: 8.255e+03, MSE(e): 1.391e-04, MSE(pi1): 2.712e-03, MSE(pi2): 1.228e-04, MSE(pi3): 7.440e-04\n",
      "Epoch 13800, Train loss: 1.484e+03, Test loss: 8.175e+03, MSE(e): 1.383e-04, MSE(pi1): 2.710e-03, MSE(pi2): 1.223e-04, MSE(pi3): 7.435e-04\n",
      "Epoch 13900, Train loss: 1.476e+03, Test loss: 8.098e+03, MSE(e): 1.375e-04, MSE(pi1): 2.709e-03, MSE(pi2): 1.218e-04, MSE(pi3): 7.430e-04\n",
      "Epoch 14000, Train loss: 1.468e+03, Test loss: 8.024e+03, MSE(e): 1.367e-04, MSE(pi1): 2.707e-03, MSE(pi2): 1.212e-04, MSE(pi3): 7.426e-04\n",
      "Epoch 14100, Train loss: 1.461e+03, Test loss: 7.952e+03, MSE(e): 1.359e-04, MSE(pi1): 2.705e-03, MSE(pi2): 1.207e-04, MSE(pi3): 7.422e-04\n",
      "Epoch 14200, Train loss: 1.453e+03, Test loss: 7.883e+03, MSE(e): 1.352e-04, MSE(pi1): 2.703e-03, MSE(pi2): 1.202e-04, MSE(pi3): 7.417e-04\n",
      "Epoch 14300, Train loss: 1.446e+03, Test loss: 7.816e+03, MSE(e): 1.344e-04, MSE(pi1): 2.702e-03, MSE(pi2): 1.197e-04, MSE(pi3): 7.413e-04\n",
      "Epoch 14400, Train loss: 1.438e+03, Test loss: 7.752e+03, MSE(e): 1.337e-04, MSE(pi1): 2.700e-03, MSE(pi2): 1.192e-04, MSE(pi3): 7.409e-04\n",
      "Epoch 14500, Train loss: 1.431e+03, Test loss: 7.690e+03, MSE(e): 1.330e-04, MSE(pi1): 2.698e-03, MSE(pi2): 1.187e-04, MSE(pi3): 7.405e-04\n",
      "Epoch 14600, Train loss: 1.424e+03, Test loss: 7.630e+03, MSE(e): 1.323e-04, MSE(pi1): 2.696e-03, MSE(pi2): 1.182e-04, MSE(pi3): 7.401e-04\n",
      "Epoch 14700, Train loss: 1.417e+03, Test loss: 7.572e+03, MSE(e): 1.316e-04, MSE(pi1): 2.694e-03, MSE(pi2): 1.178e-04, MSE(pi3): 7.397e-04\n",
      "Epoch 14800, Train loss: 1.410e+03, Test loss: 7.516e+03, MSE(e): 1.309e-04, MSE(pi1): 2.693e-03, MSE(pi2): 1.173e-04, MSE(pi3): 7.394e-04\n",
      "Epoch 14900, Train loss: 1.403e+03, Test loss: 7.461e+03, MSE(e): 1.302e-04, MSE(pi1): 2.691e-03, MSE(pi2): 1.168e-04, MSE(pi3): 7.390e-04\n",
      "Epoch 15000, Train loss: 1.397e+03, Test loss: 7.408e+03, MSE(e): 1.296e-04, MSE(pi1): 2.689e-03, MSE(pi2): 1.163e-04, MSE(pi3): 7.387e-04\n",
      "Epoch 15100, Train loss: 1.390e+03, Test loss: 7.355e+03, MSE(e): 1.289e-04, MSE(pi1): 2.687e-03, MSE(pi2): 1.159e-04, MSE(pi3): 7.383e-04\n",
      "Epoch 15200, Train loss: 1.384e+03, Test loss: 7.305e+03, MSE(e): 1.283e-04, MSE(pi1): 2.685e-03, MSE(pi2): 1.154e-04, MSE(pi3): 7.380e-04\n",
      "Epoch 15300, Train loss: 1.377e+03, Test loss: 7.255e+03, MSE(e): 1.277e-04, MSE(pi1): 2.683e-03, MSE(pi2): 1.150e-04, MSE(pi3): 7.377e-04\n",
      "Epoch 15400, Train loss: 1.371e+03, Test loss: 7.206e+03, MSE(e): 1.270e-04, MSE(pi1): 2.680e-03, MSE(pi2): 1.145e-04, MSE(pi3): 7.374e-04\n",
      "Epoch 15500, Train loss: 1.365e+03, Test loss: 7.159e+03, MSE(e): 1.264e-04, MSE(pi1): 2.678e-03, MSE(pi2): 1.141e-04, MSE(pi3): 7.371e-04\n",
      "Epoch 15600, Train loss: 1.359e+03, Test loss: 7.112e+03, MSE(e): 1.259e-04, MSE(pi1): 2.676e-03, MSE(pi2): 1.137e-04, MSE(pi3): 7.368e-04\n",
      "Epoch 15700, Train loss: 1.353e+03, Test loss: 7.067e+03, MSE(e): 1.253e-04, MSE(pi1): 2.674e-03, MSE(pi2): 1.132e-04, MSE(pi3): 7.365e-04\n",
      "Epoch 15800, Train loss: 1.347e+03, Test loss: 7.024e+03, MSE(e): 1.247e-04, MSE(pi1): 2.672e-03, MSE(pi2): 1.128e-04, MSE(pi3): 7.362e-04\n",
      "Epoch 15900, Train loss: 1.342e+03, Test loss: 6.982e+03, MSE(e): 1.241e-04, MSE(pi1): 2.670e-03, MSE(pi2): 1.124e-04, MSE(pi3): 7.358e-04\n",
      "Epoch 16000, Train loss: 1.336e+03, Test loss: 6.941e+03, MSE(e): 1.236e-04, MSE(pi1): 2.669e-03, MSE(pi2): 1.119e-04, MSE(pi3): 7.355e-04\n",
      "Epoch 16100, Train loss: 1.330e+03, Test loss: 6.901e+03, MSE(e): 1.230e-04, MSE(pi1): 2.667e-03, MSE(pi2): 1.115e-04, MSE(pi3): 7.351e-04\n",
      "Epoch 16200, Train loss: 1.325e+03, Test loss: 6.862e+03, MSE(e): 1.225e-04, MSE(pi1): 2.666e-03, MSE(pi2): 1.111e-04, MSE(pi3): 7.347e-04\n",
      "Epoch 16300, Train loss: 1.319e+03, Test loss: 6.825e+03, MSE(e): 1.219e-04, MSE(pi1): 2.665e-03, MSE(pi2): 1.107e-04, MSE(pi3): 7.343e-04\n",
      "Epoch 16400, Train loss: 1.314e+03, Test loss: 6.788e+03, MSE(e): 1.214e-04, MSE(pi1): 2.664e-03, MSE(pi2): 1.102e-04, MSE(pi3): 7.339e-04\n",
      "Epoch 16500, Train loss: 1.309e+03, Test loss: 6.753e+03, MSE(e): 1.208e-04, MSE(pi1): 2.664e-03, MSE(pi2): 1.098e-04, MSE(pi3): 7.335e-04\n",
      "Epoch 16600, Train loss: 1.303e+03, Test loss: 6.718e+03, MSE(e): 1.203e-04, MSE(pi1): 2.663e-03, MSE(pi2): 1.094e-04, MSE(pi3): 7.331e-04\n",
      "Epoch 16700, Train loss: 1.298e+03, Test loss: 6.684e+03, MSE(e): 1.198e-04, MSE(pi1): 2.662e-03, MSE(pi2): 1.090e-04, MSE(pi3): 7.327e-04\n",
      "Epoch 16800, Train loss: 1.293e+03, Test loss: 6.651e+03, MSE(e): 1.193e-04, MSE(pi1): 2.661e-03, MSE(pi2): 1.086e-04, MSE(pi3): 7.323e-04\n",
      "Epoch 16900, Train loss: 1.288e+03, Test loss: 6.619e+03, MSE(e): 1.188e-04, MSE(pi1): 2.661e-03, MSE(pi2): 1.081e-04, MSE(pi3): 7.318e-04\n",
      "Epoch 17000, Train loss: 1.283e+03, Test loss: 6.588e+03, MSE(e): 1.183e-04, MSE(pi1): 2.660e-03, MSE(pi2): 1.077e-04, MSE(pi3): 7.314e-04\n",
      "Epoch 17100, Train loss: 1.278e+03, Test loss: 6.557e+03, MSE(e): 1.178e-04, MSE(pi1): 2.659e-03, MSE(pi2): 1.073e-04, MSE(pi3): 7.309e-04\n",
      "Epoch 17200, Train loss: 1.273e+03, Test loss: 6.527e+03, MSE(e): 1.173e-04, MSE(pi1): 2.659e-03, MSE(pi2): 1.069e-04, MSE(pi3): 7.305e-04\n",
      "Epoch 17300, Train loss: 1.268e+03, Test loss: 6.498e+03, MSE(e): 1.168e-04, MSE(pi1): 2.658e-03, MSE(pi2): 1.065e-04, MSE(pi3): 7.300e-04\n",
      "Epoch 17400, Train loss: 1.263e+03, Test loss: 6.469e+03, MSE(e): 1.164e-04, MSE(pi1): 2.658e-03, MSE(pi2): 1.061e-04, MSE(pi3): 7.296e-04\n",
      "Epoch 17500, Train loss: 1.259e+03, Test loss: 6.441e+03, MSE(e): 1.159e-04, MSE(pi1): 2.657e-03, MSE(pi2): 1.057e-04, MSE(pi3): 7.291e-04\n",
      "Epoch 17600, Train loss: 1.254e+03, Test loss: 6.413e+03, MSE(e): 1.155e-04, MSE(pi1): 2.657e-03, MSE(pi2): 1.054e-04, MSE(pi3): 7.287e-04\n",
      "Epoch 17700, Train loss: 1.250e+03, Test loss: 6.386e+03, MSE(e): 1.150e-04, MSE(pi1): 2.656e-03, MSE(pi2): 1.050e-04, MSE(pi3): 7.282e-04\n",
      "Epoch 17800, Train loss: 1.245e+03, Test loss: 6.360e+03, MSE(e): 1.146e-04, MSE(pi1): 2.656e-03, MSE(pi2): 1.046e-04, MSE(pi3): 7.277e-04\n",
      "Epoch 17900, Train loss: 1.241e+03, Test loss: 6.334e+03, MSE(e): 1.142e-04, MSE(pi1): 2.656e-03, MSE(pi2): 1.042e-04, MSE(pi3): 7.273e-04\n",
      "Epoch 18000, Train loss: 1.237e+03, Test loss: 6.309e+03, MSE(e): 1.137e-04, MSE(pi1): 2.655e-03, MSE(pi2): 1.038e-04, MSE(pi3): 7.268e-04\n",
      "Epoch 18100, Train loss: 1.232e+03, Test loss: 6.284e+03, MSE(e): 1.133e-04, MSE(pi1): 2.655e-03, MSE(pi2): 1.035e-04, MSE(pi3): 7.264e-04\n",
      "Epoch 18200, Train loss: 1.228e+03, Test loss: 6.260e+03, MSE(e): 1.129e-04, MSE(pi1): 2.655e-03, MSE(pi2): 1.031e-04, MSE(pi3): 7.259e-04\n",
      "Epoch 18300, Train loss: 1.224e+03, Test loss: 6.236e+03, MSE(e): 1.125e-04, MSE(pi1): 2.655e-03, MSE(pi2): 1.027e-04, MSE(pi3): 7.254e-04\n",
      "Epoch 18400, Train loss: 1.220e+03, Test loss: 6.213e+03, MSE(e): 1.121e-04, MSE(pi1): 2.654e-03, MSE(pi2): 1.024e-04, MSE(pi3): 7.249e-04\n",
      "Epoch 18500, Train loss: 1.216e+03, Test loss: 6.190e+03, MSE(e): 1.117e-04, MSE(pi1): 2.654e-03, MSE(pi2): 1.020e-04, MSE(pi3): 7.245e-04\n",
      "Epoch 18600, Train loss: 1.212e+03, Test loss: 6.167e+03, MSE(e): 1.113e-04, MSE(pi1): 2.654e-03, MSE(pi2): 1.017e-04, MSE(pi3): 7.240e-04\n",
      "Epoch 18700, Train loss: 1.208e+03, Test loss: 6.145e+03, MSE(e): 1.109e-04, MSE(pi1): 2.653e-03, MSE(pi2): 1.013e-04, MSE(pi3): 7.235e-04\n",
      "Epoch 18800, Train loss: 1.204e+03, Test loss: 6.123e+03, MSE(e): 1.105e-04, MSE(pi1): 2.653e-03, MSE(pi2): 1.010e-04, MSE(pi3): 7.231e-04\n",
      "Epoch 18900, Train loss: 1.200e+03, Test loss: 6.102e+03, MSE(e): 1.102e-04, MSE(pi1): 2.653e-03, MSE(pi2): 1.006e-04, MSE(pi3): 7.226e-04\n",
      "Epoch 19000, Train loss: 1.197e+03, Test loss: 6.081e+03, MSE(e): 1.098e-04, MSE(pi1): 2.652e-03, MSE(pi2): 1.003e-04, MSE(pi3): 7.222e-04\n",
      "Epoch 19100, Train loss: 1.193e+03, Test loss: 6.060e+03, MSE(e): 1.094e-04, MSE(pi1): 2.652e-03, MSE(pi2): 9.998e-05, MSE(pi3): 7.217e-04\n",
      "Epoch 19200, Train loss: 1.189e+03, Test loss: 6.040e+03, MSE(e): 1.091e-04, MSE(pi1): 2.652e-03, MSE(pi2): 9.965e-05, MSE(pi3): 7.213e-04\n",
      "Epoch 19300, Train loss: 1.186e+03, Test loss: 6.020e+03, MSE(e): 1.087e-04, MSE(pi1): 2.652e-03, MSE(pi2): 9.933e-05, MSE(pi3): 7.208e-04\n",
      "Epoch 19400, Train loss: 1.182e+03, Test loss: 6.000e+03, MSE(e): 1.083e-04, MSE(pi1): 2.651e-03, MSE(pi2): 9.901e-05, MSE(pi3): 7.204e-04\n",
      "Epoch 19500, Train loss: 1.178e+03, Test loss: 5.981e+03, MSE(e): 1.080e-04, MSE(pi1): 2.651e-03, MSE(pi2): 9.869e-05, MSE(pi3): 7.199e-04\n",
      "Epoch 19600, Train loss: 1.175e+03, Test loss: 5.962e+03, MSE(e): 1.076e-04, MSE(pi1): 2.651e-03, MSE(pi2): 9.838e-05, MSE(pi3): 7.195e-04\n",
      "Epoch 19700, Train loss: 1.172e+03, Test loss: 5.943e+03, MSE(e): 1.073e-04, MSE(pi1): 2.651e-03, MSE(pi2): 9.807e-05, MSE(pi3): 7.190e-04\n",
      "Epoch 19800, Train loss: 1.168e+03, Test loss: 5.924e+03, MSE(e): 1.070e-04, MSE(pi1): 2.650e-03, MSE(pi2): 9.776e-05, MSE(pi3): 7.186e-04\n",
      "Epoch 19900, Train loss: 1.165e+03, Test loss: 5.906e+03, MSE(e): 1.066e-04, MSE(pi1): 2.650e-03, MSE(pi2): 9.745e-05, MSE(pi3): 7.182e-04\n",
      "Epoch 20000, Train loss: 1.161e+03, Test loss: 5.887e+03, MSE(e): 1.063e-04, MSE(pi1): 2.650e-03, MSE(pi2): 9.715e-05, MSE(pi3): 7.178e-04\n",
      "Epoch 20100, Train loss: 1.158e+03, Test loss: 5.869e+03, MSE(e): 1.060e-04, MSE(pi1): 2.649e-03, MSE(pi2): 9.685e-05, MSE(pi3): 7.174e-04\n",
      "Epoch 20200, Train loss: 1.155e+03, Test loss: 5.851e+03, MSE(e): 1.056e-04, MSE(pi1): 2.649e-03, MSE(pi2): 9.655e-05, MSE(pi3): 7.169e-04\n",
      "Epoch 20300, Train loss: 1.151e+03, Test loss: 5.833e+03, MSE(e): 1.053e-04, MSE(pi1): 2.649e-03, MSE(pi2): 9.626e-05, MSE(pi3): 7.165e-04\n",
      "Epoch 20400, Train loss: 1.148e+03, Test loss: 5.815e+03, MSE(e): 1.050e-04, MSE(pi1): 2.648e-03, MSE(pi2): 9.597e-05, MSE(pi3): 7.161e-04\n",
      "Epoch 20500, Train loss: 1.145e+03, Test loss: 5.798e+03, MSE(e): 1.047e-04, MSE(pi1): 2.648e-03, MSE(pi2): 9.569e-05, MSE(pi3): 7.157e-04\n",
      "Epoch 20600, Train loss: 1.142e+03, Test loss: 5.780e+03, MSE(e): 1.044e-04, MSE(pi1): 2.648e-03, MSE(pi2): 9.540e-05, MSE(pi3): 7.153e-04\n",
      "Epoch 20700, Train loss: 1.139e+03, Test loss: 5.762e+03, MSE(e): 1.041e-04, MSE(pi1): 2.647e-03, MSE(pi2): 9.512e-05, MSE(pi3): 7.149e-04\n",
      "Epoch 20800, Train loss: 1.136e+03, Test loss: 5.745e+03, MSE(e): 1.038e-04, MSE(pi1): 2.647e-03, MSE(pi2): 9.484e-05, MSE(pi3): 7.145e-04\n",
      "Epoch 20900, Train loss: 1.133e+03, Test loss: 5.727e+03, MSE(e): 1.035e-04, MSE(pi1): 2.647e-03, MSE(pi2): 9.455e-05, MSE(pi3): 7.141e-04\n",
      "Epoch 21000, Train loss: 1.129e+03, Test loss: 5.710e+03, MSE(e): 1.032e-04, MSE(pi1): 2.646e-03, MSE(pi2): 9.427e-05, MSE(pi3): 7.137e-04\n",
      "Epoch 21100, Train loss: 1.126e+03, Test loss: 5.693e+03, MSE(e): 1.029e-04, MSE(pi1): 2.646e-03, MSE(pi2): 9.400e-05, MSE(pi3): 7.133e-04\n",
      "Epoch 21200, Train loss: 1.123e+03, Test loss: 5.676e+03, MSE(e): 1.026e-04, MSE(pi1): 2.646e-03, MSE(pi2): 9.373e-05, MSE(pi3): 7.129e-04\n",
      "Epoch 21300, Train loss: 1.120e+03, Test loss: 5.659e+03, MSE(e): 1.023e-04, MSE(pi1): 2.646e-03, MSE(pi2): 9.345e-05, MSE(pi3): 7.125e-04\n",
      "Epoch 21400, Train loss: 1.117e+03, Test loss: 5.643e+03, MSE(e): 1.020e-04, MSE(pi1): 2.646e-03, MSE(pi2): 9.318e-05, MSE(pi3): 7.121e-04\n",
      "Epoch 21500, Train loss: 1.114e+03, Test loss: 5.627e+03, MSE(e): 1.017e-04, MSE(pi1): 2.645e-03, MSE(pi2): 9.291e-05, MSE(pi3): 7.118e-04\n",
      "Epoch 21600, Train loss: 1.112e+03, Test loss: 5.610e+03, MSE(e): 1.014e-04, MSE(pi1): 2.645e-03, MSE(pi2): 9.265e-05, MSE(pi3): 7.114e-04\n",
      "Epoch 21700, Train loss: 1.109e+03, Test loss: 5.594e+03, MSE(e): 1.011e-04, MSE(pi1): 2.644e-03, MSE(pi2): 9.238e-05, MSE(pi3): 7.110e-04\n",
      "Epoch 21800, Train loss: 1.106e+03, Test loss: 5.578e+03, MSE(e): 1.008e-04, MSE(pi1): 2.644e-03, MSE(pi2): 9.212e-05, MSE(pi3): 7.107e-04\n",
      "Epoch 21900, Train loss: 1.103e+03, Test loss: 5.562e+03, MSE(e): 1.005e-04, MSE(pi1): 2.644e-03, MSE(pi2): 9.187e-05, MSE(pi3): 7.103e-04\n",
      "Epoch 22000, Train loss: 1.100e+03, Test loss: 5.546e+03, MSE(e): 1.003e-04, MSE(pi1): 2.643e-03, MSE(pi2): 9.161e-05, MSE(pi3): 7.100e-04\n",
      "Epoch 22100, Train loss: 1.097e+03, Test loss: 5.530e+03, MSE(e): 9.999e-05, MSE(pi1): 2.643e-03, MSE(pi2): 9.136e-05, MSE(pi3): 7.096e-04\n",
      "Epoch 22200, Train loss: 1.095e+03, Test loss: 5.515e+03, MSE(e): 9.971e-05, MSE(pi1): 2.643e-03, MSE(pi2): 9.111e-05, MSE(pi3): 7.093e-04\n",
      "Epoch 22300, Train loss: 1.092e+03, Test loss: 5.499e+03, MSE(e): 9.944e-05, MSE(pi1): 2.642e-03, MSE(pi2): 9.086e-05, MSE(pi3): 7.089e-04\n",
      "Epoch 22400, Train loss: 1.089e+03, Test loss: 5.484e+03, MSE(e): 9.918e-05, MSE(pi1): 2.642e-03, MSE(pi2): 9.061e-05, MSE(pi3): 7.086e-04\n",
      "Epoch 22500, Train loss: 1.086e+03, Test loss: 5.469e+03, MSE(e): 9.891e-05, MSE(pi1): 2.642e-03, MSE(pi2): 9.036e-05, MSE(pi3): 7.082e-04\n",
      "Epoch 22600, Train loss: 1.084e+03, Test loss: 5.454e+03, MSE(e): 9.864e-05, MSE(pi1): 2.641e-03, MSE(pi2): 9.012e-05, MSE(pi3): 7.079e-04\n",
      "Epoch 22700, Train loss: 1.081e+03, Test loss: 5.439e+03, MSE(e): 9.838e-05, MSE(pi1): 2.641e-03, MSE(pi2): 8.987e-05, MSE(pi3): 7.076e-04\n",
      "Epoch 22800, Train loss: 1.078e+03, Test loss: 5.424e+03, MSE(e): 9.812e-05, MSE(pi1): 2.641e-03, MSE(pi2): 8.963e-05, MSE(pi3): 7.072e-04\n",
      "Epoch 22900, Train loss: 1.076e+03, Test loss: 5.410e+03, MSE(e): 9.786e-05, MSE(pi1): 2.640e-03, MSE(pi2): 8.939e-05, MSE(pi3): 7.069e-04\n",
      "Epoch 23000, Train loss: 1.073e+03, Test loss: 5.395e+03, MSE(e): 9.760e-05, MSE(pi1): 2.640e-03, MSE(pi2): 8.915e-05, MSE(pi3): 7.066e-04\n",
      "Epoch 23100, Train loss: 1.071e+03, Test loss: 5.381e+03, MSE(e): 9.735e-05, MSE(pi1): 2.640e-03, MSE(pi2): 8.892e-05, MSE(pi3): 7.063e-04\n",
      "Epoch 23200, Train loss: 1.068e+03, Test loss: 5.367e+03, MSE(e): 9.710e-05, MSE(pi1): 2.640e-03, MSE(pi2): 8.868e-05, MSE(pi3): 7.059e-04\n",
      "Epoch 23300, Train loss: 1.066e+03, Test loss: 5.353e+03, MSE(e): 9.685e-05, MSE(pi1): 2.639e-03, MSE(pi2): 8.845e-05, MSE(pi3): 7.056e-04\n",
      "Epoch 23400, Train loss: 1.063e+03, Test loss: 5.339e+03, MSE(e): 9.660e-05, MSE(pi1): 2.638e-03, MSE(pi2): 8.823e-05, MSE(pi3): 7.053e-04\n",
      "Epoch 23500, Train loss: 1.061e+03, Test loss: 5.325e+03, MSE(e): 9.636e-05, MSE(pi1): 2.637e-03, MSE(pi2): 8.800e-05, MSE(pi3): 7.051e-04\n",
      "Epoch 23600, Train loss: 1.058e+03, Test loss: 5.311e+03, MSE(e): 9.611e-05, MSE(pi1): 2.638e-03, MSE(pi2): 8.778e-05, MSE(pi3): 7.047e-04\n",
      "Epoch 23700, Train loss: 1.056e+03, Test loss: 5.297e+03, MSE(e): 9.586e-05, MSE(pi1): 2.637e-03, MSE(pi2): 8.755e-05, MSE(pi3): 7.044e-04\n",
      "Epoch 23800, Train loss: 1.053e+03, Test loss: 5.284e+03, MSE(e): 9.562e-05, MSE(pi1): 2.637e-03, MSE(pi2): 8.733e-05, MSE(pi3): 7.041e-04\n",
      "Epoch 23900, Train loss: 1.051e+03, Test loss: 5.271e+03, MSE(e): 9.539e-05, MSE(pi1): 2.637e-03, MSE(pi2): 8.711e-05, MSE(pi3): 7.038e-04\n",
      "Epoch 24000, Train loss: 1.048e+03, Test loss: 5.257e+03, MSE(e): 9.515e-05, MSE(pi1): 2.637e-03, MSE(pi2): 8.688e-05, MSE(pi3): 7.035e-04\n",
      "Epoch 24100, Train loss: 1.046e+03, Test loss: 5.244e+03, MSE(e): 9.491e-05, MSE(pi1): 2.636e-03, MSE(pi2): 8.667e-05, MSE(pi3): 7.032e-04\n",
      "Epoch 24200, Train loss: 1.044e+03, Test loss: 5.231e+03, MSE(e): 9.468e-05, MSE(pi1): 2.636e-03, MSE(pi2): 8.645e-05, MSE(pi3): 7.029e-04\n",
      "Epoch 24300, Train loss: 1.041e+03, Test loss: 5.218e+03, MSE(e): 9.445e-05, MSE(pi1): 2.636e-03, MSE(pi2): 8.623e-05, MSE(pi3): 7.026e-04\n",
      "Epoch 24400, Train loss: 1.039e+03, Test loss: 5.205e+03, MSE(e): 9.421e-05, MSE(pi1): 2.635e-03, MSE(pi2): 8.602e-05, MSE(pi3): 7.023e-04\n",
      "Epoch 24500, Train loss: 1.036e+03, Test loss: 5.192e+03, MSE(e): 9.398e-05, MSE(pi1): 2.635e-03, MSE(pi2): 8.580e-05, MSE(pi3): 7.020e-04\n",
      "Epoch 24600, Train loss: 1.034e+03, Test loss: 5.180e+03, MSE(e): 9.375e-05, MSE(pi1): 2.635e-03, MSE(pi2): 8.559e-05, MSE(pi3): 7.017e-04\n",
      "Epoch 24700, Train loss: 1.032e+03, Test loss: 5.167e+03, MSE(e): 9.352e-05, MSE(pi1): 2.634e-03, MSE(pi2): 8.538e-05, MSE(pi3): 7.015e-04\n",
      "Epoch 24800, Train loss: 1.030e+03, Test loss: 5.154e+03, MSE(e): 9.330e-05, MSE(pi1): 2.634e-03, MSE(pi2): 8.517e-05, MSE(pi3): 7.012e-04\n",
      "Epoch 24900, Train loss: 1.027e+03, Test loss: 5.142e+03, MSE(e): 9.307e-05, MSE(pi1): 2.634e-03, MSE(pi2): 8.497e-05, MSE(pi3): 7.009e-04\n",
      "Epoch 25000, Train loss: 1.025e+03, Test loss: 5.129e+03, MSE(e): 9.285e-05, MSE(pi1): 2.634e-03, MSE(pi2): 8.476e-05, MSE(pi3): 7.006e-04\n",
      "Epoch 25100, Train loss: 1.023e+03, Test loss: 5.117e+03, MSE(e): 9.263e-05, MSE(pi1): 2.633e-03, MSE(pi2): 8.456e-05, MSE(pi3): 7.003e-04\n",
      "Epoch 25200, Train loss: 1.021e+03, Test loss: 5.105e+03, MSE(e): 9.241e-05, MSE(pi1): 2.633e-03, MSE(pi2): 8.435e-05, MSE(pi3): 7.001e-04\n",
      "Epoch 25300, Train loss: 1.018e+03, Test loss: 5.092e+03, MSE(e): 9.219e-05, MSE(pi1): 2.633e-03, MSE(pi2): 8.415e-05, MSE(pi3): 6.998e-04\n",
      "Epoch 25400, Train loss: 1.016e+03, Test loss: 5.080e+03, MSE(e): 9.198e-05, MSE(pi1): 2.632e-03, MSE(pi2): 8.395e-05, MSE(pi3): 6.996e-04\n",
      "Epoch 25500, Train loss: 1.014e+03, Test loss: 5.068e+03, MSE(e): 9.176e-05, MSE(pi1): 2.633e-03, MSE(pi2): 8.376e-05, MSE(pi3): 6.992e-04\n",
      "Epoch 25600, Train loss: 1.012e+03, Test loss: 5.056e+03, MSE(e): 9.155e-05, MSE(pi1): 2.632e-03, MSE(pi2): 8.356e-05, MSE(pi3): 6.990e-04\n",
      "Epoch 25700, Train loss: 1.010e+03, Test loss: 5.044e+03, MSE(e): 9.134e-05, MSE(pi1): 2.632e-03, MSE(pi2): 8.336e-05, MSE(pi3): 6.987e-04\n",
      "Epoch 25800, Train loss: 1.007e+03, Test loss: 5.032e+03, MSE(e): 9.112e-05, MSE(pi1): 2.631e-03, MSE(pi2): 8.317e-05, MSE(pi3): 6.985e-04\n",
      "Epoch 25900, Train loss: 1.005e+03, Test loss: 5.020e+03, MSE(e): 9.092e-05, MSE(pi1): 2.631e-03, MSE(pi2): 8.297e-05, MSE(pi3): 6.983e-04\n",
      "Epoch 26000, Train loss: 1.003e+03, Test loss: 5.008e+03, MSE(e): 9.071e-05, MSE(pi1): 2.631e-03, MSE(pi2): 8.278e-05, MSE(pi3): 6.980e-04\n",
      "Epoch 26100, Train loss: 1.001e+03, Test loss: 4.996e+03, MSE(e): 9.050e-05, MSE(pi1): 2.632e-03, MSE(pi2): 8.259e-05, MSE(pi3): 6.976e-04\n",
      "Epoch 26200, Train loss: 9.991e+02, Test loss: 4.984e+03, MSE(e): 9.030e-05, MSE(pi1): 2.630e-03, MSE(pi2): 8.240e-05, MSE(pi3): 6.975e-04\n",
      "Epoch 26300, Train loss: 9.971e+02, Test loss: 4.972e+03, MSE(e): 9.010e-05, MSE(pi1): 2.630e-03, MSE(pi2): 8.222e-05, MSE(pi3): 6.972e-04\n",
      "Epoch 26400, Train loss: 9.950e+02, Test loss: 4.961e+03, MSE(e): 8.989e-05, MSE(pi1): 2.630e-03, MSE(pi2): 8.202e-05, MSE(pi3): 6.969e-04\n",
      "Epoch 26500, Train loss: 9.929e+02, Test loss: 4.949e+03, MSE(e): 8.969e-05, MSE(pi1): 2.630e-03, MSE(pi2): 8.184e-05, MSE(pi3): 6.967e-04\n",
      "Epoch 26600, Train loss: 9.909e+02, Test loss: 4.937e+03, MSE(e): 8.949e-05, MSE(pi1): 2.628e-03, MSE(pi2): 8.165e-05, MSE(pi3): 6.966e-04\n",
      "Epoch 26700, Train loss: 9.889e+02, Test loss: 4.926e+03, MSE(e): 8.929e-05, MSE(pi1): 2.631e-03, MSE(pi2): 8.146e-05, MSE(pi3): 6.961e-04\n",
      "Epoch 26800, Train loss: 9.869e+02, Test loss: 4.914e+03, MSE(e): 8.909e-05, MSE(pi1): 2.629e-03, MSE(pi2): 8.127e-05, MSE(pi3): 6.960e-04\n",
      "Epoch 26900, Train loss: 9.849e+02, Test loss: 4.902e+03, MSE(e): 8.889e-05, MSE(pi1): 2.630e-03, MSE(pi2): 8.109e-05, MSE(pi3): 6.957e-04\n",
      "Epoch 27000, Train loss: 9.829e+02, Test loss: 4.890e+03, MSE(e): 8.870e-05, MSE(pi1): 2.629e-03, MSE(pi2): 8.091e-05, MSE(pi3): 6.955e-04\n",
      "Epoch 27100, Train loss: 9.809e+02, Test loss: 4.879e+03, MSE(e): 8.851e-05, MSE(pi1): 2.629e-03, MSE(pi2): 8.073e-05, MSE(pi3): 6.953e-04\n",
      "Epoch 27200, Train loss: 9.790e+02, Test loss: 4.867e+03, MSE(e): 8.831e-05, MSE(pi1): 2.629e-03, MSE(pi2): 8.055e-05, MSE(pi3): 6.950e-04\n",
      "Epoch 27300, Train loss: 9.771e+02, Test loss: 4.855e+03, MSE(e): 8.812e-05, MSE(pi1): 2.629e-03, MSE(pi2): 8.037e-05, MSE(pi3): 6.948e-04\n",
      "Epoch 27400, Train loss: 9.751e+02, Test loss: 4.844e+03, MSE(e): 8.793e-05, MSE(pi1): 2.628e-03, MSE(pi2): 8.020e-05, MSE(pi3): 6.946e-04\n",
      "Epoch 27500, Train loss: 9.732e+02, Test loss: 4.833e+03, MSE(e): 8.774e-05, MSE(pi1): 2.628e-03, MSE(pi2): 8.002e-05, MSE(pi3): 6.943e-04\n",
      "Epoch 27600, Train loss: 9.713e+02, Test loss: 4.821e+03, MSE(e): 8.755e-05, MSE(pi1): 2.628e-03, MSE(pi2): 7.984e-05, MSE(pi3): 6.941e-04\n",
      "Epoch 27700, Train loss: 9.694e+02, Test loss: 4.810e+03, MSE(e): 8.737e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.967e-05, MSE(pi3): 6.941e-04\n",
      "Epoch 27800, Train loss: 9.676e+02, Test loss: 4.799e+03, MSE(e): 8.718e-05, MSE(pi1): 2.629e-03, MSE(pi2): 7.949e-05, MSE(pi3): 6.936e-04\n",
      "Epoch 27900, Train loss: 9.657e+02, Test loss: 4.787e+03, MSE(e): 8.700e-05, MSE(pi1): 2.628e-03, MSE(pi2): 7.932e-05, MSE(pi3): 6.934e-04\n",
      "Epoch 28000, Train loss: 9.638e+02, Test loss: 4.776e+03, MSE(e): 8.681e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.914e-05, MSE(pi3): 6.932e-04\n",
      "Epoch 28100, Train loss: 9.619e+02, Test loss: 4.765e+03, MSE(e): 8.663e-05, MSE(pi1): 2.628e-03, MSE(pi2): 7.897e-05, MSE(pi3): 6.929e-04\n",
      "Epoch 28200, Train loss: 9.601e+02, Test loss: 4.753e+03, MSE(e): 8.645e-05, MSE(pi1): 2.628e-03, MSE(pi2): 7.880e-05, MSE(pi3): 6.927e-04\n",
      "Epoch 28300, Train loss: 9.582e+02, Test loss: 4.742e+03, MSE(e): 8.626e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.863e-05, MSE(pi3): 6.927e-04\n",
      "Epoch 28400, Train loss: 9.565e+02, Test loss: 4.731e+03, MSE(e): 8.609e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.846e-05, MSE(pi3): 6.924e-04\n",
      "Epoch 28500, Train loss: 9.546e+02, Test loss: 4.720e+03, MSE(e): 8.590e-05, MSE(pi1): 2.628e-03, MSE(pi2): 7.828e-05, MSE(pi3): 6.921e-04\n",
      "Epoch 28600, Train loss: 9.528e+02, Test loss: 4.708e+03, MSE(e): 8.573e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.812e-05, MSE(pi3): 6.919e-04\n",
      "Epoch 28700, Train loss: 9.511e+02, Test loss: 4.697e+03, MSE(e): 8.556e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.796e-05, MSE(pi3): 6.917e-04\n",
      "Epoch 28800, Train loss: 9.493e+02, Test loss: 4.686e+03, MSE(e): 8.538e-05, MSE(pi1): 2.628e-03, MSE(pi2): 7.779e-05, MSE(pi3): 6.914e-04\n",
      "Epoch 28900, Train loss: 9.476e+02, Test loss: 4.675e+03, MSE(e): 8.521e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.763e-05, MSE(pi3): 6.913e-04\n",
      "Epoch 29000, Train loss: 9.458e+02, Test loss: 4.664e+03, MSE(e): 8.503e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.746e-05, MSE(pi3): 6.911e-04\n",
      "Epoch 29100, Train loss: 9.441e+02, Test loss: 4.652e+03, MSE(e): 8.486e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.730e-05, MSE(pi3): 6.908e-04\n",
      "Epoch 29200, Train loss: 9.423e+02, Test loss: 4.641e+03, MSE(e): 8.469e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.713e-05, MSE(pi3): 6.907e-04\n",
      "Epoch 29300, Train loss: 9.406e+02, Test loss: 4.630e+03, MSE(e): 8.453e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.697e-05, MSE(pi3): 6.905e-04\n",
      "Epoch 29400, Train loss: 9.389e+02, Test loss: 4.619e+03, MSE(e): 8.435e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.681e-05, MSE(pi3): 6.902e-04\n",
      "Epoch 29500, Train loss: 9.372e+02, Test loss: 4.608e+03, MSE(e): 8.419e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.665e-05, MSE(pi3): 6.900e-04\n",
      "Epoch 29600, Train loss: 9.355e+02, Test loss: 4.597e+03, MSE(e): 8.402e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.649e-05, MSE(pi3): 6.900e-04\n",
      "Epoch 29700, Train loss: 9.338e+02, Test loss: 4.586e+03, MSE(e): 8.385e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.633e-05, MSE(pi3): 6.898e-04\n",
      "Epoch 29800, Train loss: 9.321e+02, Test loss: 4.576e+03, MSE(e): 8.368e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.617e-05, MSE(pi3): 6.895e-04\n",
      "Epoch 29900, Train loss: 9.305e+02, Test loss: 4.565e+03, MSE(e): 8.352e-05, MSE(pi1): 2.623e-03, MSE(pi2): 7.601e-05, MSE(pi3): 6.896e-04\n",
      "Epoch 30000, Train loss: 9.288e+02, Test loss: 4.554e+03, MSE(e): 8.335e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.585e-05, MSE(pi3): 6.891e-04\n",
      "Epoch 30100, Train loss: 9.271e+02, Test loss: 4.543e+03, MSE(e): 8.319e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.570e-05, MSE(pi3): 6.888e-04\n",
      "Epoch 30200, Train loss: 9.254e+02, Test loss: 4.533e+03, MSE(e): 8.302e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.554e-05, MSE(pi3): 6.888e-04\n",
      "Epoch 30300, Train loss: 9.238e+02, Test loss: 4.522e+03, MSE(e): 8.286e-05, MSE(pi1): 2.624e-03, MSE(pi2): 7.538e-05, MSE(pi3): 6.887e-04\n",
      "Epoch 30400, Train loss: 9.222e+02, Test loss: 4.511e+03, MSE(e): 8.270e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.522e-05, MSE(pi3): 6.883e-04\n",
      "Epoch 30500, Train loss: 9.206e+02, Test loss: 4.501e+03, MSE(e): 8.255e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.507e-05, MSE(pi3): 6.882e-04\n",
      "Epoch 30600, Train loss: 9.190e+02, Test loss: 4.490e+03, MSE(e): 8.239e-05, MSE(pi1): 2.624e-03, MSE(pi2): 7.491e-05, MSE(pi3): 6.881e-04\n",
      "Epoch 30700, Train loss: 9.174e+02, Test loss: 4.480e+03, MSE(e): 8.223e-05, MSE(pi1): 2.624e-03, MSE(pi2): 7.476e-05, MSE(pi3): 6.879e-04\n",
      "Epoch 30800, Train loss: 9.158e+02, Test loss: 4.470e+03, MSE(e): 8.207e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.461e-05, MSE(pi3): 6.876e-04\n",
      "Epoch 30900, Train loss: 9.142e+02, Test loss: 4.459e+03, MSE(e): 8.191e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.446e-05, MSE(pi3): 6.873e-04\n",
      "Epoch 31000, Train loss: 9.126e+02, Test loss: 4.449e+03, MSE(e): 8.176e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.431e-05, MSE(pi3): 6.872e-04\n",
      "Epoch 31100, Train loss: 9.111e+02, Test loss: 4.438e+03, MSE(e): 8.160e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.416e-05, MSE(pi3): 6.871e-04\n",
      "Epoch 31200, Train loss: 9.095e+02, Test loss: 4.428e+03, MSE(e): 8.145e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.400e-05, MSE(pi3): 6.869e-04\n",
      "Epoch 31300, Train loss: 9.079e+02, Test loss: 4.418e+03, MSE(e): 8.129e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.385e-05, MSE(pi3): 6.866e-04\n",
      "Epoch 31400, Train loss: 9.064e+02, Test loss: 4.407e+03, MSE(e): 8.115e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.371e-05, MSE(pi3): 6.865e-04\n",
      "Epoch 31500, Train loss: 9.049e+02, Test loss: 4.397e+03, MSE(e): 8.100e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.356e-05, MSE(pi3): 6.864e-04\n",
      "Epoch 31600, Train loss: 9.034e+02, Test loss: 4.387e+03, MSE(e): 8.085e-05, MSE(pi1): 2.622e-03, MSE(pi2): 7.342e-05, MSE(pi3): 6.864e-04\n",
      "Epoch 31700, Train loss: 9.019e+02, Test loss: 4.377e+03, MSE(e): 8.070e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.327e-05, MSE(pi3): 6.859e-04\n",
      "Epoch 31800, Train loss: 9.004e+02, Test loss: 4.367e+03, MSE(e): 8.055e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.312e-05, MSE(pi3): 6.858e-04\n",
      "Epoch 31900, Train loss: 8.989e+02, Test loss: 4.357e+03, MSE(e): 8.040e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.298e-05, MSE(pi3): 6.856e-04\n",
      "Epoch 32000, Train loss: 8.974e+02, Test loss: 4.347e+03, MSE(e): 8.025e-05, MSE(pi1): 2.625e-03, MSE(pi2): 7.283e-05, MSE(pi3): 6.855e-04\n",
      "Epoch 32100, Train loss: 8.960e+02, Test loss: 4.337e+03, MSE(e): 8.011e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.269e-05, MSE(pi3): 6.853e-04\n",
      "Epoch 32200, Train loss: 8.945e+02, Test loss: 4.327e+03, MSE(e): 7.997e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.255e-05, MSE(pi3): 6.851e-04\n",
      "Epoch 32300, Train loss: 8.930e+02, Test loss: 4.317e+03, MSE(e): 7.982e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.241e-05, MSE(pi3): 6.849e-04\n",
      "Epoch 32400, Train loss: 8.915e+02, Test loss: 4.308e+03, MSE(e): 7.967e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.226e-05, MSE(pi3): 6.848e-04\n",
      "Epoch 32500, Train loss: 8.901e+02, Test loss: 4.298e+03, MSE(e): 7.953e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.212e-05, MSE(pi3): 6.847e-04\n",
      "Epoch 32600, Train loss: 8.887e+02, Test loss: 4.288e+03, MSE(e): 7.939e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.198e-05, MSE(pi3): 6.845e-04\n",
      "Epoch 32700, Train loss: 8.873e+02, Test loss: 4.278e+03, MSE(e): 7.925e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.184e-05, MSE(pi3): 6.843e-04\n",
      "Epoch 32800, Train loss: 8.858e+02, Test loss: 4.268e+03, MSE(e): 7.911e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.170e-05, MSE(pi3): 6.841e-04\n",
      "Epoch 32900, Train loss: 8.844e+02, Test loss: 4.259e+03, MSE(e): 7.897e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.156e-05, MSE(pi3): 6.840e-04\n",
      "Epoch 33000, Train loss: 8.830e+02, Test loss: 4.249e+03, MSE(e): 7.882e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.142e-05, MSE(pi3): 6.839e-04\n",
      "Epoch 33100, Train loss: 8.816e+02, Test loss: 4.240e+03, MSE(e): 7.869e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.128e-05, MSE(pi3): 6.837e-04\n",
      "Epoch 33200, Train loss: 8.802e+02, Test loss: 4.230e+03, MSE(e): 7.855e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.114e-05, MSE(pi3): 6.835e-04\n",
      "Epoch 33300, Train loss: 8.789e+02, Test loss: 4.221e+03, MSE(e): 7.842e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.101e-05, MSE(pi3): 6.833e-04\n",
      "Epoch 33400, Train loss: 8.774e+02, Test loss: 4.211e+03, MSE(e): 7.828e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.087e-05, MSE(pi3): 6.832e-04\n",
      "Epoch 33500, Train loss: 8.760e+02, Test loss: 4.202e+03, MSE(e): 7.814e-05, MSE(pi1): 2.626e-03, MSE(pi2): 7.073e-05, MSE(pi3): 6.831e-04\n",
      "Epoch 33600, Train loss: 8.747e+02, Test loss: 4.193e+03, MSE(e): 7.800e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.059e-05, MSE(pi3): 6.829e-04\n",
      "Epoch 33700, Train loss: 8.733e+02, Test loss: 4.184e+03, MSE(e): 7.787e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.046e-05, MSE(pi3): 6.828e-04\n",
      "Epoch 33800, Train loss: 8.720e+02, Test loss: 4.174e+03, MSE(e): 7.774e-05, MSE(pi1): 2.628e-03, MSE(pi2): 7.032e-05, MSE(pi3): 6.826e-04\n",
      "Epoch 33900, Train loss: 8.706e+02, Test loss: 4.165e+03, MSE(e): 7.761e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.019e-05, MSE(pi3): 6.824e-04\n",
      "Epoch 34000, Train loss: 8.692e+02, Test loss: 4.156e+03, MSE(e): 7.747e-05, MSE(pi1): 2.627e-03, MSE(pi2): 7.005e-05, MSE(pi3): 6.823e-04\n",
      "Epoch 34100, Train loss: 8.679e+02, Test loss: 4.147e+03, MSE(e): 7.733e-05, MSE(pi1): 2.628e-03, MSE(pi2): 6.992e-05, MSE(pi3): 6.821e-04\n",
      "Epoch 34200, Train loss: 8.666e+02, Test loss: 4.138e+03, MSE(e): 7.720e-05, MSE(pi1): 2.628e-03, MSE(pi2): 6.978e-05, MSE(pi3): 6.820e-04\n",
      "Epoch 34300, Train loss: 8.653e+02, Test loss: 4.128e+03, MSE(e): 7.708e-05, MSE(pi1): 2.626e-03, MSE(pi2): 6.965e-05, MSE(pi3): 6.820e-04\n",
      "Epoch 34400, Train loss: 8.639e+02, Test loss: 4.120e+03, MSE(e): 7.694e-05, MSE(pi1): 2.628e-03, MSE(pi2): 6.952e-05, MSE(pi3): 6.817e-04\n",
      "Epoch 34500, Train loss: 8.626e+02, Test loss: 4.110e+03, MSE(e): 7.681e-05, MSE(pi1): 2.628e-03, MSE(pi2): 6.939e-05, MSE(pi3): 6.815e-04\n",
      "Epoch 34600, Train loss: 8.613e+02, Test loss: 4.102e+03, MSE(e): 7.669e-05, MSE(pi1): 2.629e-03, MSE(pi2): 6.926e-05, MSE(pi3): 6.813e-04\n",
      "Epoch 34700, Train loss: 8.600e+02, Test loss: 4.093e+03, MSE(e): 7.655e-05, MSE(pi1): 2.628e-03, MSE(pi2): 6.912e-05, MSE(pi3): 6.813e-04\n",
      "Epoch 34800, Train loss: 8.588e+02, Test loss: 4.084e+03, MSE(e): 7.643e-05, MSE(pi1): 2.626e-03, MSE(pi2): 6.900e-05, MSE(pi3): 6.813e-04\n",
      "Epoch 34900, Train loss: 8.575e+02, Test loss: 4.075e+03, MSE(e): 7.630e-05, MSE(pi1): 2.630e-03, MSE(pi2): 6.886e-05, MSE(pi3): 6.809e-04\n",
      "Epoch 35000, Train loss: 8.562e+02, Test loss: 4.066e+03, MSE(e): 7.617e-05, MSE(pi1): 2.629e-03, MSE(pi2): 6.873e-05, MSE(pi3): 6.808e-04\n",
      "Epoch 35100, Train loss: 8.549e+02, Test loss: 4.058e+03, MSE(e): 7.604e-05, MSE(pi1): 2.629e-03, MSE(pi2): 6.860e-05, MSE(pi3): 6.806e-04\n",
      "Epoch 35200, Train loss: 8.537e+02, Test loss: 4.049e+03, MSE(e): 7.592e-05, MSE(pi1): 2.629e-03, MSE(pi2): 6.848e-05, MSE(pi3): 6.805e-04\n",
      "Epoch 35300, Train loss: 8.524e+02, Test loss: 4.040e+03, MSE(e): 7.580e-05, MSE(pi1): 2.630e-03, MSE(pi2): 6.835e-05, MSE(pi3): 6.804e-04\n",
      "Epoch 35400, Train loss: 8.511e+02, Test loss: 4.031e+03, MSE(e): 7.567e-05, MSE(pi1): 2.627e-03, MSE(pi2): 6.822e-05, MSE(pi3): 6.804e-04\n",
      "Epoch 35500, Train loss: 8.499e+02, Test loss: 4.023e+03, MSE(e): 7.555e-05, MSE(pi1): 2.632e-03, MSE(pi2): 6.809e-05, MSE(pi3): 6.799e-04\n",
      "Epoch 35600, Train loss: 8.486e+02, Test loss: 4.014e+03, MSE(e): 7.543e-05, MSE(pi1): 2.630e-03, MSE(pi2): 6.796e-05, MSE(pi3): 6.799e-04\n",
      "Epoch 35700, Train loss: 8.473e+02, Test loss: 4.006e+03, MSE(e): 7.530e-05, MSE(pi1): 2.630e-03, MSE(pi2): 6.783e-05, MSE(pi3): 6.798e-04\n",
      "Epoch 35800, Train loss: 8.461e+02, Test loss: 3.997e+03, MSE(e): 7.518e-05, MSE(pi1): 2.631e-03, MSE(pi2): 6.770e-05, MSE(pi3): 6.797e-04\n",
      "Epoch 35900, Train loss: 8.448e+02, Test loss: 3.989e+03, MSE(e): 7.505e-05, MSE(pi1): 2.629e-03, MSE(pi2): 6.757e-05, MSE(pi3): 6.797e-04\n",
      "Epoch 36000, Train loss: 8.436e+02, Test loss: 3.980e+03, MSE(e): 7.493e-05, MSE(pi1): 2.630e-03, MSE(pi2): 6.745e-05, MSE(pi3): 6.795e-04\n",
      "Epoch 36100, Train loss: 8.424e+02, Test loss: 3.972e+03, MSE(e): 7.481e-05, MSE(pi1): 2.630e-03, MSE(pi2): 6.732e-05, MSE(pi3): 6.793e-04\n",
      "Epoch 36200, Train loss: 8.412e+02, Test loss: 3.964e+03, MSE(e): 7.469e-05, MSE(pi1): 2.630e-03, MSE(pi2): 6.720e-05, MSE(pi3): 6.792e-04\n",
      "Epoch 36300, Train loss: 8.399e+02, Test loss: 3.956e+03, MSE(e): 7.456e-05, MSE(pi1): 2.631e-03, MSE(pi2): 6.707e-05, MSE(pi3): 6.790e-04\n",
      "Epoch 36400, Train loss: 8.387e+02, Test loss: 3.947e+03, MSE(e): 7.444e-05, MSE(pi1): 2.632e-03, MSE(pi2): 6.695e-05, MSE(pi3): 6.789e-04\n",
      "Epoch 36500, Train loss: 8.375e+02, Test loss: 3.939e+03, MSE(e): 7.432e-05, MSE(pi1): 2.633e-03, MSE(pi2): 6.682e-05, MSE(pi3): 6.787e-04\n",
      "Epoch 36600, Train loss: 8.363e+02, Test loss: 3.931e+03, MSE(e): 7.421e-05, MSE(pi1): 2.630e-03, MSE(pi2): 6.670e-05, MSE(pi3): 6.788e-04\n",
      "Epoch 36700, Train loss: 8.351e+02, Test loss: 3.923e+03, MSE(e): 7.408e-05, MSE(pi1): 2.631e-03, MSE(pi2): 6.657e-05, MSE(pi3): 6.786e-04\n",
      "Epoch 36800, Train loss: 8.339e+02, Test loss: 3.915e+03, MSE(e): 7.397e-05, MSE(pi1): 2.633e-03, MSE(pi2): 6.645e-05, MSE(pi3): 6.783e-04\n",
      "Epoch 36900, Train loss: 8.327e+02, Test loss: 3.907e+03, MSE(e): 7.385e-05, MSE(pi1): 2.632e-03, MSE(pi2): 6.632e-05, MSE(pi3): 6.783e-04\n",
      "Epoch 37000, Train loss: 8.315e+02, Test loss: 3.899e+03, MSE(e): 7.373e-05, MSE(pi1): 2.633e-03, MSE(pi2): 6.620e-05, MSE(pi3): 6.781e-04\n",
      "Epoch 37100, Train loss: 8.303e+02, Test loss: 3.891e+03, MSE(e): 7.361e-05, MSE(pi1): 2.632e-03, MSE(pi2): 6.608e-05, MSE(pi3): 6.781e-04\n",
      "Epoch 37200, Train loss: 8.291e+02, Test loss: 3.884e+03, MSE(e): 7.349e-05, MSE(pi1): 2.633e-03, MSE(pi2): 6.595e-05, MSE(pi3): 6.779e-04\n",
      "Epoch 37300, Train loss: 8.279e+02, Test loss: 3.876e+03, MSE(e): 7.338e-05, MSE(pi1): 2.632e-03, MSE(pi2): 6.583e-05, MSE(pi3): 6.779e-04\n",
      "Epoch 37400, Train loss: 8.267e+02, Test loss: 3.868e+03, MSE(e): 7.325e-05, MSE(pi1): 2.633e-03, MSE(pi2): 6.571e-05, MSE(pi3): 6.776e-04\n",
      "Epoch 37500, Train loss: 8.256e+02, Test loss: 3.860e+03, MSE(e): 7.314e-05, MSE(pi1): 2.634e-03, MSE(pi2): 6.559e-05, MSE(pi3): 6.774e-04\n",
      "Epoch 37600, Train loss: 8.244e+02, Test loss: 3.852e+03, MSE(e): 7.303e-05, MSE(pi1): 2.635e-03, MSE(pi2): 6.547e-05, MSE(pi3): 6.773e-04\n",
      "Epoch 37700, Train loss: 8.233e+02, Test loss: 3.845e+03, MSE(e): 7.292e-05, MSE(pi1): 2.635e-03, MSE(pi2): 6.535e-05, MSE(pi3): 6.771e-04\n",
      "Epoch 37800, Train loss: 8.221e+02, Test loss: 3.837e+03, MSE(e): 7.280e-05, MSE(pi1): 2.635e-03, MSE(pi2): 6.523e-05, MSE(pi3): 6.771e-04\n",
      "Epoch 37900, Train loss: 8.210e+02, Test loss: 3.829e+03, MSE(e): 7.268e-05, MSE(pi1): 2.635e-03, MSE(pi2): 6.511e-05, MSE(pi3): 6.770e-04\n",
      "Epoch 38000, Train loss: 8.198e+02, Test loss: 3.822e+03, MSE(e): 7.257e-05, MSE(pi1): 2.635e-03, MSE(pi2): 6.499e-05, MSE(pi3): 6.768e-04\n",
      "Epoch 38100, Train loss: 8.187e+02, Test loss: 3.814e+03, MSE(e): 7.246e-05, MSE(pi1): 2.633e-03, MSE(pi2): 6.487e-05, MSE(pi3): 6.769e-04\n",
      "Epoch 38200, Train loss: 8.176e+02, Test loss: 3.806e+03, MSE(e): 7.235e-05, MSE(pi1): 2.640e-03, MSE(pi2): 6.475e-05, MSE(pi3): 6.764e-04\n",
      "Epoch 38300, Train loss: 8.165e+02, Test loss: 3.799e+03, MSE(e): 7.224e-05, MSE(pi1): 2.638e-03, MSE(pi2): 6.463e-05, MSE(pi3): 6.764e-04\n",
      "Epoch 38400, Train loss: 8.154e+02, Test loss: 3.791e+03, MSE(e): 7.214e-05, MSE(pi1): 2.634e-03, MSE(pi2): 6.452e-05, MSE(pi3): 6.765e-04\n",
      "Epoch 38500, Train loss: 8.143e+02, Test loss: 3.784e+03, MSE(e): 7.203e-05, MSE(pi1): 2.635e-03, MSE(pi2): 6.441e-05, MSE(pi3): 6.764e-04\n",
      "Epoch 38600, Train loss: 8.132e+02, Test loss: 3.777e+03, MSE(e): 7.191e-05, MSE(pi1): 2.638e-03, MSE(pi2): 6.429e-05, MSE(pi3): 6.761e-04\n",
      "Epoch 38700, Train loss: 8.122e+02, Test loss: 3.770e+03, MSE(e): 7.181e-05, MSE(pi1): 2.636e-03, MSE(pi2): 6.418e-05, MSE(pi3): 6.761e-04\n",
      "Epoch 38800, Train loss: 8.111e+02, Test loss: 3.762e+03, MSE(e): 7.171e-05, MSE(pi1): 2.636e-03, MSE(pi2): 6.407e-05, MSE(pi3): 6.760e-04\n",
      "Epoch 38900, Train loss: 8.100e+02, Test loss: 3.755e+03, MSE(e): 7.160e-05, MSE(pi1): 2.636e-03, MSE(pi2): 6.396e-05, MSE(pi3): 6.759e-04\n",
      "Epoch 39000, Train loss: 8.089e+02, Test loss: 3.748e+03, MSE(e): 7.149e-05, MSE(pi1): 2.639e-03, MSE(pi2): 6.384e-05, MSE(pi3): 6.756e-04\n",
      "Epoch 39100, Train loss: 8.079e+02, Test loss: 3.741e+03, MSE(e): 7.139e-05, MSE(pi1): 2.636e-03, MSE(pi2): 6.373e-05, MSE(pi3): 6.757e-04\n",
      "Epoch 39200, Train loss: 8.068e+02, Test loss: 3.734e+03, MSE(e): 7.128e-05, MSE(pi1): 2.637e-03, MSE(pi2): 6.362e-05, MSE(pi3): 6.756e-04\n",
      "Epoch 39300, Train loss: 8.057e+02, Test loss: 3.727e+03, MSE(e): 7.117e-05, MSE(pi1): 2.639e-03, MSE(pi2): 6.350e-05, MSE(pi3): 6.753e-04\n",
      "Epoch 39400, Train loss: 8.047e+02, Test loss: 3.720e+03, MSE(e): 7.107e-05, MSE(pi1): 2.639e-03, MSE(pi2): 6.339e-05, MSE(pi3): 6.752e-04\n",
      "Epoch 39500, Train loss: 8.036e+02, Test loss: 3.713e+03, MSE(e): 7.096e-05, MSE(pi1): 2.639e-03, MSE(pi2): 6.328e-05, MSE(pi3): 6.751e-04\n",
      "Epoch 39600, Train loss: 8.025e+02, Test loss: 3.706e+03, MSE(e): 7.085e-05, MSE(pi1): 2.639e-03, MSE(pi2): 6.316e-05, MSE(pi3): 6.750e-04\n",
      "Epoch 39700, Train loss: 8.015e+02, Test loss: 3.699e+03, MSE(e): 7.075e-05, MSE(pi1): 2.640e-03, MSE(pi2): 6.305e-05, MSE(pi3): 6.748e-04\n",
      "Epoch 39800, Train loss: 8.005e+02, Test loss: 3.693e+03, MSE(e): 7.065e-05, MSE(pi1): 2.642e-03, MSE(pi2): 6.295e-05, MSE(pi3): 6.746e-04\n",
      "Epoch 39900, Train loss: 7.994e+02, Test loss: 3.686e+03, MSE(e): 7.055e-05, MSE(pi1): 2.640e-03, MSE(pi2): 6.283e-05, MSE(pi3): 6.747e-04\n",
      "Epoch 40000, Train loss: 7.983e+02, Test loss: 3.679e+03, MSE(e): 7.044e-05, MSE(pi1): 2.637e-03, MSE(pi2): 6.272e-05, MSE(pi3): 6.748e-04\n",
      "Epoch 40100, Train loss: 7.973e+02, Test loss: 3.673e+03, MSE(e): 7.033e-05, MSE(pi1): 2.643e-03, MSE(pi2): 6.261e-05, MSE(pi3): 6.743e-04\n",
      "Epoch 40200, Train loss: 7.963e+02, Test loss: 3.665e+03, MSE(e): 7.024e-05, MSE(pi1): 2.639e-03, MSE(pi2): 6.250e-05, MSE(pi3): 6.745e-04\n",
      "Epoch 40300, Train loss: 7.953e+02, Test loss: 3.659e+03, MSE(e): 7.014e-05, MSE(pi1): 2.640e-03, MSE(pi2): 6.239e-05, MSE(pi3): 6.743e-04\n",
      "Epoch 40400, Train loss: 7.942e+02, Test loss: 3.652e+03, MSE(e): 7.003e-05, MSE(pi1): 2.643e-03, MSE(pi2): 6.228e-05, MSE(pi3): 6.740e-04\n",
      "Epoch 40500, Train loss: 7.931e+02, Test loss: 3.646e+03, MSE(e): 6.992e-05, MSE(pi1): 2.642e-03, MSE(pi2): 6.217e-05, MSE(pi3): 6.740e-04\n",
      "Epoch 40600, Train loss: 7.921e+02, Test loss: 3.639e+03, MSE(e): 6.983e-05, MSE(pi1): 2.643e-03, MSE(pi2): 6.206e-05, MSE(pi3): 6.738e-04\n",
      "Epoch 40700, Train loss: 7.911e+02, Test loss: 3.632e+03, MSE(e): 6.972e-05, MSE(pi1): 2.643e-03, MSE(pi2): 6.195e-05, MSE(pi3): 6.737e-04\n",
      "Epoch 40800, Train loss: 7.901e+02, Test loss: 3.626e+03, MSE(e): 6.963e-05, MSE(pi1): 2.644e-03, MSE(pi2): 6.184e-05, MSE(pi3): 6.735e-04\n",
      "Epoch 40900, Train loss: 7.891e+02, Test loss: 3.619e+03, MSE(e): 6.953e-05, MSE(pi1): 2.645e-03, MSE(pi2): 6.173e-05, MSE(pi3): 6.734e-04\n",
      "Epoch 41000, Train loss: 7.881e+02, Test loss: 3.613e+03, MSE(e): 6.943e-05, MSE(pi1): 2.645e-03, MSE(pi2): 6.163e-05, MSE(pi3): 6.734e-04\n",
      "Epoch 41100, Train loss: 7.872e+02, Test loss: 3.606e+03, MSE(e): 6.933e-05, MSE(pi1): 2.646e-03, MSE(pi2): 6.152e-05, MSE(pi3): 6.732e-04\n",
      "Epoch 41200, Train loss: 7.862e+02, Test loss: 3.600e+03, MSE(e): 6.923e-05, MSE(pi1): 2.648e-03, MSE(pi2): 6.142e-05, MSE(pi3): 6.730e-04\n",
      "Epoch 41300, Train loss: 7.851e+02, Test loss: 3.594e+03, MSE(e): 6.913e-05, MSE(pi1): 2.648e-03, MSE(pi2): 6.131e-05, MSE(pi3): 6.729e-04\n",
      "Epoch 41400, Train loss: 7.841e+02, Test loss: 3.588e+03, MSE(e): 6.903e-05, MSE(pi1): 2.648e-03, MSE(pi2): 6.120e-05, MSE(pi3): 6.728e-04\n",
      "Epoch 41500, Train loss: 7.831e+02, Test loss: 3.582e+03, MSE(e): 6.893e-05, MSE(pi1): 2.648e-03, MSE(pi2): 6.110e-05, MSE(pi3): 6.727e-04\n",
      "Epoch 41600, Train loss: 7.822e+02, Test loss: 3.575e+03, MSE(e): 6.884e-05, MSE(pi1): 2.648e-03, MSE(pi2): 6.099e-05, MSE(pi3): 6.726e-04\n",
      "Epoch 41700, Train loss: 7.812e+02, Test loss: 3.569e+03, MSE(e): 6.874e-05, MSE(pi1): 2.647e-03, MSE(pi2): 6.089e-05, MSE(pi3): 6.726e-04\n",
      "Epoch 41800, Train loss: 7.802e+02, Test loss: 3.563e+03, MSE(e): 6.864e-05, MSE(pi1): 2.643e-03, MSE(pi2): 6.078e-05, MSE(pi3): 6.729e-04\n",
      "Epoch 41900, Train loss: 7.793e+02, Test loss: 3.557e+03, MSE(e): 6.855e-05, MSE(pi1): 2.651e-03, MSE(pi2): 6.068e-05, MSE(pi3): 6.723e-04\n",
      "Epoch 42000, Train loss: 7.783e+02, Test loss: 3.551e+03, MSE(e): 6.845e-05, MSE(pi1): 2.648e-03, MSE(pi2): 6.058e-05, MSE(pi3): 6.723e-04\n",
      "Epoch 42100, Train loss: 7.772e+02, Test loss: 3.545e+03, MSE(e): 6.834e-05, MSE(pi1): 2.647e-03, MSE(pi2): 6.047e-05, MSE(pi3): 6.723e-04\n",
      "Epoch 42200, Train loss: 7.763e+02, Test loss: 3.538e+03, MSE(e): 6.826e-05, MSE(pi1): 2.647e-03, MSE(pi2): 6.037e-05, MSE(pi3): 6.723e-04\n",
      "Epoch 42300, Train loss: 7.754e+02, Test loss: 3.532e+03, MSE(e): 6.816e-05, MSE(pi1): 2.648e-03, MSE(pi2): 6.026e-05, MSE(pi3): 6.721e-04\n",
      "Epoch 42400, Train loss: 7.744e+02, Test loss: 3.526e+03, MSE(e): 6.806e-05, MSE(pi1): 2.649e-03, MSE(pi2): 6.016e-05, MSE(pi3): 6.720e-04\n",
      "Epoch 42500, Train loss: 7.735e+02, Test loss: 3.520e+03, MSE(e): 6.797e-05, MSE(pi1): 2.650e-03, MSE(pi2): 6.006e-05, MSE(pi3): 6.718e-04\n",
      "Epoch 42600, Train loss: 7.725e+02, Test loss: 3.514e+03, MSE(e): 6.788e-05, MSE(pi1): 2.650e-03, MSE(pi2): 5.995e-05, MSE(pi3): 6.717e-04\n",
      "Epoch 42700, Train loss: 7.716e+02, Test loss: 3.508e+03, MSE(e): 6.778e-05, MSE(pi1): 2.651e-03, MSE(pi2): 5.985e-05, MSE(pi3): 6.716e-04\n",
      "Epoch 42800, Train loss: 7.706e+02, Test loss: 3.502e+03, MSE(e): 6.769e-05, MSE(pi1): 2.652e-03, MSE(pi2): 5.975e-05, MSE(pi3): 6.714e-04\n",
      "Epoch 42900, Train loss: 7.697e+02, Test loss: 3.497e+03, MSE(e): 6.759e-05, MSE(pi1): 2.656e-03, MSE(pi2): 5.965e-05, MSE(pi3): 6.711e-04\n",
      "Epoch 43000, Train loss: 7.687e+02, Test loss: 3.490e+03, MSE(e): 6.750e-05, MSE(pi1): 2.652e-03, MSE(pi2): 5.954e-05, MSE(pi3): 6.713e-04\n",
      "Epoch 43100, Train loss: 7.677e+02, Test loss: 3.485e+03, MSE(e): 6.740e-05, MSE(pi1): 2.654e-03, MSE(pi2): 5.944e-05, MSE(pi3): 6.711e-04\n",
      "Epoch 43200, Train loss: 7.668e+02, Test loss: 3.479e+03, MSE(e): 6.731e-05, MSE(pi1): 2.654e-03, MSE(pi2): 5.934e-05, MSE(pi3): 6.710e-04\n",
      "Epoch 43300, Train loss: 7.659e+02, Test loss: 3.473e+03, MSE(e): 6.723e-05, MSE(pi1): 2.655e-03, MSE(pi2): 5.924e-05, MSE(pi3): 6.709e-04\n",
      "Epoch 43400, Train loss: 7.650e+02, Test loss: 3.467e+03, MSE(e): 6.713e-05, MSE(pi1): 2.655e-03, MSE(pi2): 5.914e-05, MSE(pi3): 6.707e-04\n",
      "Epoch 43500, Train loss: 7.640e+02, Test loss: 3.461e+03, MSE(e): 6.703e-05, MSE(pi1): 2.655e-03, MSE(pi2): 5.904e-05, MSE(pi3): 6.707e-04\n",
      "Epoch 43600, Train loss: 7.631e+02, Test loss: 3.455e+03, MSE(e): 6.694e-05, MSE(pi1): 2.655e-03, MSE(pi2): 5.894e-05, MSE(pi3): 6.706e-04\n",
      "Epoch 43700, Train loss: 7.622e+02, Test loss: 3.449e+03, MSE(e): 6.685e-05, MSE(pi1): 2.656e-03, MSE(pi2): 5.883e-05, MSE(pi3): 6.705e-04\n",
      "Epoch 43800, Train loss: 7.612e+02, Test loss: 3.444e+03, MSE(e): 6.676e-05, MSE(pi1): 2.657e-03, MSE(pi2): 5.873e-05, MSE(pi3): 6.703e-04\n",
      "Epoch 43900, Train loss: 7.603e+02, Test loss: 3.438e+03, MSE(e): 6.666e-05, MSE(pi1): 2.657e-03, MSE(pi2): 5.863e-05, MSE(pi3): 6.702e-04\n",
      "Epoch 44000, Train loss: 7.594e+02, Test loss: 3.432e+03, MSE(e): 6.658e-05, MSE(pi1): 2.658e-03, MSE(pi2): 5.853e-05, MSE(pi3): 6.701e-04\n",
      "Epoch 44100, Train loss: 7.585e+02, Test loss: 3.426e+03, MSE(e): 6.648e-05, MSE(pi1): 2.657e-03, MSE(pi2): 5.843e-05, MSE(pi3): 6.701e-04\n",
      "Epoch 44200, Train loss: 7.575e+02, Test loss: 3.420e+03, MSE(e): 6.639e-05, MSE(pi1): 2.657e-03, MSE(pi2): 5.833e-05, MSE(pi3): 6.701e-04\n",
      "Epoch 44300, Train loss: 7.567e+02, Test loss: 3.414e+03, MSE(e): 6.630e-05, MSE(pi1): 2.658e-03, MSE(pi2): 5.824e-05, MSE(pi3): 6.699e-04\n",
      "Epoch 44400, Train loss: 7.558e+02, Test loss: 3.408e+03, MSE(e): 6.622e-05, MSE(pi1): 2.658e-03, MSE(pi2): 5.814e-05, MSE(pi3): 6.699e-04\n",
      "Epoch 44500, Train loss: 7.548e+02, Test loss: 3.402e+03, MSE(e): 6.612e-05, MSE(pi1): 2.658e-03, MSE(pi2): 5.804e-05, MSE(pi3): 6.699e-04\n",
      "Epoch 44600, Train loss: 7.541e+02, Test loss: 3.397e+03, MSE(e): 6.604e-05, MSE(pi1): 2.658e-03, MSE(pi2): 5.795e-05, MSE(pi3): 6.698e-04\n",
      "Epoch 44700, Train loss: 7.531e+02, Test loss: 3.391e+03, MSE(e): 6.595e-05, MSE(pi1): 2.659e-03, MSE(pi2): 5.785e-05, MSE(pi3): 6.697e-04\n",
      "Epoch 44800, Train loss: 7.522e+02, Test loss: 3.385e+03, MSE(e): 6.586e-05, MSE(pi1): 2.659e-03, MSE(pi2): 5.775e-05, MSE(pi3): 6.696e-04\n",
      "Epoch 44900, Train loss: 7.514e+02, Test loss: 3.379e+03, MSE(e): 6.578e-05, MSE(pi1): 2.660e-03, MSE(pi2): 5.766e-05, MSE(pi3): 6.694e-04\n",
      "Epoch 45000, Train loss: 7.505e+02, Test loss: 3.374e+03, MSE(e): 6.569e-05, MSE(pi1): 2.661e-03, MSE(pi2): 5.756e-05, MSE(pi3): 6.693e-04\n",
      "Epoch 45100, Train loss: 7.495e+02, Test loss: 3.368e+03, MSE(e): 6.560e-05, MSE(pi1): 2.662e-03, MSE(pi2): 5.746e-05, MSE(pi3): 6.692e-04\n",
      "Epoch 45200, Train loss: 7.488e+02, Test loss: 3.362e+03, MSE(e): 6.552e-05, MSE(pi1): 2.661e-03, MSE(pi2): 5.737e-05, MSE(pi3): 6.691e-04\n",
      "Epoch 45300, Train loss: 7.479e+02, Test loss: 3.355e+03, MSE(e): 6.543e-05, MSE(pi1): 2.662e-03, MSE(pi2): 5.728e-05, MSE(pi3): 6.690e-04\n",
      "Epoch 45400, Train loss: 7.470e+02, Test loss: 3.350e+03, MSE(e): 6.534e-05, MSE(pi1): 2.664e-03, MSE(pi2): 5.718e-05, MSE(pi3): 6.688e-04\n",
      "Epoch 45500, Train loss: 7.461e+02, Test loss: 3.343e+03, MSE(e): 6.525e-05, MSE(pi1): 2.664e-03, MSE(pi2): 5.708e-05, MSE(pi3): 6.688e-04\n",
      "Epoch 45600, Train loss: 7.453e+02, Test loss: 3.336e+03, MSE(e): 6.517e-05, MSE(pi1): 2.664e-03, MSE(pi2): 5.699e-05, MSE(pi3): 6.687e-04\n",
      "Epoch 45700, Train loss: 7.443e+02, Test loss: 3.330e+03, MSE(e): 6.508e-05, MSE(pi1): 2.665e-03, MSE(pi2): 5.689e-05, MSE(pi3): 6.686e-04\n",
      "Epoch 45800, Train loss: 7.435e+02, Test loss: 3.323e+03, MSE(e): 6.499e-05, MSE(pi1): 2.665e-03, MSE(pi2): 5.679e-05, MSE(pi3): 6.686e-04\n",
      "Epoch 45900, Train loss: 7.427e+02, Test loss: 3.315e+03, MSE(e): 6.491e-05, MSE(pi1): 2.664e-03, MSE(pi2): 5.670e-05, MSE(pi3): 6.686e-04\n",
      "Epoch 46000, Train loss: 7.417e+02, Test loss: 3.308e+03, MSE(e): 6.482e-05, MSE(pi1): 2.665e-03, MSE(pi2): 5.661e-05, MSE(pi3): 6.685e-04\n",
      "Epoch 46100, Train loss: 7.409e+02, Test loss: 3.299e+03, MSE(e): 6.473e-05, MSE(pi1): 2.668e-03, MSE(pi2): 5.651e-05, MSE(pi3): 6.682e-04\n",
      "Epoch 46200, Train loss: 7.401e+02, Test loss: 3.290e+03, MSE(e): 6.465e-05, MSE(pi1): 2.666e-03, MSE(pi2): 5.642e-05, MSE(pi3): 6.683e-04\n",
      "Epoch 46300, Train loss: 7.391e+02, Test loss: 3.281e+03, MSE(e): 6.455e-05, MSE(pi1): 2.666e-03, MSE(pi2): 5.632e-05, MSE(pi3): 6.682e-04\n",
      "Epoch 46400, Train loss: 7.382e+02, Test loss: 3.271e+03, MSE(e): 6.447e-05, MSE(pi1): 2.668e-03, MSE(pi2): 5.623e-05, MSE(pi3): 6.681e-04\n",
      "Epoch 46500, Train loss: 7.373e+02, Test loss: 3.261e+03, MSE(e): 6.438e-05, MSE(pi1): 2.669e-03, MSE(pi2): 5.614e-05, MSE(pi3): 6.679e-04\n",
      "Epoch 46600, Train loss: 7.364e+02, Test loss: 3.252e+03, MSE(e): 6.428e-05, MSE(pi1): 2.667e-03, MSE(pi2): 5.605e-05, MSE(pi3): 6.680e-04\n",
      "Epoch 46700, Train loss: 7.354e+02, Test loss: 3.242e+03, MSE(e): 6.419e-05, MSE(pi1): 2.668e-03, MSE(pi2): 5.595e-05, MSE(pi3): 6.679e-04\n",
      "Epoch 46800, Train loss: 7.345e+02, Test loss: 3.233e+03, MSE(e): 6.409e-05, MSE(pi1): 2.665e-03, MSE(pi2): 5.586e-05, MSE(pi3): 6.681e-04\n",
      "Epoch 46900, Train loss: 7.336e+02, Test loss: 3.224e+03, MSE(e): 6.401e-05, MSE(pi1): 2.672e-03, MSE(pi2): 5.577e-05, MSE(pi3): 6.675e-04\n",
      "Epoch 47000, Train loss: 7.326e+02, Test loss: 3.215e+03, MSE(e): 6.391e-05, MSE(pi1): 2.669e-03, MSE(pi2): 5.567e-05, MSE(pi3): 6.676e-04\n",
      "Epoch 47100, Train loss: 7.316e+02, Test loss: 3.207e+03, MSE(e): 6.381e-05, MSE(pi1): 2.670e-03, MSE(pi2): 5.557e-05, MSE(pi3): 6.676e-04\n",
      "Epoch 47200, Train loss: 7.307e+02, Test loss: 3.198e+03, MSE(e): 6.372e-05, MSE(pi1): 2.672e-03, MSE(pi2): 5.548e-05, MSE(pi3): 6.673e-04\n",
      "Epoch 47300, Train loss: 7.298e+02, Test loss: 3.190e+03, MSE(e): 6.363e-05, MSE(pi1): 2.672e-03, MSE(pi2): 5.538e-05, MSE(pi3): 6.672e-04\n",
      "Epoch 47400, Train loss: 7.288e+02, Test loss: 3.182e+03, MSE(e): 6.353e-05, MSE(pi1): 2.677e-03, MSE(pi2): 5.528e-05, MSE(pi3): 6.669e-04\n",
      "Epoch 47500, Train loss: 7.278e+02, Test loss: 3.175e+03, MSE(e): 6.343e-05, MSE(pi1): 2.671e-03, MSE(pi2): 5.519e-05, MSE(pi3): 6.672e-04\n",
      "Epoch 47600, Train loss: 7.269e+02, Test loss: 3.167e+03, MSE(e): 6.334e-05, MSE(pi1): 2.671e-03, MSE(pi2): 5.509e-05, MSE(pi3): 6.672e-04\n",
      "Epoch 47700, Train loss: 7.259e+02, Test loss: 3.159e+03, MSE(e): 6.325e-05, MSE(pi1): 2.672e-03, MSE(pi2): 5.500e-05, MSE(pi3): 6.671e-04\n",
      "Epoch 47800, Train loss: 7.250e+02, Test loss: 3.152e+03, MSE(e): 6.315e-05, MSE(pi1): 2.673e-03, MSE(pi2): 5.490e-05, MSE(pi3): 6.670e-04\n",
      "Epoch 47900, Train loss: 7.241e+02, Test loss: 3.144e+03, MSE(e): 6.306e-05, MSE(pi1): 2.671e-03, MSE(pi2): 5.481e-05, MSE(pi3): 6.671e-04\n",
      "Epoch 48000, Train loss: 7.231e+02, Test loss: 3.137e+03, MSE(e): 6.297e-05, MSE(pi1): 2.676e-03, MSE(pi2): 5.472e-05, MSE(pi3): 6.666e-04\n",
      "Epoch 48100, Train loss: 7.222e+02, Test loss: 3.130e+03, MSE(e): 6.288e-05, MSE(pi1): 2.673e-03, MSE(pi2): 5.462e-05, MSE(pi3): 6.668e-04\n",
      "Epoch 48200, Train loss: 7.213e+02, Test loss: 3.123e+03, MSE(e): 6.278e-05, MSE(pi1): 2.674e-03, MSE(pi2): 5.453e-05, MSE(pi3): 6.667e-04\n",
      "Epoch 48300, Train loss: 7.203e+02, Test loss: 3.116e+03, MSE(e): 6.269e-05, MSE(pi1): 2.675e-03, MSE(pi2): 5.443e-05, MSE(pi3): 6.666e-04\n",
      "Epoch 48400, Train loss: 7.195e+02, Test loss: 3.109e+03, MSE(e): 6.260e-05, MSE(pi1): 2.679e-03, MSE(pi2): 5.434e-05, MSE(pi3): 6.662e-04\n",
      "Epoch 48500, Train loss: 7.185e+02, Test loss: 3.102e+03, MSE(e): 6.251e-05, MSE(pi1): 2.677e-03, MSE(pi2): 5.424e-05, MSE(pi3): 6.663e-04\n",
      "Epoch 48600, Train loss: 7.176e+02, Test loss: 3.095e+03, MSE(e): 6.241e-05, MSE(pi1): 2.678e-03, MSE(pi2): 5.415e-05, MSE(pi3): 6.661e-04\n",
      "Epoch 48700, Train loss: 7.168e+02, Test loss: 3.088e+03, MSE(e): 6.233e-05, MSE(pi1): 2.677e-03, MSE(pi2): 5.406e-05, MSE(pi3): 6.662e-04\n",
      "Epoch 48800, Train loss: 7.159e+02, Test loss: 3.082e+03, MSE(e): 6.224e-05, MSE(pi1): 2.676e-03, MSE(pi2): 5.396e-05, MSE(pi3): 6.662e-04\n",
      "Epoch 48900, Train loss: 7.149e+02, Test loss: 3.075e+03, MSE(e): 6.215e-05, MSE(pi1): 2.677e-03, MSE(pi2): 5.387e-05, MSE(pi3): 6.662e-04\n",
      "Epoch 49000, Train loss: 7.140e+02, Test loss: 3.069e+03, MSE(e): 6.205e-05, MSE(pi1): 2.678e-03, MSE(pi2): 5.377e-05, MSE(pi3): 6.660e-04\n",
      "Epoch 49100, Train loss: 7.130e+02, Test loss: 3.063e+03, MSE(e): 6.196e-05, MSE(pi1): 2.675e-03, MSE(pi2): 5.368e-05, MSE(pi3): 6.662e-04\n",
      "Epoch 49200, Train loss: 7.121e+02, Test loss: 3.057e+03, MSE(e): 6.187e-05, MSE(pi1): 2.680e-03, MSE(pi2): 5.358e-05, MSE(pi3): 6.657e-04\n",
      "Epoch 49300, Train loss: 7.112e+02, Test loss: 3.051e+03, MSE(e): 6.178e-05, MSE(pi1): 2.679e-03, MSE(pi2): 5.349e-05, MSE(pi3): 6.658e-04\n",
      "Epoch 49400, Train loss: 7.104e+02, Test loss: 3.044e+03, MSE(e): 6.170e-05, MSE(pi1): 2.683e-03, MSE(pi2): 5.341e-05, MSE(pi3): 6.654e-04\n",
      "Epoch 49500, Train loss: 7.095e+02, Test loss: 3.038e+03, MSE(e): 6.161e-05, MSE(pi1): 2.679e-03, MSE(pi2): 5.331e-05, MSE(pi3): 6.657e-04\n",
      "Epoch 49600, Train loss: 7.086e+02, Test loss: 3.032e+03, MSE(e): 6.152e-05, MSE(pi1): 2.677e-03, MSE(pi2): 5.322e-05, MSE(pi3): 6.658e-04\n",
      "Epoch 49700, Train loss: 7.077e+02, Test loss: 3.027e+03, MSE(e): 6.143e-05, MSE(pi1): 2.679e-03, MSE(pi2): 5.313e-05, MSE(pi3): 6.656e-04\n",
      "Epoch 49800, Train loss: 7.068e+02, Test loss: 3.021e+03, MSE(e): 6.134e-05, MSE(pi1): 2.682e-03, MSE(pi2): 5.304e-05, MSE(pi3): 6.653e-04\n",
      "Epoch 49900, Train loss: 7.058e+02, Test loss: 3.015e+03, MSE(e): 6.124e-05, MSE(pi1): 2.685e-03, MSE(pi2): 5.294e-05, MSE(pi3): 6.650e-04\n",
      "Epoch 50000, Train loss: 7.049e+02, Test loss: 3.010e+03, MSE(e): 6.115e-05, MSE(pi1): 2.680e-03, MSE(pi2): 5.285e-05, MSE(pi3): 6.654e-04\n",
      "Epoch 50100, Train loss: 7.041e+02, Test loss: 3.004e+03, MSE(e): 6.107e-05, MSE(pi1): 2.683e-03, MSE(pi2): 5.276e-05, MSE(pi3): 6.651e-04\n",
      "Epoch 50200, Train loss: 7.032e+02, Test loss: 2.998e+03, MSE(e): 6.098e-05, MSE(pi1): 2.687e-03, MSE(pi2): 5.267e-05, MSE(pi3): 6.648e-04\n",
      "Epoch 50300, Train loss: 7.024e+02, Test loss: 2.993e+03, MSE(e): 6.090e-05, MSE(pi1): 2.684e-03, MSE(pi2): 5.258e-05, MSE(pi3): 6.650e-04\n",
      "Epoch 50400, Train loss: 7.015e+02, Test loss: 2.987e+03, MSE(e): 6.081e-05, MSE(pi1): 2.686e-03, MSE(pi2): 5.249e-05, MSE(pi3): 6.648e-04\n",
      "Epoch 50500, Train loss: 7.007e+02, Test loss: 2.982e+03, MSE(e): 6.073e-05, MSE(pi1): 2.687e-03, MSE(pi2): 5.241e-05, MSE(pi3): 6.646e-04\n",
      "Epoch 50600, Train loss: 6.999e+02, Test loss: 2.976e+03, MSE(e): 6.065e-05, MSE(pi1): 2.684e-03, MSE(pi2): 5.232e-05, MSE(pi3): 6.648e-04\n",
      "Epoch 50700, Train loss: 6.989e+02, Test loss: 2.971e+03, MSE(e): 6.056e-05, MSE(pi1): 2.687e-03, MSE(pi2): 5.223e-05, MSE(pi3): 6.646e-04\n",
      "Epoch 50800, Train loss: 6.981e+02, Test loss: 2.966e+03, MSE(e): 6.047e-05, MSE(pi1): 2.684e-03, MSE(pi2): 5.214e-05, MSE(pi3): 6.647e-04\n",
      "Epoch 50900, Train loss: 6.972e+02, Test loss: 2.961e+03, MSE(e): 6.038e-05, MSE(pi1): 2.690e-03, MSE(pi2): 5.205e-05, MSE(pi3): 6.642e-04\n",
      "Epoch 51000, Train loss: 6.963e+02, Test loss: 2.956e+03, MSE(e): 6.029e-05, MSE(pi1): 2.685e-03, MSE(pi2): 5.196e-05, MSE(pi3): 6.646e-04\n",
      "Epoch 51100, Train loss: 6.954e+02, Test loss: 2.950e+03, MSE(e): 6.021e-05, MSE(pi1): 2.685e-03, MSE(pi2): 5.187e-05, MSE(pi3): 6.645e-04\n",
      "Epoch 51200, Train loss: 6.946e+02, Test loss: 2.945e+03, MSE(e): 6.012e-05, MSE(pi1): 2.687e-03, MSE(pi2): 5.178e-05, MSE(pi3): 6.644e-04\n",
      "Epoch 51300, Train loss: 6.937e+02, Test loss: 2.940e+03, MSE(e): 6.003e-05, MSE(pi1): 2.685e-03, MSE(pi2): 5.169e-05, MSE(pi3): 6.645e-04\n",
      "Epoch 51400, Train loss: 6.928e+02, Test loss: 2.935e+03, MSE(e): 5.995e-05, MSE(pi1): 2.692e-03, MSE(pi2): 5.161e-05, MSE(pi3): 6.639e-04\n",
      "Epoch 51500, Train loss: 6.920e+02, Test loss: 2.930e+03, MSE(e): 5.986e-05, MSE(pi1): 2.687e-03, MSE(pi2): 5.152e-05, MSE(pi3): 6.643e-04\n",
      "Epoch 51600, Train loss: 6.911e+02, Test loss: 2.925e+03, MSE(e): 5.978e-05, MSE(pi1): 2.687e-03, MSE(pi2): 5.143e-05, MSE(pi3): 6.642e-04\n",
      "Epoch 51700, Train loss: 6.904e+02, Test loss: 2.920e+03, MSE(e): 5.970e-05, MSE(pi1): 2.689e-03, MSE(pi2): 5.135e-05, MSE(pi3): 6.640e-04\n",
      "Epoch 51800, Train loss: 6.895e+02, Test loss: 2.915e+03, MSE(e): 5.962e-05, MSE(pi1): 2.687e-03, MSE(pi2): 5.126e-05, MSE(pi3): 6.642e-04\n",
      "Epoch 51900, Train loss: 6.887e+02, Test loss: 2.910e+03, MSE(e): 5.954e-05, MSE(pi1): 2.697e-03, MSE(pi2): 5.118e-05, MSE(pi3): 6.634e-04\n",
      "Epoch 52000, Train loss: 6.878e+02, Test loss: 2.905e+03, MSE(e): 5.945e-05, MSE(pi1): 2.687e-03, MSE(pi2): 5.109e-05, MSE(pi3): 6.641e-04\n",
      "Epoch 52100, Train loss: 6.870e+02, Test loss: 2.900e+03, MSE(e): 5.936e-05, MSE(pi1): 2.688e-03, MSE(pi2): 5.101e-05, MSE(pi3): 6.639e-04\n",
      "Epoch 52200, Train loss: 6.862e+02, Test loss: 2.896e+03, MSE(e): 5.928e-05, MSE(pi1): 2.688e-03, MSE(pi2): 5.092e-05, MSE(pi3): 6.639e-04\n",
      "Epoch 52300, Train loss: 6.855e+02, Test loss: 2.890e+03, MSE(e): 5.922e-05, MSE(pi1): 2.687e-03, MSE(pi2): 5.085e-05, MSE(pi3): 6.639e-04\n",
      "Epoch 52400, Train loss: 6.846e+02, Test loss: 2.885e+03, MSE(e): 5.913e-05, MSE(pi1): 2.692e-03, MSE(pi2): 5.076e-05, MSE(pi3): 6.636e-04\n",
      "Epoch 52500, Train loss: 6.838e+02, Test loss: 2.881e+03, MSE(e): 5.904e-05, MSE(pi1): 2.688e-03, MSE(pi2): 5.068e-05, MSE(pi3): 6.639e-04\n",
      "Epoch 52600, Train loss: 6.828e+02, Test loss: 2.876e+03, MSE(e): 5.895e-05, MSE(pi1): 2.689e-03, MSE(pi2): 5.059e-05, MSE(pi3): 6.637e-04\n",
      "Epoch 52700, Train loss: 6.821e+02, Test loss: 2.871e+03, MSE(e): 5.888e-05, MSE(pi1): 2.691e-03, MSE(pi2): 5.051e-05, MSE(pi3): 6.636e-04\n",
      "Epoch 52800, Train loss: 6.815e+02, Test loss: 2.866e+03, MSE(e): 5.882e-05, MSE(pi1): 2.693e-03, MSE(pi2): 5.043e-05, MSE(pi3): 6.634e-04\n",
      "Epoch 52900, Train loss: 6.810e+02, Test loss: 2.861e+03, MSE(e): 5.877e-05, MSE(pi1): 2.691e-03, MSE(pi2): 5.036e-05, MSE(pi3): 6.634e-04\n",
      "Epoch 53000, Train loss: 6.803e+02, Test loss: 2.856e+03, MSE(e): 5.870e-05, MSE(pi1): 2.701e-03, MSE(pi2): 5.029e-05, MSE(pi3): 6.627e-04\n",
      "Epoch 53100, Train loss: 6.792e+02, Test loss: 2.852e+03, MSE(e): 5.859e-05, MSE(pi1): 2.692e-03, MSE(pi2): 5.019e-05, MSE(pi3): 6.634e-04\n",
      "Epoch 53200, Train loss: 6.779e+02, Test loss: 2.848e+03, MSE(e): 5.846e-05, MSE(pi1): 2.692e-03, MSE(pi2): 5.009e-05, MSE(pi3): 6.634e-04\n",
      "Epoch 53300, Train loss: 6.771e+02, Test loss: 2.844e+03, MSE(e): 5.838e-05, MSE(pi1): 2.693e-03, MSE(pi2): 5.001e-05, MSE(pi3): 6.632e-04\n",
      "Epoch 53400, Train loss: 6.767e+02, Test loss: 2.838e+03, MSE(e): 5.834e-05, MSE(pi1): 2.689e-03, MSE(pi2): 4.994e-05, MSE(pi3): 6.635e-04\n",
      "Epoch 53500, Train loss: 6.765e+02, Test loss: 2.832e+03, MSE(e): 5.832e-05, MSE(pi1): 2.694e-03, MSE(pi2): 4.989e-05, MSE(pi3): 6.631e-04\n",
      "Epoch 53600, Train loss: 6.757e+02, Test loss: 2.828e+03, MSE(e): 5.824e-05, MSE(pi1): 2.696e-03, MSE(pi2): 4.981e-05, MSE(pi3): 6.629e-04\n",
      "Epoch 53700, Train loss: 6.741e+02, Test loss: 2.825e+03, MSE(e): 5.808e-05, MSE(pi1): 2.692e-03, MSE(pi2): 4.970e-05, MSE(pi3): 6.632e-04\n",
      "Epoch 53800, Train loss: 6.729e+02, Test loss: 2.822e+03, MSE(e): 5.796e-05, MSE(pi1): 2.694e-03, MSE(pi2): 4.959e-05, MSE(pi3): 6.630e-04\n",
      "Epoch 53900, Train loss: 6.727e+02, Test loss: 2.816e+03, MSE(e): 5.794e-05, MSE(pi1): 2.703e-03, MSE(pi2): 4.954e-05, MSE(pi3): 6.623e-04\n",
      "Epoch 54000, Train loss: 6.729e+02, Test loss: 2.808e+03, MSE(e): 5.796e-05, MSE(pi1): 2.699e-03, MSE(pi2): 4.950e-05, MSE(pi3): 6.626e-04\n",
      "Epoch 54100, Train loss: 6.724e+02, Test loss: 2.803e+03, MSE(e): 5.791e-05, MSE(pi1): 2.698e-03, MSE(pi2): 4.944e-05, MSE(pi3): 6.626e-04\n",
      "Epoch 54200, Train loss: 6.703e+02, Test loss: 2.803e+03, MSE(e): 5.770e-05, MSE(pi1): 2.696e-03, MSE(pi2): 4.930e-05, MSE(pi3): 6.627e-04\n",
      "Epoch 54300, Train loss: 6.686e+02, Test loss: 2.801e+03, MSE(e): 5.753e-05, MSE(pi1): 2.695e-03, MSE(pi2): 4.918e-05, MSE(pi3): 6.628e-04\n",
      "Epoch 54400, Train loss: 6.688e+02, Test loss: 2.794e+03, MSE(e): 5.755e-05, MSE(pi1): 2.695e-03, MSE(pi2): 4.914e-05, MSE(pi3): 6.628e-04\n",
      "Epoch 54500, Train loss: 6.701e+02, Test loss: 2.783e+03, MSE(e): 5.768e-05, MSE(pi1): 2.707e-03, MSE(pi2): 4.916e-05, MSE(pi3): 6.618e-04\n",
      "Epoch 54600, Train loss: 6.691e+02, Test loss: 2.779e+03, MSE(e): 5.758e-05, MSE(pi1): 2.700e-03, MSE(pi2): 4.908e-05, MSE(pi3): 6.623e-04\n",
      "Epoch 54700, Train loss: 6.655e+02, Test loss: 2.783e+03, MSE(e): 5.722e-05, MSE(pi1): 2.694e-03, MSE(pi2): 4.887e-05, MSE(pi3): 6.628e-04\n",
      "Epoch 54800, Train loss: 6.642e+02, Test loss: 2.780e+03, MSE(e): 5.710e-05, MSE(pi1): 2.693e-03, MSE(pi2): 4.875e-05, MSE(pi3): 6.629e-04\n",
      "Epoch 54900, Train loss: 6.666e+02, Test loss: 2.767e+03, MSE(e): 5.733e-05, MSE(pi1): 2.698e-03, MSE(pi2): 4.882e-05, MSE(pi3): 6.624e-04\n",
      "Epoch 55000, Train loss: 6.688e+02, Test loss: 2.753e+03, MSE(e): 5.755e-05, MSE(pi1): 2.701e-03, MSE(pi2): 4.889e-05, MSE(pi3): 6.621e-04\n",
      "Epoch 55100, Train loss: 6.628e+02, Test loss: 2.765e+03, MSE(e): 5.695e-05, MSE(pi1): 2.704e-03, MSE(pi2): 4.858e-05, MSE(pi3): 6.619e-04\n",
      "Epoch 55200, Train loss: 6.596e+02, Test loss: 2.767e+03, MSE(e): 5.663e-05, MSE(pi1): 2.696e-03, MSE(pi2): 4.836e-05, MSE(pi3): 6.626e-04\n",
      "Epoch 55300, Train loss: 6.630e+02, Test loss: 2.751e+03, MSE(e): 5.697e-05, MSE(pi1): 2.701e-03, MSE(pi2): 4.847e-05, MSE(pi3): 6.621e-04\n",
      "Epoch 55400, Train loss: 6.719e+02, Test loss: 2.718e+03, MSE(e): 5.786e-05, MSE(pi1): 2.720e-03, MSE(pi2): 4.886e-05, MSE(pi3): 6.604e-04\n",
      "Epoch 55500, Train loss: 6.579e+02, Test loss: 2.756e+03, MSE(e): 5.646e-05, MSE(pi1): 2.701e-03, MSE(pi2): 4.820e-05, MSE(pi3): 6.621e-04\n",
      "Epoch 55600, Train loss: 6.549e+02, Test loss: 2.750e+03, MSE(e): 5.617e-05, MSE(pi1): 2.683e-03, MSE(pi2): 4.796e-05, MSE(pi3): 6.635e-04\n",
      "Epoch 55700, Train loss: 6.673e+02, Test loss: 2.719e+03, MSE(e): 5.740e-05, MSE(pi1): 2.713e-03, MSE(pi2): 4.846e-05, MSE(pi3): 6.610e-04\n",
      "Epoch 55800, Train loss: 6.646e+02, Test loss: 2.716e+03, MSE(e): 5.713e-05, MSE(pi1): 2.721e-03, MSE(pi2): 4.846e-05, MSE(pi3): 6.603e-04\n",
      "Epoch 55900, Train loss: 6.527e+02, Test loss: 2.712e+03, MSE(e): 5.594e-05, MSE(pi1): 2.678e-03, MSE(pi2): 4.770e-05, MSE(pi3): 6.639e-04\n",
      "Epoch 56000, Train loss: 6.537e+02, Test loss: 2.789e+03, MSE(e): 5.604e-05, MSE(pi1): 2.710e-03, MSE(pi2): 4.794e-05, MSE(pi3): 6.614e-04\n",
      "Epoch 56100, Train loss: 6.504e+02, Test loss: 2.734e+03, MSE(e): 5.571e-05, MSE(pi1): 2.668e-03, MSE(pi2): 4.751e-05, MSE(pi3): 6.648e-04\n",
      "Epoch 56200, Train loss: 6.510e+02, Test loss: 2.721e+03, MSE(e): 5.578e-05, MSE(pi1): 2.681e-03, MSE(pi2): 4.748e-05, MSE(pi3): 6.636e-04\n",
      "Epoch 56300, Train loss: 6.703e+02, Test loss: 2.677e+03, MSE(e): 5.770e-05, MSE(pi1): 2.720e-03, MSE(pi2): 4.830e-05, MSE(pi3): 6.602e-04\n",
      "Epoch 56400, Train loss: 6.752e+02, Test loss: 2.640e+03, MSE(e): 5.819e-05, MSE(pi1): 2.741e-03, MSE(pi2): 4.868e-05, MSE(pi3): 6.585e-04\n",
      "Epoch 56500, Train loss: 6.491e+02, Test loss: 2.692e+03, MSE(e): 5.559e-05, MSE(pi1): 2.679e-03, MSE(pi2): 4.727e-05, MSE(pi3): 6.638e-04\n",
      "Epoch 56600, Train loss: 6.839e+02, Test loss: 2.650e+03, MSE(e): 5.906e-05, MSE(pi1): 2.722e-03, MSE(pi2): 4.873e-05, MSE(pi3): 6.599e-04\n",
      "Epoch 56700, Train loss: 6.488e+02, Test loss: 2.728e+03, MSE(e): 5.555e-05, MSE(pi1): 2.681e-03, MSE(pi2): 4.718e-05, MSE(pi3): 6.638e-04\n",
      "Epoch 56800, Train loss: 6.462e+02, Test loss: 2.698e+03, MSE(e): 5.530e-05, MSE(pi1): 2.670e-03, MSE(pi2): 4.699e-05, MSE(pi3): 6.645e-04\n",
      "Epoch 56900, Train loss: 6.623e+02, Test loss: 2.664e+03, MSE(e): 5.691e-05, MSE(pi1): 2.712e-03, MSE(pi2): 4.767e-05, MSE(pi3): 6.607e-04\n",
      "Epoch 57000, Train loss: 6.949e+02, Test loss: 2.548e+03, MSE(e): 6.015e-05, MSE(pi1): 2.765e-03, MSE(pi2): 4.924e-05, MSE(pi3): 6.564e-04\n",
      "Epoch 57100, Train loss: 6.456e+02, Test loss: 2.681e+03, MSE(e): 5.524e-05, MSE(pi1): 2.681e-03, MSE(pi2): 4.686e-05, MSE(pi3): 6.636e-04\n",
      "Epoch 57200, Train loss: 6.449e+02, Test loss: 2.685e+03, MSE(e): 5.517e-05, MSE(pi1): 2.679e-03, MSE(pi2): 4.677e-05, MSE(pi3): 6.636e-04\n",
      "Epoch 57300, Train loss: 7.167e+02, Test loss: 2.496e+03, MSE(e): 6.234e-05, MSE(pi1): 2.776e-03, MSE(pi2): 4.997e-05, MSE(pi3): 6.554e-04\n",
      "Epoch 57400, Train loss: 6.439e+02, Test loss: 2.675e+03, MSE(e): 5.507e-05, MSE(pi1): 2.680e-03, MSE(pi2): 4.666e-05, MSE(pi3): 6.637e-04\n",
      "Epoch 57500, Train loss: 6.419e+02, Test loss: 2.671e+03, MSE(e): 5.487e-05, MSE(pi1): 2.676e-03, MSE(pi2): 4.651e-05, MSE(pi3): 6.639e-04\n",
      "Epoch 57600, Train loss: 7.006e+02, Test loss: 2.542e+03, MSE(e): 6.073e-05, MSE(pi1): 2.757e-03, MSE(pi2): 4.906e-05, MSE(pi3): 6.569e-04\n",
      "Epoch 57700, Train loss: 6.407e+02, Test loss: 2.702e+03, MSE(e): 5.474e-05, MSE(pi1): 2.688e-03, MSE(pi2): 4.644e-05, MSE(pi3): 6.630e-04\n",
      "Epoch 57800, Train loss: 6.401e+02, Test loss: 2.650e+03, MSE(e): 5.469e-05, MSE(pi1): 2.677e-03, MSE(pi2): 4.631e-05, MSE(pi3): 6.637e-04\n",
      "Epoch 57900, Train loss: 6.750e+02, Test loss: 2.588e+03, MSE(e): 5.817e-05, MSE(pi1): 2.733e-03, MSE(pi2): 4.779e-05, MSE(pi3): 6.588e-04\n",
      "Epoch 58000, Train loss: 6.408e+02, Test loss: 2.686e+03, MSE(e): 5.475e-05, MSE(pi1): 2.716e-03, MSE(pi2): 4.648e-05, MSE(pi3): 6.604e-04\n",
      "Epoch 58100, Train loss: 6.388e+02, Test loss: 2.633e+03, MSE(e): 5.456e-05, MSE(pi1): 2.678e-03, MSE(pi2): 4.614e-05, MSE(pi3): 6.636e-04\n",
      "Epoch 58200, Train loss: 6.517e+02, Test loss: 2.621e+03, MSE(e): 5.585e-05, MSE(pi1): 2.708e-03, MSE(pi2): 4.665e-05, MSE(pi3): 6.609e-04\n",
      "Epoch 58300, Train loss: 6.768e+02, Test loss: 2.517e+03, MSE(e): 5.835e-05, MSE(pi1): 2.761e-03, MSE(pi2): 4.798e-05, MSE(pi3): 6.566e-04\n",
      "Epoch 58400, Train loss: 6.374e+02, Test loss: 2.622e+03, MSE(e): 5.442e-05, MSE(pi1): 2.682e-03, MSE(pi2): 4.596e-05, MSE(pi3): 6.633e-04\n",
      "Epoch 58500, Train loss: 6.387e+02, Test loss: 2.631e+03, MSE(e): 5.455e-05, MSE(pi1): 2.691e-03, MSE(pi2): 4.595e-05, MSE(pi3): 6.623e-04\n",
      "Epoch 58600, Train loss: 7.028e+02, Test loss: 2.445e+03, MSE(e): 6.094e-05, MSE(pi1): 2.779e-03, MSE(pi2): 4.885e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 58700, Train loss: 6.359e+02, Test loss: 2.615e+03, MSE(e): 5.427e-05, MSE(pi1): 2.684e-03, MSE(pi2): 4.578e-05, MSE(pi3): 6.631e-04\n",
      "Epoch 58800, Train loss: 6.340e+02, Test loss: 2.622e+03, MSE(e): 5.409e-05, MSE(pi1): 2.681e-03, MSE(pi2): 4.563e-05, MSE(pi3): 6.632e-04\n",
      "Epoch 58900, Train loss: 7.040e+02, Test loss: 2.446e+03, MSE(e): 6.107e-05, MSE(pi1): 2.777e-03, MSE(pi2): 4.870e-05, MSE(pi3): 6.550e-04\n",
      "Epoch 59000, Train loss: 6.342e+02, Test loss: 2.613e+03, MSE(e): 5.410e-05, MSE(pi1): 2.685e-03, MSE(pi2): 4.559e-05, MSE(pi3): 6.630e-04\n",
      "Epoch 59100, Train loss: 6.316e+02, Test loss: 2.607e+03, MSE(e): 5.384e-05, MSE(pi1): 2.678e-03, MSE(pi2): 4.541e-05, MSE(pi3): 6.634e-04\n",
      "Epoch 59200, Train loss: 6.986e+02, Test loss: 2.455e+03, MSE(e): 6.053e-05, MSE(pi1): 2.771e-03, MSE(pi2): 4.831e-05, MSE(pi3): 6.555e-04\n",
      "Epoch 59300, Train loss: 6.324e+02, Test loss: 2.610e+03, MSE(e): 5.392e-05, MSE(pi1): 2.689e-03, MSE(pi2): 4.539e-05, MSE(pi3): 6.626e-04\n",
      "Epoch 59400, Train loss: 6.297e+02, Test loss: 2.592e+03, MSE(e): 5.365e-05, MSE(pi1): 2.680e-03, MSE(pi2): 4.521e-05, MSE(pi3): 6.632e-04\n",
      "Epoch 59500, Train loss: 6.936e+02, Test loss: 2.455e+03, MSE(e): 6.003e-05, MSE(pi1): 2.768e-03, MSE(pi2): 4.796e-05, MSE(pi3): 6.556e-04\n",
      "Epoch 59600, Train loss: 6.305e+02, Test loss: 2.604e+03, MSE(e): 5.373e-05, MSE(pi1): 2.691e-03, MSE(pi2): 4.520e-05, MSE(pi3): 6.624e-04\n",
      "Epoch 59700, Train loss: 6.279e+02, Test loss: 2.579e+03, MSE(e): 5.348e-05, MSE(pi1): 2.681e-03, MSE(pi2): 4.502e-05, MSE(pi3): 6.631e-04\n",
      "Epoch 59800, Train loss: 6.901e+02, Test loss: 2.448e+03, MSE(e): 5.968e-05, MSE(pi1): 2.766e-03, MSE(pi2): 4.768e-05, MSE(pi3): 6.558e-04\n",
      "Epoch 59900, Train loss: 6.289e+02, Test loss: 2.591e+03, MSE(e): 5.357e-05, MSE(pi1): 2.690e-03, MSE(pi2): 4.501e-05, MSE(pi3): 6.625e-04\n",
      "Epoch 60000, Train loss: 6.261e+02, Test loss: 2.567e+03, MSE(e): 5.329e-05, MSE(pi1): 2.681e-03, MSE(pi2): 4.482e-05, MSE(pi3): 6.630e-04\n",
      "Epoch 60100, Train loss: 6.903e+02, Test loss: 2.430e+03, MSE(e): 5.970e-05, MSE(pi1): 2.774e-03, MSE(pi2): 4.757e-05, MSE(pi3): 6.551e-04\n",
      "Epoch 60200, Train loss: 6.273e+02, Test loss: 2.572e+03, MSE(e): 5.341e-05, MSE(pi1): 2.690e-03, MSE(pi2): 4.482e-05, MSE(pi3): 6.624e-04\n",
      "Epoch 60300, Train loss: 6.242e+02, Test loss: 2.557e+03, MSE(e): 5.311e-05, MSE(pi1): 2.683e-03, MSE(pi2): 4.462e-05, MSE(pi3): 6.628e-04\n",
      "Epoch 60400, Train loss: 6.933e+02, Test loss: 2.402e+03, MSE(e): 6.000e-05, MSE(pi1): 2.780e-03, MSE(pi2): 4.760e-05, MSE(pi3): 6.546e-04\n",
      "Epoch 60500, Train loss: 6.257e+02, Test loss: 2.550e+03, MSE(e): 5.326e-05, MSE(pi1): 2.690e-03, MSE(pi2): 4.464e-05, MSE(pi3): 6.624e-04\n",
      "Epoch 60600, Train loss: 6.224e+02, Test loss: 2.548e+03, MSE(e): 5.293e-05, MSE(pi1): 2.682e-03, MSE(pi2): 4.443e-05, MSE(pi3): 6.629e-04\n",
      "Epoch 60700, Train loss: 6.965e+02, Test loss: 2.365e+03, MSE(e): 6.032e-05, MSE(pi1): 2.786e-03, MSE(pi2): 4.765e-05, MSE(pi3): 6.540e-04\n",
      "Epoch 60800, Train loss: 6.239e+02, Test loss: 2.529e+03, MSE(e): 5.307e-05, MSE(pi1): 2.694e-03, MSE(pi2): 4.444e-05, MSE(pi3): 6.620e-04\n",
      "Epoch 60900, Train loss: 6.213e+02, Test loss: 2.539e+03, MSE(e): 5.281e-05, MSE(pi1): 2.690e-03, MSE(pi2): 4.426e-05, MSE(pi3): 6.621e-04\n",
      "Epoch 61000, Train loss: 6.917e+02, Test loss: 2.332e+03, MSE(e): 5.984e-05, MSE(pi1): 2.798e-03, MSE(pi2): 4.744e-05, MSE(pi3): 6.532e-04\n",
      "Epoch 61100, Train loss: 6.218e+02, Test loss: 2.512e+03, MSE(e): 5.286e-05, MSE(pi1): 2.690e-03, MSE(pi2): 4.423e-05, MSE(pi3): 6.623e-04\n",
      "Epoch 61200, Train loss: 6.225e+02, Test loss: 2.524e+03, MSE(e): 5.293e-05, MSE(pi1): 2.690e-03, MSE(pi2): 4.420e-05, MSE(pi3): 6.621e-04\n",
      "Epoch 61300, Train loss: 6.391e+02, Test loss: 2.472e+03, MSE(e): 5.459e-05, MSE(pi1): 2.757e-03, MSE(pi2): 4.521e-05, MSE(pi3): 6.566e-04\n",
      "Epoch 61400, Train loss: 6.193e+02, Test loss: 2.501e+03, MSE(e): 5.262e-05, MSE(pi1): 2.685e-03, MSE(pi2): 4.401e-05, MSE(pi3): 6.626e-04\n",
      "Epoch 61500, Train loss: 6.299e+02, Test loss: 2.492e+03, MSE(e): 5.367e-05, MSE(pi1): 2.711e-03, MSE(pi2): 4.440e-05, MSE(pi3): 6.602e-04\n",
      "Epoch 61600, Train loss: 6.200e+02, Test loss: 2.539e+03, MSE(e): 5.268e-05, MSE(pi1): 2.693e-03, MSE(pi2): 4.398e-05, MSE(pi3): 6.620e-04\n",
      "Epoch 61700, Train loss: 6.161e+02, Test loss: 2.504e+03, MSE(e): 5.229e-05, MSE(pi1): 2.683e-03, MSE(pi2): 4.375e-05, MSE(pi3): 6.628e-04\n",
      "Epoch 61800, Train loss: 6.300e+02, Test loss: 2.471e+03, MSE(e): 5.368e-05, MSE(pi1): 2.719e-03, MSE(pi2): 4.431e-05, MSE(pi3): 6.595e-04\n",
      "Epoch 61900, Train loss: 6.187e+02, Test loss: 2.507e+03, MSE(e): 5.255e-05, MSE(pi1): 2.693e-03, MSE(pi2): 4.381e-05, MSE(pi3): 6.621e-04\n",
      "Epoch 62000, Train loss: 6.141e+02, Test loss: 2.494e+03, MSE(e): 5.210e-05, MSE(pi1): 2.680e-03, MSE(pi2): 4.355e-05, MSE(pi3): 6.629e-04\n",
      "Epoch 62100, Train loss: 6.588e+02, Test loss: 2.393e+03, MSE(e): 5.656e-05, MSE(pi1): 2.756e-03, MSE(pi2): 4.545e-05, MSE(pi3): 6.563e-04\n",
      "Epoch 62200, Train loss: 6.171e+02, Test loss: 2.430e+03, MSE(e): 5.239e-05, MSE(pi1): 2.701e-03, MSE(pi2): 4.363e-05, MSE(pi3): 6.612e-04\n",
      "Epoch 62300, Train loss: 6.169e+02, Test loss: 2.321e+03, MSE(e): 5.236e-05, MSE(pi1): 2.738e-03, MSE(pi2): 4.364e-05, MSE(pi3): 6.580e-04\n",
      "Epoch 62400, Train loss: 6.197e+02, Test loss: 2.267e+03, MSE(e): 5.265e-05, MSE(pi1): 2.748e-03, MSE(pi2): 4.377e-05, MSE(pi3): 6.570e-04\n",
      "Epoch 62500, Train loss: 6.200e+02, Test loss: 2.256e+03, MSE(e): 5.268e-05, MSE(pi1): 2.742e-03, MSE(pi2): 4.376e-05, MSE(pi3): 6.575e-04\n",
      "Epoch 62600, Train loss: 6.199e+02, Test loss: 2.252e+03, MSE(e): 5.267e-05, MSE(pi1): 2.752e-03, MSE(pi2): 4.371e-05, MSE(pi3): 6.567e-04\n",
      "Epoch 62700, Train loss: 6.195e+02, Test loss: 2.248e+03, MSE(e): 5.263e-05, MSE(pi1): 2.746e-03, MSE(pi2): 4.364e-05, MSE(pi3): 6.571e-04\n",
      "Epoch 62800, Train loss: 6.192e+02, Test loss: 2.245e+03, MSE(e): 5.260e-05, MSE(pi1): 2.748e-03, MSE(pi2): 4.357e-05, MSE(pi3): 6.570e-04\n",
      "Epoch 62900, Train loss: 6.187e+02, Test loss: 2.241e+03, MSE(e): 5.255e-05, MSE(pi1): 2.751e-03, MSE(pi2): 4.350e-05, MSE(pi3): 6.567e-04\n",
      "Epoch 63000, Train loss: 6.183e+02, Test loss: 2.237e+03, MSE(e): 5.251e-05, MSE(pi1): 2.751e-03, MSE(pi2): 4.343e-05, MSE(pi3): 6.567e-04\n",
      "Epoch 63100, Train loss: 6.177e+02, Test loss: 2.233e+03, MSE(e): 5.245e-05, MSE(pi1): 2.752e-03, MSE(pi2): 4.336e-05, MSE(pi3): 6.567e-04\n",
      "Epoch 63200, Train loss: 6.172e+02, Test loss: 2.229e+03, MSE(e): 5.240e-05, MSE(pi1): 2.754e-03, MSE(pi2): 4.329e-05, MSE(pi3): 6.565e-04\n",
      "Epoch 63300, Train loss: 6.167e+02, Test loss: 2.225e+03, MSE(e): 5.234e-05, MSE(pi1): 2.750e-03, MSE(pi2): 4.322e-05, MSE(pi3): 6.568e-04\n",
      "Epoch 63400, Train loss: 6.161e+02, Test loss: 2.220e+03, MSE(e): 5.229e-05, MSE(pi1): 2.750e-03, MSE(pi2): 4.315e-05, MSE(pi3): 6.568e-04\n",
      "Epoch 63500, Train loss: 6.155e+02, Test loss: 2.216e+03, MSE(e): 5.223e-05, MSE(pi1): 2.755e-03, MSE(pi2): 4.308e-05, MSE(pi3): 6.564e-04\n",
      "Epoch 63600, Train loss: 6.149e+02, Test loss: 2.212e+03, MSE(e): 5.217e-05, MSE(pi1): 2.748e-03, MSE(pi2): 4.301e-05, MSE(pi3): 6.569e-04\n",
      "Epoch 63700, Train loss: 6.144e+02, Test loss: 2.207e+03, MSE(e): 5.211e-05, MSE(pi1): 2.755e-03, MSE(pi2): 4.294e-05, MSE(pi3): 6.564e-04\n",
      "Epoch 63800, Train loss: 6.137e+02, Test loss: 2.203e+03, MSE(e): 5.205e-05, MSE(pi1): 2.751e-03, MSE(pi2): 4.288e-05, MSE(pi3): 6.567e-04\n",
      "Epoch 63900, Train loss: 6.131e+02, Test loss: 2.198e+03, MSE(e): 5.199e-05, MSE(pi1): 2.752e-03, MSE(pi2): 4.281e-05, MSE(pi3): 6.566e-04\n",
      "Epoch 64000, Train loss: 6.125e+02, Test loss: 2.194e+03, MSE(e): 5.192e-05, MSE(pi1): 2.753e-03, MSE(pi2): 4.274e-05, MSE(pi3): 6.565e-04\n",
      "Epoch 64100, Train loss: 6.119e+02, Test loss: 2.189e+03, MSE(e): 5.186e-05, MSE(pi1): 2.751e-03, MSE(pi2): 4.268e-05, MSE(pi3): 6.566e-04\n",
      "Epoch 64200, Train loss: 6.113e+02, Test loss: 2.185e+03, MSE(e): 5.181e-05, MSE(pi1): 2.754e-03, MSE(pi2): 4.261e-05, MSE(pi3): 6.564e-04\n",
      "Epoch 64300, Train loss: 6.107e+02, Test loss: 2.180e+03, MSE(e): 5.174e-05, MSE(pi1): 2.755e-03, MSE(pi2): 4.255e-05, MSE(pi3): 6.563e-04\n",
      "Epoch 64400, Train loss: 6.100e+02, Test loss: 2.176e+03, MSE(e): 5.168e-05, MSE(pi1): 2.750e-03, MSE(pi2): 4.248e-05, MSE(pi3): 6.566e-04\n",
      "Epoch 64500, Train loss: 6.094e+02, Test loss: 2.171e+03, MSE(e): 5.162e-05, MSE(pi1): 2.753e-03, MSE(pi2): 4.242e-05, MSE(pi3): 6.565e-04\n",
      "Epoch 64600, Train loss: 6.088e+02, Test loss: 2.167e+03, MSE(e): 5.156e-05, MSE(pi1): 2.748e-03, MSE(pi2): 4.236e-05, MSE(pi3): 6.568e-04\n",
      "Epoch 64700, Train loss: 6.083e+02, Test loss: 2.162e+03, MSE(e): 5.151e-05, MSE(pi1): 2.754e-03, MSE(pi2): 4.230e-05, MSE(pi3): 6.563e-04\n",
      "Epoch 64800, Train loss: 6.076e+02, Test loss: 2.158e+03, MSE(e): 5.144e-05, MSE(pi1): 2.756e-03, MSE(pi2): 4.223e-05, MSE(pi3): 6.562e-04\n",
      "Epoch 64900, Train loss: 6.070e+02, Test loss: 2.153e+03, MSE(e): 5.138e-05, MSE(pi1): 2.751e-03, MSE(pi2): 4.217e-05, MSE(pi3): 6.565e-04\n",
      "Epoch 65000, Train loss: 6.064e+02, Test loss: 2.149e+03, MSE(e): 5.132e-05, MSE(pi1): 2.752e-03, MSE(pi2): 4.211e-05, MSE(pi3): 6.565e-04\n",
      "Epoch 65100, Train loss: 6.058e+02, Test loss: 2.144e+03, MSE(e): 5.126e-05, MSE(pi1): 2.752e-03, MSE(pi2): 4.204e-05, MSE(pi3): 6.565e-04\n",
      "Epoch 65200, Train loss: 6.052e+02, Test loss: 2.139e+03, MSE(e): 5.120e-05, MSE(pi1): 2.754e-03, MSE(pi2): 4.198e-05, MSE(pi3): 6.563e-04\n",
      "Epoch 65300, Train loss: 6.046e+02, Test loss: 2.135e+03, MSE(e): 5.114e-05, MSE(pi1): 2.755e-03, MSE(pi2): 4.192e-05, MSE(pi3): 6.562e-04\n",
      "Epoch 65400, Train loss: 6.041e+02, Test loss: 2.130e+03, MSE(e): 5.109e-05, MSE(pi1): 2.755e-03, MSE(pi2): 4.186e-05, MSE(pi3): 6.562e-04\n",
      "Epoch 65500, Train loss: 6.034e+02, Test loss: 2.126e+03, MSE(e): 5.102e-05, MSE(pi1): 2.755e-03, MSE(pi2): 4.180e-05, MSE(pi3): 6.562e-04\n",
      "Epoch 65600, Train loss: 6.030e+02, Test loss: 2.121e+03, MSE(e): 5.097e-05, MSE(pi1): 2.771e-03, MSE(pi2): 4.174e-05, MSE(pi3): 6.551e-04\n",
      "Epoch 65700, Train loss: 6.022e+02, Test loss: 2.117e+03, MSE(e): 5.090e-05, MSE(pi1): 2.755e-03, MSE(pi2): 4.168e-05, MSE(pi3): 6.562e-04\n",
      "Epoch 65800, Train loss: 6.017e+02, Test loss: 2.112e+03, MSE(e): 5.085e-05, MSE(pi1): 2.754e-03, MSE(pi2): 4.162e-05, MSE(pi3): 6.562e-04\n",
      "Epoch 65900, Train loss: 6.011e+02, Test loss: 2.107e+03, MSE(e): 5.079e-05, MSE(pi1): 2.758e-03, MSE(pi2): 4.156e-05, MSE(pi3): 6.559e-04\n",
      "Epoch 66000, Train loss: 6.005e+02, Test loss: 2.103e+03, MSE(e): 5.073e-05, MSE(pi1): 2.757e-03, MSE(pi2): 4.150e-05, MSE(pi3): 6.560e-04\n",
      "Epoch 66100, Train loss: 5.999e+02, Test loss: 2.099e+03, MSE(e): 5.067e-05, MSE(pi1): 2.764e-03, MSE(pi2): 4.144e-05, MSE(pi3): 6.555e-04\n",
      "Epoch 66200, Train loss: 5.993e+02, Test loss: 2.094e+03, MSE(e): 5.061e-05, MSE(pi1): 2.756e-03, MSE(pi2): 4.138e-05, MSE(pi3): 6.561e-04\n",
      "Epoch 66300, Train loss: 5.987e+02, Test loss: 2.090e+03, MSE(e): 5.055e-05, MSE(pi1): 2.758e-03, MSE(pi2): 4.132e-05, MSE(pi3): 6.560e-04\n",
      "Epoch 66400, Train loss: 5.982e+02, Test loss: 2.085e+03, MSE(e): 5.050e-05, MSE(pi1): 2.754e-03, MSE(pi2): 4.126e-05, MSE(pi3): 6.562e-04\n",
      "Epoch 66500, Train loss: 5.976e+02, Test loss: 2.081e+03, MSE(e): 5.044e-05, MSE(pi1): 2.754e-03, MSE(pi2): 4.120e-05, MSE(pi3): 6.563e-04\n",
      "Epoch 66600, Train loss: 5.970e+02, Test loss: 2.076e+03, MSE(e): 5.038e-05, MSE(pi1): 2.754e-03, MSE(pi2): 4.114e-05, MSE(pi3): 6.562e-04\n",
      "Epoch 66700, Train loss: 5.965e+02, Test loss: 2.072e+03, MSE(e): 5.033e-05, MSE(pi1): 2.761e-03, MSE(pi2): 4.109e-05, MSE(pi3): 6.557e-04\n",
      "Epoch 66800, Train loss: 5.959e+02, Test loss: 2.067e+03, MSE(e): 5.027e-05, MSE(pi1): 2.756e-03, MSE(pi2): 4.103e-05, MSE(pi3): 6.560e-04\n",
      "Epoch 66900, Train loss: 5.953e+02, Test loss: 2.063e+03, MSE(e): 5.021e-05, MSE(pi1): 2.760e-03, MSE(pi2): 4.097e-05, MSE(pi3): 6.557e-04\n",
      "Epoch 67000, Train loss: 5.948e+02, Test loss: 2.059e+03, MSE(e): 5.016e-05, MSE(pi1): 2.760e-03, MSE(pi2): 4.091e-05, MSE(pi3): 6.557e-04\n",
      "Epoch 67100, Train loss: 5.942e+02, Test loss: 2.054e+03, MSE(e): 5.010e-05, MSE(pi1): 2.759e-03, MSE(pi2): 4.085e-05, MSE(pi3): 6.558e-04\n",
      "Epoch 67200, Train loss: 5.936e+02, Test loss: 2.050e+03, MSE(e): 5.004e-05, MSE(pi1): 2.757e-03, MSE(pi2): 4.079e-05, MSE(pi3): 6.559e-04\n",
      "Epoch 67300, Train loss: 5.930e+02, Test loss: 2.046e+03, MSE(e): 4.998e-05, MSE(pi1): 2.757e-03, MSE(pi2): 4.074e-05, MSE(pi3): 6.559e-04\n",
      "Epoch 67400, Train loss: 5.925e+02, Test loss: 2.041e+03, MSE(e): 4.993e-05, MSE(pi1): 2.754e-03, MSE(pi2): 4.068e-05, MSE(pi3): 6.562e-04\n",
      "Epoch 67500, Train loss: 5.920e+02, Test loss: 2.037e+03, MSE(e): 4.987e-05, MSE(pi1): 2.762e-03, MSE(pi2): 4.062e-05, MSE(pi3): 6.555e-04\n",
      "Epoch 67600, Train loss: 5.914e+02, Test loss: 2.033e+03, MSE(e): 4.982e-05, MSE(pi1): 2.758e-03, MSE(pi2): 4.057e-05, MSE(pi3): 6.558e-04\n",
      "Epoch 67700, Train loss: 5.908e+02, Test loss: 2.029e+03, MSE(e): 4.976e-05, MSE(pi1): 2.760e-03, MSE(pi2): 4.051e-05, MSE(pi3): 6.556e-04\n",
      "Epoch 67800, Train loss: 5.903e+02, Test loss: 2.024e+03, MSE(e): 4.971e-05, MSE(pi1): 2.762e-03, MSE(pi2): 4.045e-05, MSE(pi3): 6.555e-04\n",
      "Epoch 67900, Train loss: 5.898e+02, Test loss: 2.020e+03, MSE(e): 4.966e-05, MSE(pi1): 2.761e-03, MSE(pi2): 4.040e-05, MSE(pi3): 6.556e-04\n",
      "Epoch 68000, Train loss: 5.892e+02, Test loss: 2.016e+03, MSE(e): 4.960e-05, MSE(pi1): 2.761e-03, MSE(pi2): 4.034e-05, MSE(pi3): 6.555e-04\n",
      "Epoch 68100, Train loss: 5.887e+02, Test loss: 2.012e+03, MSE(e): 4.955e-05, MSE(pi1): 2.762e-03, MSE(pi2): 4.028e-05, MSE(pi3): 6.555e-04\n",
      "Epoch 68200, Train loss: 5.881e+02, Test loss: 2.008e+03, MSE(e): 4.949e-05, MSE(pi1): 2.760e-03, MSE(pi2): 4.023e-05, MSE(pi3): 6.556e-04\n",
      "Epoch 68300, Train loss: 5.876e+02, Test loss: 2.004e+03, MSE(e): 4.944e-05, MSE(pi1): 2.756e-03, MSE(pi2): 4.017e-05, MSE(pi3): 6.559e-04\n",
      "Epoch 68400, Train loss: 5.870e+02, Test loss: 1.999e+03, MSE(e): 4.938e-05, MSE(pi1): 2.756e-03, MSE(pi2): 4.012e-05, MSE(pi3): 6.559e-04\n",
      "Epoch 68500, Train loss: 5.865e+02, Test loss: 1.996e+03, MSE(e): 4.933e-05, MSE(pi1): 2.757e-03, MSE(pi2): 4.006e-05, MSE(pi3): 6.558e-04\n",
      "Epoch 68600, Train loss: 5.860e+02, Test loss: 1.991e+03, MSE(e): 4.928e-05, MSE(pi1): 2.764e-03, MSE(pi2): 4.001e-05, MSE(pi3): 6.552e-04\n",
      "Epoch 68700, Train loss: 5.855e+02, Test loss: 1.987e+03, MSE(e): 4.923e-05, MSE(pi1): 2.760e-03, MSE(pi2): 3.995e-05, MSE(pi3): 6.556e-04\n",
      "Epoch 68800, Train loss: 5.849e+02, Test loss: 1.984e+03, MSE(e): 4.917e-05, MSE(pi1): 2.760e-03, MSE(pi2): 3.990e-05, MSE(pi3): 6.556e-04\n",
      "Epoch 68900, Train loss: 5.844e+02, Test loss: 1.980e+03, MSE(e): 4.912e-05, MSE(pi1): 2.763e-03, MSE(pi2): 3.984e-05, MSE(pi3): 6.553e-04\n",
      "Epoch 69000, Train loss: 5.838e+02, Test loss: 1.976e+03, MSE(e): 4.907e-05, MSE(pi1): 2.762e-03, MSE(pi2): 3.979e-05, MSE(pi3): 6.554e-04\n",
      "Epoch 69100, Train loss: 5.833e+02, Test loss: 1.972e+03, MSE(e): 4.901e-05, MSE(pi1): 2.763e-03, MSE(pi2): 3.973e-05, MSE(pi3): 6.553e-04\n",
      "Epoch 69200, Train loss: 5.828e+02, Test loss: 1.968e+03, MSE(e): 4.896e-05, MSE(pi1): 2.763e-03, MSE(pi2): 3.968e-05, MSE(pi3): 6.553e-04\n",
      "Epoch 69300, Train loss: 5.822e+02, Test loss: 1.964e+03, MSE(e): 4.890e-05, MSE(pi1): 2.763e-03, MSE(pi2): 3.962e-05, MSE(pi3): 6.553e-04\n",
      "Epoch 69400, Train loss: 5.817e+02, Test loss: 1.960e+03, MSE(e): 4.885e-05, MSE(pi1): 2.763e-03, MSE(pi2): 3.957e-05, MSE(pi3): 6.553e-04\n",
      "Epoch 69500, Train loss: 5.811e+02, Test loss: 1.956e+03, MSE(e): 4.879e-05, MSE(pi1): 2.762e-03, MSE(pi2): 3.951e-05, MSE(pi3): 6.553e-04\n",
      "Epoch 69600, Train loss: 5.806e+02, Test loss: 1.952e+03, MSE(e): 4.874e-05, MSE(pi1): 2.762e-03, MSE(pi2): 3.946e-05, MSE(pi3): 6.554e-04\n",
      "Epoch 69700, Train loss: 5.801e+02, Test loss: 1.949e+03, MSE(e): 4.869e-05, MSE(pi1): 2.761e-03, MSE(pi2): 3.940e-05, MSE(pi3): 6.554e-04\n",
      "Epoch 69800, Train loss: 5.796e+02, Test loss: 1.945e+03, MSE(e): 4.864e-05, MSE(pi1): 2.762e-03, MSE(pi2): 3.935e-05, MSE(pi3): 6.553e-04\n",
      "Epoch 69900, Train loss: 5.791e+02, Test loss: 1.941e+03, MSE(e): 4.859e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.930e-05, MSE(pi3): 6.550e-04\n",
      "Epoch 70000, Train loss: 5.785e+02, Test loss: 1.938e+03, MSE(e): 4.853e-05, MSE(pi1): 2.761e-03, MSE(pi2): 3.924e-05, MSE(pi3): 6.554e-04\n",
      "Epoch 70100, Train loss: 5.780e+02, Test loss: 1.934e+03, MSE(e): 4.849e-05, MSE(pi1): 2.761e-03, MSE(pi2): 3.919e-05, MSE(pi3): 6.553e-04\n",
      "Epoch 70200, Train loss: 5.776e+02, Test loss: 1.930e+03, MSE(e): 4.844e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.914e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 70300, Train loss: 5.770e+02, Test loss: 1.927e+03, MSE(e): 4.838e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.909e-05, MSE(pi3): 6.551e-04\n",
      "Epoch 70400, Train loss: 5.765e+02, Test loss: 1.923e+03, MSE(e): 4.833e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.903e-05, MSE(pi3): 6.550e-04\n",
      "Epoch 70500, Train loss: 5.760e+02, Test loss: 1.920e+03, MSE(e): 4.828e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.898e-05, MSE(pi3): 6.550e-04\n",
      "Epoch 70600, Train loss: 5.755e+02, Test loss: 1.916e+03, MSE(e): 4.824e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.893e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 70700, Train loss: 5.750e+02, Test loss: 1.913e+03, MSE(e): 4.818e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.888e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 70800, Train loss: 5.745e+02, Test loss: 1.909e+03, MSE(e): 4.813e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.883e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 70900, Train loss: 5.740e+02, Test loss: 1.906e+03, MSE(e): 4.808e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.878e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 71000, Train loss: 5.735e+02, Test loss: 1.902e+03, MSE(e): 4.803e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.872e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 71100, Train loss: 5.730e+02, Test loss: 1.899e+03, MSE(e): 4.798e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.867e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 71200, Train loss: 5.725e+02, Test loss: 1.896e+03, MSE(e): 4.793e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.862e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 71300, Train loss: 5.720e+02, Test loss: 1.892e+03, MSE(e): 4.788e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.857e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 71400, Train loss: 5.715e+02, Test loss: 1.889e+03, MSE(e): 4.783e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.852e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 71500, Train loss: 5.710e+02, Test loss: 1.886e+03, MSE(e): 4.778e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.847e-05, MSE(pi3): 6.549e-04\n",
      "Epoch 71600, Train loss: 5.705e+02, Test loss: 1.882e+03, MSE(e): 4.773e-05, MSE(pi1): 2.764e-03, MSE(pi2): 3.842e-05, MSE(pi3): 6.550e-04\n",
      "Epoch 71700, Train loss: 5.700e+02, Test loss: 1.879e+03, MSE(e): 4.768e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.837e-05, MSE(pi3): 6.548e-04\n",
      "Epoch 71800, Train loss: 5.695e+02, Test loss: 1.876e+03, MSE(e): 4.763e-05, MSE(pi1): 2.767e-03, MSE(pi2): 3.832e-05, MSE(pi3): 6.547e-04\n",
      "Epoch 71900, Train loss: 5.690e+02, Test loss: 1.873e+03, MSE(e): 4.758e-05, MSE(pi1): 2.763e-03, MSE(pi2): 3.827e-05, MSE(pi3): 6.550e-04\n",
      "Epoch 72000, Train loss: 5.685e+02, Test loss: 1.869e+03, MSE(e): 4.754e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.822e-05, MSE(pi3): 6.548e-04\n",
      "Epoch 72100, Train loss: 5.680e+02, Test loss: 1.866e+03, MSE(e): 4.749e-05, MSE(pi1): 2.769e-03, MSE(pi2): 3.817e-05, MSE(pi3): 6.545e-04\n",
      "Epoch 72200, Train loss: 5.675e+02, Test loss: 1.863e+03, MSE(e): 4.744e-05, MSE(pi1): 2.767e-03, MSE(pi2): 3.812e-05, MSE(pi3): 6.547e-04\n",
      "Epoch 72300, Train loss: 5.671e+02, Test loss: 1.860e+03, MSE(e): 4.739e-05, MSE(pi1): 2.768e-03, MSE(pi2): 3.807e-05, MSE(pi3): 6.546e-04\n",
      "Epoch 72400, Train loss: 5.666e+02, Test loss: 1.857e+03, MSE(e): 4.734e-05, MSE(pi1): 2.768e-03, MSE(pi2): 3.802e-05, MSE(pi3): 6.546e-04\n",
      "Epoch 72500, Train loss: 5.661e+02, Test loss: 1.854e+03, MSE(e): 4.729e-05, MSE(pi1): 2.767e-03, MSE(pi2): 3.797e-05, MSE(pi3): 6.546e-04\n",
      "Epoch 72600, Train loss: 5.656e+02, Test loss: 1.851e+03, MSE(e): 4.725e-05, MSE(pi1): 2.768e-03, MSE(pi2): 3.792e-05, MSE(pi3): 6.545e-04\n",
      "Epoch 72700, Train loss: 5.652e+02, Test loss: 1.848e+03, MSE(e): 4.720e-05, MSE(pi1): 2.769e-03, MSE(pi2): 3.787e-05, MSE(pi3): 6.545e-04\n",
      "Epoch 72800, Train loss: 5.647e+02, Test loss: 1.845e+03, MSE(e): 4.715e-05, MSE(pi1): 2.767e-03, MSE(pi2): 3.782e-05, MSE(pi3): 6.546e-04\n",
      "Epoch 72900, Train loss: 5.642e+02, Test loss: 1.842e+03, MSE(e): 4.710e-05, MSE(pi1): 2.761e-03, MSE(pi2): 3.777e-05, MSE(pi3): 6.551e-04\n",
      "Epoch 73000, Train loss: 5.637e+02, Test loss: 1.839e+03, MSE(e): 4.706e-05, MSE(pi1): 2.767e-03, MSE(pi2): 3.772e-05, MSE(pi3): 6.546e-04\n",
      "Epoch 73100, Train loss: 5.632e+02, Test loss: 1.836e+03, MSE(e): 4.701e-05, MSE(pi1): 2.770e-03, MSE(pi2): 3.767e-05, MSE(pi3): 6.543e-04\n",
      "Epoch 73200, Train loss: 5.628e+02, Test loss: 1.834e+03, MSE(e): 4.696e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.763e-05, MSE(pi3): 6.546e-04\n",
      "Epoch 73300, Train loss: 5.623e+02, Test loss: 1.831e+03, MSE(e): 4.691e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.758e-05, MSE(pi3): 6.547e-04\n",
      "Epoch 73400, Train loss: 5.618e+02, Test loss: 1.828e+03, MSE(e): 4.687e-05, MSE(pi1): 2.769e-03, MSE(pi2): 3.753e-05, MSE(pi3): 6.544e-04\n",
      "Epoch 73500, Train loss: 5.614e+02, Test loss: 1.825e+03, MSE(e): 4.682e-05, MSE(pi1): 2.770e-03, MSE(pi2): 3.748e-05, MSE(pi3): 6.543e-04\n",
      "Epoch 73600, Train loss: 5.609e+02, Test loss: 1.822e+03, MSE(e): 4.677e-05, MSE(pi1): 2.769e-03, MSE(pi2): 3.743e-05, MSE(pi3): 6.544e-04\n",
      "Epoch 73700, Train loss: 5.605e+02, Test loss: 1.820e+03, MSE(e): 4.673e-05, MSE(pi1): 2.770e-03, MSE(pi2): 3.739e-05, MSE(pi3): 6.542e-04\n",
      "Epoch 73800, Train loss: 5.600e+02, Test loss: 1.817e+03, MSE(e): 4.668e-05, MSE(pi1): 2.771e-03, MSE(pi2): 3.734e-05, MSE(pi3): 6.542e-04\n",
      "Epoch 73900, Train loss: 5.595e+02, Test loss: 1.814e+03, MSE(e): 4.664e-05, MSE(pi1): 2.770e-03, MSE(pi2): 3.729e-05, MSE(pi3): 6.542e-04\n",
      "Epoch 74000, Train loss: 5.590e+02, Test loss: 1.812e+03, MSE(e): 4.659e-05, MSE(pi1): 2.771e-03, MSE(pi2): 3.725e-05, MSE(pi3): 6.541e-04\n",
      "Epoch 74100, Train loss: 5.586e+02, Test loss: 1.809e+03, MSE(e): 4.654e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.720e-05, MSE(pi3): 6.541e-04\n",
      "Epoch 74200, Train loss: 5.582e+02, Test loss: 1.806e+03, MSE(e): 4.650e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.715e-05, MSE(pi3): 6.540e-04\n",
      "Epoch 74300, Train loss: 5.577e+02, Test loss: 1.804e+03, MSE(e): 4.645e-05, MSE(pi1): 2.771e-03, MSE(pi2): 3.710e-05, MSE(pi3): 6.540e-04\n",
      "Epoch 74400, Train loss: 5.572e+02, Test loss: 1.801e+03, MSE(e): 4.641e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.706e-05, MSE(pi3): 6.540e-04\n",
      "Epoch 74500, Train loss: 5.568e+02, Test loss: 1.799e+03, MSE(e): 4.636e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.701e-05, MSE(pi3): 6.540e-04\n",
      "Epoch 74600, Train loss: 5.563e+02, Test loss: 1.796e+03, MSE(e): 4.631e-05, MSE(pi1): 2.773e-03, MSE(pi2): 3.696e-05, MSE(pi3): 6.539e-04\n",
      "Epoch 74700, Train loss: 5.558e+02, Test loss: 1.794e+03, MSE(e): 4.627e-05, MSE(pi1): 2.769e-03, MSE(pi2): 3.692e-05, MSE(pi3): 6.542e-04\n",
      "Epoch 74800, Train loss: 5.554e+02, Test loss: 1.791e+03, MSE(e): 4.622e-05, MSE(pi1): 2.768e-03, MSE(pi2): 3.687e-05, MSE(pi3): 6.542e-04\n",
      "Epoch 74900, Train loss: 5.549e+02, Test loss: 1.789e+03, MSE(e): 4.618e-05, MSE(pi1): 2.770e-03, MSE(pi2): 3.683e-05, MSE(pi3): 6.541e-04\n",
      "Epoch 75000, Train loss: 5.545e+02, Test loss: 1.787e+03, MSE(e): 4.613e-05, MSE(pi1): 2.768e-03, MSE(pi2): 3.678e-05, MSE(pi3): 6.543e-04\n",
      "Epoch 75100, Train loss: 5.540e+02, Test loss: 1.784e+03, MSE(e): 4.609e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.673e-05, MSE(pi3): 6.545e-04\n",
      "Epoch 75200, Train loss: 5.535e+02, Test loss: 1.782e+03, MSE(e): 4.604e-05, MSE(pi1): 2.767e-03, MSE(pi2): 3.669e-05, MSE(pi3): 6.543e-04\n",
      "Epoch 75300, Train loss: 5.531e+02, Test loss: 1.779e+03, MSE(e): 4.600e-05, MSE(pi1): 2.768e-03, MSE(pi2): 3.664e-05, MSE(pi3): 6.542e-04\n",
      "Epoch 75400, Train loss: 5.526e+02, Test loss: 1.777e+03, MSE(e): 4.595e-05, MSE(pi1): 2.767e-03, MSE(pi2): 3.660e-05, MSE(pi3): 6.543e-04\n",
      "Epoch 75500, Train loss: 5.522e+02, Test loss: 1.775e+03, MSE(e): 4.591e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.655e-05, MSE(pi3): 6.543e-04\n",
      "Epoch 75600, Train loss: 5.518e+02, Test loss: 1.773e+03, MSE(e): 4.586e-05, MSE(pi1): 2.768e-03, MSE(pi2): 3.651e-05, MSE(pi3): 6.542e-04\n",
      "Epoch 75700, Train loss: 5.513e+02, Test loss: 1.770e+03, MSE(e): 4.582e-05, MSE(pi1): 2.769e-03, MSE(pi2): 3.646e-05, MSE(pi3): 6.541e-04\n",
      "Epoch 75800, Train loss: 5.509e+02, Test loss: 1.768e+03, MSE(e): 4.578e-05, MSE(pi1): 2.768e-03, MSE(pi2): 3.642e-05, MSE(pi3): 6.541e-04\n",
      "Epoch 75900, Train loss: 5.504e+02, Test loss: 1.766e+03, MSE(e): 4.573e-05, MSE(pi1): 2.768e-03, MSE(pi2): 3.637e-05, MSE(pi3): 6.541e-04\n",
      "Epoch 76000, Train loss: 5.500e+02, Test loss: 1.764e+03, MSE(e): 4.569e-05, MSE(pi1): 2.769e-03, MSE(pi2): 3.633e-05, MSE(pi3): 6.540e-04\n",
      "Epoch 76100, Train loss: 5.496e+02, Test loss: 1.762e+03, MSE(e): 4.564e-05, MSE(pi1): 2.770e-03, MSE(pi2): 3.628e-05, MSE(pi3): 6.539e-04\n",
      "Epoch 76200, Train loss: 5.491e+02, Test loss: 1.759e+03, MSE(e): 4.560e-05, MSE(pi1): 2.773e-03, MSE(pi2): 3.624e-05, MSE(pi3): 6.536e-04\n",
      "Epoch 76300, Train loss: 5.487e+02, Test loss: 1.757e+03, MSE(e): 4.556e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.620e-05, MSE(pi3): 6.537e-04\n",
      "Epoch 76400, Train loss: 5.482e+02, Test loss: 1.755e+03, MSE(e): 4.551e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.615e-05, MSE(pi3): 6.537e-04\n",
      "Epoch 76500, Train loss: 5.478e+02, Test loss: 1.753e+03, MSE(e): 4.547e-05, MSE(pi1): 2.773e-03, MSE(pi2): 3.611e-05, MSE(pi3): 6.536e-04\n",
      "Epoch 76600, Train loss: 5.474e+02, Test loss: 1.751e+03, MSE(e): 4.542e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.606e-05, MSE(pi3): 6.537e-04\n",
      "Epoch 76700, Train loss: 5.469e+02, Test loss: 1.749e+03, MSE(e): 4.538e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.602e-05, MSE(pi3): 6.536e-04\n",
      "Epoch 76800, Train loss: 5.465e+02, Test loss: 1.747e+03, MSE(e): 4.534e-05, MSE(pi1): 2.773e-03, MSE(pi2): 3.597e-05, MSE(pi3): 6.535e-04\n",
      "Epoch 76900, Train loss: 5.461e+02, Test loss: 1.745e+03, MSE(e): 4.529e-05, MSE(pi1): 2.773e-03, MSE(pi2): 3.593e-05, MSE(pi3): 6.536e-04\n",
      "Epoch 77000, Train loss: 5.456e+02, Test loss: 1.743e+03, MSE(e): 4.525e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.589e-05, MSE(pi3): 6.536e-04\n",
      "Epoch 77100, Train loss: 5.452e+02, Test loss: 1.741e+03, MSE(e): 4.521e-05, MSE(pi1): 2.773e-03, MSE(pi2): 3.584e-05, MSE(pi3): 6.536e-04\n",
      "Epoch 77200, Train loss: 5.448e+02, Test loss: 1.739e+03, MSE(e): 4.517e-05, MSE(pi1): 2.775e-03, MSE(pi2): 3.580e-05, MSE(pi3): 6.533e-04\n",
      "Epoch 77300, Train loss: 5.444e+02, Test loss: 1.737e+03, MSE(e): 4.513e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.576e-05, MSE(pi3): 6.534e-04\n",
      "Epoch 77400, Train loss: 5.439e+02, Test loss: 1.735e+03, MSE(e): 4.508e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.572e-05, MSE(pi3): 6.535e-04\n",
      "Epoch 77500, Train loss: 5.436e+02, Test loss: 1.734e+03, MSE(e): 4.504e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.568e-05, MSE(pi3): 6.534e-04\n",
      "Epoch 77600, Train loss: 5.432e+02, Test loss: 1.732e+03, MSE(e): 4.501e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.564e-05, MSE(pi3): 6.533e-04\n",
      "Epoch 77700, Train loss: 5.427e+02, Test loss: 1.730e+03, MSE(e): 4.496e-05, MSE(pi1): 2.775e-03, MSE(pi2): 3.559e-05, MSE(pi3): 6.532e-04\n",
      "Epoch 77800, Train loss: 5.423e+02, Test loss: 1.728e+03, MSE(e): 4.492e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.555e-05, MSE(pi3): 6.533e-04\n",
      "Epoch 77900, Train loss: 5.419e+02, Test loss: 1.726e+03, MSE(e): 4.488e-05, MSE(pi1): 2.771e-03, MSE(pi2): 3.551e-05, MSE(pi3): 6.535e-04\n",
      "Epoch 78000, Train loss: 5.415e+02, Test loss: 1.725e+03, MSE(e): 4.484e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.547e-05, MSE(pi3): 6.535e-04\n",
      "Epoch 78100, Train loss: 5.411e+02, Test loss: 1.723e+03, MSE(e): 4.480e-05, MSE(pi1): 2.776e-03, MSE(pi2): 3.543e-05, MSE(pi3): 6.531e-04\n",
      "Epoch 78200, Train loss: 5.408e+02, Test loss: 1.721e+03, MSE(e): 4.476e-05, MSE(pi1): 2.785e-03, MSE(pi2): 3.539e-05, MSE(pi3): 6.525e-04\n",
      "Epoch 78300, Train loss: 5.402e+02, Test loss: 1.720e+03, MSE(e): 4.471e-05, MSE(pi1): 2.771e-03, MSE(pi2): 3.534e-05, MSE(pi3): 6.535e-04\n",
      "Epoch 78400, Train loss: 5.398e+02, Test loss: 1.718e+03, MSE(e): 4.467e-05, MSE(pi1): 2.771e-03, MSE(pi2): 3.530e-05, MSE(pi3): 6.535e-04\n",
      "Epoch 78500, Train loss: 5.394e+02, Test loss: 1.716e+03, MSE(e): 4.463e-05, MSE(pi1): 2.771e-03, MSE(pi2): 3.526e-05, MSE(pi3): 6.535e-04\n",
      "Epoch 78600, Train loss: 5.390e+02, Test loss: 1.715e+03, MSE(e): 4.459e-05, MSE(pi1): 2.770e-03, MSE(pi2): 3.522e-05, MSE(pi3): 6.536e-04\n",
      "Epoch 78700, Train loss: 5.386e+02, Test loss: 1.713e+03, MSE(e): 4.455e-05, MSE(pi1): 2.773e-03, MSE(pi2): 3.518e-05, MSE(pi3): 6.533e-04\n",
      "Epoch 78800, Train loss: 5.382e+02, Test loss: 1.711e+03, MSE(e): 4.451e-05, MSE(pi1): 2.776e-03, MSE(pi2): 3.514e-05, MSE(pi3): 6.531e-04\n",
      "Epoch 78900, Train loss: 5.377e+02, Test loss: 1.710e+03, MSE(e): 4.447e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.510e-05, MSE(pi3): 6.532e-04\n",
      "Epoch 79000, Train loss: 5.374e+02, Test loss: 1.708e+03, MSE(e): 4.443e-05, MSE(pi1): 2.776e-03, MSE(pi2): 3.506e-05, MSE(pi3): 6.530e-04\n",
      "Epoch 79100, Train loss: 5.369e+02, Test loss: 1.707e+03, MSE(e): 4.438e-05, MSE(pi1): 2.776e-03, MSE(pi2): 3.501e-05, MSE(pi3): 6.530e-04\n",
      "Epoch 79200, Train loss: 5.365e+02, Test loss: 1.705e+03, MSE(e): 4.434e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.497e-05, MSE(pi3): 6.531e-04\n",
      "Epoch 79300, Train loss: 5.361e+02, Test loss: 1.704e+03, MSE(e): 4.431e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.493e-05, MSE(pi3): 6.532e-04\n",
      "Epoch 79400, Train loss: 5.358e+02, Test loss: 1.702e+03, MSE(e): 4.427e-05, MSE(pi1): 2.773e-03, MSE(pi2): 3.490e-05, MSE(pi3): 6.532e-04\n",
      "Epoch 79500, Train loss: 5.354e+02, Test loss: 1.701e+03, MSE(e): 4.423e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.485e-05, MSE(pi3): 6.530e-04\n",
      "Epoch 79600, Train loss: 5.349e+02, Test loss: 1.700e+03, MSE(e): 4.418e-05, MSE(pi1): 2.775e-03, MSE(pi2): 3.481e-05, MSE(pi3): 6.530e-04\n",
      "Epoch 79700, Train loss: 5.345e+02, Test loss: 1.698e+03, MSE(e): 4.415e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.477e-05, MSE(pi3): 6.530e-04\n",
      "Epoch 79800, Train loss: 5.342e+02, Test loss: 1.697e+03, MSE(e): 4.411e-05, MSE(pi1): 2.777e-03, MSE(pi2): 3.474e-05, MSE(pi3): 6.528e-04\n",
      "Epoch 79900, Train loss: 5.338e+02, Test loss: 1.696e+03, MSE(e): 4.407e-05, MSE(pi1): 2.778e-03, MSE(pi2): 3.469e-05, MSE(pi3): 6.527e-04\n",
      "Epoch 80000, Train loss: 5.334e+02, Test loss: 1.694e+03, MSE(e): 4.403e-05, MSE(pi1): 2.777e-03, MSE(pi2): 3.466e-05, MSE(pi3): 6.527e-04\n",
      "Epoch 80100, Train loss: 5.331e+02, Test loss: 1.693e+03, MSE(e): 4.400e-05, MSE(pi1): 2.777e-03, MSE(pi2): 3.462e-05, MSE(pi3): 6.527e-04\n",
      "Epoch 80200, Train loss: 5.326e+02, Test loss: 1.691e+03, MSE(e): 4.395e-05, MSE(pi1): 2.776e-03, MSE(pi2): 3.458e-05, MSE(pi3): 6.528e-04\n",
      "Epoch 80300, Train loss: 5.321e+02, Test loss: 1.690e+03, MSE(e): 4.391e-05, MSE(pi1): 2.777e-03, MSE(pi2): 3.453e-05, MSE(pi3): 6.527e-04\n",
      "Epoch 80400, Train loss: 5.318e+02, Test loss: 1.689e+03, MSE(e): 4.387e-05, MSE(pi1): 2.775e-03, MSE(pi2): 3.450e-05, MSE(pi3): 6.528e-04\n",
      "Epoch 80500, Train loss: 5.315e+02, Test loss: 1.687e+03, MSE(e): 4.384e-05, MSE(pi1): 2.778e-03, MSE(pi2): 3.446e-05, MSE(pi3): 6.526e-04\n",
      "Epoch 80600, Train loss: 5.311e+02, Test loss: 1.687e+03, MSE(e): 4.380e-05, MSE(pi1): 2.780e-03, MSE(pi2): 3.442e-05, MSE(pi3): 6.524e-04\n",
      "Epoch 80700, Train loss: 5.306e+02, Test loss: 1.685e+03, MSE(e): 4.376e-05, MSE(pi1): 2.776e-03, MSE(pi2): 3.438e-05, MSE(pi3): 6.527e-04\n",
      "Epoch 80800, Train loss: 5.301e+02, Test loss: 1.684e+03, MSE(e): 4.371e-05, MSE(pi1): 2.778e-03, MSE(pi2): 3.434e-05, MSE(pi3): 6.525e-04\n",
      "Epoch 80900, Train loss: 5.299e+02, Test loss: 1.683e+03, MSE(e): 4.368e-05, MSE(pi1): 2.782e-03, MSE(pi2): 3.431e-05, MSE(pi3): 6.522e-04\n",
      "Epoch 81000, Train loss: 5.295e+02, Test loss: 1.682e+03, MSE(e): 4.364e-05, MSE(pi1): 2.779e-03, MSE(pi2): 3.427e-05, MSE(pi3): 6.524e-04\n",
      "Epoch 81100, Train loss: 5.291e+02, Test loss: 1.681e+03, MSE(e): 4.360e-05, MSE(pi1): 2.778e-03, MSE(pi2): 3.423e-05, MSE(pi3): 6.525e-04\n",
      "Epoch 81200, Train loss: 5.288e+02, Test loss: 1.679e+03, MSE(e): 4.358e-05, MSE(pi1): 2.779e-03, MSE(pi2): 3.420e-05, MSE(pi3): 6.523e-04\n",
      "Epoch 81300, Train loss: 5.283e+02, Test loss: 1.678e+03, MSE(e): 4.352e-05, MSE(pi1): 2.779e-03, MSE(pi2): 3.415e-05, MSE(pi3): 6.524e-04\n",
      "Epoch 81400, Train loss: 5.280e+02, Test loss: 1.677e+03, MSE(e): 4.350e-05, MSE(pi1): 2.778e-03, MSE(pi2): 3.412e-05, MSE(pi3): 6.524e-04\n",
      "Epoch 81500, Train loss: 5.276e+02, Test loss: 1.676e+03, MSE(e): 4.346e-05, MSE(pi1): 2.779e-03, MSE(pi2): 3.408e-05, MSE(pi3): 6.522e-04\n",
      "Epoch 81600, Train loss: 5.272e+02, Test loss: 1.675e+03, MSE(e): 4.342e-05, MSE(pi1): 2.780e-03, MSE(pi2): 3.404e-05, MSE(pi3): 6.522e-04\n",
      "Epoch 81700, Train loss: 5.268e+02, Test loss: 1.674e+03, MSE(e): 4.337e-05, MSE(pi1): 2.781e-03, MSE(pi2): 3.400e-05, MSE(pi3): 6.521e-04\n",
      "Epoch 81800, Train loss: 5.264e+02, Test loss: 1.673e+03, MSE(e): 4.334e-05, MSE(pi1): 2.778e-03, MSE(pi2): 3.396e-05, MSE(pi3): 6.524e-04\n",
      "Epoch 81900, Train loss: 5.260e+02, Test loss: 1.672e+03, MSE(e): 4.330e-05, MSE(pi1): 2.776e-03, MSE(pi2): 3.393e-05, MSE(pi3): 6.525e-04\n",
      "Epoch 82000, Train loss: 5.256e+02, Test loss: 1.671e+03, MSE(e): 4.325e-05, MSE(pi1): 2.783e-03, MSE(pi2): 3.389e-05, MSE(pi3): 6.520e-04\n",
      "Epoch 82100, Train loss: 5.252e+02, Test loss: 1.670e+03, MSE(e): 4.322e-05, MSE(pi1): 2.775e-03, MSE(pi2): 3.385e-05, MSE(pi3): 6.525e-04\n",
      "Epoch 82200, Train loss: 5.253e+02, Test loss: 1.668e+03, MSE(e): 4.323e-05, MSE(pi1): 2.778e-03, MSE(pi2): 3.383e-05, MSE(pi3): 6.523e-04\n",
      "Epoch 82300, Train loss: 5.249e+02, Test loss: 1.670e+03, MSE(e): 4.318e-05, MSE(pi1): 2.780e-03, MSE(pi2): 3.380e-05, MSE(pi3): 6.522e-04\n",
      "Epoch 82400, Train loss: 5.222e+02, Test loss: 1.669e+03, MSE(e): 4.292e-05, MSE(pi1): 2.769e-03, MSE(pi2): 3.363e-05, MSE(pi3): 6.530e-04\n",
      "Epoch 82500, Train loss: 5.282e+02, Test loss: 1.658e+03, MSE(e): 4.352e-05, MSE(pi1): 2.787e-03, MSE(pi2): 3.391e-05, MSE(pi3): 6.514e-04\n",
      "Epoch 82600, Train loss: 5.204e+02, Test loss: 1.679e+03, MSE(e): 4.274e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.355e-05, MSE(pi3): 6.531e-04\n",
      "Epoch 82700, Train loss: 5.242e+02, Test loss: 1.653e+03, MSE(e): 4.312e-05, MSE(pi1): 2.776e-03, MSE(pi2): 3.364e-05, MSE(pi3): 6.523e-04\n",
      "Epoch 82800, Train loss: 5.222e+02, Test loss: 1.673e+03, MSE(e): 4.292e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.362e-05, MSE(pi3): 6.524e-04\n",
      "Epoch 82900, Train loss: 5.218e+02, Test loss: 1.653e+03, MSE(e): 4.288e-05, MSE(pi1): 2.780e-03, MSE(pi2): 3.348e-05, MSE(pi3): 6.519e-04\n",
      "Epoch 83000, Train loss: 5.211e+02, Test loss: 1.673e+03, MSE(e): 4.281e-05, MSE(pi1): 2.783e-03, MSE(pi2): 3.353e-05, MSE(pi3): 6.516e-04\n",
      "Epoch 83100, Train loss: 5.236e+02, Test loss: 1.647e+03, MSE(e): 4.305e-05, MSE(pi1): 2.788e-03, MSE(pi2): 3.353e-05, MSE(pi3): 6.513e-04\n",
      "Epoch 83200, Train loss: 5.172e+02, Test loss: 1.676e+03, MSE(e): 4.242e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.329e-05, MSE(pi3): 6.530e-04\n",
      "Epoch 83300, Train loss: 5.266e+02, Test loss: 1.651e+03, MSE(e): 4.335e-05, MSE(pi1): 2.796e-03, MSE(pi2): 3.370e-05, MSE(pi3): 6.505e-04\n",
      "Epoch 83400, Train loss: 5.185e+02, Test loss: 1.650e+03, MSE(e): 4.255e-05, MSE(pi1): 2.775e-03, MSE(pi2): 3.323e-05, MSE(pi3): 6.523e-04\n",
      "Epoch 83500, Train loss: 5.160e+02, Test loss: 1.675e+03, MSE(e): 4.231e-05, MSE(pi1): 2.770e-03, MSE(pi2): 3.319e-05, MSE(pi3): 6.526e-04\n",
      "Epoch 83600, Train loss: 5.237e+02, Test loss: 1.655e+03, MSE(e): 4.306e-05, MSE(pi1): 2.791e-03, MSE(pi2): 3.353e-05, MSE(pi3): 6.507e-04\n",
      "Epoch 83700, Train loss: 5.241e+02, Test loss: 1.639e+03, MSE(e): 4.311e-05, MSE(pi1): 2.792e-03, MSE(pi2): 3.345e-05, MSE(pi3): 6.507e-04\n",
      "Epoch 83800, Train loss: 5.161e+02, Test loss: 1.650e+03, MSE(e): 4.230e-05, MSE(pi1): 2.782e-03, MSE(pi2): 3.304e-05, MSE(pi3): 6.517e-04\n",
      "Epoch 83900, Train loss: 5.138e+02, Test loss: 1.670e+03, MSE(e): 4.208e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.298e-05, MSE(pi3): 6.529e-04\n",
      "Epoch 84000, Train loss: 5.148e+02, Test loss: 1.672e+03, MSE(e): 4.218e-05, MSE(pi1): 2.776e-03, MSE(pi2): 3.306e-05, MSE(pi3): 6.521e-04\n",
      "Epoch 84100, Train loss: 5.176e+02, Test loss: 1.663e+03, MSE(e): 4.246e-05, MSE(pi1): 2.780e-03, MSE(pi2): 3.318e-05, MSE(pi3): 6.516e-04\n",
      "Epoch 84200, Train loss: 5.210e+02, Test loss: 1.652e+03, MSE(e): 4.280e-05, MSE(pi1): 2.788e-03, MSE(pi2): 3.331e-05, MSE(pi3): 6.509e-04\n",
      "Epoch 84300, Train loss: 5.231e+02, Test loss: 1.645e+03, MSE(e): 4.301e-05, MSE(pi1): 2.794e-03, MSE(pi2): 3.337e-05, MSE(pi3): 6.503e-04\n",
      "Epoch 84400, Train loss: 5.239e+02, Test loss: 1.640e+03, MSE(e): 4.309e-05, MSE(pi1): 2.797e-03, MSE(pi2): 3.338e-05, MSE(pi3): 6.501e-04\n",
      "Epoch 84500, Train loss: 5.238e+02, Test loss: 1.639e+03, MSE(e): 4.308e-05, MSE(pi1): 2.798e-03, MSE(pi2): 3.335e-05, MSE(pi3): 6.500e-04\n",
      "Epoch 84600, Train loss: 5.229e+02, Test loss: 1.640e+03, MSE(e): 4.299e-05, MSE(pi1): 2.796e-03, MSE(pi2): 3.330e-05, MSE(pi3): 6.502e-04\n",
      "Epoch 84700, Train loss: 5.205e+02, Test loss: 1.645e+03, MSE(e): 4.275e-05, MSE(pi1): 2.792e-03, MSE(pi2): 3.319e-05, MSE(pi3): 6.505e-04\n",
      "Epoch 84800, Train loss: 5.167e+02, Test loss: 1.654e+03, MSE(e): 4.237e-05, MSE(pi1): 2.787e-03, MSE(pi2): 3.302e-05, MSE(pi3): 6.509e-04\n",
      "Epoch 84900, Train loss: 5.124e+02, Test loss: 1.665e+03, MSE(e): 4.194e-05, MSE(pi1): 2.779e-03, MSE(pi2): 3.281e-05, MSE(pi3): 6.516e-04\n",
      "Epoch 85000, Train loss: 5.095e+02, Test loss: 1.669e+03, MSE(e): 4.165e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.262e-05, MSE(pi3): 6.527e-04\n",
      "Epoch 85100, Train loss: 5.093e+02, Test loss: 1.653e+03, MSE(e): 4.164e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.252e-05, MSE(pi3): 6.528e-04\n",
      "Epoch 85200, Train loss: 5.138e+02, Test loss: 1.628e+03, MSE(e): 4.208e-05, MSE(pi1): 2.783e-03, MSE(pi2): 3.266e-05, MSE(pi3): 6.512e-04\n",
      "Epoch 85300, Train loss: 5.228e+02, Test loss: 1.625e+03, MSE(e): 4.298e-05, MSE(pi1): 2.804e-03, MSE(pi2): 3.313e-05, MSE(pi3): 6.494e-04\n",
      "Epoch 85400, Train loss: 5.141e+02, Test loss: 1.651e+03, MSE(e): 4.211e-05, MSE(pi1): 2.784e-03, MSE(pi2): 3.280e-05, MSE(pi3): 6.509e-04\n",
      "Epoch 85500, Train loss: 5.072e+02, Test loss: 1.665e+03, MSE(e): 4.143e-05, MSE(pi1): 2.762e-03, MSE(pi2): 3.241e-05, MSE(pi3): 6.529e-04\n",
      "Epoch 85600, Train loss: 5.114e+02, Test loss: 1.627e+03, MSE(e): 4.184e-05, MSE(pi1): 2.785e-03, MSE(pi2): 3.248e-05, MSE(pi3): 6.510e-04\n",
      "Epoch 85700, Train loss: 5.206e+02, Test loss: 1.628e+03, MSE(e): 4.276e-05, MSE(pi1): 2.799e-03, MSE(pi2): 3.299e-05, MSE(pi3): 6.497e-04\n",
      "Epoch 85800, Train loss: 5.067e+02, Test loss: 1.666e+03, MSE(e): 4.138e-05, MSE(pi1): 2.770e-03, MSE(pi2): 3.237e-05, MSE(pi3): 6.522e-04\n",
      "Epoch 85900, Train loss: 5.102e+02, Test loss: 1.625e+03, MSE(e): 4.172e-05, MSE(pi1): 2.776e-03, MSE(pi2): 3.237e-05, MSE(pi3): 6.517e-04\n",
      "Epoch 86000, Train loss: 5.164e+02, Test loss: 1.635e+03, MSE(e): 4.235e-05, MSE(pi1): 2.795e-03, MSE(pi2): 3.278e-05, MSE(pi3): 6.499e-04\n",
      "Epoch 86100, Train loss: 5.051e+02, Test loss: 1.658e+03, MSE(e): 4.122e-05, MSE(pi1): 2.758e-03, MSE(pi2): 3.219e-05, MSE(pi3): 6.531e-04\n",
      "Epoch 86200, Train loss: 5.202e+02, Test loss: 1.616e+03, MSE(e): 4.272e-05, MSE(pi1): 2.800e-03, MSE(pi2): 3.283e-05, MSE(pi3): 6.495e-04\n",
      "Epoch 86300, Train loss: 5.048e+02, Test loss: 1.664e+03, MSE(e): 4.118e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.220e-05, MSE(pi3): 6.524e-04\n",
      "Epoch 86400, Train loss: 5.155e+02, Test loss: 1.614e+03, MSE(e): 4.226e-05, MSE(pi1): 2.793e-03, MSE(pi2): 3.255e-05, MSE(pi3): 6.500e-04\n",
      "Epoch 86500, Train loss: 5.046e+02, Test loss: 1.661e+03, MSE(e): 4.117e-05, MSE(pi1): 2.771e-03, MSE(pi2): 3.218e-05, MSE(pi3): 6.519e-04\n",
      "Epoch 86600, Train loss: 5.156e+02, Test loss: 1.613e+03, MSE(e): 4.227e-05, MSE(pi1): 2.797e-03, MSE(pi2): 3.252e-05, MSE(pi3): 6.497e-04\n",
      "Epoch 86700, Train loss: 5.032e+02, Test loss: 1.662e+03, MSE(e): 4.103e-05, MSE(pi1): 2.762e-03, MSE(pi2): 3.206e-05, MSE(pi3): 6.526e-04\n",
      "Epoch 86800, Train loss: 5.189e+02, Test loss: 1.612e+03, MSE(e): 4.260e-05, MSE(pi1): 2.802e-03, MSE(pi2): 3.268e-05, MSE(pi3): 6.492e-04\n",
      "Epoch 86900, Train loss: 5.023e+02, Test loss: 1.654e+03, MSE(e): 4.094e-05, MSE(pi1): 2.759e-03, MSE(pi2): 3.192e-05, MSE(pi3): 6.528e-04\n",
      "Epoch 87000, Train loss: 5.135e+02, Test loss: 1.628e+03, MSE(e): 4.205e-05, MSE(pi1): 2.792e-03, MSE(pi2): 3.248e-05, MSE(pi3): 6.500e-04\n",
      "Epoch 87100, Train loss: 5.058e+02, Test loss: 1.618e+03, MSE(e): 4.129e-05, MSE(pi1): 2.780e-03, MSE(pi2): 3.196e-05, MSE(pi3): 6.511e-04\n",
      "Epoch 87200, Train loss: 5.016e+02, Test loss: 1.660e+03, MSE(e): 4.087e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.192e-05, MSE(pi3): 6.522e-04\n",
      "Epoch 87300, Train loss: 5.168e+02, Test loss: 1.615e+03, MSE(e): 4.238e-05, MSE(pi1): 2.802e-03, MSE(pi2): 3.254e-05, MSE(pi3): 6.491e-04\n",
      "Epoch 87400, Train loss: 5.037e+02, Test loss: 1.619e+03, MSE(e): 4.108e-05, MSE(pi1): 2.773e-03, MSE(pi2): 3.182e-05, MSE(pi3): 6.516e-04\n",
      "Epoch 87500, Train loss: 5.002e+02, Test loss: 1.660e+03, MSE(e): 4.073e-05, MSE(pi1): 2.768e-03, MSE(pi2): 3.179e-05, MSE(pi3): 6.520e-04\n",
      "Epoch 87600, Train loss: 5.109e+02, Test loss: 1.626e+03, MSE(e): 4.180e-05, MSE(pi1): 2.793e-03, MSE(pi2): 3.227e-05, MSE(pi3): 6.498e-04\n",
      "Epoch 87700, Train loss: 5.124e+02, Test loss: 1.606e+03, MSE(e): 4.194e-05, MSE(pi1): 2.802e-03, MSE(pi2): 3.219e-05, MSE(pi3): 6.491e-04\n",
      "Epoch 87800, Train loss: 5.002e+02, Test loss: 1.634e+03, MSE(e): 4.073e-05, MSE(pi1): 2.760e-03, MSE(pi2): 3.162e-05, MSE(pi3): 6.527e-04\n",
      "Epoch 87900, Train loss: 4.988e+02, Test loss: 1.658e+03, MSE(e): 4.059e-05, MSE(pi1): 2.761e-03, MSE(pi2): 3.167e-05, MSE(pi3): 6.525e-04\n",
      "Epoch 88000, Train loss: 5.050e+02, Test loss: 1.635e+03, MSE(e): 4.121e-05, MSE(pi1): 2.785e-03, MSE(pi2): 3.197e-05, MSE(pi3): 6.503e-04\n",
      "Epoch 88100, Train loss: 5.154e+02, Test loss: 1.608e+03, MSE(e): 4.225e-05, MSE(pi1): 2.804e-03, MSE(pi2): 3.234e-05, MSE(pi3): 6.488e-04\n",
      "Epoch 88200, Train loss: 5.099e+02, Test loss: 1.604e+03, MSE(e): 4.169e-05, MSE(pi1): 2.796e-03, MSE(pi2): 3.199e-05, MSE(pi3): 6.495e-04\n",
      "Epoch 88300, Train loss: 5.001e+02, Test loss: 1.618e+03, MSE(e): 4.072e-05, MSE(pi1): 2.769e-03, MSE(pi2): 3.151e-05, MSE(pi3): 6.517e-04\n",
      "Epoch 88400, Train loss: 4.976e+02, Test loss: 1.641e+03, MSE(e): 4.048e-05, MSE(pi1): 2.758e-03, MSE(pi2): 3.144e-05, MSE(pi3): 6.526e-04\n",
      "Epoch 88500, Train loss: 4.965e+02, Test loss: 1.655e+03, MSE(e): 4.037e-05, MSE(pi1): 2.759e-03, MSE(pi2): 3.144e-05, MSE(pi3): 6.525e-04\n",
      "Epoch 88600, Train loss: 4.968e+02, Test loss: 1.655e+03, MSE(e): 4.039e-05, MSE(pi1): 2.765e-03, MSE(pi2): 3.149e-05, MSE(pi3): 6.520e-04\n",
      "Epoch 88700, Train loss: 4.983e+02, Test loss: 1.646e+03, MSE(e): 4.055e-05, MSE(pi1): 2.772e-03, MSE(pi2): 3.156e-05, MSE(pi3): 6.514e-04\n",
      "Epoch 88800, Train loss: 5.005e+02, Test loss: 1.637e+03, MSE(e): 4.076e-05, MSE(pi1): 2.778e-03, MSE(pi2): 3.164e-05, MSE(pi3): 6.508e-04\n",
      "Epoch 88900, Train loss: 5.019e+02, Test loss: 1.631e+03, MSE(e): 4.090e-05, MSE(pi1): 2.782e-03, MSE(pi2): 3.169e-05, MSE(pi3): 6.504e-04\n",
      "Epoch 89000, Train loss: 5.030e+02, Test loss: 1.627e+03, MSE(e): 4.101e-05, MSE(pi1): 2.785e-03, MSE(pi2): 3.172e-05, MSE(pi3): 6.502e-04\n",
      "Epoch 89100, Train loss: 5.026e+02, Test loss: 1.627e+03, MSE(e): 4.097e-05, MSE(pi1): 2.786e-03, MSE(pi2): 3.168e-05, MSE(pi3): 6.501e-04\n",
      "Epoch 89200, Train loss: 5.015e+02, Test loss: 1.628e+03, MSE(e): 4.086e-05, MSE(pi1): 2.782e-03, MSE(pi2): 3.162e-05, MSE(pi3): 6.504e-04\n",
      "Epoch 89300, Train loss: 4.994e+02, Test loss: 1.633e+03, MSE(e): 4.065e-05, MSE(pi1): 2.780e-03, MSE(pi2): 3.152e-05, MSE(pi3): 6.505e-04\n",
      "Epoch 89400, Train loss: 4.968e+02, Test loss: 1.641e+03, MSE(e): 4.039e-05, MSE(pi1): 2.775e-03, MSE(pi2): 3.139e-05, MSE(pi3): 6.509e-04\n",
      "Epoch 89500, Train loss: 4.944e+02, Test loss: 1.649e+03, MSE(e): 4.015e-05, MSE(pi1): 2.768e-03, MSE(pi2): 3.125e-05, MSE(pi3): 6.515e-04\n",
      "Epoch 89600, Train loss: 4.930e+02, Test loss: 1.654e+03, MSE(e): 4.001e-05, MSE(pi1): 2.761e-03, MSE(pi2): 3.114e-05, MSE(pi3): 6.521e-04\n",
      "Epoch 89700, Train loss: 4.930e+02, Test loss: 1.647e+03, MSE(e): 4.001e-05, MSE(pi1): 2.756e-03, MSE(pi2): 3.107e-05, MSE(pi3): 6.526e-04\n",
      "Epoch 89800, Train loss: 4.940e+02, Test loss: 1.624e+03, MSE(e): 4.011e-05, MSE(pi1): 2.758e-03, MSE(pi2): 3.102e-05, MSE(pi3): 6.524e-04\n",
      "Epoch 89900, Train loss: 4.986e+02, Test loss: 1.602e+03, MSE(e): 4.057e-05, MSE(pi1): 2.782e-03, MSE(pi2): 3.119e-05, MSE(pi3): 6.503e-04\n",
      "Epoch 90000, Train loss: 5.103e+02, Test loss: 1.594e+03, MSE(e): 4.173e-05, MSE(pi1): 2.805e-03, MSE(pi2): 3.175e-05, MSE(pi3): 6.484e-04\n",
      "Epoch 90100, Train loss: 5.063e+02, Test loss: 1.607e+03, MSE(e): 4.134e-05, MSE(pi1): 2.799e-03, MSE(pi2): 3.166e-05, MSE(pi3): 6.488e-04\n",
      "Epoch 90200, Train loss: 4.945e+02, Test loss: 1.636e+03, MSE(e): 4.017e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.117e-05, MSE(pi3): 6.509e-04\n",
      "Epoch 90300, Train loss: 4.907e+02, Test loss: 1.652e+03, MSE(e): 3.979e-05, MSE(pi1): 2.754e-03, MSE(pi2): 3.092e-05, MSE(pi3): 6.526e-04\n",
      "Epoch 90400, Train loss: 4.927e+02, Test loss: 1.616e+03, MSE(e): 3.998e-05, MSE(pi1): 2.762e-03, MSE(pi2): 3.086e-05, MSE(pi3): 6.520e-04\n",
      "Epoch 90500, Train loss: 5.078e+02, Test loss: 1.592e+03, MSE(e): 4.149e-05, MSE(pi1): 2.802e-03, MSE(pi2): 3.156e-05, MSE(pi3): 6.486e-04\n",
      "Epoch 90600, Train loss: 5.001e+02, Test loss: 1.615e+03, MSE(e): 4.072e-05, MSE(pi1): 2.786e-03, MSE(pi2): 3.134e-05, MSE(pi3): 6.498e-04\n",
      "Epoch 90700, Train loss: 4.895e+02, Test loss: 1.652e+03, MSE(e): 3.967e-05, MSE(pi1): 2.761e-03, MSE(pi2): 3.084e-05, MSE(pi3): 6.520e-04\n",
      "Epoch 90800, Train loss: 4.918e+02, Test loss: 1.612e+03, MSE(e): 3.990e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.076e-05, MSE(pi3): 6.516e-04\n",
      "Epoch 90900, Train loss: 5.093e+02, Test loss: 1.592e+03, MSE(e): 4.164e-05, MSE(pi1): 2.805e-03, MSE(pi2): 3.161e-05, MSE(pi3): 6.482e-04\n",
      "Epoch 91000, Train loss: 4.913e+02, Test loss: 1.637e+03, MSE(e): 3.984e-05, MSE(pi1): 2.778e-03, MSE(pi2): 3.091e-05, MSE(pi3): 6.504e-04\n",
      "Epoch 91100, Train loss: 4.895e+02, Test loss: 1.630e+03, MSE(e): 3.967e-05, MSE(pi1): 2.755e-03, MSE(pi2): 3.066e-05, MSE(pi3): 6.524e-04\n",
      "Epoch 91200, Train loss: 5.082e+02, Test loss: 1.590e+03, MSE(e): 4.153e-05, MSE(pi1): 2.807e-03, MSE(pi2): 3.150e-05, MSE(pi3): 6.480e-04\n",
      "Epoch 91300, Train loss: 4.898e+02, Test loss: 1.638e+03, MSE(e): 3.970e-05, MSE(pi1): 2.773e-03, MSE(pi2): 3.080e-05, MSE(pi3): 6.507e-04\n",
      "Epoch 91400, Train loss: 4.895e+02, Test loss: 1.616e+03, MSE(e): 3.967e-05, MSE(pi1): 2.766e-03, MSE(pi2): 3.058e-05, MSE(pi3): 6.515e-04\n",
      "Epoch 91500, Train loss: 5.052e+02, Test loss: 1.596e+03, MSE(e): 4.124e-05, MSE(pi1): 2.806e-03, MSE(pi2): 3.139e-05, MSE(pi3): 6.479e-04\n",
      "Epoch 91600, Train loss: 4.867e+02, Test loss: 1.651e+03, MSE(e): 3.939e-05, MSE(pi1): 2.759e-03, MSE(pi2): 3.057e-05, MSE(pi3): 6.520e-04\n",
      "Epoch 91700, Train loss: 5.010e+02, Test loss: 1.591e+03, MSE(e): 4.081e-05, MSE(pi1): 2.800e-03, MSE(pi2): 3.105e-05, MSE(pi3): 6.485e-04\n",
      "Epoch 91800, Train loss: 4.888e+02, Test loss: 1.634e+03, MSE(e): 3.960e-05, MSE(pi1): 2.771e-03, MSE(pi2): 3.069e-05, MSE(pi3): 6.508e-04\n",
      "Epoch 91900, Train loss: 4.898e+02, Test loss: 1.604e+03, MSE(e): 3.969e-05, MSE(pi1): 2.774e-03, MSE(pi2): 3.050e-05, MSE(pi3): 6.507e-04\n",
      "Epoch 92000, Train loss: 4.937e+02, Test loss: 1.615e+03, MSE(e): 4.008e-05, MSE(pi1): 2.789e-03, MSE(pi2): 3.086e-05, MSE(pi3): 6.493e-04\n",
      "Epoch 92100, Train loss: 4.871e+02, Test loss: 1.619e+03, MSE(e): 3.943e-05, MSE(pi1): 2.760e-03, MSE(pi2): 3.039e-05, MSE(pi3): 6.518e-04\n",
      "Epoch 92200, Train loss: 4.971e+02, Test loss: 1.606e+03, MSE(e): 4.043e-05, MSE(pi1): 2.790e-03, MSE(pi2): 3.097e-05, MSE(pi3): 6.491e-04\n",
      "Epoch 92300, Train loss: 4.862e+02, Test loss: 1.624e+03, MSE(e): 3.934e-05, MSE(pi1): 2.762e-03, MSE(pi2): 3.033e-05, MSE(pi3): 6.517e-04\n",
      "Epoch 92400, Train loss: 4.959e+02, Test loss: 1.606e+03, MSE(e): 4.031e-05, MSE(pi1): 2.791e-03, MSE(pi2): 3.090e-05, MSE(pi3): 6.489e-04\n",
      "Epoch 92500, Train loss: 4.859e+02, Test loss: 1.618e+03, MSE(e): 3.931e-05, MSE(pi1): 2.752e-03, MSE(pi2): 3.028e-05, MSE(pi3): 6.524e-04\n",
      "Epoch 92600, Train loss: 4.908e+02, Test loss: 1.616e+03, MSE(e): 3.980e-05, MSE(pi1): 2.780e-03, MSE(pi2): 3.066e-05, MSE(pi3): 6.499e-04\n",
      "Epoch 92700, Train loss: 4.891e+02, Test loss: 1.599e+03, MSE(e): 3.963e-05, MSE(pi1): 2.782e-03, MSE(pi2): 3.036e-05, MSE(pi3): 6.499e-04\n",
      "Epoch 92800, Train loss: 4.843e+02, Test loss: 1.640e+03, MSE(e): 3.915e-05, MSE(pi1): 2.770e-03, MSE(pi2): 3.035e-05, MSE(pi3): 6.507e-04\n",
      "Epoch 92900, Train loss: 5.032e+02, Test loss: 1.586e+03, MSE(e): 4.103e-05, MSE(pi1): 2.811e-03, MSE(pi2): 3.101e-05, MSE(pi3): 6.474e-04\n",
      "Epoch 93000, Train loss: 4.830e+02, Test loss: 1.647e+03, MSE(e): 3.902e-05, MSE(pi1): 2.753e-03, MSE(pi2): 3.018e-05, MSE(pi3): 6.521e-04\n",
      "Epoch 93100, Train loss: 4.961e+02, Test loss: 1.600e+03, MSE(e): 4.033e-05, MSE(pi1): 2.800e-03, MSE(pi2): 3.079e-05, MSE(pi3): 6.481e-04\n",
      "Epoch 93200, Train loss: 4.861e+02, Test loss: 1.603e+03, MSE(e): 3.933e-05, MSE(pi1): 2.773e-03, MSE(pi2): 3.017e-05, MSE(pi3): 6.505e-04\n",
      "Epoch 93300, Train loss: 4.822e+02, Test loss: 1.643e+03, MSE(e): 3.895e-05, MSE(pi1): 2.763e-03, MSE(pi2): 3.018e-05, MSE(pi3): 6.512e-04\n",
      "Epoch 93400, Train loss: 5.022e+02, Test loss: 1.588e+03, MSE(e): 4.094e-05, MSE(pi1): 2.803e-03, MSE(pi2): 3.097e-05, MSE(pi3): 6.479e-04\n",
      "Epoch 93500, Train loss: 4.835e+02, Test loss: 1.613e+03, MSE(e): 3.907e-05, MSE(pi1): 2.762e-03, MSE(pi2): 3.002e-05, MSE(pi3): 6.515e-04\n",
      "Epoch 93600, Train loss: 4.814e+02, Test loss: 1.643e+03, MSE(e): 3.886e-05, MSE(pi1): 2.764e-03, MSE(pi2): 3.011e-05, MSE(pi3): 6.510e-04\n",
      "Epoch 93700, Train loss: 4.980e+02, Test loss: 1.593e+03, MSE(e): 4.051e-05, MSE(pi1): 2.805e-03, MSE(pi2): 3.077e-05, MSE(pi3): 6.477e-04\n",
      "Epoch 93800, Train loss: 4.872e+02, Test loss: 1.597e+03, MSE(e): 3.944e-05, MSE(pi1): 2.786e-03, MSE(pi2): 3.013e-05, MSE(pi3): 6.492e-04\n",
      "Epoch 93900, Train loss: 4.803e+02, Test loss: 1.648e+03, MSE(e): 3.876e-05, MSE(pi1): 2.759e-03, MSE(pi2): 2.996e-05, MSE(pi3): 6.514e-04\n",
      "Epoch 94000, Train loss: 4.861e+02, Test loss: 1.616e+03, MSE(e): 3.933e-05, MSE(pi1): 2.783e-03, MSE(pi2): 3.027e-05, MSE(pi3): 6.493e-04\n",
      "Epoch 94100, Train loss: 5.016e+02, Test loss: 1.584e+03, MSE(e): 4.087e-05, MSE(pi1): 2.813e-03, MSE(pi2): 3.079e-05, MSE(pi3): 6.469e-04\n",
      "Epoch 94200, Train loss: 4.815e+02, Test loss: 1.612e+03, MSE(e): 3.887e-05, MSE(pi1): 2.764e-03, MSE(pi2): 2.985e-05, MSE(pi3): 6.510e-04\n",
      "Epoch 94300, Train loss: 4.789e+02, Test loss: 1.649e+03, MSE(e): 3.861e-05, MSE(pi1): 2.758e-03, MSE(pi2): 2.987e-05, MSE(pi3): 6.514e-04\n",
      "Epoch 94400, Train loss: 4.833e+02, Test loss: 1.620e+03, MSE(e): 3.906e-05, MSE(pi1): 2.777e-03, MSE(pi2): 3.010e-05, MSE(pi3): 6.498e-04\n",
      "Epoch 94500, Train loss: 4.983e+02, Test loss: 1.588e+03, MSE(e): 4.055e-05, MSE(pi1): 2.806e-03, MSE(pi2): 3.066e-05, MSE(pi3): 6.474e-04\n",
      "Epoch 94600, Train loss: 4.931e+02, Test loss: 1.589e+03, MSE(e): 4.003e-05, MSE(pi1): 2.794e-03, MSE(pi2): 3.031e-05, MSE(pi3): 6.484e-04\n",
      "Epoch 94700, Train loss: 4.802e+02, Test loss: 1.613e+03, MSE(e): 3.874e-05, MSE(pi1): 2.768e-03, MSE(pi2): 2.973e-05, MSE(pi3): 6.506e-04\n",
      "Epoch 94800, Train loss: 4.783e+02, Test loss: 1.644e+03, MSE(e): 3.855e-05, MSE(pi1): 2.755e-03, MSE(pi2): 2.973e-05, MSE(pi3): 6.517e-04\n",
      "Epoch 94900, Train loss: 4.776e+02, Test loss: 1.645e+03, MSE(e): 3.849e-05, MSE(pi1): 2.759e-03, MSE(pi2): 2.977e-05, MSE(pi3): 6.512e-04\n",
      "Epoch 95000, Train loss: 4.812e+02, Test loss: 1.621e+03, MSE(e): 3.885e-05, MSE(pi1): 2.776e-03, MSE(pi2): 2.994e-05, MSE(pi3): 6.498e-04\n",
      "Epoch 95100, Train loss: 4.913e+02, Test loss: 1.595e+03, MSE(e): 3.985e-05, MSE(pi1): 2.795e-03, MSE(pi2): 3.032e-05, MSE(pi3): 6.481e-04\n",
      "Epoch 95200, Train loss: 4.995e+02, Test loss: 1.583e+03, MSE(e): 4.067e-05, MSE(pi1): 2.813e-03, MSE(pi2): 3.058e-05, MSE(pi3): 6.466e-04\n",
      "Epoch 95300, Train loss: 4.903e+02, Test loss: 1.589e+03, MSE(e): 3.975e-05, MSE(pi1): 2.802e-03, MSE(pi2): 3.010e-05, MSE(pi3): 6.476e-04\n",
      "Epoch 95400, Train loss: 4.794e+02, Test loss: 1.605e+03, MSE(e): 3.867e-05, MSE(pi1): 2.767e-03, MSE(pi2): 2.960e-05, MSE(pi3): 6.505e-04\n",
      "Epoch 95500, Train loss: 4.772e+02, Test loss: 1.625e+03, MSE(e): 3.845e-05, MSE(pi1): 2.757e-03, MSE(pi2): 2.953e-05, MSE(pi3): 6.514e-04\n",
      "Epoch 95600, Train loss: 4.762e+02, Test loss: 1.640e+03, MSE(e): 3.835e-05, MSE(pi1): 2.751e-03, MSE(pi2): 2.952e-05, MSE(pi3): 6.519e-04\n",
      "Epoch 95700, Train loss: 4.756e+02, Test loss: 1.646e+03, MSE(e): 3.829e-05, MSE(pi1): 2.754e-03, MSE(pi2): 2.951e-05, MSE(pi3): 6.515e-04\n",
      "Epoch 95800, Train loss: 4.753e+02, Test loss: 1.647e+03, MSE(e): 3.826e-05, MSE(pi1): 2.757e-03, MSE(pi2): 2.950e-05, MSE(pi3): 6.514e-04\n",
      "Epoch 95900, Train loss: 4.752e+02, Test loss: 1.646e+03, MSE(e): 3.825e-05, MSE(pi1): 2.754e-03, MSE(pi2): 2.947e-05, MSE(pi3): 6.515e-04\n",
      "Epoch 96000, Train loss: 4.753e+02, Test loss: 1.643e+03, MSE(e): 3.826e-05, MSE(pi1): 2.751e-03, MSE(pi2): 2.945e-05, MSE(pi3): 6.518e-04\n",
      "Epoch 96100, Train loss: 4.755e+02, Test loss: 1.635e+03, MSE(e): 3.828e-05, MSE(pi1): 2.755e-03, MSE(pi2): 2.941e-05, MSE(pi3): 6.514e-04\n",
      "Epoch 96200, Train loss: 4.762e+02, Test loss: 1.617e+03, MSE(e): 3.835e-05, MSE(pi1): 2.758e-03, MSE(pi2): 2.937e-05, MSE(pi3): 6.511e-04\n",
      "Epoch 96300, Train loss: 4.830e+02, Test loss: 1.595e+03, MSE(e): 3.902e-05, MSE(pi1): 2.779e-03, MSE(pi2): 2.962e-05, MSE(pi3): 6.494e-04\n",
      "Epoch 96400, Train loss: 4.948e+02, Test loss: 1.584e+03, MSE(e): 4.020e-05, MSE(pi1): 2.783e-03, MSE(pi2): 3.023e-05, MSE(pi3): 6.491e-04\n",
      "Epoch 96500, Train loss: 4.726e+02, Test loss: 1.642e+03, MSE(e): 3.799e-05, MSE(pi1): 2.704e-03, MSE(pi2): 2.924e-05, MSE(pi3): 6.557e-04\n",
      "Epoch 96600, Train loss: 4.764e+02, Test loss: 1.600e+03, MSE(e): 3.838e-05, MSE(pi1): 2.655e-03, MSE(pi2): 2.922e-05, MSE(pi3): 6.601e-04\n",
      "Epoch 96700, Train loss: 4.649e+02, Test loss: 1.630e+03, MSE(e): 3.724e-05, MSE(pi1): 2.552e-03, MSE(pi2): 2.897e-05, MSE(pi3): 6.693e-04\n",
      "Epoch 96800, Train loss: 4.659e+02, Test loss: 1.604e+03, MSE(e): 3.734e-05, MSE(pi1): 2.556e-03, MSE(pi2): 2.892e-05, MSE(pi3): 6.689e-04\n",
      "Epoch 96900, Train loss: 4.753e+02, Test loss: 1.581e+03, MSE(e): 3.829e-05, MSE(pi1): 2.555e-03, MSE(pi2): 2.938e-05, MSE(pi3): 6.688e-04\n",
      "Epoch 97000, Train loss: 4.659e+02, Test loss: 1.620e+03, MSE(e): 3.735e-05, MSE(pi1): 2.543e-03, MSE(pi2): 2.881e-05, MSE(pi3): 6.700e-04\n",
      "Epoch 97100, Train loss: 4.677e+02, Test loss: 1.590e+03, MSE(e): 3.752e-05, MSE(pi1): 2.542e-03, MSE(pi2): 2.904e-05, MSE(pi3): 6.702e-04\n",
      "Epoch 97200, Train loss: 4.683e+02, Test loss: 1.618e+03, MSE(e): 3.759e-05, MSE(pi1): 2.538e-03, MSE(pi2): 2.882e-05, MSE(pi3): 6.704e-04\n",
      "Epoch 97300, Train loss: 4.873e+02, Test loss: 1.571e+03, MSE(e): 3.949e-05, MSE(pi1): 2.575e-03, MSE(pi2): 2.978e-05, MSE(pi3): 6.670e-04\n",
      "Epoch 97400, Train loss: 4.609e+02, Test loss: 1.623e+03, MSE(e): 3.685e-05, MSE(pi1): 2.524e-03, MSE(pi2): 2.870e-05, MSE(pi3): 6.716e-04\n",
      "Epoch 97500, Train loss: 4.857e+02, Test loss: 1.571e+03, MSE(e): 3.932e-05, MSE(pi1): 2.575e-03, MSE(pi2): 2.960e-05, MSE(pi3): 6.670e-04\n",
      "Epoch 97600, Train loss: 4.669e+02, Test loss: 1.572e+03, MSE(e): 3.745e-05, MSE(pi1): 2.538e-03, MSE(pi2): 2.891e-05, MSE(pi3): 6.701e-04\n",
      "Epoch 97700, Train loss: 4.606e+02, Test loss: 1.626e+03, MSE(e): 3.682e-05, MSE(pi1): 2.517e-03, MSE(pi2): 2.862e-05, MSE(pi3): 6.721e-04\n",
      "Epoch 97800, Train loss: 4.674e+02, Test loss: 1.576e+03, MSE(e): 3.750e-05, MSE(pi1): 2.554e-03, MSE(pi2): 2.885e-05, MSE(pi3): 6.686e-04\n",
      "Epoch 97900, Train loss: 4.739e+02, Test loss: 1.562e+03, MSE(e): 3.815e-05, MSE(pi1): 2.554e-03, MSE(pi2): 2.918e-05, MSE(pi3): 6.685e-04\n",
      "Epoch 98000, Train loss: 4.740e+02, Test loss: 1.566e+03, MSE(e): 3.816e-05, MSE(pi1): 2.563e-03, MSE(pi2): 2.917e-05, MSE(pi3): 6.677e-04\n",
      "Epoch 98100, Train loss: 4.714e+02, Test loss: 1.568e+03, MSE(e): 3.790e-05, MSE(pi1): 2.559e-03, MSE(pi2): 2.906e-05, MSE(pi3): 6.680e-04\n",
      "Epoch 98200, Train loss: 4.625e+02, Test loss: 1.629e+03, MSE(e): 3.701e-05, MSE(pi1): 2.535e-03, MSE(pi2): 2.854e-05, MSE(pi3): 6.702e-04\n",
      "Epoch 98300, Train loss: 4.805e+02, Test loss: 1.560e+03, MSE(e): 3.880e-05, MSE(pi1): 2.569e-03, MSE(pi2): 2.932e-05, MSE(pi3): 6.670e-04\n",
      "Epoch 98400, Train loss: 4.589e+02, Test loss: 1.591e+03, MSE(e): 3.665e-05, MSE(pi1): 2.528e-03, MSE(pi2): 2.850e-05, MSE(pi3): 6.708e-04\n",
      "Epoch 98500, Train loss: 4.595e+02, Test loss: 1.592e+03, MSE(e): 3.671e-05, MSE(pi1): 2.540e-03, MSE(pi2): 2.842e-05, MSE(pi3): 6.696e-04\n",
      "Epoch 98600, Train loss: 4.956e+02, Test loss: 1.555e+03, MSE(e): 4.031e-05, MSE(pi1): 2.575e-03, MSE(pi2): 3.006e-05, MSE(pi3): 6.664e-04\n",
      "Epoch 98700, Train loss: 4.825e+02, Test loss: 1.553e+03, MSE(e): 3.901e-05, MSE(pi1): 2.566e-03, MSE(pi2): 2.942e-05, MSE(pi3): 6.672e-04\n",
      "Epoch 98800, Train loss: 4.564e+02, Test loss: 1.612e+03, MSE(e): 3.640e-05, MSE(pi1): 2.523e-03, MSE(pi2): 2.836e-05, MSE(pi3): 6.712e-04\n",
      "Epoch 98900, Train loss: 4.602e+02, Test loss: 1.596e+03, MSE(e): 3.678e-05, MSE(pi1): 2.542e-03, MSE(pi2): 2.829e-05, MSE(pi3): 6.693e-04\n",
      "Epoch 99000, Train loss: 4.842e+02, Test loss: 1.558e+03, MSE(e): 3.918e-05, MSE(pi1): 2.568e-03, MSE(pi2): 2.945e-05, MSE(pi3): 6.669e-04\n",
      "Epoch 99100, Train loss: 4.559e+02, Test loss: 1.597e+03, MSE(e): 3.636e-05, MSE(pi1): 2.522e-03, MSE(pi2): 2.827e-05, MSE(pi3): 6.711e-04\n",
      "Epoch 99200, Train loss: 4.584e+02, Test loss: 1.619e+03, MSE(e): 3.660e-05, MSE(pi1): 2.526e-03, MSE(pi2): 2.823e-05, MSE(pi3): 6.707e-04\n",
      "Epoch 99300, Train loss: 4.887e+02, Test loss: 1.549e+03, MSE(e): 3.963e-05, MSE(pi1): 2.566e-03, MSE(pi2): 2.962e-05, MSE(pi3): 6.670e-04\n",
      "Epoch 99400, Train loss: 4.554e+02, Test loss: 1.588e+03, MSE(e): 3.631e-05, MSE(pi1): 2.526e-03, MSE(pi2): 2.820e-05, MSE(pi3): 6.706e-04\n",
      "Epoch 99500, Train loss: 4.573e+02, Test loss: 1.579e+03, MSE(e): 3.650e-05, MSE(pi1): 2.541e-03, MSE(pi2): 2.823e-05, MSE(pi3): 6.692e-04\n",
      "Epoch 99600, Train loss: 4.586e+02, Test loss: 1.572e+03, MSE(e): 3.663e-05, MSE(pi1): 2.543e-03, MSE(pi2): 2.822e-05, MSE(pi3): 6.690e-04\n",
      "Epoch 99700, Train loss: 4.607e+02, Test loss: 1.576e+03, MSE(e): 3.684e-05, MSE(pi1): 2.538e-03, MSE(pi2): 2.842e-05, MSE(pi3): 6.693e-04\n",
      "Epoch 99800, Train loss: 4.606e+02, Test loss: 1.566e+03, MSE(e): 3.682e-05, MSE(pi1): 2.538e-03, MSE(pi2): 2.837e-05, MSE(pi3): 6.693e-04\n",
      "Epoch 99900, Train loss: 4.646e+02, Test loss: 1.598e+03, MSE(e): 3.722e-05, MSE(pi1): 2.535e-03, MSE(pi2): 2.812e-05, MSE(pi3): 6.697e-04\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 9000\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 100\n",
    "\n",
    "second_lr = 1e-4\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
