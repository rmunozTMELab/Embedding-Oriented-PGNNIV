{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from models.baseline import BaselineNonlinearModel\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from vecopsciml.operators.zero_order import Mx, My"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear/baseline_model\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/non_linear/non_linear_1000.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/non_linear')\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/non_linear/baseline_model')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear/non_linear_1000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data splitting in train/test\n",
    "X = torch.tensor(dataset['X_train'], dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(dataset['y_train'], dtype=torch.float32).unsqueeze(1)\n",
    "K = torch.tensor(dataset['k_train'], dtype=torch.float32).unsqueeze(1)\n",
    "f = torch.tensor(dataset['f_train'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X, y, K, f, test_size=0.3, random_state=42)\n",
    "\n",
    "# Data processing and adequacy with our TensOps library\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "# Loading and processing validation data\n",
    "X_val = torch.tensor(dataset['X_val'], dtype=torch.float32).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, 5, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 8.467e+08, Test loss: 1.108e+09, MSE(e): 5.296e+01, MSE(pi1): 2.566e+04, MSE(pi2): 1.880e+01, MSE(pi3): 6.049e+02\n",
      "Epoch 100, Train loss: 4.130e+06, Test loss: 4.776e+06, MSE(e): 4.085e-01, MSE(pi1): 2.505e+00, MSE(pi2): 2.855e-01, MSE(pi3): 1.983e-01\n",
      "Epoch 200, Train loss: 3.909e+06, Test loss: 4.347e+06, MSE(e): 3.888e-01, MSE(pi1): 7.409e-01, MSE(pi2): 2.792e-01, MSE(pi3): 1.328e-01\n",
      "Epoch 300, Train loss: 3.958e+06, Test loss: 4.323e+06, MSE(e): 3.940e-01, MSE(pi1): 6.016e-01, MSE(pi2): 2.815e-01, MSE(pi3): 1.212e-01\n",
      "Epoch 400, Train loss: 2.757e+06, Test loss: 2.836e+06, MSE(e): 2.737e-01, MSE(pi1): 9.157e-01, MSE(pi2): 1.847e-01, MSE(pi3): 1.096e-01\n",
      "Epoch 500, Train loss: 2.609e+06, Test loss: 2.530e+06, MSE(e): 2.595e-01, MSE(pi1): 3.826e-01, MSE(pi2): 1.840e-01, MSE(pi3): 9.294e-02\n",
      "Epoch 600, Train loss: 1.084e+05, Test loss: 1.672e+05, MSE(e): 9.799e-03, MSE(pi1): 4.122e-01, MSE(pi2): 6.419e-03, MSE(pi3): 6.230e-02\n",
      "Epoch 700, Train loss: 4.394e+04, Test loss: 8.083e+04, MSE(e): 3.688e-03, MSE(pi1): 2.052e-01, MSE(pi2): 2.909e-03, MSE(pi3): 4.996e-02\n",
      "Epoch 800, Train loss: 3.910e+04, Test loss: 7.630e+04, MSE(e): 3.215e-03, MSE(pi1): 2.904e-01, MSE(pi2): 2.273e-03, MSE(pi3): 4.043e-02\n",
      "Epoch 900, Train loss: 3.149e+04, Test loss: 5.754e+04, MSE(e): 2.621e-03, MSE(pi1): 1.796e-01, MSE(pi2): 2.049e-03, MSE(pi3): 3.480e-02\n",
      "Epoch 1000, Train loss: 3.328e+04, Test loss: 5.517e+04, MSE(e): 2.608e-03, MSE(pi1): 3.969e-01, MSE(pi2): 2.019e-03, MSE(pi3): 3.222e-02\n",
      "Epoch 1100, Train loss: 8.838e+04, Test loss: 1.547e+05, MSE(e): 5.881e-03, MSE(pi1): 1.528e+00, MSE(pi2): 3.941e-03, MSE(pi3): 1.429e-01\n",
      "Epoch 1200, Train loss: 4.282e+04, Test loss: 9.856e+04, MSE(e): 3.186e-03, MSE(pi1): 2.762e-01, MSE(pi2): 2.347e-03, MSE(pi3): 8.200e-02\n",
      "Epoch 1300, Train loss: 5.750e+04, Test loss: 6.249e+04, MSE(e): 4.890e-03, MSE(pi1): 1.857e-01, MSE(pi2): 2.743e-03, MSE(pi3): 6.735e-02\n",
      "Epoch 1400, Train loss: 7.296e+04, Test loss: 7.736e+04, MSE(e): 6.553e-03, MSE(pi1): 1.584e-01, MSE(pi2): 3.235e-03, MSE(pi3): 5.843e-02\n",
      "Epoch 1500, Train loss: 2.996e+04, Test loss: 4.492e+04, MSE(e): 2.370e-03, MSE(pi1): 1.361e-01, MSE(pi2): 1.459e-03, MSE(pi3): 4.896e-02\n",
      "Epoch 1600, Train loss: 2.167e+04, Test loss: 3.396e+04, MSE(e): 1.663e-03, MSE(pi1): 1.229e-01, MSE(pi2): 9.233e-04, MSE(pi3): 3.815e-02\n",
      "Epoch 1700, Train loss: 1.351e+04, Test loss: 3.052e+04, MSE(e): 9.631e-04, MSE(pi1): 1.206e-01, MSE(pi2): 6.099e-04, MSE(pi3): 2.677e-02\n",
      "Epoch 1800, Train loss: 5.517e+04, Test loss: 3.411e+04, MSE(e): 5.119e-03, MSE(pi1): 1.540e-01, MSE(pi2): 2.724e-03, MSE(pi3): 2.434e-02\n",
      "Epoch 1900, Train loss: 1.532e+04, Test loss: 3.129e+04, MSE(e): 1.150e-03, MSE(pi1): 1.540e-01, MSE(pi2): 6.335e-04, MSE(pi3): 2.276e-02\n",
      "Epoch 2000, Train loss: 3.234e+04, Test loss: 2.228e+04, MSE(e): 2.960e-03, MSE(pi1): 8.398e-02, MSE(pi2): 1.519e-03, MSE(pi3): 1.903e-02\n",
      "Epoch 2100, Train loss: 2.549e+04, Test loss: 3.875e+04, MSE(e): 2.282e-03, MSE(pi1): 7.557e-02, MSE(pi2): 1.548e-03, MSE(pi3): 1.909e-02\n",
      "Epoch 2200, Train loss: 1.474e+04, Test loss: 2.238e+04, MSE(e): 9.707e-04, MSE(pi1): 2.909e-01, MSE(pi2): 4.999e-04, MSE(pi3): 2.122e-02\n",
      "Epoch 2300, Train loss: 1.776e+04, Test loss: 3.797e+04, MSE(e): 1.503e-03, MSE(pi1): 1.223e-01, MSE(pi2): 1.004e-03, MSE(pi3): 1.508e-02\n",
      "Epoch 2400, Train loss: 1.127e+04, Test loss: 2.559e+04, MSE(e): 8.071e-04, MSE(pi1): 1.480e-01, MSE(pi2): 4.696e-04, MSE(pi3): 1.722e-02\n",
      "Epoch 2500, Train loss: 1.428e+04, Test loss: 3.947e+04, MSE(e): 1.170e-03, MSE(pi1): 1.230e-01, MSE(pi2): 7.309e-04, MSE(pi3): 1.349e-02\n",
      "Epoch 2600, Train loss: 1.578e+04, Test loss: 2.975e+04, MSE(e): 1.352e-03, MSE(pi1): 1.204e-01, MSE(pi2): 7.833e-04, MSE(pi3): 1.051e-02\n",
      "Epoch 2700, Train loss: 9.750e+03, Test loss: 2.502e+04, MSE(e): 7.917e-04, MSE(pi1): 1.005e-01, MSE(pi2): 4.459e-04, MSE(pi3): 8.271e-03\n",
      "Epoch 2800, Train loss: 9.995e+03, Test loss: 2.659e+04, MSE(e): 7.706e-04, MSE(pi1): 1.199e-01, MSE(pi2): 4.344e-04, MSE(pi3): 1.090e-02\n",
      "Epoch 2900, Train loss: 9.526e+03, Test loss: 1.993e+04, MSE(e): 5.975e-04, MSE(pi1): 2.795e-01, MSE(pi2): 3.406e-04, MSE(pi3): 7.559e-03\n",
      "Epoch 3000, Train loss: 1.400e+04, Test loss: 2.127e+04, MSE(e): 9.486e-04, MSE(pi1): 3.632e-01, MSE(pi2): 4.685e-04, MSE(pi3): 8.866e-03\n",
      "Epoch 3100, Train loss: 1.293e+04, Test loss: 2.703e+04, MSE(e): 1.061e-03, MSE(pi1): 1.190e-01, MSE(pi2): 6.347e-04, MSE(pi3): 1.124e-02\n",
      "Epoch 3200, Train loss: 1.502e+04, Test loss: 2.317e+04, MSE(e): 1.097e-03, MSE(pi1): 3.032e-01, MSE(pi2): 5.609e-04, MSE(pi3): 1.022e-02\n",
      "Epoch 3300, Train loss: 9.525e+03, Test loss: 2.600e+04, MSE(e): 7.298e-04, MSE(pi1): 1.010e-01, MSE(pi2): 3.892e-04, MSE(pi3): 1.216e-02\n",
      "Epoch 3400, Train loss: 1.396e+04, Test loss: 3.628e+04, MSE(e): 7.191e-04, MSE(pi1): 1.964e-01, MSE(pi2): 4.371e-04, MSE(pi3): 4.802e-02\n",
      "Epoch 3500, Train loss: 8.116e+03, Test loss: 2.579e+04, MSE(e): 4.405e-04, MSE(pi1): 8.002e-02, MSE(pi2): 3.274e-04, MSE(pi3): 2.911e-02\n",
      "Epoch 3600, Train loss: 1.280e+04, Test loss: 2.904e+04, MSE(e): 1.056e-03, MSE(pi1): 5.076e-02, MSE(pi2): 7.180e-04, MSE(pi3): 1.733e-02\n",
      "Epoch 3700, Train loss: 1.226e+04, Test loss: 2.316e+04, MSE(e): 1.012e-03, MSE(pi1): 8.143e-02, MSE(pi2): 7.380e-04, MSE(pi3): 1.325e-02\n",
      "Epoch 3800, Train loss: 9.651e+03, Test loss: 2.072e+04, MSE(e): 6.995e-04, MSE(pi1): 1.672e-01, MSE(pi2): 3.796e-04, MSE(pi3): 9.840e-03\n",
      "Epoch 3900, Train loss: 6.825e+03, Test loss: 2.022e+04, MSE(e): 5.261e-04, MSE(pi1): 6.433e-02, MSE(pi2): 3.099e-04, MSE(pi3): 9.207e-03\n",
      "Epoch 4000, Train loss: 9.140e+03, Test loss: 1.948e+04, MSE(e): 5.943e-04, MSE(pi1): 2.418e-01, MSE(pi2): 3.621e-04, MSE(pi3): 7.788e-03\n",
      "Epoch 4100, Train loss: 1.664e+04, Test loss: 2.295e+04, MSE(e): 1.342e-03, MSE(pi1): 2.334e-01, MSE(pi2): 6.016e-04, MSE(pi3): 8.881e-03\n",
      "Epoch 4200, Train loss: 5.964e+03, Test loss: 2.565e+04, MSE(e): 3.594e-04, MSE(pi1): 1.459e-01, MSE(pi2): 2.052e-04, MSE(pi3): 9.110e-03\n",
      "Epoch 4300, Train loss: 8.053e+03, Test loss: 2.331e+04, MSE(e): 5.952e-04, MSE(pi1): 1.347e-01, MSE(pi2): 3.584e-04, MSE(pi3): 7.534e-03\n",
      "Epoch 4400, Train loss: 5.561e+03, Test loss: 2.394e+04, MSE(e): 3.608e-04, MSE(pi1): 1.021e-01, MSE(pi2): 2.037e-04, MSE(pi3): 9.315e-03\n",
      "Epoch 4500, Train loss: 3.682e+04, Test loss: 3.904e+04, MSE(e): 3.468e-03, MSE(pi1): 1.607e-01, MSE(pi2): 1.679e-03, MSE(pi3): 5.315e-03\n",
      "Epoch 4600, Train loss: 4.691e+03, Test loss: 1.884e+04, MSE(e): 3.079e-04, MSE(pi1): 1.027e-01, MSE(pi2): 1.836e-04, MSE(pi3): 5.846e-03\n",
      "Epoch 4700, Train loss: 4.602e+03, Test loss: 1.762e+04, MSE(e): 3.011e-04, MSE(pi1): 1.175e-01, MSE(pi2): 1.760e-04, MSE(pi3): 4.156e-03\n",
      "Epoch 4800, Train loss: 1.675e+04, Test loss: 2.210e+04, MSE(e): 1.286e-03, MSE(pi1): 3.027e-01, MSE(pi2): 6.850e-04, MSE(pi3): 8.649e-03\n",
      "Epoch 4900, Train loss: 1.541e+04, Test loss: 3.247e+04, MSE(e): 1.378e-03, MSE(pi1): 1.095e-01, MSE(pi2): 9.324e-04, MSE(pi3): 5.306e-03\n",
      "Epoch 5000, Train loss: 6.572e+03, Test loss: 2.309e+04, MSE(e): 5.128e-04, MSE(pi1): 5.664e-02, MSE(pi2): 3.697e-04, MSE(pi3): 8.773e-03\n",
      "Epoch 5100, Train loss: 9.915e+03, Test loss: 2.407e+04, MSE(e): 8.280e-04, MSE(pi1): 5.034e-02, MSE(pi2): 4.633e-04, MSE(pi3): 1.131e-02\n",
      "Epoch 5200, Train loss: 8.372e+03, Test loss: 2.009e+04, MSE(e): 4.949e-04, MSE(pi1): 2.663e-01, MSE(pi2): 3.251e-04, MSE(pi3): 7.589e-03\n",
      "Epoch 5300, Train loss: 9.607e+03, Test loss: 3.310e+04, MSE(e): 7.154e-04, MSE(pi1): 1.985e-01, MSE(pi2): 3.981e-04, MSE(pi3): 4.675e-03\n",
      "Epoch 5400, Train loss: 8.733e+03, Test loss: 2.310e+04, MSE(e): 5.454e-04, MSE(pi1): 2.902e-01, MSE(pi2): 3.169e-04, MSE(pi3): 3.769e-03\n",
      "Epoch 5500, Train loss: 6.643e+03, Test loss: 2.190e+04, MSE(e): 4.285e-04, MSE(pi1): 1.876e-01, MSE(pi2): 2.404e-04, MSE(pi3): 4.828e-03\n",
      "Epoch 5600, Train loss: 5.637e+03, Test loss: 2.579e+04, MSE(e): 3.702e-04, MSE(pi1): 1.241e-01, MSE(pi2): 2.215e-04, MSE(pi3): 6.936e-03\n",
      "Epoch 5700, Train loss: 5.324e+03, Test loss: 3.305e+04, MSE(e): 4.347e-04, MSE(pi1): 5.596e-02, MSE(pi2): 2.401e-04, MSE(pi3): 4.175e-03\n",
      "Epoch 5800, Train loss: 9.169e+03, Test loss: 3.079e+04, MSE(e): 8.285e-04, MSE(pi1): 5.953e-02, MSE(pi2): 5.566e-04, MSE(pi3): 2.876e-03\n",
      "Epoch 5900, Train loss: 6.864e+03, Test loss: 2.495e+04, MSE(e): 3.828e-04, MSE(pi1): 8.636e-02, MSE(pi2): 2.604e-04, MSE(pi3): 2.172e-02\n",
      "Epoch 6000, Train loss: 7.139e+03, Test loss: 2.097e+04, MSE(e): 5.473e-04, MSE(pi1): 4.204e-02, MSE(pi2): 3.255e-04, MSE(pi3): 1.245e-02\n",
      "Epoch 6100, Train loss: 1.090e+04, Test loss: 2.395e+04, MSE(e): 9.621e-04, MSE(pi1): 5.129e-02, MSE(pi2): 6.234e-04, MSE(pi3): 7.618e-03\n",
      "Epoch 6200, Train loss: 4.109e+03, Test loss: 1.917e+04, MSE(e): 3.006e-04, MSE(pi1): 4.552e-02, MSE(pi2): 2.006e-04, MSE(pi3): 6.474e-03\n",
      "Epoch 6300, Train loss: 6.343e+03, Test loss: 2.229e+04, MSE(e): 5.329e-04, MSE(pi1): 5.348e-02, MSE(pi2): 3.070e-04, MSE(pi3): 4.793e-03\n",
      "Epoch 6400, Train loss: 9.629e+03, Test loss: 2.690e+04, MSE(e): 8.897e-04, MSE(pi1): 2.769e-02, MSE(pi2): 5.313e-04, MSE(pi3): 4.536e-03\n",
      "Epoch 6500, Train loss: 1.255e+04, Test loss: 5.002e+04, MSE(e): 1.034e-03, MSE(pi1): 1.593e-01, MSE(pi2): 5.822e-04, MSE(pi3): 6.198e-03\n",
      "Epoch 6600, Train loss: 5.855e+03, Test loss: 1.727e+04, MSE(e): 4.377e-04, MSE(pi1): 1.127e-01, MSE(pi2): 2.281e-04, MSE(pi3): 3.514e-03\n",
      "Epoch 6700, Train loss: 5.238e+03, Test loss: 2.005e+04, MSE(e): 4.160e-04, MSE(pi1): 5.879e-02, MSE(pi2): 2.801e-04, MSE(pi3): 4.898e-03\n",
      "Epoch 6800, Train loss: 3.872e+03, Test loss: 2.159e+04, MSE(e): 2.660e-04, MSE(pi1): 7.605e-02, MSE(pi2): 1.570e-04, MSE(pi3): 4.515e-03\n",
      "Epoch 6900, Train loss: 5.283e+03, Test loss: 2.559e+04, MSE(e): 3.087e-04, MSE(pi1): 1.501e-01, MSE(pi2): 2.018e-04, MSE(pi3): 6.952e-03\n",
      "Epoch 7000, Train loss: 4.446e+03, Test loss: 1.832e+04, MSE(e): 2.701e-04, MSE(pi1): 1.338e-01, MSE(pi2): 1.684e-04, MSE(pi3): 4.073e-03\n",
      "Epoch 7100, Train loss: 6.261e+03, Test loss: 2.549e+04, MSE(e): 3.860e-04, MSE(pi1): 1.901e-01, MSE(pi2): 2.612e-04, MSE(pi3): 5.003e-03\n",
      "Epoch 7200, Train loss: 5.509e+03, Test loss: 2.026e+04, MSE(e): 4.614e-04, MSE(pi1): 5.555e-02, MSE(pi2): 2.279e-04, MSE(pi3): 3.390e-03\n",
      "Epoch 7300, Train loss: 4.656e+03, Test loss: 2.139e+04, MSE(e): 2.845e-04, MSE(pi1): 1.493e-01, MSE(pi2): 1.555e-04, MSE(pi3): 3.183e-03\n",
      "Epoch 7400, Train loss: 8.851e+03, Test loss: 2.328e+04, MSE(e): 7.372e-04, MSE(pi1): 8.873e-02, MSE(pi2): 4.564e-04, MSE(pi3): 5.908e-03\n",
      "Epoch 7500, Train loss: 1.502e+04, Test loss: 2.708e+04, MSE(e): 1.353e-03, MSE(pi1): 1.031e-01, MSE(pi2): 8.375e-04, MSE(pi3): 4.627e-03\n",
      "Epoch 7600, Train loss: 4.480e+03, Test loss: 2.065e+04, MSE(e): 3.320e-04, MSE(pi1): 9.159e-02, MSE(pi2): 2.293e-04, MSE(pi3): 2.431e-03\n",
      "Epoch 7700, Train loss: 7.254e+03, Test loss: 2.932e+04, MSE(e): 6.184e-04, MSE(pi1): 8.370e-02, MSE(pi2): 3.080e-04, MSE(pi3): 2.320e-03\n",
      "Epoch 7800, Train loss: 5.867e+03, Test loss: 2.706e+04, MSE(e): 4.163e-04, MSE(pi1): 4.048e-02, MSE(pi2): 2.364e-04, MSE(pi3): 1.299e-02\n",
      "Epoch 7900, Train loss: 8.972e+03, Test loss: 2.502e+04, MSE(e): 8.106e-04, MSE(pi1): 4.162e-02, MSE(pi2): 5.265e-04, MSE(pi3): 4.487e-03\n",
      "Epoch 8000, Train loss: 6.109e+03, Test loss: 2.928e+04, MSE(e): 5.312e-04, MSE(pi1): 4.727e-02, MSE(pi2): 3.172e-04, MSE(pi3): 3.238e-03\n",
      "Epoch 8100, Train loss: 4.143e+03, Test loss: 2.343e+04, MSE(e): 3.099e-04, MSE(pi1): 6.113e-02, MSE(pi2): 1.662e-04, MSE(pi3): 4.329e-03\n",
      "Epoch 8200, Train loss: 4.887e+03, Test loss: 2.374e+04, MSE(e): 3.871e-04, MSE(pi1): 7.236e-02, MSE(pi2): 2.313e-04, MSE(pi3): 2.926e-03\n",
      "Epoch 8300, Train loss: 3.131e+03, Test loss: 2.417e+04, MSE(e): 2.627e-04, MSE(pi1): 2.202e-02, MSE(pi2): 1.375e-04, MSE(pi3): 2.842e-03\n",
      "Epoch 8400, Train loss: 5.149e+03, Test loss: 2.566e+04, MSE(e): 4.546e-04, MSE(pi1): 2.471e-02, MSE(pi2): 2.864e-04, MSE(pi3): 3.551e-03\n",
      "Epoch 8500, Train loss: 8.580e+03, Test loss: 3.090e+04, MSE(e): 6.264e-04, MSE(pi1): 1.823e-01, MSE(pi2): 3.810e-04, MSE(pi3): 4.932e-03\n",
      "Epoch 8600, Train loss: 6.601e+03, Test loss: 2.293e+04, MSE(e): 5.658e-04, MSE(pi1): 5.829e-02, MSE(pi2): 2.949e-04, MSE(pi3): 3.593e-03\n",
      "Epoch 8700, Train loss: 6.370e+03, Test loss: 2.498e+04, MSE(e): 4.985e-04, MSE(pi1): 1.003e-01, MSE(pi2): 2.601e-04, MSE(pi3): 3.811e-03\n",
      "Epoch 8800, Train loss: 6.297e+03, Test loss: 2.574e+04, MSE(e): 5.517e-04, MSE(pi1): 4.832e-02, MSE(pi2): 2.675e-04, MSE(pi3): 2.963e-03\n",
      "Epoch 8900, Train loss: 1.151e+04, Test loss: 3.257e+04, MSE(e): 1.016e-03, MSE(pi1): 9.249e-02, MSE(pi2): 5.756e-04, MSE(pi3): 4.252e-03\n",
      "Epoch 9000, Train loss: 6.617e+03, Test loss: 2.146e+04, MSE(e): 6.071e-04, MSE(pi1): 3.024e-02, MSE(pi2): 3.326e-04, MSE(pi3): 2.431e-03\n",
      "Epoch 9100, Train loss: 4.072e+04, Test loss: 2.940e+04, MSE(e): 3.946e-03, MSE(pi1): 1.025e-01, MSE(pi2): 1.604e-03, MSE(pi3): 2.340e-03\n",
      "Epoch 9200, Train loss: 4.300e+03, Test loss: 2.842e+04, MSE(e): 3.649e-04, MSE(pi1): 3.794e-02, MSE(pi2): 1.858e-04, MSE(pi3): 2.716e-03\n",
      "Epoch 9300, Train loss: 3.738e+03, Test loss: 2.940e+04, MSE(e): 3.240e-04, MSE(pi1): 2.032e-02, MSE(pi2): 1.766e-04, MSE(pi3): 2.942e-03\n",
      "Epoch 9400, Train loss: 2.430e+03, Test loss: 1.956e+04, MSE(e): 1.669e-04, MSE(pi1): 5.211e-02, MSE(pi2): 1.060e-04, MSE(pi3): 2.403e-03\n",
      "Epoch 9500, Train loss: 2.204e+06, Test loss: 2.235e+07, MSE(e): 8.333e-02, MSE(pi1): 1.336e+02, MSE(pi2): 1.883e-02, MSE(pi3): 3.503e-01\n",
      "Epoch 9600, Train loss: 2.908e+03, Test loss: 2.140e+04, MSE(e): 1.396e-04, MSE(pi1): 3.293e-02, MSE(pi2): 8.323e-05, MSE(pi3): 1.183e-02\n",
      "Epoch 9700, Train loss: 3.570e+03, Test loss: 2.292e+04, MSE(e): 2.683e-04, MSE(pi1): 2.022e-02, MSE(pi2): 1.530e-04, MSE(pi3): 6.840e-03\n",
      "Epoch 9800, Train loss: 3.389e+04, Test loss: 3.232e+04, MSE(e): 3.295e-03, MSE(pi1): 2.348e-02, MSE(pi2): 1.423e-03, MSE(pi3): 7.117e-03\n",
      "Epoch 9900, Train loss: 1.390e+04, Test loss: 5.896e+04, MSE(e): 1.331e-03, MSE(pi1): 1.365e-02, MSE(pi2): 8.413e-04, MSE(pi3): 4.543e-03\n",
      "\n",
      "Training process finished after 10000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = BaselineNonlinearModel(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 10000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 9000.\n",
      "Epoch 9000, Train loss: 2.623e+03, Test loss: 2.016e+04, MSE(e): 2.231e-04, MSE(pi1): 1.143e-02, MSE(pi2): 1.298e-04, MSE(pi3): 2.770e-03\n",
      "Epoch 9100, Train loss: 1.753e+03, Test loss: 1.870e+04, MSE(e): 1.426e-04, MSE(pi1): 7.449e-03, MSE(pi2): 7.777e-05, MSE(pi3): 2.529e-03\n",
      "Epoch 9200, Train loss: 1.616e+03, Test loss: 1.819e+04, MSE(e): 1.301e-04, MSE(pi1): 7.452e-03, MSE(pi2): 7.318e-05, MSE(pi3): 2.406e-03\n",
      "Epoch 9300, Train loss: 1.520e+03, Test loss: 1.784e+04, MSE(e): 1.216e-04, MSE(pi1): 7.388e-03, MSE(pi2): 6.988e-05, MSE(pi3): 2.306e-03\n",
      "Epoch 9400, Train loss: 1.437e+03, Test loss: 1.757e+04, MSE(e): 1.143e-04, MSE(pi1): 7.260e-03, MSE(pi2): 6.693e-05, MSE(pi3): 2.214e-03\n",
      "Epoch 9500, Train loss: 1.366e+03, Test loss: 1.738e+04, MSE(e): 1.082e-04, MSE(pi1): 7.124e-03, MSE(pi2): 6.435e-05, MSE(pi3): 2.129e-03\n",
      "Epoch 9600, Train loss: 1.306e+03, Test loss: 1.725e+04, MSE(e): 1.031e-04, MSE(pi1): 7.007e-03, MSE(pi2): 6.209e-05, MSE(pi3): 2.054e-03\n",
      "Epoch 9700, Train loss: 1.254e+03, Test loss: 1.716e+04, MSE(e): 9.853e-05, MSE(pi1): 6.880e-03, MSE(pi2): 6.004e-05, MSE(pi3): 1.994e-03\n",
      "Epoch 9800, Train loss: 1.207e+03, Test loss: 1.710e+04, MSE(e): 9.450e-05, MSE(pi1): 6.731e-03, MSE(pi2): 5.820e-05, MSE(pi3): 1.947e-03\n",
      "Epoch 9900, Train loss: 1.167e+03, Test loss: 1.706e+04, MSE(e): 9.104e-05, MSE(pi1): 6.584e-03, MSE(pi2): 5.661e-05, MSE(pi3): 1.908e-03\n",
      "Epoch 10000, Train loss: 1.133e+03, Test loss: 1.703e+04, MSE(e): 8.806e-05, MSE(pi1): 6.441e-03, MSE(pi2): 5.524e-05, MSE(pi3): 1.875e-03\n",
      "Epoch 10100, Train loss: 1.103e+03, Test loss: 1.701e+04, MSE(e): 8.550e-05, MSE(pi1): 6.307e-03, MSE(pi2): 5.405e-05, MSE(pi3): 1.846e-03\n",
      "Epoch 10200, Train loss: 1.076e+03, Test loss: 1.700e+04, MSE(e): 8.324e-05, MSE(pi1): 6.185e-03, MSE(pi2): 5.301e-05, MSE(pi3): 1.821e-03\n",
      "Epoch 10300, Train loss: 1.053e+03, Test loss: 1.699e+04, MSE(e): 8.125e-05, MSE(pi1): 6.068e-03, MSE(pi2): 5.208e-05, MSE(pi3): 1.798e-03\n",
      "Epoch 10400, Train loss: 1.032e+03, Test loss: 1.697e+04, MSE(e): 7.946e-05, MSE(pi1): 5.951e-03, MSE(pi2): 5.124e-05, MSE(pi3): 1.779e-03\n",
      "Epoch 10500, Train loss: 1.013e+03, Test loss: 1.696e+04, MSE(e): 7.783e-05, MSE(pi1): 5.842e-03, MSE(pi2): 5.049e-05, MSE(pi3): 1.761e-03\n",
      "Epoch 10600, Train loss: 9.952e+02, Test loss: 1.694e+04, MSE(e): 7.633e-05, MSE(pi1): 5.745e-03, MSE(pi2): 4.979e-05, MSE(pi3): 1.743e-03\n",
      "Epoch 10700, Train loss: 9.787e+02, Test loss: 1.692e+04, MSE(e): 7.495e-05, MSE(pi1): 5.654e-03, MSE(pi2): 4.914e-05, MSE(pi3): 1.726e-03\n",
      "Epoch 10800, Train loss: 9.634e+02, Test loss: 1.690e+04, MSE(e): 7.367e-05, MSE(pi1): 5.566e-03, MSE(pi2): 4.854e-05, MSE(pi3): 1.710e-03\n",
      "Epoch 10900, Train loss: 9.490e+02, Test loss: 1.688e+04, MSE(e): 7.246e-05, MSE(pi1): 5.482e-03, MSE(pi2): 4.798e-05, MSE(pi3): 1.695e-03\n",
      "Epoch 11000, Train loss: 9.354e+02, Test loss: 1.686e+04, MSE(e): 7.133e-05, MSE(pi1): 5.399e-03, MSE(pi2): 4.745e-05, MSE(pi3): 1.680e-03\n",
      "Epoch 11100, Train loss: 9.225e+02, Test loss: 1.683e+04, MSE(e): 7.024e-05, MSE(pi1): 5.331e-03, MSE(pi2): 4.694e-05, MSE(pi3): 1.667e-03\n",
      "Epoch 11200, Train loss: 9.101e+02, Test loss: 1.681e+04, MSE(e): 6.918e-05, MSE(pi1): 5.285e-03, MSE(pi2): 4.645e-05, MSE(pi3): 1.654e-03\n",
      "Epoch 11300, Train loss: 8.982e+02, Test loss: 1.678e+04, MSE(e): 6.816e-05, MSE(pi1): 5.233e-03, MSE(pi2): 4.599e-05, MSE(pi3): 1.642e-03\n",
      "Epoch 11400, Train loss: 8.872e+02, Test loss: 1.675e+04, MSE(e): 6.731e-05, MSE(pi1): 5.114e-03, MSE(pi2): 4.558e-05, MSE(pi3): 1.629e-03\n",
      "Epoch 11500, Train loss: 8.768e+02, Test loss: 1.672e+04, MSE(e): 6.643e-05, MSE(pi1): 5.066e-03, MSE(pi2): 4.516e-05, MSE(pi3): 1.617e-03\n",
      "Epoch 11600, Train loss: 8.664e+02, Test loss: 1.668e+04, MSE(e): 6.555e-05, MSE(pi1): 5.034e-03, MSE(pi2): 4.474e-05, MSE(pi3): 1.605e-03\n",
      "Epoch 11700, Train loss: 8.564e+02, Test loss: 1.665e+04, MSE(e): 6.470e-05, MSE(pi1): 5.002e-03, MSE(pi2): 4.434e-05, MSE(pi3): 1.593e-03\n",
      "Epoch 11800, Train loss: 8.468e+02, Test loss: 1.661e+04, MSE(e): 6.392e-05, MSE(pi1): 4.927e-03, MSE(pi2): 4.397e-05, MSE(pi3): 1.582e-03\n",
      "Epoch 11900, Train loss: 8.379e+02, Test loss: 1.657e+04, MSE(e): 6.322e-05, MSE(pi1): 4.863e-03, MSE(pi2): 4.360e-05, MSE(pi3): 1.570e-03\n",
      "Epoch 12000, Train loss: 8.291e+02, Test loss: 1.653e+04, MSE(e): 6.247e-05, MSE(pi1): 4.839e-03, MSE(pi2): 4.323e-05, MSE(pi3): 1.559e-03\n",
      "Epoch 12100, Train loss: 8.203e+02, Test loss: 1.649e+04, MSE(e): 6.173e-05, MSE(pi1): 4.812e-03, MSE(pi2): 4.287e-05, MSE(pi3): 1.548e-03\n",
      "Epoch 12200, Train loss: 8.121e+02, Test loss: 1.645e+04, MSE(e): 6.108e-05, MSE(pi1): 4.728e-03, MSE(pi2): 4.255e-05, MSE(pi3): 1.540e-03\n",
      "Epoch 12300, Train loss: 8.043e+02, Test loss: 1.640e+04, MSE(e): 6.042e-05, MSE(pi1): 4.715e-03, MSE(pi2): 4.222e-05, MSE(pi3): 1.528e-03\n",
      "Epoch 12400, Train loss: 7.963e+02, Test loss: 1.636e+04, MSE(e): 5.973e-05, MSE(pi1): 4.724e-03, MSE(pi2): 4.187e-05, MSE(pi3): 1.517e-03\n",
      "Epoch 12500, Train loss: 7.885e+02, Test loss: 1.631e+04, MSE(e): 5.907e-05, MSE(pi1): 4.714e-03, MSE(pi2): 4.154e-05, MSE(pi3): 1.506e-03\n",
      "Epoch 12600, Train loss: 7.811e+02, Test loss: 1.626e+04, MSE(e): 5.845e-05, MSE(pi1): 4.696e-03, MSE(pi2): 4.122e-05, MSE(pi3): 1.496e-03\n",
      "Epoch 12700, Train loss: 7.747e+02, Test loss: 1.621e+04, MSE(e): 5.799e-05, MSE(pi1): 4.557e-03, MSE(pi2): 4.098e-05, MSE(pi3): 1.492e-03\n",
      "Epoch 12800, Train loss: 7.675e+02, Test loss: 1.616e+04, MSE(e): 5.737e-05, MSE(pi1): 4.546e-03, MSE(pi2): 4.066e-05, MSE(pi3): 1.482e-03\n",
      "Epoch 12900, Train loss: 7.609e+02, Test loss: 1.611e+04, MSE(e): 5.682e-05, MSE(pi1): 4.547e-03, MSE(pi2): 4.037e-05, MSE(pi3): 1.473e-03\n",
      "Epoch 13000, Train loss: 7.544e+02, Test loss: 1.606e+04, MSE(e): 5.626e-05, MSE(pi1): 4.539e-03, MSE(pi2): 4.007e-05, MSE(pi3): 1.464e-03\n",
      "Epoch 13100, Train loss: 7.479e+02, Test loss: 1.601e+04, MSE(e): 5.568e-05, MSE(pi1): 4.560e-03, MSE(pi2): 3.978e-05, MSE(pi3): 1.454e-03\n",
      "Epoch 13200, Train loss: 7.416e+02, Test loss: 1.596e+04, MSE(e): 5.513e-05, MSE(pi1): 4.575e-03, MSE(pi2): 3.949e-05, MSE(pi3): 1.445e-03\n",
      "Epoch 13300, Train loss: 7.359e+02, Test loss: 1.591e+04, MSE(e): 5.473e-05, MSE(pi1): 4.457e-03, MSE(pi2): 3.927e-05, MSE(pi3): 1.441e-03\n",
      "Epoch 13400, Train loss: 7.301e+02, Test loss: 1.586e+04, MSE(e): 5.431e-05, MSE(pi1): 4.335e-03, MSE(pi2): 3.904e-05, MSE(pi3): 1.436e-03\n",
      "Epoch 13500, Train loss: 7.243e+02, Test loss: 1.581e+04, MSE(e): 5.381e-05, MSE(pi1): 4.340e-03, MSE(pi2): 3.876e-05, MSE(pi3): 1.428e-03\n",
      "Epoch 13600, Train loss: 7.187e+02, Test loss: 1.575e+04, MSE(e): 5.331e-05, MSE(pi1): 4.364e-03, MSE(pi2): 3.848e-05, MSE(pi3): 1.419e-03\n",
      "Epoch 13700, Train loss: 7.130e+02, Test loss: 1.570e+04, MSE(e): 5.280e-05, MSE(pi1): 4.386e-03, MSE(pi2): 3.821e-05, MSE(pi3): 1.411e-03\n",
      "Epoch 13800, Train loss: 7.080e+02, Test loss: 1.565e+04, MSE(e): 5.247e-05, MSE(pi1): 4.270e-03, MSE(pi2): 3.802e-05, MSE(pi3): 1.406e-03\n",
      "Epoch 13900, Train loss: 7.031e+02, Test loss: 1.560e+04, MSE(e): 5.207e-05, MSE(pi1): 4.255e-03, MSE(pi2): 3.777e-05, MSE(pi3): 1.399e-03\n",
      "Epoch 14000, Train loss: 6.976e+02, Test loss: 1.555e+04, MSE(e): 5.156e-05, MSE(pi1): 4.284e-03, MSE(pi2): 3.750e-05, MSE(pi3): 1.392e-03\n",
      "Epoch 14100, Train loss: 6.927e+02, Test loss: 1.549e+04, MSE(e): 5.112e-05, MSE(pi1): 4.303e-03, MSE(pi2): 3.725e-05, MSE(pi3): 1.384e-03\n",
      "Epoch 14200, Train loss: 6.879e+02, Test loss: 1.544e+04, MSE(e): 5.074e-05, MSE(pi1): 4.277e-03, MSE(pi2): 3.703e-05, MSE(pi3): 1.377e-03\n",
      "Epoch 14300, Train loss: 6.840e+02, Test loss: 1.539e+04, MSE(e): 5.050e-05, MSE(pi1): 4.171e-03, MSE(pi2): 3.687e-05, MSE(pi3): 1.373e-03\n",
      "Epoch 14400, Train loss: 6.788e+02, Test loss: 1.534e+04, MSE(e): 5.003e-05, MSE(pi1): 4.194e-03, MSE(pi2): 3.660e-05, MSE(pi3): 1.365e-03\n",
      "Epoch 14500, Train loss: 6.743e+02, Test loss: 1.529e+04, MSE(e): 4.962e-05, MSE(pi1): 4.224e-03, MSE(pi2): 3.636e-05, MSE(pi3): 1.358e-03\n",
      "Epoch 14600, Train loss: 6.695e+02, Test loss: 1.523e+04, MSE(e): 4.917e-05, MSE(pi1): 4.264e-03, MSE(pi2): 3.611e-05, MSE(pi3): 1.352e-03\n",
      "Epoch 14700, Train loss: 6.658e+02, Test loss: 1.518e+04, MSE(e): 4.894e-05, MSE(pi1): 4.173e-03, MSE(pi2): 3.596e-05, MSE(pi3): 1.347e-03\n",
      "Epoch 14800, Train loss: 6.611e+02, Test loss: 1.513e+04, MSE(e): 4.856e-05, MSE(pi1): 4.153e-03, MSE(pi2): 3.573e-05, MSE(pi3): 1.340e-03\n",
      "Epoch 14900, Train loss: 6.575e+02, Test loss: 1.508e+04, MSE(e): 4.825e-05, MSE(pi1): 4.171e-03, MSE(pi2): 3.552e-05, MSE(pi3): 1.333e-03\n",
      "Epoch 15000, Train loss: 6.529e+02, Test loss: 1.503e+04, MSE(e): 4.782e-05, MSE(pi1): 4.201e-03, MSE(pi2): 3.529e-05, MSE(pi3): 1.326e-03\n",
      "Epoch 15100, Train loss: 6.495e+02, Test loss: 1.498e+04, MSE(e): 4.754e-05, MSE(pi1): 4.200e-03, MSE(pi2): 3.509e-05, MSE(pi3): 1.321e-03\n",
      "Epoch 15200, Train loss: 6.441e+02, Test loss: 1.492e+04, MSE(e): 4.699e-05, MSE(pi1): 4.300e-03, MSE(pi2): 3.478e-05, MSE(pi3): 1.312e-03\n",
      "Epoch 15300, Train loss: 6.431e+02, Test loss: 1.487e+04, MSE(e): 4.710e-05, MSE(pi1): 4.058e-03, MSE(pi2): 3.480e-05, MSE(pi3): 1.315e-03\n",
      "Epoch 15400, Train loss: 6.381e+02, Test loss: 1.483e+04, MSE(e): 4.666e-05, MSE(pi1): 4.054e-03, MSE(pi2): 3.454e-05, MSE(pi3): 1.309e-03\n",
      "Epoch 15500, Train loss: 6.337e+02, Test loss: 1.477e+04, MSE(e): 4.626e-05, MSE(pi1): 4.074e-03, MSE(pi2): 3.431e-05, MSE(pi3): 1.304e-03\n",
      "Epoch 15600, Train loss: 6.307e+02, Test loss: 1.472e+04, MSE(e): 4.601e-05, MSE(pi1): 4.060e-03, MSE(pi2): 3.414e-05, MSE(pi3): 1.299e-03\n",
      "Epoch 15700, Train loss: 6.271e+02, Test loss: 1.467e+04, MSE(e): 4.571e-05, MSE(pi1): 4.041e-03, MSE(pi2): 3.396e-05, MSE(pi3): 1.296e-03\n",
      "Epoch 15800, Train loss: 6.233e+02, Test loss: 1.462e+04, MSE(e): 4.539e-05, MSE(pi1): 4.029e-03, MSE(pi2): 3.376e-05, MSE(pi3): 1.291e-03\n",
      "Epoch 15900, Train loss: 6.202e+02, Test loss: 1.457e+04, MSE(e): 4.513e-05, MSE(pi1): 4.015e-03, MSE(pi2): 3.359e-05, MSE(pi3): 1.287e-03\n",
      "Epoch 16000, Train loss: 6.170e+02, Test loss: 1.452e+04, MSE(e): 4.487e-05, MSE(pi1): 3.993e-03, MSE(pi2): 3.343e-05, MSE(pi3): 1.284e-03\n",
      "Epoch 16100, Train loss: 6.134e+02, Test loss: 1.447e+04, MSE(e): 4.458e-05, MSE(pi1): 3.970e-03, MSE(pi2): 3.324e-05, MSE(pi3): 1.279e-03\n",
      "Epoch 16200, Train loss: 6.100e+02, Test loss: 1.442e+04, MSE(e): 4.427e-05, MSE(pi1): 3.969e-03, MSE(pi2): 3.306e-05, MSE(pi3): 1.275e-03\n",
      "Epoch 16300, Train loss: 6.069e+02, Test loss: 1.436e+04, MSE(e): 4.402e-05, MSE(pi1): 3.956e-03, MSE(pi2): 3.289e-05, MSE(pi3): 1.271e-03\n",
      "Epoch 16400, Train loss: 6.039e+02, Test loss: 1.432e+04, MSE(e): 4.377e-05, MSE(pi1): 3.952e-03, MSE(pi2): 3.273e-05, MSE(pi3): 1.267e-03\n",
      "Epoch 16500, Train loss: 6.004e+02, Test loss: 1.427e+04, MSE(e): 4.344e-05, MSE(pi1): 3.980e-03, MSE(pi2): 3.252e-05, MSE(pi3): 1.261e-03\n",
      "Epoch 16600, Train loss: 5.974e+02, Test loss: 1.421e+04, MSE(e): 4.320e-05, MSE(pi1): 3.949e-03, MSE(pi2): 3.237e-05, MSE(pi3): 1.258e-03\n",
      "Epoch 16700, Train loss: 5.951e+02, Test loss: 1.417e+04, MSE(e): 4.301e-05, MSE(pi1): 3.948e-03, MSE(pi2): 3.222e-05, MSE(pi3): 1.255e-03\n",
      "Epoch 16800, Train loss: 5.918e+02, Test loss: 1.412e+04, MSE(e): 4.271e-05, MSE(pi1): 3.953e-03, MSE(pi2): 3.204e-05, MSE(pi3): 1.251e-03\n",
      "Epoch 16900, Train loss: 5.885e+02, Test loss: 1.407e+04, MSE(e): 4.242e-05, MSE(pi1): 3.958e-03, MSE(pi2): 3.187e-05, MSE(pi3): 1.247e-03\n",
      "Epoch 17000, Train loss: 5.861e+02, Test loss: 1.402e+04, MSE(e): 4.223e-05, MSE(pi1): 3.953e-03, MSE(pi2): 3.172e-05, MSE(pi3): 1.242e-03\n",
      "Epoch 17100, Train loss: 5.837e+02, Test loss: 1.398e+04, MSE(e): 4.204e-05, MSE(pi1): 3.941e-03, MSE(pi2): 3.158e-05, MSE(pi3): 1.239e-03\n",
      "Epoch 17200, Train loss: 5.808e+02, Test loss: 1.393e+04, MSE(e): 4.179e-05, MSE(pi1): 3.929e-03, MSE(pi2): 3.144e-05, MSE(pi3): 1.236e-03\n",
      "Epoch 17300, Train loss: 5.771e+02, Test loss: 1.388e+04, MSE(e): 4.146e-05, MSE(pi1): 3.945e-03, MSE(pi2): 3.125e-05, MSE(pi3): 1.230e-03\n",
      "Epoch 17400, Train loss: 5.741e+02, Test loss: 1.382e+04, MSE(e): 4.121e-05, MSE(pi1): 3.917e-03, MSE(pi2): 3.108e-05, MSE(pi3): 1.228e-03\n",
      "Epoch 17500, Train loss: 5.713e+02, Test loss: 1.378e+04, MSE(e): 4.097e-05, MSE(pi1): 3.914e-03, MSE(pi2): 3.091e-05, MSE(pi3): 1.224e-03\n",
      "Epoch 17600, Train loss: 5.697e+02, Test loss: 1.374e+04, MSE(e): 4.086e-05, MSE(pi1): 3.925e-03, MSE(pi2): 3.080e-05, MSE(pi3): 1.219e-03\n",
      "Epoch 17700, Train loss: 5.678e+02, Test loss: 1.369e+04, MSE(e): 4.070e-05, MSE(pi1): 3.896e-03, MSE(pi2): 3.068e-05, MSE(pi3): 1.218e-03\n",
      "Epoch 17800, Train loss: 5.645e+02, Test loss: 1.364e+04, MSE(e): 4.042e-05, MSE(pi1): 3.894e-03, MSE(pi2): 3.053e-05, MSE(pi3): 1.214e-03\n",
      "Epoch 17900, Train loss: 5.603e+02, Test loss: 1.359e+04, MSE(e): 4.003e-05, MSE(pi1): 3.899e-03, MSE(pi2): 3.031e-05, MSE(pi3): 1.210e-03\n",
      "Epoch 18000, Train loss: 5.563e+02, Test loss: 1.353e+04, MSE(e): 3.967e-05, MSE(pi1): 3.893e-03, MSE(pi2): 3.011e-05, MSE(pi3): 1.206e-03\n",
      "Epoch 18100, Train loss: 5.527e+02, Test loss: 1.348e+04, MSE(e): 3.936e-05, MSE(pi1): 3.887e-03, MSE(pi2): 2.993e-05, MSE(pi3): 1.202e-03\n",
      "Epoch 18200, Train loss: 5.492e+02, Test loss: 1.344e+04, MSE(e): 3.904e-05, MSE(pi1): 3.891e-03, MSE(pi2): 2.974e-05, MSE(pi3): 1.198e-03\n",
      "Epoch 18300, Train loss: 5.460e+02, Test loss: 1.339e+04, MSE(e): 3.876e-05, MSE(pi1): 3.891e-03, MSE(pi2): 2.957e-05, MSE(pi3): 1.195e-03\n",
      "Epoch 18400, Train loss: 5.438e+02, Test loss: 1.335e+04, MSE(e): 3.856e-05, MSE(pi1): 3.903e-03, MSE(pi2): 2.942e-05, MSE(pi3): 1.191e-03\n",
      "Epoch 18500, Train loss: 5.439e+02, Test loss: 1.331e+04, MSE(e): 3.862e-05, MSE(pi1): 3.880e-03, MSE(pi2): 2.938e-05, MSE(pi3): 1.188e-03\n",
      "Epoch 18600, Train loss: 5.517e+02, Test loss: 1.330e+04, MSE(e): 3.947e-05, MSE(pi1): 3.844e-03, MSE(pi2): 2.966e-05, MSE(pi3): 1.185e-03\n",
      "Epoch 18700, Train loss: 5.432e+02, Test loss: 1.327e+04, MSE(e): 3.862e-05, MSE(pi1): 3.826e-03, MSE(pi2): 2.932e-05, MSE(pi3): 1.188e-03\n",
      "Epoch 18800, Train loss: 5.391e+02, Test loss: 1.319e+04, MSE(e): 3.824e-05, MSE(pi1): 3.824e-03, MSE(pi2): 2.912e-05, MSE(pi3): 1.185e-03\n",
      "Epoch 18900, Train loss: 5.307e+02, Test loss: 1.313e+04, MSE(e): 3.743e-05, MSE(pi1): 3.855e-03, MSE(pi2): 2.871e-05, MSE(pi3): 1.178e-03\n",
      "Epoch 19000, Train loss: 5.203e+02, Test loss: 1.307e+04, MSE(e): 3.646e-05, MSE(pi1): 3.853e-03, MSE(pi2): 2.832e-05, MSE(pi3): 1.172e-03\n",
      "Epoch 19100, Train loss: 5.086e+02, Test loss: 1.301e+04, MSE(e): 3.536e-05, MSE(pi1): 3.814e-03, MSE(pi2): 2.781e-05, MSE(pi3): 1.169e-03\n",
      "Epoch 19200, Train loss: 5.029e+02, Test loss: 1.296e+04, MSE(e): 3.485e-05, MSE(pi1): 3.807e-03, MSE(pi2): 2.746e-05, MSE(pi3): 1.163e-03\n",
      "Epoch 19300, Train loss: 5.002e+02, Test loss: 1.292e+04, MSE(e): 3.464e-05, MSE(pi1): 3.808e-03, MSE(pi2): 2.726e-05, MSE(pi3): 1.157e-03\n",
      "Epoch 19400, Train loss: 4.977e+02, Test loss: 1.288e+04, MSE(e): 3.444e-05, MSE(pi1): 3.804e-03, MSE(pi2): 2.709e-05, MSE(pi3): 1.153e-03\n",
      "Epoch 19500, Train loss: 4.953e+02, Test loss: 1.284e+04, MSE(e): 3.422e-05, MSE(pi1): 3.803e-03, MSE(pi2): 2.693e-05, MSE(pi3): 1.150e-03\n",
      "Epoch 19600, Train loss: 4.930e+02, Test loss: 1.280e+04, MSE(e): 3.403e-05, MSE(pi1): 3.813e-03, MSE(pi2): 2.679e-05, MSE(pi3): 1.145e-03\n",
      "Epoch 19700, Train loss: 4.912e+02, Test loss: 1.276e+04, MSE(e): 3.388e-05, MSE(pi1): 3.825e-03, MSE(pi2): 2.667e-05, MSE(pi3): 1.141e-03\n",
      "Epoch 19800, Train loss: 4.898e+02, Test loss: 1.272e+04, MSE(e): 3.378e-05, MSE(pi1): 3.825e-03, MSE(pi2): 2.657e-05, MSE(pi3): 1.137e-03\n",
      "Epoch 19900, Train loss: 4.874e+02, Test loss: 1.268e+04, MSE(e): 3.351e-05, MSE(pi1): 3.862e-03, MSE(pi2): 2.643e-05, MSE(pi3): 1.137e-03\n",
      "Epoch 20000, Train loss: 4.853e+02, Test loss: 1.264e+04, MSE(e): 3.337e-05, MSE(pi1): 3.758e-03, MSE(pi2): 2.635e-05, MSE(pi3): 1.140e-03\n",
      "Epoch 20100, Train loss: 4.812e+02, Test loss: 1.260e+04, MSE(e): 3.302e-05, MSE(pi1): 3.736e-03, MSE(pi2): 2.609e-05, MSE(pi3): 1.136e-03\n",
      "Epoch 20200, Train loss: 4.765e+02, Test loss: 1.256e+04, MSE(e): 3.260e-05, MSE(pi1): 3.725e-03, MSE(pi2): 2.582e-05, MSE(pi3): 1.133e-03\n",
      "Epoch 20300, Train loss: 4.734e+02, Test loss: 1.252e+04, MSE(e): 3.232e-05, MSE(pi1): 3.712e-03, MSE(pi2): 2.564e-05, MSE(pi3): 1.130e-03\n",
      "Epoch 20400, Train loss: 4.717e+02, Test loss: 1.247e+04, MSE(e): 3.218e-05, MSE(pi1): 3.699e-03, MSE(pi2): 2.553e-05, MSE(pi3): 1.128e-03\n",
      "Epoch 20500, Train loss: 4.701e+02, Test loss: 1.243e+04, MSE(e): 3.205e-05, MSE(pi1): 3.688e-03, MSE(pi2): 2.543e-05, MSE(pi3): 1.126e-03\n",
      "Epoch 20600, Train loss: 4.676e+02, Test loss: 1.239e+04, MSE(e): 3.184e-05, MSE(pi1): 3.684e-03, MSE(pi2): 2.527e-05, MSE(pi3): 1.124e-03\n",
      "Epoch 20700, Train loss: 4.646e+02, Test loss: 1.234e+04, MSE(e): 3.158e-05, MSE(pi1): 3.686e-03, MSE(pi2): 2.509e-05, MSE(pi3): 1.120e-03\n",
      "Epoch 20800, Train loss: 4.621e+02, Test loss: 1.230e+04, MSE(e): 3.135e-05, MSE(pi1): 3.691e-03, MSE(pi2): 2.493e-05, MSE(pi3): 1.117e-03\n",
      "Epoch 20900, Train loss: 4.603e+02, Test loss: 1.226e+04, MSE(e): 3.120e-05, MSE(pi1): 3.692e-03, MSE(pi2): 2.480e-05, MSE(pi3): 1.114e-03\n",
      "Epoch 21000, Train loss: 4.586e+02, Test loss: 1.222e+04, MSE(e): 3.105e-05, MSE(pi1): 3.698e-03, MSE(pi2): 2.469e-05, MSE(pi3): 1.111e-03\n",
      "Epoch 21100, Train loss: 4.565e+02, Test loss: 1.217e+04, MSE(e): 3.086e-05, MSE(pi1): 3.710e-03, MSE(pi2): 2.455e-05, MSE(pi3): 1.107e-03\n",
      "Epoch 21200, Train loss: 4.542e+02, Test loss: 1.213e+04, MSE(e): 3.065e-05, MSE(pi1): 3.727e-03, MSE(pi2): 2.440e-05, MSE(pi3): 1.104e-03\n",
      "Epoch 21300, Train loss: 4.517e+02, Test loss: 1.209e+04, MSE(e): 3.045e-05, MSE(pi1): 3.701e-03, MSE(pi2): 2.425e-05, MSE(pi3): 1.102e-03\n",
      "Epoch 21400, Train loss: 4.493e+02, Test loss: 1.205e+04, MSE(e): 3.027e-05, MSE(pi1): 3.656e-03, MSE(pi2): 2.411e-05, MSE(pi3): 1.100e-03\n",
      "Epoch 21500, Train loss: 4.478e+02, Test loss: 1.201e+04, MSE(e): 3.012e-05, MSE(pi1): 3.696e-03, MSE(pi2): 2.401e-05, MSE(pi3): 1.096e-03\n",
      "Epoch 21600, Train loss: 4.454e+02, Test loss: 1.196e+04, MSE(e): 2.994e-05, MSE(pi1): 3.639e-03, MSE(pi2): 2.387e-05, MSE(pi3): 1.096e-03\n",
      "Epoch 21700, Train loss: 4.428e+02, Test loss: 1.192e+04, MSE(e): 2.972e-05, MSE(pi1): 3.623e-03, MSE(pi2): 2.372e-05, MSE(pi3): 1.094e-03\n",
      "Epoch 21800, Train loss: 4.399e+02, Test loss: 1.188e+04, MSE(e): 2.947e-05, MSE(pi1): 3.596e-03, MSE(pi2): 2.354e-05, MSE(pi3): 1.093e-03\n",
      "Epoch 21900, Train loss: 4.373e+02, Test loss: 1.183e+04, MSE(e): 2.925e-05, MSE(pi1): 3.580e-03, MSE(pi2): 2.339e-05, MSE(pi3): 1.091e-03\n",
      "Epoch 22000, Train loss: 4.356e+02, Test loss: 1.179e+04, MSE(e): 2.910e-05, MSE(pi1): 3.568e-03, MSE(pi2): 2.327e-05, MSE(pi3): 1.089e-03\n",
      "Epoch 22100, Train loss: 4.343e+02, Test loss: 1.175e+04, MSE(e): 2.899e-05, MSE(pi1): 3.559e-03, MSE(pi2): 2.318e-05, MSE(pi3): 1.087e-03\n",
      "Epoch 22200, Train loss: 4.329e+02, Test loss: 1.170e+04, MSE(e): 2.889e-05, MSE(pi1): 3.546e-03, MSE(pi2): 2.310e-05, MSE(pi3): 1.086e-03\n",
      "Epoch 22300, Train loss: 4.305e+02, Test loss: 1.166e+04, MSE(e): 2.868e-05, MSE(pi1): 3.546e-03, MSE(pi2): 2.295e-05, MSE(pi3): 1.083e-03\n",
      "Epoch 22400, Train loss: 4.272e+02, Test loss: 1.162e+04, MSE(e): 2.838e-05, MSE(pi1): 3.537e-03, MSE(pi2): 2.276e-05, MSE(pi3): 1.080e-03\n",
      "Epoch 22500, Train loss: 4.240e+02, Test loss: 1.159e+04, MSE(e): 2.809e-05, MSE(pi1): 3.535e-03, MSE(pi2): 2.257e-05, MSE(pi3): 1.078e-03\n",
      "Epoch 22600, Train loss: 4.212e+02, Test loss: 1.155e+04, MSE(e): 2.785e-05, MSE(pi1): 3.517e-03, MSE(pi2): 2.241e-05, MSE(pi3): 1.075e-03\n",
      "Epoch 22700, Train loss: 4.190e+02, Test loss: 1.151e+04, MSE(e): 2.766e-05, MSE(pi1): 3.512e-03, MSE(pi2): 2.227e-05, MSE(pi3): 1.073e-03\n",
      "Epoch 22800, Train loss: 4.172e+02, Test loss: 1.146e+04, MSE(e): 2.750e-05, MSE(pi1): 3.506e-03, MSE(pi2): 2.216e-05, MSE(pi3): 1.071e-03\n",
      "Epoch 22900, Train loss: 4.165e+02, Test loss: 1.142e+04, MSE(e): 2.746e-05, MSE(pi1): 3.496e-03, MSE(pi2): 2.210e-05, MSE(pi3): 1.070e-03\n",
      "Epoch 23000, Train loss: 4.211e+02, Test loss: 1.137e+04, MSE(e): 2.792e-05, MSE(pi1): 3.500e-03, MSE(pi2): 2.235e-05, MSE(pi3): 1.069e-03\n",
      "Epoch 23100, Train loss: 4.225e+02, Test loss: 1.133e+04, MSE(e): 2.808e-05, MSE(pi1): 3.482e-03, MSE(pi2): 2.243e-05, MSE(pi3): 1.069e-03\n",
      "Epoch 23200, Train loss: 4.151e+02, Test loss: 1.129e+04, MSE(e): 2.738e-05, MSE(pi1): 3.464e-03, MSE(pi2): 2.201e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 23300, Train loss: 4.086e+02, Test loss: 1.126e+04, MSE(e): 2.678e-05, MSE(pi1): 3.455e-03, MSE(pi2): 2.164e-05, MSE(pi3): 1.062e-03\n",
      "Epoch 23400, Train loss: 4.058e+02, Test loss: 1.123e+04, MSE(e): 2.654e-05, MSE(pi1): 3.438e-03, MSE(pi2): 2.148e-05, MSE(pi3): 1.060e-03\n",
      "Epoch 23500, Train loss: 4.041e+02, Test loss: 1.119e+04, MSE(e): 2.639e-05, MSE(pi1): 3.439e-03, MSE(pi2): 2.136e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 23600, Train loss: 4.023e+02, Test loss: 1.115e+04, MSE(e): 2.624e-05, MSE(pi1): 3.436e-03, MSE(pi2): 2.124e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 23700, Train loss: 4.004e+02, Test loss: 1.111e+04, MSE(e): 2.608e-05, MSE(pi1): 3.428e-03, MSE(pi2): 2.111e-05, MSE(pi3): 1.053e-03\n",
      "Epoch 23800, Train loss: 3.986e+02, Test loss: 1.107e+04, MSE(e): 2.593e-05, MSE(pi1): 3.424e-03, MSE(pi2): 2.099e-05, MSE(pi3): 1.051e-03\n",
      "Epoch 23900, Train loss: 3.969e+02, Test loss: 1.103e+04, MSE(e): 2.578e-05, MSE(pi1): 3.417e-03, MSE(pi2): 2.087e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 24000, Train loss: 3.951e+02, Test loss: 1.099e+04, MSE(e): 2.563e-05, MSE(pi1): 3.410e-03, MSE(pi2): 2.076e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 24100, Train loss: 3.934e+02, Test loss: 1.095e+04, MSE(e): 2.548e-05, MSE(pi1): 3.409e-03, MSE(pi2): 2.066e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 24200, Train loss: 3.917e+02, Test loss: 1.091e+04, MSE(e): 2.534e-05, MSE(pi1): 3.408e-03, MSE(pi2): 2.055e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 24300, Train loss: 3.900e+02, Test loss: 1.087e+04, MSE(e): 2.520e-05, MSE(pi1): 3.402e-03, MSE(pi2): 2.045e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 24400, Train loss: 3.884e+02, Test loss: 1.083e+04, MSE(e): 2.506e-05, MSE(pi1): 3.393e-03, MSE(pi2): 2.035e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 24500, Train loss: 3.867e+02, Test loss: 1.079e+04, MSE(e): 2.492e-05, MSE(pi1): 3.386e-03, MSE(pi2): 2.025e-05, MSE(pi3): 1.036e-03\n",
      "Epoch 24600, Train loss: 3.851e+02, Test loss: 1.076e+04, MSE(e): 2.478e-05, MSE(pi1): 3.380e-03, MSE(pi2): 2.015e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 24700, Train loss: 3.835e+02, Test loss: 1.072e+04, MSE(e): 2.465e-05, MSE(pi1): 3.380e-03, MSE(pi2): 2.005e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 24800, Train loss: 3.819e+02, Test loss: 1.068e+04, MSE(e): 2.452e-05, MSE(pi1): 3.379e-03, MSE(pi2): 1.995e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 24900, Train loss: 3.803e+02, Test loss: 1.064e+04, MSE(e): 2.438e-05, MSE(pi1): 3.376e-03, MSE(pi2): 1.986e-05, MSE(pi3): 1.027e-03\n",
      "Epoch 25000, Train loss: 3.787e+02, Test loss: 1.060e+04, MSE(e): 2.425e-05, MSE(pi1): 3.371e-03, MSE(pi2): 1.976e-05, MSE(pi3): 1.025e-03\n",
      "Epoch 25100, Train loss: 3.772e+02, Test loss: 1.057e+04, MSE(e): 2.412e-05, MSE(pi1): 3.364e-03, MSE(pi2): 1.967e-05, MSE(pi3): 1.023e-03\n",
      "Epoch 25200, Train loss: 3.757e+02, Test loss: 1.053e+04, MSE(e): 2.399e-05, MSE(pi1): 3.362e-03, MSE(pi2): 1.957e-05, MSE(pi3): 1.021e-03\n",
      "Epoch 25300, Train loss: 3.741e+02, Test loss: 1.049e+04, MSE(e): 2.387e-05, MSE(pi1): 3.359e-03, MSE(pi2): 1.948e-05, MSE(pi3): 1.019e-03\n",
      "Epoch 25400, Train loss: 3.726e+02, Test loss: 1.045e+04, MSE(e): 2.374e-05, MSE(pi1): 3.360e-03, MSE(pi2): 1.939e-05, MSE(pi3): 1.016e-03\n",
      "Epoch 25500, Train loss: 3.711e+02, Test loss: 1.042e+04, MSE(e): 2.361e-05, MSE(pi1): 3.355e-03, MSE(pi2): 1.929e-05, MSE(pi3): 1.014e-03\n",
      "Epoch 25600, Train loss: 3.697e+02, Test loss: 1.038e+04, MSE(e): 2.349e-05, MSE(pi1): 3.351e-03, MSE(pi2): 1.920e-05, MSE(pi3): 1.012e-03\n",
      "Epoch 25700, Train loss: 3.682e+02, Test loss: 1.034e+04, MSE(e): 2.337e-05, MSE(pi1): 3.346e-03, MSE(pi2): 1.911e-05, MSE(pi3): 1.011e-03\n",
      "Epoch 25800, Train loss: 3.668e+02, Test loss: 1.031e+04, MSE(e): 2.324e-05, MSE(pi1): 3.346e-03, MSE(pi2): 1.902e-05, MSE(pi3): 1.008e-03\n",
      "Epoch 25900, Train loss: 3.653e+02, Test loss: 1.027e+04, MSE(e): 2.312e-05, MSE(pi1): 3.345e-03, MSE(pi2): 1.893e-05, MSE(pi3): 1.006e-03\n",
      "Epoch 26000, Train loss: 3.639e+02, Test loss: 1.024e+04, MSE(e): 2.301e-05, MSE(pi1): 3.345e-03, MSE(pi2): 1.884e-05, MSE(pi3): 1.004e-03\n",
      "Epoch 26100, Train loss: 3.625e+02, Test loss: 1.020e+04, MSE(e): 2.289e-05, MSE(pi1): 3.331e-03, MSE(pi2): 1.876e-05, MSE(pi3): 1.003e-03\n",
      "Epoch 26200, Train loss: 3.611e+02, Test loss: 1.017e+04, MSE(e): 2.277e-05, MSE(pi1): 3.327e-03, MSE(pi2): 1.867e-05, MSE(pi3): 1.001e-03\n",
      "Epoch 26300, Train loss: 3.597e+02, Test loss: 1.013e+04, MSE(e): 2.265e-05, MSE(pi1): 3.326e-03, MSE(pi2): 1.858e-05, MSE(pi3): 9.989e-04\n",
      "Epoch 26400, Train loss: 3.583e+02, Test loss: 1.010e+04, MSE(e): 2.254e-05, MSE(pi1): 3.329e-03, MSE(pi2): 1.850e-05, MSE(pi3): 9.964e-04\n",
      "Epoch 26500, Train loss: 3.569e+02, Test loss: 1.006e+04, MSE(e): 2.242e-05, MSE(pi1): 3.323e-03, MSE(pi2): 1.841e-05, MSE(pi3): 9.947e-04\n",
      "Epoch 26600, Train loss: 3.556e+02, Test loss: 1.003e+04, MSE(e): 2.231e-05, MSE(pi1): 3.316e-03, MSE(pi2): 1.833e-05, MSE(pi3): 9.932e-04\n",
      "Epoch 26700, Train loss: 3.543e+02, Test loss: 9.995e+03, MSE(e): 2.220e-05, MSE(pi1): 3.309e-03, MSE(pi2): 1.824e-05, MSE(pi3): 9.917e-04\n",
      "Epoch 26800, Train loss: 3.529e+02, Test loss: 9.961e+03, MSE(e): 2.209e-05, MSE(pi1): 3.305e-03, MSE(pi2): 1.816e-05, MSE(pi3): 9.898e-04\n",
      "Epoch 26900, Train loss: 3.516e+02, Test loss: 9.928e+03, MSE(e): 2.198e-05, MSE(pi1): 3.302e-03, MSE(pi2): 1.808e-05, MSE(pi3): 9.881e-04\n",
      "Epoch 27000, Train loss: 3.503e+02, Test loss: 9.895e+03, MSE(e): 2.187e-05, MSE(pi1): 3.304e-03, MSE(pi2): 1.800e-05, MSE(pi3): 9.855e-04\n",
      "Epoch 27100, Train loss: 3.490e+02, Test loss: 9.862e+03, MSE(e): 2.176e-05, MSE(pi1): 3.298e-03, MSE(pi2): 1.792e-05, MSE(pi3): 9.839e-04\n",
      "Epoch 27200, Train loss: 3.477e+02, Test loss: 9.829e+03, MSE(e): 2.166e-05, MSE(pi1): 3.296e-03, MSE(pi2): 1.784e-05, MSE(pi3): 9.818e-04\n",
      "Epoch 27300, Train loss: 3.465e+02, Test loss: 9.797e+03, MSE(e): 2.155e-05, MSE(pi1): 3.295e-03, MSE(pi2): 1.776e-05, MSE(pi3): 9.799e-04\n",
      "Epoch 27400, Train loss: 3.452e+02, Test loss: 9.764e+03, MSE(e): 2.144e-05, MSE(pi1): 3.293e-03, MSE(pi2): 1.768e-05, MSE(pi3): 9.780e-04\n",
      "Epoch 27500, Train loss: 3.440e+02, Test loss: 9.732e+03, MSE(e): 2.134e-05, MSE(pi1): 3.287e-03, MSE(pi2): 1.760e-05, MSE(pi3): 9.766e-04\n",
      "Epoch 27600, Train loss: 3.427e+02, Test loss: 9.700e+03, MSE(e): 2.124e-05, MSE(pi1): 3.285e-03, MSE(pi2): 1.752e-05, MSE(pi3): 9.747e-04\n",
      "Epoch 27700, Train loss: 3.415e+02, Test loss: 9.669e+03, MSE(e): 2.113e-05, MSE(pi1): 3.283e-03, MSE(pi2): 1.745e-05, MSE(pi3): 9.727e-04\n",
      "Epoch 27800, Train loss: 3.403e+02, Test loss: 9.637e+03, MSE(e): 2.103e-05, MSE(pi1): 3.274e-03, MSE(pi2): 1.737e-05, MSE(pi3): 9.717e-04\n",
      "Epoch 27900, Train loss: 3.390e+02, Test loss: 9.606e+03, MSE(e): 2.093e-05, MSE(pi1): 3.269e-03, MSE(pi2): 1.730e-05, MSE(pi3): 9.701e-04\n",
      "Epoch 28000, Train loss: 3.378e+02, Test loss: 9.575e+03, MSE(e): 2.083e-05, MSE(pi1): 3.266e-03, MSE(pi2): 1.722e-05, MSE(pi3): 9.683e-04\n",
      "Epoch 28100, Train loss: 3.367e+02, Test loss: 9.544e+03, MSE(e): 2.073e-05, MSE(pi1): 3.272e-03, MSE(pi2): 1.715e-05, MSE(pi3): 9.661e-04\n",
      "Epoch 28200, Train loss: 3.355e+02, Test loss: 9.513e+03, MSE(e): 2.064e-05, MSE(pi1): 3.262e-03, MSE(pi2): 1.707e-05, MSE(pi3): 9.651e-04\n",
      "Epoch 28300, Train loss: 3.343e+02, Test loss: 9.483e+03, MSE(e): 2.054e-05, MSE(pi1): 3.253e-03, MSE(pi2): 1.700e-05, MSE(pi3): 9.640e-04\n",
      "Epoch 28400, Train loss: 3.331e+02, Test loss: 9.453e+03, MSE(e): 2.044e-05, MSE(pi1): 3.247e-03, MSE(pi2): 1.693e-05, MSE(pi3): 9.623e-04\n",
      "Epoch 28500, Train loss: 3.320e+02, Test loss: 9.423e+03, MSE(e): 2.035e-05, MSE(pi1): 3.251e-03, MSE(pi2): 1.685e-05, MSE(pi3): 9.600e-04\n",
      "Epoch 28600, Train loss: 3.309e+02, Test loss: 9.393e+03, MSE(e): 2.025e-05, MSE(pi1): 3.244e-03, MSE(pi2): 1.678e-05, MSE(pi3): 9.588e-04\n",
      "Epoch 28700, Train loss: 3.297e+02, Test loss: 9.364e+03, MSE(e): 2.016e-05, MSE(pi1): 3.236e-03, MSE(pi2): 1.671e-05, MSE(pi3): 9.576e-04\n",
      "Epoch 28800, Train loss: 3.286e+02, Test loss: 9.334e+03, MSE(e): 2.007e-05, MSE(pi1): 3.240e-03, MSE(pi2): 1.664e-05, MSE(pi3): 9.554e-04\n",
      "Epoch 28900, Train loss: 3.275e+02, Test loss: 9.305e+03, MSE(e): 1.997e-05, MSE(pi1): 3.240e-03, MSE(pi2): 1.657e-05, MSE(pi3): 9.533e-04\n",
      "Epoch 29000, Train loss: 3.264e+02, Test loss: 9.276e+03, MSE(e): 1.988e-05, MSE(pi1): 3.247e-03, MSE(pi2): 1.650e-05, MSE(pi3): 9.512e-04\n",
      "Epoch 29100, Train loss: 3.253e+02, Test loss: 9.247e+03, MSE(e): 1.979e-05, MSE(pi1): 3.246e-03, MSE(pi2): 1.643e-05, MSE(pi3): 9.492e-04\n",
      "Epoch 29200, Train loss: 3.242e+02, Test loss: 9.219e+03, MSE(e): 1.970e-05, MSE(pi1): 3.247e-03, MSE(pi2): 1.637e-05, MSE(pi3): 9.473e-04\n",
      "Epoch 29300, Train loss: 3.231e+02, Test loss: 9.190e+03, MSE(e): 1.961e-05, MSE(pi1): 3.235e-03, MSE(pi2): 1.630e-05, MSE(pi3): 9.462e-04\n",
      "Epoch 29400, Train loss: 3.220e+02, Test loss: 9.162e+03, MSE(e): 1.952e-05, MSE(pi1): 3.240e-03, MSE(pi2): 1.623e-05, MSE(pi3): 9.443e-04\n",
      "Epoch 29500, Train loss: 3.209e+02, Test loss: 9.134e+03, MSE(e): 1.943e-05, MSE(pi1): 3.223e-03, MSE(pi2): 1.616e-05, MSE(pi3): 9.438e-04\n",
      "Epoch 29600, Train loss: 3.199e+02, Test loss: 9.106e+03, MSE(e): 1.934e-05, MSE(pi1): 3.228e-03, MSE(pi2): 1.609e-05, MSE(pi3): 9.420e-04\n",
      "Epoch 29700, Train loss: 3.189e+02, Test loss: 9.078e+03, MSE(e): 1.926e-05, MSE(pi1): 3.212e-03, MSE(pi2): 1.603e-05, MSE(pi3): 9.415e-04\n",
      "Epoch 29800, Train loss: 3.178e+02, Test loss: 9.050e+03, MSE(e): 1.917e-05, MSE(pi1): 3.209e-03, MSE(pi2): 1.597e-05, MSE(pi3): 9.396e-04\n",
      "Epoch 29900, Train loss: 3.167e+02, Test loss: 9.023e+03, MSE(e): 1.908e-05, MSE(pi1): 3.200e-03, MSE(pi2): 1.590e-05, MSE(pi3): 9.388e-04\n",
      "Epoch 30000, Train loss: 3.157e+02, Test loss: 8.996e+03, MSE(e): 1.900e-05, MSE(pi1): 3.201e-03, MSE(pi2): 1.584e-05, MSE(pi3): 9.371e-04\n",
      "Epoch 30100, Train loss: 3.147e+02, Test loss: 8.970e+03, MSE(e): 1.891e-05, MSE(pi1): 3.207e-03, MSE(pi2): 1.577e-05, MSE(pi3): 9.352e-04\n",
      "Epoch 30200, Train loss: 3.137e+02, Test loss: 8.943e+03, MSE(e): 1.883e-05, MSE(pi1): 3.203e-03, MSE(pi2): 1.571e-05, MSE(pi3): 9.333e-04\n",
      "Epoch 30300, Train loss: 3.127e+02, Test loss: 8.916e+03, MSE(e): 1.875e-05, MSE(pi1): 3.193e-03, MSE(pi2): 1.565e-05, MSE(pi3): 9.326e-04\n",
      "Epoch 30400, Train loss: 3.117e+02, Test loss: 8.890e+03, MSE(e): 1.867e-05, MSE(pi1): 3.169e-03, MSE(pi2): 1.558e-05, MSE(pi3): 9.330e-04\n",
      "Epoch 30500, Train loss: 3.109e+02, Test loss: 8.864e+03, MSE(e): 1.859e-05, MSE(pi1): 3.177e-03, MSE(pi2): 1.552e-05, MSE(pi3): 9.318e-04\n",
      "Epoch 30600, Train loss: 3.097e+02, Test loss: 8.837e+03, MSE(e): 1.850e-05, MSE(pi1): 3.173e-03, MSE(pi2): 1.546e-05, MSE(pi3): 9.290e-04\n",
      "Epoch 30700, Train loss: 3.087e+02, Test loss: 8.811e+03, MSE(e): 1.842e-05, MSE(pi1): 3.174e-03, MSE(pi2): 1.540e-05, MSE(pi3): 9.274e-04\n",
      "Epoch 30800, Train loss: 3.077e+02, Test loss: 8.786e+03, MSE(e): 1.834e-05, MSE(pi1): 3.178e-03, MSE(pi2): 1.534e-05, MSE(pi3): 9.251e-04\n",
      "Epoch 30900, Train loss: 3.069e+02, Test loss: 8.760e+03, MSE(e): 1.826e-05, MSE(pi1): 3.183e-03, MSE(pi2): 1.528e-05, MSE(pi3): 9.240e-04\n",
      "Epoch 31000, Train loss: 3.058e+02, Test loss: 8.735e+03, MSE(e): 1.819e-05, MSE(pi1): 3.182e-03, MSE(pi2): 1.522e-05, MSE(pi3): 9.216e-04\n",
      "Epoch 31100, Train loss: 3.050e+02, Test loss: 8.709e+03, MSE(e): 1.811e-05, MSE(pi1): 3.166e-03, MSE(pi2): 1.516e-05, MSE(pi3): 9.222e-04\n",
      "Epoch 31200, Train loss: 3.040e+02, Test loss: 8.684e+03, MSE(e): 1.803e-05, MSE(pi1): 3.171e-03, MSE(pi2): 1.511e-05, MSE(pi3): 9.193e-04\n",
      "Epoch 31300, Train loss: 3.031e+02, Test loss: 8.659e+03, MSE(e): 1.795e-05, MSE(pi1): 3.187e-03, MSE(pi2): 1.505e-05, MSE(pi3): 9.167e-04\n",
      "Epoch 31400, Train loss: 3.022e+02, Test loss: 8.634e+03, MSE(e): 1.788e-05, MSE(pi1): 3.169e-03, MSE(pi2): 1.499e-05, MSE(pi3): 9.167e-04\n",
      "Epoch 31500, Train loss: 3.013e+02, Test loss: 8.609e+03, MSE(e): 1.780e-05, MSE(pi1): 3.172e-03, MSE(pi2): 1.493e-05, MSE(pi3): 9.147e-04\n",
      "Epoch 31600, Train loss: 3.004e+02, Test loss: 8.585e+03, MSE(e): 1.773e-05, MSE(pi1): 3.152e-03, MSE(pi2): 1.487e-05, MSE(pi3): 9.150e-04\n",
      "Epoch 31700, Train loss: 2.994e+02, Test loss: 8.560e+03, MSE(e): 1.766e-05, MSE(pi1): 3.152e-03, MSE(pi2): 1.482e-05, MSE(pi3): 9.131e-04\n",
      "Epoch 31800, Train loss: 2.986e+02, Test loss: 8.536e+03, MSE(e): 1.758e-05, MSE(pi1): 3.155e-03, MSE(pi2): 1.476e-05, MSE(pi3): 9.118e-04\n",
      "Epoch 31900, Train loss: 2.977e+02, Test loss: 8.512e+03, MSE(e): 1.751e-05, MSE(pi1): 3.161e-03, MSE(pi2): 1.471e-05, MSE(pi3): 9.092e-04\n",
      "Epoch 32000, Train loss: 2.968e+02, Test loss: 8.488e+03, MSE(e): 1.744e-05, MSE(pi1): 3.160e-03, MSE(pi2): 1.465e-05, MSE(pi3): 9.081e-04\n",
      "Epoch 32100, Train loss: 2.959e+02, Test loss: 8.464e+03, MSE(e): 1.737e-05, MSE(pi1): 3.155e-03, MSE(pi2): 1.460e-05, MSE(pi3): 9.064e-04\n",
      "Epoch 32200, Train loss: 2.951e+02, Test loss: 8.440e+03, MSE(e): 1.730e-05, MSE(pi1): 3.150e-03, MSE(pi2): 1.454e-05, MSE(pi3): 9.058e-04\n",
      "Epoch 32300, Train loss: 2.941e+02, Test loss: 8.417e+03, MSE(e): 1.722e-05, MSE(pi1): 3.169e-03, MSE(pi2): 1.449e-05, MSE(pi3): 9.026e-04\n",
      "Epoch 32400, Train loss: 2.933e+02, Test loss: 8.393e+03, MSE(e): 1.715e-05, MSE(pi1): 3.169e-03, MSE(pi2): 1.443e-05, MSE(pi3): 9.008e-04\n",
      "Epoch 32500, Train loss: 2.925e+02, Test loss: 8.370e+03, MSE(e): 1.708e-05, MSE(pi1): 3.162e-03, MSE(pi2): 1.438e-05, MSE(pi3): 9.001e-04\n",
      "Epoch 32600, Train loss: 2.916e+02, Test loss: 8.346e+03, MSE(e): 1.701e-05, MSE(pi1): 3.152e-03, MSE(pi2): 1.433e-05, MSE(pi3): 8.991e-04\n",
      "Epoch 32700, Train loss: 2.909e+02, Test loss: 8.324e+03, MSE(e): 1.695e-05, MSE(pi1): 3.134e-03, MSE(pi2): 1.427e-05, MSE(pi3): 9.006e-04\n",
      "Epoch 32800, Train loss: 2.900e+02, Test loss: 8.300e+03, MSE(e): 1.688e-05, MSE(pi1): 3.163e-03, MSE(pi2): 1.422e-05, MSE(pi3): 8.957e-04\n",
      "Epoch 32900, Train loss: 2.891e+02, Test loss: 8.278e+03, MSE(e): 1.681e-05, MSE(pi1): 3.152e-03, MSE(pi2): 1.417e-05, MSE(pi3): 8.949e-04\n",
      "Epoch 33000, Train loss: 2.884e+02, Test loss: 8.255e+03, MSE(e): 1.675e-05, MSE(pi1): 3.150e-03, MSE(pi2): 1.412e-05, MSE(pi3): 8.938e-04\n",
      "Epoch 33100, Train loss: 2.875e+02, Test loss: 8.232e+03, MSE(e): 1.668e-05, MSE(pi1): 3.140e-03, MSE(pi2): 1.407e-05, MSE(pi3): 8.929e-04\n",
      "Epoch 33200, Train loss: 2.868e+02, Test loss: 8.210e+03, MSE(e): 1.662e-05, MSE(pi1): 3.135e-03, MSE(pi2): 1.401e-05, MSE(pi3): 8.924e-04\n",
      "Epoch 33300, Train loss: 2.859e+02, Test loss: 8.187e+03, MSE(e): 1.655e-05, MSE(pi1): 3.150e-03, MSE(pi2): 1.396e-05, MSE(pi3): 8.893e-04\n",
      "Epoch 33400, Train loss: 2.851e+02, Test loss: 8.165e+03, MSE(e): 1.648e-05, MSE(pi1): 3.148e-03, MSE(pi2): 1.391e-05, MSE(pi3): 8.879e-04\n",
      "Epoch 33500, Train loss: 2.844e+02, Test loss: 8.143e+03, MSE(e): 1.643e-05, MSE(pi1): 3.136e-03, MSE(pi2): 1.386e-05, MSE(pi3): 8.881e-04\n",
      "Epoch 33600, Train loss: 2.837e+02, Test loss: 8.122e+03, MSE(e): 1.636e-05, MSE(pi1): 3.160e-03, MSE(pi2): 1.381e-05, MSE(pi3): 8.843e-04\n",
      "Epoch 33700, Train loss: 2.829e+02, Test loss: 8.099e+03, MSE(e): 1.630e-05, MSE(pi1): 3.139e-03, MSE(pi2): 1.377e-05, MSE(pi3): 8.846e-04\n",
      "Epoch 33800, Train loss: 2.820e+02, Test loss: 8.078e+03, MSE(e): 1.623e-05, MSE(pi1): 3.138e-03, MSE(pi2): 1.372e-05, MSE(pi3): 8.829e-04\n",
      "Epoch 33900, Train loss: 2.813e+02, Test loss: 8.056e+03, MSE(e): 1.617e-05, MSE(pi1): 3.135e-03, MSE(pi2): 1.367e-05, MSE(pi3): 8.822e-04\n",
      "Epoch 34000, Train loss: 2.805e+02, Test loss: 8.035e+03, MSE(e): 1.611e-05, MSE(pi1): 3.159e-03, MSE(pi2): 1.362e-05, MSE(pi3): 8.780e-04\n",
      "Epoch 34100, Train loss: 2.798e+02, Test loss: 8.013e+03, MSE(e): 1.605e-05, MSE(pi1): 3.129e-03, MSE(pi2): 1.357e-05, MSE(pi3): 8.793e-04\n",
      "Epoch 34200, Train loss: 2.790e+02, Test loss: 7.992e+03, MSE(e): 1.599e-05, MSE(pi1): 3.131e-03, MSE(pi2): 1.353e-05, MSE(pi3): 8.773e-04\n",
      "Epoch 34300, Train loss: 2.783e+02, Test loss: 7.971e+03, MSE(e): 1.593e-05, MSE(pi1): 3.151e-03, MSE(pi2): 1.348e-05, MSE(pi3): 8.744e-04\n",
      "Epoch 34400, Train loss: 2.775e+02, Test loss: 7.950e+03, MSE(e): 1.587e-05, MSE(pi1): 3.137e-03, MSE(pi2): 1.343e-05, MSE(pi3): 8.741e-04\n",
      "Epoch 34500, Train loss: 2.768e+02, Test loss: 7.930e+03, MSE(e): 1.581e-05, MSE(pi1): 3.143e-03, MSE(pi2): 1.339e-05, MSE(pi3): 8.723e-04\n",
      "Epoch 34600, Train loss: 2.761e+02, Test loss: 7.909e+03, MSE(e): 1.575e-05, MSE(pi1): 3.138e-03, MSE(pi2): 1.334e-05, MSE(pi3): 8.715e-04\n",
      "Epoch 34700, Train loss: 2.754e+02, Test loss: 7.888e+03, MSE(e): 1.569e-05, MSE(pi1): 3.138e-03, MSE(pi2): 1.330e-05, MSE(pi3): 8.701e-04\n",
      "Epoch 34800, Train loss: 2.746e+02, Test loss: 7.867e+03, MSE(e): 1.564e-05, MSE(pi1): 3.133e-03, MSE(pi2): 1.325e-05, MSE(pi3): 8.689e-04\n",
      "Epoch 34900, Train loss: 2.740e+02, Test loss: 7.847e+03, MSE(e): 1.558e-05, MSE(pi1): 3.144e-03, MSE(pi2): 1.321e-05, MSE(pi3): 8.671e-04\n",
      "Epoch 35000, Train loss: 2.733e+02, Test loss: 7.827e+03, MSE(e): 1.553e-05, MSE(pi1): 3.134e-03, MSE(pi2): 1.316e-05, MSE(pi3): 8.663e-04\n",
      "Epoch 35100, Train loss: 2.726e+02, Test loss: 7.807e+03, MSE(e): 1.547e-05, MSE(pi1): 3.129e-03, MSE(pi2): 1.312e-05, MSE(pi3): 8.655e-04\n",
      "Epoch 35200, Train loss: 2.719e+02, Test loss: 7.786e+03, MSE(e): 1.542e-05, MSE(pi1): 3.123e-03, MSE(pi2): 1.308e-05, MSE(pi3): 8.647e-04\n",
      "Epoch 35300, Train loss: 2.713e+02, Test loss: 7.766e+03, MSE(e): 1.537e-05, MSE(pi1): 3.134e-03, MSE(pi2): 1.303e-05, MSE(pi3): 8.625e-04\n",
      "Epoch 35400, Train loss: 2.706e+02, Test loss: 7.747e+03, MSE(e): 1.531e-05, MSE(pi1): 3.130e-03, MSE(pi2): 1.299e-05, MSE(pi3): 8.621e-04\n",
      "Epoch 35500, Train loss: 2.699e+02, Test loss: 7.726e+03, MSE(e): 1.526e-05, MSE(pi1): 3.121e-03, MSE(pi2): 1.295e-05, MSE(pi3): 8.610e-04\n",
      "Epoch 35600, Train loss: 2.693e+02, Test loss: 7.707e+03, MSE(e): 1.521e-05, MSE(pi1): 3.117e-03, MSE(pi2): 1.291e-05, MSE(pi3): 8.604e-04\n",
      "Epoch 35700, Train loss: 2.688e+02, Test loss: 7.687e+03, MSE(e): 1.516e-05, MSE(pi1): 3.134e-03, MSE(pi2): 1.287e-05, MSE(pi3): 8.579e-04\n",
      "Epoch 35800, Train loss: 2.683e+02, Test loss: 7.667e+03, MSE(e): 1.511e-05, MSE(pi1): 3.141e-03, MSE(pi2): 1.283e-05, MSE(pi3): 8.572e-04\n",
      "Epoch 35900, Train loss: 2.676e+02, Test loss: 7.647e+03, MSE(e): 1.507e-05, MSE(pi1): 3.115e-03, MSE(pi2): 1.279e-05, MSE(pi3): 8.575e-04\n",
      "Epoch 36000, Train loss: 2.670e+02, Test loss: 7.627e+03, MSE(e): 1.502e-05, MSE(pi1): 3.101e-03, MSE(pi2): 1.275e-05, MSE(pi3): 8.571e-04\n",
      "Epoch 36100, Train loss: 2.665e+02, Test loss: 7.607e+03, MSE(e): 1.498e-05, MSE(pi1): 3.129e-03, MSE(pi2): 1.271e-05, MSE(pi3): 8.537e-04\n",
      "Epoch 36200, Train loss: 2.658e+02, Test loss: 7.586e+03, MSE(e): 1.493e-05, MSE(pi1): 3.116e-03, MSE(pi2): 1.268e-05, MSE(pi3): 8.526e-04\n",
      "Epoch 36300, Train loss: 2.648e+02, Test loss: 7.563e+03, MSE(e): 1.484e-05, MSE(pi1): 3.115e-03, MSE(pi2): 1.264e-05, MSE(pi3): 8.517e-04\n",
      "Epoch 36400, Train loss: 2.640e+02, Test loss: 7.544e+03, MSE(e): 1.478e-05, MSE(pi1): 3.130e-03, MSE(pi2): 1.260e-05, MSE(pi3): 8.494e-04\n",
      "Epoch 36500, Train loss: 2.636e+02, Test loss: 7.528e+03, MSE(e): 1.475e-05, MSE(pi1): 3.092e-03, MSE(pi2): 1.256e-05, MSE(pi3): 8.519e-04\n",
      "Epoch 36600, Train loss: 2.630e+02, Test loss: 7.512e+03, MSE(e): 1.471e-05, MSE(pi1): 3.100e-03, MSE(pi2): 1.252e-05, MSE(pi3): 8.493e-04\n",
      "Epoch 36700, Train loss: 2.624e+02, Test loss: 7.496e+03, MSE(e): 1.466e-05, MSE(pi1): 3.087e-03, MSE(pi2): 1.248e-05, MSE(pi3): 8.495e-04\n",
      "Epoch 36800, Train loss: 2.618e+02, Test loss: 7.480e+03, MSE(e): 1.461e-05, MSE(pi1): 3.092e-03, MSE(pi2): 1.244e-05, MSE(pi3): 8.475e-04\n",
      "Epoch 36900, Train loss: 2.612e+02, Test loss: 7.463e+03, MSE(e): 1.457e-05, MSE(pi1): 3.097e-03, MSE(pi2): 1.240e-05, MSE(pi3): 8.455e-04\n",
      "Epoch 37000, Train loss: 2.606e+02, Test loss: 7.446e+03, MSE(e): 1.452e-05, MSE(pi1): 3.100e-03, MSE(pi2): 1.236e-05, MSE(pi3): 8.440e-04\n",
      "Epoch 37100, Train loss: 2.600e+02, Test loss: 7.429e+03, MSE(e): 1.448e-05, MSE(pi1): 3.079e-03, MSE(pi2): 1.233e-05, MSE(pi3): 8.447e-04\n",
      "Epoch 37200, Train loss: 2.594e+02, Test loss: 7.410e+03, MSE(e): 1.443e-05, MSE(pi1): 3.085e-03, MSE(pi2): 1.229e-05, MSE(pi3): 8.427e-04\n",
      "Epoch 37300, Train loss: 2.587e+02, Test loss: 7.392e+03, MSE(e): 1.437e-05, MSE(pi1): 3.091e-03, MSE(pi2): 1.226e-05, MSE(pi3): 8.413e-04\n",
      "Epoch 37400, Train loss: 2.580e+02, Test loss: 7.373e+03, MSE(e): 1.430e-05, MSE(pi1): 3.079e-03, MSE(pi2): 1.222e-05, MSE(pi3): 8.418e-04\n",
      "Epoch 37500, Train loss: 2.575e+02, Test loss: 7.356e+03, MSE(e): 1.425e-05, MSE(pi1): 3.068e-03, MSE(pi2): 1.218e-05, MSE(pi3): 8.423e-04\n",
      "Epoch 37600, Train loss: 2.568e+02, Test loss: 7.341e+03, MSE(e): 1.421e-05, MSE(pi1): 3.075e-03, MSE(pi2): 1.215e-05, MSE(pi3): 8.390e-04\n",
      "Epoch 37700, Train loss: 2.563e+02, Test loss: 7.326e+03, MSE(e): 1.417e-05, MSE(pi1): 3.083e-03, MSE(pi2): 1.211e-05, MSE(pi3): 8.374e-04\n",
      "Epoch 37800, Train loss: 2.558e+02, Test loss: 7.311e+03, MSE(e): 1.413e-05, MSE(pi1): 3.058e-03, MSE(pi2): 1.207e-05, MSE(pi3): 8.385e-04\n",
      "Epoch 37900, Train loss: 2.552e+02, Test loss: 7.296e+03, MSE(e): 1.409e-05, MSE(pi1): 3.066e-03, MSE(pi2): 1.204e-05, MSE(pi3): 8.362e-04\n",
      "Epoch 38000, Train loss: 2.547e+02, Test loss: 7.280e+03, MSE(e): 1.405e-05, MSE(pi1): 3.069e-03, MSE(pi2): 1.200e-05, MSE(pi3): 8.348e-04\n",
      "Epoch 38100, Train loss: 2.542e+02, Test loss: 7.264e+03, MSE(e): 1.401e-05, MSE(pi1): 3.067e-03, MSE(pi2): 1.196e-05, MSE(pi3): 8.344e-04\n",
      "Epoch 38200, Train loss: 2.536e+02, Test loss: 7.246e+03, MSE(e): 1.396e-05, MSE(pi1): 3.062e-03, MSE(pi2): 1.193e-05, MSE(pi3): 8.341e-04\n",
      "Epoch 38300, Train loss: 2.530e+02, Test loss: 7.229e+03, MSE(e): 1.390e-05, MSE(pi1): 3.059e-03, MSE(pi2): 1.189e-05, MSE(pi3): 8.338e-04\n",
      "Epoch 38400, Train loss: 2.521e+02, Test loss: 7.211e+03, MSE(e): 1.384e-05, MSE(pi1): 3.075e-03, MSE(pi2): 1.186e-05, MSE(pi3): 8.303e-04\n",
      "Epoch 38500, Train loss: 2.519e+02, Test loss: 7.196e+03, MSE(e): 1.380e-05, MSE(pi1): 3.069e-03, MSE(pi2): 1.183e-05, MSE(pi3): 8.319e-04\n",
      "Epoch 38600, Train loss: 2.511e+02, Test loss: 7.181e+03, MSE(e): 1.376e-05, MSE(pi1): 3.053e-03, MSE(pi2): 1.179e-05, MSE(pi3): 8.298e-04\n",
      "Epoch 38700, Train loss: 2.506e+02, Test loss: 7.167e+03, MSE(e): 1.372e-05, MSE(pi1): 3.061e-03, MSE(pi2): 1.176e-05, MSE(pi3): 8.282e-04\n",
      "Epoch 38800, Train loss: 2.502e+02, Test loss: 7.153e+03, MSE(e): 1.368e-05, MSE(pi1): 3.072e-03, MSE(pi2): 1.172e-05, MSE(pi3): 8.262e-04\n",
      "Epoch 38900, Train loss: 2.498e+02, Test loss: 7.138e+03, MSE(e): 1.364e-05, MSE(pi1): 3.081e-03, MSE(pi2): 1.169e-05, MSE(pi3): 8.258e-04\n",
      "Epoch 39000, Train loss: 2.490e+02, Test loss: 7.122e+03, MSE(e): 1.359e-05, MSE(pi1): 3.051e-03, MSE(pi2): 1.165e-05, MSE(pi3): 8.254e-04\n",
      "Epoch 39100, Train loss: 2.485e+02, Test loss: 7.106e+03, MSE(e): 1.355e-05, MSE(pi1): 3.062e-03, MSE(pi2): 1.162e-05, MSE(pi3): 8.238e-04\n",
      "Epoch 39200, Train loss: 2.479e+02, Test loss: 7.090e+03, MSE(e): 1.350e-05, MSE(pi1): 3.047e-03, MSE(pi2): 1.159e-05, MSE(pi3): 8.238e-04\n",
      "Epoch 39300, Train loss: 2.473e+02, Test loss: 7.073e+03, MSE(e): 1.344e-05, MSE(pi1): 3.037e-03, MSE(pi2): 1.156e-05, MSE(pi3): 8.244e-04\n",
      "Epoch 39400, Train loss: 2.467e+02, Test loss: 7.058e+03, MSE(e): 1.340e-05, MSE(pi1): 3.033e-03, MSE(pi2): 1.153e-05, MSE(pi3): 8.229e-04\n",
      "Epoch 39500, Train loss: 2.463e+02, Test loss: 7.044e+03, MSE(e): 1.337e-05, MSE(pi1): 3.027e-03, MSE(pi2): 1.149e-05, MSE(pi3): 8.230e-04\n",
      "Epoch 39600, Train loss: 2.457e+02, Test loss: 7.030e+03, MSE(e): 1.333e-05, MSE(pi1): 3.038e-03, MSE(pi2): 1.146e-05, MSE(pi3): 8.202e-04\n",
      "Epoch 39700, Train loss: 2.453e+02, Test loss: 7.016e+03, MSE(e): 1.330e-05, MSE(pi1): 3.027e-03, MSE(pi2): 1.143e-05, MSE(pi3): 8.207e-04\n",
      "Epoch 39800, Train loss: 2.448e+02, Test loss: 7.002e+03, MSE(e): 1.325e-05, MSE(pi1): 3.017e-03, MSE(pi2): 1.139e-05, MSE(pi3): 8.203e-04\n",
      "Epoch 39900, Train loss: 2.443e+02, Test loss: 6.988e+03, MSE(e): 1.321e-05, MSE(pi1): 3.048e-03, MSE(pi2): 1.136e-05, MSE(pi3): 8.170e-04\n",
      "Epoch 40000, Train loss: 2.438e+02, Test loss: 6.972e+03, MSE(e): 1.316e-05, MSE(pi1): 3.048e-03, MSE(pi2): 1.133e-05, MSE(pi3): 8.162e-04\n",
      "Epoch 40100, Train loss: 2.434e+02, Test loss: 6.957e+03, MSE(e): 1.312e-05, MSE(pi1): 3.086e-03, MSE(pi2): 1.130e-05, MSE(pi3): 8.133e-04\n",
      "Epoch 40200, Train loss: 2.425e+02, Test loss: 6.941e+03, MSE(e): 1.307e-05, MSE(pi1): 3.024e-03, MSE(pi2): 1.127e-05, MSE(pi3): 8.154e-04\n",
      "Epoch 40300, Train loss: 2.421e+02, Test loss: 6.927e+03, MSE(e): 1.304e-05, MSE(pi1): 3.026e-03, MSE(pi2): 1.124e-05, MSE(pi3): 8.150e-04\n",
      "Epoch 40400, Train loss: 2.417e+02, Test loss: 6.914e+03, MSE(e): 1.300e-05, MSE(pi1): 3.019e-03, MSE(pi2): 1.121e-05, MSE(pi3): 8.143e-04\n",
      "Epoch 40500, Train loss: 2.412e+02, Test loss: 6.900e+03, MSE(e): 1.297e-05, MSE(pi1): 3.021e-03, MSE(pi2): 1.117e-05, MSE(pi3): 8.134e-04\n",
      "Epoch 40600, Train loss: 2.407e+02, Test loss: 6.887e+03, MSE(e): 1.293e-05, MSE(pi1): 3.020e-03, MSE(pi2): 1.114e-05, MSE(pi3): 8.120e-04\n",
      "Epoch 40700, Train loss: 2.404e+02, Test loss: 6.873e+03, MSE(e): 1.289e-05, MSE(pi1): 3.016e-03, MSE(pi2): 1.111e-05, MSE(pi3): 8.132e-04\n",
      "Epoch 40800, Train loss: 2.397e+02, Test loss: 6.858e+03, MSE(e): 1.285e-05, MSE(pi1): 3.003e-03, MSE(pi2): 1.108e-05, MSE(pi3): 8.115e-04\n",
      "Epoch 40900, Train loss: 2.391e+02, Test loss: 6.843e+03, MSE(e): 1.280e-05, MSE(pi1): 3.011e-03, MSE(pi2): 1.105e-05, MSE(pi3): 8.097e-04\n",
      "Epoch 41000, Train loss: 2.387e+02, Test loss: 6.829e+03, MSE(e): 1.276e-05, MSE(pi1): 3.000e-03, MSE(pi2): 1.102e-05, MSE(pi3): 8.105e-04\n",
      "Epoch 41100, Train loss: 2.383e+02, Test loss: 6.815e+03, MSE(e): 1.272e-05, MSE(pi1): 3.026e-03, MSE(pi2): 1.099e-05, MSE(pi3): 8.081e-04\n",
      "Epoch 41200, Train loss: 2.375e+02, Test loss: 6.801e+03, MSE(e): 1.268e-05, MSE(pi1): 3.008e-03, MSE(pi2): 1.096e-05, MSE(pi3): 8.065e-04\n",
      "Epoch 41300, Train loss: 2.371e+02, Test loss: 6.788e+03, MSE(e): 1.265e-05, MSE(pi1): 3.003e-03, MSE(pi2): 1.093e-05, MSE(pi3): 8.062e-04\n",
      "Epoch 41400, Train loss: 2.368e+02, Test loss: 6.775e+03, MSE(e): 1.262e-05, MSE(pi1): 2.994e-03, MSE(pi2): 1.090e-05, MSE(pi3): 8.065e-04\n",
      "Epoch 41500, Train loss: 2.363e+02, Test loss: 6.762e+03, MSE(e): 1.258e-05, MSE(pi1): 3.011e-03, MSE(pi2): 1.087e-05, MSE(pi3): 8.042e-04\n",
      "Epoch 41600, Train loss: 2.358e+02, Test loss: 6.748e+03, MSE(e): 1.254e-05, MSE(pi1): 2.995e-03, MSE(pi2): 1.084e-05, MSE(pi3): 8.041e-04\n",
      "Epoch 41700, Train loss: 2.352e+02, Test loss: 6.734e+03, MSE(e): 1.250e-05, MSE(pi1): 2.994e-03, MSE(pi2): 1.081e-05, MSE(pi3): 8.032e-04\n",
      "Epoch 41800, Train loss: 2.347e+02, Test loss: 6.720e+03, MSE(e): 1.246e-05, MSE(pi1): 2.992e-03, MSE(pi2): 1.078e-05, MSE(pi3): 8.024e-04\n",
      "Epoch 41900, Train loss: 2.345e+02, Test loss: 6.707e+03, MSE(e): 1.242e-05, MSE(pi1): 3.018e-03, MSE(pi2): 1.076e-05, MSE(pi3): 8.008e-04\n",
      "Epoch 42000, Train loss: 2.341e+02, Test loss: 6.694e+03, MSE(e): 1.239e-05, MSE(pi1): 3.021e-03, MSE(pi2): 1.073e-05, MSE(pi3): 8.001e-04\n",
      "Epoch 42100, Train loss: 2.336e+02, Test loss: 6.682e+03, MSE(e): 1.235e-05, MSE(pi1): 3.016e-03, MSE(pi2): 1.070e-05, MSE(pi3): 7.994e-04\n",
      "Epoch 42200, Train loss: 2.331e+02, Test loss: 6.669e+03, MSE(e): 1.232e-05, MSE(pi1): 2.986e-03, MSE(pi2): 1.067e-05, MSE(pi3): 8.001e-04\n",
      "Epoch 42300, Train loss: 2.326e+02, Test loss: 6.655e+03, MSE(e): 1.228e-05, MSE(pi1): 2.983e-03, MSE(pi2): 1.064e-05, MSE(pi3): 7.987e-04\n",
      "Epoch 42400, Train loss: 2.321e+02, Test loss: 6.642e+03, MSE(e): 1.224e-05, MSE(pi1): 2.979e-03, MSE(pi2): 1.061e-05, MSE(pi3): 7.981e-04\n",
      "Epoch 42500, Train loss: 2.316e+02, Test loss: 6.629e+03, MSE(e): 1.221e-05, MSE(pi1): 2.984e-03, MSE(pi2): 1.059e-05, MSE(pi3): 7.970e-04\n",
      "Epoch 42600, Train loss: 2.312e+02, Test loss: 6.615e+03, MSE(e): 1.217e-05, MSE(pi1): 2.981e-03, MSE(pi2): 1.056e-05, MSE(pi3): 7.971e-04\n",
      "Epoch 42700, Train loss: 2.307e+02, Test loss: 6.602e+03, MSE(e): 1.213e-05, MSE(pi1): 2.981e-03, MSE(pi2): 1.053e-05, MSE(pi3): 7.956e-04\n",
      "Epoch 42800, Train loss: 2.302e+02, Test loss: 6.590e+03, MSE(e): 1.210e-05, MSE(pi1): 2.982e-03, MSE(pi2): 1.051e-05, MSE(pi3): 7.943e-04\n",
      "Epoch 42900, Train loss: 2.298e+02, Test loss: 6.577e+03, MSE(e): 1.206e-05, MSE(pi1): 2.984e-03, MSE(pi2): 1.048e-05, MSE(pi3): 7.932e-04\n",
      "Epoch 43000, Train loss: 2.295e+02, Test loss: 6.566e+03, MSE(e): 1.203e-05, MSE(pi1): 2.971e-03, MSE(pi2): 1.045e-05, MSE(pi3): 7.947e-04\n",
      "Epoch 43100, Train loss: 2.290e+02, Test loss: 6.553e+03, MSE(e): 1.200e-05, MSE(pi1): 2.978e-03, MSE(pi2): 1.042e-05, MSE(pi3): 7.922e-04\n",
      "Epoch 43200, Train loss: 2.285e+02, Test loss: 6.540e+03, MSE(e): 1.196e-05, MSE(pi1): 2.970e-03, MSE(pi2): 1.040e-05, MSE(pi3): 7.921e-04\n",
      "Epoch 43300, Train loss: 2.280e+02, Test loss: 6.526e+03, MSE(e): 1.192e-05, MSE(pi1): 2.972e-03, MSE(pi2): 1.037e-05, MSE(pi3): 7.906e-04\n",
      "Epoch 43400, Train loss: 2.278e+02, Test loss: 6.515e+03, MSE(e): 1.189e-05, MSE(pi1): 2.993e-03, MSE(pi2): 1.034e-05, MSE(pi3): 7.893e-04\n",
      "Epoch 43500, Train loss: 2.271e+02, Test loss: 6.501e+03, MSE(e): 1.185e-05, MSE(pi1): 2.962e-03, MSE(pi2): 1.032e-05, MSE(pi3): 7.897e-04\n",
      "Epoch 43600, Train loss: 2.268e+02, Test loss: 6.490e+03, MSE(e): 1.182e-05, MSE(pi1): 2.949e-03, MSE(pi2): 1.029e-05, MSE(pi3): 7.903e-04\n",
      "Epoch 43700, Train loss: 2.264e+02, Test loss: 6.477e+03, MSE(e): 1.179e-05, MSE(pi1): 2.950e-03, MSE(pi2): 1.026e-05, MSE(pi3): 7.894e-04\n",
      "Epoch 43800, Train loss: 2.261e+02, Test loss: 6.466e+03, MSE(e): 1.176e-05, MSE(pi1): 2.967e-03, MSE(pi2): 1.024e-05, MSE(pi3): 7.883e-04\n",
      "Epoch 43900, Train loss: 2.255e+02, Test loss: 6.453e+03, MSE(e): 1.172e-05, MSE(pi1): 2.944e-03, MSE(pi2): 1.021e-05, MSE(pi3): 7.882e-04\n",
      "Epoch 44000, Train loss: 2.251e+02, Test loss: 6.441e+03, MSE(e): 1.169e-05, MSE(pi1): 2.954e-03, MSE(pi2): 1.019e-05, MSE(pi3): 7.869e-04\n",
      "Epoch 44100, Train loss: 2.247e+02, Test loss: 6.429e+03, MSE(e): 1.166e-05, MSE(pi1): 2.941e-03, MSE(pi2): 1.016e-05, MSE(pi3): 7.873e-04\n",
      "Epoch 44200, Train loss: 2.243e+02, Test loss: 6.417e+03, MSE(e): 1.162e-05, MSE(pi1): 2.950e-03, MSE(pi2): 1.014e-05, MSE(pi3): 7.856e-04\n",
      "Epoch 44300, Train loss: 2.238e+02, Test loss: 6.405e+03, MSE(e): 1.159e-05, MSE(pi1): 2.943e-03, MSE(pi2): 1.011e-05, MSE(pi3): 7.850e-04\n",
      "Epoch 44400, Train loss: 2.235e+02, Test loss: 6.393e+03, MSE(e): 1.156e-05, MSE(pi1): 2.941e-03, MSE(pi2): 1.009e-05, MSE(pi3): 7.847e-04\n",
      "Epoch 44500, Train loss: 2.232e+02, Test loss: 6.382e+03, MSE(e): 1.153e-05, MSE(pi1): 2.946e-03, MSE(pi2): 1.006e-05, MSE(pi3): 7.845e-04\n",
      "Epoch 44600, Train loss: 2.227e+02, Test loss: 6.370e+03, MSE(e): 1.150e-05, MSE(pi1): 2.933e-03, MSE(pi2): 1.003e-05, MSE(pi3): 7.834e-04\n",
      "Epoch 44700, Train loss: 2.223e+02, Test loss: 6.358e+03, MSE(e): 1.147e-05, MSE(pi1): 2.940e-03, MSE(pi2): 1.001e-05, MSE(pi3): 7.821e-04\n",
      "Epoch 44800, Train loss: 2.221e+02, Test loss: 6.346e+03, MSE(e): 1.143e-05, MSE(pi1): 2.944e-03, MSE(pi2): 9.982e-06, MSE(pi3): 7.830e-04\n",
      "Epoch 44900, Train loss: 2.216e+02, Test loss: 6.334e+03, MSE(e): 1.140e-05, MSE(pi1): 2.917e-03, MSE(pi2): 9.959e-06, MSE(pi3): 7.843e-04\n",
      "Epoch 45000, Train loss: 2.212e+02, Test loss: 6.322e+03, MSE(e): 1.137e-05, MSE(pi1): 2.936e-03, MSE(pi2): 9.934e-06, MSE(pi3): 7.816e-04\n",
      "Epoch 45100, Train loss: 2.208e+02, Test loss: 6.311e+03, MSE(e): 1.134e-05, MSE(pi1): 2.929e-03, MSE(pi2): 9.910e-06, MSE(pi3): 7.809e-04\n",
      "Epoch 45200, Train loss: 2.203e+02, Test loss: 6.300e+03, MSE(e): 1.131e-05, MSE(pi1): 2.931e-03, MSE(pi2): 9.887e-06, MSE(pi3): 7.789e-04\n",
      "Epoch 45300, Train loss: 2.199e+02, Test loss: 6.288e+03, MSE(e): 1.128e-05, MSE(pi1): 2.925e-03, MSE(pi2): 9.862e-06, MSE(pi3): 7.791e-04\n",
      "Epoch 45400, Train loss: 2.199e+02, Test loss: 6.278e+03, MSE(e): 1.125e-05, MSE(pi1): 2.989e-03, MSE(pi2): 9.840e-06, MSE(pi3): 7.751e-04\n",
      "Epoch 45500, Train loss: 2.195e+02, Test loss: 6.265e+03, MSE(e): 1.121e-05, MSE(pi1): 2.939e-03, MSE(pi2): 9.817e-06, MSE(pi3): 7.795e-04\n",
      "Epoch 45600, Train loss: 2.189e+02, Test loss: 6.254e+03, MSE(e): 1.119e-05, MSE(pi1): 2.936e-03, MSE(pi2): 9.792e-06, MSE(pi3): 7.767e-04\n",
      "Epoch 45700, Train loss: 2.184e+02, Test loss: 6.242e+03, MSE(e): 1.115e-05, MSE(pi1): 2.920e-03, MSE(pi2): 9.768e-06, MSE(pi3): 7.764e-04\n",
      "Epoch 45800, Train loss: 2.180e+02, Test loss: 6.231e+03, MSE(e): 1.112e-05, MSE(pi1): 2.927e-03, MSE(pi2): 9.744e-06, MSE(pi3): 7.753e-04\n",
      "Epoch 45900, Train loss: 2.180e+02, Test loss: 6.221e+03, MSE(e): 1.110e-05, MSE(pi1): 2.958e-03, MSE(pi2): 9.722e-06, MSE(pi3): 7.734e-04\n",
      "Epoch 46000, Train loss: 2.173e+02, Test loss: 6.209e+03, MSE(e): 1.107e-05, MSE(pi1): 2.906e-03, MSE(pi2): 9.697e-06, MSE(pi3): 7.759e-04\n",
      "Epoch 46100, Train loss: 2.171e+02, Test loss: 6.198e+03, MSE(e): 1.104e-05, MSE(pi1): 2.942e-03, MSE(pi2): 9.675e-06, MSE(pi3): 7.730e-04\n",
      "Epoch 46200, Train loss: 2.167e+02, Test loss: 6.187e+03, MSE(e): 1.101e-05, MSE(pi1): 2.937e-03, MSE(pi2): 9.652e-06, MSE(pi3): 7.725e-04\n",
      "Epoch 46300, Train loss: 2.164e+02, Test loss: 6.176e+03, MSE(e): 1.098e-05, MSE(pi1): 2.951e-03, MSE(pi2): 9.629e-06, MSE(pi3): 7.710e-04\n",
      "Epoch 46400, Train loss: 2.158e+02, Test loss: 6.165e+03, MSE(e): 1.095e-05, MSE(pi1): 2.902e-03, MSE(pi2): 9.606e-06, MSE(pi3): 7.731e-04\n",
      "Epoch 46500, Train loss: 2.154e+02, Test loss: 6.154e+03, MSE(e): 1.091e-05, MSE(pi1): 2.899e-03, MSE(pi2): 9.584e-06, MSE(pi3): 7.729e-04\n",
      "Epoch 46600, Train loss: 2.155e+02, Test loss: 6.144e+03, MSE(e): 1.089e-05, MSE(pi1): 2.915e-03, MSE(pi2): 9.562e-06, MSE(pi3): 7.744e-04\n",
      "Epoch 46700, Train loss: 2.148e+02, Test loss: 6.132e+03, MSE(e): 1.086e-05, MSE(pi1): 2.897e-03, MSE(pi2): 9.540e-06, MSE(pi3): 7.716e-04\n",
      "Epoch 46800, Train loss: 2.144e+02, Test loss: 6.122e+03, MSE(e): 1.083e-05, MSE(pi1): 2.906e-03, MSE(pi2): 9.516e-06, MSE(pi3): 7.698e-04\n",
      "Epoch 46900, Train loss: 2.140e+02, Test loss: 6.110e+03, MSE(e): 1.080e-05, MSE(pi1): 2.895e-03, MSE(pi2): 9.495e-06, MSE(pi3): 7.708e-04\n",
      "Epoch 47000, Train loss: 2.137e+02, Test loss: 6.100e+03, MSE(e): 1.077e-05, MSE(pi1): 2.921e-03, MSE(pi2): 9.473e-06, MSE(pi3): 7.672e-04\n",
      "Epoch 47100, Train loss: 2.134e+02, Test loss: 6.089e+03, MSE(e): 1.075e-05, MSE(pi1): 2.919e-03, MSE(pi2): 9.450e-06, MSE(pi3): 7.670e-04\n",
      "Epoch 47200, Train loss: 2.130e+02, Test loss: 6.078e+03, MSE(e): 1.072e-05, MSE(pi1): 2.892e-03, MSE(pi2): 9.428e-06, MSE(pi3): 7.686e-04\n",
      "Epoch 47300, Train loss: 2.133e+02, Test loss: 6.071e+03, MSE(e): 1.071e-05, MSE(pi1): 2.971e-03, MSE(pi2): 9.408e-06, MSE(pi3): 7.646e-04\n",
      "Epoch 47400, Train loss: 2.123e+02, Test loss: 6.058e+03, MSE(e): 1.066e-05, MSE(pi1): 2.904e-03, MSE(pi2): 9.387e-06, MSE(pi3): 7.672e-04\n",
      "Epoch 47500, Train loss: 2.120e+02, Test loss: 6.047e+03, MSE(e): 1.063e-05, MSE(pi1): 2.893e-03, MSE(pi2): 9.363e-06, MSE(pi3): 7.668e-04\n",
      "Epoch 47600, Train loss: 2.116e+02, Test loss: 6.037e+03, MSE(e): 1.061e-05, MSE(pi1): 2.897e-03, MSE(pi2): 9.340e-06, MSE(pi3): 7.654e-04\n",
      "Epoch 47700, Train loss: 2.116e+02, Test loss: 6.027e+03, MSE(e): 1.059e-05, MSE(pi1): 2.918e-03, MSE(pi2): 9.319e-06, MSE(pi3): 7.653e-04\n",
      "Epoch 47800, Train loss: 2.109e+02, Test loss: 6.015e+03, MSE(e): 1.055e-05, MSE(pi1): 2.885e-03, MSE(pi2): 9.300e-06, MSE(pi3): 7.655e-04\n",
      "Epoch 47900, Train loss: 2.106e+02, Test loss: 6.005e+03, MSE(e): 1.052e-05, MSE(pi1): 2.895e-03, MSE(pi2): 9.278e-06, MSE(pi3): 7.639e-04\n",
      "Epoch 48000, Train loss: 2.103e+02, Test loss: 5.995e+03, MSE(e): 1.050e-05, MSE(pi1): 2.882e-03, MSE(pi2): 9.256e-06, MSE(pi3): 7.648e-04\n",
      "Epoch 48100, Train loss: 2.099e+02, Test loss: 5.985e+03, MSE(e): 1.047e-05, MSE(pi1): 2.879e-03, MSE(pi2): 9.235e-06, MSE(pi3): 7.637e-04\n",
      "Epoch 48200, Train loss: 2.098e+02, Test loss: 5.975e+03, MSE(e): 1.045e-05, MSE(pi1): 2.932e-03, MSE(pi2): 9.215e-06, MSE(pi3): 7.598e-04\n",
      "Epoch 48300, Train loss: 2.093e+02, Test loss: 5.964e+03, MSE(e): 1.042e-05, MSE(pi1): 2.898e-03, MSE(pi2): 9.195e-06, MSE(pi3): 7.614e-04\n",
      "Epoch 48400, Train loss: 2.089e+02, Test loss: 5.954e+03, MSE(e): 1.039e-05, MSE(pi1): 2.882e-03, MSE(pi2): 9.173e-06, MSE(pi3): 7.616e-04\n",
      "Epoch 48500, Train loss: 2.087e+02, Test loss: 5.944e+03, MSE(e): 1.037e-05, MSE(pi1): 2.905e-03, MSE(pi2): 9.153e-06, MSE(pi3): 7.599e-04\n",
      "Epoch 48600, Train loss: 2.082e+02, Test loss: 5.934e+03, MSE(e): 1.034e-05, MSE(pi1): 2.880e-03, MSE(pi2): 9.133e-06, MSE(pi3): 7.604e-04\n",
      "Epoch 48700, Train loss: 2.079e+02, Test loss: 5.924e+03, MSE(e): 1.031e-05, MSE(pi1): 2.881e-03, MSE(pi2): 9.111e-06, MSE(pi3): 7.595e-04\n",
      "Epoch 48800, Train loss: 2.079e+02, Test loss: 5.915e+03, MSE(e): 1.029e-05, MSE(pi1): 2.870e-03, MSE(pi2): 9.092e-06, MSE(pi3): 7.628e-04\n",
      "Epoch 48900, Train loss: 2.075e+02, Test loss: 5.905e+03, MSE(e): 1.027e-05, MSE(pi1): 2.865e-03, MSE(pi2): 9.070e-06, MSE(pi3): 7.612e-04\n",
      "Epoch 49000, Train loss: 2.078e+02, Test loss: 5.896e+03, MSE(e): 1.026e-05, MSE(pi1): 2.982e-03, MSE(pi2): 9.051e-06, MSE(pi3): 7.542e-04\n",
      "Epoch 49100, Train loss: 2.068e+02, Test loss: 5.884e+03, MSE(e): 1.022e-05, MSE(pi1): 2.888e-03, MSE(pi2): 9.031e-06, MSE(pi3): 7.572e-04\n",
      "Epoch 49200, Train loss: 2.063e+02, Test loss: 5.874e+03, MSE(e): 1.019e-05, MSE(pi1): 2.861e-03, MSE(pi2): 9.009e-06, MSE(pi3): 7.587e-04\n",
      "Epoch 49300, Train loss: 2.061e+02, Test loss: 5.865e+03, MSE(e): 1.016e-05, MSE(pi1): 2.887e-03, MSE(pi2): 8.990e-06, MSE(pi3): 7.558e-04\n",
      "Epoch 49400, Train loss: 2.059e+02, Test loss: 5.855e+03, MSE(e): 1.014e-05, MSE(pi1): 2.892e-03, MSE(pi2): 8.970e-06, MSE(pi3): 7.558e-04\n",
      "Epoch 49500, Train loss: 2.054e+02, Test loss: 5.845e+03, MSE(e): 1.011e-05, MSE(pi1): 2.854e-03, MSE(pi2): 8.951e-06, MSE(pi3): 7.575e-04\n",
      "Epoch 49600, Train loss: 2.051e+02, Test loss: 5.836e+03, MSE(e): 1.009e-05, MSE(pi1): 2.874e-03, MSE(pi2): 8.930e-06, MSE(pi3): 7.551e-04\n",
      "Epoch 49700, Train loss: 2.055e+02, Test loss: 5.827e+03, MSE(e): 1.008e-05, MSE(pi1): 2.956e-03, MSE(pi2): 8.912e-06, MSE(pi3): 7.511e-04\n",
      "Epoch 49800, Train loss: 2.046e+02, Test loss: 5.816e+03, MSE(e): 1.003e-05, MSE(pi1): 2.887e-03, MSE(pi2): 8.894e-06, MSE(pi3): 7.540e-04\n",
      "Epoch 49900, Train loss: 2.043e+02, Test loss: 5.806e+03, MSE(e): 1.001e-05, MSE(pi1): 2.854e-03, MSE(pi2): 8.873e-06, MSE(pi3): 7.557e-04\n",
      "Epoch 50000, Train loss: 2.039e+02, Test loss: 5.797e+03, MSE(e): 9.987e-06, MSE(pi1): 2.856e-03, MSE(pi2): 8.854e-06, MSE(pi3): 7.545e-04\n",
      "Epoch 50100, Train loss: 2.037e+02, Test loss: 5.788e+03, MSE(e): 9.967e-06, MSE(pi1): 2.869e-03, MSE(pi2): 8.834e-06, MSE(pi3): 7.528e-04\n",
      "Epoch 50200, Train loss: 2.036e+02, Test loss: 5.778e+03, MSE(e): 9.950e-06, MSE(pi1): 2.901e-03, MSE(pi2): 8.815e-06, MSE(pi3): 7.513e-04\n",
      "Epoch 50300, Train loss: 2.030e+02, Test loss: 5.768e+03, MSE(e): 9.916e-06, MSE(pi1): 2.841e-03, MSE(pi2): 8.796e-06, MSE(pi3): 7.537e-04\n",
      "Epoch 50400, Train loss: 2.027e+02, Test loss: 5.759e+03, MSE(e): 9.890e-06, MSE(pi1): 2.858e-03, MSE(pi2): 8.777e-06, MSE(pi3): 7.519e-04\n",
      "Epoch 50500, Train loss: 2.027e+02, Test loss: 5.750e+03, MSE(e): 9.874e-06, MSE(pi1): 2.898e-03, MSE(pi2): 8.759e-06, MSE(pi3): 7.494e-04\n",
      "Epoch 50600, Train loss: 2.023e+02, Test loss: 5.740e+03, MSE(e): 9.841e-06, MSE(pi1): 2.872e-03, MSE(pi2): 8.743e-06, MSE(pi3): 7.518e-04\n",
      "Epoch 50700, Train loss: 2.019e+02, Test loss: 5.731e+03, MSE(e): 9.822e-06, MSE(pi1): 2.865e-03, MSE(pi2): 8.722e-06, MSE(pi3): 7.502e-04\n",
      "Epoch 50800, Train loss: 2.017e+02, Test loss: 5.722e+03, MSE(e): 9.802e-06, MSE(pi1): 2.880e-03, MSE(pi2): 8.702e-06, MSE(pi3): 7.483e-04\n",
      "Epoch 50900, Train loss: 2.019e+02, Test loss: 5.714e+03, MSE(e): 9.787e-06, MSE(pi1): 2.927e-03, MSE(pi2): 8.685e-06, MSE(pi3): 7.470e-04\n",
      "Epoch 51000, Train loss: 2.009e+02, Test loss: 5.703e+03, MSE(e): 9.748e-06, MSE(pi1): 2.833e-03, MSE(pi2): 8.666e-06, MSE(pi3): 7.512e-04\n",
      "Epoch 51100, Train loss: 2.007e+02, Test loss: 5.694e+03, MSE(e): 9.727e-06, MSE(pi1): 2.855e-03, MSE(pi2): 8.647e-06, MSE(pi3): 7.484e-04\n",
      "Epoch 51200, Train loss: 2.009e+02, Test loss: 5.685e+03, MSE(e): 9.715e-06, MSE(pi1): 2.931e-03, MSE(pi2): 8.630e-06, MSE(pi3): 7.443e-04\n",
      "Epoch 51300, Train loss: 2.003e+02, Test loss: 5.676e+03, MSE(e): 9.679e-06, MSE(pi1): 2.848e-03, MSE(pi2): 8.614e-06, MSE(pi3): 7.502e-04\n",
      "Epoch 51400, Train loss: 1.998e+02, Test loss: 5.666e+03, MSE(e): 9.658e-06, MSE(pi1): 2.839e-03, MSE(pi2): 8.593e-06, MSE(pi3): 7.481e-04\n",
      "Epoch 51500, Train loss: 1.995e+02, Test loss: 5.657e+03, MSE(e): 9.637e-06, MSE(pi1): 2.838e-03, MSE(pi2): 8.574e-06, MSE(pi3): 7.477e-04\n",
      "Epoch 51600, Train loss: 1.995e+02, Test loss: 5.649e+03, MSE(e): 9.622e-06, MSE(pi1): 2.887e-03, MSE(pi2): 8.556e-06, MSE(pi3): 7.445e-04\n",
      "Epoch 51700, Train loss: 1.992e+02, Test loss: 5.639e+03, MSE(e): 9.589e-06, MSE(pi1): 2.820e-03, MSE(pi2): 8.541e-06, MSE(pi3): 7.515e-04\n",
      "Epoch 51800, Train loss: 1.987e+02, Test loss: 5.630e+03, MSE(e): 9.566e-06, MSE(pi1): 2.837e-03, MSE(pi2): 8.523e-06, MSE(pi3): 7.467e-04\n",
      "Epoch 51900, Train loss: 1.984e+02, Test loss: 5.621e+03, MSE(e): 9.545e-06, MSE(pi1): 2.830e-03, MSE(pi2): 8.504e-06, MSE(pi3): 7.467e-04\n",
      "Epoch 52000, Train loss: 1.984e+02, Test loss: 5.613e+03, MSE(e): 9.528e-06, MSE(pi1): 2.832e-03, MSE(pi2): 8.484e-06, MSE(pi3): 7.479e-04\n",
      "Epoch 52100, Train loss: 1.980e+02, Test loss: 5.604e+03, MSE(e): 9.508e-06, MSE(pi1): 2.865e-03, MSE(pi2): 8.469e-06, MSE(pi3): 7.430e-04\n",
      "Epoch 52200, Train loss: 1.977e+02, Test loss: 5.595e+03, MSE(e): 9.481e-06, MSE(pi1): 2.844e-03, MSE(pi2): 8.451e-06, MSE(pi3): 7.442e-04\n",
      "Epoch 52300, Train loss: 1.974e+02, Test loss: 5.586e+03, MSE(e): 9.459e-06, MSE(pi1): 2.841e-03, MSE(pi2): 8.433e-06, MSE(pi3): 7.443e-04\n",
      "Epoch 52400, Train loss: 1.975e+02, Test loss: 5.578e+03, MSE(e): 9.448e-06, MSE(pi1): 2.896e-03, MSE(pi2): 8.416e-06, MSE(pi3): 7.403e-04\n",
      "Epoch 52500, Train loss: 1.969e+02, Test loss: 5.568e+03, MSE(e): 9.415e-06, MSE(pi1): 2.827e-03, MSE(pi2): 8.400e-06, MSE(pi3): 7.444e-04\n",
      "Epoch 52600, Train loss: 1.968e+02, Test loss: 5.560e+03, MSE(e): 9.400e-06, MSE(pi1): 2.870e-03, MSE(pi2): 8.381e-06, MSE(pi3): 7.406e-04\n",
      "Epoch 52700, Train loss: 1.962e+02, Test loss: 5.550e+03, MSE(e): 9.371e-06, MSE(pi1): 2.828e-03, MSE(pi2): 8.364e-06, MSE(pi3): 7.425e-04\n",
      "Epoch 52800, Train loss: 1.963e+02, Test loss: 5.543e+03, MSE(e): 9.357e-06, MSE(pi1): 2.845e-03, MSE(pi2): 8.346e-06, MSE(pi3): 7.430e-04\n",
      "Epoch 52900, Train loss: 1.961e+02, Test loss: 5.534e+03, MSE(e): 9.330e-06, MSE(pi1): 2.805e-03, MSE(pi2): 8.331e-06, MSE(pi3): 7.476e-04\n",
      "Epoch 53000, Train loss: 1.956e+02, Test loss: 5.525e+03, MSE(e): 9.312e-06, MSE(pi1): 2.842e-03, MSE(pi2): 8.313e-06, MSE(pi3): 7.405e-04\n",
      "Epoch 53100, Train loss: 1.954e+02, Test loss: 5.517e+03, MSE(e): 9.294e-06, MSE(pi1): 2.843e-03, MSE(pi2): 8.296e-06, MSE(pi3): 7.405e-04\n",
      "Epoch 53200, Train loss: 1.953e+02, Test loss: 5.508e+03, MSE(e): 9.273e-06, MSE(pi1): 2.869e-03, MSE(pi2): 8.277e-06, MSE(pi3): 7.385e-04\n",
      "Epoch 53300, Train loss: 1.947e+02, Test loss: 5.499e+03, MSE(e): 9.246e-06, MSE(pi1): 2.812e-03, MSE(pi2): 8.262e-06, MSE(pi3): 7.412e-04\n",
      "Epoch 53400, Train loss: 1.945e+02, Test loss: 5.490e+03, MSE(e): 9.226e-06, MSE(pi1): 2.812e-03, MSE(pi2): 8.245e-06, MSE(pi3): 7.412e-04\n",
      "Epoch 53500, Train loss: 1.943e+02, Test loss: 5.482e+03, MSE(e): 9.208e-06, MSE(pi1): 2.834e-03, MSE(pi2): 8.229e-06, MSE(pi3): 7.389e-04\n",
      "Epoch 53600, Train loss: 1.944e+02, Test loss: 5.474e+03, MSE(e): 9.190e-06, MSE(pi1): 2.869e-03, MSE(pi2): 8.213e-06, MSE(pi3): 7.377e-04\n",
      "Epoch 53700, Train loss: 1.938e+02, Test loss: 5.465e+03, MSE(e): 9.159e-06, MSE(pi1): 2.814e-03, MSE(pi2): 8.197e-06, MSE(pi3): 7.411e-04\n",
      "Epoch 53800, Train loss: 1.937e+02, Test loss: 5.457e+03, MSE(e): 9.149e-06, MSE(pi1): 2.815e-03, MSE(pi2): 8.181e-06, MSE(pi3): 7.402e-04\n",
      "Epoch 53900, Train loss: 1.933e+02, Test loss: 5.448e+03, MSE(e): 9.126e-06, MSE(pi1): 2.825e-03, MSE(pi2): 8.162e-06, MSE(pi3): 7.380e-04\n",
      "Epoch 54000, Train loss: 1.930e+02, Test loss: 5.440e+03, MSE(e): 9.103e-06, MSE(pi1): 2.843e-03, MSE(pi2): 8.148e-06, MSE(pi3): 7.358e-04\n",
      "Epoch 54100, Train loss: 1.927e+02, Test loss: 5.432e+03, MSE(e): 9.080e-06, MSE(pi1): 2.854e-03, MSE(pi2): 8.131e-06, MSE(pi3): 7.338e-04\n",
      "Epoch 54200, Train loss: 1.926e+02, Test loss: 5.423e+03, MSE(e): 9.060e-06, MSE(pi1): 2.851e-03, MSE(pi2): 8.117e-06, MSE(pi3): 7.344e-04\n",
      "Epoch 54300, Train loss: 1.923e+02, Test loss: 5.416e+03, MSE(e): 9.042e-06, MSE(pi1): 2.848e-03, MSE(pi2): 8.100e-06, MSE(pi3): 7.339e-04\n",
      "Epoch 54400, Train loss: 1.922e+02, Test loss: 5.408e+03, MSE(e): 9.027e-06, MSE(pi1): 2.853e-03, MSE(pi2): 8.084e-06, MSE(pi3): 7.335e-04\n",
      "Epoch 54500, Train loss: 1.919e+02, Test loss: 5.400e+03, MSE(e): 9.006e-06, MSE(pi1): 2.834e-03, MSE(pi2): 8.069e-06, MSE(pi3): 7.345e-04\n",
      "Epoch 54600, Train loss: 1.917e+02, Test loss: 5.391e+03, MSE(e): 8.987e-06, MSE(pi1): 2.832e-03, MSE(pi2): 8.051e-06, MSE(pi3): 7.346e-04\n",
      "Epoch 54700, Train loss: 1.913e+02, Test loss: 5.383e+03, MSE(e): 8.963e-06, MSE(pi1): 2.818e-03, MSE(pi2): 8.034e-06, MSE(pi3): 7.351e-04\n",
      "Epoch 54800, Train loss: 1.912e+02, Test loss: 5.374e+03, MSE(e): 8.941e-06, MSE(pi1): 2.819e-03, MSE(pi2): 8.020e-06, MSE(pi3): 7.355e-04\n",
      "Epoch 54900, Train loss: 1.910e+02, Test loss: 5.366e+03, MSE(e): 8.922e-06, MSE(pi1): 2.848e-03, MSE(pi2): 8.007e-06, MSE(pi3): 7.331e-04\n",
      "Epoch 55000, Train loss: 1.906e+02, Test loss: 5.358e+03, MSE(e): 8.906e-06, MSE(pi1): 2.823e-03, MSE(pi2): 7.990e-06, MSE(pi3): 7.330e-04\n",
      "Epoch 55100, Train loss: 1.904e+02, Test loss: 5.350e+03, MSE(e): 8.888e-06, MSE(pi1): 2.825e-03, MSE(pi2): 7.973e-06, MSE(pi3): 7.324e-04\n",
      "Epoch 55200, Train loss: 1.902e+02, Test loss: 5.342e+03, MSE(e): 8.871e-06, MSE(pi1): 2.831e-03, MSE(pi2): 7.957e-06, MSE(pi3): 7.320e-04\n",
      "Epoch 55300, Train loss: 1.899e+02, Test loss: 5.335e+03, MSE(e): 8.852e-06, MSE(pi1): 2.828e-03, MSE(pi2): 7.942e-06, MSE(pi3): 7.311e-04\n",
      "Epoch 55400, Train loss: 1.899e+02, Test loss: 5.327e+03, MSE(e): 8.831e-06, MSE(pi1): 2.855e-03, MSE(pi2): 7.925e-06, MSE(pi3): 7.303e-04\n",
      "Epoch 55500, Train loss: 1.895e+02, Test loss: 5.318e+03, MSE(e): 8.809e-06, MSE(pi1): 2.857e-03, MSE(pi2): 7.910e-06, MSE(pi3): 7.285e-04\n",
      "Epoch 55600, Train loss: 1.893e+02, Test loss: 5.310e+03, MSE(e): 8.790e-06, MSE(pi1): 2.859e-03, MSE(pi2): 7.897e-06, MSE(pi3): 7.283e-04\n",
      "Epoch 55700, Train loss: 1.890e+02, Test loss: 5.302e+03, MSE(e): 8.771e-06, MSE(pi1): 2.823e-03, MSE(pi2): 7.881e-06, MSE(pi3): 7.304e-04\n",
      "Epoch 55800, Train loss: 1.890e+02, Test loss: 5.294e+03, MSE(e): 8.758e-06, MSE(pi1): 2.842e-03, MSE(pi2): 7.867e-06, MSE(pi3): 7.298e-04\n",
      "Epoch 55900, Train loss: 1.888e+02, Test loss: 5.287e+03, MSE(e): 8.744e-06, MSE(pi1): 2.826e-03, MSE(pi2): 7.851e-06, MSE(pi3): 7.310e-04\n",
      "Epoch 56000, Train loss: 1.883e+02, Test loss: 5.279e+03, MSE(e): 8.721e-06, MSE(pi1): 2.825e-03, MSE(pi2): 7.836e-06, MSE(pi3): 7.283e-04\n",
      "Epoch 56100, Train loss: 1.881e+02, Test loss: 5.270e+03, MSE(e): 8.700e-06, MSE(pi1): 2.836e-03, MSE(pi2): 7.821e-06, MSE(pi3): 7.272e-04\n",
      "Epoch 56200, Train loss: 1.879e+02, Test loss: 5.263e+03, MSE(e): 8.678e-06, MSE(pi1): 2.815e-03, MSE(pi2): 7.805e-06, MSE(pi3): 7.293e-04\n",
      "Epoch 56300, Train loss: 1.876e+02, Test loss: 5.254e+03, MSE(e): 8.655e-06, MSE(pi1): 2.826e-03, MSE(pi2): 7.792e-06, MSE(pi3): 7.280e-04\n",
      "Epoch 56400, Train loss: 1.874e+02, Test loss: 5.247e+03, MSE(e): 8.641e-06, MSE(pi1): 2.828e-03, MSE(pi2): 7.779e-06, MSE(pi3): 7.272e-04\n",
      "Epoch 56500, Train loss: 1.876e+02, Test loss: 5.241e+03, MSE(e): 8.631e-06, MSE(pi1): 2.878e-03, MSE(pi2): 7.760e-06, MSE(pi3): 7.250e-04\n",
      "Epoch 56600, Train loss: 1.870e+02, Test loss: 5.232e+03, MSE(e): 8.610e-06, MSE(pi1): 2.842e-03, MSE(pi2): 7.747e-06, MSE(pi3): 7.249e-04\n",
      "Epoch 56700, Train loss: 1.868e+02, Test loss: 5.225e+03, MSE(e): 8.587e-06, MSE(pi1): 2.821e-03, MSE(pi2): 7.729e-06, MSE(pi3): 7.267e-04\n",
      "Epoch 56800, Train loss: 1.868e+02, Test loss: 5.218e+03, MSE(e): 8.573e-06, MSE(pi1): 2.841e-03, MSE(pi2): 7.717e-06, MSE(pi3): 7.269e-04\n",
      "Epoch 56900, Train loss: 1.862e+02, Test loss: 5.208e+03, MSE(e): 8.551e-06, MSE(pi1): 2.809e-03, MSE(pi2): 7.704e-06, MSE(pi3): 7.264e-04\n",
      "Epoch 57000, Train loss: 1.862e+02, Test loss: 5.201e+03, MSE(e): 8.533e-06, MSE(pi1): 2.842e-03, MSE(pi2): 7.693e-06, MSE(pi3): 7.241e-04\n",
      "Epoch 57100, Train loss: 1.859e+02, Test loss: 5.194e+03, MSE(e): 8.521e-06, MSE(pi1): 2.823e-03, MSE(pi2): 7.679e-06, MSE(pi3): 7.246e-04\n",
      "Epoch 57200, Train loss: 1.857e+02, Test loss: 5.186e+03, MSE(e): 8.503e-06, MSE(pi1): 2.821e-03, MSE(pi2): 7.664e-06, MSE(pi3): 7.241e-04\n",
      "Epoch 57300, Train loss: 1.855e+02, Test loss: 5.179e+03, MSE(e): 8.483e-06, MSE(pi1): 2.809e-03, MSE(pi2): 7.646e-06, MSE(pi3): 7.253e-04\n",
      "Epoch 57400, Train loss: 1.854e+02, Test loss: 5.172e+03, MSE(e): 8.469e-06, MSE(pi1): 2.869e-03, MSE(pi2): 7.632e-06, MSE(pi3): 7.200e-04\n",
      "Epoch 57500, Train loss: 1.850e+02, Test loss: 5.164e+03, MSE(e): 8.444e-06, MSE(pi1): 2.822e-03, MSE(pi2): 7.617e-06, MSE(pi3): 7.235e-04\n",
      "Epoch 57600, Train loss: 1.849e+02, Test loss: 5.156e+03, MSE(e): 8.429e-06, MSE(pi1): 2.818e-03, MSE(pi2): 7.605e-06, MSE(pi3): 7.240e-04\n",
      "Epoch 57700, Train loss: 1.846e+02, Test loss: 5.148e+03, MSE(e): 8.410e-06, MSE(pi1): 2.823e-03, MSE(pi2): 7.591e-06, MSE(pi3): 7.227e-04\n",
      "Epoch 57800, Train loss: 1.843e+02, Test loss: 5.140e+03, MSE(e): 8.395e-06, MSE(pi1): 2.805e-03, MSE(pi2): 7.577e-06, MSE(pi3): 7.235e-04\n",
      "Epoch 57900, Train loss: 1.842e+02, Test loss: 5.133e+03, MSE(e): 8.380e-06, MSE(pi1): 2.791e-03, MSE(pi2): 7.565e-06, MSE(pi3): 7.245e-04\n",
      "Epoch 58000, Train loss: 1.841e+02, Test loss: 5.127e+03, MSE(e): 8.367e-06, MSE(pi1): 2.828e-03, MSE(pi2): 7.550e-06, MSE(pi3): 7.212e-04\n",
      "Epoch 58100, Train loss: 1.839e+02, Test loss: 5.119e+03, MSE(e): 8.345e-06, MSE(pi1): 2.796e-03, MSE(pi2): 7.534e-06, MSE(pi3): 7.249e-04\n",
      "Epoch 58200, Train loss: 1.835e+02, Test loss: 5.111e+03, MSE(e): 8.324e-06, MSE(pi1): 2.808e-03, MSE(pi2): 7.521e-06, MSE(pi3): 7.212e-04\n",
      "Epoch 58300, Train loss: 1.833e+02, Test loss: 5.103e+03, MSE(e): 8.308e-06, MSE(pi1): 2.783e-03, MSE(pi2): 7.509e-06, MSE(pi3): 7.236e-04\n",
      "Epoch 58400, Train loss: 1.831e+02, Test loss: 5.096e+03, MSE(e): 8.290e-06, MSE(pi1): 2.833e-03, MSE(pi2): 7.493e-06, MSE(pi3): 7.188e-04\n",
      "Epoch 58500, Train loss: 1.828e+02, Test loss: 5.089e+03, MSE(e): 8.276e-06, MSE(pi1): 2.797e-03, MSE(pi2): 7.480e-06, MSE(pi3): 7.209e-04\n",
      "Epoch 58600, Train loss: 1.828e+02, Test loss: 5.083e+03, MSE(e): 8.265e-06, MSE(pi1): 2.829e-03, MSE(pi2): 7.466e-06, MSE(pi3): 7.186e-04\n",
      "Epoch 58700, Train loss: 1.828e+02, Test loss: 5.077e+03, MSE(e): 8.260e-06, MSE(pi1): 2.828e-03, MSE(pi2): 7.456e-06, MSE(pi3): 7.196e-04\n",
      "Epoch 58800, Train loss: 1.825e+02, Test loss: 5.069e+03, MSE(e): 8.231e-06, MSE(pi1): 2.842e-03, MSE(pi2): 7.440e-06, MSE(pi3): 7.181e-04\n",
      "Epoch 58900, Train loss: 1.821e+02, Test loss: 5.060e+03, MSE(e): 8.211e-06, MSE(pi1): 2.794e-03, MSE(pi2): 7.426e-06, MSE(pi3): 7.201e-04\n",
      "Epoch 59000, Train loss: 1.819e+02, Test loss: 5.052e+03, MSE(e): 8.192e-06, MSE(pi1): 2.783e-03, MSE(pi2): 7.412e-06, MSE(pi3): 7.217e-04\n",
      "Epoch 59100, Train loss: 1.817e+02, Test loss: 5.046e+03, MSE(e): 8.176e-06, MSE(pi1): 2.833e-03, MSE(pi2): 7.400e-06, MSE(pi3): 7.163e-04\n",
      "Epoch 59200, Train loss: 1.816e+02, Test loss: 5.039e+03, MSE(e): 8.166e-06, MSE(pi1): 2.796e-03, MSE(pi2): 7.390e-06, MSE(pi3): 7.197e-04\n",
      "Epoch 59300, Train loss: 1.813e+02, Test loss: 5.032e+03, MSE(e): 8.151e-06, MSE(pi1): 2.797e-03, MSE(pi2): 7.374e-06, MSE(pi3): 7.186e-04\n",
      "Epoch 59400, Train loss: 1.811e+02, Test loss: 5.025e+03, MSE(e): 8.132e-06, MSE(pi1): 2.808e-03, MSE(pi2): 7.358e-06, MSE(pi3): 7.173e-04\n",
      "Epoch 59500, Train loss: 1.811e+02, Test loss: 5.019e+03, MSE(e): 8.122e-06, MSE(pi1): 2.786e-03, MSE(pi2): 7.346e-06, MSE(pi3): 7.200e-04\n",
      "Epoch 59600, Train loss: 1.809e+02, Test loss: 5.011e+03, MSE(e): 8.106e-06, MSE(pi1): 2.830e-03, MSE(pi2): 7.337e-06, MSE(pi3): 7.155e-04\n",
      "Epoch 59700, Train loss: 1.805e+02, Test loss: 5.003e+03, MSE(e): 8.078e-06, MSE(pi1): 2.774e-03, MSE(pi2): 7.320e-06, MSE(pi3): 7.198e-04\n",
      "Epoch 59800, Train loss: 1.804e+02, Test loss: 4.996e+03, MSE(e): 8.061e-06, MSE(pi1): 2.819e-03, MSE(pi2): 7.308e-06, MSE(pi3): 7.157e-04\n",
      "Epoch 59900, Train loss: 1.803e+02, Test loss: 4.989e+03, MSE(e): 8.047e-06, MSE(pi1): 2.800e-03, MSE(pi2): 7.294e-06, MSE(pi3): 7.178e-04\n",
      "Epoch 60000, Train loss: 1.801e+02, Test loss: 4.983e+03, MSE(e): 8.038e-06, MSE(pi1): 2.792e-03, MSE(pi2): 7.283e-06, MSE(pi3): 7.181e-04\n",
      "Epoch 60100, Train loss: 1.801e+02, Test loss: 4.977e+03, MSE(e): 8.029e-06, MSE(pi1): 2.811e-03, MSE(pi2): 7.265e-06, MSE(pi3): 7.171e-04\n",
      "Epoch 60200, Train loss: 1.796e+02, Test loss: 4.969e+03, MSE(e): 8.008e-06, MSE(pi1): 2.786e-03, MSE(pi2): 7.254e-06, MSE(pi3): 7.166e-04\n",
      "Epoch 60300, Train loss: 1.795e+02, Test loss: 4.963e+03, MSE(e): 7.994e-06, MSE(pi1): 2.819e-03, MSE(pi2): 7.243e-06, MSE(pi3): 7.141e-04\n",
      "Epoch 60400, Train loss: 1.793e+02, Test loss: 4.954e+03, MSE(e): 7.975e-06, MSE(pi1): 2.821e-03, MSE(pi2): 7.233e-06, MSE(pi3): 7.129e-04\n",
      "Epoch 60500, Train loss: 1.792e+02, Test loss: 4.947e+03, MSE(e): 7.958e-06, MSE(pi1): 2.839e-03, MSE(pi2): 7.221e-06, MSE(pi3): 7.120e-04\n",
      "Epoch 60600, Train loss: 1.788e+02, Test loss: 4.940e+03, MSE(e): 7.937e-06, MSE(pi1): 2.790e-03, MSE(pi2): 7.203e-06, MSE(pi3): 7.149e-04\n",
      "Epoch 60700, Train loss: 1.789e+02, Test loss: 4.938e+03, MSE(e): 7.954e-06, MSE(pi1): 2.799e-03, MSE(pi2): 7.206e-06, MSE(pi3): 7.134e-04\n",
      "Epoch 60800, Train loss: 1.790e+02, Test loss: 4.929e+03, MSE(e): 7.967e-06, MSE(pi1): 2.773e-03, MSE(pi2): 7.206e-06, MSE(pi3): 7.158e-04\n",
      "Epoch 60900, Train loss: 1.783e+02, Test loss: 4.917e+03, MSE(e): 7.893e-06, MSE(pi1): 2.783e-03, MSE(pi2): 7.170e-06, MSE(pi3): 7.153e-04\n",
      "Epoch 61000, Train loss: 1.783e+02, Test loss: 4.914e+03, MSE(e): 7.879e-06, MSE(pi1): 2.818e-03, MSE(pi2): 7.153e-06, MSE(pi3): 7.132e-04\n",
      "Epoch 61100, Train loss: 1.780e+02, Test loss: 4.910e+03, MSE(e): 7.871e-06, MSE(pi1): 2.799e-03, MSE(pi2): 7.144e-06, MSE(pi3): 7.134e-04\n",
      "Epoch 61200, Train loss: 1.781e+02, Test loss: 4.903e+03, MSE(e): 7.885e-06, MSE(pi1): 2.754e-03, MSE(pi2): 7.145e-06, MSE(pi3): 7.173e-04\n",
      "Epoch 61300, Train loss: 1.777e+02, Test loss: 4.893e+03, MSE(e): 7.851e-06, MSE(pi1): 2.779e-03, MSE(pi2): 7.128e-06, MSE(pi3): 7.139e-04\n",
      "Epoch 61400, Train loss: 1.774e+02, Test loss: 4.883e+03, MSE(e): 7.824e-06, MSE(pi1): 2.804e-03, MSE(pi2): 7.109e-06, MSE(pi3): 7.110e-04\n",
      "Epoch 61500, Train loss: 1.771e+02, Test loss: 4.882e+03, MSE(e): 7.800e-06, MSE(pi1): 2.784e-03, MSE(pi2): 7.085e-06, MSE(pi3): 7.128e-04\n",
      "Epoch 61600, Train loss: 1.777e+02, Test loss: 4.878e+03, MSE(e): 7.846e-06, MSE(pi1): 2.810e-03, MSE(pi2): 7.109e-06, MSE(pi3): 7.117e-04\n",
      "Epoch 61700, Train loss: 1.775e+02, Test loss: 4.868e+03, MSE(e): 7.824e-06, MSE(pi1): 2.815e-03, MSE(pi2): 7.091e-06, MSE(pi3): 7.106e-04\n",
      "Epoch 61800, Train loss: 1.767e+02, Test loss: 4.858e+03, MSE(e): 7.764e-06, MSE(pi1): 2.793e-03, MSE(pi2): 7.059e-06, MSE(pi3): 7.117e-04\n",
      "Epoch 61900, Train loss: 1.765e+02, Test loss: 4.857e+03, MSE(e): 7.746e-06, MSE(pi1): 2.778e-03, MSE(pi2): 7.041e-06, MSE(pi3): 7.123e-04\n",
      "Epoch 62000, Train loss: 1.768e+02, Test loss: 4.850e+03, MSE(e): 7.781e-06, MSE(pi1): 2.762e-03, MSE(pi2): 7.057e-06, MSE(pi3): 7.141e-04\n",
      "Epoch 62100, Train loss: 1.763e+02, Test loss: 4.839e+03, MSE(e): 7.744e-06, MSE(pi1): 2.758e-03, MSE(pi2): 7.036e-06, MSE(pi3): 7.132e-04\n",
      "Epoch 62200, Train loss: 1.760e+02, Test loss: 4.830e+03, MSE(e): 7.708e-06, MSE(pi1): 2.787e-03, MSE(pi2): 7.012e-06, MSE(pi3): 7.101e-04\n",
      "Epoch 62300, Train loss: 1.758e+02, Test loss: 4.830e+03, MSE(e): 7.692e-06, MSE(pi1): 2.757e-03, MSE(pi2): 6.997e-06, MSE(pi3): 7.134e-04\n",
      "Epoch 62400, Train loss: 1.765e+02, Test loss: 4.825e+03, MSE(e): 7.759e-06, MSE(pi1): 2.760e-03, MSE(pi2): 7.024e-06, MSE(pi3): 7.131e-04\n",
      "Epoch 62500, Train loss: 1.757e+02, Test loss: 4.812e+03, MSE(e): 7.671e-06, MSE(pi1): 2.798e-03, MSE(pi2): 6.978e-06, MSE(pi3): 7.099e-04\n",
      "Epoch 62600, Train loss: 1.756e+02, Test loss: 4.807e+03, MSE(e): 7.673e-06, MSE(pi1): 2.774e-03, MSE(pi2): 6.971e-06, MSE(pi3): 7.114e-04\n",
      "Epoch 62700, Train loss: 1.751e+02, Test loss: 4.805e+03, MSE(e): 7.640e-06, MSE(pi1): 2.772e-03, MSE(pi2): 6.955e-06, MSE(pi3): 7.098e-04\n",
      "Epoch 62800, Train loss: 1.755e+02, Test loss: 4.797e+03, MSE(e): 7.674e-06, MSE(pi1): 2.784e-03, MSE(pi2): 6.966e-06, MSE(pi3): 7.090e-04\n",
      "Epoch 62900, Train loss: 1.748e+02, Test loss: 4.786e+03, MSE(e): 7.608e-06, MSE(pi1): 2.785e-03, MSE(pi2): 6.933e-06, MSE(pi3): 7.088e-04\n",
      "Epoch 63000, Train loss: 1.746e+02, Test loss: 4.783e+03, MSE(e): 7.587e-06, MSE(pi1): 2.777e-03, MSE(pi2): 6.910e-06, MSE(pi3): 7.100e-04\n",
      "Epoch 63100, Train loss: 1.751e+02, Test loss: 4.780e+03, MSE(e): 7.646e-06, MSE(pi1): 2.746e-03, MSE(pi2): 6.939e-06, MSE(pi3): 7.114e-04\n",
      "Epoch 63200, Train loss: 1.747e+02, Test loss: 4.769e+03, MSE(e): 7.606e-06, MSE(pi1): 2.743e-03, MSE(pi2): 6.912e-06, MSE(pi3): 7.123e-04\n",
      "Epoch 63300, Train loss: 1.747e+02, Test loss: 4.760e+03, MSE(e): 7.589e-06, MSE(pi1): 2.784e-03, MSE(pi2): 6.898e-06, MSE(pi3): 7.095e-04\n",
      "Epoch 63400, Train loss: 1.743e+02, Test loss: 4.762e+03, MSE(e): 7.565e-06, MSE(pi1): 2.790e-03, MSE(pi2): 6.883e-06, MSE(pi3): 7.077e-04\n",
      "Epoch 63500, Train loss: 1.746e+02, Test loss: 4.752e+03, MSE(e): 7.600e-06, MSE(pi1): 2.757e-03, MSE(pi2): 6.896e-06, MSE(pi3): 7.100e-04\n",
      "Epoch 63600, Train loss: 1.738e+02, Test loss: 4.739e+03, MSE(e): 7.513e-06, MSE(pi1): 2.776e-03, MSE(pi2): 6.855e-06, MSE(pi3): 7.090e-04\n",
      "Epoch 63700, Train loss: 1.736e+02, Test loss: 4.740e+03, MSE(e): 7.493e-06, MSE(pi1): 2.802e-03, MSE(pi2): 6.831e-06, MSE(pi3): 7.065e-04\n",
      "Epoch 63800, Train loss: 1.738e+02, Test loss: 4.735e+03, MSE(e): 7.546e-06, MSE(pi1): 2.749e-03, MSE(pi2): 6.857e-06, MSE(pi3): 7.089e-04\n",
      "Epoch 63900, Train loss: 1.733e+02, Test loss: 4.723e+03, MSE(e): 7.485e-06, MSE(pi1): 2.784e-03, MSE(pi2): 6.826e-06, MSE(pi3): 7.062e-04\n",
      "Epoch 64000, Train loss: 1.731e+02, Test loss: 4.717e+03, MSE(e): 7.474e-06, MSE(pi1): 2.761e-03, MSE(pi2): 6.809e-06, MSE(pi3): 7.078e-04\n",
      "Epoch 64100, Train loss: 1.735e+02, Test loss: 4.718e+03, MSE(e): 7.500e-06, MSE(pi1): 2.724e-03, MSE(pi2): 6.821e-06, MSE(pi3): 7.127e-04\n",
      "Epoch 64200, Train loss: 1.731e+02, Test loss: 4.706e+03, MSE(e): 7.478e-06, MSE(pi1): 2.753e-03, MSE(pi2): 6.801e-06, MSE(pi3): 7.079e-04\n",
      "Epoch 64300, Train loss: 1.731e+02, Test loss: 4.699e+03, MSE(e): 7.459e-06, MSE(pi1): 2.807e-03, MSE(pi2): 6.782e-06, MSE(pi3): 7.042e-04\n",
      "Epoch 64400, Train loss: 1.727e+02, Test loss: 4.700e+03, MSE(e): 7.423e-06, MSE(pi1): 2.805e-03, MSE(pi2): 6.764e-06, MSE(pi3): 7.041e-04\n",
      "Epoch 64500, Train loss: 1.729e+02, Test loss: 4.690e+03, MSE(e): 7.458e-06, MSE(pi1): 2.768e-03, MSE(pi2): 6.780e-06, MSE(pi3): 7.063e-04\n",
      "Epoch 64600, Train loss: 1.720e+02, Test loss: 4.676e+03, MSE(e): 7.375e-06, MSE(pi1): 2.743e-03, MSE(pi2): 6.745e-06, MSE(pi3): 7.084e-04\n",
      "Epoch 64700, Train loss: 1.718e+02, Test loss: 4.679e+03, MSE(e): 7.362e-06, MSE(pi1): 2.785e-03, MSE(pi2): 6.723e-06, MSE(pi3): 7.031e-04\n",
      "Epoch 64800, Train loss: 1.727e+02, Test loss: 4.673e+03, MSE(e): 7.456e-06, MSE(pi1): 2.757e-03, MSE(pi2): 6.762e-06, MSE(pi3): 7.057e-04\n",
      "Epoch 64900, Train loss: 1.716e+02, Test loss: 4.657e+03, MSE(e): 7.349e-06, MSE(pi1): 2.752e-03, MSE(pi2): 6.717e-06, MSE(pi3): 7.056e-04\n",
      "Epoch 65000, Train loss: 1.714e+02, Test loss: 4.663e+03, MSE(e): 7.328e-06, MSE(pi1): 2.784e-03, MSE(pi2): 6.691e-06, MSE(pi3): 7.031e-04\n",
      "Epoch 65100, Train loss: 1.722e+02, Test loss: 4.655e+03, MSE(e): 7.416e-06, MSE(pi1): 2.736e-03, MSE(pi2): 6.727e-06, MSE(pi3): 7.073e-04\n",
      "Epoch 65200, Train loss: 1.713e+02, Test loss: 4.639e+03, MSE(e): 7.310e-06, MSE(pi1): 2.825e-03, MSE(pi2): 6.685e-06, MSE(pi3): 6.998e-04\n",
      "Epoch 65300, Train loss: 1.708e+02, Test loss: 4.643e+03, MSE(e): 7.282e-06, MSE(pi1): 2.730e-03, MSE(pi2): 6.657e-06, MSE(pi3): 7.068e-04\n",
      "Epoch 65400, Train loss: 1.717e+02, Test loss: 4.636e+03, MSE(e): 7.372e-06, MSE(pi1): 2.726e-03, MSE(pi2): 6.694e-06, MSE(pi3): 7.068e-04\n",
      "Epoch 65500, Train loss: 1.705e+02, Test loss: 4.623e+03, MSE(e): 7.258e-06, MSE(pi1): 2.762e-03, MSE(pi2): 6.644e-06, MSE(pi3): 7.034e-04\n",
      "Epoch 65600, Train loss: 1.704e+02, Test loss: 4.626e+03, MSE(e): 7.243e-06, MSE(pi1): 2.736e-03, MSE(pi2): 6.626e-06, MSE(pi3): 7.057e-04\n",
      "Epoch 65700, Train loss: 1.715e+02, Test loss: 4.619e+03, MSE(e): 7.352e-06, MSE(pi1): 2.734e-03, MSE(pi2): 6.672e-06, MSE(pi3): 7.062e-04\n",
      "Epoch 65800, Train loss: 1.702e+02, Test loss: 4.603e+03, MSE(e): 7.224e-06, MSE(pi1): 2.714e-03, MSE(pi2): 6.615e-06, MSE(pi3): 7.079e-04\n",
      "Epoch 65900, Train loss: 1.701e+02, Test loss: 4.610e+03, MSE(e): 7.219e-06, MSE(pi1): 2.723e-03, MSE(pi2): 6.601e-06, MSE(pi3): 7.068e-04\n",
      "Epoch 66000, Train loss: 1.708e+02, Test loss: 4.601e+03, MSE(e): 7.298e-06, MSE(pi1): 2.733e-03, MSE(pi2): 6.632e-06, MSE(pi3): 7.047e-04\n",
      "Epoch 66100, Train loss: 1.698e+02, Test loss: 4.587e+03, MSE(e): 7.187e-06, MSE(pi1): 2.795e-03, MSE(pi2): 6.584e-06, MSE(pi3): 7.000e-04\n",
      "Epoch 66200, Train loss: 1.696e+02, Test loss: 4.590e+03, MSE(e): 7.180e-06, MSE(pi1): 2.721e-03, MSE(pi2): 6.569e-06, MSE(pi3): 7.056e-04\n",
      "Epoch 66300, Train loss: 1.705e+02, Test loss: 4.582e+03, MSE(e): 7.268e-06, MSE(pi1): 2.754e-03, MSE(pi2): 6.603e-06, MSE(pi3): 7.028e-04\n",
      "Epoch 66400, Train loss: 1.694e+02, Test loss: 4.568e+03, MSE(e): 7.154e-06, MSE(pi1): 2.755e-03, MSE(pi2): 6.555e-06, MSE(pi3): 7.028e-04\n",
      "Epoch 66500, Train loss: 1.694e+02, Test loss: 4.575e+03, MSE(e): 7.175e-06, MSE(pi1): 2.746e-03, MSE(pi2): 6.558e-06, MSE(pi3): 7.021e-04\n",
      "Epoch 66600, Train loss: 1.699e+02, Test loss: 4.563e+03, MSE(e): 7.219e-06, MSE(pi1): 2.715e-03, MSE(pi2): 6.565e-06, MSE(pi3): 7.052e-04\n",
      "Epoch 66700, Train loss: 1.696e+02, Test loss: 4.552e+03, MSE(e): 7.183e-06, MSE(pi1): 2.790e-03, MSE(pi2): 6.548e-06, MSE(pi3): 6.987e-04\n",
      "Epoch 66800, Train loss: 1.697e+02, Test loss: 4.558e+03, MSE(e): 7.207e-06, MSE(pi1): 2.725e-03, MSE(pi2): 6.558e-06, MSE(pi3): 7.035e-04\n",
      "Epoch 66900, Train loss: 1.690e+02, Test loss: 4.544e+03, MSE(e): 7.128e-06, MSE(pi1): 2.745e-03, MSE(pi2): 6.514e-06, MSE(pi3): 7.029e-04\n",
      "Epoch 67000, Train loss: 1.687e+02, Test loss: 4.538e+03, MSE(e): 7.105e-06, MSE(pi1): 2.744e-03, MSE(pi2): 6.495e-06, MSE(pi3): 7.020e-04\n",
      "Epoch 67100, Train loss: 1.692e+02, Test loss: 4.539e+03, MSE(e): 7.159e-06, MSE(pi1): 2.721e-03, MSE(pi2): 6.521e-06, MSE(pi3): 7.039e-04\n",
      "Epoch 67200, Train loss: 1.682e+02, Test loss: 4.524e+03, MSE(e): 7.057e-06, MSE(pi1): 2.775e-03, MSE(pi2): 6.474e-06, MSE(pi3): 6.986e-04\n",
      "Epoch 67300, Train loss: 1.680e+02, Test loss: 4.524e+03, MSE(e): 7.033e-06, MSE(pi1): 2.713e-03, MSE(pi2): 6.449e-06, MSE(pi3): 7.052e-04\n",
      "Epoch 67400, Train loss: 1.692e+02, Test loss: 4.519e+03, MSE(e): 7.154e-06, MSE(pi1): 2.746e-03, MSE(pi2): 6.503e-06, MSE(pi3): 7.017e-04\n",
      "Epoch 67500, Train loss: 1.691e+02, Test loss: 4.505e+03, MSE(e): 7.131e-06, MSE(pi1): 2.742e-03, MSE(pi2): 6.491e-06, MSE(pi3): 7.032e-04\n",
      "Epoch 67600, Train loss: 1.682e+02, Test loss: 4.513e+03, MSE(e): 7.067e-06, MSE(pi1): 2.749e-03, MSE(pi2): 6.457e-06, MSE(pi3): 7.004e-04\n",
      "Epoch 67700, Train loss: 1.682e+02, Test loss: 4.500e+03, MSE(e): 7.074e-06, MSE(pi1): 2.768e-03, MSE(pi2): 6.449e-06, MSE(pi3): 6.981e-04\n",
      "Epoch 67800, Train loss: 1.674e+02, Test loss: 4.495e+03, MSE(e): 6.986e-06, MSE(pi1): 2.779e-03, MSE(pi2): 6.399e-06, MSE(pi3): 6.971e-04\n",
      "Epoch 67900, Train loss: 1.682e+02, Test loss: 4.494e+03, MSE(e): 7.079e-06, MSE(pi1): 2.768e-03, MSE(pi2): 6.447e-06, MSE(pi3): 6.972e-04\n",
      "Epoch 68000, Train loss: 1.672e+02, Test loss: 4.479e+03, MSE(e): 6.972e-06, MSE(pi1): 2.725e-03, MSE(pi2): 6.393e-06, MSE(pi3): 7.026e-04\n",
      "Epoch 68100, Train loss: 1.671e+02, Test loss: 4.484e+03, MSE(e): 6.977e-06, MSE(pi1): 2.751e-03, MSE(pi2): 6.393e-06, MSE(pi3): 6.985e-04\n",
      "Epoch 68200, Train loss: 1.675e+02, Test loss: 4.471e+03, MSE(e): 7.015e-06, MSE(pi1): 2.708e-03, MSE(pi2): 6.401e-06, MSE(pi3): 7.028e-04\n",
      "Epoch 68300, Train loss: 1.666e+02, Test loss: 4.467e+03, MSE(e): 6.927e-06, MSE(pi1): 2.742e-03, MSE(pi2): 6.350e-06, MSE(pi3): 6.987e-04\n",
      "Epoch 68400, Train loss: 1.681e+02, Test loss: 4.465e+03, MSE(e): 7.075e-06, MSE(pi1): 2.740e-03, MSE(pi2): 6.418e-06, MSE(pi3): 6.991e-04\n",
      "Epoch 68500, Train loss: 1.670e+02, Test loss: 4.447e+03, MSE(e): 6.964e-06, MSE(pi1): 2.775e-03, MSE(pi2): 6.375e-06, MSE(pi3): 6.960e-04\n",
      "Epoch 68600, Train loss: 1.666e+02, Test loss: 4.455e+03, MSE(e): 6.923e-06, MSE(pi1): 2.698e-03, MSE(pi2): 6.341e-06, MSE(pi3): 7.036e-04\n",
      "Epoch 68700, Train loss: 1.668e+02, Test loss: 4.443e+03, MSE(e): 6.957e-06, MSE(pi1): 2.725e-03, MSE(pi2): 6.352e-06, MSE(pi3): 6.996e-04\n",
      "Epoch 68800, Train loss: 1.657e+02, Test loss: 4.440e+03, MSE(e): 6.856e-06, MSE(pi1): 2.714e-03, MSE(pi2): 6.297e-06, MSE(pi3): 7.004e-04\n",
      "Epoch 68900, Train loss: 1.670e+02, Test loss: 4.436e+03, MSE(e): 6.983e-06, MSE(pi1): 2.725e-03, MSE(pi2): 6.359e-06, MSE(pi3): 6.990e-04\n",
      "Epoch 69000, Train loss: 1.659e+02, Test loss: 4.421e+03, MSE(e): 6.855e-06, MSE(pi1): 2.789e-03, MSE(pi2): 6.303e-06, MSE(pi3): 6.942e-04\n",
      "Epoch 69100, Train loss: 1.668e+02, Test loss: 4.429e+03, MSE(e): 6.969e-06, MSE(pi1): 2.689e-03, MSE(pi2): 6.349e-06, MSE(pi3): 7.018e-04\n",
      "Epoch 69200, Train loss: 1.652e+02, Test loss: 4.412e+03, MSE(e): 6.819e-06, MSE(pi1): 2.748e-03, MSE(pi2): 6.275e-06, MSE(pi3): 6.957e-04\n",
      "Epoch 69300, Train loss: 1.654e+02, Test loss: 4.417e+03, MSE(e): 6.834e-06, MSE(pi1): 2.716e-03, MSE(pi2): 6.269e-06, MSE(pi3): 6.989e-04\n",
      "Epoch 69400, Train loss: 1.660e+02, Test loss: 4.406e+03, MSE(e): 6.893e-06, MSE(pi1): 2.732e-03, MSE(pi2): 6.291e-06, MSE(pi3): 6.977e-04\n",
      "Epoch 69500, Train loss: 1.649e+02, Test loss: 4.408e+03, MSE(e): 6.796e-06, MSE(pi1): 2.729e-03, MSE(pi2): 6.248e-06, MSE(pi3): 6.964e-04\n",
      "Epoch 69600, Train loss: 1.656e+02, Test loss: 4.396e+03, MSE(e): 6.861e-06, MSE(pi1): 2.713e-03, MSE(pi2): 6.268e-06, MSE(pi3): 6.984e-04\n",
      "Epoch 69700, Train loss: 1.650e+02, Test loss: 4.384e+03, MSE(e): 6.807e-06, MSE(pi1): 2.730e-03, MSE(pi2): 6.244e-06, MSE(pi3): 6.967e-04\n",
      "Epoch 69800, Train loss: 1.662e+02, Test loss: 4.389e+03, MSE(e): 6.908e-06, MSE(pi1): 2.751e-03, MSE(pi2): 6.285e-06, MSE(pi3): 6.958e-04\n",
      "Epoch 69900, Train loss: 1.648e+02, Test loss: 4.381e+03, MSE(e): 6.756e-06, MSE(pi1): 2.787e-03, MSE(pi2): 6.198e-06, MSE(pi3): 6.941e-04\n",
      "Epoch 70000, Train loss: 1.653e+02, Test loss: 4.378e+03, MSE(e): 6.832e-06, MSE(pi1): 2.683e-03, MSE(pi2): 6.241e-06, MSE(pi3): 7.018e-04\n",
      "Epoch 70100, Train loss: 1.643e+02, Test loss: 4.363e+03, MSE(e): 6.731e-06, MSE(pi1): 2.792e-03, MSE(pi2): 6.193e-06, MSE(pi3): 6.909e-04\n",
      "Epoch 70200, Train loss: 1.660e+02, Test loss: 4.368e+03, MSE(e): 6.906e-06, MSE(pi1): 2.735e-03, MSE(pi2): 6.263e-06, MSE(pi3): 6.955e-04\n",
      "Epoch 70300, Train loss: 1.640e+02, Test loss: 4.367e+03, MSE(e): 6.704e-06, MSE(pi1): 2.754e-03, MSE(pi2): 6.172e-06, MSE(pi3): 6.938e-04\n",
      "Epoch 70400, Train loss: 1.644e+02, Test loss: 4.355e+03, MSE(e): 6.760e-06, MSE(pi1): 2.706e-03, MSE(pi2): 6.186e-06, MSE(pi3): 6.978e-04\n",
      "Epoch 70500, Train loss: 1.637e+02, Test loss: 4.343e+03, MSE(e): 6.688e-06, MSE(pi1): 2.733e-03, MSE(pi2): 6.153e-06, MSE(pi3): 6.946e-04\n",
      "Epoch 70600, Train loss: 1.642e+02, Test loss: 4.346e+03, MSE(e): 6.736e-06, MSE(pi1): 2.734e-03, MSE(pi2): 6.170e-06, MSE(pi3): 6.955e-04\n",
      "Epoch 70700, Train loss: 1.670e+02, Test loss: 4.334e+03, MSE(e): 6.996e-06, MSE(pi1): 2.727e-03, MSE(pi2): 6.322e-06, MSE(pi3): 6.973e-04\n",
      "Epoch 70800, Train loss: 1.641e+02, Test loss: 4.335e+03, MSE(e): 6.690e-06, MSE(pi1): 2.686e-03, MSE(pi2): 6.143e-06, MSE(pi3): 7.034e-04\n",
      "Epoch 70900, Train loss: 1.635e+02, Test loss: 4.322e+03, MSE(e): 6.667e-06, MSE(pi1): 2.731e-03, MSE(pi2): 6.128e-06, MSE(pi3): 6.953e-04\n",
      "Epoch 71000, Train loss: 1.650e+02, Test loss: 4.323e+03, MSE(e): 6.814e-06, MSE(pi1): 2.752e-03, MSE(pi2): 6.182e-06, MSE(pi3): 6.932e-04\n",
      "Epoch 71100, Train loss: 1.654e+02, Test loss: 4.322e+03, MSE(e): 6.843e-06, MSE(pi1): 2.755e-03, MSE(pi2): 6.194e-06, MSE(pi3): 6.937e-04\n",
      "Epoch 71200, Train loss: 1.650e+02, Test loss: 4.319e+03, MSE(e): 6.818e-06, MSE(pi1): 2.686e-03, MSE(pi2): 6.176e-06, MSE(pi3): 7.000e-04\n",
      "Epoch 71300, Train loss: 1.654e+02, Test loss: 4.316e+03, MSE(e): 6.860e-06, MSE(pi1): 2.724e-03, MSE(pi2): 6.171e-06, MSE(pi3): 6.952e-04\n",
      "Epoch 71400, Train loss: 1.640e+02, Test loss: 4.313e+03, MSE(e): 6.725e-06, MSE(pi1): 2.674e-03, MSE(pi2): 6.129e-06, MSE(pi3): 6.998e-04\n",
      "Epoch 71500, Train loss: 1.638e+02, Test loss: 4.310e+03, MSE(e): 6.721e-06, MSE(pi1): 2.696e-03, MSE(pi2): 6.108e-06, MSE(pi3): 6.965e-04\n",
      "Epoch 71600, Train loss: 1.641e+02, Test loss: 4.305e+03, MSE(e): 6.749e-06, MSE(pi1): 2.732e-03, MSE(pi2): 6.097e-06, MSE(pi3): 6.932e-04\n",
      "Epoch 71700, Train loss: 1.638e+02, Test loss: 4.300e+03, MSE(e): 6.715e-06, MSE(pi1): 2.693e-03, MSE(pi2): 6.081e-06, MSE(pi3): 6.972e-04\n",
      "Epoch 71800, Train loss: 1.637e+02, Test loss: 4.295e+03, MSE(e): 6.709e-06, MSE(pi1): 2.701e-03, MSE(pi2): 6.070e-06, MSE(pi3): 6.964e-04\n",
      "Epoch 71900, Train loss: 1.635e+02, Test loss: 4.290e+03, MSE(e): 6.690e-06, MSE(pi1): 2.716e-03, MSE(pi2): 6.052e-06, MSE(pi3): 6.946e-04\n",
      "Epoch 72000, Train loss: 1.632e+02, Test loss: 4.284e+03, MSE(e): 6.653e-06, MSE(pi1): 2.721e-03, MSE(pi2): 6.037e-06, MSE(pi3): 6.951e-04\n",
      "Epoch 72100, Train loss: 1.634e+02, Test loss: 4.278e+03, MSE(e): 6.681e-06, MSE(pi1): 2.687e-03, MSE(pi2): 6.029e-06, MSE(pi3): 6.968e-04\n",
      "Epoch 72200, Train loss: 1.632e+02, Test loss: 4.272e+03, MSE(e): 6.658e-06, MSE(pi1): 2.704e-03, MSE(pi2): 6.016e-06, MSE(pi3): 6.953e-04\n",
      "Epoch 72300, Train loss: 1.630e+02, Test loss: 4.267e+03, MSE(e): 6.643e-06, MSE(pi1): 2.714e-03, MSE(pi2): 6.006e-06, MSE(pi3): 6.942e-04\n",
      "Epoch 72400, Train loss: 1.629e+02, Test loss: 4.261e+03, MSE(e): 6.628e-06, MSE(pi1): 2.707e-03, MSE(pi2): 5.995e-06, MSE(pi3): 6.952e-04\n",
      "Epoch 72500, Train loss: 1.628e+02, Test loss: 4.255e+03, MSE(e): 6.618e-06, MSE(pi1): 2.694e-03, MSE(pi2): 5.985e-06, MSE(pi3): 6.970e-04\n",
      "Epoch 72600, Train loss: 1.627e+02, Test loss: 4.249e+03, MSE(e): 6.619e-06, MSE(pi1): 2.691e-03, MSE(pi2): 5.976e-06, MSE(pi3): 6.963e-04\n",
      "Epoch 72700, Train loss: 1.626e+02, Test loss: 4.244e+03, MSE(e): 6.601e-06, MSE(pi1): 2.725e-03, MSE(pi2): 5.970e-06, MSE(pi3): 6.937e-04\n",
      "Epoch 72800, Train loss: 1.627e+02, Test loss: 4.237e+03, MSE(e): 6.609e-06, MSE(pi1): 2.682e-03, MSE(pi2): 5.954e-06, MSE(pi3): 6.984e-04\n",
      "Epoch 72900, Train loss: 1.621e+02, Test loss: 4.232e+03, MSE(e): 6.571e-06, MSE(pi1): 2.688e-03, MSE(pi2): 5.941e-06, MSE(pi3): 6.952e-04\n",
      "Epoch 73000, Train loss: 1.622e+02, Test loss: 4.226e+03, MSE(e): 6.550e-06, MSE(pi1): 2.736e-03, MSE(pi2): 5.931e-06, MSE(pi3): 6.930e-04\n",
      "Epoch 73100, Train loss: 1.618e+02, Test loss: 4.219e+03, MSE(e): 6.539e-06, MSE(pi1): 2.677e-03, MSE(pi2): 5.922e-06, MSE(pi3): 6.965e-04\n",
      "Epoch 73200, Train loss: 1.621e+02, Test loss: 4.213e+03, MSE(e): 6.566e-06, MSE(pi1): 2.693e-03, MSE(pi2): 5.915e-06, MSE(pi3): 6.948e-04\n",
      "Epoch 73300, Train loss: 1.621e+02, Test loss: 4.208e+03, MSE(e): 6.561e-06, MSE(pi1): 2.717e-03, MSE(pi2): 5.913e-06, MSE(pi3): 6.934e-04\n",
      "Epoch 73400, Train loss: 1.618e+02, Test loss: 4.202e+03, MSE(e): 6.549e-06, MSE(pi1): 2.690e-03, MSE(pi2): 5.902e-06, MSE(pi3): 6.942e-04\n",
      "Epoch 73500, Train loss: 1.616e+02, Test loss: 4.196e+03, MSE(e): 6.531e-06, MSE(pi1): 2.682e-03, MSE(pi2): 5.886e-06, MSE(pi3): 6.948e-04\n",
      "Epoch 73600, Train loss: 1.613e+02, Test loss: 4.190e+03, MSE(e): 6.501e-06, MSE(pi1): 2.676e-03, MSE(pi2): 5.872e-06, MSE(pi3): 6.952e-04\n",
      "Epoch 73700, Train loss: 1.614e+02, Test loss: 4.185e+03, MSE(e): 6.503e-06, MSE(pi1): 2.678e-03, MSE(pi2): 5.866e-06, MSE(pi3): 6.955e-04\n",
      "Epoch 73800, Train loss: 1.612e+02, Test loss: 4.179e+03, MSE(e): 6.484e-06, MSE(pi1): 2.723e-03, MSE(pi2): 5.856e-06, MSE(pi3): 6.917e-04\n",
      "Epoch 73900, Train loss: 1.609e+02, Test loss: 4.173e+03, MSE(e): 6.469e-06, MSE(pi1): 2.677e-03, MSE(pi2): 5.848e-06, MSE(pi3): 6.944e-04\n",
      "Epoch 74000, Train loss: 1.611e+02, Test loss: 4.168e+03, MSE(e): 6.457e-06, MSE(pi1): 2.702e-03, MSE(pi2): 5.836e-06, MSE(pi3): 6.952e-04\n",
      "Epoch 74100, Train loss: 1.606e+02, Test loss: 4.162e+03, MSE(e): 6.449e-06, MSE(pi1): 2.658e-03, MSE(pi2): 5.827e-06, MSE(pi3): 6.957e-04\n",
      "Epoch 74200, Train loss: 1.605e+02, Test loss: 4.158e+03, MSE(e): 6.422e-06, MSE(pi1): 2.649e-03, MSE(pi2): 5.822e-06, MSE(pi3): 6.982e-04\n",
      "Epoch 74300, Train loss: 1.602e+02, Test loss: 4.152e+03, MSE(e): 6.394e-06, MSE(pi1): 2.705e-03, MSE(pi2): 5.809e-06, MSE(pi3): 6.920e-04\n",
      "Epoch 74400, Train loss: 1.605e+02, Test loss: 4.145e+03, MSE(e): 6.438e-06, MSE(pi1): 2.665e-03, MSE(pi2): 5.802e-06, MSE(pi3): 6.947e-04\n",
      "Epoch 74500, Train loss: 1.601e+02, Test loss: 4.140e+03, MSE(e): 6.395e-06, MSE(pi1): 2.695e-03, MSE(pi2): 5.788e-06, MSE(pi3): 6.923e-04\n",
      "Epoch 74600, Train loss: 1.606e+02, Test loss: 4.134e+03, MSE(e): 6.443e-06, MSE(pi1): 2.658e-03, MSE(pi2): 5.785e-06, MSE(pi3): 6.955e-04\n",
      "Epoch 74700, Train loss: 1.602e+02, Test loss: 4.128e+03, MSE(e): 6.410e-06, MSE(pi1): 2.670e-03, MSE(pi2): 5.772e-06, MSE(pi3): 6.937e-04\n",
      "Epoch 74800, Train loss: 1.599e+02, Test loss: 4.123e+03, MSE(e): 6.387e-06, MSE(pi1): 2.689e-03, MSE(pi2): 5.761e-06, MSE(pi3): 6.914e-04\n",
      "Epoch 74900, Train loss: 1.598e+02, Test loss: 4.118e+03, MSE(e): 6.370e-06, MSE(pi1): 2.696e-03, MSE(pi2): 5.757e-06, MSE(pi3): 6.915e-04\n",
      "Epoch 75000, Train loss: 1.598e+02, Test loss: 4.112e+03, MSE(e): 6.363e-06, MSE(pi1): 2.727e-03, MSE(pi2): 5.743e-06, MSE(pi3): 6.887e-04\n",
      "Epoch 75100, Train loss: 1.600e+02, Test loss: 4.106e+03, MSE(e): 6.382e-06, MSE(pi1): 2.696e-03, MSE(pi2): 5.742e-06, MSE(pi3): 6.919e-04\n",
      "Epoch 75200, Train loss: 1.598e+02, Test loss: 4.101e+03, MSE(e): 6.376e-06, MSE(pi1): 2.669e-03, MSE(pi2): 5.730e-06, MSE(pi3): 6.938e-04\n",
      "Epoch 75300, Train loss: 1.598e+02, Test loss: 4.095e+03, MSE(e): 6.370e-06, MSE(pi1): 2.664e-03, MSE(pi2): 5.720e-06, MSE(pi3): 6.941e-04\n",
      "Epoch 75400, Train loss: 1.595e+02, Test loss: 4.089e+03, MSE(e): 6.355e-06, MSE(pi1): 2.701e-03, MSE(pi2): 5.711e-06, MSE(pi3): 6.892e-04\n",
      "Epoch 75500, Train loss: 1.591e+02, Test loss: 4.084e+03, MSE(e): 6.315e-06, MSE(pi1): 2.676e-03, MSE(pi2): 5.696e-06, MSE(pi3): 6.917e-04\n",
      "Epoch 75600, Train loss: 1.591e+02, Test loss: 4.079e+03, MSE(e): 6.309e-06, MSE(pi1): 2.683e-03, MSE(pi2): 5.690e-06, MSE(pi3): 6.921e-04\n",
      "Epoch 75700, Train loss: 1.588e+02, Test loss: 4.073e+03, MSE(e): 6.292e-06, MSE(pi1): 2.666e-03, MSE(pi2): 5.675e-06, MSE(pi3): 6.919e-04\n",
      "Epoch 75800, Train loss: 1.589e+02, Test loss: 4.069e+03, MSE(e): 6.294e-06, MSE(pi1): 2.656e-03, MSE(pi2): 5.670e-06, MSE(pi3): 6.935e-04\n",
      "Epoch 75900, Train loss: 1.584e+02, Test loss: 4.063e+03, MSE(e): 6.257e-06, MSE(pi1): 2.676e-03, MSE(pi2): 5.660e-06, MSE(pi3): 6.906e-04\n",
      "Epoch 76000, Train loss: 1.583e+02, Test loss: 4.058e+03, MSE(e): 6.236e-06, MSE(pi1): 2.707e-03, MSE(pi2): 5.649e-06, MSE(pi3): 6.887e-04\n",
      "Epoch 76100, Train loss: 1.583e+02, Test loss: 4.052e+03, MSE(e): 6.249e-06, MSE(pi1): 2.659e-03, MSE(pi2): 5.643e-06, MSE(pi3): 6.925e-04\n",
      "Epoch 76200, Train loss: 1.581e+02, Test loss: 4.047e+03, MSE(e): 6.221e-06, MSE(pi1): 2.688e-03, MSE(pi2): 5.630e-06, MSE(pi3): 6.905e-04\n",
      "Epoch 76300, Train loss: 1.578e+02, Test loss: 4.041e+03, MSE(e): 6.208e-06, MSE(pi1): 2.648e-03, MSE(pi2): 5.616e-06, MSE(pi3): 6.926e-04\n",
      "Epoch 76400, Train loss: 1.578e+02, Test loss: 4.035e+03, MSE(e): 6.198e-06, MSE(pi1): 2.657e-03, MSE(pi2): 5.608e-06, MSE(pi3): 6.929e-04\n",
      "Epoch 76500, Train loss: 1.575e+02, Test loss: 4.030e+03, MSE(e): 6.179e-06, MSE(pi1): 2.654e-03, MSE(pi2): 5.600e-06, MSE(pi3): 6.920e-04\n",
      "Epoch 76600, Train loss: 1.576e+02, Test loss: 4.025e+03, MSE(e): 6.188e-06, MSE(pi1): 2.689e-03, MSE(pi2): 5.598e-06, MSE(pi3): 6.885e-04\n",
      "Epoch 76700, Train loss: 1.573e+02, Test loss: 4.021e+03, MSE(e): 6.150e-06, MSE(pi1): 2.665e-03, MSE(pi2): 5.584e-06, MSE(pi3): 6.914e-04\n",
      "Epoch 76800, Train loss: 1.572e+02, Test loss: 4.016e+03, MSE(e): 6.140e-06, MSE(pi1): 2.727e-03, MSE(pi2): 5.579e-06, MSE(pi3): 6.848e-04\n",
      "Epoch 76900, Train loss: 1.572e+02, Test loss: 4.010e+03, MSE(e): 6.155e-06, MSE(pi1): 2.690e-03, MSE(pi2): 5.565e-06, MSE(pi3): 6.877e-04\n",
      "Epoch 77000, Train loss: 1.570e+02, Test loss: 4.004e+03, MSE(e): 6.146e-06, MSE(pi1): 2.666e-03, MSE(pi2): 5.559e-06, MSE(pi3): 6.889e-04\n",
      "Epoch 77100, Train loss: 1.569e+02, Test loss: 3.999e+03, MSE(e): 6.133e-06, MSE(pi1): 2.677e-03, MSE(pi2): 5.552e-06, MSE(pi3): 6.878e-04\n",
      "Epoch 77200, Train loss: 1.569e+02, Test loss: 3.995e+03, MSE(e): 6.114e-06, MSE(pi1): 2.746e-03, MSE(pi2): 5.541e-06, MSE(pi3): 6.826e-04\n",
      "Epoch 77300, Train loss: 1.566e+02, Test loss: 3.989e+03, MSE(e): 6.103e-06, MSE(pi1): 2.680e-03, MSE(pi2): 5.534e-06, MSE(pi3): 6.872e-04\n",
      "Epoch 77400, Train loss: 1.564e+02, Test loss: 3.984e+03, MSE(e): 6.081e-06, MSE(pi1): 2.683e-03, MSE(pi2): 5.522e-06, MSE(pi3): 6.876e-04\n",
      "Epoch 77500, Train loss: 1.561e+02, Test loss: 3.979e+03, MSE(e): 6.057e-06, MSE(pi1): 2.685e-03, MSE(pi2): 5.511e-06, MSE(pi3): 6.864e-04\n",
      "Epoch 77600, Train loss: 1.559e+02, Test loss: 3.973e+03, MSE(e): 6.046e-06, MSE(pi1): 2.671e-03, MSE(pi2): 5.504e-06, MSE(pi3): 6.874e-04\n",
      "Epoch 77700, Train loss: 1.557e+02, Test loss: 3.969e+03, MSE(e): 6.030e-06, MSE(pi1): 2.662e-03, MSE(pi2): 5.497e-06, MSE(pi3): 6.883e-04\n",
      "Epoch 77800, Train loss: 1.557e+02, Test loss: 3.963e+03, MSE(e): 6.026e-06, MSE(pi1): 2.658e-03, MSE(pi2): 5.488e-06, MSE(pi3): 6.886e-04\n",
      "Epoch 77900, Train loss: 1.559e+02, Test loss: 3.958e+03, MSE(e): 6.041e-06, MSE(pi1): 2.711e-03, MSE(pi2): 5.482e-06, MSE(pi3): 6.833e-04\n",
      "Epoch 78000, Train loss: 1.556e+02, Test loss: 3.953e+03, MSE(e): 6.015e-06, MSE(pi1): 2.683e-03, MSE(pi2): 5.473e-06, MSE(pi3): 6.858e-04\n",
      "Epoch 78100, Train loss: 1.554e+02, Test loss: 3.947e+03, MSE(e): 5.999e-06, MSE(pi1): 2.673e-03, MSE(pi2): 5.463e-06, MSE(pi3): 6.866e-04\n",
      "Epoch 78200, Train loss: 1.552e+02, Test loss: 3.943e+03, MSE(e): 5.989e-06, MSE(pi1): 2.658e-03, MSE(pi2): 5.454e-06, MSE(pi3): 6.876e-04\n",
      "Epoch 78300, Train loss: 1.550e+02, Test loss: 3.938e+03, MSE(e): 5.965e-06, MSE(pi1): 2.665e-03, MSE(pi2): 5.447e-06, MSE(pi3): 6.873e-04\n",
      "Epoch 78400, Train loss: 1.551e+02, Test loss: 3.932e+03, MSE(e): 5.977e-06, MSE(pi1): 2.652e-03, MSE(pi2): 5.435e-06, MSE(pi3): 6.882e-04\n",
      "Epoch 78500, Train loss: 1.549e+02, Test loss: 3.927e+03, MSE(e): 5.956e-06, MSE(pi1): 2.672e-03, MSE(pi2): 5.427e-06, MSE(pi3): 6.860e-04\n",
      "Epoch 78600, Train loss: 1.550e+02, Test loss: 3.921e+03, MSE(e): 5.971e-06, MSE(pi1): 2.638e-03, MSE(pi2): 5.415e-06, MSE(pi3): 6.891e-04\n",
      "Epoch 78700, Train loss: 1.549e+02, Test loss: 3.918e+03, MSE(e): 5.938e-06, MSE(pi1): 2.696e-03, MSE(pi2): 5.405e-06, MSE(pi3): 6.856e-04\n",
      "Epoch 78800, Train loss: 1.547e+02, Test loss: 3.913e+03, MSE(e): 5.929e-06, MSE(pi1): 2.695e-03, MSE(pi2): 5.398e-06, MSE(pi3): 6.844e-04\n",
      "Epoch 78900, Train loss: 1.545e+02, Test loss: 3.907e+03, MSE(e): 5.924e-06, MSE(pi1): 2.648e-03, MSE(pi2): 5.390e-06, MSE(pi3): 6.878e-04\n",
      "Epoch 79000, Train loss: 1.546e+02, Test loss: 3.902e+03, MSE(e): 5.924e-06, MSE(pi1): 2.638e-03, MSE(pi2): 5.382e-06, MSE(pi3): 6.893e-04\n",
      "Epoch 79100, Train loss: 1.541e+02, Test loss: 3.897e+03, MSE(e): 5.887e-06, MSE(pi1): 2.617e-03, MSE(pi2): 5.375e-06, MSE(pi3): 6.903e-04\n",
      "Epoch 79200, Train loss: 1.541e+02, Test loss: 3.892e+03, MSE(e): 5.887e-06, MSE(pi1): 2.643e-03, MSE(pi2): 5.365e-06, MSE(pi3): 6.875e-04\n",
      "Epoch 79300, Train loss: 1.541e+02, Test loss: 3.887e+03, MSE(e): 5.873e-06, MSE(pi1): 2.682e-03, MSE(pi2): 5.360e-06, MSE(pi3): 6.850e-04\n",
      "Epoch 79400, Train loss: 1.540e+02, Test loss: 3.882e+03, MSE(e): 5.884e-06, MSE(pi1): 2.658e-03, MSE(pi2): 5.351e-06, MSE(pi3): 6.854e-04\n",
      "Epoch 79500, Train loss: 1.538e+02, Test loss: 3.877e+03, MSE(e): 5.863e-06, MSE(pi1): 2.668e-03, MSE(pi2): 5.342e-06, MSE(pi3): 6.843e-04\n",
      "Epoch 79600, Train loss: 1.536e+02, Test loss: 3.874e+03, MSE(e): 5.838e-06, MSE(pi1): 2.733e-03, MSE(pi2): 5.339e-06, MSE(pi3): 6.789e-04\n",
      "Epoch 79700, Train loss: 1.536e+02, Test loss: 3.868e+03, MSE(e): 5.835e-06, MSE(pi1): 2.742e-03, MSE(pi2): 5.329e-06, MSE(pi3): 6.781e-04\n",
      "Epoch 79800, Train loss: 1.534e+02, Test loss: 3.864e+03, MSE(e): 5.826e-06, MSE(pi1): 2.669e-03, MSE(pi2): 5.324e-06, MSE(pi3): 6.843e-04\n",
      "Epoch 79900, Train loss: 1.532e+02, Test loss: 3.858e+03, MSE(e): 5.813e-06, MSE(pi1): 2.653e-03, MSE(pi2): 5.311e-06, MSE(pi3): 6.856e-04\n",
      "Epoch 80000, Train loss: 1.536e+02, Test loss: 3.853e+03, MSE(e): 5.826e-06, MSE(pi1): 2.675e-03, MSE(pi2): 5.300e-06, MSE(pi3): 6.861e-04\n",
      "Epoch 80100, Train loss: 1.532e+02, Test loss: 3.848e+03, MSE(e): 5.801e-06, MSE(pi1): 2.684e-03, MSE(pi2): 5.290e-06, MSE(pi3): 6.831e-04\n",
      "Epoch 80200, Train loss: 1.531e+02, Test loss: 3.842e+03, MSE(e): 5.801e-06, MSE(pi1): 2.664e-03, MSE(pi2): 5.281e-06, MSE(pi3): 6.841e-04\n",
      "Epoch 80300, Train loss: 1.528e+02, Test loss: 3.839e+03, MSE(e): 5.772e-06, MSE(pi1): 2.656e-03, MSE(pi2): 5.278e-06, MSE(pi3): 6.851e-04\n",
      "Epoch 80400, Train loss: 1.526e+02, Test loss: 3.834e+03, MSE(e): 5.764e-06, MSE(pi1): 2.653e-03, MSE(pi2): 5.272e-06, MSE(pi3): 6.839e-04\n",
      "Epoch 80500, Train loss: 1.526e+02, Test loss: 3.829e+03, MSE(e): 5.761e-06, MSE(pi1): 2.630e-03, MSE(pi2): 5.263e-06, MSE(pi3): 6.865e-04\n",
      "Epoch 80600, Train loss: 1.523e+02, Test loss: 3.824e+03, MSE(e): 5.737e-06, MSE(pi1): 2.645e-03, MSE(pi2): 5.258e-06, MSE(pi3): 6.851e-04\n",
      "Epoch 80700, Train loss: 1.522e+02, Test loss: 3.820e+03, MSE(e): 5.729e-06, MSE(pi1): 2.665e-03, MSE(pi2): 5.249e-06, MSE(pi3): 6.829e-04\n",
      "Epoch 80800, Train loss: 1.523e+02, Test loss: 3.814e+03, MSE(e): 5.729e-06, MSE(pi1): 2.647e-03, MSE(pi2): 5.237e-06, MSE(pi3): 6.855e-04\n",
      "Epoch 80900, Train loss: 1.523e+02, Test loss: 3.809e+03, MSE(e): 5.718e-06, MSE(pi1): 2.640e-03, MSE(pi2): 5.230e-06, MSE(pi3): 6.868e-04\n",
      "Epoch 81000, Train loss: 1.520e+02, Test loss: 3.805e+03, MSE(e): 5.703e-06, MSE(pi1): 2.648e-03, MSE(pi2): 5.223e-06, MSE(pi3): 6.845e-04\n",
      "Epoch 81100, Train loss: 1.519e+02, Test loss: 3.799e+03, MSE(e): 5.708e-06, MSE(pi1): 2.624e-03, MSE(pi2): 5.215e-06, MSE(pi3): 6.858e-04\n",
      "Epoch 81200, Train loss: 1.516e+02, Test loss: 3.795e+03, MSE(e): 5.681e-06, MSE(pi1): 2.621e-03, MSE(pi2): 5.208e-06, MSE(pi3): 6.860e-04\n",
      "Epoch 81300, Train loss: 1.518e+02, Test loss: 3.789e+03, MSE(e): 5.697e-06, MSE(pi1): 2.670e-03, MSE(pi2): 5.195e-06, MSE(pi3): 6.808e-04\n",
      "Epoch 81400, Train loss: 1.517e+02, Test loss: 3.785e+03, MSE(e): 5.700e-06, MSE(pi1): 2.658e-03, MSE(pi2): 5.190e-06, MSE(pi3): 6.810e-04\n",
      "Epoch 81500, Train loss: 1.518e+02, Test loss: 3.780e+03, MSE(e): 5.694e-06, MSE(pi1): 2.687e-03, MSE(pi2): 5.182e-06, MSE(pi3): 6.798e-04\n",
      "Epoch 81600, Train loss: 1.519e+02, Test loss: 3.775e+03, MSE(e): 5.716e-06, MSE(pi1): 2.672e-03, MSE(pi2): 5.179e-06, MSE(pi3): 6.799e-04\n",
      "Epoch 81700, Train loss: 1.518e+02, Test loss: 3.770e+03, MSE(e): 5.715e-06, MSE(pi1): 2.674e-03, MSE(pi2): 5.171e-06, MSE(pi3): 6.793e-04\n",
      "Epoch 81800, Train loss: 1.520e+02, Test loss: 3.766e+03, MSE(e): 5.705e-06, MSE(pi1): 2.745e-03, MSE(pi2): 5.167e-06, MSE(pi3): 6.752e-04\n",
      "Epoch 81900, Train loss: 1.527e+02, Test loss: 3.761e+03, MSE(e): 5.794e-06, MSE(pi1): 2.699e-03, MSE(pi2): 5.188e-06, MSE(pi3): 6.777e-04\n",
      "Epoch 82000, Train loss: 1.518e+02, Test loss: 3.756e+03, MSE(e): 5.719e-06, MSE(pi1): 2.689e-03, MSE(pi2): 5.159e-06, MSE(pi3): 6.776e-04\n",
      "Epoch 82100, Train loss: 1.523e+02, Test loss: 3.751e+03, MSE(e): 5.762e-06, MSE(pi1): 2.689e-03, MSE(pi2): 5.169e-06, MSE(pi3): 6.776e-04\n",
      "Epoch 82200, Train loss: 1.517e+02, Test loss: 3.746e+03, MSE(e): 5.705e-06, MSE(pi1): 2.694e-03, MSE(pi2): 5.146e-06, MSE(pi3): 6.768e-04\n",
      "Epoch 82300, Train loss: 1.513e+02, Test loss: 3.741e+03, MSE(e): 5.657e-06, MSE(pi1): 2.631e-03, MSE(pi2): 5.119e-06, MSE(pi3): 6.837e-04\n",
      "Epoch 82400, Train loss: 1.507e+02, Test loss: 3.738e+03, MSE(e): 5.606e-06, MSE(pi1): 2.677e-03, MSE(pi2): 5.108e-06, MSE(pi3): 6.782e-04\n",
      "Epoch 82500, Train loss: 1.503e+02, Test loss: 3.734e+03, MSE(e): 5.570e-06, MSE(pi1): 2.629e-03, MSE(pi2): 5.101e-06, MSE(pi3): 6.826e-04\n",
      "Epoch 82600, Train loss: 1.501e+02, Test loss: 3.730e+03, MSE(e): 5.558e-06, MSE(pi1): 2.619e-03, MSE(pi2): 5.095e-06, MSE(pi3): 6.834e-04\n",
      "Epoch 82700, Train loss: 1.499e+02, Test loss: 3.725e+03, MSE(e): 5.550e-06, MSE(pi1): 2.645e-03, MSE(pi2): 5.090e-06, MSE(pi3): 6.793e-04\n",
      "Epoch 82800, Train loss: 1.500e+02, Test loss: 3.721e+03, MSE(e): 5.555e-06, MSE(pi1): 2.702e-03, MSE(pi2): 5.081e-06, MSE(pi3): 6.746e-04\n",
      "Epoch 82900, Train loss: 1.511e+02, Test loss: 3.716e+03, MSE(e): 5.646e-06, MSE(pi1): 2.709e-03, MSE(pi2): 5.092e-06, MSE(pi3): 6.755e-04\n",
      "Epoch 83000, Train loss: 1.508e+02, Test loss: 3.710e+03, MSE(e): 5.638e-06, MSE(pi1): 2.672e-03, MSE(pi2): 5.083e-06, MSE(pi3): 6.768e-04\n",
      "Epoch 83100, Train loss: 1.502e+02, Test loss: 3.705e+03, MSE(e): 5.575e-06, MSE(pi1): 2.665e-03, MSE(pi2): 5.058e-06, MSE(pi3): 6.780e-04\n",
      "Epoch 83200, Train loss: 1.497e+02, Test loss: 3.701e+03, MSE(e): 5.534e-06, MSE(pi1): 2.625e-03, MSE(pi2): 5.045e-06, MSE(pi3): 6.807e-04\n",
      "Epoch 83300, Train loss: 1.494e+02, Test loss: 3.698e+03, MSE(e): 5.502e-06, MSE(pi1): 2.648e-03, MSE(pi2): 5.040e-06, MSE(pi3): 6.791e-04\n",
      "Epoch 83400, Train loss: 1.496e+02, Test loss: 3.693e+03, MSE(e): 5.496e-06, MSE(pi1): 2.613e-03, MSE(pi2): 5.031e-06, MSE(pi3): 6.851e-04\n",
      "Epoch 83500, Train loss: 1.492e+02, Test loss: 3.690e+03, MSE(e): 5.478e-06, MSE(pi1): 2.632e-03, MSE(pi2): 5.029e-06, MSE(pi3): 6.809e-04\n",
      "Epoch 83600, Train loss: 1.493e+02, Test loss: 3.685e+03, MSE(e): 5.502e-06, MSE(pi1): 2.703e-03, MSE(pi2): 5.021e-06, MSE(pi3): 6.726e-04\n",
      "Epoch 83700, Train loss: 1.510e+02, Test loss: 3.678e+03, MSE(e): 5.657e-06, MSE(pi1): 2.701e-03, MSE(pi2): 5.062e-06, MSE(pi3): 6.739e-04\n",
      "Epoch 83800, Train loss: 1.494e+02, Test loss: 3.674e+03, MSE(e): 5.513e-06, MSE(pi1): 2.655e-03, MSE(pi2): 5.006e-06, MSE(pi3): 6.775e-04\n",
      "Epoch 83900, Train loss: 1.489e+02, Test loss: 3.670e+03, MSE(e): 5.462e-06, MSE(pi1): 2.645e-03, MSE(pi2): 4.992e-06, MSE(pi3): 6.778e-04\n",
      "Epoch 84000, Train loss: 1.487e+02, Test loss: 3.667e+03, MSE(e): 5.445e-06, MSE(pi1): 2.618e-03, MSE(pi2): 4.987e-06, MSE(pi3): 6.807e-04\n",
      "Epoch 84100, Train loss: 1.488e+02, Test loss: 3.663e+03, MSE(e): 5.452e-06, MSE(pi1): 2.684e-03, MSE(pi2): 4.984e-06, MSE(pi3): 6.739e-04\n",
      "Epoch 84200, Train loss: 1.505e+02, Test loss: 3.657e+03, MSE(e): 5.617e-06, MSE(pi1): 2.681e-03, MSE(pi2): 5.026e-06, MSE(pi3): 6.746e-04\n",
      "Epoch 84300, Train loss: 1.489e+02, Test loss: 3.652e+03, MSE(e): 5.469e-06, MSE(pi1): 2.642e-03, MSE(pi2): 4.969e-06, MSE(pi3): 6.782e-04\n",
      "Epoch 84400, Train loss: 1.485e+02, Test loss: 3.649e+03, MSE(e): 5.428e-06, MSE(pi1): 2.651e-03, MSE(pi2): 4.957e-06, MSE(pi3): 6.769e-04\n",
      "Epoch 84500, Train loss: 1.480e+02, Test loss: 3.646e+03, MSE(e): 5.393e-06, MSE(pi1): 2.642e-03, MSE(pi2): 4.954e-06, MSE(pi3): 6.763e-04\n",
      "Epoch 84600, Train loss: 1.483e+02, Test loss: 3.641e+03, MSE(e): 5.414e-06, MSE(pi1): 2.687e-03, MSE(pi2): 4.944e-06, MSE(pi3): 6.729e-04\n",
      "Epoch 84700, Train loss: 1.493e+02, Test loss: 3.636e+03, MSE(e): 5.493e-06, MSE(pi1): 2.727e-03, MSE(pi2): 4.959e-06, MSE(pi3): 6.711e-04\n",
      "Epoch 84800, Train loss: 1.482e+02, Test loss: 3.631e+03, MSE(e): 5.405e-06, MSE(pi1): 2.665e-03, MSE(pi2): 4.929e-06, MSE(pi3): 6.751e-04\n",
      "Epoch 84900, Train loss: 1.477e+02, Test loss: 3.627e+03, MSE(e): 5.367e-06, MSE(pi1): 2.623e-03, MSE(pi2): 4.922e-06, MSE(pi3): 6.782e-04\n",
      "Epoch 85000, Train loss: 1.478e+02, Test loss: 3.622e+03, MSE(e): 5.368e-06, MSE(pi1): 2.729e-03, MSE(pi2): 4.920e-06, MSE(pi3): 6.680e-04\n",
      "Epoch 85100, Train loss: 1.483e+02, Test loss: 3.619e+03, MSE(e): 5.404e-06, MSE(pi1): 2.710e-03, MSE(pi2): 4.912e-06, MSE(pi3): 6.718e-04\n",
      "Epoch 85200, Train loss: 1.475e+02, Test loss: 3.614e+03, MSE(e): 5.353e-06, MSE(pi1): 2.628e-03, MSE(pi2): 4.898e-06, MSE(pi3): 6.765e-04\n",
      "Epoch 85300, Train loss: 1.473e+02, Test loss: 3.611e+03, MSE(e): 5.332e-06, MSE(pi1): 2.690e-03, MSE(pi2): 4.889e-06, MSE(pi3): 6.703e-04\n",
      "Epoch 85400, Train loss: 1.478e+02, Test loss: 3.606e+03, MSE(e): 5.378e-06, MSE(pi1): 2.690e-03, MSE(pi2): 4.891e-06, MSE(pi3): 6.714e-04\n",
      "Epoch 85500, Train loss: 1.473e+02, Test loss: 3.602e+03, MSE(e): 5.322e-06, MSE(pi1): 2.677e-03, MSE(pi2): 4.876e-06, MSE(pi3): 6.731e-04\n",
      "Epoch 85600, Train loss: 1.473e+02, Test loss: 3.597e+03, MSE(e): 5.342e-06, MSE(pi1): 2.671e-03, MSE(pi2): 4.861e-06, MSE(pi3): 6.718e-04\n",
      "Epoch 85700, Train loss: 1.472e+02, Test loss: 3.592e+03, MSE(e): 5.319e-06, MSE(pi1): 2.640e-03, MSE(pi2): 4.856e-06, MSE(pi3): 6.764e-04\n",
      "Epoch 85800, Train loss: 1.475e+02, Test loss: 3.589e+03, MSE(e): 5.352e-06, MSE(pi1): 2.667e-03, MSE(pi2): 4.861e-06, MSE(pi3): 6.728e-04\n",
      "Epoch 85900, Train loss: 1.476e+02, Test loss: 3.583e+03, MSE(e): 5.372e-06, MSE(pi1): 2.650e-03, MSE(pi2): 4.862e-06, MSE(pi3): 6.736e-04\n",
      "Epoch 86000, Train loss: 1.470e+02, Test loss: 3.580e+03, MSE(e): 5.301e-06, MSE(pi1): 2.644e-03, MSE(pi2): 4.841e-06, MSE(pi3): 6.756e-04\n",
      "Epoch 86100, Train loss: 1.464e+02, Test loss: 3.577e+03, MSE(e): 5.264e-06, MSE(pi1): 2.620e-03, MSE(pi2): 4.837e-06, MSE(pi3): 6.755e-04\n",
      "Epoch 86200, Train loss: 1.464e+02, Test loss: 3.573e+03, MSE(e): 5.258e-06, MSE(pi1): 2.672e-03, MSE(pi2): 4.831e-06, MSE(pi3): 6.707e-04\n",
      "Epoch 86300, Train loss: 1.475e+02, Test loss: 3.567e+03, MSE(e): 5.365e-06, MSE(pi1): 2.645e-03, MSE(pi2): 4.843e-06, MSE(pi3): 6.735e-04\n",
      "Epoch 86400, Train loss: 1.465e+02, Test loss: 3.563e+03, MSE(e): 5.269e-06, MSE(pi1): 2.631e-03, MSE(pi2): 4.811e-06, MSE(pi3): 6.746e-04\n",
      "Epoch 86500, Train loss: 1.460e+02, Test loss: 3.560e+03, MSE(e): 5.231e-06, MSE(pi1): 2.629e-03, MSE(pi2): 4.806e-06, MSE(pi3): 6.736e-04\n",
      "Epoch 86600, Train loss: 1.472e+02, Test loss: 3.555e+03, MSE(e): 5.337e-06, MSE(pi1): 2.622e-03, MSE(pi2): 4.818e-06, MSE(pi3): 6.760e-04\n",
      "Epoch 86700, Train loss: 1.462e+02, Test loss: 3.551e+03, MSE(e): 5.243e-06, MSE(pi1): 2.646e-03, MSE(pi2): 4.789e-06, MSE(pi3): 6.730e-04\n",
      "Epoch 86800, Train loss: 1.458e+02, Test loss: 3.548e+03, MSE(e): 5.211e-06, MSE(pi1): 2.631e-03, MSE(pi2): 4.786e-06, MSE(pi3): 6.738e-04\n",
      "Epoch 86900, Train loss: 1.462e+02, Test loss: 3.542e+03, MSE(e): 5.240e-06, MSE(pi1): 2.643e-03, MSE(pi2): 4.775e-06, MSE(pi3): 6.740e-04\n",
      "Epoch 87000, Train loss: 1.459e+02, Test loss: 3.540e+03, MSE(e): 5.203e-06, MSE(pi1): 2.663e-03, MSE(pi2): 4.771e-06, MSE(pi3): 6.722e-04\n",
      "Epoch 87100, Train loss: 1.465e+02, Test loss: 3.534e+03, MSE(e): 5.281e-06, MSE(pi1): 2.629e-03, MSE(pi2): 4.775e-06, MSE(pi3): 6.740e-04\n",
      "Epoch 87200, Train loss: 1.456e+02, Test loss: 3.531e+03, MSE(e): 5.192e-06, MSE(pi1): 2.620e-03, MSE(pi2): 4.751e-06, MSE(pi3): 6.750e-04\n",
      "Epoch 87300, Train loss: 1.452e+02, Test loss: 3.528e+03, MSE(e): 5.171e-06, MSE(pi1): 2.628e-03, MSE(pi2): 4.733e-06, MSE(pi3): 6.724e-04\n",
      "Epoch 87400, Train loss: 1.452e+02, Test loss: 3.524e+03, MSE(e): 5.163e-06, MSE(pi1): 2.599e-03, MSE(pi2): 4.741e-06, MSE(pi3): 6.756e-04\n",
      "Epoch 87500, Train loss: 1.452e+02, Test loss: 3.520e+03, MSE(e): 5.157e-06, MSE(pi1): 2.593e-03, MSE(pi2): 4.748e-06, MSE(pi3): 6.766e-04\n",
      "Epoch 87600, Train loss: 1.453e+02, Test loss: 3.516e+03, MSE(e): 5.157e-06, MSE(pi1): 2.596e-03, MSE(pi2): 4.748e-06, MSE(pi3): 6.772e-04\n",
      "Epoch 87700, Train loss: 1.449e+02, Test loss: 3.511e+03, MSE(e): 5.148e-06, MSE(pi1): 2.609e-03, MSE(pi2): 4.743e-06, MSE(pi3): 6.738e-04\n",
      "Epoch 87800, Train loss: 1.450e+02, Test loss: 3.507e+03, MSE(e): 5.145e-06, MSE(pi1): 2.605e-03, MSE(pi2): 4.736e-06, MSE(pi3): 6.751e-04\n",
      "Epoch 87900, Train loss: 1.449e+02, Test loss: 3.502e+03, MSE(e): 5.137e-06, MSE(pi1): 2.628e-03, MSE(pi2): 4.731e-06, MSE(pi3): 6.724e-04\n",
      "Epoch 88000, Train loss: 1.447e+02, Test loss: 3.498e+03, MSE(e): 5.127e-06, MSE(pi1): 2.611e-03, MSE(pi2): 4.726e-06, MSE(pi3): 6.737e-04\n",
      "Epoch 88100, Train loss: 1.447e+02, Test loss: 3.493e+03, MSE(e): 5.119e-06, MSE(pi1): 2.622e-03, MSE(pi2): 4.718e-06, MSE(pi3): 6.729e-04\n",
      "Epoch 88200, Train loss: 1.446e+02, Test loss: 3.488e+03, MSE(e): 5.114e-06, MSE(pi1): 2.635e-03, MSE(pi2): 4.709e-06, MSE(pi3): 6.708e-04\n",
      "Epoch 88300, Train loss: 1.446e+02, Test loss: 3.484e+03, MSE(e): 5.107e-06, MSE(pi1): 2.614e-03, MSE(pi2): 4.709e-06, MSE(pi3): 6.743e-04\n",
      "Epoch 88400, Train loss: 1.445e+02, Test loss: 3.479e+03, MSE(e): 5.101e-06, MSE(pi1): 2.648e-03, MSE(pi2): 4.698e-06, MSE(pi3): 6.698e-04\n",
      "Epoch 88500, Train loss: 1.442e+02, Test loss: 3.475e+03, MSE(e): 5.089e-06, MSE(pi1): 2.631e-03, MSE(pi2): 4.694e-06, MSE(pi3): 6.703e-04\n",
      "Epoch 88600, Train loss: 1.444e+02, Test loss: 3.470e+03, MSE(e): 5.087e-06, MSE(pi1): 2.591e-03, MSE(pi2): 4.689e-06, MSE(pi3): 6.759e-04\n",
      "Epoch 88700, Train loss: 1.441e+02, Test loss: 3.466e+03, MSE(e): 5.072e-06, MSE(pi1): 2.632e-03, MSE(pi2): 4.680e-06, MSE(pi3): 6.707e-04\n",
      "Epoch 88800, Train loss: 1.442e+02, Test loss: 3.461e+03, MSE(e): 5.073e-06, MSE(pi1): 2.612e-03, MSE(pi2): 4.677e-06, MSE(pi3): 6.730e-04\n",
      "Epoch 88900, Train loss: 1.440e+02, Test loss: 3.457e+03, MSE(e): 5.064e-06, MSE(pi1): 2.594e-03, MSE(pi2): 4.670e-06, MSE(pi3): 6.743e-04\n",
      "Epoch 89000, Train loss: 1.439e+02, Test loss: 3.452e+03, MSE(e): 5.058e-06, MSE(pi1): 2.601e-03, MSE(pi2): 4.663e-06, MSE(pi3): 6.729e-04\n",
      "Epoch 89100, Train loss: 1.440e+02, Test loss: 3.449e+03, MSE(e): 5.047e-06, MSE(pi1): 2.663e-03, MSE(pi2): 4.654e-06, MSE(pi3): 6.688e-04\n",
      "Epoch 89200, Train loss: 1.437e+02, Test loss: 3.443e+03, MSE(e): 5.046e-06, MSE(pi1): 2.613e-03, MSE(pi2): 4.648e-06, MSE(pi3): 6.713e-04\n",
      "Epoch 89300, Train loss: 1.436e+02, Test loss: 3.439e+03, MSE(e): 5.040e-06, MSE(pi1): 2.620e-03, MSE(pi2): 4.642e-06, MSE(pi3): 6.699e-04\n",
      "Epoch 89400, Train loss: 1.435e+02, Test loss: 3.435e+03, MSE(e): 5.029e-06, MSE(pi1): 2.633e-03, MSE(pi2): 4.635e-06, MSE(pi3): 6.687e-04\n",
      "Epoch 89500, Train loss: 1.435e+02, Test loss: 3.431e+03, MSE(e): 5.020e-06, MSE(pi1): 2.644e-03, MSE(pi2): 4.629e-06, MSE(pi3): 6.681e-04\n",
      "Epoch 89600, Train loss: 1.433e+02, Test loss: 3.426e+03, MSE(e): 5.016e-06, MSE(pi1): 2.594e-03, MSE(pi2): 4.620e-06, MSE(pi3): 6.718e-04\n",
      "Epoch 89700, Train loss: 1.438e+02, Test loss: 3.424e+03, MSE(e): 5.008e-06, MSE(pi1): 2.689e-03, MSE(pi2): 4.617e-06, MSE(pi3): 6.679e-04\n",
      "Epoch 89800, Train loss: 1.435e+02, Test loss: 3.418e+03, MSE(e): 5.005e-06, MSE(pi1): 2.602e-03, MSE(pi2): 4.610e-06, MSE(pi3): 6.738e-04\n",
      "Epoch 89900, Train loss: 1.432e+02, Test loss: 3.415e+03, MSE(e): 4.991e-06, MSE(pi1): 2.647e-03, MSE(pi2): 4.603e-06, MSE(pi3): 6.681e-04\n",
      "Epoch 90000, Train loss: 1.433e+02, Test loss: 3.410e+03, MSE(e): 4.986e-06, MSE(pi1): 2.581e-03, MSE(pi2): 4.602e-06, MSE(pi3): 6.760e-04\n",
      "Epoch 90100, Train loss: 1.430e+02, Test loss: 3.406e+03, MSE(e): 4.981e-06, MSE(pi1): 2.630e-03, MSE(pi2): 4.592e-06, MSE(pi3): 6.686e-04\n",
      "Epoch 90200, Train loss: 1.430e+02, Test loss: 3.402e+03, MSE(e): 4.971e-06, MSE(pi1): 2.658e-03, MSE(pi2): 4.586e-06, MSE(pi3): 6.671e-04\n",
      "Epoch 90300, Train loss: 1.428e+02, Test loss: 3.398e+03, MSE(e): 4.967e-06, MSE(pi1): 2.592e-03, MSE(pi2): 4.581e-06, MSE(pi3): 6.717e-04\n",
      "Epoch 90400, Train loss: 1.426e+02, Test loss: 3.394e+03, MSE(e): 4.954e-06, MSE(pi1): 2.628e-03, MSE(pi2): 4.572e-06, MSE(pi3): 6.680e-04\n",
      "Epoch 90500, Train loss: 1.426e+02, Test loss: 3.390e+03, MSE(e): 4.955e-06, MSE(pi1): 2.629e-03, MSE(pi2): 4.567e-06, MSE(pi3): 6.680e-04\n",
      "Epoch 90600, Train loss: 1.424e+02, Test loss: 3.385e+03, MSE(e): 4.946e-06, MSE(pi1): 2.600e-03, MSE(pi2): 4.560e-06, MSE(pi3): 6.697e-04\n",
      "Epoch 90700, Train loss: 1.426e+02, Test loss: 3.382e+03, MSE(e): 4.942e-06, MSE(pi1): 2.619e-03, MSE(pi2): 4.557e-06, MSE(pi3): 6.698e-04\n",
      "Epoch 90800, Train loss: 1.424e+02, Test loss: 3.377e+03, MSE(e): 4.933e-06, MSE(pi1): 2.632e-03, MSE(pi2): 4.547e-06, MSE(pi3): 6.675e-04\n",
      "Epoch 90900, Train loss: 1.424e+02, Test loss: 3.374e+03, MSE(e): 4.930e-06, MSE(pi1): 2.631e-03, MSE(pi2): 4.539e-06, MSE(pi3): 6.677e-04\n",
      "Epoch 91000, Train loss: 1.424e+02, Test loss: 3.370e+03, MSE(e): 4.922e-06, MSE(pi1): 2.614e-03, MSE(pi2): 4.533e-06, MSE(pi3): 6.708e-04\n",
      "Epoch 91100, Train loss: 1.420e+02, Test loss: 3.366e+03, MSE(e): 4.910e-06, MSE(pi1): 2.602e-03, MSE(pi2): 4.529e-06, MSE(pi3): 6.686e-04\n",
      "Epoch 91200, Train loss: 1.421e+02, Test loss: 3.362e+03, MSE(e): 4.905e-06, MSE(pi1): 2.596e-03, MSE(pi2): 4.522e-06, MSE(pi3): 6.708e-04\n",
      "Epoch 91300, Train loss: 1.421e+02, Test loss: 3.358e+03, MSE(e): 4.903e-06, MSE(pi1): 2.600e-03, MSE(pi2): 4.514e-06, MSE(pi3): 6.704e-04\n",
      "Epoch 91400, Train loss: 1.418e+02, Test loss: 3.354e+03, MSE(e): 4.890e-06, MSE(pi1): 2.625e-03, MSE(pi2): 4.509e-06, MSE(pi3): 6.668e-04\n",
      "Epoch 91500, Train loss: 1.419e+02, Test loss: 3.350e+03, MSE(e): 4.887e-06, MSE(pi1): 2.596e-03, MSE(pi2): 4.501e-06, MSE(pi3): 6.703e-04\n",
      "Epoch 91600, Train loss: 1.417e+02, Test loss: 3.346e+03, MSE(e): 4.877e-06, MSE(pi1): 2.606e-03, MSE(pi2): 4.496e-06, MSE(pi3): 6.685e-04\n",
      "Epoch 91700, Train loss: 1.417e+02, Test loss: 3.342e+03, MSE(e): 4.870e-06, MSE(pi1): 2.604e-03, MSE(pi2): 4.489e-06, MSE(pi3): 6.697e-04\n",
      "Epoch 91800, Train loss: 1.415e+02, Test loss: 3.338e+03, MSE(e): 4.864e-06, MSE(pi1): 2.578e-03, MSE(pi2): 4.485e-06, MSE(pi3): 6.710e-04\n",
      "Epoch 91900, Train loss: 1.416e+02, Test loss: 3.334e+03, MSE(e): 4.861e-06, MSE(pi1): 2.587e-03, MSE(pi2): 4.480e-06, MSE(pi3): 6.714e-04\n",
      "Epoch 92000, Train loss: 1.415e+02, Test loss: 3.331e+03, MSE(e): 4.853e-06, MSE(pi1): 2.574e-03, MSE(pi2): 4.475e-06, MSE(pi3): 6.724e-04\n",
      "Epoch 92100, Train loss: 1.413e+02, Test loss: 3.327e+03, MSE(e): 4.844e-06, MSE(pi1): 2.610e-03, MSE(pi2): 4.464e-06, MSE(pi3): 6.681e-04\n",
      "Epoch 92200, Train loss: 1.413e+02, Test loss: 3.323e+03, MSE(e): 4.834e-06, MSE(pi1): 2.583e-03, MSE(pi2): 4.462e-06, MSE(pi3): 6.715e-04\n",
      "Epoch 92300, Train loss: 1.412e+02, Test loss: 3.320e+03, MSE(e): 4.828e-06, MSE(pi1): 2.583e-03, MSE(pi2): 4.451e-06, MSE(pi3): 6.709e-04\n",
      "Epoch 92400, Train loss: 1.412e+02, Test loss: 3.316e+03, MSE(e): 4.829e-06, MSE(pi1): 2.587e-03, MSE(pi2): 4.447e-06, MSE(pi3): 6.703e-04\n",
      "Epoch 92500, Train loss: 1.412e+02, Test loss: 3.312e+03, MSE(e): 4.822e-06, MSE(pi1): 2.584e-03, MSE(pi2): 4.441e-06, MSE(pi3): 6.715e-04\n",
      "Epoch 92600, Train loss: 1.409e+02, Test loss: 3.308e+03, MSE(e): 4.811e-06, MSE(pi1): 2.623e-03, MSE(pi2): 4.435e-06, MSE(pi3): 6.658e-04\n",
      "Epoch 92700, Train loss: 1.409e+02, Test loss: 3.304e+03, MSE(e): 4.807e-06, MSE(pi1): 2.614e-03, MSE(pi2): 4.429e-06, MSE(pi3): 6.665e-04\n",
      "Epoch 92800, Train loss: 1.408e+02, Test loss: 3.300e+03, MSE(e): 4.802e-06, MSE(pi1): 2.591e-03, MSE(pi2): 4.421e-06, MSE(pi3): 6.688e-04\n",
      "Epoch 92900, Train loss: 1.407e+02, Test loss: 3.297e+03, MSE(e): 4.791e-06, MSE(pi1): 2.606e-03, MSE(pi2): 4.414e-06, MSE(pi3): 6.672e-04\n",
      "Epoch 93000, Train loss: 1.408e+02, Test loss: 3.294e+03, MSE(e): 4.782e-06, MSE(pi1): 2.650e-03, MSE(pi2): 4.408e-06, MSE(pi3): 6.649e-04\n",
      "Epoch 93100, Train loss: 1.405e+02, Test loss: 3.289e+03, MSE(e): 4.784e-06, MSE(pi1): 2.582e-03, MSE(pi2): 4.403e-06, MSE(pi3): 6.683e-04\n",
      "Epoch 93200, Train loss: 1.404e+02, Test loss: 3.286e+03, MSE(e): 4.772e-06, MSE(pi1): 2.583e-03, MSE(pi2): 4.402e-06, MSE(pi3): 6.679e-04\n",
      "Epoch 93300, Train loss: 1.405e+02, Test loss: 3.282e+03, MSE(e): 4.769e-06, MSE(pi1): 2.581e-03, MSE(pi2): 4.393e-06, MSE(pi3): 6.704e-04\n",
      "Epoch 93400, Train loss: 1.403e+02, Test loss: 3.278e+03, MSE(e): 4.757e-06, MSE(pi1): 2.604e-03, MSE(pi2): 4.383e-06, MSE(pi3): 6.670e-04\n",
      "Epoch 93500, Train loss: 1.403e+02, Test loss: 3.274e+03, MSE(e): 4.750e-06, MSE(pi1): 2.592e-03, MSE(pi2): 4.380e-06, MSE(pi3): 6.683e-04\n",
      "Epoch 93600, Train loss: 1.408e+02, Test loss: 3.272e+03, MSE(e): 4.748e-06, MSE(pi1): 2.692e-03, MSE(pi2): 4.372e-06, MSE(pi3): 6.636e-04\n",
      "Epoch 93700, Train loss: 1.400e+02, Test loss: 3.267e+03, MSE(e): 4.740e-06, MSE(pi1): 2.591e-03, MSE(pi2): 4.369e-06, MSE(pi3): 6.672e-04\n",
      "Epoch 93800, Train loss: 1.399e+02, Test loss: 3.264e+03, MSE(e): 4.731e-06, MSE(pi1): 2.601e-03, MSE(pi2): 4.364e-06, MSE(pi3): 6.660e-04\n",
      "Epoch 93900, Train loss: 1.400e+02, Test loss: 3.260e+03, MSE(e): 4.730e-06, MSE(pi1): 2.605e-03, MSE(pi2): 4.356e-06, MSE(pi3): 6.667e-04\n",
      "Epoch 94000, Train loss: 1.398e+02, Test loss: 3.256e+03, MSE(e): 4.723e-06, MSE(pi1): 2.577e-03, MSE(pi2): 4.354e-06, MSE(pi3): 6.684e-04\n",
      "Epoch 94100, Train loss: 1.398e+02, Test loss: 3.253e+03, MSE(e): 4.721e-06, MSE(pi1): 2.566e-03, MSE(pi2): 4.348e-06, MSE(pi3): 6.688e-04\n",
      "Epoch 94200, Train loss: 1.397e+02, Test loss: 3.249e+03, MSE(e): 4.711e-06, MSE(pi1): 2.647e-03, MSE(pi2): 4.335e-06, MSE(pi3): 6.607e-04\n",
      "Epoch 94300, Train loss: 1.397e+02, Test loss: 3.246e+03, MSE(e): 4.699e-06, MSE(pi1): 2.610e-03, MSE(pi2): 4.335e-06, MSE(pi3): 6.656e-04\n",
      "Epoch 94400, Train loss: 1.397e+02, Test loss: 3.242e+03, MSE(e): 4.699e-06, MSE(pi1): 2.622e-03, MSE(pi2): 4.328e-06, MSE(pi3): 6.646e-04\n",
      "Epoch 94500, Train loss: 1.396e+02, Test loss: 3.239e+03, MSE(e): 4.690e-06, MSE(pi1): 2.604e-03, MSE(pi2): 4.326e-06, MSE(pi3): 6.665e-04\n",
      "Epoch 94600, Train loss: 1.394e+02, Test loss: 3.236e+03, MSE(e): 4.685e-06, MSE(pi1): 2.608e-03, MSE(pi2): 4.317e-06, MSE(pi3): 6.652e-04\n",
      "Epoch 94700, Train loss: 1.394e+02, Test loss: 3.232e+03, MSE(e): 4.676e-06, MSE(pi1): 2.593e-03, MSE(pi2): 4.309e-06, MSE(pi3): 6.668e-04\n",
      "Epoch 94800, Train loss: 1.396e+02, Test loss: 3.228e+03, MSE(e): 4.673e-06, MSE(pi1): 2.659e-03, MSE(pi2): 4.297e-06, MSE(pi3): 6.626e-04\n",
      "Epoch 94900, Train loss: 1.392e+02, Test loss: 3.224e+03, MSE(e): 4.666e-06, MSE(pi1): 2.623e-03, MSE(pi2): 4.297e-06, MSE(pi3): 6.634e-04\n",
      "Epoch 95000, Train loss: 1.394e+02, Test loss: 3.221e+03, MSE(e): 4.665e-06, MSE(pi1): 2.603e-03, MSE(pi2): 4.296e-06, MSE(pi3): 6.667e-04\n",
      "Epoch 95100, Train loss: 1.390e+02, Test loss: 3.217e+03, MSE(e): 4.654e-06, MSE(pi1): 2.568e-03, MSE(pi2): 4.292e-06, MSE(pi3): 6.680e-04\n",
      "Epoch 95200, Train loss: 1.391e+02, Test loss: 3.214e+03, MSE(e): 4.652e-06, MSE(pi1): 2.573e-03, MSE(pi2): 4.287e-06, MSE(pi3): 6.683e-04\n",
      "Epoch 95300, Train loss: 1.389e+02, Test loss: 3.211e+03, MSE(e): 4.643e-06, MSE(pi1): 2.614e-03, MSE(pi2): 4.277e-06, MSE(pi3): 6.627e-04\n",
      "Epoch 95400, Train loss: 1.388e+02, Test loss: 3.207e+03, MSE(e): 4.635e-06, MSE(pi1): 2.579e-03, MSE(pi2): 4.273e-06, MSE(pi3): 6.667e-04\n",
      "Epoch 95500, Train loss: 1.388e+02, Test loss: 3.204e+03, MSE(e): 4.627e-06, MSE(pi1): 2.624e-03, MSE(pi2): 4.265e-06, MSE(pi3): 6.626e-04\n",
      "Epoch 95600, Train loss: 1.387e+02, Test loss: 3.200e+03, MSE(e): 4.624e-06, MSE(pi1): 2.599e-03, MSE(pi2): 4.261e-06, MSE(pi3): 6.644e-04\n",
      "Epoch 95700, Train loss: 1.387e+02, Test loss: 3.197e+03, MSE(e): 4.616e-06, MSE(pi1): 2.564e-03, MSE(pi2): 4.256e-06, MSE(pi3): 6.694e-04\n",
      "Epoch 95800, Train loss: 1.387e+02, Test loss: 3.194e+03, MSE(e): 4.611e-06, MSE(pi1): 2.593e-03, MSE(pi2): 4.246e-06, MSE(pi3): 6.662e-04\n",
      "Epoch 95900, Train loss: 1.385e+02, Test loss: 3.190e+03, MSE(e): 4.608e-06, MSE(pi1): 2.583e-03, MSE(pi2): 4.242e-06, MSE(pi3): 6.659e-04\n",
      "Epoch 96000, Train loss: 1.384e+02, Test loss: 3.186e+03, MSE(e): 4.600e-06, MSE(pi1): 2.573e-03, MSE(pi2): 4.234e-06, MSE(pi3): 6.666e-04\n",
      "Epoch 96100, Train loss: 1.384e+02, Test loss: 3.183e+03, MSE(e): 4.597e-06, MSE(pi1): 2.615e-03, MSE(pi2): 4.232e-06, MSE(pi3): 6.630e-04\n",
      "Epoch 96200, Train loss: 1.385e+02, Test loss: 3.180e+03, MSE(e): 4.588e-06, MSE(pi1): 2.633e-03, MSE(pi2): 4.229e-06, MSE(pi3): 6.628e-04\n",
      "Epoch 96300, Train loss: 1.383e+02, Test loss: 3.177e+03, MSE(e): 4.583e-06, MSE(pi1): 2.644e-03, MSE(pi2): 4.216e-06, MSE(pi3): 6.606e-04\n",
      "Epoch 96400, Train loss: 1.380e+02, Test loss: 3.173e+03, MSE(e): 4.576e-06, MSE(pi1): 2.587e-03, MSE(pi2): 4.214e-06, MSE(pi3): 6.639e-04\n",
      "Epoch 96500, Train loss: 1.381e+02, Test loss: 3.170e+03, MSE(e): 4.570e-06, MSE(pi1): 2.593e-03, MSE(pi2): 4.209e-06, MSE(pi3): 6.645e-04\n",
      "Epoch 96600, Train loss: 1.382e+02, Test loss: 3.166e+03, MSE(e): 4.563e-06, MSE(pi1): 2.617e-03, MSE(pi2): 4.203e-06, MSE(pi3): 6.638e-04\n",
      "Epoch 96700, Train loss: 1.381e+02, Test loss: 3.163e+03, MSE(e): 4.556e-06, MSE(pi1): 2.616e-03, MSE(pi2): 4.196e-06, MSE(pi3): 6.633e-04\n",
      "Epoch 96800, Train loss: 1.378e+02, Test loss: 3.159e+03, MSE(e): 4.553e-06, MSE(pi1): 2.578e-03, MSE(pi2): 4.189e-06, MSE(pi3): 6.643e-04\n",
      "Epoch 96900, Train loss: 1.380e+02, Test loss: 3.157e+03, MSE(e): 4.545e-06, MSE(pi1): 2.590e-03, MSE(pi2): 4.183e-06, MSE(pi3): 6.663e-04\n",
      "Epoch 97000, Train loss: 1.381e+02, Test loss: 3.154e+03, MSE(e): 4.540e-06, MSE(pi1): 2.633e-03, MSE(pi2): 4.183e-06, MSE(pi3): 6.632e-04\n",
      "Epoch 97100, Train loss: 1.377e+02, Test loss: 3.149e+03, MSE(e): 4.540e-06, MSE(pi1): 2.564e-03, MSE(pi2): 4.183e-06, MSE(pi3): 6.664e-04\n",
      "Epoch 97200, Train loss: 1.377e+02, Test loss: 3.147e+03, MSE(e): 4.531e-06, MSE(pi1): 2.577e-03, MSE(pi2): 4.175e-06, MSE(pi3): 6.662e-04\n",
      "Epoch 97300, Train loss: 1.376e+02, Test loss: 3.144e+03, MSE(e): 4.522e-06, MSE(pi1): 2.560e-03, MSE(pi2): 4.166e-06, MSE(pi3): 6.677e-04\n",
      "Epoch 97400, Train loss: 1.374e+02, Test loss: 3.140e+03, MSE(e): 4.519e-06, MSE(pi1): 2.585e-03, MSE(pi2): 4.159e-06, MSE(pi3): 6.635e-04\n",
      "Epoch 97500, Train loss: 1.375e+02, Test loss: 3.136e+03, MSE(e): 4.513e-06, MSE(pi1): 2.589e-03, MSE(pi2): 4.154e-06, MSE(pi3): 6.643e-04\n",
      "Epoch 97600, Train loss: 1.373e+02, Test loss: 3.133e+03, MSE(e): 4.510e-06, MSE(pi1): 2.548e-03, MSE(pi2): 4.150e-06, MSE(pi3): 6.676e-04\n",
      "Epoch 97700, Train loss: 1.374e+02, Test loss: 3.130e+03, MSE(e): 4.504e-06, MSE(pi1): 2.546e-03, MSE(pi2): 4.149e-06, MSE(pi3): 6.689e-04\n",
      "Epoch 97800, Train loss: 1.372e+02, Test loss: 3.127e+03, MSE(e): 4.497e-06, MSE(pi1): 2.590e-03, MSE(pi2): 4.137e-06, MSE(pi3): 6.630e-04\n",
      "Epoch 97900, Train loss: 1.372e+02, Test loss: 3.123e+03, MSE(e): 4.496e-06, MSE(pi1): 2.579e-03, MSE(pi2): 4.135e-06, MSE(pi3): 6.642e-04\n",
      "Epoch 98000, Train loss: 1.371e+02, Test loss: 3.120e+03, MSE(e): 4.485e-06, MSE(pi1): 2.560e-03, MSE(pi2): 4.130e-06, MSE(pi3): 6.666e-04\n",
      "Epoch 98100, Train loss: 1.372e+02, Test loss: 3.117e+03, MSE(e): 4.482e-06, MSE(pi1): 2.566e-03, MSE(pi2): 4.125e-06, MSE(pi3): 6.668e-04\n",
      "Epoch 98200, Train loss: 1.372e+02, Test loss: 3.114e+03, MSE(e): 4.481e-06, MSE(pi1): 2.564e-03, MSE(pi2): 4.119e-06, MSE(pi3): 6.677e-04\n",
      "Epoch 98300, Train loss: 1.369e+02, Test loss: 3.111e+03, MSE(e): 4.469e-06, MSE(pi1): 2.573e-03, MSE(pi2): 4.113e-06, MSE(pi3): 6.645e-04\n",
      "Epoch 98400, Train loss: 1.367e+02, Test loss: 3.107e+03, MSE(e): 4.464e-06, MSE(pi1): 2.571e-03, MSE(pi2): 4.105e-06, MSE(pi3): 6.638e-04\n",
      "Epoch 98500, Train loss: 1.367e+02, Test loss: 3.104e+03, MSE(e): 4.456e-06, MSE(pi1): 2.572e-03, MSE(pi2): 4.100e-06, MSE(pi3): 6.638e-04\n",
      "Epoch 98600, Train loss: 1.368e+02, Test loss: 3.102e+03, MSE(e): 4.458e-06, MSE(pi1): 2.617e-03, MSE(pi2): 4.096e-06, MSE(pi3): 6.607e-04\n",
      "Epoch 98700, Train loss: 1.366e+02, Test loss: 3.098e+03, MSE(e): 4.450e-06, MSE(pi1): 2.578e-03, MSE(pi2): 4.092e-06, MSE(pi3): 6.629e-04\n",
      "Epoch 98800, Train loss: 1.367e+02, Test loss: 3.095e+03, MSE(e): 4.446e-06, MSE(pi1): 2.640e-03, MSE(pi2): 4.086e-06, MSE(pi3): 6.589e-04\n",
      "Epoch 98900, Train loss: 1.366e+02, Test loss: 3.092e+03, MSE(e): 4.441e-06, MSE(pi1): 2.598e-03, MSE(pi2): 4.081e-06, MSE(pi3): 6.619e-04\n",
      "Epoch 99000, Train loss: 1.363e+02, Test loss: 3.089e+03, MSE(e): 4.427e-06, MSE(pi1): 2.592e-03, MSE(pi2): 4.077e-06, MSE(pi3): 6.614e-04\n",
      "Epoch 99100, Train loss: 1.362e+02, Test loss: 3.086e+03, MSE(e): 4.419e-06, MSE(pi1): 2.590e-03, MSE(pi2): 4.067e-06, MSE(pi3): 6.611e-04\n",
      "Epoch 99200, Train loss: 1.362e+02, Test loss: 3.082e+03, MSE(e): 4.414e-06, MSE(pi1): 2.571e-03, MSE(pi2): 4.064e-06, MSE(pi3): 6.636e-04\n",
      "Epoch 99300, Train loss: 1.364e+02, Test loss: 3.079e+03, MSE(e): 4.409e-06, MSE(pi1): 2.555e-03, MSE(pi2): 4.065e-06, MSE(pi3): 6.676e-04\n",
      "Epoch 99400, Train loss: 1.363e+02, Test loss: 3.076e+03, MSE(e): 4.414e-06, MSE(pi1): 2.635e-03, MSE(pi2): 4.048e-06, MSE(pi3): 6.581e-04\n",
      "Epoch 99500, Train loss: 1.362e+02, Test loss: 3.073e+03, MSE(e): 4.402e-06, MSE(pi1): 2.583e-03, MSE(pi2): 4.050e-06, MSE(pi3): 6.633e-04\n",
      "Epoch 99600, Train loss: 1.361e+02, Test loss: 3.070e+03, MSE(e): 4.402e-06, MSE(pi1): 2.562e-03, MSE(pi2): 4.044e-06, MSE(pi3): 6.650e-04\n",
      "Epoch 99700, Train loss: 1.360e+02, Test loss: 3.067e+03, MSE(e): 4.388e-06, MSE(pi1): 2.601e-03, MSE(pi2): 4.042e-06, MSE(pi3): 6.613e-04\n",
      "Epoch 99800, Train loss: 1.361e+02, Test loss: 3.064e+03, MSE(e): 4.386e-06, MSE(pi1): 2.611e-03, MSE(pi2): 4.032e-06, MSE(pi3): 6.612e-04\n",
      "Epoch 99900, Train loss: 1.359e+02, Test loss: 3.061e+03, MSE(e): 4.379e-06, MSE(pi1): 2.593e-03, MSE(pi2): 4.034e-06, MSE(pi3): 6.622e-04\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 9000\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 100\n",
    "\n",
    "second_lr = 1e-4\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
