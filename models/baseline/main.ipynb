{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from model.baseline_model import BaselineNonlinearModel\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from vecopsciml.operators.zero_order import Mx, My"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear/baseline_model\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/non_linear/non_linear_10000.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/non_linear')\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/non_linear/baseline_model')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear/non_linear_10000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data splitting in train/test\n",
    "X = torch.tensor(dataset['X_train'], dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(dataset['y_train'], dtype=torch.float32).unsqueeze(1)\n",
    "K = torch.tensor(dataset['k_train'], dtype=torch.float32).unsqueeze(1)\n",
    "f = torch.tensor(dataset['f_train'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X, y, K, f, test_size=0.3, random_state=42)\n",
    "\n",
    "# Data processing and adequacy with our TensOps library\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "# Loading and processing validation data\n",
    "X_val = torch.tensor(dataset['X_val'], dtype=torch.float32).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, 5, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 3.696e+07, Test loss: 8.012e+07, MSE(e): 3.631e+00, MSE(pi1): 2.688e+01, MSE(pi2): 1.071e+00, MSE(pi3): 3.784e+00\n",
      "Epoch 100, Train loss: 1.236e+06, Test loss: 2.231e+06, MSE(e): 1.214e-01, MSE(pi1): 1.147e+00, MSE(pi2): 8.977e-02, MSE(pi3): 1.019e-01\n",
      "Epoch 200, Train loss: 2.270e+04, Test loss: 6.233e+04, MSE(e): 1.978e-03, MSE(pi1): 1.688e-01, MSE(pi2): 1.190e-03, MSE(pi3): 1.227e-02\n",
      "Epoch 300, Train loss: 1.132e+04, Test loss: 3.734e+04, MSE(e): 1.038e-03, MSE(pi1): 6.144e-02, MSE(pi2): 6.316e-04, MSE(pi3): 3.317e-03\n",
      "Epoch 400, Train loss: 6.540e+03, Test loss: 2.286e+04, MSE(e): 6.165e-04, MSE(pi1): 2.737e-02, MSE(pi2): 3.942e-04, MSE(pi3): 1.009e-03\n",
      "Epoch 500, Train loss: 9.198e+03, Test loss: 2.504e+04, MSE(e): 8.345e-04, MSE(pi1): 6.026e-02, MSE(pi2): 4.966e-04, MSE(pi3): 2.499e-03\n",
      "Epoch 600, Train loss: 8.557e+03, Test loss: 4.721e+04, MSE(e): 6.898e-04, MSE(pi1): 6.981e-02, MSE(pi2): 4.637e-04, MSE(pi3): 9.609e-03\n",
      "Epoch 700, Train loss: 6.617e+03, Test loss: 3.664e+04, MSE(e): 5.877e-04, MSE(pi1): 5.575e-02, MSE(pi2): 3.540e-04, MSE(pi3): 1.818e-03\n",
      "Epoch 800, Train loss: 6.656e+03, Test loss: 2.383e+04, MSE(e): 6.118e-04, MSE(pi1): 4.321e-02, MSE(pi2): 3.589e-04, MSE(pi3): 1.058e-03\n",
      "Epoch 900, Train loss: 8.264e+03, Test loss: 2.693e+04, MSE(e): 7.801e-04, MSE(pi1): 3.786e-02, MSE(pi2): 5.257e-04, MSE(pi3): 8.374e-04\n",
      "Epoch 1000, Train loss: 5.720e+03, Test loss: 2.075e+04, MSE(e): 5.271e-04, MSE(pi1): 3.410e-02, MSE(pi2): 3.365e-04, MSE(pi3): 1.071e-03\n",
      "Epoch 1100, Train loss: 4.827e+03, Test loss: 2.000e+04, MSE(e): 4.027e-04, MSE(pi1): 5.660e-02, MSE(pi2): 2.386e-04, MSE(pi3): 2.339e-03\n",
      "Epoch 1200, Train loss: 3.872e+03, Test loss: 2.240e+04, MSE(e): 3.185e-04, MSE(pi1): 6.207e-02, MSE(pi2): 1.932e-04, MSE(pi3): 6.590e-04\n",
      "Epoch 1300, Train loss: 3.268e+03, Test loss: 1.446e+04, MSE(e): 2.879e-04, MSE(pi1): 3.277e-02, MSE(pi2): 1.835e-04, MSE(pi3): 6.159e-04\n",
      "Epoch 1400, Train loss: 1.991e+03, Test loss: 6.199e+03, MSE(e): 1.689e-04, MSE(pi1): 2.550e-02, MSE(pi2): 1.017e-04, MSE(pi3): 4.756e-04\n",
      "Epoch 1500, Train loss: 1.388e+03, Test loss: 4.551e+03, MSE(e): 1.249e-04, MSE(pi1): 9.246e-03, MSE(pi2): 7.599e-05, MSE(pi3): 4.698e-04\n",
      "Epoch 1600, Train loss: 2.158e+03, Test loss: 8.374e+03, MSE(e): 1.554e-04, MSE(pi1): 5.095e-02, MSE(pi2): 7.352e-05, MSE(pi3): 9.481e-04\n",
      "Epoch 1700, Train loss: 3.693e+03, Test loss: 1.542e+04, MSE(e): 3.159e-04, MSE(pi1): 3.846e-02, MSE(pi2): 1.645e-04, MSE(pi3): 1.500e-03\n",
      "Epoch 1800, Train loss: 2.015e+03, Test loss: 5.844e+03, MSE(e): 1.691e-04, MSE(pi1): 2.733e-02, MSE(pi2): 1.106e-04, MSE(pi3): 5.074e-04\n",
      "Epoch 1900, Train loss: 1.969e+03, Test loss: 6.936e+03, MSE(e): 1.657e-04, MSE(pi1): 2.687e-02, MSE(pi2): 9.831e-05, MSE(pi3): 4.383e-04\n",
      "Epoch 2000, Train loss: 1.385e+04, Test loss: 3.895e+04, MSE(e): 1.330e-03, MSE(pi1): 3.674e-02, MSE(pi2): 6.646e-04, MSE(pi3): 1.845e-03\n",
      "Epoch 2100, Train loss: 2.241e+03, Test loss: 7.407e+03, MSE(e): 1.800e-04, MSE(pi1): 3.742e-02, MSE(pi2): 9.805e-05, MSE(pi3): 6.672e-04\n",
      "Epoch 2200, Train loss: 2.235e+03, Test loss: 7.591e+03, MSE(e): 2.010e-04, MSE(pi1): 1.791e-02, MSE(pi2): 1.196e-04, MSE(pi3): 4.538e-04\n",
      "Epoch 2300, Train loss: 2.236e+03, Test loss: 1.128e+04, MSE(e): 1.978e-04, MSE(pi1): 1.968e-02, MSE(pi2): 1.052e-04, MSE(pi3): 6.129e-04\n",
      "Epoch 2400, Train loss: 1.093e+03, Test loss: 6.026e+03, MSE(e): 8.875e-05, MSE(pi1): 1.625e-02, MSE(pi2): 5.546e-05, MSE(pi3): 4.255e-04\n",
      "Epoch 2500, Train loss: 3.408e+03, Test loss: 1.291e+04, MSE(e): 2.985e-04, MSE(pi1): 3.686e-02, MSE(pi2): 1.572e-04, MSE(pi3): 5.385e-04\n",
      "Epoch 2600, Train loss: 2.653e+03, Test loss: 9.487e+03, MSE(e): 2.249e-04, MSE(pi1): 3.610e-02, MSE(pi2): 1.469e-04, MSE(pi3): 4.268e-04\n",
      "Epoch 2700, Train loss: 7.737e+03, Test loss: 3.157e+04, MSE(e): 6.626e-04, MSE(pi1): 9.017e-02, MSE(pi2): 3.033e-04, MSE(pi3): 2.090e-03\n",
      "Epoch 2800, Train loss: 3.468e+03, Test loss: 1.960e+04, MSE(e): 3.156e-04, MSE(pi1): 2.188e-02, MSE(pi2): 1.770e-04, MSE(pi3): 9.346e-04\n",
      "Epoch 2900, Train loss: 6.107e+03, Test loss: 2.896e+04, MSE(e): 5.627e-04, MSE(pi1): 4.154e-02, MSE(pi2): 2.984e-04, MSE(pi3): 6.456e-04\n",
      "Epoch 3000, Train loss: 1.425e+03, Test loss: 5.381e+03, MSE(e): 9.958e-05, MSE(pi1): 3.765e-02, MSE(pi2): 5.258e-05, MSE(pi3): 5.218e-04\n",
      "Epoch 3100, Train loss: 2.834e+03, Test loss: 6.718e+03, MSE(e): 2.612e-04, MSE(pi1): 1.831e-02, MSE(pi2): 1.511e-04, MSE(pi3): 3.891e-04\n",
      "Epoch 3200, Train loss: 1.165e+03, Test loss: 5.299e+03, MSE(e): 9.656e-05, MSE(pi1): 1.465e-02, MSE(pi2): 5.466e-05, MSE(pi3): 5.232e-04\n",
      "Epoch 3300, Train loss: 2.902e+03, Test loss: 1.464e+04, MSE(e): 2.329e-04, MSE(pi1): 5.262e-02, MSE(pi2): 1.265e-04, MSE(pi3): 4.692e-04\n",
      "Epoch 3400, Train loss: 4.156e+03, Test loss: 1.716e+04, MSE(e): 3.609e-04, MSE(pi1): 4.693e-02, MSE(pi2): 2.088e-04, MSE(pi3): 7.759e-04\n",
      "Epoch 3500, Train loss: 3.199e+03, Test loss: 9.000e+03, MSE(e): 2.062e-04, MSE(pi1): 1.010e-01, MSE(pi2): 1.266e-04, MSE(pi3): 1.263e-03\n",
      "Epoch 3600, Train loss: 2.740e+03, Test loss: 8.104e+03, MSE(e): 2.518e-04, MSE(pi1): 1.576e-02, MSE(pi2): 1.492e-04, MSE(pi3): 6.438e-04\n",
      "Epoch 3700, Train loss: 2.635e+03, Test loss: 1.549e+04, MSE(e): 2.350e-04, MSE(pi1): 2.413e-02, MSE(pi2): 1.337e-04, MSE(pi3): 4.335e-04\n",
      "Epoch 3800, Train loss: 3.561e+03, Test loss: 1.692e+04, MSE(e): 2.969e-04, MSE(pi1): 5.153e-02, MSE(pi2): 1.446e-04, MSE(pi3): 7.688e-04\n",
      "Epoch 3900, Train loss: 1.845e+03, Test loss: 8.529e+03, MSE(e): 1.544e-04, MSE(pi1): 2.481e-02, MSE(pi2): 8.755e-05, MSE(pi3): 5.365e-04\n",
      "Epoch 4000, Train loss: 2.581e+03, Test loss: 6.810e+03, MSE(e): 2.427e-04, MSE(pi1): 1.079e-02, MSE(pi2): 1.524e-04, MSE(pi3): 4.597e-04\n",
      "Epoch 4100, Train loss: 4.271e+03, Test loss: 1.702e+04, MSE(e): 3.650e-04, MSE(pi1): 5.609e-02, MSE(pi2): 1.981e-04, MSE(pi3): 5.987e-04\n",
      "Epoch 4200, Train loss: 1.607e+03, Test loss: 5.231e+03, MSE(e): 1.241e-04, MSE(pi1): 3.251e-02, MSE(pi2): 6.053e-05, MSE(pi3): 4.061e-04\n",
      "Epoch 4300, Train loss: 1.876e+03, Test loss: 9.260e+03, MSE(e): 1.558e-04, MSE(pi1): 2.500e-02, MSE(pi2): 9.909e-05, MSE(pi3): 6.751e-04\n",
      "Epoch 4400, Train loss: 2.501e+03, Test loss: 1.850e+04, MSE(e): 2.322e-04, MSE(pi1): 1.210e-02, MSE(pi2): 1.148e-04, MSE(pi3): 5.778e-04\n",
      "Epoch 4500, Train loss: 2.396e+03, Test loss: 8.176e+03, MSE(e): 2.048e-04, MSE(pi1): 3.066e-02, MSE(pi2): 1.253e-04, MSE(pi3): 4.172e-04\n",
      "Epoch 4600, Train loss: 2.476e+03, Test loss: 9.231e+03, MSE(e): 2.075e-04, MSE(pi1): 3.577e-02, MSE(pi2): 1.212e-04, MSE(pi3): 4.224e-04\n",
      "Epoch 4700, Train loss: 2.261e+03, Test loss: 1.081e+04, MSE(e): 1.999e-04, MSE(pi1): 2.104e-02, MSE(pi2): 9.162e-05, MSE(pi3): 5.095e-04\n",
      "Epoch 4800, Train loss: 3.296e+03, Test loss: 7.966e+03, MSE(e): 2.894e-04, MSE(pi1): 2.116e-02, MSE(pi2): 1.465e-04, MSE(pi3): 1.902e-03\n",
      "Epoch 4900, Train loss: 2.226e+03, Test loss: 5.758e+03, MSE(e): 1.862e-04, MSE(pi1): 3.329e-02, MSE(pi2): 1.187e-04, MSE(pi3): 3.040e-04\n",
      "Epoch 5000, Train loss: 1.410e+03, Test loss: 9.030e+03, MSE(e): 1.192e-04, MSE(pi1): 1.548e-02, MSE(pi2): 6.327e-05, MSE(pi3): 6.333e-04\n",
      "Epoch 5100, Train loss: 1.985e+03, Test loss: 7.424e+03, MSE(e): 1.148e-04, MSE(pi1): 7.564e-02, MSE(pi2): 6.740e-05, MSE(pi3): 8.127e-04\n",
      "Epoch 5200, Train loss: 1.013e+04, Test loss: 3.883e+04, MSE(e): 9.833e-04, MSE(pi1): 2.450e-02, MSE(pi2): 5.614e-04, MSE(pi3): 5.516e-04\n",
      "Epoch 5300, Train loss: 2.312e+03, Test loss: 8.466e+03, MSE(e): 2.010e-04, MSE(pi1): 2.588e-02, MSE(pi2): 1.059e-04, MSE(pi3): 4.310e-04\n",
      "Epoch 5400, Train loss: 5.414e+03, Test loss: 1.291e+04, MSE(e): 5.173e-04, MSE(pi1): 1.906e-02, MSE(pi2): 2.601e-04, MSE(pi3): 5.070e-04\n",
      "Epoch 5500, Train loss: 3.415e+03, Test loss: 1.478e+04, MSE(e): 3.145e-04, MSE(pi1): 2.356e-02, MSE(pi2): 2.076e-04, MSE(pi3): 3.409e-04\n",
      "Epoch 5600, Train loss: 2.947e+03, Test loss: 7.615e+03, MSE(e): 2.528e-04, MSE(pi1): 3.228e-02, MSE(pi2): 1.442e-04, MSE(pi3): 9.631e-04\n",
      "Epoch 5700, Train loss: 2.647e+03, Test loss: 9.115e+03, MSE(e): 2.497e-04, MSE(pi1): 1.024e-02, MSE(pi2): 1.219e-04, MSE(pi3): 4.774e-04\n",
      "Epoch 5800, Train loss: 3.379e+03, Test loss: 6.715e+03, MSE(e): 3.181e-04, MSE(pi1): 1.523e-02, MSE(pi2): 1.532e-04, MSE(pi3): 4.539e-04\n",
      "Epoch 5900, Train loss: 4.325e+03, Test loss: 1.487e+04, MSE(e): 3.955e-04, MSE(pi1): 2.723e-02, MSE(pi2): 2.079e-04, MSE(pi3): 9.720e-04\n",
      "Epoch 6000, Train loss: 5.248e+03, Test loss: 1.410e+04, MSE(e): 5.060e-04, MSE(pi1): 1.274e-02, MSE(pi2): 2.637e-04, MSE(pi3): 5.965e-04\n",
      "Epoch 6100, Train loss: 3.161e+03, Test loss: 7.306e+03, MSE(e): 2.860e-04, MSE(pi1): 2.053e-02, MSE(pi2): 1.449e-04, MSE(pi3): 9.499e-04\n",
      "Epoch 6200, Train loss: 2.538e+04, Test loss: 6.757e+04, MSE(e): 2.495e-03, MSE(pi1): 3.728e-02, MSE(pi2): 1.244e-03, MSE(pi3): 4.779e-04\n",
      "Epoch 6300, Train loss: 3.468e+03, Test loss: 7.140e+03, MSE(e): 3.059e-04, MSE(pi1): 3.562e-02, MSE(pi2): 1.659e-04, MSE(pi3): 5.244e-04\n",
      "Epoch 6400, Train loss: 5.869e+03, Test loss: 1.732e+04, MSE(e): 5.530e-04, MSE(pi1): 2.993e-02, MSE(pi2): 3.127e-04, MSE(pi3): 4.022e-04\n",
      "Epoch 6500, Train loss: 1.240e+03, Test loss: 4.143e+03, MSE(e): 9.808e-05, MSE(pi1): 2.004e-02, MSE(pi2): 5.230e-05, MSE(pi3): 5.834e-04\n",
      "Epoch 6600, Train loss: 3.303e+03, Test loss: 1.151e+04, MSE(e): 3.107e-04, MSE(pi1): 1.267e-02, MSE(pi2): 1.520e-04, MSE(pi3): 6.929e-04\n",
      "Epoch 6700, Train loss: 6.191e+03, Test loss: 2.379e+04, MSE(e): 5.823e-04, MSE(pi1): 2.601e-02, MSE(pi2): 3.047e-04, MSE(pi3): 1.072e-03\n",
      "Epoch 6800, Train loss: 3.204e+03, Test loss: 1.458e+04, MSE(e): 2.783e-04, MSE(pi1): 3.124e-02, MSE(pi2): 1.654e-04, MSE(pi3): 1.077e-03\n",
      "Epoch 6900, Train loss: 4.312e+03, Test loss: 1.286e+04, MSE(e): 3.884e-04, MSE(pi1): 2.978e-02, MSE(pi2): 1.852e-04, MSE(pi3): 1.301e-03\n",
      "Epoch 7000, Train loss: 1.083e+03, Test loss: 4.218e+03, MSE(e): 9.735e-05, MSE(pi1): 5.008e-03, MSE(pi2): 5.960e-05, MSE(pi3): 5.920e-04\n",
      "Epoch 7100, Train loss: 2.088e+03, Test loss: 1.081e+04, MSE(e): 1.834e-04, MSE(pi1): 1.695e-02, MSE(pi2): 1.125e-04, MSE(pi3): 8.450e-04\n",
      "Epoch 7200, Train loss: 3.990e+03, Test loss: 2.132e+04, MSE(e): 3.788e-04, MSE(pi1): 1.231e-02, MSE(pi2): 1.801e-04, MSE(pi3): 7.878e-04\n",
      "Epoch 7300, Train loss: 5.700e+03, Test loss: 1.693e+04, MSE(e): 5.254e-04, MSE(pi1): 3.923e-02, MSE(pi2): 3.207e-04, MSE(pi3): 5.374e-04\n",
      "Epoch 7400, Train loss: 2.964e+03, Test loss: 1.247e+04, MSE(e): 2.696e-04, MSE(pi1): 2.076e-02, MSE(pi2): 1.256e-04, MSE(pi3): 5.958e-04\n",
      "Epoch 7500, Train loss: 4.229e+04, Test loss: 1.095e+05, MSE(e): 4.115e-03, MSE(pi1): 7.143e-02, MSE(pi2): 3.297e-03, MSE(pi3): 4.254e-03\n",
      "Epoch 7600, Train loss: 1.331e+04, Test loss: 2.953e+04, MSE(e): 1.298e-03, MSE(pi1): 2.102e-02, MSE(pi2): 1.090e-03, MSE(pi3): 1.144e-03\n",
      "Epoch 7700, Train loss: 1.603e+04, Test loss: 5.629e+04, MSE(e): 1.580e-03, MSE(pi1): 1.865e-02, MSE(pi2): 8.908e-04, MSE(pi3): 4.066e-04\n",
      "Epoch 7800, Train loss: 8.072e+03, Test loss: 2.103e+04, MSE(e): 7.890e-04, MSE(pi1): 1.449e-02, MSE(pi2): 5.581e-04, MSE(pi3): 3.633e-04\n",
      "Epoch 7900, Train loss: 8.535e+03, Test loss: 2.572e+04, MSE(e): 8.137e-04, MSE(pi1): 3.252e-02, MSE(pi2): 5.692e-04, MSE(pi3): 7.212e-04\n",
      "Epoch 8000, Train loss: 7.118e+03, Test loss: 1.965e+04, MSE(e): 6.912e-04, MSE(pi1): 1.544e-02, MSE(pi2): 4.681e-04, MSE(pi3): 5.066e-04\n",
      "Epoch 8100, Train loss: 6.371e+03, Test loss: 1.240e+04, MSE(e): 6.116e-04, MSE(pi1): 1.778e-02, MSE(pi2): 3.349e-04, MSE(pi3): 7.653e-04\n",
      "Epoch 8200, Train loss: 2.149e+03, Test loss: 1.553e+04, MSE(e): 1.824e-04, MSE(pi1): 2.377e-02, MSE(pi2): 1.560e-04, MSE(pi3): 8.692e-04\n",
      "Epoch 8300, Train loss: 5.485e+03, Test loss: 3.439e+04, MSE(e): 5.317e-04, MSE(pi1): 1.278e-02, MSE(pi2): 2.746e-04, MSE(pi3): 3.950e-04\n",
      "Epoch 8400, Train loss: 1.687e+03, Test loss: 7.398e+03, MSE(e): 1.482e-04, MSE(pi1): 1.626e-02, MSE(pi2): 9.286e-05, MSE(pi3): 4.241e-04\n",
      "Epoch 8500, Train loss: 2.330e+03, Test loss: 1.307e+04, MSE(e): 2.210e-04, MSE(pi1): 7.164e-03, MSE(pi2): 1.290e-04, MSE(pi3): 4.861e-04\n",
      "Epoch 8600, Train loss: 2.882e+03, Test loss: 2.447e+08, MSE(e): 2.744e-04, MSE(pi1): 8.364e-03, MSE(pi2): 1.576e-04, MSE(pi3): 5.444e-04\n",
      "Epoch 8700, Train loss: 2.124e+03, Test loss: 3.394e+06, MSE(e): 1.979e-04, MSE(pi1): 9.777e-03, MSE(pi2): 1.187e-04, MSE(pi3): 4.699e-04\n",
      "Epoch 8800, Train loss: 2.817e+03, Test loss: 3.252e+09, MSE(e): 2.527e-04, MSE(pi1): 2.250e-02, MSE(pi2): 1.588e-04, MSE(pi3): 6.466e-04\n",
      "Epoch 8900, Train loss: 6.388e+03, Test loss: 5.795e+07, MSE(e): 6.090e-04, MSE(pi1): 2.005e-02, MSE(pi2): 2.575e-04, MSE(pi3): 9.657e-04\n",
      "Epoch 9000, Train loss: 2.556e+03, Test loss: 1.635e+04, MSE(e): 2.442e-04, MSE(pi1): 6.308e-03, MSE(pi2): 1.284e-04, MSE(pi3): 5.067e-04\n",
      "Epoch 9100, Train loss: 3.613e+03, Test loss: 1.760e+04, MSE(e): 3.480e-04, MSE(pi1): 8.067e-03, MSE(pi2): 1.809e-04, MSE(pi3): 5.276e-04\n",
      "Epoch 9200, Train loss: 4.287e+03, Test loss: 1.207e+04, MSE(e): 3.994e-04, MSE(pi1): 2.341e-02, MSE(pi2): 1.771e-04, MSE(pi3): 5.795e-04\n",
      "Epoch 9300, Train loss: 4.631e+03, Test loss: 1.780e+04, MSE(e): 4.401e-04, MSE(pi1): 1.789e-02, MSE(pi2): 2.013e-04, MSE(pi3): 5.118e-04\n",
      "Epoch 9400, Train loss: 8.355e+03, Test loss: 2.064e+04, MSE(e): 8.058e-04, MSE(pi1): 2.118e-02, MSE(pi2): 3.609e-04, MSE(pi3): 8.513e-04\n",
      "Epoch 9500, Train loss: 1.766e+03, Test loss: 9.794e+03, MSE(e): 1.543e-04, MSE(pi1): 1.613e-02, MSE(pi2): 8.368e-05, MSE(pi3): 6.129e-04\n",
      "Epoch 9600, Train loss: 4.935e+03, Test loss: 1.618e+04, MSE(e): 4.766e-04, MSE(pi1): 1.105e-02, MSE(pi2): 2.374e-04, MSE(pi3): 5.807e-04\n",
      "Epoch 9700, Train loss: 1.918e+03, Test loss: 1.477e+04, MSE(e): 1.792e-04, MSE(pi1): 7.485e-03, MSE(pi2): 1.073e-04, MSE(pi3): 5.076e-04\n",
      "Epoch 9800, Train loss: 7.339e+03, Test loss: 1.503e+04, MSE(e): 7.119e-04, MSE(pi1): 1.664e-02, MSE(pi2): 3.781e-04, MSE(pi3): 5.340e-04\n",
      "Epoch 9900, Train loss: 1.579e+03, Test loss: 7.973e+03, MSE(e): 1.126e-04, MSE(pi1): 2.581e-02, MSE(pi2): 6.896e-05, MSE(pi3): 1.945e-03\n",
      "\n",
      "Training process finished after 10000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = BaselineNonlinearModel(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 10000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 9000.\n",
      "Epoch 9000, Train loss: 7.228e+02, Test loss: 3.864e+03, MSE(e): 6.469e-05, MSE(pi1): 2.773e-03, MSE(pi2): 4.879e-05, MSE(pi3): 4.822e-04\n",
      "Epoch 9100, Train loss: 5.686e+02, Test loss: 4.114e+03, MSE(e): 4.940e-05, MSE(pi1): 2.670e-03, MSE(pi2): 3.909e-05, MSE(pi3): 4.789e-04\n",
      "Epoch 9200, Train loss: 5.257e+02, Test loss: 8.171e+04, MSE(e): 4.514e-05, MSE(pi1): 2.610e-03, MSE(pi2): 3.617e-05, MSE(pi3): 4.817e-04\n",
      "Epoch 9300, Train loss: 4.992e+02, Test loss: 4.975e+09, MSE(e): 4.252e-05, MSE(pi1): 2.582e-03, MSE(pi2): 3.458e-05, MSE(pi3): 4.821e-04\n",
      "Epoch 9400, Train loss: 4.783e+02, Test loss: 4.017e+09, MSE(e): 4.045e-05, MSE(pi1): 2.568e-03, MSE(pi2): 3.334e-05, MSE(pi3): 4.812e-04\n",
      "Epoch 9500, Train loss: 4.607e+02, Test loss: 3.804e+09, MSE(e): 3.870e-05, MSE(pi1): 2.561e-03, MSE(pi2): 3.225e-05, MSE(pi3): 4.800e-04\n",
      "Epoch 9600, Train loss: 4.451e+02, Test loss: 3.658e+09, MSE(e): 3.716e-05, MSE(pi1): 2.557e-03, MSE(pi2): 3.127e-05, MSE(pi3): 4.787e-04\n",
      "Epoch 9700, Train loss: 4.310e+02, Test loss: 3.533e+09, MSE(e): 3.577e-05, MSE(pi1): 2.554e-03, MSE(pi2): 3.036e-05, MSE(pi3): 4.776e-04\n",
      "Epoch 9800, Train loss: 4.179e+02, Test loss: 3.418e+09, MSE(e): 3.448e-05, MSE(pi1): 2.552e-03, MSE(pi2): 2.950e-05, MSE(pi3): 4.763e-04\n",
      "Epoch 9900, Train loss: 4.056e+02, Test loss: 3.322e+09, MSE(e): 3.325e-05, MSE(pi1): 2.552e-03, MSE(pi2): 2.867e-05, MSE(pi3): 4.748e-04\n",
      "Epoch 10000, Train loss: 3.934e+02, Test loss: 3.477e+09, MSE(e): 3.206e-05, MSE(pi1): 2.553e-03, MSE(pi2): 2.786e-05, MSE(pi3): 4.733e-04\n",
      "Epoch 10100, Train loss: 3.819e+02, Test loss: 3.693e+09, MSE(e): 3.091e-05, MSE(pi1): 2.552e-03, MSE(pi2): 2.707e-05, MSE(pi3): 4.721e-04\n",
      "Epoch 10200, Train loss: 3.713e+02, Test loss: 3.521e+09, MSE(e): 2.987e-05, MSE(pi1): 2.550e-03, MSE(pi2): 2.635e-05, MSE(pi3): 4.711e-04\n",
      "Epoch 10300, Train loss: 3.620e+02, Test loss: 3.365e+09, MSE(e): 2.894e-05, MSE(pi1): 2.551e-03, MSE(pi2): 2.571e-05, MSE(pi3): 4.698e-04\n",
      "Epoch 10400, Train loss: 3.535e+02, Test loss: 3.443e+09, MSE(e): 2.810e-05, MSE(pi1): 2.547e-03, MSE(pi2): 2.512e-05, MSE(pi3): 4.695e-04\n",
      "Epoch 10500, Train loss: 3.453e+02, Test loss: 3.468e+09, MSE(e): 2.729e-05, MSE(pi1): 2.547e-03, MSE(pi2): 2.454e-05, MSE(pi3): 4.689e-04\n",
      "Epoch 10600, Train loss: 3.375e+02, Test loss: 3.504e+09, MSE(e): 2.652e-05, MSE(pi1): 2.544e-03, MSE(pi2): 2.399e-05, MSE(pi3): 4.681e-04\n",
      "Epoch 10700, Train loss: 3.302e+02, Test loss: 3.530e+09, MSE(e): 2.580e-05, MSE(pi1): 2.540e-03, MSE(pi2): 2.347e-05, MSE(pi3): 4.674e-04\n",
      "Epoch 10800, Train loss: 3.235e+02, Test loss: 3.537e+09, MSE(e): 2.515e-05, MSE(pi1): 2.535e-03, MSE(pi2): 2.298e-05, MSE(pi3): 4.668e-04\n",
      "Epoch 10900, Train loss: 3.176e+02, Test loss: 3.521e+09, MSE(e): 2.456e-05, MSE(pi1): 2.532e-03, MSE(pi2): 2.252e-05, MSE(pi3): 4.660e-04\n",
      "Epoch 11000, Train loss: 3.122e+02, Test loss: 3.493e+09, MSE(e): 2.403e-05, MSE(pi1): 2.529e-03, MSE(pi2): 2.210e-05, MSE(pi3): 4.653e-04\n",
      "Epoch 11100, Train loss: 3.070e+02, Test loss: 3.490e+09, MSE(e): 2.352e-05, MSE(pi1): 2.527e-03, MSE(pi2): 2.171e-05, MSE(pi3): 4.647e-04\n",
      "Epoch 11200, Train loss: 3.020e+02, Test loss: 3.556e+09, MSE(e): 2.303e-05, MSE(pi1): 2.525e-03, MSE(pi2): 2.134e-05, MSE(pi3): 4.640e-04\n",
      "Epoch 11300, Train loss: 2.971e+02, Test loss: 3.780e+09, MSE(e): 2.256e-05, MSE(pi1): 2.523e-03, MSE(pi2): 2.098e-05, MSE(pi3): 4.634e-04\n",
      "Epoch 11400, Train loss: 2.924e+02, Test loss: 4.463e+09, MSE(e): 2.208e-05, MSE(pi1): 2.522e-03, MSE(pi2): 2.065e-05, MSE(pi3): 4.627e-04\n",
      "Epoch 11500, Train loss: 2.874e+02, Test loss: 5.321e+09, MSE(e): 2.160e-05, MSE(pi1): 2.522e-03, MSE(pi2): 2.032e-05, MSE(pi3): 4.619e-04\n",
      "Epoch 11600, Train loss: 2.825e+02, Test loss: 6.861e+09, MSE(e): 2.111e-05, MSE(pi1): 2.523e-03, MSE(pi2): 2.001e-05, MSE(pi3): 4.611e-04\n",
      "Epoch 11700, Train loss: 2.778e+02, Test loss: 5.339e+09, MSE(e): 2.065e-05, MSE(pi1): 2.522e-03, MSE(pi2): 1.972e-05, MSE(pi3): 4.607e-04\n",
      "Epoch 11800, Train loss: 2.737e+02, Test loss: 6.243e+08, MSE(e): 2.025e-05, MSE(pi1): 2.521e-03, MSE(pi2): 1.945e-05, MSE(pi3): 4.603e-04\n",
      "Epoch 11900, Train loss: 2.701e+02, Test loss: 5.041e+05, MSE(e): 1.989e-05, MSE(pi1): 2.519e-03, MSE(pi2): 1.921e-05, MSE(pi3): 4.599e-04\n",
      "Epoch 12000, Train loss: 2.668e+02, Test loss: 1.050e+05, MSE(e): 1.957e-05, MSE(pi1): 2.516e-03, MSE(pi2): 1.898e-05, MSE(pi3): 4.597e-04\n",
      "Epoch 12100, Train loss: 2.639e+02, Test loss: 5.156e+04, MSE(e): 1.928e-05, MSE(pi1): 2.512e-03, MSE(pi2): 1.878e-05, MSE(pi3): 4.596e-04\n",
      "Epoch 12200, Train loss: 2.614e+02, Test loss: 2.699e+04, MSE(e): 1.903e-05, MSE(pi1): 2.506e-03, MSE(pi2): 1.859e-05, MSE(pi3): 4.599e-04\n",
      "Epoch 12300, Train loss: 2.590e+02, Test loss: 1.545e+04, MSE(e): 1.880e-05, MSE(pi1): 2.496e-03, MSE(pi2): 1.841e-05, MSE(pi3): 4.605e-04\n",
      "Epoch 12400, Train loss: 2.566e+02, Test loss: 9.960e+03, MSE(e): 1.856e-05, MSE(pi1): 2.483e-03, MSE(pi2): 1.824e-05, MSE(pi3): 4.612e-04\n",
      "Epoch 12500, Train loss: 2.541e+02, Test loss: 7.454e+03, MSE(e): 1.832e-05, MSE(pi1): 2.472e-03, MSE(pi2): 1.807e-05, MSE(pi3): 4.617e-04\n",
      "Epoch 12600, Train loss: 2.516e+02, Test loss: 6.867e+03, MSE(e): 1.808e-05, MSE(pi1): 2.464e-03, MSE(pi2): 1.791e-05, MSE(pi3): 4.620e-04\n",
      "Epoch 12700, Train loss: 2.492e+02, Test loss: 8.011e+03, MSE(e): 1.784e-05, MSE(pi1): 2.457e-03, MSE(pi2): 1.774e-05, MSE(pi3): 4.621e-04\n",
      "Epoch 12800, Train loss: 2.469e+02, Test loss: 8.386e+03, MSE(e): 1.761e-05, MSE(pi1): 2.451e-03, MSE(pi2): 1.758e-05, MSE(pi3): 4.622e-04\n",
      "Epoch 12900, Train loss: 2.446e+02, Test loss: 7.318e+03, MSE(e): 1.739e-05, MSE(pi1): 2.447e-03, MSE(pi2): 1.741e-05, MSE(pi3): 4.622e-04\n",
      "Epoch 13000, Train loss: 2.425e+02, Test loss: 6.404e+03, MSE(e): 1.718e-05, MSE(pi1): 2.443e-03, MSE(pi2): 1.726e-05, MSE(pi3): 4.621e-04\n",
      "Epoch 13100, Train loss: 2.404e+02, Test loss: 5.774e+03, MSE(e): 1.698e-05, MSE(pi1): 2.440e-03, MSE(pi2): 1.711e-05, MSE(pi3): 4.619e-04\n",
      "Epoch 13200, Train loss: 2.384e+02, Test loss: 5.393e+03, MSE(e): 1.678e-05, MSE(pi1): 2.438e-03, MSE(pi2): 1.697e-05, MSE(pi3): 4.618e-04\n",
      "Epoch 13300, Train loss: 2.364e+02, Test loss: 5.148e+03, MSE(e): 1.659e-05, MSE(pi1): 2.436e-03, MSE(pi2): 1.683e-05, MSE(pi3): 4.615e-04\n",
      "Epoch 13400, Train loss: 2.345e+02, Test loss: 5.066e+03, MSE(e): 1.640e-05, MSE(pi1): 2.434e-03, MSE(pi2): 1.669e-05, MSE(pi3): 4.613e-04\n",
      "Epoch 13500, Train loss: 2.326e+02, Test loss: 5.205e+03, MSE(e): 1.622e-05, MSE(pi1): 2.433e-03, MSE(pi2): 1.656e-05, MSE(pi3): 4.610e-04\n",
      "Epoch 13600, Train loss: 2.308e+02, Test loss: 5.519e+03, MSE(e): 1.604e-05, MSE(pi1): 2.432e-03, MSE(pi2): 1.642e-05, MSE(pi3): 4.607e-04\n",
      "Epoch 13700, Train loss: 2.290e+02, Test loss: 6.192e+03, MSE(e): 1.586e-05, MSE(pi1): 2.431e-03, MSE(pi2): 1.629e-05, MSE(pi3): 4.603e-04\n",
      "Epoch 13800, Train loss: 2.272e+02, Test loss: 7.328e+03, MSE(e): 1.569e-05, MSE(pi1): 2.430e-03, MSE(pi2): 1.616e-05, MSE(pi3): 4.600e-04\n",
      "Epoch 13900, Train loss: 2.255e+02, Test loss: 9.364e+03, MSE(e): 1.552e-05, MSE(pi1): 2.430e-03, MSE(pi2): 1.603e-05, MSE(pi3): 4.596e-04\n",
      "Epoch 14000, Train loss: 2.237e+02, Test loss: 1.291e+04, MSE(e): 1.535e-05, MSE(pi1): 2.430e-03, MSE(pi2): 1.591e-05, MSE(pi3): 4.592e-04\n",
      "Epoch 14100, Train loss: 2.220e+02, Test loss: 1.960e+04, MSE(e): 1.518e-05, MSE(pi1): 2.430e-03, MSE(pi2): 1.578e-05, MSE(pi3): 4.587e-04\n",
      "Epoch 14200, Train loss: 2.203e+02, Test loss: 3.894e+04, MSE(e): 1.502e-05, MSE(pi1): 2.430e-03, MSE(pi2): 1.566e-05, MSE(pi3): 4.583e-04\n",
      "Epoch 14300, Train loss: 2.186e+02, Test loss: 1.322e+05, MSE(e): 1.485e-05, MSE(pi1): 2.431e-03, MSE(pi2): 1.554e-05, MSE(pi3): 4.579e-04\n",
      "Epoch 14400, Train loss: 2.168e+02, Test loss: 2.745e+06, MSE(e): 1.467e-05, MSE(pi1): 2.431e-03, MSE(pi2): 1.541e-05, MSE(pi3): 4.575e-04\n",
      "Epoch 14500, Train loss: 2.150e+02, Test loss: 1.526e+08, MSE(e): 1.449e-05, MSE(pi1): 2.432e-03, MSE(pi2): 1.529e-05, MSE(pi3): 4.570e-04\n",
      "Epoch 14600, Train loss: 2.131e+02, Test loss: 8.917e+08, MSE(e): 1.431e-05, MSE(pi1): 2.433e-03, MSE(pi2): 1.517e-05, MSE(pi3): 4.564e-04\n",
      "Epoch 14700, Train loss: 2.113e+02, Test loss: 1.734e+09, MSE(e): 1.413e-05, MSE(pi1): 2.432e-03, MSE(pi2): 1.506e-05, MSE(pi3): 4.562e-04\n",
      "Epoch 14800, Train loss: 2.095e+02, Test loss: 2.292e+09, MSE(e): 1.396e-05, MSE(pi1): 2.433e-03, MSE(pi2): 1.495e-05, MSE(pi3): 4.557e-04\n",
      "Epoch 14900, Train loss: 2.079e+02, Test loss: 2.611e+09, MSE(e): 1.380e-05, MSE(pi1): 2.431e-03, MSE(pi2): 1.485e-05, MSE(pi3): 4.556e-04\n",
      "Epoch 15000, Train loss: 2.063e+02, Test loss: 2.861e+09, MSE(e): 1.365e-05, MSE(pi1): 2.430e-03, MSE(pi2): 1.475e-05, MSE(pi3): 4.553e-04\n",
      "Epoch 15100, Train loss: 2.049e+02, Test loss: 3.142e+09, MSE(e): 1.351e-05, MSE(pi1): 2.429e-03, MSE(pi2): 1.465e-05, MSE(pi3): 4.550e-04\n",
      "Epoch 15200, Train loss: 2.036e+02, Test loss: 3.457e+09, MSE(e): 1.339e-05, MSE(pi1): 2.427e-03, MSE(pi2): 1.455e-05, MSE(pi3): 4.547e-04\n",
      "Epoch 15300, Train loss: 2.024e+02, Test loss: 3.846e+09, MSE(e): 1.327e-05, MSE(pi1): 2.426e-03, MSE(pi2): 1.446e-05, MSE(pi3): 4.544e-04\n",
      "Epoch 15400, Train loss: 2.013e+02, Test loss: 4.206e+09, MSE(e): 1.316e-05, MSE(pi1): 2.424e-03, MSE(pi2): 1.437e-05, MSE(pi3): 4.541e-04\n",
      "Epoch 15500, Train loss: 2.002e+02, Test loss: 4.585e+09, MSE(e): 1.306e-05, MSE(pi1): 2.422e-03, MSE(pi2): 1.428e-05, MSE(pi3): 4.538e-04\n",
      "Epoch 15600, Train loss: 1.991e+02, Test loss: 4.933e+09, MSE(e): 1.296e-05, MSE(pi1): 2.420e-03, MSE(pi2): 1.419e-05, MSE(pi3): 4.535e-04\n",
      "Epoch 15700, Train loss: 1.981e+02, Test loss: 5.231e+09, MSE(e): 1.286e-05, MSE(pi1): 2.418e-03, MSE(pi2): 1.410e-05, MSE(pi3): 4.532e-04\n",
      "Epoch 15800, Train loss: 1.971e+02, Test loss: 5.460e+09, MSE(e): 1.277e-05, MSE(pi1): 2.416e-03, MSE(pi2): 1.402e-05, MSE(pi3): 4.529e-04\n",
      "Epoch 15900, Train loss: 1.962e+02, Test loss: 5.618e+09, MSE(e): 1.268e-05, MSE(pi1): 2.414e-03, MSE(pi2): 1.393e-05, MSE(pi3): 4.526e-04\n",
      "Epoch 16000, Train loss: 1.952e+02, Test loss: 5.718e+09, MSE(e): 1.259e-05, MSE(pi1): 2.413e-03, MSE(pi2): 1.384e-05, MSE(pi3): 4.522e-04\n",
      "Epoch 16100, Train loss: 1.943e+02, Test loss: 5.769e+09, MSE(e): 1.250e-05, MSE(pi1): 2.412e-03, MSE(pi2): 1.376e-05, MSE(pi3): 4.519e-04\n",
      "Epoch 16200, Train loss: 1.934e+02, Test loss: 5.786e+09, MSE(e): 1.241e-05, MSE(pi1): 2.409e-03, MSE(pi2): 1.367e-05, MSE(pi3): 4.518e-04\n",
      "Epoch 16300, Train loss: 1.925e+02, Test loss: 5.779e+09, MSE(e): 1.233e-05, MSE(pi1): 2.406e-03, MSE(pi2): 1.359e-05, MSE(pi3): 4.517e-04\n",
      "Epoch 16400, Train loss: 1.917e+02, Test loss: 5.759e+09, MSE(e): 1.225e-05, MSE(pi1): 2.401e-03, MSE(pi2): 1.351e-05, MSE(pi3): 4.516e-04\n",
      "Epoch 16500, Train loss: 1.908e+02, Test loss: 5.732e+09, MSE(e): 1.217e-05, MSE(pi1): 2.397e-03, MSE(pi2): 1.343e-05, MSE(pi3): 4.516e-04\n",
      "Epoch 16600, Train loss: 1.900e+02, Test loss: 5.706e+09, MSE(e): 1.209e-05, MSE(pi1): 2.392e-03, MSE(pi2): 1.335e-05, MSE(pi3): 4.516e-04\n",
      "Epoch 16700, Train loss: 1.892e+02, Test loss: 5.681e+09, MSE(e): 1.201e-05, MSE(pi1): 2.388e-03, MSE(pi2): 1.327e-05, MSE(pi3): 4.516e-04\n",
      "Epoch 16800, Train loss: 1.884e+02, Test loss: 5.660e+09, MSE(e): 1.194e-05, MSE(pi1): 2.383e-03, MSE(pi2): 1.319e-05, MSE(pi3): 4.516e-04\n",
      "Epoch 16900, Train loss: 1.875e+02, Test loss: 5.650e+09, MSE(e): 1.186e-05, MSE(pi1): 2.379e-03, MSE(pi2): 1.312e-05, MSE(pi3): 4.516e-04\n",
      "Epoch 17000, Train loss: 1.867e+02, Test loss: 5.649e+09, MSE(e): 1.178e-05, MSE(pi1): 2.375e-03, MSE(pi2): 1.304e-05, MSE(pi3): 4.516e-04\n",
      "Epoch 17100, Train loss: 1.859e+02, Test loss: 5.657e+09, MSE(e): 1.170e-05, MSE(pi1): 2.370e-03, MSE(pi2): 1.296e-05, MSE(pi3): 4.516e-04\n",
      "Epoch 17200, Train loss: 1.851e+02, Test loss: 5.677e+09, MSE(e): 1.162e-05, MSE(pi1): 2.366e-03, MSE(pi2): 1.288e-05, MSE(pi3): 4.515e-04\n",
      "Epoch 17300, Train loss: 1.842e+02, Test loss: 5.709e+09, MSE(e): 1.154e-05, MSE(pi1): 2.362e-03, MSE(pi2): 1.280e-05, MSE(pi3): 4.515e-04\n",
      "Epoch 17400, Train loss: 1.834e+02, Test loss: 5.750e+09, MSE(e): 1.146e-05, MSE(pi1): 2.358e-03, MSE(pi2): 1.273e-05, MSE(pi3): 4.514e-04\n",
      "Epoch 17500, Train loss: 1.825e+02, Test loss: 5.800e+09, MSE(e): 1.138e-05, MSE(pi1): 2.354e-03, MSE(pi2): 1.265e-05, MSE(pi3): 4.514e-04\n",
      "Epoch 17600, Train loss: 1.816e+02, Test loss: 5.862e+09, MSE(e): 1.130e-05, MSE(pi1): 2.350e-03, MSE(pi2): 1.257e-05, MSE(pi3): 4.513e-04\n",
      "Epoch 17700, Train loss: 1.808e+02, Test loss: 5.931e+09, MSE(e): 1.122e-05, MSE(pi1): 2.346e-03, MSE(pi2): 1.249e-05, MSE(pi3): 4.512e-04\n",
      "Epoch 17800, Train loss: 1.799e+02, Test loss: 6.009e+09, MSE(e): 1.113e-05, MSE(pi1): 2.343e-03, MSE(pi2): 1.241e-05, MSE(pi3): 4.511e-04\n",
      "Epoch 17900, Train loss: 1.790e+02, Test loss: 6.090e+09, MSE(e): 1.105e-05, MSE(pi1): 2.340e-03, MSE(pi2): 1.233e-05, MSE(pi3): 4.510e-04\n",
      "Epoch 18000, Train loss: 1.781e+02, Test loss: 6.171e+09, MSE(e): 1.096e-05, MSE(pi1): 2.337e-03, MSE(pi2): 1.225e-05, MSE(pi3): 4.508e-04\n",
      "Epoch 18100, Train loss: 1.772e+02, Test loss: 6.251e+09, MSE(e): 1.088e-05, MSE(pi1): 2.334e-03, MSE(pi2): 1.217e-05, MSE(pi3): 4.506e-04\n",
      "Epoch 18200, Train loss: 1.763e+02, Test loss: 6.328e+09, MSE(e): 1.079e-05, MSE(pi1): 2.332e-03, MSE(pi2): 1.209e-05, MSE(pi3): 4.504e-04\n",
      "Epoch 18300, Train loss: 1.755e+02, Test loss: 6.392e+09, MSE(e): 1.071e-05, MSE(pi1): 2.330e-03, MSE(pi2): 1.202e-05, MSE(pi3): 4.502e-04\n",
      "Epoch 18400, Train loss: 1.746e+02, Test loss: 6.434e+09, MSE(e): 1.064e-05, MSE(pi1): 2.327e-03, MSE(pi2): 1.194e-05, MSE(pi3): 4.500e-04\n",
      "Epoch 18500, Train loss: 1.738e+02, Test loss: 6.429e+09, MSE(e): 1.056e-05, MSE(pi1): 2.325e-03, MSE(pi2): 1.187e-05, MSE(pi3): 4.497e-04\n",
      "Epoch 18600, Train loss: 1.731e+02, Test loss: 6.338e+09, MSE(e): 1.049e-05, MSE(pi1): 2.323e-03, MSE(pi2): 1.180e-05, MSE(pi3): 4.495e-04\n",
      "Epoch 18700, Train loss: 1.723e+02, Test loss: 6.105e+09, MSE(e): 1.041e-05, MSE(pi1): 2.321e-03, MSE(pi2): 1.172e-05, MSE(pi3): 4.494e-04\n",
      "Epoch 18800, Train loss: 1.715e+02, Test loss: 5.667e+09, MSE(e): 1.034e-05, MSE(pi1): 2.318e-03, MSE(pi2): 1.165e-05, MSE(pi3): 4.492e-04\n",
      "Epoch 18900, Train loss: 1.708e+02, Test loss: 4.954e+09, MSE(e): 1.027e-05, MSE(pi1): 2.316e-03, MSE(pi2): 1.158e-05, MSE(pi3): 4.490e-04\n",
      "Epoch 19000, Train loss: 1.701e+02, Test loss: 3.907e+09, MSE(e): 1.021e-05, MSE(pi1): 2.313e-03, MSE(pi2): 1.151e-05, MSE(pi3): 4.488e-04\n",
      "Epoch 19100, Train loss: 1.694e+02, Test loss: 2.632e+09, MSE(e): 1.014e-05, MSE(pi1): 2.311e-03, MSE(pi2): 1.144e-05, MSE(pi3): 4.486e-04\n",
      "Epoch 19200, Train loss: 1.687e+02, Test loss: 1.412e+09, MSE(e): 1.008e-05, MSE(pi1): 2.308e-03, MSE(pi2): 1.138e-05, MSE(pi3): 4.485e-04\n",
      "Epoch 19300, Train loss: 1.681e+02, Test loss: 5.158e+08, MSE(e): 1.002e-05, MSE(pi1): 2.306e-03, MSE(pi2): 1.131e-05, MSE(pi3): 4.483e-04\n",
      "Epoch 19400, Train loss: 1.675e+02, Test loss: 1.099e+08, MSE(e): 9.959e-06, MSE(pi1): 2.303e-03, MSE(pi2): 1.124e-05, MSE(pi3): 4.482e-04\n",
      "Epoch 19500, Train loss: 1.668e+02, Test loss: 1.486e+07, MSE(e): 9.900e-06, MSE(pi1): 2.301e-03, MSE(pi2): 1.118e-05, MSE(pi3): 4.480e-04\n",
      "Epoch 19600, Train loss: 1.662e+02, Test loss: 2.018e+06, MSE(e): 9.842e-06, MSE(pi1): 2.298e-03, MSE(pi2): 1.111e-05, MSE(pi3): 4.479e-04\n",
      "Epoch 19700, Train loss: 1.656e+02, Test loss: 4.325e+05, MSE(e): 9.786e-06, MSE(pi1): 2.296e-03, MSE(pi2): 1.105e-05, MSE(pi3): 4.477e-04\n",
      "Epoch 19800, Train loss: 1.650e+02, Test loss: 1.636e+05, MSE(e): 9.731e-06, MSE(pi1): 2.293e-03, MSE(pi2): 1.099e-05, MSE(pi3): 4.476e-04\n",
      "Epoch 19900, Train loss: 1.644e+02, Test loss: 8.346e+04, MSE(e): 9.676e-06, MSE(pi1): 2.291e-03, MSE(pi2): 1.093e-05, MSE(pi3): 4.474e-04\n",
      "Epoch 20000, Train loss: 1.639e+02, Test loss: 4.882e+04, MSE(e): 9.624e-06, MSE(pi1): 2.288e-03, MSE(pi2): 1.087e-05, MSE(pi3): 4.473e-04\n",
      "Epoch 20100, Train loss: 1.633e+02, Test loss: 2.964e+04, MSE(e): 9.573e-06, MSE(pi1): 2.286e-03, MSE(pi2): 1.081e-05, MSE(pi3): 4.471e-04\n",
      "Epoch 20200, Train loss: 1.628e+02, Test loss: 1.862e+04, MSE(e): 9.523e-06, MSE(pi1): 2.284e-03, MSE(pi2): 1.075e-05, MSE(pi3): 4.470e-04\n",
      "Epoch 20300, Train loss: 1.622e+02, Test loss: 1.199e+04, MSE(e): 9.474e-06, MSE(pi1): 2.281e-03, MSE(pi2): 1.069e-05, MSE(pi3): 4.469e-04\n",
      "Epoch 20400, Train loss: 1.617e+02, Test loss: 8.067e+03, MSE(e): 9.426e-06, MSE(pi1): 2.279e-03, MSE(pi2): 1.064e-05, MSE(pi3): 4.467e-04\n",
      "Epoch 20500, Train loss: 1.612e+02, Test loss: 5.670e+03, MSE(e): 9.380e-06, MSE(pi1): 2.276e-03, MSE(pi2): 1.058e-05, MSE(pi3): 4.466e-04\n",
      "Epoch 20600, Train loss: 1.607e+02, Test loss: 4.178e+03, MSE(e): 9.334e-06, MSE(pi1): 2.274e-03, MSE(pi2): 1.053e-05, MSE(pi3): 4.465e-04\n",
      "Epoch 20700, Train loss: 1.603e+02, Test loss: 3.190e+03, MSE(e): 9.290e-06, MSE(pi1): 2.272e-03, MSE(pi2): 1.048e-05, MSE(pi3): 4.463e-04\n",
      "Epoch 20800, Train loss: 1.598e+02, Test loss: 2.524e+03, MSE(e): 9.246e-06, MSE(pi1): 2.270e-03, MSE(pi2): 1.042e-05, MSE(pi3): 4.462e-04\n",
      "Epoch 20900, Train loss: 1.593e+02, Test loss: 2.061e+03, MSE(e): 9.203e-06, MSE(pi1): 2.267e-03, MSE(pi2): 1.037e-05, MSE(pi3): 4.461e-04\n",
      "Epoch 21000, Train loss: 1.589e+02, Test loss: 1.738e+03, MSE(e): 9.161e-06, MSE(pi1): 2.265e-03, MSE(pi2): 1.032e-05, MSE(pi3): 4.459e-04\n",
      "Epoch 21100, Train loss: 1.584e+02, Test loss: 1.489e+03, MSE(e): 9.120e-06, MSE(pi1): 2.263e-03, MSE(pi2): 1.027e-05, MSE(pi3): 4.458e-04\n",
      "Epoch 21200, Train loss: 1.580e+02, Test loss: 1.302e+03, MSE(e): 9.080e-06, MSE(pi1): 2.261e-03, MSE(pi2): 1.022e-05, MSE(pi3): 4.457e-04\n",
      "Epoch 21300, Train loss: 1.576e+02, Test loss: 1.158e+03, MSE(e): 9.040e-06, MSE(pi1): 2.259e-03, MSE(pi2): 1.017e-05, MSE(pi3): 4.455e-04\n",
      "Epoch 21400, Train loss: 1.571e+02, Test loss: 1.043e+03, MSE(e): 9.001e-06, MSE(pi1): 2.257e-03, MSE(pi2): 1.013e-05, MSE(pi3): 4.454e-04\n",
      "Epoch 21500, Train loss: 1.567e+02, Test loss: 9.501e+02, MSE(e): 8.964e-06, MSE(pi1): 2.255e-03, MSE(pi2): 1.008e-05, MSE(pi3): 4.452e-04\n",
      "Epoch 21600, Train loss: 1.563e+02, Test loss: 8.738e+02, MSE(e): 8.926e-06, MSE(pi1): 2.253e-03, MSE(pi2): 1.003e-05, MSE(pi3): 4.451e-04\n",
      "Epoch 21700, Train loss: 1.559e+02, Test loss: 8.102e+02, MSE(e): 8.889e-06, MSE(pi1): 2.251e-03, MSE(pi2): 9.989e-06, MSE(pi3): 4.450e-04\n",
      "Epoch 21800, Train loss: 1.555e+02, Test loss: 7.573e+02, MSE(e): 8.853e-06, MSE(pi1): 2.249e-03, MSE(pi2): 9.944e-06, MSE(pi3): 4.449e-04\n",
      "Epoch 21900, Train loss: 1.551e+02, Test loss: 7.114e+02, MSE(e): 8.818e-06, MSE(pi1): 2.247e-03, MSE(pi2): 9.901e-06, MSE(pi3): 4.448e-04\n",
      "Epoch 22000, Train loss: 1.548e+02, Test loss: 6.724e+02, MSE(e): 8.785e-06, MSE(pi1): 2.245e-03, MSE(pi2): 9.859e-06, MSE(pi3): 4.447e-04\n",
      "Epoch 22100, Train loss: 1.544e+02, Test loss: 6.377e+02, MSE(e): 8.751e-06, MSE(pi1): 2.243e-03, MSE(pi2): 9.818e-06, MSE(pi3): 4.446e-04\n",
      "Epoch 22200, Train loss: 1.540e+02, Test loss: 6.071e+02, MSE(e): 8.717e-06, MSE(pi1): 2.241e-03, MSE(pi2): 9.775e-06, MSE(pi3): 4.445e-04\n",
      "Epoch 22300, Train loss: 1.537e+02, Test loss: 5.796e+02, MSE(e): 8.684e-06, MSE(pi1): 2.239e-03, MSE(pi2): 9.734e-06, MSE(pi3): 4.444e-04\n",
      "Epoch 22400, Train loss: 1.533e+02, Test loss: 5.555e+02, MSE(e): 8.653e-06, MSE(pi1): 2.237e-03, MSE(pi2): 9.694e-06, MSE(pi3): 4.443e-04\n",
      "Epoch 22500, Train loss: 1.530e+02, Test loss: 5.339e+02, MSE(e): 8.620e-06, MSE(pi1): 2.235e-03, MSE(pi2): 9.653e-06, MSE(pi3): 4.442e-04\n",
      "Epoch 22600, Train loss: 1.526e+02, Test loss: 5.153e+02, MSE(e): 8.589e-06, MSE(pi1): 2.233e-03, MSE(pi2): 9.614e-06, MSE(pi3): 4.441e-04\n",
      "Epoch 22700, Train loss: 1.523e+02, Test loss: 4.986e+02, MSE(e): 8.559e-06, MSE(pi1): 2.231e-03, MSE(pi2): 9.574e-06, MSE(pi3): 4.440e-04\n",
      "Epoch 22800, Train loss: 1.520e+02, Test loss: 4.836e+02, MSE(e): 8.528e-06, MSE(pi1): 2.229e-03, MSE(pi2): 9.536e-06, MSE(pi3): 4.439e-04\n",
      "Epoch 22900, Train loss: 1.517e+02, Test loss: 4.700e+02, MSE(e): 8.500e-06, MSE(pi1): 2.227e-03, MSE(pi2): 9.499e-06, MSE(pi3): 4.438e-04\n",
      "Epoch 23000, Train loss: 1.513e+02, Test loss: 4.574e+02, MSE(e): 8.470e-06, MSE(pi1): 2.225e-03, MSE(pi2): 9.460e-06, MSE(pi3): 4.437e-04\n",
      "Epoch 23100, Train loss: 1.510e+02, Test loss: 4.461e+02, MSE(e): 8.441e-06, MSE(pi1): 2.223e-03, MSE(pi2): 9.423e-06, MSE(pi3): 4.437e-04\n",
      "Epoch 23200, Train loss: 1.507e+02, Test loss: 4.357e+02, MSE(e): 8.412e-06, MSE(pi1): 2.222e-03, MSE(pi2): 9.386e-06, MSE(pi3): 4.436e-04\n",
      "Epoch 23300, Train loss: 1.504e+02, Test loss: 4.260e+02, MSE(e): 8.384e-06, MSE(pi1): 2.220e-03, MSE(pi2): 9.350e-06, MSE(pi3): 4.435e-04\n",
      "Epoch 23400, Train loss: 1.501e+02, Test loss: 4.171e+02, MSE(e): 8.356e-06, MSE(pi1): 2.218e-03, MSE(pi2): 9.313e-06, MSE(pi3): 4.434e-04\n",
      "Epoch 23500, Train loss: 1.498e+02, Test loss: 4.090e+02, MSE(e): 8.329e-06, MSE(pi1): 2.216e-03, MSE(pi2): 9.277e-06, MSE(pi3): 4.433e-04\n",
      "Epoch 23600, Train loss: 1.495e+02, Test loss: 4.016e+02, MSE(e): 8.301e-06, MSE(pi1): 2.214e-03, MSE(pi2): 9.240e-06, MSE(pi3): 4.432e-04\n",
      "Epoch 23700, Train loss: 1.492e+02, Test loss: 3.948e+02, MSE(e): 8.275e-06, MSE(pi1): 2.212e-03, MSE(pi2): 9.206e-06, MSE(pi3): 4.432e-04\n",
      "Epoch 23800, Train loss: 1.489e+02, Test loss: 3.886e+02, MSE(e): 8.248e-06, MSE(pi1): 2.211e-03, MSE(pi2): 9.170e-06, MSE(pi3): 4.431e-04\n",
      "Epoch 23900, Train loss: 1.486e+02, Test loss: 3.827e+02, MSE(e): 8.221e-06, MSE(pi1): 2.209e-03, MSE(pi2): 9.136e-06, MSE(pi3): 4.430e-04\n",
      "Epoch 24000, Train loss: 1.483e+02, Test loss: 3.772e+02, MSE(e): 8.195e-06, MSE(pi1): 2.207e-03, MSE(pi2): 9.103e-06, MSE(pi3): 4.429e-04\n",
      "Epoch 24100, Train loss: 1.480e+02, Test loss: 3.722e+02, MSE(e): 8.169e-06, MSE(pi1): 2.205e-03, MSE(pi2): 9.068e-06, MSE(pi3): 4.429e-04\n",
      "Epoch 24200, Train loss: 1.477e+02, Test loss: 3.675e+02, MSE(e): 8.140e-06, MSE(pi1): 2.203e-03, MSE(pi2): 9.032e-06, MSE(pi3): 4.428e-04\n",
      "Epoch 24300, Train loss: 1.474e+02, Test loss: 3.631e+02, MSE(e): 8.113e-06, MSE(pi1): 2.202e-03, MSE(pi2): 8.999e-06, MSE(pi3): 4.427e-04\n",
      "Epoch 24400, Train loss: 1.471e+02, Test loss: 3.590e+02, MSE(e): 8.084e-06, MSE(pi1): 2.200e-03, MSE(pi2): 8.962e-06, MSE(pi3): 4.426e-04\n",
      "Epoch 24500, Train loss: 1.468e+02, Test loss: 3.551e+02, MSE(e): 8.055e-06, MSE(pi1): 2.199e-03, MSE(pi2): 8.928e-06, MSE(pi3): 4.426e-04\n",
      "Epoch 24600, Train loss: 1.465e+02, Test loss: 3.514e+02, MSE(e): 8.025e-06, MSE(pi1): 2.197e-03, MSE(pi2): 8.892e-06, MSE(pi3): 4.425e-04\n",
      "Epoch 24700, Train loss: 1.461e+02, Test loss: 3.479e+02, MSE(e): 7.993e-06, MSE(pi1): 2.195e-03, MSE(pi2): 8.855e-06, MSE(pi3): 4.424e-04\n",
      "Epoch 24800, Train loss: 1.458e+02, Test loss: 3.444e+02, MSE(e): 7.961e-06, MSE(pi1): 2.194e-03, MSE(pi2): 8.820e-06, MSE(pi3): 4.424e-04\n",
      "Epoch 24900, Train loss: 1.454e+02, Test loss: 3.411e+02, MSE(e): 7.926e-06, MSE(pi1): 2.192e-03, MSE(pi2): 8.783e-06, MSE(pi3): 4.423e-04\n",
      "Epoch 25000, Train loss: 1.450e+02, Test loss: 3.377e+02, MSE(e): 7.886e-06, MSE(pi1): 2.190e-03, MSE(pi2): 8.743e-06, MSE(pi3): 4.422e-04\n",
      "Epoch 25100, Train loss: 1.444e+02, Test loss: 3.339e+02, MSE(e): 7.834e-06, MSE(pi1): 2.188e-03, MSE(pi2): 8.699e-06, MSE(pi3): 4.422e-04\n",
      "Epoch 25200, Train loss: 1.419e+02, Test loss: 3.260e+02, MSE(e): 7.578e-06, MSE(pi1): 2.175e-03, MSE(pi2): 8.593e-06, MSE(pi3): 4.433e-04\n",
      "Epoch 25300, Train loss: 1.416e+02, Test loss: 3.235e+02, MSE(e): 7.549e-06, MSE(pi1): 2.174e-03, MSE(pi2): 8.560e-06, MSE(pi3): 4.432e-04\n",
      "Epoch 25400, Train loss: 1.412e+02, Test loss: 3.214e+02, MSE(e): 7.516e-06, MSE(pi1): 2.172e-03, MSE(pi2): 8.524e-06, MSE(pi3): 4.432e-04\n",
      "Epoch 25500, Train loss: 1.409e+02, Test loss: 3.195e+02, MSE(e): 7.485e-06, MSE(pi1): 2.170e-03, MSE(pi2): 8.487e-06, MSE(pi3): 4.431e-04\n",
      "Epoch 25600, Train loss: 1.405e+02, Test loss: 3.178e+02, MSE(e): 7.455e-06, MSE(pi1): 2.168e-03, MSE(pi2): 8.450e-06, MSE(pi3): 4.431e-04\n",
      "Epoch 25700, Train loss: 1.403e+02, Test loss: 3.164e+02, MSE(e): 7.428e-06, MSE(pi1): 2.167e-03, MSE(pi2): 8.415e-06, MSE(pi3): 4.429e-04\n",
      "Epoch 25800, Train loss: 1.400e+02, Test loss: 3.153e+02, MSE(e): 7.404e-06, MSE(pi1): 2.166e-03, MSE(pi2): 8.381e-06, MSE(pi3): 4.428e-04\n",
      "Epoch 25900, Train loss: 1.397e+02, Test loss: 3.143e+02, MSE(e): 7.381e-06, MSE(pi1): 2.166e-03, MSE(pi2): 8.349e-06, MSE(pi3): 4.427e-04\n",
      "Epoch 26000, Train loss: 1.395e+02, Test loss: 3.135e+02, MSE(e): 7.362e-06, MSE(pi1): 2.165e-03, MSE(pi2): 8.317e-06, MSE(pi3): 4.425e-04\n",
      "Epoch 26100, Train loss: 1.393e+02, Test loss: 3.128e+02, MSE(e): 7.341e-06, MSE(pi1): 2.165e-03, MSE(pi2): 8.284e-06, MSE(pi3): 4.423e-04\n",
      "Epoch 26200, Train loss: 1.391e+02, Test loss: 3.122e+02, MSE(e): 7.323e-06, MSE(pi1): 2.164e-03, MSE(pi2): 8.252e-06, MSE(pi3): 4.422e-04\n",
      "Epoch 26300, Train loss: 1.389e+02, Test loss: 3.116e+02, MSE(e): 7.304e-06, MSE(pi1): 2.163e-03, MSE(pi2): 8.221e-06, MSE(pi3): 4.420e-04\n",
      "Epoch 26400, Train loss: 1.387e+02, Test loss: 3.110e+02, MSE(e): 7.285e-06, MSE(pi1): 2.163e-03, MSE(pi2): 8.190e-06, MSE(pi3): 4.419e-04\n",
      "Epoch 26500, Train loss: 1.385e+02, Test loss: 3.105e+02, MSE(e): 7.268e-06, MSE(pi1): 2.162e-03, MSE(pi2): 8.161e-06, MSE(pi3): 4.417e-04\n",
      "Epoch 26600, Train loss: 1.383e+02, Test loss: 3.102e+02, MSE(e): 7.252e-06, MSE(pi1): 2.161e-03, MSE(pi2): 8.132e-06, MSE(pi3): 4.416e-04\n",
      "Epoch 26700, Train loss: 1.381e+02, Test loss: 3.099e+02, MSE(e): 7.235e-06, MSE(pi1): 2.161e-03, MSE(pi2): 8.101e-06, MSE(pi3): 4.414e-04\n",
      "Epoch 26800, Train loss: 1.379e+02, Test loss: 3.096e+02, MSE(e): 7.220e-06, MSE(pi1): 2.160e-03, MSE(pi2): 8.072e-06, MSE(pi3): 4.413e-04\n",
      "Epoch 26900, Train loss: 1.378e+02, Test loss: 3.094e+02, MSE(e): 7.205e-06, MSE(pi1): 2.160e-03, MSE(pi2): 8.043e-06, MSE(pi3): 4.411e-04\n",
      "Epoch 27000, Train loss: 1.376e+02, Test loss: 3.094e+02, MSE(e): 7.192e-06, MSE(pi1): 2.159e-03, MSE(pi2): 8.015e-06, MSE(pi3): 4.409e-04\n",
      "Epoch 27100, Train loss: 1.375e+02, Test loss: 3.095e+02, MSE(e): 7.179e-06, MSE(pi1): 2.159e-03, MSE(pi2): 7.988e-06, MSE(pi3): 4.408e-04\n",
      "Epoch 27200, Train loss: 1.374e+02, Test loss: 3.096e+02, MSE(e): 7.170e-06, MSE(pi1): 2.159e-03, MSE(pi2): 7.962e-06, MSE(pi3): 4.405e-04\n",
      "Epoch 27300, Train loss: 1.373e+02, Test loss: 3.103e+02, MSE(e): 7.168e-06, MSE(pi1): 2.161e-03, MSE(pi2): 7.938e-06, MSE(pi3): 4.402e-04\n",
      "Epoch 27400, Train loss: 1.373e+02, Test loss: 3.116e+02, MSE(e): 7.173e-06, MSE(pi1): 2.165e-03, MSE(pi2): 7.913e-06, MSE(pi3): 4.395e-04\n",
      "Epoch 27500, Train loss: 1.372e+02, Test loss: 3.122e+02, MSE(e): 7.158e-06, MSE(pi1): 2.165e-03, MSE(pi2): 7.881e-06, MSE(pi3): 4.392e-04\n",
      "Epoch 27600, Train loss: 1.369e+02, Test loss: 3.125e+02, MSE(e): 7.138e-06, MSE(pi1): 2.165e-03, MSE(pi2): 7.849e-06, MSE(pi3): 4.391e-04\n",
      "Epoch 27700, Train loss: 1.367e+02, Test loss: 3.128e+02, MSE(e): 7.118e-06, MSE(pi1): 2.164e-03, MSE(pi2): 7.817e-06, MSE(pi3): 4.390e-04\n",
      "Epoch 27800, Train loss: 1.365e+02, Test loss: 3.132e+02, MSE(e): 7.097e-06, MSE(pi1): 2.163e-03, MSE(pi2): 7.785e-06, MSE(pi3): 4.388e-04\n",
      "Epoch 27900, Train loss: 1.363e+02, Test loss: 3.136e+02, MSE(e): 7.076e-06, MSE(pi1): 2.163e-03, MSE(pi2): 7.753e-06, MSE(pi3): 4.387e-04\n",
      "Epoch 28000, Train loss: 1.360e+02, Test loss: 3.141e+02, MSE(e): 7.054e-06, MSE(pi1): 2.162e-03, MSE(pi2): 7.721e-06, MSE(pi3): 4.386e-04\n",
      "Epoch 28100, Train loss: 1.358e+02, Test loss: 3.146e+02, MSE(e): 7.032e-06, MSE(pi1): 2.161e-03, MSE(pi2): 7.689e-06, MSE(pi3): 4.385e-04\n",
      "Epoch 28200, Train loss: 1.355e+02, Test loss: 3.152e+02, MSE(e): 7.009e-06, MSE(pi1): 2.160e-03, MSE(pi2): 7.657e-06, MSE(pi3): 4.383e-04\n",
      "Epoch 28300, Train loss: 1.353e+02, Test loss: 3.157e+02, MSE(e): 6.987e-06, MSE(pi1): 2.159e-03, MSE(pi2): 7.626e-06, MSE(pi3): 4.382e-04\n",
      "Epoch 28400, Train loss: 1.350e+02, Test loss: 3.163e+02, MSE(e): 6.965e-06, MSE(pi1): 2.158e-03, MSE(pi2): 7.594e-06, MSE(pi3): 4.381e-04\n",
      "Epoch 28500, Train loss: 1.348e+02, Test loss: 3.169e+02, MSE(e): 6.942e-06, MSE(pi1): 2.157e-03, MSE(pi2): 7.562e-06, MSE(pi3): 4.380e-04\n",
      "Epoch 28600, Train loss: 1.345e+02, Test loss: 3.175e+02, MSE(e): 6.919e-06, MSE(pi1): 2.156e-03, MSE(pi2): 7.531e-06, MSE(pi3): 4.379e-04\n",
      "Epoch 28700, Train loss: 1.343e+02, Test loss: 3.182e+02, MSE(e): 6.897e-06, MSE(pi1): 2.155e-03, MSE(pi2): 7.499e-06, MSE(pi3): 4.378e-04\n",
      "Epoch 28800, Train loss: 1.341e+02, Test loss: 3.189e+02, MSE(e): 6.873e-06, MSE(pi1): 2.154e-03, MSE(pi2): 7.468e-06, MSE(pi3): 4.377e-04\n",
      "Epoch 28900, Train loss: 1.338e+02, Test loss: 3.197e+02, MSE(e): 6.852e-06, MSE(pi1): 2.153e-03, MSE(pi2): 7.438e-06, MSE(pi3): 4.376e-04\n",
      "Epoch 29000, Train loss: 1.336e+02, Test loss: 3.204e+02, MSE(e): 6.829e-06, MSE(pi1): 2.152e-03, MSE(pi2): 7.406e-06, MSE(pi3): 4.376e-04\n",
      "Epoch 29100, Train loss: 1.333e+02, Test loss: 3.211e+02, MSE(e): 6.806e-06, MSE(pi1): 2.150e-03, MSE(pi2): 7.376e-06, MSE(pi3): 4.375e-04\n",
      "Epoch 29200, Train loss: 1.331e+02, Test loss: 3.219e+02, MSE(e): 6.783e-06, MSE(pi1): 2.149e-03, MSE(pi2): 7.345e-06, MSE(pi3): 4.374e-04\n",
      "Epoch 29300, Train loss: 1.328e+02, Test loss: 3.227e+02, MSE(e): 6.760e-06, MSE(pi1): 2.148e-03, MSE(pi2): 7.315e-06, MSE(pi3): 4.373e-04\n",
      "Epoch 29400, Train loss: 1.326e+02, Test loss: 3.236e+02, MSE(e): 6.738e-06, MSE(pi1): 2.147e-03, MSE(pi2): 7.285e-06, MSE(pi3): 4.372e-04\n",
      "Epoch 29500, Train loss: 1.323e+02, Test loss: 3.244e+02, MSE(e): 6.713e-06, MSE(pi1): 2.146e-03, MSE(pi2): 7.253e-06, MSE(pi3): 4.372e-04\n",
      "Epoch 29600, Train loss: 1.321e+02, Test loss: 3.251e+02, MSE(e): 6.690e-06, MSE(pi1): 2.144e-03, MSE(pi2): 7.223e-06, MSE(pi3): 4.371e-04\n",
      "Epoch 29700, Train loss: 1.318e+02, Test loss: 3.259e+02, MSE(e): 6.668e-06, MSE(pi1): 2.143e-03, MSE(pi2): 7.192e-06, MSE(pi3): 4.370e-04\n",
      "Epoch 29800, Train loss: 1.316e+02, Test loss: 3.267e+02, MSE(e): 6.644e-06, MSE(pi1): 2.142e-03, MSE(pi2): 7.162e-06, MSE(pi3): 4.370e-04\n",
      "Epoch 29900, Train loss: 1.313e+02, Test loss: 3.276e+02, MSE(e): 6.622e-06, MSE(pi1): 2.140e-03, MSE(pi2): 7.133e-06, MSE(pi3): 4.369e-04\n",
      "Epoch 30000, Train loss: 1.311e+02, Test loss: 3.285e+02, MSE(e): 6.599e-06, MSE(pi1): 2.139e-03, MSE(pi2): 7.103e-06, MSE(pi3): 4.369e-04\n",
      "Epoch 30100, Train loss: 1.308e+02, Test loss: 3.293e+02, MSE(e): 6.576e-06, MSE(pi1): 2.138e-03, MSE(pi2): 7.073e-06, MSE(pi3): 4.368e-04\n",
      "Epoch 30200, Train loss: 1.306e+02, Test loss: 3.302e+02, MSE(e): 6.553e-06, MSE(pi1): 2.137e-03, MSE(pi2): 7.043e-06, MSE(pi3): 4.368e-04\n",
      "Epoch 30300, Train loss: 1.303e+02, Test loss: 3.310e+02, MSE(e): 6.531e-06, MSE(pi1): 2.135e-03, MSE(pi2): 7.014e-06, MSE(pi3): 4.367e-04\n",
      "Epoch 30400, Train loss: 1.301e+02, Test loss: 3.318e+02, MSE(e): 6.508e-06, MSE(pi1): 2.134e-03, MSE(pi2): 6.984e-06, MSE(pi3): 4.366e-04\n",
      "Epoch 30500, Train loss: 1.299e+02, Test loss: 3.326e+02, MSE(e): 6.487e-06, MSE(pi1): 2.133e-03, MSE(pi2): 6.956e-06, MSE(pi3): 4.366e-04\n",
      "Epoch 30600, Train loss: 1.296e+02, Test loss: 3.334e+02, MSE(e): 6.464e-06, MSE(pi1): 2.131e-03, MSE(pi2): 6.927e-06, MSE(pi3): 4.365e-04\n",
      "Epoch 30700, Train loss: 1.294e+02, Test loss: 3.342e+02, MSE(e): 6.441e-06, MSE(pi1): 2.130e-03, MSE(pi2): 6.898e-06, MSE(pi3): 4.365e-04\n",
      "Epoch 30800, Train loss: 1.291e+02, Test loss: 3.351e+02, MSE(e): 6.420e-06, MSE(pi1): 2.129e-03, MSE(pi2): 6.870e-06, MSE(pi3): 4.364e-04\n",
      "Epoch 30900, Train loss: 1.289e+02, Test loss: 3.359e+02, MSE(e): 6.398e-06, MSE(pi1): 2.127e-03, MSE(pi2): 6.841e-06, MSE(pi3): 4.364e-04\n",
      "Epoch 31000, Train loss: 1.287e+02, Test loss: 3.367e+02, MSE(e): 6.377e-06, MSE(pi1): 2.126e-03, MSE(pi2): 6.812e-06, MSE(pi3): 4.363e-04\n",
      "Epoch 31100, Train loss: 1.284e+02, Test loss: 3.375e+02, MSE(e): 6.355e-06, MSE(pi1): 2.125e-03, MSE(pi2): 6.784e-06, MSE(pi3): 4.363e-04\n",
      "Epoch 31200, Train loss: 1.282e+02, Test loss: 3.383e+02, MSE(e): 6.334e-06, MSE(pi1): 2.124e-03, MSE(pi2): 6.757e-06, MSE(pi3): 4.363e-04\n",
      "Epoch 31300, Train loss: 1.280e+02, Test loss: 3.391e+02, MSE(e): 6.313e-06, MSE(pi1): 2.122e-03, MSE(pi2): 6.729e-06, MSE(pi3): 4.362e-04\n",
      "Epoch 31400, Train loss: 1.278e+02, Test loss: 3.398e+02, MSE(e): 6.292e-06, MSE(pi1): 2.121e-03, MSE(pi2): 6.702e-06, MSE(pi3): 4.362e-04\n",
      "Epoch 31500, Train loss: 1.275e+02, Test loss: 3.405e+02, MSE(e): 6.271e-06, MSE(pi1): 2.120e-03, MSE(pi2): 6.674e-06, MSE(pi3): 4.361e-04\n",
      "Epoch 31600, Train loss: 1.273e+02, Test loss: 3.412e+02, MSE(e): 6.250e-06, MSE(pi1): 2.118e-03, MSE(pi2): 6.647e-06, MSE(pi3): 4.361e-04\n",
      "Epoch 31700, Train loss: 1.271e+02, Test loss: 3.418e+02, MSE(e): 6.230e-06, MSE(pi1): 2.117e-03, MSE(pi2): 6.620e-06, MSE(pi3): 4.361e-04\n",
      "Epoch 31800, Train loss: 1.269e+02, Test loss: 3.426e+02, MSE(e): 6.209e-06, MSE(pi1): 2.115e-03, MSE(pi2): 6.592e-06, MSE(pi3): 4.360e-04\n",
      "Epoch 31900, Train loss: 1.266e+02, Test loss: 3.433e+02, MSE(e): 6.188e-06, MSE(pi1): 2.114e-03, MSE(pi2): 6.564e-06, MSE(pi3): 4.360e-04\n",
      "Epoch 32000, Train loss: 1.264e+02, Test loss: 3.439e+02, MSE(e): 6.168e-06, MSE(pi1): 2.113e-03, MSE(pi2): 6.538e-06, MSE(pi3): 4.360e-04\n",
      "Epoch 32100, Train loss: 1.262e+02, Test loss: 3.445e+02, MSE(e): 6.148e-06, MSE(pi1): 2.112e-03, MSE(pi2): 6.510e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 32200, Train loss: 1.260e+02, Test loss: 3.453e+02, MSE(e): 6.129e-06, MSE(pi1): 2.110e-03, MSE(pi2): 6.485e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 32300, Train loss: 1.258e+02, Test loss: 3.459e+02, MSE(e): 6.110e-06, MSE(pi1): 2.109e-03, MSE(pi2): 6.460e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 32400, Train loss: 1.256e+02, Test loss: 3.465e+02, MSE(e): 6.091e-06, MSE(pi1): 2.108e-03, MSE(pi2): 6.433e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 32500, Train loss: 1.254e+02, Test loss: 3.472e+02, MSE(e): 6.071e-06, MSE(pi1): 2.107e-03, MSE(pi2): 6.407e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 32600, Train loss: 1.252e+02, Test loss: 3.478e+02, MSE(e): 6.053e-06, MSE(pi1): 2.105e-03, MSE(pi2): 6.381e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 32700, Train loss: 1.250e+02, Test loss: 3.484e+02, MSE(e): 6.034e-06, MSE(pi1): 2.104e-03, MSE(pi2): 6.355e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 32800, Train loss: 1.247e+02, Test loss: 3.489e+02, MSE(e): 6.014e-06, MSE(pi1): 2.102e-03, MSE(pi2): 6.330e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 32900, Train loss: 1.246e+02, Test loss: 3.494e+02, MSE(e): 5.997e-06, MSE(pi1): 2.101e-03, MSE(pi2): 6.306e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 33000, Train loss: 1.244e+02, Test loss: 3.499e+02, MSE(e): 5.980e-06, MSE(pi1): 2.098e-03, MSE(pi2): 6.281e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 33100, Train loss: 1.242e+02, Test loss: 3.504e+02, MSE(e): 5.962e-06, MSE(pi1): 2.095e-03, MSE(pi2): 6.255e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 33200, Train loss: 1.240e+02, Test loss: 3.509e+02, MSE(e): 5.945e-06, MSE(pi1): 2.094e-03, MSE(pi2): 6.232e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 33300, Train loss: 1.238e+02, Test loss: 3.513e+02, MSE(e): 5.926e-06, MSE(pi1): 2.092e-03, MSE(pi2): 6.208e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 33400, Train loss: 1.236e+02, Test loss: 3.517e+02, MSE(e): 5.909e-06, MSE(pi1): 2.091e-03, MSE(pi2): 6.183e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 33500, Train loss: 1.234e+02, Test loss: 3.520e+02, MSE(e): 5.890e-06, MSE(pi1): 2.090e-03, MSE(pi2): 6.158e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 33600, Train loss: 1.232e+02, Test loss: 3.523e+02, MSE(e): 5.873e-06, MSE(pi1): 2.088e-03, MSE(pi2): 6.134e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 33700, Train loss: 1.230e+02, Test loss: 3.527e+02, MSE(e): 5.858e-06, MSE(pi1): 2.087e-03, MSE(pi2): 6.111e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 33800, Train loss: 1.228e+02, Test loss: 3.529e+02, MSE(e): 5.841e-06, MSE(pi1): 2.085e-03, MSE(pi2): 6.088e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 33900, Train loss: 1.227e+02, Test loss: 3.531e+02, MSE(e): 5.824e-06, MSE(pi1): 2.084e-03, MSE(pi2): 6.063e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 34000, Train loss: 1.225e+02, Test loss: 3.535e+02, MSE(e): 5.807e-06, MSE(pi1): 2.082e-03, MSE(pi2): 6.039e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 34100, Train loss: 1.223e+02, Test loss: 3.537e+02, MSE(e): 5.792e-06, MSE(pi1): 2.080e-03, MSE(pi2): 6.016e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 34200, Train loss: 1.221e+02, Test loss: 3.539e+02, MSE(e): 5.775e-06, MSE(pi1): 2.078e-03, MSE(pi2): 5.993e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 34300, Train loss: 1.219e+02, Test loss: 3.540e+02, MSE(e): 5.758e-06, MSE(pi1): 2.077e-03, MSE(pi2): 5.969e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 34400, Train loss: 1.218e+02, Test loss: 3.541e+02, MSE(e): 5.741e-06, MSE(pi1): 2.076e-03, MSE(pi2): 5.946e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 34500, Train loss: 1.216e+02, Test loss: 3.543e+02, MSE(e): 5.725e-06, MSE(pi1): 2.074e-03, MSE(pi2): 5.923e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 34600, Train loss: 1.214e+02, Test loss: 3.545e+02, MSE(e): 5.709e-06, MSE(pi1): 2.073e-03, MSE(pi2): 5.900e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 34700, Train loss: 1.212e+02, Test loss: 3.546e+02, MSE(e): 5.692e-06, MSE(pi1): 2.072e-03, MSE(pi2): 5.877e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 34800, Train loss: 1.210e+02, Test loss: 3.547e+02, MSE(e): 5.676e-06, MSE(pi1): 2.070e-03, MSE(pi2): 5.855e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 34900, Train loss: 1.209e+02, Test loss: 3.547e+02, MSE(e): 5.659e-06, MSE(pi1): 2.069e-03, MSE(pi2): 5.831e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 35000, Train loss: 1.207e+02, Test loss: 3.548e+02, MSE(e): 5.643e-06, MSE(pi1): 2.068e-03, MSE(pi2): 5.809e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 35100, Train loss: 1.205e+02, Test loss: 3.548e+02, MSE(e): 5.627e-06, MSE(pi1): 2.067e-03, MSE(pi2): 5.787e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 35200, Train loss: 1.203e+02, Test loss: 3.548e+02, MSE(e): 5.610e-06, MSE(pi1): 2.065e-03, MSE(pi2): 5.764e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 35300, Train loss: 1.201e+02, Test loss: 3.548e+02, MSE(e): 5.593e-06, MSE(pi1): 2.064e-03, MSE(pi2): 5.740e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 35400, Train loss: 1.200e+02, Test loss: 3.548e+02, MSE(e): 5.578e-06, MSE(pi1): 2.062e-03, MSE(pi2): 5.719e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 35500, Train loss: 1.198e+02, Test loss: 3.546e+02, MSE(e): 5.561e-06, MSE(pi1): 2.061e-03, MSE(pi2): 5.698e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 35600, Train loss: 1.196e+02, Test loss: 3.544e+02, MSE(e): 5.544e-06, MSE(pi1): 2.060e-03, MSE(pi2): 5.675e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 35700, Train loss: 1.195e+02, Test loss: 3.544e+02, MSE(e): 5.529e-06, MSE(pi1): 2.059e-03, MSE(pi2): 5.653e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 35800, Train loss: 1.193e+02, Test loss: 3.542e+02, MSE(e): 5.512e-06, MSE(pi1): 2.057e-03, MSE(pi2): 5.631e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 35900, Train loss: 1.191e+02, Test loss: 3.541e+02, MSE(e): 5.496e-06, MSE(pi1): 2.056e-03, MSE(pi2): 5.608e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 36000, Train loss: 1.189e+02, Test loss: 3.539e+02, MSE(e): 5.481e-06, MSE(pi1): 2.055e-03, MSE(pi2): 5.586e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 36100, Train loss: 1.188e+02, Test loss: 3.537e+02, MSE(e): 5.465e-06, MSE(pi1): 2.054e-03, MSE(pi2): 5.564e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 36200, Train loss: 1.186e+02, Test loss: 3.535e+02, MSE(e): 5.448e-06, MSE(pi1): 2.052e-03, MSE(pi2): 5.542e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 36300, Train loss: 1.184e+02, Test loss: 3.532e+02, MSE(e): 5.432e-06, MSE(pi1): 2.051e-03, MSE(pi2): 5.522e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 36400, Train loss: 1.182e+02, Test loss: 3.530e+02, MSE(e): 5.416e-06, MSE(pi1): 2.050e-03, MSE(pi2): 5.500e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 36500, Train loss: 1.181e+02, Test loss: 3.528e+02, MSE(e): 5.401e-06, MSE(pi1): 2.048e-03, MSE(pi2): 5.478e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 36600, Train loss: 1.179e+02, Test loss: 3.525e+02, MSE(e): 5.384e-06, MSE(pi1): 2.047e-03, MSE(pi2): 5.456e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 36700, Train loss: 1.177e+02, Test loss: 3.522e+02, MSE(e): 5.368e-06, MSE(pi1): 2.046e-03, MSE(pi2): 5.435e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 36800, Train loss: 1.175e+02, Test loss: 3.519e+02, MSE(e): 5.352e-06, MSE(pi1): 2.045e-03, MSE(pi2): 5.414e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 36900, Train loss: 1.174e+02, Test loss: 3.516e+02, MSE(e): 5.335e-06, MSE(pi1): 2.043e-03, MSE(pi2): 5.393e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 37000, Train loss: 1.172e+02, Test loss: 3.514e+02, MSE(e): 5.320e-06, MSE(pi1): 2.042e-03, MSE(pi2): 5.371e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 37100, Train loss: 1.170e+02, Test loss: 3.510e+02, MSE(e): 5.302e-06, MSE(pi1): 2.041e-03, MSE(pi2): 5.349e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 37200, Train loss: 1.168e+02, Test loss: 3.506e+02, MSE(e): 5.288e-06, MSE(pi1): 2.039e-03, MSE(pi2): 5.328e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 37300, Train loss: 1.167e+02, Test loss: 3.502e+02, MSE(e): 5.272e-06, MSE(pi1): 2.038e-03, MSE(pi2): 5.307e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 37400, Train loss: 1.165e+02, Test loss: 3.496e+02, MSE(e): 5.257e-06, MSE(pi1): 2.037e-03, MSE(pi2): 5.287e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 37500, Train loss: 1.163e+02, Test loss: 3.491e+02, MSE(e): 5.240e-06, MSE(pi1): 2.036e-03, MSE(pi2): 5.266e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 37600, Train loss: 1.162e+02, Test loss: 3.486e+02, MSE(e): 5.226e-06, MSE(pi1): 2.035e-03, MSE(pi2): 5.246e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 37700, Train loss: 1.160e+02, Test loss: 3.481e+02, MSE(e): 5.210e-06, MSE(pi1): 2.033e-03, MSE(pi2): 5.224e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 37800, Train loss: 1.158e+02, Test loss: 3.477e+02, MSE(e): 5.194e-06, MSE(pi1): 2.032e-03, MSE(pi2): 5.204e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 37900, Train loss: 1.156e+02, Test loss: 3.474e+02, MSE(e): 5.178e-06, MSE(pi1): 2.030e-03, MSE(pi2): 5.182e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 38000, Train loss: 1.155e+02, Test loss: 3.471e+02, MSE(e): 5.162e-06, MSE(pi1): 2.029e-03, MSE(pi2): 5.161e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 38100, Train loss: 1.153e+02, Test loss: 3.467e+02, MSE(e): 5.148e-06, MSE(pi1): 2.028e-03, MSE(pi2): 5.142e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 38200, Train loss: 1.152e+02, Test loss: 3.461e+02, MSE(e): 5.132e-06, MSE(pi1): 2.027e-03, MSE(pi2): 5.122e-06, MSE(pi3): 4.356e-04\n",
      "Epoch 38300, Train loss: 1.150e+02, Test loss: 3.455e+02, MSE(e): 5.117e-06, MSE(pi1): 2.025e-03, MSE(pi2): 5.101e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 38400, Train loss: 1.148e+02, Test loss: 3.449e+02, MSE(e): 5.102e-06, MSE(pi1): 2.024e-03, MSE(pi2): 5.081e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 38500, Train loss: 1.147e+02, Test loss: 3.444e+02, MSE(e): 5.087e-06, MSE(pi1): 2.023e-03, MSE(pi2): 5.062e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 38600, Train loss: 1.145e+02, Test loss: 3.439e+02, MSE(e): 5.073e-06, MSE(pi1): 2.021e-03, MSE(pi2): 5.044e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 38700, Train loss: 1.144e+02, Test loss: 3.434e+02, MSE(e): 5.059e-06, MSE(pi1): 2.020e-03, MSE(pi2): 5.026e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 38800, Train loss: 1.142e+02, Test loss: 3.429e+02, MSE(e): 5.044e-06, MSE(pi1): 2.019e-03, MSE(pi2): 5.006e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 38900, Train loss: 1.140e+02, Test loss: 3.423e+02, MSE(e): 5.030e-06, MSE(pi1): 2.018e-03, MSE(pi2): 4.988e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 39000, Train loss: 1.139e+02, Test loss: 3.418e+02, MSE(e): 5.015e-06, MSE(pi1): 2.017e-03, MSE(pi2): 4.968e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 39100, Train loss: 1.137e+02, Test loss: 3.413e+02, MSE(e): 5.000e-06, MSE(pi1): 2.015e-03, MSE(pi2): 4.949e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 39200, Train loss: 1.136e+02, Test loss: 3.409e+02, MSE(e): 4.985e-06, MSE(pi1): 2.014e-03, MSE(pi2): 4.931e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 39300, Train loss: 1.134e+02, Test loss: 3.404e+02, MSE(e): 4.971e-06, MSE(pi1): 2.013e-03, MSE(pi2): 4.912e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 39400, Train loss: 1.133e+02, Test loss: 3.399e+02, MSE(e): 4.958e-06, MSE(pi1): 2.012e-03, MSE(pi2): 4.894e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 39500, Train loss: 1.131e+02, Test loss: 3.394e+02, MSE(e): 4.943e-06, MSE(pi1): 2.011e-03, MSE(pi2): 4.875e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 39600, Train loss: 1.130e+02, Test loss: 3.389e+02, MSE(e): 4.929e-06, MSE(pi1): 2.010e-03, MSE(pi2): 4.857e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 39700, Train loss: 1.128e+02, Test loss: 3.384e+02, MSE(e): 4.915e-06, MSE(pi1): 2.008e-03, MSE(pi2): 4.838e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 39800, Train loss: 1.127e+02, Test loss: 3.380e+02, MSE(e): 4.902e-06, MSE(pi1): 2.007e-03, MSE(pi2): 4.821e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 39900, Train loss: 1.125e+02, Test loss: 3.376e+02, MSE(e): 4.887e-06, MSE(pi1): 2.006e-03, MSE(pi2): 4.801e-06, MSE(pi3): 4.357e-04\n",
      "Epoch 40000, Train loss: 1.124e+02, Test loss: 3.372e+02, MSE(e): 4.872e-06, MSE(pi1): 2.005e-03, MSE(pi2): 4.782e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 40100, Train loss: 1.122e+02, Test loss: 3.367e+02, MSE(e): 4.859e-06, MSE(pi1): 2.004e-03, MSE(pi2): 4.764e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 40200, Train loss: 1.121e+02, Test loss: 3.363e+02, MSE(e): 4.845e-06, MSE(pi1): 2.003e-03, MSE(pi2): 4.746e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 40300, Train loss: 1.119e+02, Test loss: 3.358e+02, MSE(e): 4.832e-06, MSE(pi1): 2.001e-03, MSE(pi2): 4.728e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 40400, Train loss: 1.118e+02, Test loss: 3.352e+02, MSE(e): 4.817e-06, MSE(pi1): 2.000e-03, MSE(pi2): 4.710e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 40500, Train loss: 1.116e+02, Test loss: 3.348e+02, MSE(e): 4.803e-06, MSE(pi1): 1.999e-03, MSE(pi2): 4.692e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 40600, Train loss: 1.115e+02, Test loss: 3.343e+02, MSE(e): 4.790e-06, MSE(pi1): 1.998e-03, MSE(pi2): 4.675e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 40700, Train loss: 1.113e+02, Test loss: 3.338e+02, MSE(e): 4.776e-06, MSE(pi1): 1.997e-03, MSE(pi2): 4.658e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 40800, Train loss: 1.112e+02, Test loss: 3.332e+02, MSE(e): 4.763e-06, MSE(pi1): 1.996e-03, MSE(pi2): 4.641e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 40900, Train loss: 1.110e+02, Test loss: 3.327e+02, MSE(e): 4.749e-06, MSE(pi1): 1.994e-03, MSE(pi2): 4.622e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 41000, Train loss: 1.109e+02, Test loss: 3.323e+02, MSE(e): 4.736e-06, MSE(pi1): 1.993e-03, MSE(pi2): 4.605e-06, MSE(pi3): 4.358e-04\n",
      "Epoch 41100, Train loss: 1.107e+02, Test loss: 3.318e+02, MSE(e): 4.722e-06, MSE(pi1): 1.992e-03, MSE(pi2): 4.587e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 41200, Train loss: 1.106e+02, Test loss: 3.314e+02, MSE(e): 4.710e-06, MSE(pi1): 1.991e-03, MSE(pi2): 4.570e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 41300, Train loss: 1.105e+02, Test loss: 3.309e+02, MSE(e): 4.696e-06, MSE(pi1): 1.990e-03, MSE(pi2): 4.553e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 41400, Train loss: 1.103e+02, Test loss: 3.304e+02, MSE(e): 4.683e-06, MSE(pi1): 1.989e-03, MSE(pi2): 4.536e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 41500, Train loss: 1.102e+02, Test loss: 3.300e+02, MSE(e): 4.670e-06, MSE(pi1): 1.988e-03, MSE(pi2): 4.520e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 41600, Train loss: 1.100e+02, Test loss: 3.296e+02, MSE(e): 4.658e-06, MSE(pi1): 1.987e-03, MSE(pi2): 4.503e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 41700, Train loss: 1.099e+02, Test loss: 3.291e+02, MSE(e): 4.645e-06, MSE(pi1): 1.985e-03, MSE(pi2): 4.487e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 41800, Train loss: 1.098e+02, Test loss: 3.286e+02, MSE(e): 4.632e-06, MSE(pi1): 1.984e-03, MSE(pi2): 4.471e-06, MSE(pi3): 4.359e-04\n",
      "Epoch 41900, Train loss: 1.096e+02, Test loss: 3.282e+02, MSE(e): 4.620e-06, MSE(pi1): 1.983e-03, MSE(pi2): 4.454e-06, MSE(pi3): 4.360e-04\n",
      "Epoch 42000, Train loss: 1.095e+02, Test loss: 3.276e+02, MSE(e): 4.605e-06, MSE(pi1): 1.982e-03, MSE(pi2): 4.436e-06, MSE(pi3): 4.360e-04\n",
      "Epoch 42100, Train loss: 1.094e+02, Test loss: 3.271e+02, MSE(e): 4.594e-06, MSE(pi1): 1.981e-03, MSE(pi2): 4.421e-06, MSE(pi3): 4.360e-04\n",
      "Epoch 42200, Train loss: 1.092e+02, Test loss: 3.266e+02, MSE(e): 4.581e-06, MSE(pi1): 1.980e-03, MSE(pi2): 4.403e-06, MSE(pi3): 4.360e-04\n",
      "Epoch 42300, Train loss: 1.091e+02, Test loss: 3.261e+02, MSE(e): 4.568e-06, MSE(pi1): 1.979e-03, MSE(pi2): 4.387e-06, MSE(pi3): 4.360e-04\n",
      "Epoch 42400, Train loss: 1.089e+02, Test loss: 3.256e+02, MSE(e): 4.556e-06, MSE(pi1): 1.978e-03, MSE(pi2): 4.371e-06, MSE(pi3): 4.360e-04\n",
      "Epoch 42500, Train loss: 1.088e+02, Test loss: 3.253e+02, MSE(e): 4.543e-06, MSE(pi1): 1.976e-03, MSE(pi2): 4.355e-06, MSE(pi3): 4.360e-04\n",
      "Epoch 42600, Train loss: 1.087e+02, Test loss: 3.249e+02, MSE(e): 4.531e-06, MSE(pi1): 1.975e-03, MSE(pi2): 4.338e-06, MSE(pi3): 4.360e-04\n",
      "Epoch 42700, Train loss: 1.085e+02, Test loss: 3.245e+02, MSE(e): 4.517e-06, MSE(pi1): 1.974e-03, MSE(pi2): 4.322e-06, MSE(pi3): 4.361e-04\n",
      "Epoch 42800, Train loss: 1.084e+02, Test loss: 3.241e+02, MSE(e): 4.506e-06, MSE(pi1): 1.973e-03, MSE(pi2): 4.306e-06, MSE(pi3): 4.361e-04\n",
      "Epoch 42900, Train loss: 1.083e+02, Test loss: 3.237e+02, MSE(e): 4.493e-06, MSE(pi1): 1.972e-03, MSE(pi2): 4.290e-06, MSE(pi3): 4.361e-04\n",
      "Epoch 43000, Train loss: 1.081e+02, Test loss: 3.232e+02, MSE(e): 4.480e-06, MSE(pi1): 1.971e-03, MSE(pi2): 4.274e-06, MSE(pi3): 4.361e-04\n",
      "Epoch 43100, Train loss: 1.080e+02, Test loss: 3.227e+02, MSE(e): 4.468e-06, MSE(pi1): 1.970e-03, MSE(pi2): 4.258e-06, MSE(pi3): 4.361e-04\n",
      "Epoch 43200, Train loss: 1.079e+02, Test loss: 3.222e+02, MSE(e): 4.455e-06, MSE(pi1): 1.969e-03, MSE(pi2): 4.242e-06, MSE(pi3): 4.361e-04\n",
      "Epoch 43300, Train loss: 1.077e+02, Test loss: 3.216e+02, MSE(e): 4.443e-06, MSE(pi1): 1.968e-03, MSE(pi2): 4.226e-06, MSE(pi3): 4.361e-04\n",
      "Epoch 43400, Train loss: 1.076e+02, Test loss: 3.213e+02, MSE(e): 4.430e-06, MSE(pi1): 1.967e-03, MSE(pi2): 4.210e-06, MSE(pi3): 4.362e-04\n",
      "Epoch 43500, Train loss: 1.075e+02, Test loss: 3.208e+02, MSE(e): 4.418e-06, MSE(pi1): 1.966e-03, MSE(pi2): 4.195e-06, MSE(pi3): 4.362e-04\n",
      "Epoch 43600, Train loss: 1.073e+02, Test loss: 3.204e+02, MSE(e): 4.406e-06, MSE(pi1): 1.965e-03, MSE(pi2): 4.180e-06, MSE(pi3): 4.362e-04\n",
      "Epoch 43700, Train loss: 1.072e+02, Test loss: 3.200e+02, MSE(e): 4.395e-06, MSE(pi1): 1.964e-03, MSE(pi2): 4.165e-06, MSE(pi3): 4.362e-04\n",
      "Epoch 43800, Train loss: 1.071e+02, Test loss: 3.196e+02, MSE(e): 4.383e-06, MSE(pi1): 1.962e-03, MSE(pi2): 4.150e-06, MSE(pi3): 4.362e-04\n",
      "Epoch 43900, Train loss: 1.069e+02, Test loss: 3.191e+02, MSE(e): 4.371e-06, MSE(pi1): 1.961e-03, MSE(pi2): 4.134e-06, MSE(pi3): 4.362e-04\n",
      "Epoch 44000, Train loss: 1.068e+02, Test loss: 3.186e+02, MSE(e): 4.359e-06, MSE(pi1): 1.960e-03, MSE(pi2): 4.120e-06, MSE(pi3): 4.362e-04\n",
      "Epoch 44100, Train loss: 1.067e+02, Test loss: 3.181e+02, MSE(e): 4.348e-06, MSE(pi1): 1.959e-03, MSE(pi2): 4.105e-06, MSE(pi3): 4.363e-04\n",
      "Epoch 44200, Train loss: 1.066e+02, Test loss: 3.176e+02, MSE(e): 4.335e-06, MSE(pi1): 1.958e-03, MSE(pi2): 4.090e-06, MSE(pi3): 4.363e-04\n",
      "Epoch 44300, Train loss: 1.064e+02, Test loss: 3.171e+02, MSE(e): 4.324e-06, MSE(pi1): 1.957e-03, MSE(pi2): 4.075e-06, MSE(pi3): 4.363e-04\n",
      "Epoch 44400, Train loss: 1.063e+02, Test loss: 3.166e+02, MSE(e): 4.311e-06, MSE(pi1): 1.956e-03, MSE(pi2): 4.060e-06, MSE(pi3): 4.363e-04\n",
      "Epoch 44500, Train loss: 1.062e+02, Test loss: 3.162e+02, MSE(e): 4.301e-06, MSE(pi1): 1.955e-03, MSE(pi2): 4.046e-06, MSE(pi3): 4.363e-04\n",
      "Epoch 44600, Train loss: 1.061e+02, Test loss: 3.158e+02, MSE(e): 4.289e-06, MSE(pi1): 1.954e-03, MSE(pi2): 4.032e-06, MSE(pi3): 4.363e-04\n",
      "Epoch 44700, Train loss: 1.059e+02, Test loss: 3.153e+02, MSE(e): 4.278e-06, MSE(pi1): 1.953e-03, MSE(pi2): 4.018e-06, MSE(pi3): 4.364e-04\n",
      "Epoch 44800, Train loss: 1.058e+02, Test loss: 3.149e+02, MSE(e): 4.266e-06, MSE(pi1): 1.952e-03, MSE(pi2): 4.003e-06, MSE(pi3): 4.364e-04\n",
      "Epoch 44900, Train loss: 1.057e+02, Test loss: 3.144e+02, MSE(e): 4.255e-06, MSE(pi1): 1.951e-03, MSE(pi2): 3.989e-06, MSE(pi3): 4.364e-04\n",
      "Epoch 45000, Train loss: 1.056e+02, Test loss: 3.140e+02, MSE(e): 4.244e-06, MSE(pi1): 1.950e-03, MSE(pi2): 3.975e-06, MSE(pi3): 4.364e-04\n",
      "Epoch 45100, Train loss: 1.055e+02, Test loss: 3.135e+02, MSE(e): 4.232e-06, MSE(pi1): 1.949e-03, MSE(pi2): 3.961e-06, MSE(pi3): 4.364e-04\n",
      "Epoch 45200, Train loss: 1.053e+02, Test loss: 3.131e+02, MSE(e): 4.221e-06, MSE(pi1): 1.948e-03, MSE(pi2): 3.947e-06, MSE(pi3): 4.364e-04\n",
      "Epoch 45300, Train loss: 1.052e+02, Test loss: 3.126e+02, MSE(e): 4.208e-06, MSE(pi1): 1.947e-03, MSE(pi2): 3.933e-06, MSE(pi3): 4.364e-04\n",
      "Epoch 45400, Train loss: 1.051e+02, Test loss: 3.121e+02, MSE(e): 4.197e-06, MSE(pi1): 1.946e-03, MSE(pi2): 3.919e-06, MSE(pi3): 4.365e-04\n",
      "Epoch 45500, Train loss: 1.050e+02, Test loss: 3.118e+02, MSE(e): 4.186e-06, MSE(pi1): 1.945e-03, MSE(pi2): 3.906e-06, MSE(pi3): 4.365e-04\n",
      "Epoch 45600, Train loss: 1.049e+02, Test loss: 3.114e+02, MSE(e): 4.176e-06, MSE(pi1): 1.944e-03, MSE(pi2): 3.892e-06, MSE(pi3): 4.365e-04\n",
      "Epoch 45700, Train loss: 1.047e+02, Test loss: 3.110e+02, MSE(e): 4.166e-06, MSE(pi1): 1.943e-03, MSE(pi2): 3.879e-06, MSE(pi3): 4.365e-04\n",
      "Epoch 45800, Train loss: 1.046e+02, Test loss: 3.106e+02, MSE(e): 4.154e-06, MSE(pi1): 1.942e-03, MSE(pi2): 3.865e-06, MSE(pi3): 4.365e-04\n",
      "Epoch 45900, Train loss: 1.045e+02, Test loss: 3.102e+02, MSE(e): 4.142e-06, MSE(pi1): 1.941e-03, MSE(pi2): 3.852e-06, MSE(pi3): 4.366e-04\n",
      "Epoch 46000, Train loss: 1.044e+02, Test loss: 3.098e+02, MSE(e): 4.131e-06, MSE(pi1): 1.940e-03, MSE(pi2): 3.838e-06, MSE(pi3): 4.366e-04\n",
      "Epoch 46100, Train loss: 1.042e+02, Test loss: 3.094e+02, MSE(e): 4.119e-06, MSE(pi1): 1.939e-03, MSE(pi2): 3.824e-06, MSE(pi3): 4.366e-04\n",
      "Epoch 46200, Train loss: 1.041e+02, Test loss: 3.090e+02, MSE(e): 4.108e-06, MSE(pi1): 1.938e-03, MSE(pi2): 3.811e-06, MSE(pi3): 4.366e-04\n",
      "Epoch 46300, Train loss: 1.040e+02, Test loss: 3.086e+02, MSE(e): 4.097e-06, MSE(pi1): 1.937e-03, MSE(pi2): 3.797e-06, MSE(pi3): 4.366e-04\n",
      "Epoch 46400, Train loss: 1.039e+02, Test loss: 3.081e+02, MSE(e): 4.086e-06, MSE(pi1): 1.936e-03, MSE(pi2): 3.784e-06, MSE(pi3): 4.366e-04\n",
      "Epoch 46500, Train loss: 1.038e+02, Test loss: 3.077e+02, MSE(e): 4.076e-06, MSE(pi1): 1.935e-03, MSE(pi2): 3.771e-06, MSE(pi3): 4.367e-04\n",
      "Epoch 46600, Train loss: 1.037e+02, Test loss: 3.073e+02, MSE(e): 4.065e-06, MSE(pi1): 1.934e-03, MSE(pi2): 3.758e-06, MSE(pi3): 4.367e-04\n",
      "Epoch 46700, Train loss: 1.035e+02, Test loss: 3.069e+02, MSE(e): 4.054e-06, MSE(pi1): 1.933e-03, MSE(pi2): 3.745e-06, MSE(pi3): 4.367e-04\n",
      "Epoch 46800, Train loss: 1.034e+02, Test loss: 3.066e+02, MSE(e): 4.043e-06, MSE(pi1): 1.932e-03, MSE(pi2): 3.732e-06, MSE(pi3): 4.367e-04\n",
      "Epoch 46900, Train loss: 1.033e+02, Test loss: 3.062e+02, MSE(e): 4.032e-06, MSE(pi1): 1.931e-03, MSE(pi2): 3.719e-06, MSE(pi3): 4.367e-04\n",
      "Epoch 47000, Train loss: 1.032e+02, Test loss: 3.058e+02, MSE(e): 4.022e-06, MSE(pi1): 1.930e-03, MSE(pi2): 3.706e-06, MSE(pi3): 4.368e-04\n",
      "Epoch 47100, Train loss: 1.031e+02, Test loss: 3.054e+02, MSE(e): 4.011e-06, MSE(pi1): 1.929e-03, MSE(pi2): 3.693e-06, MSE(pi3): 4.368e-04\n",
      "Epoch 47200, Train loss: 1.030e+02, Test loss: 3.050e+02, MSE(e): 4.000e-06, MSE(pi1): 1.928e-03, MSE(pi2): 3.681e-06, MSE(pi3): 4.368e-04\n",
      "Epoch 47300, Train loss: 1.029e+02, Test loss: 3.046e+02, MSE(e): 3.989e-06, MSE(pi1): 1.927e-03, MSE(pi2): 3.668e-06, MSE(pi3): 4.368e-04\n",
      "Epoch 47400, Train loss: 1.027e+02, Test loss: 3.042e+02, MSE(e): 3.979e-06, MSE(pi1): 1.927e-03, MSE(pi2): 3.656e-06, MSE(pi3): 4.369e-04\n",
      "Epoch 47500, Train loss: 1.026e+02, Test loss: 3.039e+02, MSE(e): 3.969e-06, MSE(pi1): 1.926e-03, MSE(pi2): 3.643e-06, MSE(pi3): 4.369e-04\n",
      "Epoch 47600, Train loss: 1.025e+02, Test loss: 3.034e+02, MSE(e): 3.958e-06, MSE(pi1): 1.925e-03, MSE(pi2): 3.631e-06, MSE(pi3): 4.369e-04\n",
      "Epoch 47700, Train loss: 1.024e+02, Test loss: 3.031e+02, MSE(e): 3.948e-06, MSE(pi1): 1.924e-03, MSE(pi2): 3.618e-06, MSE(pi3): 4.369e-04\n",
      "Epoch 47800, Train loss: 1.023e+02, Test loss: 3.028e+02, MSE(e): 3.937e-06, MSE(pi1): 1.923e-03, MSE(pi2): 3.606e-06, MSE(pi3): 4.369e-04\n",
      "Epoch 47900, Train loss: 1.022e+02, Test loss: 3.025e+02, MSE(e): 3.927e-06, MSE(pi1): 1.922e-03, MSE(pi2): 3.593e-06, MSE(pi3): 4.370e-04\n",
      "Epoch 48000, Train loss: 1.021e+02, Test loss: 3.021e+02, MSE(e): 3.916e-06, MSE(pi1): 1.921e-03, MSE(pi2): 3.581e-06, MSE(pi3): 4.370e-04\n",
      "Epoch 48100, Train loss: 1.020e+02, Test loss: 3.018e+02, MSE(e): 3.906e-06, MSE(pi1): 1.920e-03, MSE(pi2): 3.569e-06, MSE(pi3): 4.370e-04\n",
      "Epoch 48200, Train loss: 1.019e+02, Test loss: 3.015e+02, MSE(e): 3.896e-06, MSE(pi1): 1.919e-03, MSE(pi2): 3.557e-06, MSE(pi3): 4.370e-04\n",
      "Epoch 48300, Train loss: 1.017e+02, Test loss: 3.011e+02, MSE(e): 3.886e-06, MSE(pi1): 1.918e-03, MSE(pi2): 3.545e-06, MSE(pi3): 4.370e-04\n",
      "Epoch 48400, Train loss: 1.016e+02, Test loss: 3.008e+02, MSE(e): 3.876e-06, MSE(pi1): 1.917e-03, MSE(pi2): 3.533e-06, MSE(pi3): 4.371e-04\n",
      "Epoch 48500, Train loss: 1.015e+02, Test loss: 3.005e+02, MSE(e): 3.866e-06, MSE(pi1): 1.916e-03, MSE(pi2): 3.521e-06, MSE(pi3): 4.371e-04\n",
      "Epoch 48600, Train loss: 1.014e+02, Test loss: 3.001e+02, MSE(e): 3.856e-06, MSE(pi1): 1.915e-03, MSE(pi2): 3.509e-06, MSE(pi3): 4.371e-04\n",
      "Epoch 48700, Train loss: 1.013e+02, Test loss: 2.998e+02, MSE(e): 3.847e-06, MSE(pi1): 1.914e-03, MSE(pi2): 3.497e-06, MSE(pi3): 4.371e-04\n",
      "Epoch 48800, Train loss: 1.012e+02, Test loss: 2.994e+02, MSE(e): 3.837e-06, MSE(pi1): 1.914e-03, MSE(pi2): 3.485e-06, MSE(pi3): 4.371e-04\n",
      "Epoch 48900, Train loss: 1.011e+02, Test loss: 2.990e+02, MSE(e): 3.826e-06, MSE(pi1): 1.913e-03, MSE(pi2): 3.474e-06, MSE(pi3): 4.371e-04\n",
      "Epoch 49000, Train loss: 1.010e+02, Test loss: 2.987e+02, MSE(e): 3.817e-06, MSE(pi1): 1.912e-03, MSE(pi2): 3.464e-06, MSE(pi3): 4.372e-04\n",
      "Epoch 49100, Train loss: 1.009e+02, Test loss: 2.984e+02, MSE(e): 3.807e-06, MSE(pi1): 1.911e-03, MSE(pi2): 3.452e-06, MSE(pi3): 4.372e-04\n",
      "Epoch 49200, Train loss: 1.008e+02, Test loss: 2.981e+02, MSE(e): 3.797e-06, MSE(pi1): 1.910e-03, MSE(pi2): 3.440e-06, MSE(pi3): 4.372e-04\n",
      "Epoch 49300, Train loss: 1.007e+02, Test loss: 2.978e+02, MSE(e): 3.786e-06, MSE(pi1): 1.909e-03, MSE(pi2): 3.428e-06, MSE(pi3): 4.373e-04\n",
      "Epoch 49400, Train loss: 1.006e+02, Test loss: 2.974e+02, MSE(e): 3.776e-06, MSE(pi1): 1.908e-03, MSE(pi2): 3.417e-06, MSE(pi3): 4.373e-04\n",
      "Epoch 49500, Train loss: 1.005e+02, Test loss: 2.970e+02, MSE(e): 3.767e-06, MSE(pi1): 1.907e-03, MSE(pi2): 3.405e-06, MSE(pi3): 4.373e-04\n",
      "Epoch 49600, Train loss: 1.004e+02, Test loss: 2.967e+02, MSE(e): 3.757e-06, MSE(pi1): 1.906e-03, MSE(pi2): 3.393e-06, MSE(pi3): 4.373e-04\n",
      "Epoch 49700, Train loss: 1.003e+02, Test loss: 2.964e+02, MSE(e): 3.747e-06, MSE(pi1): 1.905e-03, MSE(pi2): 3.383e-06, MSE(pi3): 4.374e-04\n",
      "Epoch 49800, Train loss: 1.002e+02, Test loss: 2.961e+02, MSE(e): 3.738e-06, MSE(pi1): 1.904e-03, MSE(pi2): 3.372e-06, MSE(pi3): 4.374e-04\n",
      "Epoch 49900, Train loss: 1.001e+02, Test loss: 2.957e+02, MSE(e): 3.728e-06, MSE(pi1): 1.903e-03, MSE(pi2): 3.360e-06, MSE(pi3): 4.374e-04\n",
      "Epoch 50000, Train loss: 9.996e+01, Test loss: 2.954e+02, MSE(e): 3.719e-06, MSE(pi1): 1.902e-03, MSE(pi2): 3.349e-06, MSE(pi3): 4.374e-04\n",
      "Epoch 50100, Train loss: 9.985e+01, Test loss: 2.951e+02, MSE(e): 3.709e-06, MSE(pi1): 1.902e-03, MSE(pi2): 3.338e-06, MSE(pi3): 4.374e-04\n",
      "Epoch 50200, Train loss: 9.976e+01, Test loss: 2.948e+02, MSE(e): 3.701e-06, MSE(pi1): 1.901e-03, MSE(pi2): 3.328e-06, MSE(pi3): 4.375e-04\n",
      "Epoch 50300, Train loss: 9.966e+01, Test loss: 2.944e+02, MSE(e): 3.691e-06, MSE(pi1): 1.900e-03, MSE(pi2): 3.317e-06, MSE(pi3): 4.375e-04\n",
      "Epoch 50400, Train loss: 9.956e+01, Test loss: 2.940e+02, MSE(e): 3.681e-06, MSE(pi1): 1.899e-03, MSE(pi2): 3.306e-06, MSE(pi3): 4.375e-04\n",
      "Epoch 50500, Train loss: 9.946e+01, Test loss: 2.936e+02, MSE(e): 3.672e-06, MSE(pi1): 1.898e-03, MSE(pi2): 3.296e-06, MSE(pi3): 4.375e-04\n",
      "Epoch 50600, Train loss: 9.937e+01, Test loss: 2.933e+02, MSE(e): 3.664e-06, MSE(pi1): 1.897e-03, MSE(pi2): 3.285e-06, MSE(pi3): 4.376e-04\n",
      "Epoch 50700, Train loss: 9.927e+01, Test loss: 2.930e+02, MSE(e): 3.655e-06, MSE(pi1): 1.896e-03, MSE(pi2): 3.275e-06, MSE(pi3): 4.376e-04\n",
      "Epoch 50800, Train loss: 9.917e+01, Test loss: 2.926e+02, MSE(e): 3.645e-06, MSE(pi1): 1.896e-03, MSE(pi2): 3.264e-06, MSE(pi3): 4.376e-04\n",
      "Epoch 50900, Train loss: 9.907e+01, Test loss: 2.923e+02, MSE(e): 3.636e-06, MSE(pi1): 1.894e-03, MSE(pi2): 3.253e-06, MSE(pi3): 4.376e-04\n",
      "Epoch 51000, Train loss: 9.897e+01, Test loss: 2.920e+02, MSE(e): 3.626e-06, MSE(pi1): 1.894e-03, MSE(pi2): 3.242e-06, MSE(pi3): 4.377e-04\n",
      "Epoch 51100, Train loss: 9.888e+01, Test loss: 2.916e+02, MSE(e): 3.618e-06, MSE(pi1): 1.893e-03, MSE(pi2): 3.232e-06, MSE(pi3): 4.377e-04\n",
      "Epoch 51200, Train loss: 9.877e+01, Test loss: 2.913e+02, MSE(e): 3.608e-06, MSE(pi1): 1.892e-03, MSE(pi2): 3.221e-06, MSE(pi3): 4.377e-04\n",
      "Epoch 51300, Train loss: 9.867e+01, Test loss: 2.909e+02, MSE(e): 3.598e-06, MSE(pi1): 1.891e-03, MSE(pi2): 3.210e-06, MSE(pi3): 4.377e-04\n",
      "Epoch 51400, Train loss: 9.858e+01, Test loss: 2.906e+02, MSE(e): 3.590e-06, MSE(pi1): 1.890e-03, MSE(pi2): 3.200e-06, MSE(pi3): 4.378e-04\n",
      "Epoch 51500, Train loss: 9.848e+01, Test loss: 2.903e+02, MSE(e): 3.581e-06, MSE(pi1): 1.890e-03, MSE(pi2): 3.189e-06, MSE(pi3): 4.378e-04\n",
      "Epoch 51600, Train loss: 9.838e+01, Test loss: 2.899e+02, MSE(e): 3.571e-06, MSE(pi1): 1.888e-03, MSE(pi2): 3.179e-06, MSE(pi3): 4.378e-04\n",
      "Epoch 51700, Train loss: 9.829e+01, Test loss: 2.896e+02, MSE(e): 3.563e-06, MSE(pi1): 1.888e-03, MSE(pi2): 3.169e-06, MSE(pi3): 4.378e-04\n",
      "Epoch 51800, Train loss: 9.820e+01, Test loss: 2.893e+02, MSE(e): 3.554e-06, MSE(pi1): 1.887e-03, MSE(pi2): 3.159e-06, MSE(pi3): 4.379e-04\n",
      "Epoch 51900, Train loss: 9.810e+01, Test loss: 2.889e+02, MSE(e): 3.545e-06, MSE(pi1): 1.886e-03, MSE(pi2): 3.149e-06, MSE(pi3): 4.379e-04\n",
      "Epoch 52000, Train loss: 9.801e+01, Test loss: 2.885e+02, MSE(e): 3.537e-06, MSE(pi1): 1.885e-03, MSE(pi2): 3.140e-06, MSE(pi3): 4.379e-04\n",
      "Epoch 52100, Train loss: 9.793e+01, Test loss: 2.882e+02, MSE(e): 3.529e-06, MSE(pi1): 1.884e-03, MSE(pi2): 3.130e-06, MSE(pi3): 4.379e-04\n",
      "Epoch 52200, Train loss: 9.784e+01, Test loss: 2.879e+02, MSE(e): 3.521e-06, MSE(pi1): 1.884e-03, MSE(pi2): 3.121e-06, MSE(pi3): 4.380e-04\n",
      "Epoch 52300, Train loss: 9.775e+01, Test loss: 2.875e+02, MSE(e): 3.512e-06, MSE(pi1): 1.883e-03, MSE(pi2): 3.111e-06, MSE(pi3): 4.380e-04\n",
      "Epoch 52400, Train loss: 9.766e+01, Test loss: 2.872e+02, MSE(e): 3.503e-06, MSE(pi1): 1.882e-03, MSE(pi2): 3.101e-06, MSE(pi3): 4.380e-04\n",
      "Epoch 52500, Train loss: 9.756e+01, Test loss: 2.868e+02, MSE(e): 3.494e-06, MSE(pi1): 1.881e-03, MSE(pi2): 3.091e-06, MSE(pi3): 4.380e-04\n",
      "Epoch 52600, Train loss: 9.747e+01, Test loss: 2.864e+02, MSE(e): 3.485e-06, MSE(pi1): 1.880e-03, MSE(pi2): 3.081e-06, MSE(pi3): 4.381e-04\n",
      "Epoch 52700, Train loss: 9.738e+01, Test loss: 2.861e+02, MSE(e): 3.477e-06, MSE(pi1): 1.880e-03, MSE(pi2): 3.071e-06, MSE(pi3): 4.381e-04\n",
      "Epoch 52800, Train loss: 9.729e+01, Test loss: 2.857e+02, MSE(e): 3.469e-06, MSE(pi1): 1.879e-03, MSE(pi2): 3.062e-06, MSE(pi3): 4.381e-04\n",
      "Epoch 52900, Train loss: 9.718e+01, Test loss: 2.853e+02, MSE(e): 3.459e-06, MSE(pi1): 1.878e-03, MSE(pi2): 3.052e-06, MSE(pi3): 4.381e-04\n",
      "Epoch 53000, Train loss: 9.711e+01, Test loss: 2.850e+02, MSE(e): 3.452e-06, MSE(pi1): 1.877e-03, MSE(pi2): 3.043e-06, MSE(pi3): 4.382e-04\n",
      "Epoch 53100, Train loss: 9.701e+01, Test loss: 2.846e+02, MSE(e): 3.442e-06, MSE(pi1): 1.876e-03, MSE(pi2): 3.032e-06, MSE(pi3): 4.382e-04\n",
      "Epoch 53200, Train loss: 9.692e+01, Test loss: 2.843e+02, MSE(e): 3.434e-06, MSE(pi1): 1.875e-03, MSE(pi2): 3.023e-06, MSE(pi3): 4.382e-04\n",
      "Epoch 53300, Train loss: 9.684e+01, Test loss: 2.840e+02, MSE(e): 3.426e-06, MSE(pi1): 1.875e-03, MSE(pi2): 3.014e-06, MSE(pi3): 4.382e-04\n",
      "Epoch 53400, Train loss: 9.674e+01, Test loss: 2.836e+02, MSE(e): 3.418e-06, MSE(pi1): 1.874e-03, MSE(pi2): 3.004e-06, MSE(pi3): 4.383e-04\n",
      "Epoch 53500, Train loss: 9.666e+01, Test loss: 2.833e+02, MSE(e): 3.410e-06, MSE(pi1): 1.873e-03, MSE(pi2): 2.995e-06, MSE(pi3): 4.383e-04\n",
      "Epoch 53600, Train loss: 9.657e+01, Test loss: 2.828e+02, MSE(e): 3.401e-06, MSE(pi1): 1.872e-03, MSE(pi2): 2.985e-06, MSE(pi3): 4.383e-04\n",
      "Epoch 53700, Train loss: 9.648e+01, Test loss: 2.825e+02, MSE(e): 3.393e-06, MSE(pi1): 1.872e-03, MSE(pi2): 2.976e-06, MSE(pi3): 4.383e-04\n",
      "Epoch 53800, Train loss: 9.640e+01, Test loss: 2.821e+02, MSE(e): 3.385e-06, MSE(pi1): 1.871e-03, MSE(pi2): 2.967e-06, MSE(pi3): 4.384e-04\n",
      "Epoch 53900, Train loss: 9.631e+01, Test loss: 2.817e+02, MSE(e): 3.377e-06, MSE(pi1): 1.870e-03, MSE(pi2): 2.959e-06, MSE(pi3): 4.384e-04\n",
      "Epoch 54000, Train loss: 9.624e+01, Test loss: 2.813e+02, MSE(e): 3.370e-06, MSE(pi1): 1.869e-03, MSE(pi2): 2.950e-06, MSE(pi3): 4.384e-04\n",
      "Epoch 54100, Train loss: 9.614e+01, Test loss: 2.809e+02, MSE(e): 3.361e-06, MSE(pi1): 1.868e-03, MSE(pi2): 2.941e-06, MSE(pi3): 4.384e-04\n",
      "Epoch 54200, Train loss: 9.606e+01, Test loss: 2.805e+02, MSE(e): 3.354e-06, MSE(pi1): 1.868e-03, MSE(pi2): 2.932e-06, MSE(pi3): 4.385e-04\n",
      "Epoch 54300, Train loss: 9.598e+01, Test loss: 2.801e+02, MSE(e): 3.346e-06, MSE(pi1): 1.867e-03, MSE(pi2): 2.924e-06, MSE(pi3): 4.385e-04\n",
      "Epoch 54400, Train loss: 9.589e+01, Test loss: 2.797e+02, MSE(e): 3.337e-06, MSE(pi1): 1.866e-03, MSE(pi2): 2.914e-06, MSE(pi3): 4.385e-04\n",
      "Epoch 54500, Train loss: 9.581e+01, Test loss: 2.793e+02, MSE(e): 3.330e-06, MSE(pi1): 1.865e-03, MSE(pi2): 2.906e-06, MSE(pi3): 4.386e-04\n",
      "Epoch 54600, Train loss: 9.572e+01, Test loss: 2.788e+02, MSE(e): 3.322e-06, MSE(pi1): 1.864e-03, MSE(pi2): 2.897e-06, MSE(pi3): 4.386e-04\n",
      "Epoch 54700, Train loss: 9.564e+01, Test loss: 2.784e+02, MSE(e): 3.314e-06, MSE(pi1): 1.863e-03, MSE(pi2): 2.888e-06, MSE(pi3): 4.386e-04\n",
      "Epoch 54800, Train loss: 9.556e+01, Test loss: 2.779e+02, MSE(e): 3.307e-06, MSE(pi1): 1.863e-03, MSE(pi2): 2.879e-06, MSE(pi3): 4.386e-04\n",
      "Epoch 54900, Train loss: 9.547e+01, Test loss: 2.774e+02, MSE(e): 3.298e-06, MSE(pi1): 1.862e-03, MSE(pi2): 2.870e-06, MSE(pi3): 4.387e-04\n",
      "Epoch 55000, Train loss: 9.539e+01, Test loss: 2.770e+02, MSE(e): 3.290e-06, MSE(pi1): 1.861e-03, MSE(pi2): 2.861e-06, MSE(pi3): 4.387e-04\n",
      "Epoch 55100, Train loss: 9.530e+01, Test loss: 2.766e+02, MSE(e): 3.282e-06, MSE(pi1): 1.860e-03, MSE(pi2): 2.852e-06, MSE(pi3): 4.387e-04\n",
      "Epoch 55200, Train loss: 9.522e+01, Test loss: 2.762e+02, MSE(e): 3.275e-06, MSE(pi1): 1.859e-03, MSE(pi2): 2.843e-06, MSE(pi3): 4.388e-04\n",
      "Epoch 55300, Train loss: 9.513e+01, Test loss: 2.757e+02, MSE(e): 3.266e-06, MSE(pi1): 1.859e-03, MSE(pi2): 2.834e-06, MSE(pi3): 4.388e-04\n",
      "Epoch 55400, Train loss: 9.505e+01, Test loss: 2.752e+02, MSE(e): 3.258e-06, MSE(pi1): 1.858e-03, MSE(pi2): 2.826e-06, MSE(pi3): 4.388e-04\n",
      "Epoch 55500, Train loss: 9.497e+01, Test loss: 2.748e+02, MSE(e): 3.251e-06, MSE(pi1): 1.857e-03, MSE(pi2): 2.817e-06, MSE(pi3): 4.388e-04\n",
      "Epoch 55600, Train loss: 9.488e+01, Test loss: 2.743e+02, MSE(e): 3.243e-06, MSE(pi1): 1.856e-03, MSE(pi2): 2.808e-06, MSE(pi3): 4.389e-04\n",
      "Epoch 55700, Train loss: 9.479e+01, Test loss: 2.738e+02, MSE(e): 3.234e-06, MSE(pi1): 1.855e-03, MSE(pi2): 2.799e-06, MSE(pi3): 4.389e-04\n",
      "Epoch 55800, Train loss: 9.471e+01, Test loss: 2.733e+02, MSE(e): 3.227e-06, MSE(pi1): 1.855e-03, MSE(pi2): 2.791e-06, MSE(pi3): 4.389e-04\n",
      "Epoch 55900, Train loss: 9.463e+01, Test loss: 2.728e+02, MSE(e): 3.219e-06, MSE(pi1): 1.854e-03, MSE(pi2): 2.783e-06, MSE(pi3): 4.390e-04\n",
      "Epoch 56000, Train loss: 9.455e+01, Test loss: 2.723e+02, MSE(e): 3.212e-06, MSE(pi1): 1.853e-03, MSE(pi2): 2.775e-06, MSE(pi3): 4.390e-04\n",
      "Epoch 56100, Train loss: 9.447e+01, Test loss: 2.718e+02, MSE(e): 3.204e-06, MSE(pi1): 1.852e-03, MSE(pi2): 2.767e-06, MSE(pi3): 4.390e-04\n",
      "Epoch 56200, Train loss: 9.440e+01, Test loss: 2.714e+02, MSE(e): 3.197e-06, MSE(pi1): 1.852e-03, MSE(pi2): 2.759e-06, MSE(pi3): 4.391e-04\n",
      "Epoch 56300, Train loss: 9.432e+01, Test loss: 2.709e+02, MSE(e): 3.190e-06, MSE(pi1): 1.851e-03, MSE(pi2): 2.750e-06, MSE(pi3): 4.391e-04\n",
      "Epoch 56400, Train loss: 9.423e+01, Test loss: 2.703e+02, MSE(e): 3.181e-06, MSE(pi1): 1.850e-03, MSE(pi2): 2.741e-06, MSE(pi3): 4.391e-04\n",
      "Epoch 56500, Train loss: 9.415e+01, Test loss: 2.698e+02, MSE(e): 3.174e-06, MSE(pi1): 1.849e-03, MSE(pi2): 2.733e-06, MSE(pi3): 4.392e-04\n",
      "Epoch 56600, Train loss: 9.407e+01, Test loss: 2.693e+02, MSE(e): 3.166e-06, MSE(pi1): 1.848e-03, MSE(pi2): 2.725e-06, MSE(pi3): 4.392e-04\n",
      "Epoch 56700, Train loss: 9.398e+01, Test loss: 2.688e+02, MSE(e): 3.158e-06, MSE(pi1): 1.847e-03, MSE(pi2): 2.716e-06, MSE(pi3): 4.392e-04\n",
      "Epoch 56800, Train loss: 9.390e+01, Test loss: 2.683e+02, MSE(e): 3.150e-06, MSE(pi1): 1.846e-03, MSE(pi2): 2.707e-06, MSE(pi3): 4.393e-04\n",
      "Epoch 56900, Train loss: 9.382e+01, Test loss: 2.677e+02, MSE(e): 3.143e-06, MSE(pi1): 1.846e-03, MSE(pi2): 2.699e-06, MSE(pi3): 4.393e-04\n",
      "Epoch 57000, Train loss: 9.373e+01, Test loss: 2.672e+02, MSE(e): 3.134e-06, MSE(pi1): 1.845e-03, MSE(pi2): 2.690e-06, MSE(pi3): 4.394e-04\n",
      "Epoch 57100, Train loss: 9.364e+01, Test loss: 2.667e+02, MSE(e): 3.126e-06, MSE(pi1): 1.844e-03, MSE(pi2): 2.682e-06, MSE(pi3): 4.394e-04\n",
      "Epoch 57200, Train loss: 9.356e+01, Test loss: 2.661e+02, MSE(e): 3.119e-06, MSE(pi1): 1.843e-03, MSE(pi2): 2.674e-06, MSE(pi3): 4.394e-04\n",
      "Epoch 57300, Train loss: 9.348e+01, Test loss: 2.656e+02, MSE(e): 3.111e-06, MSE(pi1): 1.843e-03, MSE(pi2): 2.666e-06, MSE(pi3): 4.394e-04\n",
      "Epoch 57400, Train loss: 9.339e+01, Test loss: 2.650e+02, MSE(e): 3.102e-06, MSE(pi1): 1.842e-03, MSE(pi2): 2.657e-06, MSE(pi3): 4.395e-04\n",
      "Epoch 57500, Train loss: 9.330e+01, Test loss: 2.645e+02, MSE(e): 3.094e-06, MSE(pi1): 1.841e-03, MSE(pi2): 2.648e-06, MSE(pi3): 4.395e-04\n",
      "Epoch 57600, Train loss: 9.323e+01, Test loss: 2.640e+02, MSE(e): 3.088e-06, MSE(pi1): 1.840e-03, MSE(pi2): 2.640e-06, MSE(pi3): 4.395e-04\n",
      "Epoch 57700, Train loss: 9.313e+01, Test loss: 2.634e+02, MSE(e): 3.078e-06, MSE(pi1): 1.839e-03, MSE(pi2): 2.631e-06, MSE(pi3): 4.396e-04\n",
      "Epoch 57800, Train loss: 9.306e+01, Test loss: 2.629e+02, MSE(e): 3.071e-06, MSE(pi1): 1.838e-03, MSE(pi2): 2.623e-06, MSE(pi3): 4.396e-04\n",
      "Epoch 57900, Train loss: 9.297e+01, Test loss: 2.624e+02, MSE(e): 3.063e-06, MSE(pi1): 1.837e-03, MSE(pi2): 2.615e-06, MSE(pi3): 4.397e-04\n",
      "Epoch 58000, Train loss: 9.289e+01, Test loss: 2.618e+02, MSE(e): 3.055e-06, MSE(pi1): 1.837e-03, MSE(pi2): 2.607e-06, MSE(pi3): 4.397e-04\n",
      "Epoch 58100, Train loss: 9.282e+01, Test loss: 2.613e+02, MSE(e): 3.048e-06, MSE(pi1): 1.836e-03, MSE(pi2): 2.599e-06, MSE(pi3): 4.397e-04\n",
      "Epoch 58200, Train loss: 9.274e+01, Test loss: 2.608e+02, MSE(e): 3.041e-06, MSE(pi1): 1.835e-03, MSE(pi2): 2.592e-06, MSE(pi3): 4.397e-04\n",
      "Epoch 58300, Train loss: 9.265e+01, Test loss: 2.602e+02, MSE(e): 3.032e-06, MSE(pi1): 1.834e-03, MSE(pi2): 2.583e-06, MSE(pi3): 4.398e-04\n",
      "Epoch 58400, Train loss: 9.256e+01, Test loss: 2.597e+02, MSE(e): 3.024e-06, MSE(pi1): 1.834e-03, MSE(pi2): 2.575e-06, MSE(pi3): 4.398e-04\n",
      "Epoch 58500, Train loss: 9.246e+01, Test loss: 2.591e+02, MSE(e): 3.014e-06, MSE(pi1): 1.833e-03, MSE(pi2): 2.566e-06, MSE(pi3): 4.399e-04\n",
      "Epoch 58600, Train loss: 9.239e+01, Test loss: 2.586e+02, MSE(e): 3.008e-06, MSE(pi1): 1.832e-03, MSE(pi2): 2.559e-06, MSE(pi3): 4.399e-04\n",
      "Epoch 58700, Train loss: 9.233e+01, Test loss: 2.580e+02, MSE(e): 3.002e-06, MSE(pi1): 1.831e-03, MSE(pi2): 2.551e-06, MSE(pi3): 4.399e-04\n",
      "Epoch 58800, Train loss: 9.226e+01, Test loss: 2.575e+02, MSE(e): 2.995e-06, MSE(pi1): 1.831e-03, MSE(pi2): 2.544e-06, MSE(pi3): 4.400e-04\n",
      "Epoch 58900, Train loss: 9.208e+01, Test loss: 2.568e+02, MSE(e): 2.978e-06, MSE(pi1): 1.829e-03, MSE(pi2): 2.532e-06, MSE(pi3): 4.401e-04\n",
      "Epoch 59000, Train loss: 9.068e+01, Test loss: 2.545e+02, MSE(e): 2.838e-06, MSE(pi1): 1.824e-03, MSE(pi2): 2.463e-06, MSE(pi3): 4.406e-04\n",
      "Epoch 59100, Train loss: 9.057e+01, Test loss: 2.532e+02, MSE(e): 2.828e-06, MSE(pi1): 1.823e-03, MSE(pi2): 2.452e-06, MSE(pi3): 4.406e-04\n",
      "Epoch 59200, Train loss: 9.049e+01, Test loss: 2.523e+02, MSE(e): 2.819e-06, MSE(pi1): 1.822e-03, MSE(pi2): 2.443e-06, MSE(pi3): 4.407e-04\n",
      "Epoch 59300, Train loss: 9.040e+01, Test loss: 2.516e+02, MSE(e): 2.812e-06, MSE(pi1): 1.821e-03, MSE(pi2): 2.434e-06, MSE(pi3): 4.408e-04\n",
      "Epoch 59400, Train loss: 9.032e+01, Test loss: 2.510e+02, MSE(e): 2.804e-06, MSE(pi1): 1.820e-03, MSE(pi2): 2.426e-06, MSE(pi3): 4.408e-04\n",
      "Epoch 59500, Train loss: 9.024e+01, Test loss: 2.505e+02, MSE(e): 2.796e-06, MSE(pi1): 1.819e-03, MSE(pi2): 2.417e-06, MSE(pi3): 4.408e-04\n",
      "Epoch 59600, Train loss: 9.016e+01, Test loss: 2.500e+02, MSE(e): 2.788e-06, MSE(pi1): 1.818e-03, MSE(pi2): 2.409e-06, MSE(pi3): 4.409e-04\n",
      "Epoch 59700, Train loss: 9.008e+01, Test loss: 2.496e+02, MSE(e): 2.781e-06, MSE(pi1): 1.818e-03, MSE(pi2): 2.402e-06, MSE(pi3): 4.409e-04\n",
      "Epoch 59800, Train loss: 9.000e+01, Test loss: 2.492e+02, MSE(e): 2.774e-06, MSE(pi1): 1.817e-03, MSE(pi2): 2.394e-06, MSE(pi3): 4.409e-04\n",
      "Epoch 59900, Train loss: 8.993e+01, Test loss: 2.488e+02, MSE(e): 2.767e-06, MSE(pi1): 1.816e-03, MSE(pi2): 2.386e-06, MSE(pi3): 4.410e-04\n",
      "Epoch 60000, Train loss: 8.985e+01, Test loss: 2.484e+02, MSE(e): 2.760e-06, MSE(pi1): 1.816e-03, MSE(pi2): 2.379e-06, MSE(pi3): 4.410e-04\n",
      "Epoch 60100, Train loss: 8.978e+01, Test loss: 2.481e+02, MSE(e): 2.753e-06, MSE(pi1): 1.815e-03, MSE(pi2): 2.372e-06, MSE(pi3): 4.410e-04\n",
      "Epoch 60200, Train loss: 8.971e+01, Test loss: 2.477e+02, MSE(e): 2.746e-06, MSE(pi1): 1.814e-03, MSE(pi2): 2.364e-06, MSE(pi3): 4.410e-04\n",
      "Epoch 60300, Train loss: 8.963e+01, Test loss: 2.474e+02, MSE(e): 2.739e-06, MSE(pi1): 1.814e-03, MSE(pi2): 2.357e-06, MSE(pi3): 4.411e-04\n",
      "Epoch 60400, Train loss: 8.956e+01, Test loss: 2.470e+02, MSE(e): 2.732e-06, MSE(pi1): 1.813e-03, MSE(pi2): 2.350e-06, MSE(pi3): 4.411e-04\n",
      "Epoch 60500, Train loss: 8.949e+01, Test loss: 2.466e+02, MSE(e): 2.725e-06, MSE(pi1): 1.812e-03, MSE(pi2): 2.343e-06, MSE(pi3): 4.411e-04\n",
      "Epoch 60600, Train loss: 8.941e+01, Test loss: 2.463e+02, MSE(e): 2.718e-06, MSE(pi1): 1.812e-03, MSE(pi2): 2.335e-06, MSE(pi3): 4.412e-04\n",
      "Epoch 60700, Train loss: 8.934e+01, Test loss: 2.459e+02, MSE(e): 2.711e-06, MSE(pi1): 1.811e-03, MSE(pi2): 2.328e-06, MSE(pi3): 4.412e-04\n",
      "Epoch 60800, Train loss: 8.927e+01, Test loss: 2.455e+02, MSE(e): 2.705e-06, MSE(pi1): 1.810e-03, MSE(pi2): 2.321e-06, MSE(pi3): 4.412e-04\n",
      "Epoch 60900, Train loss: 8.920e+01, Test loss: 2.451e+02, MSE(e): 2.698e-06, MSE(pi1): 1.810e-03, MSE(pi2): 2.313e-06, MSE(pi3): 4.412e-04\n",
      "Epoch 61000, Train loss: 8.913e+01, Test loss: 2.447e+02, MSE(e): 2.691e-06, MSE(pi1): 1.809e-03, MSE(pi2): 2.306e-06, MSE(pi3): 4.413e-04\n",
      "Epoch 61100, Train loss: 8.906e+01, Test loss: 2.443e+02, MSE(e): 2.684e-06, MSE(pi1): 1.808e-03, MSE(pi2): 2.299e-06, MSE(pi3): 4.413e-04\n",
      "Epoch 61200, Train loss: 8.899e+01, Test loss: 2.439e+02, MSE(e): 2.677e-06, MSE(pi1): 1.808e-03, MSE(pi2): 2.292e-06, MSE(pi3): 4.413e-04\n",
      "Epoch 61300, Train loss: 8.892e+01, Test loss: 2.435e+02, MSE(e): 2.671e-06, MSE(pi1): 1.807e-03, MSE(pi2): 2.286e-06, MSE(pi3): 4.413e-04\n",
      "Epoch 61400, Train loss: 8.885e+01, Test loss: 2.431e+02, MSE(e): 2.665e-06, MSE(pi1): 1.807e-03, MSE(pi2): 2.279e-06, MSE(pi3): 4.414e-04\n",
      "Epoch 61500, Train loss: 8.878e+01, Test loss: 2.427e+02, MSE(e): 2.658e-06, MSE(pi1): 1.806e-03, MSE(pi2): 2.272e-06, MSE(pi3): 4.414e-04\n",
      "Epoch 61600, Train loss: 8.872e+01, Test loss: 2.423e+02, MSE(e): 2.652e-06, MSE(pi1): 1.805e-03, MSE(pi2): 2.265e-06, MSE(pi3): 4.414e-04\n",
      "Epoch 61700, Train loss: 8.865e+01, Test loss: 2.419e+02, MSE(e): 2.646e-06, MSE(pi1): 1.805e-03, MSE(pi2): 2.259e-06, MSE(pi3): 4.414e-04\n",
      "Epoch 61800, Train loss: 8.859e+01, Test loss: 2.415e+02, MSE(e): 2.640e-06, MSE(pi1): 1.804e-03, MSE(pi2): 2.253e-06, MSE(pi3): 4.415e-04\n",
      "Epoch 61900, Train loss: 8.852e+01, Test loss: 2.411e+02, MSE(e): 2.633e-06, MSE(pi1): 1.803e-03, MSE(pi2): 2.246e-06, MSE(pi3): 4.415e-04\n",
      "Epoch 62000, Train loss: 8.845e+01, Test loss: 2.407e+02, MSE(e): 2.627e-06, MSE(pi1): 1.803e-03, MSE(pi2): 2.239e-06, MSE(pi3): 4.415e-04\n",
      "Epoch 62100, Train loss: 8.839e+01, Test loss: 2.403e+02, MSE(e): 2.621e-06, MSE(pi1): 1.802e-03, MSE(pi2): 2.233e-06, MSE(pi3): 4.416e-04\n",
      "Epoch 62200, Train loss: 8.833e+01, Test loss: 2.398e+02, MSE(e): 2.615e-06, MSE(pi1): 1.802e-03, MSE(pi2): 2.227e-06, MSE(pi3): 4.416e-04\n",
      "Epoch 62300, Train loss: 8.826e+01, Test loss: 2.394e+02, MSE(e): 2.609e-06, MSE(pi1): 1.801e-03, MSE(pi2): 2.220e-06, MSE(pi3): 4.416e-04\n",
      "Epoch 62400, Train loss: 8.819e+01, Test loss: 2.390e+02, MSE(e): 2.602e-06, MSE(pi1): 1.800e-03, MSE(pi2): 2.213e-06, MSE(pi3): 4.416e-04\n",
      "Epoch 62500, Train loss: 8.813e+01, Test loss: 2.386e+02, MSE(e): 2.596e-06, MSE(pi1): 1.800e-03, MSE(pi2): 2.207e-06, MSE(pi3): 4.417e-04\n",
      "Epoch 62600, Train loss: 8.806e+01, Test loss: 2.381e+02, MSE(e): 2.590e-06, MSE(pi1): 1.799e-03, MSE(pi2): 2.200e-06, MSE(pi3): 4.417e-04\n",
      "Epoch 62700, Train loss: 8.800e+01, Test loss: 2.377e+02, MSE(e): 2.584e-06, MSE(pi1): 1.798e-03, MSE(pi2): 2.193e-06, MSE(pi3): 4.417e-04\n",
      "Epoch 62800, Train loss: 8.793e+01, Test loss: 2.373e+02, MSE(e): 2.578e-06, MSE(pi1): 1.798e-03, MSE(pi2): 2.187e-06, MSE(pi3): 4.418e-04\n",
      "Epoch 62900, Train loss: 8.787e+01, Test loss: 2.369e+02, MSE(e): 2.572e-06, MSE(pi1): 1.797e-03, MSE(pi2): 2.180e-06, MSE(pi3): 4.418e-04\n",
      "Epoch 63000, Train loss: 8.781e+01, Test loss: 2.365e+02, MSE(e): 2.566e-06, MSE(pi1): 1.796e-03, MSE(pi2): 2.174e-06, MSE(pi3): 4.418e-04\n",
      "Epoch 63100, Train loss: 8.775e+01, Test loss: 2.360e+02, MSE(e): 2.561e-06, MSE(pi1): 1.796e-03, MSE(pi2): 2.167e-06, MSE(pi3): 4.418e-04\n",
      "Epoch 63200, Train loss: 8.769e+01, Test loss: 2.356e+02, MSE(e): 2.555e-06, MSE(pi1): 1.795e-03, MSE(pi2): 2.160e-06, MSE(pi3): 4.419e-04\n",
      "Epoch 63300, Train loss: 8.765e+01, Test loss: 2.352e+02, MSE(e): 2.551e-06, MSE(pi1): 1.795e-03, MSE(pi2): 2.155e-06, MSE(pi3): 4.419e-04\n",
      "Epoch 63400, Train loss: 8.760e+01, Test loss: 2.347e+02, MSE(e): 2.546e-06, MSE(pi1): 1.794e-03, MSE(pi2): 2.149e-06, MSE(pi3): 4.419e-04\n",
      "Epoch 63500, Train loss: 8.755e+01, Test loss: 2.343e+02, MSE(e): 2.542e-06, MSE(pi1): 1.794e-03, MSE(pi2): 2.144e-06, MSE(pi3): 4.419e-04\n",
      "Epoch 63600, Train loss: 8.751e+01, Test loss: 2.339e+02, MSE(e): 2.538e-06, MSE(pi1): 1.793e-03, MSE(pi2): 2.138e-06, MSE(pi3): 4.420e-04\n",
      "Epoch 63700, Train loss: 8.745e+01, Test loss: 2.334e+02, MSE(e): 2.533e-06, MSE(pi1): 1.792e-03, MSE(pi2): 2.132e-06, MSE(pi3): 4.420e-04\n",
      "Epoch 63800, Train loss: 8.741e+01, Test loss: 2.330e+02, MSE(e): 2.529e-06, MSE(pi1): 1.792e-03, MSE(pi2): 2.126e-06, MSE(pi3): 4.420e-04\n",
      "Epoch 63900, Train loss: 8.735e+01, Test loss: 2.325e+02, MSE(e): 2.523e-06, MSE(pi1): 1.791e-03, MSE(pi2): 2.119e-06, MSE(pi3): 4.421e-04\n",
      "Epoch 64000, Train loss: 8.729e+01, Test loss: 2.321e+02, MSE(e): 2.518e-06, MSE(pi1): 1.790e-03, MSE(pi2): 2.113e-06, MSE(pi3): 4.421e-04\n",
      "Epoch 64100, Train loss: 8.723e+01, Test loss: 2.316e+02, MSE(e): 2.512e-06, MSE(pi1): 1.789e-03, MSE(pi2): 2.107e-06, MSE(pi3): 4.422e-04\n",
      "Epoch 64200, Train loss: 8.716e+01, Test loss: 2.312e+02, MSE(e): 2.506e-06, MSE(pi1): 1.789e-03, MSE(pi2): 2.100e-06, MSE(pi3): 4.422e-04\n",
      "Epoch 64300, Train loss: 8.711e+01, Test loss: 2.308e+02, MSE(e): 2.501e-06, MSE(pi1): 1.788e-03, MSE(pi2): 2.095e-06, MSE(pi3): 4.422e-04\n",
      "Epoch 64400, Train loss: 8.706e+01, Test loss: 2.303e+02, MSE(e): 2.495e-06, MSE(pi1): 1.788e-03, MSE(pi2): 2.089e-06, MSE(pi3): 4.423e-04\n",
      "Epoch 64500, Train loss: 8.700e+01, Test loss: 2.299e+02, MSE(e): 2.490e-06, MSE(pi1): 1.787e-03, MSE(pi2): 2.083e-06, MSE(pi3): 4.423e-04\n",
      "Epoch 64600, Train loss: 8.695e+01, Test loss: 2.295e+02, MSE(e): 2.485e-06, MSE(pi1): 1.786e-03, MSE(pi2): 2.078e-06, MSE(pi3): 4.423e-04\n",
      "Epoch 64700, Train loss: 8.689e+01, Test loss: 2.291e+02, MSE(e): 2.480e-06, MSE(pi1): 1.785e-03, MSE(pi2): 2.072e-06, MSE(pi3): 4.424e-04\n",
      "Epoch 64800, Train loss: 8.683e+01, Test loss: 2.286e+02, MSE(e): 2.474e-06, MSE(pi1): 1.785e-03, MSE(pi2): 2.066e-06, MSE(pi3): 4.424e-04\n",
      "Epoch 64900, Train loss: 8.677e+01, Test loss: 2.282e+02, MSE(e): 2.468e-06, MSE(pi1): 1.784e-03, MSE(pi2): 2.061e-06, MSE(pi3): 4.424e-04\n",
      "Epoch 65000, Train loss: 8.673e+01, Test loss: 2.279e+02, MSE(e): 2.464e-06, MSE(pi1): 1.783e-03, MSE(pi2): 2.056e-06, MSE(pi3): 4.425e-04\n",
      "Epoch 65100, Train loss: 8.662e+01, Test loss: 2.290e+02, MSE(e): 2.454e-06, MSE(pi1): 1.774e-03, MSE(pi2): 2.054e-06, MSE(pi3): 4.433e-04\n",
      "Epoch 65200, Train loss: 8.652e+01, Test loss: 2.286e+02, MSE(e): 2.445e-06, MSE(pi1): 1.772e-03, MSE(pi2): 2.047e-06, MSE(pi3): 4.435e-04\n",
      "Epoch 65300, Train loss: 8.647e+01, Test loss: 2.282e+02, MSE(e): 2.440e-06, MSE(pi1): 1.771e-03, MSE(pi2): 2.042e-06, MSE(pi3): 4.436e-04\n",
      "Epoch 65400, Train loss: 8.642e+01, Test loss: 2.278e+02, MSE(e): 2.436e-06, MSE(pi1): 1.770e-03, MSE(pi2): 2.038e-06, MSE(pi3): 4.436e-04\n",
      "Epoch 65500, Train loss: 8.638e+01, Test loss: 2.276e+02, MSE(e): 2.432e-06, MSE(pi1): 1.770e-03, MSE(pi2): 2.034e-06, MSE(pi3): 4.436e-04\n",
      "Epoch 65600, Train loss: 8.633e+01, Test loss: 2.273e+02, MSE(e): 2.427e-06, MSE(pi1): 1.769e-03, MSE(pi2): 2.029e-06, MSE(pi3): 4.436e-04\n",
      "Epoch 65700, Train loss: 8.627e+01, Test loss: 2.270e+02, MSE(e): 2.422e-06, MSE(pi1): 1.769e-03, MSE(pi2): 2.024e-06, MSE(pi3): 4.437e-04\n",
      "Epoch 65800, Train loss: 8.622e+01, Test loss: 2.266e+02, MSE(e): 2.416e-06, MSE(pi1): 1.768e-03, MSE(pi2): 2.019e-06, MSE(pi3): 4.437e-04\n",
      "Epoch 65900, Train loss: 8.616e+01, Test loss: 2.264e+02, MSE(e): 2.411e-06, MSE(pi1): 1.768e-03, MSE(pi2): 2.013e-06, MSE(pi3): 4.437e-04\n",
      "Epoch 66000, Train loss: 8.610e+01, Test loss: 2.260e+02, MSE(e): 2.405e-06, MSE(pi1): 1.767e-03, MSE(pi2): 2.008e-06, MSE(pi3): 4.438e-04\n",
      "Epoch 66100, Train loss: 8.604e+01, Test loss: 2.257e+02, MSE(e): 2.399e-06, MSE(pi1): 1.766e-03, MSE(pi2): 2.002e-06, MSE(pi3): 4.438e-04\n",
      "Epoch 66200, Train loss: 8.598e+01, Test loss: 2.254e+02, MSE(e): 2.393e-06, MSE(pi1): 1.766e-03, MSE(pi2): 1.997e-06, MSE(pi3): 4.438e-04\n",
      "Epoch 66300, Train loss: 8.592e+01, Test loss: 2.251e+02, MSE(e): 2.388e-06, MSE(pi1): 1.765e-03, MSE(pi2): 1.992e-06, MSE(pi3): 4.439e-04\n",
      "Epoch 66400, Train loss: 8.586e+01, Test loss: 2.247e+02, MSE(e): 2.382e-06, MSE(pi1): 1.765e-03, MSE(pi2): 1.986e-06, MSE(pi3): 4.439e-04\n",
      "Epoch 66500, Train loss: 8.579e+01, Test loss: 2.244e+02, MSE(e): 2.376e-06, MSE(pi1): 1.764e-03, MSE(pi2): 1.980e-06, MSE(pi3): 4.440e-04\n",
      "Epoch 66600, Train loss: 8.574e+01, Test loss: 2.241e+02, MSE(e): 2.370e-06, MSE(pi1): 1.763e-03, MSE(pi2): 1.974e-06, MSE(pi3): 4.440e-04\n",
      "Epoch 66700, Train loss: 8.568e+01, Test loss: 2.238e+02, MSE(e): 2.365e-06, MSE(pi1): 1.763e-03, MSE(pi2): 1.969e-06, MSE(pi3): 4.440e-04\n",
      "Epoch 66800, Train loss: 8.562e+01, Test loss: 2.236e+02, MSE(e): 2.360e-06, MSE(pi1): 1.762e-03, MSE(pi2): 1.964e-06, MSE(pi3): 4.441e-04\n",
      "Epoch 66900, Train loss: 8.556e+01, Test loss: 2.233e+02, MSE(e): 2.353e-06, MSE(pi1): 1.761e-03, MSE(pi2): 1.958e-06, MSE(pi3): 4.441e-04\n",
      "Epoch 67000, Train loss: 8.550e+01, Test loss: 2.230e+02, MSE(e): 2.347e-06, MSE(pi1): 1.761e-03, MSE(pi2): 1.952e-06, MSE(pi3): 4.441e-04\n",
      "Epoch 67100, Train loss: 8.544e+01, Test loss: 2.227e+02, MSE(e): 2.342e-06, MSE(pi1): 1.760e-03, MSE(pi2): 1.947e-06, MSE(pi3): 4.442e-04\n",
      "Epoch 67200, Train loss: 8.538e+01, Test loss: 2.224e+02, MSE(e): 2.336e-06, MSE(pi1): 1.760e-03, MSE(pi2): 1.941e-06, MSE(pi3): 4.442e-04\n",
      "Epoch 67300, Train loss: 8.531e+01, Test loss: 2.220e+02, MSE(e): 2.330e-06, MSE(pi1): 1.759e-03, MSE(pi2): 1.935e-06, MSE(pi3): 4.442e-04\n",
      "Epoch 67400, Train loss: 8.525e+01, Test loss: 2.218e+02, MSE(e): 2.324e-06, MSE(pi1): 1.758e-03, MSE(pi2): 1.930e-06, MSE(pi3): 4.443e-04\n",
      "Epoch 67500, Train loss: 8.520e+01, Test loss: 2.215e+02, MSE(e): 2.319e-06, MSE(pi1): 1.758e-03, MSE(pi2): 1.925e-06, MSE(pi3): 4.443e-04\n",
      "Epoch 67600, Train loss: 8.514e+01, Test loss: 2.212e+02, MSE(e): 2.313e-06, MSE(pi1): 1.757e-03, MSE(pi2): 1.920e-06, MSE(pi3): 4.443e-04\n",
      "Epoch 67700, Train loss: 8.508e+01, Test loss: 2.209e+02, MSE(e): 2.308e-06, MSE(pi1): 1.757e-03, MSE(pi2): 1.914e-06, MSE(pi3): 4.444e-04\n",
      "Epoch 67800, Train loss: 8.503e+01, Test loss: 2.206e+02, MSE(e): 2.302e-06, MSE(pi1): 1.756e-03, MSE(pi2): 1.909e-06, MSE(pi3): 4.444e-04\n",
      "Epoch 67900, Train loss: 8.496e+01, Test loss: 2.203e+02, MSE(e): 2.296e-06, MSE(pi1): 1.755e-03, MSE(pi2): 1.903e-06, MSE(pi3): 4.445e-04\n",
      "Epoch 68000, Train loss: 8.491e+01, Test loss: 2.200e+02, MSE(e): 2.291e-06, MSE(pi1): 1.755e-03, MSE(pi2): 1.897e-06, MSE(pi3): 4.445e-04\n",
      "Epoch 68100, Train loss: 8.485e+01, Test loss: 2.198e+02, MSE(e): 2.285e-06, MSE(pi1): 1.754e-03, MSE(pi2): 1.892e-06, MSE(pi3): 4.445e-04\n",
      "Epoch 68200, Train loss: 8.479e+01, Test loss: 2.195e+02, MSE(e): 2.280e-06, MSE(pi1): 1.753e-03, MSE(pi2): 1.887e-06, MSE(pi3): 4.446e-04\n",
      "Epoch 68300, Train loss: 8.474e+01, Test loss: 2.192e+02, MSE(e): 2.275e-06, MSE(pi1): 1.753e-03, MSE(pi2): 1.883e-06, MSE(pi3): 4.446e-04\n",
      "Epoch 68400, Train loss: 8.469e+01, Test loss: 2.190e+02, MSE(e): 2.270e-06, MSE(pi1): 1.752e-03, MSE(pi2): 1.878e-06, MSE(pi3): 4.446e-04\n",
      "Epoch 68500, Train loss: 8.463e+01, Test loss: 2.187e+02, MSE(e): 2.265e-06, MSE(pi1): 1.752e-03, MSE(pi2): 1.873e-06, MSE(pi3): 4.447e-04\n",
      "Epoch 68600, Train loss: 8.458e+01, Test loss: 2.185e+02, MSE(e): 2.260e-06, MSE(pi1): 1.751e-03, MSE(pi2): 1.868e-06, MSE(pi3): 4.447e-04\n",
      "Epoch 68700, Train loss: 8.452e+01, Test loss: 2.182e+02, MSE(e): 2.254e-06, MSE(pi1): 1.750e-03, MSE(pi2): 1.863e-06, MSE(pi3): 4.448e-04\n",
      "Epoch 68800, Train loss: 8.446e+01, Test loss: 2.179e+02, MSE(e): 2.249e-06, MSE(pi1): 1.750e-03, MSE(pi2): 1.857e-06, MSE(pi3): 4.448e-04\n",
      "Epoch 68900, Train loss: 8.441e+01, Test loss: 2.177e+02, MSE(e): 2.244e-06, MSE(pi1): 1.749e-03, MSE(pi2): 1.852e-06, MSE(pi3): 4.448e-04\n",
      "Epoch 69000, Train loss: 8.436e+01, Test loss: 2.175e+02, MSE(e): 2.239e-06, MSE(pi1): 1.749e-03, MSE(pi2): 1.847e-06, MSE(pi3): 4.449e-04\n",
      "Epoch 69100, Train loss: 8.430e+01, Test loss: 2.172e+02, MSE(e): 2.233e-06, MSE(pi1): 1.748e-03, MSE(pi2): 1.842e-06, MSE(pi3): 4.449e-04\n",
      "Epoch 69200, Train loss: 8.425e+01, Test loss: 2.170e+02, MSE(e): 2.228e-06, MSE(pi1): 1.747e-03, MSE(pi2): 1.837e-06, MSE(pi3): 4.449e-04\n",
      "Epoch 69300, Train loss: 8.419e+01, Test loss: 2.167e+02, MSE(e): 2.223e-06, MSE(pi1): 1.747e-03, MSE(pi2): 1.832e-06, MSE(pi3): 4.450e-04\n",
      "Epoch 69400, Train loss: 8.414e+01, Test loss: 2.164e+02, MSE(e): 2.218e-06, MSE(pi1): 1.746e-03, MSE(pi2): 1.827e-06, MSE(pi3): 4.450e-04\n",
      "Epoch 69500, Train loss: 8.408e+01, Test loss: 2.162e+02, MSE(e): 2.212e-06, MSE(pi1): 1.746e-03, MSE(pi2): 1.821e-06, MSE(pi3): 4.450e-04\n",
      "Epoch 69600, Train loss: 8.404e+01, Test loss: 2.160e+02, MSE(e): 2.208e-06, MSE(pi1): 1.745e-03, MSE(pi2): 1.817e-06, MSE(pi3): 4.451e-04\n",
      "Epoch 69700, Train loss: 8.399e+01, Test loss: 2.158e+02, MSE(e): 2.203e-06, MSE(pi1): 1.745e-03, MSE(pi2): 1.813e-06, MSE(pi3): 4.451e-04\n",
      "Epoch 69800, Train loss: 8.394e+01, Test loss: 2.156e+02, MSE(e): 2.199e-06, MSE(pi1): 1.744e-03, MSE(pi2): 1.808e-06, MSE(pi3): 4.451e-04\n",
      "Epoch 69900, Train loss: 8.388e+01, Test loss: 2.153e+02, MSE(e): 2.193e-06, MSE(pi1): 1.744e-03, MSE(pi2): 1.803e-06, MSE(pi3): 4.452e-04\n",
      "Epoch 70000, Train loss: 8.383e+01, Test loss: 2.150e+02, MSE(e): 2.188e-06, MSE(pi1): 1.743e-03, MSE(pi2): 1.798e-06, MSE(pi3): 4.452e-04\n",
      "Epoch 70100, Train loss: 8.378e+01, Test loss: 2.148e+02, MSE(e): 2.183e-06, MSE(pi1): 1.743e-03, MSE(pi2): 1.794e-06, MSE(pi3): 4.452e-04\n",
      "Epoch 70200, Train loss: 8.374e+01, Test loss: 2.146e+02, MSE(e): 2.179e-06, MSE(pi1): 1.742e-03, MSE(pi2): 1.789e-06, MSE(pi3): 4.453e-04\n",
      "Epoch 70300, Train loss: 8.369e+01, Test loss: 2.144e+02, MSE(e): 2.174e-06, MSE(pi1): 1.742e-03, MSE(pi2): 1.784e-06, MSE(pi3): 4.453e-04\n",
      "Epoch 70400, Train loss: 8.364e+01, Test loss: 2.142e+02, MSE(e): 2.169e-06, MSE(pi1): 1.741e-03, MSE(pi2): 1.779e-06, MSE(pi3): 4.453e-04\n",
      "Epoch 70500, Train loss: 8.359e+01, Test loss: 2.141e+02, MSE(e): 2.165e-06, MSE(pi1): 1.740e-03, MSE(pi2): 1.776e-06, MSE(pi3): 4.454e-04\n",
      "Epoch 70600, Train loss: 8.355e+01, Test loss: 2.139e+02, MSE(e): 2.161e-06, MSE(pi1): 1.740e-03, MSE(pi2): 1.772e-06, MSE(pi3): 4.454e-04\n",
      "Epoch 70700, Train loss: 8.350e+01, Test loss: 2.137e+02, MSE(e): 2.156e-06, MSE(pi1): 1.740e-03, MSE(pi2): 1.767e-06, MSE(pi3): 4.454e-04\n",
      "Epoch 70800, Train loss: 8.345e+01, Test loss: 2.134e+02, MSE(e): 2.151e-06, MSE(pi1): 1.739e-03, MSE(pi2): 1.762e-06, MSE(pi3): 4.455e-04\n",
      "Epoch 70900, Train loss: 8.341e+01, Test loss: 2.133e+02, MSE(e): 2.147e-06, MSE(pi1): 1.738e-03, MSE(pi2): 1.758e-06, MSE(pi3): 4.455e-04\n",
      "Epoch 71000, Train loss: 8.336e+01, Test loss: 2.131e+02, MSE(e): 2.143e-06, MSE(pi1): 1.738e-03, MSE(pi2): 1.754e-06, MSE(pi3): 4.455e-04\n",
      "Epoch 71100, Train loss: 8.331e+01, Test loss: 2.129e+02, MSE(e): 2.138e-06, MSE(pi1): 1.737e-03, MSE(pi2): 1.749e-06, MSE(pi3): 4.456e-04\n",
      "Epoch 71200, Train loss: 8.327e+01, Test loss: 2.127e+02, MSE(e): 2.134e-06, MSE(pi1): 1.737e-03, MSE(pi2): 1.744e-06, MSE(pi3): 4.456e-04\n",
      "Epoch 71300, Train loss: 8.322e+01, Test loss: 2.125e+02, MSE(e): 2.130e-06, MSE(pi1): 1.736e-03, MSE(pi2): 1.740e-06, MSE(pi3): 4.456e-04\n",
      "Epoch 71400, Train loss: 8.317e+01, Test loss: 2.123e+02, MSE(e): 2.125e-06, MSE(pi1): 1.736e-03, MSE(pi2): 1.735e-06, MSE(pi3): 4.456e-04\n",
      "Epoch 71500, Train loss: 8.313e+01, Test loss: 2.122e+02, MSE(e): 2.121e-06, MSE(pi1): 1.735e-03, MSE(pi2): 1.731e-06, MSE(pi3): 4.457e-04\n",
      "Epoch 71600, Train loss: 8.308e+01, Test loss: 2.119e+02, MSE(e): 2.116e-06, MSE(pi1): 1.735e-03, MSE(pi2): 1.727e-06, MSE(pi3): 4.457e-04\n",
      "Epoch 71700, Train loss: 8.304e+01, Test loss: 2.118e+02, MSE(e): 2.113e-06, MSE(pi1): 1.734e-03, MSE(pi2): 1.723e-06, MSE(pi3): 4.457e-04\n",
      "Epoch 71800, Train loss: 8.300e+01, Test loss: 2.117e+02, MSE(e): 2.109e-06, MSE(pi1): 1.734e-03, MSE(pi2): 1.718e-06, MSE(pi3): 4.458e-04\n",
      "Epoch 71900, Train loss: 8.296e+01, Test loss: 2.115e+02, MSE(e): 2.105e-06, MSE(pi1): 1.733e-03, MSE(pi2): 1.714e-06, MSE(pi3): 4.458e-04\n",
      "Epoch 72000, Train loss: 8.292e+01, Test loss: 2.113e+02, MSE(e): 2.101e-06, MSE(pi1): 1.733e-03, MSE(pi2): 1.710e-06, MSE(pi3): 4.458e-04\n",
      "Epoch 72100, Train loss: 8.287e+01, Test loss: 2.112e+02, MSE(e): 2.096e-06, MSE(pi1): 1.732e-03, MSE(pi2): 1.706e-06, MSE(pi3): 4.459e-04\n",
      "Epoch 72200, Train loss: 8.282e+01, Test loss: 2.111e+02, MSE(e): 2.092e-06, MSE(pi1): 1.732e-03, MSE(pi2): 1.702e-06, MSE(pi3): 4.459e-04\n",
      "Epoch 72300, Train loss: 8.278e+01, Test loss: 2.109e+02, MSE(e): 2.087e-06, MSE(pi1): 1.731e-03, MSE(pi2): 1.698e-06, MSE(pi3): 4.459e-04\n",
      "Epoch 72400, Train loss: 8.273e+01, Test loss: 2.107e+02, MSE(e): 2.083e-06, MSE(pi1): 1.731e-03, MSE(pi2): 1.693e-06, MSE(pi3): 4.459e-04\n",
      "Epoch 72500, Train loss: 8.269e+01, Test loss: 2.105e+02, MSE(e): 2.078e-06, MSE(pi1): 1.730e-03, MSE(pi2): 1.689e-06, MSE(pi3): 4.460e-04\n",
      "Epoch 72600, Train loss: 8.265e+01, Test loss: 2.104e+02, MSE(e): 2.075e-06, MSE(pi1): 1.730e-03, MSE(pi2): 1.685e-06, MSE(pi3): 4.460e-04\n",
      "Epoch 72700, Train loss: 8.260e+01, Test loss: 2.102e+02, MSE(e): 2.070e-06, MSE(pi1): 1.729e-03, MSE(pi2): 1.680e-06, MSE(pi3): 4.460e-04\n",
      "Epoch 72800, Train loss: 8.256e+01, Test loss: 2.101e+02, MSE(e): 2.066e-06, MSE(pi1): 1.729e-03, MSE(pi2): 1.677e-06, MSE(pi3): 4.460e-04\n",
      "Epoch 72900, Train loss: 8.252e+01, Test loss: 2.099e+02, MSE(e): 2.063e-06, MSE(pi1): 1.729e-03, MSE(pi2): 1.673e-06, MSE(pi3): 4.461e-04\n",
      "Epoch 73000, Train loss: 8.248e+01, Test loss: 2.098e+02, MSE(e): 2.058e-06, MSE(pi1): 1.728e-03, MSE(pi2): 1.669e-06, MSE(pi3): 4.461e-04\n",
      "Epoch 73100, Train loss: 8.245e+01, Test loss: 2.097e+02, MSE(e): 2.055e-06, MSE(pi1): 1.728e-03, MSE(pi2): 1.665e-06, MSE(pi3): 4.461e-04\n",
      "Epoch 73200, Train loss: 8.240e+01, Test loss: 2.095e+02, MSE(e): 2.051e-06, MSE(pi1): 1.727e-03, MSE(pi2): 1.661e-06, MSE(pi3): 4.462e-04\n",
      "Epoch 73300, Train loss: 8.237e+01, Test loss: 2.094e+02, MSE(e): 2.047e-06, MSE(pi1): 1.727e-03, MSE(pi2): 1.658e-06, MSE(pi3): 4.462e-04\n",
      "Epoch 73400, Train loss: 8.232e+01, Test loss: 2.093e+02, MSE(e): 2.043e-06, MSE(pi1): 1.726e-03, MSE(pi2): 1.654e-06, MSE(pi3): 4.462e-04\n",
      "Epoch 73500, Train loss: 8.227e+01, Test loss: 2.092e+02, MSE(e): 2.038e-06, MSE(pi1): 1.726e-03, MSE(pi2): 1.649e-06, MSE(pi3): 4.462e-04\n",
      "Epoch 73600, Train loss: 8.223e+01, Test loss: 2.090e+02, MSE(e): 2.034e-06, MSE(pi1): 1.726e-03, MSE(pi2): 1.645e-06, MSE(pi3): 4.463e-04\n",
      "Epoch 73700, Train loss: 8.218e+01, Test loss: 2.089e+02, MSE(e): 2.030e-06, MSE(pi1): 1.725e-03, MSE(pi2): 1.641e-06, MSE(pi3): 4.463e-04\n",
      "Epoch 73800, Train loss: 8.215e+01, Test loss: 2.088e+02, MSE(e): 2.027e-06, MSE(pi1): 1.725e-03, MSE(pi2): 1.638e-06, MSE(pi3): 4.463e-04\n",
      "Epoch 73900, Train loss: 8.211e+01, Test loss: 2.087e+02, MSE(e): 2.023e-06, MSE(pi1): 1.725e-03, MSE(pi2): 1.634e-06, MSE(pi3): 4.463e-04\n",
      "Epoch 74000, Train loss: 8.207e+01, Test loss: 2.086e+02, MSE(e): 2.019e-06, MSE(pi1): 1.724e-03, MSE(pi2): 1.630e-06, MSE(pi3): 4.463e-04\n",
      "Epoch 74100, Train loss: 8.203e+01, Test loss: 2.085e+02, MSE(e): 2.015e-06, MSE(pi1): 1.724e-03, MSE(pi2): 1.627e-06, MSE(pi3): 4.464e-04\n",
      "Epoch 74200, Train loss: 8.199e+01, Test loss: 2.084e+02, MSE(e): 2.011e-06, MSE(pi1): 1.723e-03, MSE(pi2): 1.623e-06, MSE(pi3): 4.464e-04\n",
      "Epoch 74300, Train loss: 8.195e+01, Test loss: 2.083e+02, MSE(e): 2.008e-06, MSE(pi1): 1.723e-03, MSE(pi2): 1.619e-06, MSE(pi3): 4.464e-04\n",
      "Epoch 74400, Train loss: 8.192e+01, Test loss: 2.082e+02, MSE(e): 2.004e-06, MSE(pi1): 1.723e-03, MSE(pi2): 1.616e-06, MSE(pi3): 4.465e-04\n",
      "Epoch 74500, Train loss: 8.188e+01, Test loss: 2.081e+02, MSE(e): 2.001e-06, MSE(pi1): 1.722e-03, MSE(pi2): 1.612e-06, MSE(pi3): 4.465e-04\n",
      "Epoch 74600, Train loss: 8.183e+01, Test loss: 2.080e+02, MSE(e): 1.996e-06, MSE(pi1): 1.722e-03, MSE(pi2): 1.608e-06, MSE(pi3): 4.465e-04\n",
      "Epoch 74700, Train loss: 8.180e+01, Test loss: 2.080e+02, MSE(e): 1.993e-06, MSE(pi1): 1.721e-03, MSE(pi2): 1.605e-06, MSE(pi3): 4.465e-04\n",
      "Epoch 74800, Train loss: 8.176e+01, Test loss: 2.079e+02, MSE(e): 1.989e-06, MSE(pi1): 1.721e-03, MSE(pi2): 1.601e-06, MSE(pi3): 4.466e-04\n",
      "Epoch 74900, Train loss: 8.171e+01, Test loss: 2.077e+02, MSE(e): 1.984e-06, MSE(pi1): 1.721e-03, MSE(pi2): 1.597e-06, MSE(pi3): 4.466e-04\n",
      "Epoch 75000, Train loss: 8.167e+01, Test loss: 2.077e+02, MSE(e): 1.981e-06, MSE(pi1): 1.720e-03, MSE(pi2): 1.593e-06, MSE(pi3): 4.466e-04\n",
      "Epoch 75100, Train loss: 8.163e+01, Test loss: 2.076e+02, MSE(e): 1.977e-06, MSE(pi1): 1.720e-03, MSE(pi2): 1.589e-06, MSE(pi3): 4.466e-04\n",
      "Epoch 75200, Train loss: 8.159e+01, Test loss: 2.074e+02, MSE(e): 1.973e-06, MSE(pi1): 1.720e-03, MSE(pi2): 1.585e-06, MSE(pi3): 4.466e-04\n",
      "Epoch 75300, Train loss: 8.155e+01, Test loss: 2.074e+02, MSE(e): 1.969e-06, MSE(pi1): 1.719e-03, MSE(pi2): 1.582e-06, MSE(pi3): 4.467e-04\n",
      "Epoch 75400, Train loss: 8.151e+01, Test loss: 2.073e+02, MSE(e): 1.965e-06, MSE(pi1): 1.719e-03, MSE(pi2): 1.578e-06, MSE(pi3): 4.467e-04\n",
      "Epoch 75500, Train loss: 8.147e+01, Test loss: 2.072e+02, MSE(e): 1.961e-06, MSE(pi1): 1.719e-03, MSE(pi2): 1.574e-06, MSE(pi3): 4.467e-04\n",
      "Epoch 75600, Train loss: 8.142e+01, Test loss: 2.071e+02, MSE(e): 1.957e-06, MSE(pi1): 1.718e-03, MSE(pi2): 1.571e-06, MSE(pi3): 4.467e-04\n",
      "Epoch 75700, Train loss: 8.139e+01, Test loss: 2.070e+02, MSE(e): 1.954e-06, MSE(pi1): 1.718e-03, MSE(pi2): 1.568e-06, MSE(pi3): 4.467e-04\n",
      "Epoch 75800, Train loss: 8.136e+01, Test loss: 2.069e+02, MSE(e): 1.950e-06, MSE(pi1): 1.718e-03, MSE(pi2): 1.564e-06, MSE(pi3): 4.467e-04\n",
      "Epoch 75900, Train loss: 8.132e+01, Test loss: 2.069e+02, MSE(e): 1.947e-06, MSE(pi1): 1.717e-03, MSE(pi2): 1.561e-06, MSE(pi3): 4.468e-04\n",
      "Epoch 76000, Train loss: 8.128e+01, Test loss: 2.068e+02, MSE(e): 1.943e-06, MSE(pi1): 1.717e-03, MSE(pi2): 1.557e-06, MSE(pi3): 4.468e-04\n",
      "Epoch 76100, Train loss: 8.125e+01, Test loss: 2.067e+02, MSE(e): 1.940e-06, MSE(pi1): 1.717e-03, MSE(pi2): 1.554e-06, MSE(pi3): 4.468e-04\n",
      "Epoch 76200, Train loss: 8.120e+01, Test loss: 2.067e+02, MSE(e): 1.935e-06, MSE(pi1): 1.716e-03, MSE(pi2): 1.550e-06, MSE(pi3): 4.468e-04\n",
      "Epoch 76300, Train loss: 8.117e+01, Test loss: 2.066e+02, MSE(e): 1.932e-06, MSE(pi1): 1.716e-03, MSE(pi2): 1.547e-06, MSE(pi3): 4.469e-04\n",
      "Epoch 76400, Train loss: 8.113e+01, Test loss: 2.065e+02, MSE(e): 1.928e-06, MSE(pi1): 1.716e-03, MSE(pi2): 1.543e-06, MSE(pi3): 4.469e-04\n",
      "Epoch 76500, Train loss: 8.109e+01, Test loss: 2.065e+02, MSE(e): 1.925e-06, MSE(pi1): 1.716e-03, MSE(pi2): 1.540e-06, MSE(pi3): 4.469e-04\n",
      "Epoch 76600, Train loss: 8.105e+01, Test loss: 2.064e+02, MSE(e): 1.920e-06, MSE(pi1): 1.715e-03, MSE(pi2): 1.536e-06, MSE(pi3): 4.469e-04\n",
      "Epoch 76700, Train loss: 8.102e+01, Test loss: 2.064e+02, MSE(e): 1.917e-06, MSE(pi1): 1.715e-03, MSE(pi2): 1.533e-06, MSE(pi3): 4.469e-04\n",
      "Epoch 76800, Train loss: 8.098e+01, Test loss: 2.063e+02, MSE(e): 1.913e-06, MSE(pi1): 1.715e-03, MSE(pi2): 1.530e-06, MSE(pi3): 4.469e-04\n",
      "Epoch 76900, Train loss: 8.093e+01, Test loss: 2.063e+02, MSE(e): 1.909e-06, MSE(pi1): 1.715e-03, MSE(pi2): 1.526e-06, MSE(pi3): 4.469e-04\n",
      "Epoch 77000, Train loss: 8.089e+01, Test loss: 2.062e+02, MSE(e): 1.905e-06, MSE(pi1): 1.714e-03, MSE(pi2): 1.522e-06, MSE(pi3): 4.469e-04\n",
      "Epoch 77100, Train loss: 8.086e+01, Test loss: 2.062e+02, MSE(e): 1.902e-06, MSE(pi1): 1.714e-03, MSE(pi2): 1.519e-06, MSE(pi3): 4.470e-04\n",
      "Epoch 77200, Train loss: 8.081e+01, Test loss: 2.062e+02, MSE(e): 1.897e-06, MSE(pi1): 1.714e-03, MSE(pi2): 1.515e-06, MSE(pi3): 4.470e-04\n",
      "Epoch 77300, Train loss: 8.079e+01, Test loss: 2.062e+02, MSE(e): 1.896e-06, MSE(pi1): 1.713e-03, MSE(pi2): 1.513e-06, MSE(pi3): 4.470e-04\n",
      "Epoch 77400, Train loss: 8.076e+01, Test loss: 2.062e+02, MSE(e): 1.892e-06, MSE(pi1): 1.713e-03, MSE(pi2): 1.510e-06, MSE(pi3): 4.470e-04\n",
      "Epoch 77500, Train loss: 8.072e+01, Test loss: 2.063e+02, MSE(e): 1.889e-06, MSE(pi1): 1.713e-03, MSE(pi2): 1.507e-06, MSE(pi3): 4.470e-04\n",
      "Epoch 77600, Train loss: 8.069e+01, Test loss: 2.063e+02, MSE(e): 1.886e-06, MSE(pi1): 1.713e-03, MSE(pi2): 1.504e-06, MSE(pi3): 4.470e-04\n",
      "Epoch 77700, Train loss: 8.066e+01, Test loss: 2.063e+02, MSE(e): 1.882e-06, MSE(pi1): 1.712e-03, MSE(pi2): 1.500e-06, MSE(pi3): 4.471e-04\n",
      "Epoch 77800, Train loss: 8.062e+01, Test loss: 2.064e+02, MSE(e): 1.879e-06, MSE(pi1): 1.712e-03, MSE(pi2): 1.497e-06, MSE(pi3): 4.471e-04\n",
      "Epoch 77900, Train loss: 8.059e+01, Test loss: 2.065e+02, MSE(e): 1.876e-06, MSE(pi1): 1.712e-03, MSE(pi2): 1.494e-06, MSE(pi3): 4.471e-04\n",
      "Epoch 78000, Train loss: 8.055e+01, Test loss: 2.066e+02, MSE(e): 1.872e-06, MSE(pi1): 1.712e-03, MSE(pi2): 1.490e-06, MSE(pi3): 4.471e-04\n",
      "Epoch 78100, Train loss: 8.050e+01, Test loss: 2.067e+02, MSE(e): 1.868e-06, MSE(pi1): 1.711e-03, MSE(pi2): 1.486e-06, MSE(pi3): 4.471e-04\n",
      "Epoch 78200, Train loss: 8.047e+01, Test loss: 2.069e+02, MSE(e): 1.864e-06, MSE(pi1): 1.711e-03, MSE(pi2): 1.483e-06, MSE(pi3): 4.471e-04\n",
      "Epoch 78300, Train loss: 8.043e+01, Test loss: 2.071e+02, MSE(e): 1.861e-06, MSE(pi1): 1.711e-03, MSE(pi2): 1.480e-06, MSE(pi3): 4.471e-04\n",
      "Epoch 78400, Train loss: 8.039e+01, Test loss: 2.073e+02, MSE(e): 1.857e-06, MSE(pi1): 1.711e-03, MSE(pi2): 1.476e-06, MSE(pi3): 4.471e-04\n",
      "Epoch 78500, Train loss: 8.036e+01, Test loss: 2.075e+02, MSE(e): 1.854e-06, MSE(pi1): 1.711e-03, MSE(pi2): 1.473e-06, MSE(pi3): 4.472e-04\n",
      "Epoch 78600, Train loss: 8.034e+01, Test loss: 2.078e+02, MSE(e): 1.852e-06, MSE(pi1): 1.710e-03, MSE(pi2): 1.471e-06, MSE(pi3): 4.472e-04\n",
      "Epoch 78700, Train loss: 8.030e+01, Test loss: 2.081e+02, MSE(e): 1.848e-06, MSE(pi1): 1.710e-03, MSE(pi2): 1.468e-06, MSE(pi3): 4.472e-04\n",
      "Epoch 78800, Train loss: 8.027e+01, Test loss: 2.083e+02, MSE(e): 1.845e-06, MSE(pi1): 1.710e-03, MSE(pi2): 1.465e-06, MSE(pi3): 4.472e-04\n",
      "Epoch 78900, Train loss: 8.024e+01, Test loss: 2.086e+02, MSE(e): 1.842e-06, MSE(pi1): 1.710e-03, MSE(pi2): 1.462e-06, MSE(pi3): 4.472e-04\n",
      "Epoch 79000, Train loss: 8.021e+01, Test loss: 2.089e+02, MSE(e): 1.839e-06, MSE(pi1): 1.709e-03, MSE(pi2): 1.459e-06, MSE(pi3): 4.472e-04\n",
      "Epoch 79100, Train loss: 8.017e+01, Test loss: 2.092e+02, MSE(e): 1.836e-06, MSE(pi1): 1.709e-03, MSE(pi2): 1.456e-06, MSE(pi3): 4.472e-04\n",
      "Epoch 79200, Train loss: 8.014e+01, Test loss: 2.095e+02, MSE(e): 1.832e-06, MSE(pi1): 1.709e-03, MSE(pi2): 1.453e-06, MSE(pi3): 4.472e-04\n",
      "Epoch 79300, Train loss: 8.011e+01, Test loss: 2.098e+02, MSE(e): 1.829e-06, MSE(pi1): 1.709e-03, MSE(pi2): 1.450e-06, MSE(pi3): 4.472e-04\n",
      "Epoch 79400, Train loss: 8.007e+01, Test loss: 2.100e+02, MSE(e): 1.826e-06, MSE(pi1): 1.709e-03, MSE(pi2): 1.447e-06, MSE(pi3): 4.472e-04\n",
      "Epoch 79500, Train loss: 8.003e+01, Test loss: 2.103e+02, MSE(e): 1.822e-06, MSE(pi1): 1.708e-03, MSE(pi2): 1.443e-06, MSE(pi3): 4.473e-04\n",
      "Epoch 79600, Train loss: 7.999e+01, Test loss: 2.105e+02, MSE(e): 1.818e-06, MSE(pi1): 1.708e-03, MSE(pi2): 1.440e-06, MSE(pi3): 4.473e-04\n",
      "Epoch 79700, Train loss: 7.995e+01, Test loss: 2.107e+02, MSE(e): 1.814e-06, MSE(pi1): 1.708e-03, MSE(pi2): 1.436e-06, MSE(pi3): 4.473e-04\n",
      "Epoch 79800, Train loss: 7.992e+01, Test loss: 2.110e+02, MSE(e): 1.811e-06, MSE(pi1): 1.708e-03, MSE(pi2): 1.433e-06, MSE(pi3): 4.473e-04\n",
      "Epoch 79900, Train loss: 7.989e+01, Test loss: 2.112e+02, MSE(e): 1.808e-06, MSE(pi1): 1.708e-03, MSE(pi2): 1.430e-06, MSE(pi3): 4.473e-04\n",
      "Epoch 80000, Train loss: 7.986e+01, Test loss: 2.115e+02, MSE(e): 1.805e-06, MSE(pi1): 1.708e-03, MSE(pi2): 1.427e-06, MSE(pi3): 4.473e-04\n",
      "Epoch 80100, Train loss: 7.983e+01, Test loss: 2.118e+02, MSE(e): 1.803e-06, MSE(pi1): 1.707e-03, MSE(pi2): 1.425e-06, MSE(pi3): 4.473e-04\n",
      "Epoch 80200, Train loss: 7.980e+01, Test loss: 2.121e+02, MSE(e): 1.799e-06, MSE(pi1): 1.707e-03, MSE(pi2): 1.421e-06, MSE(pi3): 4.473e-04\n",
      "Epoch 80300, Train loss: 7.975e+01, Test loss: 2.123e+02, MSE(e): 1.795e-06, MSE(pi1): 1.707e-03, MSE(pi2): 1.418e-06, MSE(pi3): 4.473e-04\n",
      "Epoch 80400, Train loss: 7.970e+01, Test loss: 2.125e+02, MSE(e): 1.790e-06, MSE(pi1): 1.707e-03, MSE(pi2): 1.413e-06, MSE(pi3): 4.473e-04\n",
      "Epoch 80500, Train loss: 7.967e+01, Test loss: 2.127e+02, MSE(e): 1.787e-06, MSE(pi1): 1.707e-03, MSE(pi2): 1.411e-06, MSE(pi3): 4.473e-04\n",
      "Epoch 80600, Train loss: 7.965e+01, Test loss: 2.130e+02, MSE(e): 1.785e-06, MSE(pi1): 1.706e-03, MSE(pi2): 1.408e-06, MSE(pi3): 4.474e-04\n",
      "Epoch 80700, Train loss: 7.962e+01, Test loss: 2.132e+02, MSE(e): 1.782e-06, MSE(pi1): 1.706e-03, MSE(pi2): 1.405e-06, MSE(pi3): 4.474e-04\n",
      "Epoch 80800, Train loss: 7.958e+01, Test loss: 2.135e+02, MSE(e): 1.778e-06, MSE(pi1): 1.706e-03, MSE(pi2): 1.402e-06, MSE(pi3): 4.474e-04\n",
      "Epoch 80900, Train loss: 7.956e+01, Test loss: 2.137e+02, MSE(e): 1.776e-06, MSE(pi1): 1.706e-03, MSE(pi2): 1.399e-06, MSE(pi3): 4.474e-04\n",
      "Epoch 81000, Train loss: 7.952e+01, Test loss: 2.139e+02, MSE(e): 1.772e-06, MSE(pi1): 1.706e-03, MSE(pi2): 1.396e-06, MSE(pi3): 4.474e-04\n",
      "Epoch 81100, Train loss: 7.948e+01, Test loss: 2.142e+02, MSE(e): 1.769e-06, MSE(pi1): 1.705e-03, MSE(pi2): 1.393e-06, MSE(pi3): 4.474e-04\n",
      "Epoch 81200, Train loss: 7.945e+01, Test loss: 2.145e+02, MSE(e): 1.766e-06, MSE(pi1): 1.705e-03, MSE(pi2): 1.390e-06, MSE(pi3): 4.474e-04\n",
      "Epoch 81300, Train loss: 7.942e+01, Test loss: 2.147e+02, MSE(e): 1.763e-06, MSE(pi1): 1.705e-03, MSE(pi2): 1.387e-06, MSE(pi3): 4.474e-04\n",
      "Epoch 81400, Train loss: 7.939e+01, Test loss: 2.150e+02, MSE(e): 1.760e-06, MSE(pi1): 1.705e-03, MSE(pi2): 1.384e-06, MSE(pi3): 4.474e-04\n",
      "Epoch 81500, Train loss: 7.936e+01, Test loss: 2.153e+02, MSE(e): 1.757e-06, MSE(pi1): 1.705e-03, MSE(pi2): 1.381e-06, MSE(pi3): 4.474e-04\n",
      "Epoch 81600, Train loss: 7.932e+01, Test loss: 2.155e+02, MSE(e): 1.753e-06, MSE(pi1): 1.705e-03, MSE(pi2): 1.377e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 81700, Train loss: 7.930e+01, Test loss: 2.158e+02, MSE(e): 1.751e-06, MSE(pi1): 1.704e-03, MSE(pi2): 1.375e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 81800, Train loss: 7.926e+01, Test loss: 2.160e+02, MSE(e): 1.747e-06, MSE(pi1): 1.704e-03, MSE(pi2): 1.372e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 81900, Train loss: 7.923e+01, Test loss: 2.163e+02, MSE(e): 1.744e-06, MSE(pi1): 1.704e-03, MSE(pi2): 1.369e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 82000, Train loss: 7.920e+01, Test loss: 2.166e+02, MSE(e): 1.741e-06, MSE(pi1): 1.704e-03, MSE(pi2): 1.366e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 82100, Train loss: 7.917e+01, Test loss: 2.168e+02, MSE(e): 1.738e-06, MSE(pi1): 1.704e-03, MSE(pi2): 1.363e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 82200, Train loss: 7.914e+01, Test loss: 2.171e+02, MSE(e): 1.735e-06, MSE(pi1): 1.704e-03, MSE(pi2): 1.360e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 82300, Train loss: 7.910e+01, Test loss: 2.173e+02, MSE(e): 1.732e-06, MSE(pi1): 1.704e-03, MSE(pi2): 1.358e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 82400, Train loss: 7.907e+01, Test loss: 2.175e+02, MSE(e): 1.729e-06, MSE(pi1): 1.703e-03, MSE(pi2): 1.355e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 82500, Train loss: 7.904e+01, Test loss: 2.178e+02, MSE(e): 1.726e-06, MSE(pi1): 1.703e-03, MSE(pi2): 1.352e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 82600, Train loss: 7.901e+01, Test loss: 2.180e+02, MSE(e): 1.723e-06, MSE(pi1): 1.703e-03, MSE(pi2): 1.349e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 82700, Train loss: 7.898e+01, Test loss: 2.183e+02, MSE(e): 1.720e-06, MSE(pi1): 1.703e-03, MSE(pi2): 1.346e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 82800, Train loss: 7.895e+01, Test loss: 2.185e+02, MSE(e): 1.717e-06, MSE(pi1): 1.703e-03, MSE(pi2): 1.343e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 82900, Train loss: 7.892e+01, Test loss: 2.187e+02, MSE(e): 1.714e-06, MSE(pi1): 1.703e-03, MSE(pi2): 1.341e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 83000, Train loss: 7.890e+01, Test loss: 2.190e+02, MSE(e): 1.712e-06, MSE(pi1): 1.703e-03, MSE(pi2): 1.338e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 83100, Train loss: 7.886e+01, Test loss: 2.193e+02, MSE(e): 1.708e-06, MSE(pi1): 1.703e-03, MSE(pi2): 1.335e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 83200, Train loss: 7.883e+01, Test loss: 2.195e+02, MSE(e): 1.706e-06, MSE(pi1): 1.702e-03, MSE(pi2): 1.333e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 83300, Train loss: 7.881e+01, Test loss: 2.198e+02, MSE(e): 1.704e-06, MSE(pi1): 1.702e-03, MSE(pi2): 1.330e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 83400, Train loss: 7.878e+01, Test loss: 2.200e+02, MSE(e): 1.700e-06, MSE(pi1): 1.702e-03, MSE(pi2): 1.327e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 83500, Train loss: 7.875e+01, Test loss: 2.203e+02, MSE(e): 1.698e-06, MSE(pi1): 1.702e-03, MSE(pi2): 1.325e-06, MSE(pi3): 4.475e-04\n",
      "Epoch 83600, Train loss: 7.872e+01, Test loss: 2.205e+02, MSE(e): 1.695e-06, MSE(pi1): 1.702e-03, MSE(pi2): 1.322e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 83700, Train loss: 7.870e+01, Test loss: 2.208e+02, MSE(e): 1.692e-06, MSE(pi1): 1.702e-03, MSE(pi2): 1.320e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 83800, Train loss: 7.866e+01, Test loss: 2.210e+02, MSE(e): 1.689e-06, MSE(pi1): 1.702e-03, MSE(pi2): 1.317e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 83900, Train loss: 7.864e+01, Test loss: 2.213e+02, MSE(e): 1.686e-06, MSE(pi1): 1.701e-03, MSE(pi2): 1.314e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 84000, Train loss: 7.861e+01, Test loss: 2.215e+02, MSE(e): 1.684e-06, MSE(pi1): 1.701e-03, MSE(pi2): 1.312e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 84100, Train loss: 7.858e+01, Test loss: 2.218e+02, MSE(e): 1.681e-06, MSE(pi1): 1.701e-03, MSE(pi2): 1.309e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 84200, Train loss: 7.855e+01, Test loss: 2.220e+02, MSE(e): 1.678e-06, MSE(pi1): 1.701e-03, MSE(pi2): 1.306e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 84300, Train loss: 7.852e+01, Test loss: 2.222e+02, MSE(e): 1.676e-06, MSE(pi1): 1.701e-03, MSE(pi2): 1.304e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 84400, Train loss: 7.849e+01, Test loss: 2.225e+02, MSE(e): 1.672e-06, MSE(pi1): 1.701e-03, MSE(pi2): 1.301e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 84500, Train loss: 7.846e+01, Test loss: 2.228e+02, MSE(e): 1.670e-06, MSE(pi1): 1.700e-03, MSE(pi2): 1.298e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 84600, Train loss: 7.843e+01, Test loss: 2.232e+02, MSE(e): 1.666e-06, MSE(pi1): 1.700e-03, MSE(pi2): 1.295e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 84700, Train loss: 7.840e+01, Test loss: 2.235e+02, MSE(e): 1.663e-06, MSE(pi1): 1.700e-03, MSE(pi2): 1.292e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 84800, Train loss: 7.837e+01, Test loss: 2.238e+02, MSE(e): 1.661e-06, MSE(pi1): 1.700e-03, MSE(pi2): 1.290e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 84900, Train loss: 7.835e+01, Test loss: 2.241e+02, MSE(e): 1.658e-06, MSE(pi1): 1.700e-03, MSE(pi2): 1.287e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 85000, Train loss: 7.832e+01, Test loss: 2.244e+02, MSE(e): 1.655e-06, MSE(pi1): 1.700e-03, MSE(pi2): 1.285e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 85100, Train loss: 7.830e+01, Test loss: 2.247e+02, MSE(e): 1.654e-06, MSE(pi1): 1.700e-03, MSE(pi2): 1.282e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 85200, Train loss: 7.827e+01, Test loss: 2.250e+02, MSE(e): 1.651e-06, MSE(pi1): 1.700e-03, MSE(pi2): 1.280e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 85300, Train loss: 7.824e+01, Test loss: 2.253e+02, MSE(e): 1.648e-06, MSE(pi1): 1.699e-03, MSE(pi2): 1.278e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 85400, Train loss: 7.822e+01, Test loss: 2.256e+02, MSE(e): 1.646e-06, MSE(pi1): 1.699e-03, MSE(pi2): 1.276e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 85500, Train loss: 7.819e+01, Test loss: 2.260e+02, MSE(e): 1.644e-06, MSE(pi1): 1.699e-03, MSE(pi2): 1.274e-06, MSE(pi3): 4.476e-04\n",
      "Epoch 85600, Train loss: 7.817e+01, Test loss: 2.263e+02, MSE(e): 1.641e-06, MSE(pi1): 1.699e-03, MSE(pi2): 1.272e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 85700, Train loss: 7.814e+01, Test loss: 2.266e+02, MSE(e): 1.639e-06, MSE(pi1): 1.699e-03, MSE(pi2): 1.269e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 85800, Train loss: 7.811e+01, Test loss: 2.269e+02, MSE(e): 1.636e-06, MSE(pi1): 1.699e-03, MSE(pi2): 1.267e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 85900, Train loss: 7.809e+01, Test loss: 2.273e+02, MSE(e): 1.633e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.264e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 86000, Train loss: 7.806e+01, Test loss: 2.276e+02, MSE(e): 1.631e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.262e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 86100, Train loss: 7.804e+01, Test loss: 2.279e+02, MSE(e): 1.629e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.260e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 86200, Train loss: 7.801e+01, Test loss: 2.282e+02, MSE(e): 1.626e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.258e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 86300, Train loss: 7.799e+01, Test loss: 2.285e+02, MSE(e): 1.624e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.256e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 86400, Train loss: 7.796e+01, Test loss: 2.288e+02, MSE(e): 1.621e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.254e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 86500, Train loss: 7.794e+01, Test loss: 2.291e+02, MSE(e): 1.619e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.251e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 86600, Train loss: 7.791e+01, Test loss: 2.294e+02, MSE(e): 1.616e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.249e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 86700, Train loss: 7.789e+01, Test loss: 2.297e+02, MSE(e): 1.614e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.247e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 86800, Train loss: 7.786e+01, Test loss: 2.301e+02, MSE(e): 1.611e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.244e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 86900, Train loss: 7.784e+01, Test loss: 2.305e+02, MSE(e): 1.610e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.243e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 87000, Train loss: 7.782e+01, Test loss: 2.308e+02, MSE(e): 1.607e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.241e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 87100, Train loss: 7.779e+01, Test loss: 2.312e+02, MSE(e): 1.605e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.239e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 87200, Train loss: 7.776e+01, Test loss: 2.315e+02, MSE(e): 1.602e-06, MSE(pi1): 1.698e-03, MSE(pi2): 1.237e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 87300, Train loss: 7.775e+01, Test loss: 2.319e+02, MSE(e): 1.600e-06, MSE(pi1): 1.697e-03, MSE(pi2): 1.235e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 87400, Train loss: 7.772e+01, Test loss: 2.322e+02, MSE(e): 1.598e-06, MSE(pi1): 1.697e-03, MSE(pi2): 1.233e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 87500, Train loss: 7.770e+01, Test loss: 2.326e+02, MSE(e): 1.596e-06, MSE(pi1): 1.697e-03, MSE(pi2): 1.231e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 87600, Train loss: 7.768e+01, Test loss: 2.329e+02, MSE(e): 1.594e-06, MSE(pi1): 1.697e-03, MSE(pi2): 1.229e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 87700, Train loss: 7.766e+01, Test loss: 2.332e+02, MSE(e): 1.592e-06, MSE(pi1): 1.697e-03, MSE(pi2): 1.227e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 87800, Train loss: 7.763e+01, Test loss: 2.335e+02, MSE(e): 1.589e-06, MSE(pi1): 1.697e-03, MSE(pi2): 1.225e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 87900, Train loss: 7.761e+01, Test loss: 2.338e+02, MSE(e): 1.587e-06, MSE(pi1): 1.697e-03, MSE(pi2): 1.223e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 88000, Train loss: 7.758e+01, Test loss: 2.341e+02, MSE(e): 1.585e-06, MSE(pi1): 1.696e-03, MSE(pi2): 1.220e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 88100, Train loss: 7.756e+01, Test loss: 2.344e+02, MSE(e): 1.583e-06, MSE(pi1): 1.696e-03, MSE(pi2): 1.218e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 88200, Train loss: 7.755e+01, Test loss: 2.348e+02, MSE(e): 1.581e-06, MSE(pi1): 1.696e-03, MSE(pi2): 1.216e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 88300, Train loss: 7.752e+01, Test loss: 2.352e+02, MSE(e): 1.578e-06, MSE(pi1): 1.696e-03, MSE(pi2): 1.214e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 88400, Train loss: 7.750e+01, Test loss: 2.357e+02, MSE(e): 1.576e-06, MSE(pi1): 1.696e-03, MSE(pi2): 1.212e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 88500, Train loss: 7.748e+01, Test loss: 2.361e+02, MSE(e): 1.574e-06, MSE(pi1): 1.696e-03, MSE(pi2): 1.210e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 88600, Train loss: 7.745e+01, Test loss: 2.366e+02, MSE(e): 1.572e-06, MSE(pi1): 1.696e-03, MSE(pi2): 1.208e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 88700, Train loss: 7.743e+01, Test loss: 2.371e+02, MSE(e): 1.570e-06, MSE(pi1): 1.696e-03, MSE(pi2): 1.206e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 88800, Train loss: 7.741e+01, Test loss: 2.375e+02, MSE(e): 1.568e-06, MSE(pi1): 1.696e-03, MSE(pi2): 1.204e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 88900, Train loss: 7.738e+01, Test loss: 2.380e+02, MSE(e): 1.565e-06, MSE(pi1): 1.696e-03, MSE(pi2): 1.202e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 89000, Train loss: 7.736e+01, Test loss: 2.384e+02, MSE(e): 1.563e-06, MSE(pi1): 1.696e-03, MSE(pi2): 1.200e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 89100, Train loss: 7.734e+01, Test loss: 2.388e+02, MSE(e): 1.561e-06, MSE(pi1): 1.695e-03, MSE(pi2): 1.198e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 89200, Train loss: 7.732e+01, Test loss: 2.392e+02, MSE(e): 1.559e-06, MSE(pi1): 1.695e-03, MSE(pi2): 1.196e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 89300, Train loss: 7.730e+01, Test loss: 2.397e+02, MSE(e): 1.557e-06, MSE(pi1): 1.695e-03, MSE(pi2): 1.194e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 89400, Train loss: 7.728e+01, Test loss: 2.401e+02, MSE(e): 1.555e-06, MSE(pi1): 1.695e-03, MSE(pi2): 1.192e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 89500, Train loss: 7.726e+01, Test loss: 2.406e+02, MSE(e): 1.554e-06, MSE(pi1): 1.695e-03, MSE(pi2): 1.191e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 89600, Train loss: 7.723e+01, Test loss: 2.411e+02, MSE(e): 1.550e-06, MSE(pi1): 1.695e-03, MSE(pi2): 1.188e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 89700, Train loss: 7.722e+01, Test loss: 2.416e+02, MSE(e): 1.549e-06, MSE(pi1): 1.695e-03, MSE(pi2): 1.186e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 89800, Train loss: 7.719e+01, Test loss: 2.421e+02, MSE(e): 1.546e-06, MSE(pi1): 1.695e-03, MSE(pi2): 1.184e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 89900, Train loss: 7.717e+01, Test loss: 2.427e+02, MSE(e): 1.545e-06, MSE(pi1): 1.695e-03, MSE(pi2): 1.183e-06, MSE(pi3): 4.477e-04\n",
      "Epoch 90000, Train loss: 7.715e+01, Test loss: 2.432e+02, MSE(e): 1.543e-06, MSE(pi1): 1.695e-03, MSE(pi2): 1.181e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 90100, Train loss: 7.713e+01, Test loss: 2.438e+02, MSE(e): 1.541e-06, MSE(pi1): 1.695e-03, MSE(pi2): 1.179e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 90200, Train loss: 7.711e+01, Test loss: 2.443e+02, MSE(e): 1.539e-06, MSE(pi1): 1.694e-03, MSE(pi2): 1.178e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 90300, Train loss: 7.710e+01, Test loss: 2.449e+02, MSE(e): 1.538e-06, MSE(pi1): 1.694e-03, MSE(pi2): 1.176e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 90400, Train loss: 7.707e+01, Test loss: 2.455e+02, MSE(e): 1.535e-06, MSE(pi1): 1.694e-03, MSE(pi2): 1.174e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 90500, Train loss: 7.706e+01, Test loss: 2.461e+02, MSE(e): 1.534e-06, MSE(pi1): 1.694e-03, MSE(pi2): 1.173e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 90600, Train loss: 7.704e+01, Test loss: 2.467e+02, MSE(e): 1.532e-06, MSE(pi1): 1.694e-03, MSE(pi2): 1.171e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 90700, Train loss: 7.701e+01, Test loss: 2.472e+02, MSE(e): 1.529e-06, MSE(pi1): 1.694e-03, MSE(pi2): 1.169e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 90800, Train loss: 7.699e+01, Test loss: 2.477e+02, MSE(e): 1.528e-06, MSE(pi1): 1.694e-03, MSE(pi2): 1.167e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 90900, Train loss: 7.698e+01, Test loss: 2.483e+02, MSE(e): 1.526e-06, MSE(pi1): 1.694e-03, MSE(pi2): 1.166e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 91000, Train loss: 7.696e+01, Test loss: 2.489e+02, MSE(e): 1.524e-06, MSE(pi1): 1.694e-03, MSE(pi2): 1.164e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 91100, Train loss: 7.694e+01, Test loss: 2.495e+02, MSE(e): 1.522e-06, MSE(pi1): 1.694e-03, MSE(pi2): 1.162e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 91200, Train loss: 7.692e+01, Test loss: 2.500e+02, MSE(e): 1.521e-06, MSE(pi1): 1.693e-03, MSE(pi2): 1.161e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 91300, Train loss: 7.690e+01, Test loss: 2.506e+02, MSE(e): 1.519e-06, MSE(pi1): 1.693e-03, MSE(pi2): 1.159e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 91400, Train loss: 7.689e+01, Test loss: 2.512e+02, MSE(e): 1.517e-06, MSE(pi1): 1.693e-03, MSE(pi2): 1.157e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 91500, Train loss: 7.687e+01, Test loss: 2.518e+02, MSE(e): 1.516e-06, MSE(pi1): 1.693e-03, MSE(pi2): 1.156e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 91600, Train loss: 7.685e+01, Test loss: 2.524e+02, MSE(e): 1.514e-06, MSE(pi1): 1.693e-03, MSE(pi2): 1.154e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 91700, Train loss: 7.683e+01, Test loss: 2.531e+02, MSE(e): 1.512e-06, MSE(pi1): 1.693e-03, MSE(pi2): 1.153e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 91800, Train loss: 7.681e+01, Test loss: 2.537e+02, MSE(e): 1.511e-06, MSE(pi1): 1.693e-03, MSE(pi2): 1.151e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 91900, Train loss: 7.680e+01, Test loss: 2.544e+02, MSE(e): 1.509e-06, MSE(pi1): 1.693e-03, MSE(pi2): 1.150e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 92000, Train loss: 7.678e+01, Test loss: 2.550e+02, MSE(e): 1.508e-06, MSE(pi1): 1.693e-03, MSE(pi2): 1.148e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 92100, Train loss: 7.676e+01, Test loss: 2.557e+02, MSE(e): 1.506e-06, MSE(pi1): 1.692e-03, MSE(pi2): 1.147e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 92200, Train loss: 7.675e+01, Test loss: 2.563e+02, MSE(e): 1.504e-06, MSE(pi1): 1.692e-03, MSE(pi2): 1.145e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 92300, Train loss: 7.673e+01, Test loss: 2.569e+02, MSE(e): 1.502e-06, MSE(pi1): 1.692e-03, MSE(pi2): 1.144e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 92400, Train loss: 7.671e+01, Test loss: 2.575e+02, MSE(e): 1.501e-06, MSE(pi1): 1.692e-03, MSE(pi2): 1.142e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 92500, Train loss: 7.669e+01, Test loss: 2.580e+02, MSE(e): 1.499e-06, MSE(pi1): 1.692e-03, MSE(pi2): 1.141e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 92600, Train loss: 7.668e+01, Test loss: 2.586e+02, MSE(e): 1.497e-06, MSE(pi1): 1.692e-03, MSE(pi2): 1.139e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 92700, Train loss: 7.666e+01, Test loss: 2.592e+02, MSE(e): 1.496e-06, MSE(pi1): 1.692e-03, MSE(pi2): 1.137e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 92800, Train loss: 7.664e+01, Test loss: 2.597e+02, MSE(e): 1.494e-06, MSE(pi1): 1.692e-03, MSE(pi2): 1.136e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 92900, Train loss: 7.662e+01, Test loss: 2.602e+02, MSE(e): 1.491e-06, MSE(pi1): 1.692e-03, MSE(pi2): 1.134e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 93000, Train loss: 7.660e+01, Test loss: 2.607e+02, MSE(e): 1.490e-06, MSE(pi1): 1.692e-03, MSE(pi2): 1.132e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 93100, Train loss: 7.659e+01, Test loss: 2.612e+02, MSE(e): 1.489e-06, MSE(pi1): 1.691e-03, MSE(pi2): 1.131e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 93200, Train loss: 7.657e+01, Test loss: 2.617e+02, MSE(e): 1.487e-06, MSE(pi1): 1.691e-03, MSE(pi2): 1.129e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 93300, Train loss: 7.655e+01, Test loss: 2.622e+02, MSE(e): 1.485e-06, MSE(pi1): 1.691e-03, MSE(pi2): 1.127e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 93400, Train loss: 7.654e+01, Test loss: 2.626e+02, MSE(e): 1.484e-06, MSE(pi1): 1.691e-03, MSE(pi2): 1.126e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 93500, Train loss: 7.651e+01, Test loss: 2.631e+02, MSE(e): 1.482e-06, MSE(pi1): 1.691e-03, MSE(pi2): 1.125e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 93600, Train loss: 7.650e+01, Test loss: 2.636e+02, MSE(e): 1.480e-06, MSE(pi1): 1.691e-03, MSE(pi2): 1.124e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 93700, Train loss: 7.649e+01, Test loss: 2.640e+02, MSE(e): 1.479e-06, MSE(pi1): 1.691e-03, MSE(pi2): 1.122e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 93800, Train loss: 7.647e+01, Test loss: 2.645e+02, MSE(e): 1.478e-06, MSE(pi1): 1.691e-03, MSE(pi2): 1.121e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 93900, Train loss: 7.646e+01, Test loss: 2.649e+02, MSE(e): 1.476e-06, MSE(pi1): 1.691e-03, MSE(pi2): 1.119e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 94000, Train loss: 7.644e+01, Test loss: 2.654e+02, MSE(e): 1.474e-06, MSE(pi1): 1.691e-03, MSE(pi2): 1.118e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 94100, Train loss: 7.642e+01, Test loss: 2.658e+02, MSE(e): 1.473e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.116e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 94200, Train loss: 7.640e+01, Test loss: 2.663e+02, MSE(e): 1.471e-06, MSE(pi1): 1.691e-03, MSE(pi2): 1.114e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 94300, Train loss: 7.638e+01, Test loss: 2.667e+02, MSE(e): 1.469e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.113e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 94400, Train loss: 7.637e+01, Test loss: 2.672e+02, MSE(e): 1.468e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.111e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 94500, Train loss: 7.635e+01, Test loss: 2.678e+02, MSE(e): 1.466e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.110e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 94600, Train loss: 7.633e+01, Test loss: 2.684e+02, MSE(e): 1.464e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.108e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 94700, Train loss: 7.631e+01, Test loss: 2.688e+02, MSE(e): 1.462e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.107e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 94800, Train loss: 7.630e+01, Test loss: 2.692e+02, MSE(e): 1.461e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.106e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 94900, Train loss: 7.627e+01, Test loss: 2.697e+02, MSE(e): 1.458e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.104e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 95000, Train loss: 7.626e+01, Test loss: 2.701e+02, MSE(e): 1.457e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.102e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 95100, Train loss: 7.624e+01, Test loss: 2.705e+02, MSE(e): 1.455e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.101e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 95200, Train loss: 7.622e+01, Test loss: 2.709e+02, MSE(e): 1.453e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.100e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 95300, Train loss: 7.621e+01, Test loss: 2.714e+02, MSE(e): 1.452e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.098e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 95400, Train loss: 7.618e+01, Test loss: 2.719e+02, MSE(e): 1.450e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.096e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 95500, Train loss: 7.617e+01, Test loss: 2.724e+02, MSE(e): 1.448e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.095e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 95600, Train loss: 7.615e+01, Test loss: 2.729e+02, MSE(e): 1.447e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.094e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 95700, Train loss: 7.614e+01, Test loss: 2.734e+02, MSE(e): 1.445e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.092e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 95800, Train loss: 7.612e+01, Test loss: 2.740e+02, MSE(e): 1.443e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.091e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 95900, Train loss: 7.610e+01, Test loss: 2.745e+02, MSE(e): 1.442e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.090e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 96000, Train loss: 7.609e+01, Test loss: 2.751e+02, MSE(e): 1.440e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.088e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 96100, Train loss: 7.607e+01, Test loss: 2.757e+02, MSE(e): 1.439e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.087e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 96200, Train loss: 7.605e+01, Test loss: 2.762e+02, MSE(e): 1.437e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.086e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 96300, Train loss: 7.604e+01, Test loss: 2.766e+02, MSE(e): 1.436e-06, MSE(pi1): 1.690e-03, MSE(pi2): 1.084e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 96400, Train loss: 7.603e+01, Test loss: 2.771e+02, MSE(e): 1.435e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.083e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 96500, Train loss: 7.601e+01, Test loss: 2.776e+02, MSE(e): 1.433e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.082e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 96600, Train loss: 7.599e+01, Test loss: 2.781e+02, MSE(e): 1.431e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.080e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 96700, Train loss: 7.597e+01, Test loss: 2.786e+02, MSE(e): 1.429e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.079e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 96800, Train loss: 7.596e+01, Test loss: 2.791e+02, MSE(e): 1.428e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.078e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 96900, Train loss: 7.594e+01, Test loss: 2.797e+02, MSE(e): 1.426e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.077e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 97000, Train loss: 7.592e+01, Test loss: 2.802e+02, MSE(e): 1.425e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.075e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 97100, Train loss: 7.590e+01, Test loss: 2.808e+02, MSE(e): 1.423e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.074e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 97200, Train loss: 7.589e+01, Test loss: 2.813e+02, MSE(e): 1.421e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.073e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 97300, Train loss: 7.588e+01, Test loss: 2.819e+02, MSE(e): 1.420e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.071e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 97400, Train loss: 7.586e+01, Test loss: 2.825e+02, MSE(e): 1.419e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.070e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 97500, Train loss: 7.583e+01, Test loss: 2.831e+02, MSE(e): 1.415e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.068e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 97600, Train loss: 7.582e+01, Test loss: 2.837e+02, MSE(e): 1.415e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.067e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 97700, Train loss: 7.580e+01, Test loss: 2.843e+02, MSE(e): 1.413e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.065e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 97800, Train loss: 7.579e+01, Test loss: 2.849e+02, MSE(e): 1.412e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.064e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 97900, Train loss: 7.577e+01, Test loss: 2.856e+02, MSE(e): 1.410e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.063e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 98000, Train loss: 7.576e+01, Test loss: 2.863e+02, MSE(e): 1.409e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.061e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 98100, Train loss: 7.574e+01, Test loss: 2.870e+02, MSE(e): 1.407e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.060e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 98200, Train loss: 7.573e+01, Test loss: 2.876e+02, MSE(e): 1.406e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.059e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 98300, Train loss: 7.572e+01, Test loss: 2.883e+02, MSE(e): 1.405e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.058e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 98400, Train loss: 7.570e+01, Test loss: 2.890e+02, MSE(e): 1.403e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.056e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 98500, Train loss: 7.569e+01, Test loss: 2.897e+02, MSE(e): 1.402e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.055e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 98600, Train loss: 7.567e+01, Test loss: 2.904e+02, MSE(e): 1.401e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.054e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 98700, Train loss: 7.566e+01, Test loss: 2.912e+02, MSE(e): 1.399e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.053e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 98800, Train loss: 7.565e+01, Test loss: 2.921e+02, MSE(e): 1.398e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.052e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 98900, Train loss: 7.564e+01, Test loss: 2.929e+02, MSE(e): 1.397e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.050e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 99000, Train loss: 7.562e+01, Test loss: 2.937e+02, MSE(e): 1.395e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.049e-06, MSE(pi3): 4.479e-04\n",
      "Epoch 99100, Train loss: 7.560e+01, Test loss: 2.945e+02, MSE(e): 1.394e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.048e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 99200, Train loss: 7.559e+01, Test loss: 2.952e+02, MSE(e): 1.393e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.047e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 99300, Train loss: 7.557e+01, Test loss: 2.959e+02, MSE(e): 1.391e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.045e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 99400, Train loss: 7.555e+01, Test loss: 2.967e+02, MSE(e): 1.389e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.044e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 99500, Train loss: 7.554e+01, Test loss: 2.975e+02, MSE(e): 1.388e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.043e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 99600, Train loss: 7.553e+01, Test loss: 2.983e+02, MSE(e): 1.386e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.041e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 99700, Train loss: 7.551e+01, Test loss: 2.991e+02, MSE(e): 1.385e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.040e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 99800, Train loss: 7.550e+01, Test loss: 3.000e+02, MSE(e): 1.384e-06, MSE(pi1): 1.688e-03, MSE(pi2): 1.039e-06, MSE(pi3): 4.478e-04\n",
      "Epoch 99900, Train loss: 7.548e+01, Test loss: 3.009e+02, MSE(e): 1.382e-06, MSE(pi1): 1.689e-03, MSE(pi2): 1.037e-06, MSE(pi3): 4.477e-04\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 9000\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 100\n",
    "\n",
    "second_lr = 1e-4\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
