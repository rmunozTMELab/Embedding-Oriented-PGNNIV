{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from model.baseline_model import BaselineNonlinearModel\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from vecopsciml.operators.zero_order import Mx, My"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear_100_0\n",
      "Folder successfully created at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear_100_0/baseline_model_100\n"
     ]
    }
   ],
   "source": [
    "data_name = 'non_linear_100_0'\n",
    "n_modes = 100\n",
    "\n",
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/', data_name, data_name) + '.pkl'\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/', data_name)\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/', data_name, 'baseline_model_') + str(n_modes)\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear_100_0/non_linear_100_0.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data splitting in train/test\n",
    "X = torch.tensor(dataset['X_train'], dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(dataset['y_train'], dtype=torch.float32).unsqueeze(1)\n",
    "K = torch.tensor(dataset['k_train'], dtype=torch.float32).unsqueeze(1)\n",
    "f = torch.tensor(dataset['f_train'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X, y, K, f, test_size=0.3, random_state=42)\n",
    "\n",
    "# Data processing and adequacy with our TensOps library\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "# Loading and processing validation data\n",
    "X_val = torch.tensor(dataset['X_val'], dtype=torch.float32).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 1.020e+09, Test loss: 6.466e+09, MSE(e): 1.003e+02, MSE(pi1): 1.639e+03, MSE(pi2): 3.952e+01, MSE(pi3): 4.686e+00\n",
      "Epoch 100, Train loss: 3.641e+07, Test loss: 4.603e+07, MSE(e): 3.604e+00, MSE(pi1): 1.406e+01, MSE(pi2): 1.446e+00, MSE(pi3): 2.237e+00\n",
      "Epoch 200, Train loss: 3.069e+07, Test loss: 3.677e+07, MSE(e): 3.052e+00, MSE(pi1): 6.044e+00, MSE(pi2): 1.390e+00, MSE(pi3): 1.041e+00\n",
      "Epoch 300, Train loss: 3.050e+07, Test loss: 3.654e+07, MSE(e): 3.037e+00, MSE(pi1): 4.633e+00, MSE(pi2): 1.387e+00, MSE(pi3): 7.755e-01\n",
      "Epoch 400, Train loss: 3.035e+07, Test loss: 3.642e+07, MSE(e): 3.027e+00, MSE(pi1): 3.001e+00, MSE(pi2): 1.386e+00, MSE(pi3): 5.201e-01\n",
      "Epoch 500, Train loss: 2.667e+07, Test loss: 3.262e+07, MSE(e): 2.479e+00, MSE(pi1): 1.794e+02, MSE(pi2): 1.148e+00, MSE(pi3): 8.705e-01\n",
      "Epoch 600, Train loss: 6.616e+06, Test loss: 7.614e+06, MSE(e): 6.355e-01, MSE(pi1): 1.908e+01, MSE(pi2): 3.985e-01, MSE(pi3): 6.972e-01\n",
      "Epoch 700, Train loss: 5.583e+06, Test loss: 6.274e+06, MSE(e): 5.440e-01, MSE(pi1): 9.066e+00, MSE(pi2): 3.618e-01, MSE(pi3): 5.244e-01\n",
      "Epoch 800, Train loss: 5.400e+06, Test loss: 5.774e+06, MSE(e): 5.284e-01, MSE(pi1): 6.859e+00, MSE(pi2): 3.558e-01, MSE(pi3): 4.740e-01\n",
      "Epoch 900, Train loss: 5.020e+06, Test loss: 5.545e+06, MSE(e): 4.924e-01, MSE(pi1): 5.346e+00, MSE(pi2): 3.390e-01, MSE(pi3): 4.221e-01\n",
      "Epoch 1000, Train loss: 4.902e+06, Test loss: 5.383e+06, MSE(e): 4.818e-01, MSE(pi1): 4.605e+00, MSE(pi2): 3.342e-01, MSE(pi3): 3.766e-01\n",
      "Epoch 1100, Train loss: 4.823e+06, Test loss: 5.288e+06, MSE(e): 4.747e-01, MSE(pi1): 4.075e+00, MSE(pi2): 3.307e-01, MSE(pi3): 3.428e-01\n",
      "Epoch 1200, Train loss: 4.761e+06, Test loss: 5.203e+06, MSE(e): 4.692e-01, MSE(pi1): 3.708e+00, MSE(pi2): 3.282e-01, MSE(pi3): 3.164e-01\n",
      "Epoch 1300, Train loss: 4.714e+06, Test loss: 5.138e+06, MSE(e): 4.649e-01, MSE(pi1): 3.506e+00, MSE(pi2): 3.260e-01, MSE(pi3): 2.970e-01\n",
      "Epoch 1400, Train loss: 4.663e+06, Test loss: 5.085e+06, MSE(e): 4.601e-01, MSE(pi1): 3.391e+00, MSE(pi2): 3.238e-01, MSE(pi3): 2.788e-01\n",
      "Epoch 1500, Train loss: 4.606e+06, Test loss: 5.021e+06, MSE(e): 4.543e-01, MSE(pi1): 3.665e+00, MSE(pi2): 3.206e-01, MSE(pi3): 2.601e-01\n",
      "Epoch 1600, Train loss: 4.506e+06, Test loss: 4.922e+06, MSE(e): 4.432e-01, MSE(pi1): 4.876e+00, MSE(pi2): 3.130e-01, MSE(pi3): 2.487e-01\n",
      "Epoch 1700, Train loss: 4.236e+06, Test loss: 4.657e+06, MSE(e): 4.117e-01, MSE(pi1): 9.358e+00, MSE(pi2): 2.852e-01, MSE(pi3): 2.444e-01\n",
      "Epoch 1800, Train loss: 3.567e+06, Test loss: 4.056e+06, MSE(e): 3.455e-01, MSE(pi1): 8.848e+00, MSE(pi2): 2.167e-01, MSE(pi3): 2.334e-01\n",
      "Epoch 1900, Train loss: 2.861e+06, Test loss: 3.458e+06, MSE(e): 2.789e-01, MSE(pi1): 5.269e+00, MSE(pi2): 1.626e-01, MSE(pi3): 1.842e-01\n",
      "Epoch 2000, Train loss: 2.399e+06, Test loss: 3.042e+06, MSE(e): 2.349e-01, MSE(pi1): 3.407e+00, MSE(pi2): 1.397e-01, MSE(pi3): 1.548e-01\n",
      "Epoch 2100, Train loss: 2.132e+06, Test loss: 2.802e+06, MSE(e): 2.092e-01, MSE(pi1): 2.633e+00, MSE(pi2): 1.311e-01, MSE(pi3): 1.346e-01\n",
      "Epoch 2200, Train loss: 1.964e+06, Test loss: 2.648e+06, MSE(e): 1.927e-01, MSE(pi1): 2.396e+00, MSE(pi2): 1.262e-01, MSE(pi3): 1.246e-01\n",
      "Epoch 2300, Train loss: 1.887e+06, Test loss: 2.601e+06, MSE(e): 1.851e-01, MSE(pi1): 2.357e+00, MSE(pi2): 1.248e-01, MSE(pi3): 1.221e-01\n",
      "Epoch 2400, Train loss: 1.784e+06, Test loss: 2.505e+06, MSE(e): 1.749e-01, MSE(pi1): 2.275e+00, MSE(pi2): 1.212e-01, MSE(pi3): 1.212e-01\n",
      "Epoch 2500, Train loss: 1.581e+06, Test loss: 2.288e+06, MSE(e): 1.543e-01, MSE(pi1): 2.669e+00, MSE(pi2): 1.066e-01, MSE(pi3): 1.180e-01\n",
      "Epoch 2600, Train loss: 9.024e+05, Test loss: 1.807e+06, MSE(e): 8.636e-02, MSE(pi1): 2.672e+00, MSE(pi2): 4.753e-02, MSE(pi3): 1.202e-01\n",
      "Epoch 2700, Train loss: 5.173e+05, Test loss: 1.147e+06, MSE(e): 4.851e-02, MSE(pi1): 2.049e+00, MSE(pi2): 2.295e-02, MSE(pi3): 1.173e-01\n",
      "Epoch 2800, Train loss: 3.281e+05, Test loss: 8.665e+05, MSE(e): 3.027e-02, MSE(pi1): 1.495e+00, MSE(pi2): 1.351e-02, MSE(pi3): 1.040e-01\n",
      "Epoch 2900, Train loss: 2.350e+05, Test loss: 6.872e+05, MSE(e): 2.165e-02, MSE(pi1): 9.806e-01, MSE(pi2): 9.515e-03, MSE(pi3): 8.735e-02\n",
      "Epoch 3000, Train loss: 2.100e+05, Test loss: 5.912e+05, MSE(e): 1.938e-02, MSE(pi1): 8.123e-01, MSE(pi2): 8.682e-03, MSE(pi3): 8.062e-02\n",
      "Epoch 3100, Train loss: 1.307e+05, Test loss: 4.624e+05, MSE(e): 1.162e-02, MSE(pi1): 6.798e-01, MSE(pi2): 5.445e-03, MSE(pi3): 7.662e-02\n",
      "Epoch 3200, Train loss: 1.075e+05, Test loss: 4.021e+05, MSE(e): 9.417e-03, MSE(pi1): 5.900e-01, MSE(pi2): 4.709e-03, MSE(pi3): 7.434e-02\n",
      "Epoch 3300, Train loss: 1.028e+05, Test loss: 3.925e+05, MSE(e): 9.022e-03, MSE(pi1): 5.247e-01, MSE(pi2): 4.947e-03, MSE(pi3): 7.330e-02\n",
      "Epoch 3400, Train loss: 7.805e+04, Test loss: 3.286e+05, MSE(e): 6.617e-03, MSE(pi1): 4.699e-01, MSE(pi2): 3.759e-03, MSE(pi3): 7.183e-02\n",
      "Epoch 3500, Train loss: 6.916e+04, Test loss: 3.100e+05, MSE(e): 5.775e-03, MSE(pi1): 4.313e-01, MSE(pi2): 3.469e-03, MSE(pi3): 7.096e-02\n",
      "Epoch 3600, Train loss: 6.177e+04, Test loss: 2.919e+05, MSE(e): 5.074e-03, MSE(pi1): 3.999e-01, MSE(pi2): 3.211e-03, MSE(pi3): 7.024e-02\n",
      "Epoch 3700, Train loss: 5.644e+04, Test loss: 3.013e+05, MSE(e): 4.573e-03, MSE(pi1): 3.750e-01, MSE(pi2): 3.012e-03, MSE(pi3): 6.961e-02\n",
      "Epoch 3800, Train loss: 1.204e+05, Test loss: 3.278e+05, MSE(e): 1.100e-02, MSE(pi1): 3.510e-01, MSE(pi2): 6.807e-03, MSE(pi3): 6.950e-02\n",
      "Epoch 3900, Train loss: 7.873e+04, Test loss: 3.298e+05, MSE(e): 6.855e-03, MSE(pi1): 3.319e-01, MSE(pi2): 4.097e-03, MSE(pi3): 6.854e-02\n",
      "Epoch 4000, Train loss: 4.480e+04, Test loss: 2.787e+05, MSE(e): 3.486e-03, MSE(pi1): 3.176e-01, MSE(pi2): 2.553e-03, MSE(pi3): 6.766e-02\n",
      "Epoch 4100, Train loss: 5.690e+04, Test loss: 2.841e+05, MSE(e): 4.713e-03, MSE(pi1): 3.053e-01, MSE(pi2): 3.037e-03, MSE(pi3): 6.716e-02\n",
      "Epoch 4200, Train loss: 4.035e+04, Test loss: 2.755e+05, MSE(e): 3.078e-03, MSE(pi1): 2.906e-01, MSE(pi2): 2.364e-03, MSE(pi3): 6.661e-02\n",
      "Epoch 4300, Train loss: 3.902e+04, Test loss: 2.737e+05, MSE(e): 2.959e-03, MSE(pi1): 2.812e-01, MSE(pi2): 2.301e-03, MSE(pi3): 6.613e-02\n",
      "Epoch 4400, Train loss: 9.726e+04, Test loss: 4.386e+05, MSE(e): 8.796e-03, MSE(pi1): 2.654e-01, MSE(pi2): 4.957e-03, MSE(pi3): 6.647e-02\n",
      "Epoch 4500, Train loss: 3.625e+04, Test loss: 2.876e+05, MSE(e): 2.712e-03, MSE(pi1): 2.608e-01, MSE(pi2): 2.163e-03, MSE(pi3): 6.519e-02\n",
      "Epoch 4600, Train loss: 3.490e+04, Test loss: 2.754e+05, MSE(e): 2.591e-03, MSE(pi1): 2.523e-01, MSE(pi2): 2.093e-03, MSE(pi3): 6.473e-02\n",
      "Epoch 4700, Train loss: 3.467e+04, Test loss: 2.742e+05, MSE(e): 2.575e-03, MSE(pi1): 2.485e-01, MSE(pi2): 2.075e-03, MSE(pi3): 6.433e-02\n",
      "Epoch 4800, Train loss: 3.330e+04, Test loss: 2.670e+05, MSE(e): 2.450e-03, MSE(pi1): 2.405e-01, MSE(pi2): 2.002e-03, MSE(pi3): 6.386e-02\n",
      "Epoch 4900, Train loss: 3.314e+04, Test loss: 3.038e+05, MSE(e): 2.444e-03, MSE(pi1): 2.351e-01, MSE(pi2): 1.988e-03, MSE(pi3): 6.343e-02\n",
      "Epoch 5000, Train loss: 3.182e+04, Test loss: 2.845e+05, MSE(e): 2.324e-03, MSE(pi1): 2.283e-01, MSE(pi2): 1.908e-03, MSE(pi3): 6.290e-02\n",
      "Epoch 5100, Train loss: 3.097e+04, Test loss: 2.739e+05, MSE(e): 2.249e-03, MSE(pi1): 2.232e-01, MSE(pi2): 1.857e-03, MSE(pi3): 6.242e-02\n",
      "Epoch 5200, Train loss: 3.115e+04, Test loss: 3.006e+05, MSE(e): 2.275e-03, MSE(pi1): 2.213e-01, MSE(pi2): 1.863e-03, MSE(pi3): 6.192e-02\n",
      "Epoch 5300, Train loss: 2.989e+04, Test loss: 2.864e+05, MSE(e): 2.160e-03, MSE(pi1): 2.149e-01, MSE(pi2): 1.781e-03, MSE(pi3): 6.140e-02\n",
      "Epoch 5400, Train loss: 3.006e+04, Test loss: 2.947e+05, MSE(e): 2.185e-03, MSE(pi1): 2.124e-01, MSE(pi2): 1.776e-03, MSE(pi3): 6.093e-02\n",
      "Epoch 5500, Train loss: 3.019e+04, Test loss: 3.446e+05, MSE(e): 2.205e-03, MSE(pi1): 2.075e-01, MSE(pi2): 1.775e-03, MSE(pi3): 6.060e-02\n",
      "Epoch 5600, Train loss: 2.823e+04, Test loss: 2.890e+05, MSE(e): 2.020e-03, MSE(pi1): 2.049e-01, MSE(pi2): 1.664e-03, MSE(pi3): 5.976e-02\n",
      "Epoch 5700, Train loss: 5.461e+04, Test loss: 3.179e+05, MSE(e): 4.658e-03, MSE(pi1): 2.094e-01, MSE(pi2): 2.846e-03, MSE(pi3): 5.927e-02\n",
      "Epoch 5800, Train loss: 4.324e+04, Test loss: 2.869e+05, MSE(e): 3.536e-03, MSE(pi1): 2.032e-01, MSE(pi2): 2.528e-03, MSE(pi3): 5.849e-02\n",
      "Epoch 5900, Train loss: 2.661e+04, Test loss: 2.903e+05, MSE(e): 1.885e-03, MSE(pi1): 1.961e-01, MSE(pi2): 1.548e-03, MSE(pi3): 5.798e-02\n",
      "Epoch 6000, Train loss: 2.672e+04, Test loss: 3.171e+05, MSE(e): 1.904e-03, MSE(pi1): 1.953e-01, MSE(pi2): 1.530e-03, MSE(pi3): 5.732e-02\n",
      "Epoch 6100, Train loss: 2.898e+04, Test loss: 3.238e+05, MSE(e): 2.139e-03, MSE(pi1): 1.904e-01, MSE(pi2): 1.625e-03, MSE(pi3): 5.686e-02\n",
      "Epoch 6200, Train loss: 2.511e+04, Test loss: 3.021e+05, MSE(e): 1.761e-03, MSE(pi1): 1.891e-01, MSE(pi2): 1.430e-03, MSE(pi3): 5.602e-02\n",
      "Epoch 6300, Train loss: 2.506e+04, Test loss: 3.225e+05, MSE(e): 1.766e-03, MSE(pi1): 1.875e-01, MSE(pi2): 1.409e-03, MSE(pi3): 5.533e-02\n",
      "Epoch 6400, Train loss: 2.483e+04, Test loss: 3.173e+05, MSE(e): 1.750e-03, MSE(pi1): 1.865e-01, MSE(pi2): 1.374e-03, MSE(pi3): 5.457e-02\n",
      "Epoch 6500, Train loss: 2.595e+04, Test loss: 3.315e+05, MSE(e): 1.863e-03, MSE(pi1): 1.903e-01, MSE(pi2): 1.403e-03, MSE(pi3): 5.415e-02\n",
      "Epoch 6600, Train loss: 2.437e+04, Test loss: 3.418e+05, MSE(e): 1.723e-03, MSE(pi1): 1.834e-01, MSE(pi2): 1.312e-03, MSE(pi3): 5.309e-02\n",
      "Epoch 6700, Train loss: 2.267e+04, Test loss: 3.194e+05, MSE(e): 1.563e-03, MSE(pi1): 1.809e-01, MSE(pi2): 1.222e-03, MSE(pi3): 5.237e-02\n",
      "Epoch 6800, Train loss: 2.215e+04, Test loss: 3.233e+05, MSE(e): 1.521e-03, MSE(pi1): 1.787e-01, MSE(pi2): 1.175e-03, MSE(pi3): 5.154e-02\n",
      "Epoch 6900, Train loss: 2.524e+04, Test loss: 3.242e+05, MSE(e): 1.788e-03, MSE(pi1): 2.269e-01, MSE(pi2): 1.310e-03, MSE(pi3): 5.091e-02\n",
      "Epoch 7000, Train loss: 2.532e+04, Test loss: 3.408e+05, MSE(e): 1.837e-03, MSE(pi1): 1.941e-01, MSE(pi2): 1.283e-03, MSE(pi3): 5.013e-02\n",
      "Epoch 7100, Train loss: 2.045e+04, Test loss: 3.277e+05, MSE(e): 1.380e-03, MSE(pi1): 1.745e-01, MSE(pi2): 1.030e-03, MSE(pi3): 4.904e-02\n",
      "Epoch 7200, Train loss: 2.041e+04, Test loss: 3.541e+05, MSE(e): 1.370e-03, MSE(pi1): 1.906e-01, MSE(pi2): 9.937e-04, MSE(pi3): 4.808e-02\n",
      "Epoch 7300, Train loss: 1.925e+04, Test loss: 3.329e+05, MSE(e): 1.282e-03, MSE(pi1): 1.703e-01, MSE(pi2): 9.257e-04, MSE(pi3): 4.724e-02\n",
      "Epoch 7400, Train loss: 1.885e+04, Test loss: 3.560e+05, MSE(e): 1.251e-03, MSE(pi1): 1.705e-01, MSE(pi2): 8.837e-04, MSE(pi3): 4.631e-02\n",
      "Epoch 7500, Train loss: 1.959e+04, Test loss: 3.421e+05, MSE(e): 1.281e-03, MSE(pi1): 2.217e-01, MSE(pi2): 8.804e-04, MSE(pi3): 4.565e-02\n",
      "Epoch 7600, Train loss: 2.436e+04, Test loss: 3.602e+05, MSE(e): 1.566e-03, MSE(pi1): 4.181e-01, MSE(pi2): 1.161e-03, MSE(pi3): 4.512e-02\n",
      "Epoch 7700, Train loss: 1.963e+04, Test loss: 3.760e+05, MSE(e): 1.287e-03, MSE(pi1): 2.384e-01, MSE(pi2): 8.322e-04, MSE(pi3): 4.375e-02\n",
      "Epoch 7800, Train loss: 1.699e+04, Test loss: 3.489e+05, MSE(e): 1.101e-03, MSE(pi1): 1.734e-01, MSE(pi2): 7.261e-04, MSE(pi3): 4.248e-02\n",
      "Epoch 7900, Train loss: 5.508e+04, Test loss: 4.666e+05, MSE(e): 4.726e-03, MSE(pi1): 3.329e-01, MSE(pi2): 2.622e-03, MSE(pi3): 4.496e-02\n",
      "Epoch 8000, Train loss: 2.781e+04, Test loss: 3.975e+05, MSE(e): 2.078e-03, MSE(pi1): 2.795e-01, MSE(pi2): 1.261e-03, MSE(pi3): 4.238e-02\n",
      "Epoch 8100, Train loss: 6.008e+04, Test loss: 3.821e+05, MSE(e): 5.116e-03, MSE(pi1): 4.821e-01, MSE(pi2): 2.876e-03, MSE(pi3): 4.097e-02\n",
      "Epoch 8200, Train loss: 2.326e+04, Test loss: 3.589e+05, MSE(e): 1.681e-03, MSE(pi1): 2.527e-01, MSE(pi2): 9.577e-04, MSE(pi3): 3.917e-02\n",
      "Epoch 8300, Train loss: 3.106e+04, Test loss: 4.348e+05, MSE(e): 2.511e-03, MSE(pi1): 2.131e-01, MSE(pi2): 1.373e-03, MSE(pi3): 3.822e-02\n",
      "Epoch 8400, Train loss: 2.374e+04, Test loss: 3.770e+05, MSE(e): 1.567e-03, MSE(pi1): 4.235e-01, MSE(pi2): 1.000e-03, MSE(pi3): 3.830e-02\n",
      "Epoch 8500, Train loss: 2.722e+04, Test loss: 3.838e+05, MSE(e): 2.018e-03, MSE(pi1): 3.421e-01, MSE(pi2): 1.111e-03, MSE(pi3): 3.617e-02\n",
      "Epoch 8600, Train loss: 1.768e+04, Test loss: 4.005e+05, MSE(e): 9.821e-04, MSE(pi1): 4.318e-01, MSE(pi2): 5.699e-04, MSE(pi3): 3.538e-02\n",
      "Epoch 8700, Train loss: 2.128e+04, Test loss: 3.997e+05, MSE(e): 1.352e-03, MSE(pi1): 3.984e-01, MSE(pi2): 8.923e-04, MSE(pi3): 3.779e-02\n",
      "Epoch 8800, Train loss: 1.889e+04, Test loss: 3.967e+05, MSE(e): 9.021e-04, MSE(pi1): 5.415e-01, MSE(pi2): 5.291e-04, MSE(pi3): 4.457e-02\n",
      "Epoch 8900, Train loss: 1.239e+04, Test loss: 3.932e+05, MSE(e): 7.016e-04, MSE(pi1): 1.569e-01, MSE(pi2): 3.795e-04, MSE(pi3): 3.806e-02\n",
      "Epoch 9000, Train loss: 1.026e+05, Test loss: 4.329e+05, MSE(e): 9.581e-03, MSE(pi1): 3.054e-01, MSE(pi2): 5.337e-03, MSE(pi3): 3.763e-02\n",
      "Epoch 9100, Train loss: 1.091e+04, Test loss: 3.980e+05, MSE(e): 6.202e-04, MSE(pi1): 1.290e-01, MSE(pi2): 3.356e-04, MSE(pi3): 3.416e-02\n",
      "Epoch 9200, Train loss: 1.586e+04, Test loss: 4.191e+05, MSE(e): 1.100e-03, MSE(pi1): 1.545e-01, MSE(pi2): 5.858e-04, MSE(pi3): 3.315e-02\n",
      "Epoch 9300, Train loss: 2.598e+04, Test loss: 4.830e+05, MSE(e): 2.097e-03, MSE(pi1): 1.761e-01, MSE(pi2): 1.099e-03, MSE(pi3): 3.249e-02\n",
      "Epoch 9400, Train loss: 1.430e+04, Test loss: 4.087e+05, MSE(e): 8.863e-04, MSE(pi1): 2.327e-01, MSE(pi2): 4.724e-04, MSE(pi3): 3.114e-02\n",
      "Epoch 9500, Train loss: 3.735e+04, Test loss: 4.652e+05, MSE(e): 2.131e-03, MSE(pi1): 1.195e+00, MSE(pi2): 1.097e-03, MSE(pi3): 4.083e-02\n",
      "Epoch 9600, Train loss: 4.872e+06, Test loss: 5.582e+06, MSE(e): 4.802e-01, MSE(pi1): 5.197e+00, MSE(pi2): 3.374e-01, MSE(pi3): 1.801e-01\n",
      "Epoch 9700, Train loss: 4.545e+06, Test loss: 5.124e+06, MSE(e): 4.503e-01, MSE(pi1): 2.437e+00, MSE(pi2): 3.212e-01, MSE(pi3): 1.734e-01\n",
      "Epoch 9800, Train loss: 4.466e+06, Test loss: 5.065e+06, MSE(e): 4.430e-01, MSE(pi1): 1.837e+00, MSE(pi2): 3.162e-01, MSE(pi3): 1.681e-01\n",
      "Epoch 9900, Train loss: 4.412e+06, Test loss: 5.083e+06, MSE(e): 4.379e-01, MSE(pi1): 1.636e+00, MSE(pi2): 3.123e-01, MSE(pi3): 1.654e-01\n",
      "Epoch 10000, Train loss: 4.359e+06, Test loss: 5.136e+06, MSE(e): 4.327e-01, MSE(pi1): 1.524e+00, MSE(pi2): 3.078e-01, MSE(pi3): 1.632e-01\n",
      "Epoch 10100, Train loss: 3.949e+06, Test loss: 4.863e+06, MSE(e): 3.912e-01, MSE(pi1): 2.102e+00, MSE(pi2): 2.650e-01, MSE(pi3): 1.576e-01\n",
      "Epoch 10200, Train loss: 2.628e+06, Test loss: 3.751e+06, MSE(e): 2.583e-01, MSE(pi1): 2.930e+00, MSE(pi2): 1.724e-01, MSE(pi3): 1.526e-01\n",
      "Epoch 10300, Train loss: 2.176e+06, Test loss: 3.191e+06, MSE(e): 2.143e-01, MSE(pi1): 1.863e+00, MSE(pi2): 1.477e-01, MSE(pi3): 1.379e-01\n",
      "Epoch 10400, Train loss: 1.957e+06, Test loss: 2.865e+06, MSE(e): 1.928e-01, MSE(pi1): 1.541e+00, MSE(pi2): 1.351e-01, MSE(pi3): 1.324e-01\n",
      "Epoch 10500, Train loss: 2.152e+06, Test loss: 3.345e+06, MSE(e): 2.125e-01, MSE(pi1): 1.451e+00, MSE(pi2): 1.402e-01, MSE(pi3): 1.292e-01\n",
      "Epoch 10600, Train loss: 1.752e+06, Test loss: 2.542e+06, MSE(e): 1.727e-01, MSE(pi1): 1.266e+00, MSE(pi2): 1.230e-01, MSE(pi3): 1.284e-01\n",
      "Epoch 10700, Train loss: 1.696e+06, Test loss: 2.523e+06, MSE(e): 1.672e-01, MSE(pi1): 1.138e+00, MSE(pi2): 1.198e-01, MSE(pi3): 1.269e-01\n",
      "Epoch 10800, Train loss: 1.647e+06, Test loss: 2.544e+06, MSE(e): 1.625e-01, MSE(pi1): 1.017e+00, MSE(pi2): 1.169e-01, MSE(pi3): 1.244e-01\n",
      "Epoch 10900, Train loss: 1.631e+06, Test loss: 2.621e+06, MSE(e): 1.610e-01, MSE(pi1): 9.017e-01, MSE(pi2): 1.155e-01, MSE(pi3): 1.217e-01\n",
      "Epoch 11000, Train loss: 1.560e+06, Test loss: 2.639e+06, MSE(e): 1.540e-01, MSE(pi1): 8.325e-01, MSE(pi2): 1.112e-01, MSE(pi3): 1.176e-01\n",
      "Epoch 11100, Train loss: 1.519e+06, Test loss: 2.720e+06, MSE(e): 1.500e-01, MSE(pi1): 7.673e-01, MSE(pi2): 1.083e-01, MSE(pi3): 1.144e-01\n",
      "Epoch 11200, Train loss: 1.496e+06, Test loss: 2.882e+06, MSE(e): 1.477e-01, MSE(pi1): 7.148e-01, MSE(pi2): 1.055e-01, MSE(pi3): 1.114e-01\n",
      "Epoch 11300, Train loss: 1.431e+06, Test loss: 2.971e+06, MSE(e): 1.413e-01, MSE(pi1): 6.597e-01, MSE(pi2): 1.013e-01, MSE(pi3): 1.092e-01\n",
      "Epoch 11400, Train loss: 1.660e+06, Test loss: 3.483e+06, MSE(e): 1.642e-01, MSE(pi1): 6.584e-01, MSE(pi2): 1.075e-01, MSE(pi3): 1.052e-01\n",
      "Epoch 11500, Train loss: 1.135e+06, Test loss: 2.836e+06, MSE(e): 1.118e-01, MSE(pi1): 5.878e-01, MSE(pi2): 8.022e-02, MSE(pi3): 1.043e-01\n",
      "Epoch 11600, Train loss: 1.034e+06, Test loss: 2.524e+06, MSE(e): 1.018e-01, MSE(pi1): 5.515e-01, MSE(pi2): 7.220e-02, MSE(pi3): 1.014e-01\n",
      "Epoch 11700, Train loss: 8.443e+05, Test loss: 2.231e+06, MSE(e): 8.294e-02, MSE(pi1): 4.985e-01, MSE(pi2): 5.913e-02, MSE(pi3): 9.877e-02\n",
      "Epoch 11800, Train loss: 5.925e+05, Test loss: 1.431e+06, MSE(e): 5.787e-02, MSE(pi1): 4.385e-01, MSE(pi2): 4.120e-02, MSE(pi3): 9.415e-02\n",
      "Epoch 11900, Train loss: 4.383e+05, Test loss: 1.257e+06, MSE(e): 4.251e-02, MSE(pi1): 3.995e-01, MSE(pi2): 3.004e-02, MSE(pi3): 9.103e-02\n",
      "Epoch 12000, Train loss: 1.965e+05, Test loss: 6.450e+05, MSE(e): 1.841e-02, MSE(pi1): 3.521e-01, MSE(pi2): 1.304e-02, MSE(pi3): 8.920e-02\n",
      "Epoch 12100, Train loss: 2.067e+05, Test loss: 5.359e+05, MSE(e): 1.946e-02, MSE(pi1): 3.361e-01, MSE(pi2): 1.212e-02, MSE(pi3): 8.726e-02\n",
      "Epoch 12200, Train loss: 1.005e+05, Test loss: 3.656e+05, MSE(e): 8.873e-03, MSE(pi1): 3.114e-01, MSE(pi2): 6.618e-03, MSE(pi3): 8.598e-02\n",
      "Epoch 12300, Train loss: 9.056e+04, Test loss: 3.234e+05, MSE(e): 7.905e-03, MSE(pi1): 3.002e-01, MSE(pi2): 5.982e-03, MSE(pi3): 8.499e-02\n",
      "Epoch 12400, Train loss: 7.670e+04, Test loss: 3.088e+05, MSE(e): 6.544e-03, MSE(pi1): 2.909e-01, MSE(pi2): 5.057e-03, MSE(pi3): 8.351e-02\n",
      "Epoch 12500, Train loss: 6.954e+04, Test loss: 2.897e+05, MSE(e): 5.847e-03, MSE(pi1): 2.824e-01, MSE(pi2): 4.580e-03, MSE(pi3): 8.237e-02\n",
      "Epoch 12600, Train loss: 6.419e+04, Test loss: 2.853e+05, MSE(e): 5.332e-03, MSE(pi1): 2.758e-01, MSE(pi2): 4.216e-03, MSE(pi3): 8.105e-02\n",
      "Epoch 12700, Train loss: 5.829e+04, Test loss: 2.623e+05, MSE(e): 4.762e-03, MSE(pi1): 2.683e-01, MSE(pi2): 3.833e-03, MSE(pi3): 7.992e-02\n",
      "Epoch 12800, Train loss: 1.003e+05, Test loss: 2.821e+05, MSE(e): 8.977e-03, MSE(pi1): 2.637e-01, MSE(pi2): 5.679e-03, MSE(pi3): 7.868e-02\n",
      "Epoch 12900, Train loss: 5.152e+04, Test loss: 2.575e+05, MSE(e): 4.119e-03, MSE(pi1): 2.562e-01, MSE(pi2): 3.378e-03, MSE(pi3): 7.760e-02\n",
      "Epoch 13000, Train loss: 8.794e+04, Test loss: 2.180e+05, MSE(e): 7.775e-03, MSE(pi1): 2.547e-01, MSE(pi2): 4.854e-03, MSE(pi3): 7.648e-02\n",
      "Epoch 13100, Train loss: 5.513e+04, Test loss: 2.569e+05, MSE(e): 4.512e-03, MSE(pi1): 2.471e-01, MSE(pi2): 3.423e-03, MSE(pi3): 7.540e-02\n",
      "Epoch 13200, Train loss: 9.319e+04, Test loss: 2.016e+05, MSE(e): 8.323e-03, MSE(pi1): 2.442e-01, MSE(pi2): 5.855e-03, MSE(pi3): 7.511e-02\n",
      "Epoch 13300, Train loss: 1.333e+05, Test loss: 2.323e+05, MSE(e): 1.236e-02, MSE(pi1): 2.396e-01, MSE(pi2): 6.628e-03, MSE(pi3): 7.367e-02\n",
      "Epoch 13400, Train loss: 5.343e+04, Test loss: 2.694e+05, MSE(e): 4.382e-03, MSE(pi1): 2.371e-01, MSE(pi2): 3.264e-03, MSE(pi3): 7.237e-02\n",
      "Epoch 13500, Train loss: 2.226e+05, Test loss: 4.114e+05, MSE(e): 2.131e-02, MSE(pi1): 2.329e-01, MSE(pi2): 1.076e-02, MSE(pi3): 7.154e-02\n",
      "Epoch 13600, Train loss: 9.952e+04, Test loss: 3.357e+05, MSE(e): 9.008e-03, MSE(pi1): 2.334e-01, MSE(pi2): 6.421e-03, MSE(pi3): 7.093e-02\n",
      "Epoch 13700, Train loss: 1.105e+05, Test loss: 2.087e+05, MSE(e): 1.012e-02, MSE(pi1): 2.302e-01, MSE(pi2): 5.521e-03, MSE(pi3): 6.995e-02\n",
      "Epoch 13800, Train loss: 5.799e+04, Test loss: 2.956e+05, MSE(e): 4.882e-03, MSE(pi1): 2.250e-01, MSE(pi2): 3.766e-03, MSE(pi3): 6.918e-02\n",
      "Epoch 13900, Train loss: 4.920e+04, Test loss: 2.135e+05, MSE(e): 4.013e-03, MSE(pi1): 2.244e-01, MSE(pi2): 3.127e-03, MSE(pi3): 6.818e-02\n",
      "Epoch 14000, Train loss: 7.224e+04, Test loss: 1.443e+05, MSE(e): 6.321e-03, MSE(pi1): 2.255e-01, MSE(pi2): 4.075e-03, MSE(pi3): 6.770e-02\n",
      "Epoch 14100, Train loss: 3.031e+04, Test loss: 1.653e+05, MSE(e): 2.145e-03, MSE(pi1): 2.197e-01, MSE(pi2): 1.940e-03, MSE(pi3): 6.658e-02\n",
      "Epoch 14200, Train loss: 2.907e+04, Test loss: 1.628e+05, MSE(e): 2.030e-03, MSE(pi1): 2.188e-01, MSE(pi2): 1.853e-03, MSE(pi3): 6.581e-02\n",
      "Epoch 14300, Train loss: 2.881e+04, Test loss: 1.561e+05, MSE(e): 2.014e-03, MSE(pi1): 2.165e-01, MSE(pi2): 1.815e-03, MSE(pi3): 6.505e-02\n",
      "Epoch 14400, Train loss: 5.146e+04, Test loss: 2.868e+05, MSE(e): 4.288e-03, MSE(pi1): 2.146e-01, MSE(pi2): 3.182e-03, MSE(pi3): 6.435e-02\n",
      "Epoch 14500, Train loss: 2.654e+04, Test loss: 1.546e+05, MSE(e): 1.809e-03, MSE(pi1): 2.118e-01, MSE(pi2): 1.678e-03, MSE(pi3): 6.331e-02\n",
      "Epoch 14600, Train loss: 2.600e+04, Test loss: 1.501e+05, MSE(e): 1.764e-03, MSE(pi1): 2.114e-01, MSE(pi2): 1.633e-03, MSE(pi3): 6.252e-02\n",
      "Epoch 14700, Train loss: 2.864e+04, Test loss: 1.547e+05, MSE(e): 2.037e-03, MSE(pi1): 2.100e-01, MSE(pi2): 1.732e-03, MSE(pi3): 6.176e-02\n",
      "Epoch 14800, Train loss: 2.451e+04, Test loss: 1.489e+05, MSE(e): 1.636e-03, MSE(pi1): 2.062e-01, MSE(pi2): 1.535e-03, MSE(pi3): 6.080e-02\n",
      "Epoch 14900, Train loss: 2.482e+04, Test loss: 1.542e+05, MSE(e): 1.675e-03, MSE(pi1): 2.060e-01, MSE(pi2): 1.532e-03, MSE(pi3): 6.002e-02\n",
      "Epoch 15000, Train loss: 2.397e+04, Test loss: 1.381e+05, MSE(e): 1.603e-03, MSE(pi1): 2.026e-01, MSE(pi2): 1.496e-03, MSE(pi3): 5.909e-02\n",
      "Epoch 15100, Train loss: 7.641e+04, Test loss: 2.987e+05, MSE(e): 6.859e-03, MSE(pi1): 1.996e-01, MSE(pi2): 3.625e-03, MSE(pi3): 5.821e-02\n",
      "Epoch 15200, Train loss: 2.260e+04, Test loss: 1.395e+05, MSE(e): 1.487e-03, MSE(pi1): 1.991e-01, MSE(pi2): 1.393e-03, MSE(pi3): 5.735e-02\n",
      "Epoch 15300, Train loss: 2.194e+04, Test loss: 1.442e+05, MSE(e): 1.432e-03, MSE(pi1): 1.977e-01, MSE(pi2): 1.357e-03, MSE(pi3): 5.645e-02\n",
      "Epoch 15400, Train loss: 2.159e+04, Test loss: 1.457e+05, MSE(e): 1.406e-03, MSE(pi1): 1.979e-01, MSE(pi2): 1.333e-03, MSE(pi3): 5.554e-02\n",
      "Epoch 15500, Train loss: 2.107e+04, Test loss: 1.491e+05, MSE(e): 1.365e-03, MSE(pi1): 1.942e-01, MSE(pi2): 1.290e-03, MSE(pi3): 5.472e-02\n",
      "Epoch 15600, Train loss: 2.346e+04, Test loss: 1.645e+05, MSE(e): 1.612e-03, MSE(pi1): 1.946e-01, MSE(pi2): 1.385e-03, MSE(pi3): 5.393e-02\n",
      "Epoch 15700, Train loss: 2.092e+04, Test loss: 1.565e+05, MSE(e): 1.370e-03, MSE(pi1): 1.924e-01, MSE(pi2): 1.261e-03, MSE(pi3): 5.286e-02\n",
      "Epoch 15800, Train loss: 1.965e+04, Test loss: 1.429e+05, MSE(e): 1.256e-03, MSE(pi1): 1.898e-01, MSE(pi2): 1.199e-03, MSE(pi3): 5.196e-02\n",
      "Epoch 15900, Train loss: 2.008e+04, Test loss: 1.453e+05, MSE(e): 1.307e-03, MSE(pi1): 1.910e-01, MSE(pi2): 1.231e-03, MSE(pi3): 5.103e-02\n",
      "Epoch 16000, Train loss: 4.074e+05, Test loss: 2.355e+05, MSE(e): 4.003e-02, MSE(pi1): 1.991e-01, MSE(pi2): 1.733e-02, MSE(pi3): 5.073e-02\n",
      "Epoch 16100, Train loss: 1.845e+04, Test loss: 1.502e+05, MSE(e): 1.167e-03, MSE(pi1): 1.857e-01, MSE(pi2): 1.119e-03, MSE(pi3): 4.920e-02\n",
      "Epoch 16200, Train loss: 9.082e+04, Test loss: 3.869e+05, MSE(e): 8.337e-03, MSE(pi1): 2.554e-01, MSE(pi2): 4.002e-03, MSE(pi3): 4.894e-02\n",
      "Epoch 16300, Train loss: 1.773e+04, Test loss: 1.469e+05, MSE(e): 1.117e-03, MSE(pi1): 1.833e-01, MSE(pi2): 1.070e-03, MSE(pi3): 4.728e-02\n",
      "Epoch 16400, Train loss: 3.721e+04, Test loss: 1.750e+05, MSE(e): 3.037e-03, MSE(pi1): 2.164e-01, MSE(pi2): 2.297e-03, MSE(pi3): 4.672e-02\n",
      "Epoch 16500, Train loss: 2.768e+05, Test loss: 3.350e+05, MSE(e): 2.704e-02, MSE(pi1): 1.894e-01, MSE(pi2): 1.174e-02, MSE(pi3): 4.557e-02\n",
      "Epoch 16600, Train loss: 1.648e+04, Test loss: 1.477e+05, MSE(e): 1.026e-03, MSE(pi1): 1.778e-01, MSE(pi2): 9.848e-04, MSE(pi3): 4.442e-02\n",
      "Epoch 16700, Train loss: 2.449e+04, Test loss: 1.917e+05, MSE(e): 1.831e-03, MSE(pi1): 1.808e-01, MSE(pi2): 1.405e-03, MSE(pi3): 4.369e-02\n",
      "Epoch 16800, Train loss: 3.218e+04, Test loss: 1.980e+05, MSE(e): 2.603e-03, MSE(pi1): 1.887e-01, MSE(pi2): 1.726e-03, MSE(pi3): 4.260e-02\n",
      "Epoch 16900, Train loss: 2.965e+04, Test loss: 2.023e+05, MSE(e): 2.361e-03, MSE(pi1): 1.890e-01, MSE(pi2): 1.486e-03, MSE(pi3): 4.147e-02\n",
      "Epoch 17000, Train loss: 2.609e+04, Test loss: 1.708e+05, MSE(e): 2.018e-03, MSE(pi1): 1.889e-01, MSE(pi2): 1.494e-03, MSE(pi3): 4.022e-02\n",
      "Epoch 17100, Train loss: 1.624e+04, Test loss: 1.345e+05, MSE(e): 1.039e-03, MSE(pi1): 1.907e-01, MSE(pi2): 9.177e-04, MSE(pi3): 3.942e-02\n",
      "Epoch 17200, Train loss: 1.523e+04, Test loss: 1.365e+05, MSE(e): 9.708e-04, MSE(pi1): 1.696e-01, MSE(pi2): 8.778e-04, MSE(pi3): 3.830e-02\n",
      "Epoch 17300, Train loss: 2.309e+05, Test loss: 2.836e+05, MSE(e): 2.253e-02, MSE(pi1): 1.930e-01, MSE(pi2): 9.710e-03, MSE(pi3): 3.721e-02\n",
      "Epoch 17400, Train loss: 1.433e+04, Test loss: 1.421e+05, MSE(e): 8.378e-04, MSE(pi1): 2.308e-01, MSE(pi2): 7.857e-04, MSE(pi3): 3.639e-02\n",
      "Epoch 17500, Train loss: 1.433e+04, Test loss: 1.543e+05, MSE(e): 9.076e-04, MSE(pi1): 1.729e-01, MSE(pi2): 8.203e-04, MSE(pi3): 3.522e-02\n",
      "Epoch 17600, Train loss: 1.311e+04, Test loss: 1.441e+05, MSE(e): 8.096e-04, MSE(pi1): 1.599e-01, MSE(pi2): 7.484e-04, MSE(pi3): 3.410e-02\n",
      "Epoch 17700, Train loss: 1.479e+05, Test loss: 2.067e+05, MSE(e): 1.427e-02, MSE(pi1): 1.839e-01, MSE(pi2): 6.372e-03, MSE(pi3): 3.386e-02\n",
      "Epoch 17800, Train loss: 1.281e+04, Test loss: 1.381e+05, MSE(e): 8.067e-04, MSE(pi1): 1.547e-01, MSE(pi2): 7.225e-04, MSE(pi3): 3.197e-02\n",
      "Epoch 17900, Train loss: 4.791e+04, Test loss: 1.607e+05, MSE(e): 4.326e-03, MSE(pi1): 1.567e-01, MSE(pi2): 2.196e-03, MSE(pi3): 3.075e-02\n",
      "Epoch 18000, Train loss: 1.135e+04, Test loss: 1.384e+05, MSE(e): 6.912e-04, MSE(pi1): 1.467e-01, MSE(pi2): 6.340e-04, MSE(pi3): 2.975e-02\n",
      "Epoch 18100, Train loss: 9.909e+04, Test loss: 3.519e+05, MSE(e): 9.375e-03, MSE(pi1): 2.440e-01, MSE(pi2): 4.249e-03, MSE(pi3): 2.902e-02\n",
      "Epoch 18200, Train loss: 5.671e+04, Test loss: 2.743e+05, MSE(e): 5.247e-03, MSE(pi1): 1.467e-01, MSE(pi2): 2.476e-03, MSE(pi3): 2.774e-02\n",
      "Epoch 18300, Train loss: 1.987e+04, Test loss: 1.279e+05, MSE(e): 1.570e-03, MSE(pi1): 1.484e-01, MSE(pi2): 1.159e-03, MSE(pi3): 2.683e-02\n",
      "Epoch 18400, Train loss: 1.085e+04, Test loss: 1.527e+05, MSE(e): 6.977e-04, MSE(pi1): 1.315e-01, MSE(pi2): 6.043e-04, MSE(pi3): 2.553e-02\n",
      "Epoch 18500, Train loss: 2.213e+04, Test loss: 1.816e+05, MSE(e): 1.772e-03, MSE(pi1): 1.928e-01, MSE(pi2): 1.282e-03, MSE(pi3): 2.481e-02\n",
      "Epoch 18600, Train loss: 9.252e+03, Test loss: 1.380e+05, MSE(e): 5.745e-04, MSE(pi1): 1.179e-01, MSE(pi2): 5.141e-04, MSE(pi3): 2.327e-02\n",
      "Epoch 18700, Train loss: 1.178e+04, Test loss: 1.435e+05, MSE(e): 7.991e-04, MSE(pi1): 1.609e-01, MSE(pi2): 6.634e-04, MSE(pi3): 2.183e-02\n",
      "Epoch 18800, Train loss: 8.443e+03, Test loss: 1.325e+05, MSE(e): 5.261e-04, MSE(pi1): 1.070e-01, MSE(pi2): 4.688e-04, MSE(pi3): 2.111e-02\n",
      "Epoch 18900, Train loss: 8.567e+03, Test loss: 1.374e+05, MSE(e): 5.382e-04, MSE(pi1): 1.166e-01, MSE(pi2): 4.761e-04, MSE(pi3): 2.019e-02\n",
      "Epoch 19000, Train loss: 5.931e+04, Test loss: 2.373e+05, MSE(e): 5.353e-03, MSE(pi1): 3.614e-01, MSE(pi2): 2.686e-03, MSE(pi3): 2.168e-02\n",
      "Epoch 19100, Train loss: 1.903e+04, Test loss: 1.764e+05, MSE(e): 1.632e-03, MSE(pi1): 9.038e-02, MSE(pi2): 9.041e-04, MSE(pi3): 1.804e-02\n",
      "Epoch 19200, Train loss: 9.142e+03, Test loss: 1.334e+05, MSE(e): 4.908e-04, MSE(pi1): 2.549e-01, MSE(pi2): 4.273e-04, MSE(pi3): 1.684e-02\n",
      "Epoch 19300, Train loss: 4.082e+04, Test loss: 2.102e+05, MSE(e): 3.757e-03, MSE(pi1): 1.460e-01, MSE(pi2): 1.711e-03, MSE(pi3): 1.784e-02\n",
      "Epoch 19400, Train loss: 1.037e+04, Test loss: 1.414e+05, MSE(e): 7.938e-04, MSE(pi1): 9.081e-02, MSE(pi2): 5.590e-04, MSE(pi3): 1.526e-02\n",
      "Epoch 19500, Train loss: 4.712e+04, Test loss: 1.103e+05, MSE(e): 4.418e-03, MSE(pi1): 1.520e-01, MSE(pi2): 2.116e-03, MSE(pi3): 1.411e-02\n",
      "Epoch 19600, Train loss: 8.965e+03, Test loss: 1.225e+05, MSE(e): 6.467e-04, MSE(pi1): 1.137e-01, MSE(pi2): 4.878e-04, MSE(pi3): 1.360e-02\n",
      "Epoch 19700, Train loss: 7.493e+03, Test loss: 1.163e+05, MSE(e): 5.534e-04, MSE(pi1): 6.562e-02, MSE(pi2): 4.649e-04, MSE(pi3): 1.303e-02\n",
      "Epoch 19800, Train loss: 9.200e+03, Test loss: 1.142e+05, MSE(e): 6.814e-04, MSE(pi1): 1.135e-01, MSE(pi2): 4.926e-04, MSE(pi3): 1.250e-02\n",
      "Epoch 19900, Train loss: 8.111e+03, Test loss: 1.142e+05, MSE(e): 6.303e-04, MSE(pi1): 5.988e-02, MSE(pi2): 5.125e-04, MSE(pi3): 1.209e-02\n",
      "\n",
      "Training process finished after 20000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = BaselineNonlinearModel(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 20000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 18000.\n",
      "Epoch 18000, Train loss: 1.135e+04, Test loss: 1.384e+05, MSE(e): 6.907e-04, MSE(pi1): 1.465e-01, MSE(pi2): 6.330e-04, MSE(pi3): 2.975e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18100, Train loss: 1.132e+04, Test loss: 1.392e+05, MSE(e): 6.895e-04, MSE(pi1): 1.452e-01, MSE(pi2): 6.327e-04, MSE(pi3): 2.973e-02\n",
      "Epoch 18200, Train loss: 1.131e+04, Test loss: 1.391e+05, MSE(e): 6.890e-04, MSE(pi1): 1.451e-01, MSE(pi2): 6.323e-04, MSE(pi3): 2.972e-02\n",
      "Epoch 18300, Train loss: 1.131e+04, Test loss: 1.390e+05, MSE(e): 6.884e-04, MSE(pi1): 1.451e-01, MSE(pi2): 6.319e-04, MSE(pi3): 2.970e-02\n",
      "Epoch 18400, Train loss: 1.130e+04, Test loss: 1.390e+05, MSE(e): 6.879e-04, MSE(pi1): 1.450e-01, MSE(pi2): 6.314e-04, MSE(pi3): 2.969e-02\n",
      "Epoch 18500, Train loss: 1.129e+04, Test loss: 1.389e+05, MSE(e): 6.873e-04, MSE(pi1): 1.449e-01, MSE(pi2): 6.310e-04, MSE(pi3): 2.967e-02\n",
      "Epoch 18600, Train loss: 1.128e+04, Test loss: 1.388e+05, MSE(e): 6.867e-04, MSE(pi1): 1.449e-01, MSE(pi2): 6.304e-04, MSE(pi3): 2.966e-02\n",
      "Epoch 18700, Train loss: 1.127e+04, Test loss: 1.388e+05, MSE(e): 6.861e-04, MSE(pi1): 1.448e-01, MSE(pi2): 6.299e-04, MSE(pi3): 2.964e-02\n",
      "Epoch 18800, Train loss: 1.127e+04, Test loss: 1.387e+05, MSE(e): 6.855e-04, MSE(pi1): 1.447e-01, MSE(pi2): 6.293e-04, MSE(pi3): 2.963e-02\n",
      "Epoch 18900, Train loss: 1.126e+04, Test loss: 1.386e+05, MSE(e): 6.848e-04, MSE(pi1): 1.447e-01, MSE(pi2): 6.287e-04, MSE(pi3): 2.961e-02\n",
      "Epoch 19000, Train loss: 1.125e+04, Test loss: 1.385e+05, MSE(e): 6.841e-04, MSE(pi1): 1.446e-01, MSE(pi2): 6.281e-04, MSE(pi3): 2.959e-02\n",
      "Epoch 19100, Train loss: 1.124e+04, Test loss: 1.384e+05, MSE(e): 6.833e-04, MSE(pi1): 1.445e-01, MSE(pi2): 6.274e-04, MSE(pi3): 2.957e-02\n",
      "Epoch 19200, Train loss: 1.123e+04, Test loss: 1.383e+05, MSE(e): 6.826e-04, MSE(pi1): 1.444e-01, MSE(pi2): 6.268e-04, MSE(pi3): 2.955e-02\n",
      "Epoch 19300, Train loss: 1.121e+04, Test loss: 1.382e+05, MSE(e): 6.818e-04, MSE(pi1): 1.443e-01, MSE(pi2): 6.260e-04, MSE(pi3): 2.953e-02\n",
      "Epoch 19400, Train loss: 1.120e+04, Test loss: 1.381e+05, MSE(e): 6.810e-04, MSE(pi1): 1.442e-01, MSE(pi2): 6.253e-04, MSE(pi3): 2.950e-02\n",
      "Epoch 19500, Train loss: 1.119e+04, Test loss: 1.380e+05, MSE(e): 6.801e-04, MSE(pi1): 1.441e-01, MSE(pi2): 6.245e-04, MSE(pi3): 2.948e-02\n",
      "Epoch 19600, Train loss: 1.118e+04, Test loss: 1.379e+05, MSE(e): 6.792e-04, MSE(pi1): 1.440e-01, MSE(pi2): 6.237e-04, MSE(pi3): 2.946e-02\n",
      "Epoch 19700, Train loss: 1.116e+04, Test loss: 1.378e+05, MSE(e): 6.782e-04, MSE(pi1): 1.439e-01, MSE(pi2): 6.228e-04, MSE(pi3): 2.943e-02\n",
      "Epoch 19800, Train loss: 1.115e+04, Test loss: 1.377e+05, MSE(e): 6.772e-04, MSE(pi1): 1.438e-01, MSE(pi2): 6.219e-04, MSE(pi3): 2.940e-02\n",
      "Epoch 19900, Train loss: 1.114e+04, Test loss: 1.375e+05, MSE(e): 6.762e-04, MSE(pi1): 1.436e-01, MSE(pi2): 6.210e-04, MSE(pi3): 2.937e-02\n",
      "Epoch 20000, Train loss: 1.112e+04, Test loss: 1.374e+05, MSE(e): 6.752e-04, MSE(pi1): 1.435e-01, MSE(pi2): 6.200e-04, MSE(pi3): 2.934e-02\n",
      "Epoch 20100, Train loss: 1.111e+04, Test loss: 1.373e+05, MSE(e): 6.740e-04, MSE(pi1): 1.434e-01, MSE(pi2): 6.190e-04, MSE(pi3): 2.931e-02\n",
      "Epoch 20200, Train loss: 1.109e+04, Test loss: 1.371e+05, MSE(e): 6.729e-04, MSE(pi1): 1.432e-01, MSE(pi2): 6.179e-04, MSE(pi3): 2.928e-02\n",
      "Epoch 20300, Train loss: 1.107e+04, Test loss: 1.370e+05, MSE(e): 6.717e-04, MSE(pi1): 1.431e-01, MSE(pi2): 6.168e-04, MSE(pi3): 2.924e-02\n",
      "Epoch 20400, Train loss: 1.105e+04, Test loss: 1.368e+05, MSE(e): 6.704e-04, MSE(pi1): 1.429e-01, MSE(pi2): 6.156e-04, MSE(pi3): 2.920e-02\n",
      "Epoch 20500, Train loss: 1.104e+04, Test loss: 1.367e+05, MSE(e): 6.691e-04, MSE(pi1): 1.427e-01, MSE(pi2): 6.144e-04, MSE(pi3): 2.916e-02\n",
      "Epoch 20600, Train loss: 1.102e+04, Test loss: 1.365e+05, MSE(e): 6.678e-04, MSE(pi1): 1.426e-01, MSE(pi2): 6.132e-04, MSE(pi3): 2.912e-02\n",
      "Epoch 20700, Train loss: 1.100e+04, Test loss: 1.363e+05, MSE(e): 6.664e-04, MSE(pi1): 1.424e-01, MSE(pi2): 6.119e-04, MSE(pi3): 2.908e-02\n",
      "Epoch 20800, Train loss: 1.098e+04, Test loss: 1.361e+05, MSE(e): 6.649e-04, MSE(pi1): 1.422e-01, MSE(pi2): 6.105e-04, MSE(pi3): 2.903e-02\n",
      "Epoch 20900, Train loss: 1.095e+04, Test loss: 1.359e+05, MSE(e): 6.634e-04, MSE(pi1): 1.420e-01, MSE(pi2): 6.091e-04, MSE(pi3): 2.898e-02\n",
      "Epoch 21000, Train loss: 1.093e+04, Test loss: 1.357e+05, MSE(e): 6.618e-04, MSE(pi1): 1.418e-01, MSE(pi2): 6.076e-04, MSE(pi3): 2.893e-02\n",
      "Epoch 21100, Train loss: 1.091e+04, Test loss: 1.355e+05, MSE(e): 6.602e-04, MSE(pi1): 1.416e-01, MSE(pi2): 6.061e-04, MSE(pi3): 2.888e-02\n",
      "Epoch 21200, Train loss: 1.088e+04, Test loss: 1.353e+05, MSE(e): 6.585e-04, MSE(pi1): 1.414e-01, MSE(pi2): 6.045e-04, MSE(pi3): 2.882e-02\n",
      "Epoch 21300, Train loss: 1.086e+04, Test loss: 1.351e+05, MSE(e): 6.567e-04, MSE(pi1): 1.411e-01, MSE(pi2): 6.028e-04, MSE(pi3): 2.877e-02\n",
      "Epoch 21400, Train loss: 1.083e+04, Test loss: 1.348e+05, MSE(e): 6.549e-04, MSE(pi1): 1.409e-01, MSE(pi2): 6.011e-04, MSE(pi3): 2.870e-02\n",
      "Epoch 21500, Train loss: 1.080e+04, Test loss: 1.346e+05, MSE(e): 6.530e-04, MSE(pi1): 1.406e-01, MSE(pi2): 5.992e-04, MSE(pi3): 2.864e-02\n",
      "Epoch 21600, Train loss: 1.077e+04, Test loss: 1.343e+05, MSE(e): 6.510e-04, MSE(pi1): 1.403e-01, MSE(pi2): 5.974e-04, MSE(pi3): 2.857e-02\n",
      "Epoch 21700, Train loss: 1.074e+04, Test loss: 1.340e+05, MSE(e): 6.489e-04, MSE(pi1): 1.400e-01, MSE(pi2): 5.954e-04, MSE(pi3): 2.850e-02\n",
      "Epoch 21800, Train loss: 1.071e+04, Test loss: 1.338e+05, MSE(e): 6.468e-04, MSE(pi1): 1.397e-01, MSE(pi2): 5.934e-04, MSE(pi3): 2.842e-02\n",
      "Epoch 21900, Train loss: 1.068e+04, Test loss: 1.335e+05, MSE(e): 6.446e-04, MSE(pi1): 1.394e-01, MSE(pi2): 5.913e-04, MSE(pi3): 2.835e-02\n",
      "Epoch 22000, Train loss: 1.064e+04, Test loss: 1.332e+05, MSE(e): 6.423e-04, MSE(pi1): 1.391e-01, MSE(pi2): 5.891e-04, MSE(pi3): 2.826e-02\n",
      "Epoch 22100, Train loss: 1.060e+04, Test loss: 1.328e+05, MSE(e): 6.399e-04, MSE(pi1): 1.387e-01, MSE(pi2): 5.868e-04, MSE(pi3): 2.818e-02\n",
      "Epoch 22200, Train loss: 1.057e+04, Test loss: 1.325e+05, MSE(e): 6.374e-04, MSE(pi1): 1.384e-01, MSE(pi2): 5.844e-04, MSE(pi3): 2.809e-02\n",
      "Epoch 22300, Train loss: 1.053e+04, Test loss: 1.322e+05, MSE(e): 6.348e-04, MSE(pi1): 1.380e-01, MSE(pi2): 5.820e-04, MSE(pi3): 2.799e-02\n",
      "Epoch 22400, Train loss: 1.049e+04, Test loss: 1.318e+05, MSE(e): 6.321e-04, MSE(pi1): 1.376e-01, MSE(pi2): 5.794e-04, MSE(pi3): 2.789e-02\n",
      "Epoch 22500, Train loss: 1.044e+04, Test loss: 1.315e+05, MSE(e): 6.294e-04, MSE(pi1): 1.372e-01, MSE(pi2): 5.768e-04, MSE(pi3): 2.779e-02\n",
      "Epoch 22600, Train loss: 1.040e+04, Test loss: 1.311e+05, MSE(e): 6.265e-04, MSE(pi1): 1.367e-01, MSE(pi2): 5.740e-04, MSE(pi3): 2.768e-02\n",
      "Epoch 22700, Train loss: 1.035e+04, Test loss: 1.307e+05, MSE(e): 6.235e-04, MSE(pi1): 1.363e-01, MSE(pi2): 5.712e-04, MSE(pi3): 2.756e-02\n",
      "Epoch 22800, Train loss: 1.031e+04, Test loss: 1.303e+05, MSE(e): 6.204e-04, MSE(pi1): 1.358e-01, MSE(pi2): 5.682e-04, MSE(pi3): 2.744e-02\n",
      "Epoch 22900, Train loss: 1.026e+04, Test loss: 1.299e+05, MSE(e): 6.172e-04, MSE(pi1): 1.353e-01, MSE(pi2): 5.651e-04, MSE(pi3): 2.732e-02\n",
      "Epoch 23000, Train loss: 1.021e+04, Test loss: 1.295e+05, MSE(e): 6.139e-04, MSE(pi1): 1.347e-01, MSE(pi2): 5.619e-04, MSE(pi3): 2.718e-02\n",
      "Epoch 23100, Train loss: 1.015e+04, Test loss: 1.290e+05, MSE(e): 6.105e-04, MSE(pi1): 1.342e-01, MSE(pi2): 5.586e-04, MSE(pi3): 2.705e-02\n",
      "Epoch 23200, Train loss: 1.010e+04, Test loss: 1.286e+05, MSE(e): 6.069e-04, MSE(pi1): 1.336e-01, MSE(pi2): 5.552e-04, MSE(pi3): 2.690e-02\n",
      "Epoch 23300, Train loss: 1.004e+04, Test loss: 1.281e+05, MSE(e): 6.032e-04, MSE(pi1): 1.329e-01, MSE(pi2): 5.516e-04, MSE(pi3): 2.675e-02\n",
      "Epoch 23400, Train loss: 9.977e+03, Test loss: 1.276e+05, MSE(e): 5.994e-04, MSE(pi1): 1.323e-01, MSE(pi2): 5.480e-04, MSE(pi3): 2.659e-02\n",
      "Epoch 23500, Train loss: 9.914e+03, Test loss: 1.271e+05, MSE(e): 5.955e-04, MSE(pi1): 1.316e-01, MSE(pi2): 5.441e-04, MSE(pi3): 2.643e-02\n",
      "Epoch 23600, Train loss: 9.849e+03, Test loss: 1.266e+05, MSE(e): 5.914e-04, MSE(pi1): 1.309e-01, MSE(pi2): 5.402e-04, MSE(pi3): 2.626e-02\n",
      "Epoch 23700, Train loss: 9.781e+03, Test loss: 1.261e+05, MSE(e): 5.872e-04, MSE(pi1): 1.301e-01, MSE(pi2): 5.361e-04, MSE(pi3): 2.608e-02\n",
      "Epoch 23800, Train loss: 9.710e+03, Test loss: 1.256e+05, MSE(e): 5.828e-04, MSE(pi1): 1.293e-01, MSE(pi2): 5.319e-04, MSE(pi3): 2.589e-02\n",
      "Epoch 23900, Train loss: 9.637e+03, Test loss: 1.250e+05, MSE(e): 5.783e-04, MSE(pi1): 1.284e-01, MSE(pi2): 5.275e-04, MSE(pi3): 2.569e-02\n",
      "Epoch 24000, Train loss: 9.561e+03, Test loss: 1.244e+05, MSE(e): 5.737e-04, MSE(pi1): 1.275e-01, MSE(pi2): 5.230e-04, MSE(pi3): 2.549e-02\n",
      "Epoch 24100, Train loss: 9.483e+03, Test loss: 1.238e+05, MSE(e): 5.689e-04, MSE(pi1): 1.266e-01, MSE(pi2): 5.184e-04, MSE(pi3): 2.527e-02\n",
      "Epoch 24200, Train loss: 9.401e+03, Test loss: 1.233e+05, MSE(e): 5.639e-04, MSE(pi1): 1.256e-01, MSE(pi2): 5.136e-04, MSE(pi3): 2.505e-02\n",
      "Epoch 24300, Train loss: 9.316e+03, Test loss: 1.226e+05, MSE(e): 5.588e-04, MSE(pi1): 1.246e-01, MSE(pi2): 5.087e-04, MSE(pi3): 2.482e-02\n",
      "Epoch 24400, Train loss: 9.229e+03, Test loss: 1.220e+05, MSE(e): 5.536e-04, MSE(pi1): 1.235e-01, MSE(pi2): 5.036e-04, MSE(pi3): 2.458e-02\n",
      "Epoch 24500, Train loss: 9.138e+03, Test loss: 1.214e+05, MSE(e): 5.482e-04, MSE(pi1): 1.223e-01, MSE(pi2): 4.984e-04, MSE(pi3): 2.432e-02\n",
      "Epoch 24600, Train loss: 9.044e+03, Test loss: 1.207e+05, MSE(e): 5.427e-04, MSE(pi1): 1.211e-01, MSE(pi2): 4.931e-04, MSE(pi3): 2.406e-02\n",
      "Epoch 24700, Train loss: 8.948e+03, Test loss: 1.201e+05, MSE(e): 5.370e-04, MSE(pi1): 1.198e-01, MSE(pi2): 4.876e-04, MSE(pi3): 2.379e-02\n",
      "Epoch 24800, Train loss: 8.847e+03, Test loss: 1.194e+05, MSE(e): 5.312e-04, MSE(pi1): 1.184e-01, MSE(pi2): 4.820e-04, MSE(pi3): 2.350e-02\n",
      "Epoch 24900, Train loss: 8.744e+03, Test loss: 1.187e+05, MSE(e): 5.252e-04, MSE(pi1): 1.170e-01, MSE(pi2): 4.763e-04, MSE(pi3): 2.321e-02\n",
      "Epoch 25000, Train loss: 8.637e+03, Test loss: 1.180e+05, MSE(e): 5.191e-04, MSE(pi1): 1.155e-01, MSE(pi2): 4.704e-04, MSE(pi3): 2.290e-02\n",
      "Epoch 25100, Train loss: 8.527e+03, Test loss: 1.173e+05, MSE(e): 5.129e-04, MSE(pi1): 1.139e-01, MSE(pi2): 4.644e-04, MSE(pi3): 2.259e-02\n",
      "Epoch 25200, Train loss: 8.414e+03, Test loss: 1.165e+05, MSE(e): 5.065e-04, MSE(pi1): 1.122e-01, MSE(pi2): 4.583e-04, MSE(pi3): 2.226e-02\n",
      "Epoch 25300, Train loss: 8.297e+03, Test loss: 1.158e+05, MSE(e): 5.000e-04, MSE(pi1): 1.105e-01, MSE(pi2): 4.521e-04, MSE(pi3): 2.192e-02\n",
      "Epoch 25400, Train loss: 8.177e+03, Test loss: 1.151e+05, MSE(e): 4.933e-04, MSE(pi1): 1.086e-01, MSE(pi2): 4.458e-04, MSE(pi3): 2.156e-02\n",
      "Epoch 25500, Train loss: 8.053e+03, Test loss: 1.143e+05, MSE(e): 4.866e-04, MSE(pi1): 1.067e-01, MSE(pi2): 4.394e-04, MSE(pi3): 2.120e-02\n",
      "Epoch 25600, Train loss: 7.926e+03, Test loss: 1.135e+05, MSE(e): 4.797e-04, MSE(pi1): 1.047e-01, MSE(pi2): 4.329e-04, MSE(pi3): 2.082e-02\n",
      "Epoch 25700, Train loss: 7.795e+03, Test loss: 1.127e+05, MSE(e): 4.726e-04, MSE(pi1): 1.025e-01, MSE(pi2): 4.263e-04, MSE(pi3): 2.043e-02\n",
      "Epoch 25800, Train loss: 7.661e+03, Test loss: 1.119e+05, MSE(e): 4.655e-04, MSE(pi1): 1.003e-01, MSE(pi2): 4.196e-04, MSE(pi3): 2.003e-02\n",
      "Epoch 25900, Train loss: 7.524e+03, Test loss: 1.111e+05, MSE(e): 4.582e-04, MSE(pi1): 9.799e-02, MSE(pi2): 4.128e-04, MSE(pi3): 1.962e-02\n",
      "Epoch 26000, Train loss: 7.382e+03, Test loss: 1.103e+05, MSE(e): 4.507e-04, MSE(pi1): 9.557e-02, MSE(pi2): 4.058e-04, MSE(pi3): 1.919e-02\n",
      "Epoch 26100, Train loss: 7.237e+03, Test loss: 1.095e+05, MSE(e): 4.430e-04, MSE(pi1): 9.305e-02, MSE(pi2): 3.987e-04, MSE(pi3): 1.876e-02\n",
      "Epoch 26200, Train loss: 7.088e+03, Test loss: 1.087e+05, MSE(e): 4.352e-04, MSE(pi1): 9.045e-02, MSE(pi2): 3.913e-04, MSE(pi3): 1.831e-02\n",
      "Epoch 26300, Train loss: 6.937e+03, Test loss: 1.078e+05, MSE(e): 4.273e-04, MSE(pi1): 8.776e-02, MSE(pi2): 3.839e-04, MSE(pi3): 1.786e-02\n",
      "Epoch 26400, Train loss: 6.784e+03, Test loss: 1.069e+05, MSE(e): 4.194e-04, MSE(pi1): 8.498e-02, MSE(pi2): 3.767e-04, MSE(pi3): 1.740e-02\n",
      "Epoch 26500, Train loss: 6.629e+03, Test loss: 1.060e+05, MSE(e): 4.114e-04, MSE(pi1): 8.213e-02, MSE(pi2): 3.696e-04, MSE(pi3): 1.693e-02\n",
      "Epoch 26600, Train loss: 6.473e+03, Test loss: 1.050e+05, MSE(e): 4.035e-04, MSE(pi1): 7.923e-02, MSE(pi2): 3.626e-04, MSE(pi3): 1.645e-02\n",
      "Epoch 26700, Train loss: 6.317e+03, Test loss: 1.041e+05, MSE(e): 3.956e-04, MSE(pi1): 7.628e-02, MSE(pi2): 3.557e-04, MSE(pi3): 1.598e-02\n",
      "Epoch 26800, Train loss: 6.160e+03, Test loss: 1.031e+05, MSE(e): 3.876e-04, MSE(pi1): 7.333e-02, MSE(pi2): 3.489e-04, MSE(pi3): 1.550e-02\n",
      "Epoch 26900, Train loss: 6.004e+03, Test loss: 1.022e+05, MSE(e): 3.798e-04, MSE(pi1): 7.038e-02, MSE(pi2): 3.422e-04, MSE(pi3): 1.503e-02\n",
      "Epoch 27000, Train loss: 5.849e+03, Test loss: 1.012e+05, MSE(e): 3.719e-04, MSE(pi1): 6.743e-02, MSE(pi2): 3.355e-04, MSE(pi3): 1.456e-02\n",
      "Epoch 27100, Train loss: 5.697e+03, Test loss: 1.005e+05, MSE(e): 3.642e-04, MSE(pi1): 6.449e-02, MSE(pi2): 3.288e-04, MSE(pi3): 1.410e-02\n",
      "Epoch 27200, Train loss: 5.551e+03, Test loss: 9.942e+04, MSE(e): 3.568e-04, MSE(pi1): 6.170e-02, MSE(pi2): 3.225e-04, MSE(pi3): 1.365e-02\n",
      "Epoch 27300, Train loss: 5.406e+03, Test loss: 9.853e+04, MSE(e): 3.494e-04, MSE(pi1): 5.904e-02, MSE(pi2): 3.164e-04, MSE(pi3): 1.321e-02\n",
      "Epoch 27400, Train loss: 5.269e+03, Test loss: 9.762e+04, MSE(e): 3.424e-04, MSE(pi1): 5.649e-02, MSE(pi2): 3.106e-04, MSE(pi3): 1.279e-02\n",
      "Epoch 27500, Train loss: 5.138e+03, Test loss: 9.686e+04, MSE(e): 3.358e-04, MSE(pi1): 5.406e-02, MSE(pi2): 3.050e-04, MSE(pi3): 1.240e-02\n",
      "Epoch 27600, Train loss: 5.018e+03, Test loss: 9.641e+04, MSE(e): 3.297e-04, MSE(pi1): 5.177e-02, MSE(pi2): 2.996e-04, MSE(pi3): 1.202e-02\n",
      "Epoch 27700, Train loss: 4.902e+03, Test loss: 9.618e+04, MSE(e): 3.236e-04, MSE(pi1): 4.964e-02, MSE(pi2): 2.945e-04, MSE(pi3): 1.170e-02\n",
      "Epoch 27800, Train loss: 4.808e+03, Test loss: 9.544e+04, MSE(e): 3.195e-04, MSE(pi1): 4.762e-02, MSE(pi2): 2.901e-04, MSE(pi3): 1.136e-02\n",
      "Epoch 27900, Train loss: 4.678e+03, Test loss: 9.390e+04, MSE(e): 3.112e-04, MSE(pi1): 4.599e-02, MSE(pi2): 2.845e-04, MSE(pi3): 1.106e-02\n",
      "Epoch 28000, Train loss: 4.580e+03, Test loss: 9.331e+04, MSE(e): 3.056e-04, MSE(pi1): 4.436e-02, MSE(pi2): 2.798e-04, MSE(pi3): 1.080e-02\n",
      "Epoch 28100, Train loss: 4.487e+03, Test loss: 9.263e+04, MSE(e): 3.001e-04, MSE(pi1): 4.294e-02, MSE(pi2): 2.753e-04, MSE(pi3): 1.056e-02\n",
      "Epoch 28200, Train loss: 4.400e+03, Test loss: 9.211e+04, MSE(e): 2.948e-04, MSE(pi1): 4.169e-02, MSE(pi2): 2.709e-04, MSE(pi3): 1.035e-02\n",
      "Epoch 28300, Train loss: 4.319e+03, Test loss: 9.147e+04, MSE(e): 2.897e-04, MSE(pi1): 4.054e-02, MSE(pi2): 2.667e-04, MSE(pi3): 1.016e-02\n",
      "Epoch 28400, Train loss: 4.242e+03, Test loss: 9.080e+04, MSE(e): 2.847e-04, MSE(pi1): 3.953e-02, MSE(pi2): 2.626e-04, MSE(pi3): 9.996e-03\n",
      "Epoch 28500, Train loss: 4.173e+03, Test loss: 9.077e+04, MSE(e): 2.801e-04, MSE(pi1): 3.871e-02, MSE(pi2): 2.587e-04, MSE(pi3): 9.847e-03\n",
      "Epoch 28600, Train loss: 4.130e+03, Test loss: 9.061e+04, MSE(e): 2.780e-04, MSE(pi1): 3.772e-02, MSE(pi2): 2.557e-04, MSE(pi3): 9.732e-03\n",
      "Epoch 28700, Train loss: 4.039e+03, Test loss: 8.943e+04, MSE(e): 2.707e-04, MSE(pi1): 3.713e-02, MSE(pi2): 2.510e-04, MSE(pi3): 9.605e-03\n",
      "Epoch 28800, Train loss: 3.979e+03, Test loss: 8.891e+04, MSE(e): 2.664e-04, MSE(pi1): 3.649e-02, MSE(pi2): 2.474e-04, MSE(pi3): 9.500e-03\n",
      "Epoch 28900, Train loss: 3.925e+03, Test loss: 8.821e+04, MSE(e): 2.625e-04, MSE(pi1): 3.590e-02, MSE(pi2): 2.443e-04, MSE(pi3): 9.408e-03\n",
      "Epoch 29000, Train loss: 3.879e+03, Test loss: 8.873e+04, MSE(e): 2.594e-04, MSE(pi1): 3.529e-02, MSE(pi2): 2.410e-04, MSE(pi3): 9.325e-03\n",
      "Epoch 29100, Train loss: 3.814e+03, Test loss: 8.756e+04, MSE(e): 2.541e-04, MSE(pi1): 3.488e-02, MSE(pi2): 2.372e-04, MSE(pi3): 9.240e-03\n",
      "Epoch 29200, Train loss: 3.767e+03, Test loss: 8.691e+04, MSE(e): 2.506e-04, MSE(pi1): 3.447e-02, MSE(pi2): 2.341e-04, MSE(pi3): 9.161e-03\n",
      "Epoch 29300, Train loss: 3.715e+03, Test loss: 8.670e+04, MSE(e): 2.465e-04, MSE(pi1): 3.400e-02, MSE(pi2): 2.309e-04, MSE(pi3): 9.091e-03\n",
      "Epoch 29400, Train loss: 3.684e+03, Test loss: 8.564e+04, MSE(e): 2.445e-04, MSE(pi1): 3.366e-02, MSE(pi2): 2.285e-04, MSE(pi3): 9.019e-03\n",
      "Epoch 29500, Train loss: 3.621e+03, Test loss: 8.587e+04, MSE(e): 2.393e-04, MSE(pi1): 3.321e-02, MSE(pi2): 2.249e-04, MSE(pi3): 8.954e-03\n",
      "Epoch 29600, Train loss: 3.588e+03, Test loss: 8.498e+04, MSE(e): 2.370e-04, MSE(pi1): 3.292e-02, MSE(pi2): 2.224e-04, MSE(pi3): 8.885e-03\n",
      "Epoch 29700, Train loss: 3.532e+03, Test loss: 8.507e+04, MSE(e): 2.325e-04, MSE(pi1): 3.250e-02, MSE(pi2): 2.192e-04, MSE(pi3): 8.823e-03\n",
      "Epoch 29800, Train loss: 3.490e+03, Test loss: 8.467e+04, MSE(e): 2.293e-04, MSE(pi1): 3.216e-02, MSE(pi2): 2.165e-04, MSE(pi3): 8.759e-03\n",
      "Epoch 29900, Train loss: 3.451e+03, Test loss: 8.412e+04, MSE(e): 2.262e-04, MSE(pi1): 3.203e-02, MSE(pi2): 2.140e-04, MSE(pi3): 8.685e-03\n",
      "Epoch 30000, Train loss: 3.409e+03, Test loss: 8.391e+04, MSE(e): 2.230e-04, MSE(pi1): 3.154e-02, MSE(pi2): 2.113e-04, MSE(pi3): 8.630e-03\n",
      "Epoch 30100, Train loss: 3.373e+03, Test loss: 8.375e+04, MSE(e): 2.200e-04, MSE(pi1): 3.172e-02, MSE(pi2): 2.088e-04, MSE(pi3): 8.555e-03\n",
      "Epoch 30200, Train loss: 3.330e+03, Test loss: 8.324e+04, MSE(e): 2.170e-04, MSE(pi1): 3.097e-02, MSE(pi2): 2.063e-04, MSE(pi3): 8.501e-03\n",
      "Epoch 30300, Train loss: 3.295e+03, Test loss: 8.244e+04, MSE(e): 2.144e-04, MSE(pi1): 3.074e-02, MSE(pi2): 2.041e-04, MSE(pi3): 8.433e-03\n",
      "Epoch 30400, Train loss: 3.255e+03, Test loss: 8.251e+04, MSE(e): 2.114e-04, MSE(pi1): 3.043e-02, MSE(pi2): 2.016e-04, MSE(pi3): 8.371e-03\n",
      "Epoch 30500, Train loss: 3.220e+03, Test loss: 8.202e+04, MSE(e): 2.086e-04, MSE(pi1): 3.042e-02, MSE(pi2): 1.993e-04, MSE(pi3): 8.292e-03\n",
      "Epoch 30600, Train loss: 3.183e+03, Test loss: 8.179e+04, MSE(e): 2.059e-04, MSE(pi1): 2.992e-02, MSE(pi2): 1.970e-04, MSE(pi3): 8.241e-03\n",
      "Epoch 30700, Train loss: 3.148e+03, Test loss: 8.145e+04, MSE(e): 2.034e-04, MSE(pi1): 2.968e-02, MSE(pi2): 1.949e-04, MSE(pi3): 8.173e-03\n",
      "Epoch 30800, Train loss: 3.115e+03, Test loss: 8.124e+04, MSE(e): 2.009e-04, MSE(pi1): 2.943e-02, MSE(pi2): 1.927e-04, MSE(pi3): 8.109e-03\n",
      "Epoch 30900, Train loss: 3.080e+03, Test loss: 8.085e+04, MSE(e): 1.984e-04, MSE(pi1): 2.919e-02, MSE(pi2): 1.907e-04, MSE(pi3): 8.044e-03\n",
      "Epoch 31000, Train loss: 3.048e+03, Test loss: 8.057e+04, MSE(e): 1.961e-04, MSE(pi1): 2.901e-02, MSE(pi2): 1.887e-04, MSE(pi3): 7.970e-03\n",
      "Epoch 31100, Train loss: 3.016e+03, Test loss: 8.003e+04, MSE(e): 1.938e-04, MSE(pi1): 2.893e-02, MSE(pi2): 1.868e-04, MSE(pi3): 7.892e-03\n",
      "Epoch 31200, Train loss: 2.982e+03, Test loss: 7.981e+04, MSE(e): 1.913e-04, MSE(pi1): 2.855e-02, MSE(pi2): 1.847e-04, MSE(pi3): 7.838e-03\n",
      "Epoch 31300, Train loss: 2.951e+03, Test loss: 7.952e+04, MSE(e): 1.890e-04, MSE(pi1): 2.834e-02, MSE(pi2): 1.828e-04, MSE(pi3): 7.769e-03\n",
      "Epoch 31400, Train loss: 2.920e+03, Test loss: 7.916e+04, MSE(e): 1.868e-04, MSE(pi1): 2.815e-02, MSE(pi2): 1.810e-04, MSE(pi3): 7.701e-03\n",
      "Epoch 31500, Train loss: 2.890e+03, Test loss: 7.884e+04, MSE(e): 1.847e-04, MSE(pi1): 2.797e-02, MSE(pi2): 1.792e-04, MSE(pi3): 7.630e-03\n",
      "Epoch 31600, Train loss: 2.890e+03, Test loss: 7.877e+04, MSE(e): 1.856e-04, MSE(pi1): 2.763e-02, MSE(pi2): 1.787e-04, MSE(pi3): 7.578e-03\n",
      "Epoch 31700, Train loss: 2.831e+03, Test loss: 7.825e+04, MSE(e): 1.806e-04, MSE(pi1): 2.756e-02, MSE(pi2): 1.757e-04, MSE(pi3): 7.496e-03\n",
      "Epoch 31800, Train loss: 2.802e+03, Test loss: 7.794e+04, MSE(e): 1.786e-04, MSE(pi1): 2.736e-02, MSE(pi2): 1.740e-04, MSE(pi3): 7.429e-03\n",
      "Epoch 31900, Train loss: 2.775e+03, Test loss: 7.779e+04, MSE(e): 1.767e-04, MSE(pi1): 2.721e-02, MSE(pi2): 1.724e-04, MSE(pi3): 7.359e-03\n",
      "Epoch 32000, Train loss: 2.750e+03, Test loss: 7.735e+04, MSE(e): 1.747e-04, MSE(pi1): 2.750e-02, MSE(pi2): 1.708e-04, MSE(pi3): 7.270e-03\n",
      "Epoch 32100, Train loss: 2.721e+03, Test loss: 7.717e+04, MSE(e): 1.730e-04, MSE(pi1): 2.688e-02, MSE(pi2): 1.693e-04, MSE(pi3): 7.219e-03\n",
      "Epoch 32200, Train loss: 2.692e+03, Test loss: 7.680e+04, MSE(e): 1.710e-04, MSE(pi1): 2.661e-02, MSE(pi2): 1.677e-04, MSE(pi3): 7.157e-03\n",
      "Epoch 32300, Train loss: 2.666e+03, Test loss: 7.649e+04, MSE(e): 1.693e-04, MSE(pi1): 2.644e-02, MSE(pi2): 1.662e-04, MSE(pi3): 7.088e-03\n",
      "Epoch 32400, Train loss: 2.647e+03, Test loss: 7.605e+04, MSE(e): 1.682e-04, MSE(pi1): 2.628e-02, MSE(pi2): 1.650e-04, MSE(pi3): 7.021e-03\n",
      "Epoch 32500, Train loss: 2.615e+03, Test loss: 7.592e+04, MSE(e): 1.658e-04, MSE(pi1): 2.616e-02, MSE(pi2): 1.633e-04, MSE(pi3): 6.949e-03\n",
      "Epoch 32600, Train loss: 2.590e+03, Test loss: 7.558e+04, MSE(e): 1.641e-04, MSE(pi1): 2.605e-02, MSE(pi2): 1.619e-04, MSE(pi3): 6.878e-03\n",
      "Epoch 32700, Train loss: 2.565e+03, Test loss: 7.540e+04, MSE(e): 1.625e-04, MSE(pi1): 2.574e-02, MSE(pi2): 1.605e-04, MSE(pi3): 6.823e-03\n",
      "Epoch 32800, Train loss: 2.541e+03, Test loss: 7.512e+04, MSE(e): 1.609e-04, MSE(pi1): 2.554e-02, MSE(pi2): 1.592e-04, MSE(pi3): 6.766e-03\n",
      "Epoch 32900, Train loss: 2.516e+03, Test loss: 7.484e+04, MSE(e): 1.593e-04, MSE(pi1): 2.549e-02, MSE(pi2): 1.578e-04, MSE(pi3): 6.685e-03\n",
      "Epoch 33000, Train loss: 2.526e+03, Test loss: 7.479e+04, MSE(e): 1.611e-04, MSE(pi1): 2.514e-02, MSE(pi2): 1.580e-04, MSE(pi3): 6.638e-03\n",
      "Epoch 33100, Train loss: 2.470e+03, Test loss: 7.429e+04, MSE(e): 1.562e-04, MSE(pi1): 2.515e-02, MSE(pi2): 1.553e-04, MSE(pi3): 6.559e-03\n",
      "Epoch 33200, Train loss: 2.447e+03, Test loss: 7.407e+04, MSE(e): 1.548e-04, MSE(pi1): 2.493e-02, MSE(pi2): 1.540e-04, MSE(pi3): 6.502e-03\n",
      "Epoch 33300, Train loss: 2.425e+03, Test loss: 7.377e+04, MSE(e): 1.533e-04, MSE(pi1): 2.478e-02, MSE(pi2): 1.528e-04, MSE(pi3): 6.440e-03\n",
      "Epoch 33400, Train loss: 2.405e+03, Test loss: 7.353e+04, MSE(e): 1.519e-04, MSE(pi1): 2.463e-02, MSE(pi2): 1.516e-04, MSE(pi3): 6.397e-03\n",
      "Epoch 33500, Train loss: 2.382e+03, Test loss: 7.328e+04, MSE(e): 1.505e-04, MSE(pi1): 2.447e-02, MSE(pi2): 1.504e-04, MSE(pi3): 6.319e-03\n",
      "Epoch 33600, Train loss: 2.374e+03, Test loss: 7.323e+04, MSE(e): 1.504e-04, MSE(pi1): 2.429e-02, MSE(pi2): 1.499e-04, MSE(pi3): 6.262e-03\n",
      "Epoch 33700, Train loss: 2.340e+03, Test loss: 7.272e+04, MSE(e): 1.478e-04, MSE(pi1): 2.422e-02, MSE(pi2): 1.482e-04, MSE(pi3): 6.200e-03\n",
      "Epoch 33800, Train loss: 2.321e+03, Test loss: 7.252e+04, MSE(e): 1.465e-04, MSE(pi1): 2.404e-02, MSE(pi2): 1.471e-04, MSE(pi3): 6.156e-03\n",
      "Epoch 33900, Train loss: 2.303e+03, Test loss: 7.229e+04, MSE(e): 1.454e-04, MSE(pi1): 2.416e-02, MSE(pi2): 1.461e-04, MSE(pi3): 6.069e-03\n",
      "Epoch 34000, Train loss: 2.281e+03, Test loss: 7.202e+04, MSE(e): 1.440e-04, MSE(pi1): 2.377e-02, MSE(pi2): 1.450e-04, MSE(pi3): 6.032e-03\n",
      "Epoch 34100, Train loss: 2.262e+03, Test loss: 7.182e+04, MSE(e): 1.428e-04, MSE(pi1): 2.363e-02, MSE(pi2): 1.439e-04, MSE(pi3): 5.977e-03\n",
      "Epoch 34200, Train loss: 2.244e+03, Test loss: 7.158e+04, MSE(e): 1.416e-04, MSE(pi1): 2.350e-02, MSE(pi2): 1.430e-04, MSE(pi3): 5.923e-03\n",
      "Epoch 34300, Train loss: 2.225e+03, Test loss: 7.135e+04, MSE(e): 1.404e-04, MSE(pi1): 2.336e-02, MSE(pi2): 1.419e-04, MSE(pi3): 5.872e-03\n",
      "Epoch 34400, Train loss: 2.207e+03, Test loss: 7.107e+04, MSE(e): 1.393e-04, MSE(pi1): 2.325e-02, MSE(pi2): 1.410e-04, MSE(pi3): 5.815e-03\n",
      "Epoch 34500, Train loss: 2.195e+03, Test loss: 7.043e+04, MSE(e): 1.387e-04, MSE(pi1): 2.328e-02, MSE(pi2): 1.405e-04, MSE(pi3): 5.753e-03\n",
      "Epoch 34600, Train loss: 2.182e+03, Test loss: 7.047e+04, MSE(e): 1.378e-04, MSE(pi1): 2.348e-02, MSE(pi2): 1.394e-04, MSE(pi3): 5.687e-03\n",
      "Epoch 34700, Train loss: 2.155e+03, Test loss: 7.032e+04, MSE(e): 1.360e-04, MSE(pi1): 2.286e-02, MSE(pi2): 1.382e-04, MSE(pi3): 5.663e-03\n",
      "Epoch 34800, Train loss: 2.138e+03, Test loss: 7.025e+04, MSE(e): 1.349e-04, MSE(pi1): 2.269e-02, MSE(pi2): 1.373e-04, MSE(pi3): 5.618e-03\n",
      "Epoch 34900, Train loss: 2.121e+03, Test loss: 6.985e+04, MSE(e): 1.338e-04, MSE(pi1): 2.267e-02, MSE(pi2): 1.364e-04, MSE(pi3): 5.562e-03\n",
      "Epoch 35000, Train loss: 2.104e+03, Test loss: 6.972e+04, MSE(e): 1.328e-04, MSE(pi1): 2.253e-02, MSE(pi2): 1.355e-04, MSE(pi3): 5.510e-03\n",
      "Epoch 35100, Train loss: 2.088e+03, Test loss: 6.947e+04, MSE(e): 1.317e-04, MSE(pi1): 2.243e-02, MSE(pi2): 1.346e-04, MSE(pi3): 5.461e-03\n",
      "Epoch 35200, Train loss: 2.074e+03, Test loss: 6.915e+04, MSE(e): 1.309e-04, MSE(pi1): 2.232e-02, MSE(pi2): 1.339e-04, MSE(pi3): 5.415e-03\n",
      "Epoch 35300, Train loss: 2.057e+03, Test loss: 6.913e+04, MSE(e): 1.298e-04, MSE(pi1): 2.223e-02, MSE(pi2): 1.330e-04, MSE(pi3): 5.365e-03\n",
      "Epoch 35400, Train loss: 2.046e+03, Test loss: 6.873e+04, MSE(e): 1.293e-04, MSE(pi1): 2.221e-02, MSE(pi2): 1.323e-04, MSE(pi3): 5.312e-03\n",
      "Epoch 35500, Train loss: 2.035e+03, Test loss: 6.864e+04, MSE(e): 1.280e-04, MSE(pi1): 2.241e-02, MSE(pi2): 1.315e-04, MSE(pi3): 5.305e-03\n",
      "Epoch 35600, Train loss: 2.016e+03, Test loss: 6.816e+04, MSE(e): 1.274e-04, MSE(pi1): 2.206e-02, MSE(pi2): 1.308e-04, MSE(pi3): 5.217e-03\n",
      "Epoch 35700, Train loss: 1.999e+03, Test loss: 6.822e+04, MSE(e): 1.262e-04, MSE(pi1): 2.208e-02, MSE(pi2): 1.299e-04, MSE(pi3): 5.166e-03\n",
      "Epoch 35800, Train loss: 1.991e+03, Test loss: 6.815e+04, MSE(e): 1.257e-04, MSE(pi1): 2.200e-02, MSE(pi2): 1.294e-04, MSE(pi3): 5.140e-03\n",
      "Epoch 35900, Train loss: 1.968e+03, Test loss: 6.766e+04, MSE(e): 1.242e-04, MSE(pi1): 2.159e-02, MSE(pi2): 1.284e-04, MSE(pi3): 5.098e-03\n",
      "Epoch 36000, Train loss: 1.954e+03, Test loss: 6.745e+04, MSE(e): 1.233e-04, MSE(pi1): 2.149e-02, MSE(pi2): 1.276e-04, MSE(pi3): 5.055e-03\n",
      "Epoch 36100, Train loss: 1.940e+03, Test loss: 6.711e+04, MSE(e): 1.225e-04, MSE(pi1): 2.140e-02, MSE(pi2): 1.269e-04, MSE(pi3): 5.013e-03\n",
      "Epoch 36200, Train loss: 1.927e+03, Test loss: 6.689e+04, MSE(e): 1.216e-04, MSE(pi1): 2.125e-02, MSE(pi2): 1.262e-04, MSE(pi3): 4.982e-03\n",
      "Epoch 36300, Train loss: 1.924e+03, Test loss: 6.636e+04, MSE(e): 1.218e-04, MSE(pi1): 2.135e-02, MSE(pi2): 1.259e-04, MSE(pi3): 4.918e-03\n",
      "Epoch 36400, Train loss: 1.916e+03, Test loss: 6.655e+04, MSE(e): 1.216e-04, MSE(pi1): 2.104e-02, MSE(pi2): 1.255e-04, MSE(pi3): 4.893e-03\n",
      "Epoch 36500, Train loss: 1.886e+03, Test loss: 6.608e+04, MSE(e): 1.191e-04, MSE(pi1): 2.106e-02, MSE(pi2): 1.241e-04, MSE(pi3): 4.844e-03\n",
      "Epoch 36600, Train loss: 1.876e+03, Test loss: 6.579e+04, MSE(e): 1.183e-04, MSE(pi1): 2.103e-02, MSE(pi2): 1.234e-04, MSE(pi3): 4.822e-03\n",
      "Epoch 36700, Train loss: 1.864e+03, Test loss: 6.530e+04, MSE(e): 1.178e-04, MSE(pi1): 2.092e-02, MSE(pi2): 1.230e-04, MSE(pi3): 4.760e-03\n",
      "Epoch 36800, Train loss: 1.848e+03, Test loss: 6.528e+04, MSE(e): 1.167e-04, MSE(pi1): 2.080e-02, MSE(pi2): 1.221e-04, MSE(pi3): 4.723e-03\n",
      "Epoch 36900, Train loss: 1.836e+03, Test loss: 6.502e+04, MSE(e): 1.160e-04, MSE(pi1): 2.074e-02, MSE(pi2): 1.214e-04, MSE(pi3): 4.683e-03\n",
      "Epoch 37000, Train loss: 1.825e+03, Test loss: 6.476e+04, MSE(e): 1.152e-04, MSE(pi1): 2.096e-02, MSE(pi2): 1.208e-04, MSE(pi3): 4.630e-03\n",
      "Epoch 37100, Train loss: 1.811e+03, Test loss: 6.455e+04, MSE(e): 1.145e-04, MSE(pi1): 2.049e-02, MSE(pi2): 1.202e-04, MSE(pi3): 4.612e-03\n",
      "Epoch 37200, Train loss: 1.801e+03, Test loss: 6.436e+04, MSE(e): 1.138e-04, MSE(pi1): 2.060e-02, MSE(pi2): 1.196e-04, MSE(pi3): 4.574e-03\n",
      "Epoch 37300, Train loss: 1.792e+03, Test loss: 6.396e+04, MSE(e): 1.133e-04, MSE(pi1): 2.023e-02, MSE(pi2): 1.191e-04, MSE(pi3): 4.559e-03\n",
      "Epoch 37400, Train loss: 1.777e+03, Test loss: 6.381e+04, MSE(e): 1.124e-04, MSE(pi1): 2.022e-02, MSE(pi2): 1.184e-04, MSE(pi3): 4.500e-03\n",
      "Epoch 37500, Train loss: 1.774e+03, Test loss: 6.339e+04, MSE(e): 1.126e-04, MSE(pi1): 2.021e-02, MSE(pi2): 1.181e-04, MSE(pi3): 4.458e-03\n",
      "Epoch 37600, Train loss: 1.753e+03, Test loss: 6.323e+04, MSE(e): 1.110e-04, MSE(pi1): 2.010e-02, MSE(pi2): 1.172e-04, MSE(pi3): 4.422e-03\n",
      "Epoch 37700, Train loss: 1.742e+03, Test loss: 6.303e+04, MSE(e): 1.103e-04, MSE(pi1): 1.996e-02, MSE(pi2): 1.166e-04, MSE(pi3): 4.392e-03\n",
      "Epoch 37800, Train loss: 1.731e+03, Test loss: 6.274e+04, MSE(e): 1.096e-04, MSE(pi1): 1.989e-02, MSE(pi2): 1.160e-04, MSE(pi3): 4.356e-03\n",
      "Epoch 37900, Train loss: 1.720e+03, Test loss: 6.244e+04, MSE(e): 1.090e-04, MSE(pi1): 1.983e-02, MSE(pi2): 1.156e-04, MSE(pi3): 4.316e-03\n",
      "Epoch 38000, Train loss: 1.718e+03, Test loss: 6.243e+04, MSE(e): 1.092e-04, MSE(pi1): 1.980e-02, MSE(pi2): 1.153e-04, MSE(pi3): 4.276e-03\n",
      "Epoch 38100, Train loss: 1.698e+03, Test loss: 6.202e+04, MSE(e): 1.077e-04, MSE(pi1): 1.969e-02, MSE(pi2): 1.144e-04, MSE(pi3): 4.244e-03\n",
      "Epoch 38200, Train loss: 1.691e+03, Test loss: 6.154e+04, MSE(e): 1.074e-04, MSE(pi1): 1.972e-02, MSE(pi2): 1.141e-04, MSE(pi3): 4.200e-03\n",
      "Epoch 38300, Train loss: 1.682e+03, Test loss: 6.169e+04, MSE(e): 1.069e-04, MSE(pi1): 1.957e-02, MSE(pi2): 1.135e-04, MSE(pi3): 4.171e-03\n",
      "Epoch 38400, Train loss: 1.667e+03, Test loss: 6.130e+04, MSE(e): 1.059e-04, MSE(pi1): 1.938e-02, MSE(pi2): 1.129e-04, MSE(pi3): 4.147e-03\n",
      "Epoch 38500, Train loss: 1.660e+03, Test loss: 6.113e+04, MSE(e): 1.056e-04, MSE(pi1): 1.938e-02, MSE(pi2): 1.125e-04, MSE(pi3): 4.105e-03\n",
      "Epoch 38600, Train loss: 1.647e+03, Test loss: 6.078e+04, MSE(e): 1.047e-04, MSE(pi1): 1.935e-02, MSE(pi2): 1.119e-04, MSE(pi3): 4.069e-03\n",
      "Epoch 38700, Train loss: 1.638e+03, Test loss: 6.057e+04, MSE(e): 1.042e-04, MSE(pi1): 1.922e-02, MSE(pi2): 1.114e-04, MSE(pi3): 4.038e-03\n",
      "Epoch 38800, Train loss: 1.628e+03, Test loss: 6.037e+04, MSE(e): 1.036e-04, MSE(pi1): 1.914e-02, MSE(pi2): 1.109e-04, MSE(pi3): 4.006e-03\n",
      "Epoch 38900, Train loss: 1.619e+03, Test loss: 6.013e+04, MSE(e): 1.031e-04, MSE(pi1): 1.919e-02, MSE(pi2): 1.105e-04, MSE(pi3): 3.964e-03\n",
      "Epoch 39000, Train loss: 1.610e+03, Test loss: 5.988e+04, MSE(e): 1.026e-04, MSE(pi1): 1.896e-02, MSE(pi2): 1.100e-04, MSE(pi3): 3.945e-03\n",
      "Epoch 39100, Train loss: 1.603e+03, Test loss: 5.968e+04, MSE(e): 1.019e-04, MSE(pi1): 1.905e-02, MSE(pi2): 1.095e-04, MSE(pi3): 3.933e-03\n",
      "Epoch 39200, Train loss: 1.591e+03, Test loss: 5.941e+04, MSE(e): 1.015e-04, MSE(pi1): 1.881e-02, MSE(pi2): 1.091e-04, MSE(pi3): 3.878e-03\n",
      "Epoch 39300, Train loss: 1.583e+03, Test loss: 5.933e+04, MSE(e): 1.010e-04, MSE(pi1): 1.867e-02, MSE(pi2): 1.087e-04, MSE(pi3): 3.856e-03\n",
      "Epoch 39400, Train loss: 1.574e+03, Test loss: 5.906e+04, MSE(e): 1.004e-04, MSE(pi1): 1.893e-02, MSE(pi2): 1.081e-04, MSE(pi3): 3.800e-03\n",
      "Epoch 39500, Train loss: 1.563e+03, Test loss: 5.888e+04, MSE(e): 9.990e-05, MSE(pi1): 1.863e-02, MSE(pi2): 1.077e-04, MSE(pi3): 3.777e-03\n",
      "Epoch 39600, Train loss: 1.558e+03, Test loss: 5.860e+04, MSE(e): 9.939e-05, MSE(pi1): 1.913e-02, MSE(pi2): 1.073e-04, MSE(pi3): 3.727e-03\n",
      "Epoch 39700, Train loss: 1.545e+03, Test loss: 5.838e+04, MSE(e): 9.888e-05, MSE(pi1): 1.842e-02, MSE(pi2): 1.069e-04, MSE(pi3): 3.719e-03\n",
      "Epoch 39800, Train loss: 1.537e+03, Test loss: 5.814e+04, MSE(e): 9.845e-05, MSE(pi1): 1.836e-02, MSE(pi2): 1.064e-04, MSE(pi3): 3.687e-03\n",
      "Epoch 39900, Train loss: 1.536e+03, Test loss: 5.777e+04, MSE(e): 9.859e-05, MSE(pi1): 1.856e-02, MSE(pi2): 1.065e-04, MSE(pi3): 3.647e-03\n",
      "Epoch 40000, Train loss: 1.521e+03, Test loss: 5.781e+04, MSE(e): 9.764e-05, MSE(pi1): 1.823e-02, MSE(pi2): 1.057e-04, MSE(pi3): 3.625e-03\n",
      "Epoch 40100, Train loss: 1.514e+03, Test loss: 5.762e+04, MSE(e): 9.721e-05, MSE(pi1): 1.822e-02, MSE(pi2): 1.053e-04, MSE(pi3): 3.599e-03\n",
      "Epoch 40200, Train loss: 1.503e+03, Test loss: 5.734e+04, MSE(e): 9.658e-05, MSE(pi1): 1.816e-02, MSE(pi2): 1.048e-04, MSE(pi3): 3.559e-03\n",
      "Epoch 40300, Train loss: 1.494e+03, Test loss: 5.716e+04, MSE(e): 9.609e-05, MSE(pi1): 1.797e-02, MSE(pi2): 1.044e-04, MSE(pi3): 3.535e-03\n",
      "Epoch 40400, Train loss: 1.486e+03, Test loss: 5.691e+04, MSE(e): 9.566e-05, MSE(pi1): 1.792e-02, MSE(pi2): 1.040e-04, MSE(pi3): 3.503e-03\n",
      "Epoch 40500, Train loss: 1.478e+03, Test loss: 5.672e+04, MSE(e): 9.521e-05, MSE(pi1): 1.781e-02, MSE(pi2): 1.037e-04, MSE(pi3): 3.476e-03\n",
      "Epoch 40600, Train loss: 1.470e+03, Test loss: 5.651e+04, MSE(e): 9.478e-05, MSE(pi1): 1.776e-02, MSE(pi2): 1.033e-04, MSE(pi3): 3.445e-03\n",
      "Epoch 40700, Train loss: 1.463e+03, Test loss: 5.636e+04, MSE(e): 9.448e-05, MSE(pi1): 1.767e-02, MSE(pi2): 1.030e-04, MSE(pi3): 3.418e-03\n",
      "Epoch 40800, Train loss: 1.454e+03, Test loss: 5.607e+04, MSE(e): 9.395e-05, MSE(pi1): 1.759e-02, MSE(pi2): 1.026e-04, MSE(pi3): 3.386e-03\n",
      "Epoch 40900, Train loss: 1.463e+03, Test loss: 5.612e+04, MSE(e): 9.496e-05, MSE(pi1): 1.751e-02, MSE(pi2): 1.028e-04, MSE(pi3): 3.381e-03\n",
      "Epoch 41000, Train loss: 1.441e+03, Test loss: 5.579e+04, MSE(e): 9.336e-05, MSE(pi1): 1.746e-02, MSE(pi2): 1.019e-04, MSE(pi3): 3.327e-03\n",
      "Epoch 41100, Train loss: 1.443e+03, Test loss: 5.542e+04, MSE(e): 9.371e-05, MSE(pi1): 1.754e-02, MSE(pi2): 1.018e-04, MSE(pi3): 3.300e-03\n",
      "Epoch 41200, Train loss: 1.427e+03, Test loss: 5.528e+04, MSE(e): 9.238e-05, MSE(pi1): 1.780e-02, MSE(pi2): 1.012e-04, MSE(pi3): 3.250e-03\n",
      "Epoch 41300, Train loss: 1.416e+03, Test loss: 5.517e+04, MSE(e): 9.193e-05, MSE(pi1): 1.728e-02, MSE(pi2): 1.008e-04, MSE(pi3): 3.234e-03\n",
      "Epoch 41400, Train loss: 1.408e+03, Test loss: 5.500e+04, MSE(e): 9.155e-05, MSE(pi1): 1.719e-02, MSE(pi2): 1.004e-04, MSE(pi3): 3.205e-03\n",
      "Epoch 41500, Train loss: 1.403e+03, Test loss: 5.486e+04, MSE(e): 9.134e-05, MSE(pi1): 1.725e-02, MSE(pi2): 1.002e-04, MSE(pi3): 3.170e-03\n",
      "Epoch 41600, Train loss: 1.394e+03, Test loss: 5.470e+04, MSE(e): 9.083e-05, MSE(pi1): 1.700e-02, MSE(pi2): 9.979e-05, MSE(pi3): 3.152e-03\n",
      "Epoch 41700, Train loss: 1.395e+03, Test loss: 5.447e+04, MSE(e): 9.045e-05, MSE(pi1): 1.738e-02, MSE(pi2): 9.945e-05, MSE(pi3): 3.162e-03\n",
      "Epoch 41800, Train loss: 1.386e+03, Test loss: 5.415e+04, MSE(e): 9.083e-05, MSE(pi1): 1.688e-02, MSE(pi2): 9.938e-05, MSE(pi3): 3.091e-03\n",
      "Epoch 41900, Train loss: 1.371e+03, Test loss: 5.407e+04, MSE(e): 8.971e-05, MSE(pi1): 1.673e-02, MSE(pi2): 9.880e-05, MSE(pi3): 3.067e-03\n",
      "Epoch 42000, Train loss: 1.364e+03, Test loss: 5.386e+04, MSE(e): 8.937e-05, MSE(pi1): 1.663e-02, MSE(pi2): 9.848e-05, MSE(pi3): 3.041e-03\n",
      "Epoch 42100, Train loss: 1.362e+03, Test loss: 5.362e+04, MSE(e): 8.940e-05, MSE(pi1): 1.661e-02, MSE(pi2): 9.830e-05, MSE(pi3): 3.018e-03\n",
      "Epoch 42200, Train loss: 1.359e+03, Test loss: 5.350e+04, MSE(e): 8.917e-05, MSE(pi1): 1.701e-02, MSE(pi2): 9.805e-05, MSE(pi3): 2.970e-03\n",
      "Epoch 42300, Train loss: 1.348e+03, Test loss: 5.339e+04, MSE(e): 8.880e-05, MSE(pi1): 1.642e-02, MSE(pi2): 9.781e-05, MSE(pi3): 2.955e-03\n",
      "Epoch 42400, Train loss: 1.338e+03, Test loss: 5.308e+04, MSE(e): 8.797e-05, MSE(pi1): 1.651e-02, MSE(pi2): 9.724e-05, MSE(pi3): 2.928e-03\n",
      "Epoch 42500, Train loss: 1.332e+03, Test loss: 5.308e+04, MSE(e): 8.776e-05, MSE(pi1): 1.622e-02, MSE(pi2): 9.701e-05, MSE(pi3): 2.919e-03\n",
      "Epoch 42600, Train loss: 1.322e+03, Test loss: 5.282e+04, MSE(e): 8.730e-05, MSE(pi1): 1.614e-02, MSE(pi2): 9.664e-05, MSE(pi3): 2.873e-03\n",
      "Epoch 42700, Train loss: 1.317e+03, Test loss: 5.271e+04, MSE(e): 8.712e-05, MSE(pi1): 1.603e-02, MSE(pi2): 9.642e-05, MSE(pi3): 2.849e-03\n",
      "Epoch 42800, Train loss: 1.308e+03, Test loss: 5.247e+04, MSE(e): 8.665e-05, MSE(pi1): 1.608e-02, MSE(pi2): 9.606e-05, MSE(pi3): 2.811e-03\n",
      "Epoch 42900, Train loss: 1.301e+03, Test loss: 5.229e+04, MSE(e): 8.633e-05, MSE(pi1): 1.590e-02, MSE(pi2): 9.577e-05, MSE(pi3): 2.789e-03\n",
      "Epoch 43000, Train loss: 1.295e+03, Test loss: 5.218e+04, MSE(e): 8.604e-05, MSE(pi1): 1.580e-02, MSE(pi2): 9.550e-05, MSE(pi3): 2.765e-03\n",
      "Epoch 43100, Train loss: 1.289e+03, Test loss: 5.200e+04, MSE(e): 8.579e-05, MSE(pi1): 1.570e-02, MSE(pi2): 9.526e-05, MSE(pi3): 2.738e-03\n",
      "Epoch 43200, Train loss: 1.298e+03, Test loss: 5.166e+04, MSE(e): 8.704e-05, MSE(pi1): 1.574e-02, MSE(pi2): 9.555e-05, MSE(pi3): 2.702e-03\n",
      "Epoch 43300, Train loss: 1.275e+03, Test loss: 5.166e+04, MSE(e): 8.509e-05, MSE(pi1): 1.567e-02, MSE(pi2): 9.465e-05, MSE(pi3): 2.676e-03\n",
      "Epoch 43400, Train loss: 1.268e+03, Test loss: 5.144e+04, MSE(e): 8.481e-05, MSE(pi1): 1.543e-02, MSE(pi2): 9.438e-05, MSE(pi3): 2.658e-03\n",
      "Epoch 43500, Train loss: 1.262e+03, Test loss: 5.117e+04, MSE(e): 8.457e-05, MSE(pi1): 1.543e-02, MSE(pi2): 9.418e-05, MSE(pi3): 2.623e-03\n",
      "Epoch 43600, Train loss: 1.256e+03, Test loss: 5.116e+04, MSE(e): 8.420e-05, MSE(pi1): 1.524e-02, MSE(pi2): 9.384e-05, MSE(pi3): 2.617e-03\n",
      "Epoch 43700, Train loss: 1.249e+03, Test loss: 5.098e+04, MSE(e): 8.390e-05, MSE(pi1): 1.524e-02, MSE(pi2): 9.357e-05, MSE(pi3): 2.574e-03\n",
      "Epoch 43800, Train loss: 1.257e+03, Test loss: 5.069e+04, MSE(e): 8.494e-05, MSE(pi1): 1.529e-02, MSE(pi2): 9.411e-05, MSE(pi3): 2.542e-03\n",
      "Epoch 43900, Train loss: 1.236e+03, Test loss: 5.065e+04, MSE(e): 8.332e-05, MSE(pi1): 1.500e-02, MSE(pi2): 9.305e-05, MSE(pi3): 2.523e-03\n",
      "Epoch 44000, Train loss: 1.229e+03, Test loss: 5.050e+04, MSE(e): 8.305e-05, MSE(pi1): 1.490e-02, MSE(pi2): 9.280e-05, MSE(pi3): 2.499e-03\n",
      "Epoch 44100, Train loss: 1.244e+03, Test loss: 5.056e+04, MSE(e): 8.483e-05, MSE(pi1): 1.472e-02, MSE(pi2): 9.347e-05, MSE(pi3): 2.484e-03\n",
      "Epoch 44200, Train loss: 1.218e+03, Test loss: 5.022e+04, MSE(e): 8.254e-05, MSE(pi1): 1.487e-02, MSE(pi2): 9.231e-05, MSE(pi3): 2.435e-03\n",
      "Epoch 44300, Train loss: 1.211e+03, Test loss: 4.993e+04, MSE(e): 8.225e-05, MSE(pi1): 1.481e-02, MSE(pi2): 9.206e-05, MSE(pi3): 2.408e-03\n",
      "Epoch 44400, Train loss: 1.212e+03, Test loss: 4.968e+04, MSE(e): 8.210e-05, MSE(pi1): 1.516e-02, MSE(pi2): 9.187e-05, MSE(pi3): 2.392e-03\n",
      "Epoch 44500, Train loss: 1.199e+03, Test loss: 4.967e+04, MSE(e): 8.168e-05, MSE(pi1): 1.456e-02, MSE(pi2): 9.153e-05, MSE(pi3): 2.363e-03\n",
      "Epoch 44600, Train loss: 1.201e+03, Test loss: 4.939e+04, MSE(e): 8.227e-05, MSE(pi1): 1.443e-02, MSE(pi2): 9.161e-05, MSE(pi3): 2.339e-03\n",
      "Epoch 44700, Train loss: 1.187e+03, Test loss: 4.942e+04, MSE(e): 8.118e-05, MSE(pi1): 1.423e-02, MSE(pi2): 9.107e-05, MSE(pi3): 2.323e-03\n",
      "Epoch 44800, Train loss: 1.185e+03, Test loss: 4.925e+04, MSE(e): 8.090e-05, MSE(pi1): 1.490e-02, MSE(pi2): 9.081e-05, MSE(pi3): 2.273e-03\n",
      "Epoch 44900, Train loss: 1.182e+03, Test loss: 4.877e+04, MSE(e): 8.128e-05, MSE(pi1): 1.408e-02, MSE(pi2): 9.104e-05, MSE(pi3): 2.285e-03\n",
      "Epoch 45000, Train loss: 1.172e+03, Test loss: 4.886e+04, MSE(e): 8.071e-05, MSE(pi1): 1.407e-02, MSE(pi2): 9.044e-05, MSE(pi3): 2.240e-03\n",
      "Epoch 45100, Train loss: 1.166e+03, Test loss: 4.884e+04, MSE(e): 8.020e-05, MSE(pi1): 1.425e-02, MSE(pi2): 9.014e-05, MSE(pi3): 2.209e-03\n",
      "Epoch 45200, Train loss: 1.179e+03, Test loss: 4.850e+04, MSE(e): 8.203e-05, MSE(pi1): 1.408e-02, MSE(pi2): 9.068e-05, MSE(pi3): 2.181e-03\n",
      "Epoch 45300, Train loss: 1.160e+03, Test loss: 4.842e+04, MSE(e): 8.040e-05, MSE(pi1): 1.391e-02, MSE(pi2): 8.992e-05, MSE(pi3): 2.171e-03\n",
      "Epoch 45400, Train loss: 1.146e+03, Test loss: 4.841e+04, MSE(e): 7.944e-05, MSE(pi1): 1.365e-02, MSE(pi2): 8.945e-05, MSE(pi3): 2.148e-03\n",
      "Epoch 45500, Train loss: 1.139e+03, Test loss: 4.824e+04, MSE(e): 7.914e-05, MSE(pi1): 1.354e-02, MSE(pi2): 8.918e-05, MSE(pi3): 2.125e-03\n",
      "Epoch 45600, Train loss: 1.134e+03, Test loss: 4.806e+04, MSE(e): 7.889e-05, MSE(pi1): 1.342e-02, MSE(pi2): 8.895e-05, MSE(pi3): 2.105e-03\n",
      "Epoch 45700, Train loss: 1.128e+03, Test loss: 4.788e+04, MSE(e): 7.865e-05, MSE(pi1): 1.327e-02, MSE(pi2): 8.873e-05, MSE(pi3): 2.091e-03\n",
      "Epoch 45800, Train loss: 1.123e+03, Test loss: 4.772e+04, MSE(e): 7.845e-05, MSE(pi1): 1.314e-02, MSE(pi2): 8.853e-05, MSE(pi3): 2.075e-03\n",
      "Epoch 45900, Train loss: 1.117e+03, Test loss: 4.763e+04, MSE(e): 7.818e-05, MSE(pi1): 1.316e-02, MSE(pi2): 8.829e-05, MSE(pi3): 2.036e-03\n",
      "Epoch 46000, Train loss: 1.116e+03, Test loss: 4.781e+04, MSE(e): 7.834e-05, MSE(pi1): 1.296e-02, MSE(pi2): 8.831e-05, MSE(pi3): 2.030e-03\n",
      "Epoch 46100, Train loss: 1.107e+03, Test loss: 4.731e+04, MSE(e): 7.778e-05, MSE(pi1): 1.295e-02, MSE(pi2): 8.787e-05, MSE(pi3): 2.001e-03\n",
      "Epoch 46200, Train loss: 1.101e+03, Test loss: 4.724e+04, MSE(e): 7.751e-05, MSE(pi1): 1.283e-02, MSE(pi2): 8.766e-05, MSE(pi3): 1.976e-03\n",
      "Epoch 46300, Train loss: 1.096e+03, Test loss: 4.709e+04, MSE(e): 7.727e-05, MSE(pi1): 1.271e-02, MSE(pi2): 8.743e-05, MSE(pi3): 1.959e-03\n",
      "Epoch 46400, Train loss: 1.092e+03, Test loss: 4.687e+04, MSE(e): 7.709e-05, MSE(pi1): 1.267e-02, MSE(pi2): 8.726e-05, MSE(pi3): 1.941e-03\n",
      "Epoch 46500, Train loss: 1.088e+03, Test loss: 4.686e+04, MSE(e): 7.691e-05, MSE(pi1): 1.281e-02, MSE(pi2): 8.706e-05, MSE(pi3): 1.905e-03\n",
      "Epoch 46600, Train loss: 1.080e+03, Test loss: 4.671e+04, MSE(e): 7.662e-05, MSE(pi1): 1.243e-02, MSE(pi2): 8.681e-05, MSE(pi3): 1.898e-03\n",
      "Epoch 46700, Train loss: 1.075e+03, Test loss: 4.653e+04, MSE(e): 7.639e-05, MSE(pi1): 1.238e-02, MSE(pi2): 8.659e-05, MSE(pi3): 1.872e-03\n",
      "Epoch 46800, Train loss: 1.071e+03, Test loss: 4.637e+04, MSE(e): 7.618e-05, MSE(pi1): 1.234e-02, MSE(pi2): 8.640e-05, MSE(pi3): 1.859e-03\n",
      "Epoch 46900, Train loss: 1.066e+03, Test loss: 4.629e+04, MSE(e): 7.597e-05, MSE(pi1): 1.235e-02, MSE(pi2): 8.619e-05, MSE(pi3): 1.826e-03\n",
      "Epoch 47000, Train loss: 1.060e+03, Test loss: 4.614e+04, MSE(e): 7.575e-05, MSE(pi1): 1.214e-02, MSE(pi2): 8.599e-05, MSE(pi3): 1.812e-03\n",
      "Epoch 47100, Train loss: 1.055e+03, Test loss: 4.599e+04, MSE(e): 7.554e-05, MSE(pi1): 1.203e-02, MSE(pi2): 8.579e-05, MSE(pi3): 1.795e-03\n",
      "Epoch 47200, Train loss: 1.051e+03, Test loss: 4.594e+04, MSE(e): 7.544e-05, MSE(pi1): 1.192e-02, MSE(pi2): 8.565e-05, MSE(pi3): 1.778e-03\n",
      "Epoch 47300, Train loss: 1.046e+03, Test loss: 4.575e+04, MSE(e): 7.512e-05, MSE(pi1): 1.180e-02, MSE(pi2): 8.539e-05, MSE(pi3): 1.765e-03\n",
      "Epoch 47400, Train loss: 1.041e+03, Test loss: 4.562e+04, MSE(e): 7.492e-05, MSE(pi1): 1.176e-02, MSE(pi2): 8.520e-05, MSE(pi3): 1.741e-03\n",
      "Epoch 47500, Train loss: 1.036e+03, Test loss: 4.548e+04, MSE(e): 7.472e-05, MSE(pi1): 1.163e-02, MSE(pi2): 8.500e-05, MSE(pi3): 1.728e-03\n",
      "Epoch 47600, Train loss: 1.036e+03, Test loss: 4.543e+04, MSE(e): 7.493e-05, MSE(pi1): 1.159e-02, MSE(pi2): 8.502e-05, MSE(pi3): 1.708e-03\n",
      "Epoch 47700, Train loss: 1.027e+03, Test loss: 4.524e+04, MSE(e): 7.432e-05, MSE(pi1): 1.148e-02, MSE(pi2): 8.462e-05, MSE(pi3): 1.692e-03\n",
      "Epoch 47800, Train loss: 1.023e+03, Test loss: 4.511e+04, MSE(e): 7.412e-05, MSE(pi1): 1.137e-02, MSE(pi2): 8.443e-05, MSE(pi3): 1.682e-03\n",
      "Epoch 47900, Train loss: 1.021e+03, Test loss: 4.503e+04, MSE(e): 7.419e-05, MSE(pi1): 1.131e-02, MSE(pi2): 8.438e-05, MSE(pi3): 1.658e-03\n",
      "Epoch 48000, Train loss: 1.018e+03, Test loss: 4.479e+04, MSE(e): 7.409e-05, MSE(pi1): 1.143e-02, MSE(pi2): 8.416e-05, MSE(pi3): 1.630e-03\n",
      "Epoch 48100, Train loss: 1.010e+03, Test loss: 4.477e+04, MSE(e): 7.355e-05, MSE(pi1): 1.111e-02, MSE(pi2): 8.387e-05, MSE(pi3): 1.631e-03\n",
      "Epoch 48200, Train loss: 1.006e+03, Test loss: 4.459e+04, MSE(e): 7.338e-05, MSE(pi1): 1.102e-02, MSE(pi2): 8.368e-05, MSE(pi3): 1.617e-03\n",
      "Epoch 48300, Train loss: 1.002e+03, Test loss: 4.455e+04, MSE(e): 7.319e-05, MSE(pi1): 1.098e-02, MSE(pi2): 8.351e-05, MSE(pi3): 1.601e-03\n",
      "Epoch 48400, Train loss: 1.001e+03, Test loss: 4.446e+04, MSE(e): 7.301e-05, MSE(pi1): 1.148e-02, MSE(pi2): 8.333e-05, MSE(pi3): 1.565e-03\n",
      "Epoch 48500, Train loss: 9.926e+02, Test loss: 4.427e+04, MSE(e): 7.277e-05, MSE(pi1): 1.081e-02, MSE(pi2): 8.312e-05, MSE(pi3): 1.567e-03\n",
      "Epoch 48600, Train loss: 9.891e+02, Test loss: 4.411e+04, MSE(e): 7.263e-05, MSE(pi1): 1.071e-02, MSE(pi2): 8.295e-05, MSE(pi3): 1.556e-03\n",
      "Epoch 48700, Train loss: 9.848e+02, Test loss: 4.402e+04, MSE(e): 7.241e-05, MSE(pi1): 1.072e-02, MSE(pi2): 8.276e-05, MSE(pi3): 1.535e-03\n",
      "Epoch 48800, Train loss: 9.807e+02, Test loss: 4.397e+04, MSE(e): 7.223e-05, MSE(pi1): 1.059e-02, MSE(pi2): 8.259e-05, MSE(pi3): 1.524e-03\n",
      "Epoch 48900, Train loss: 9.791e+02, Test loss: 4.388e+04, MSE(e): 7.207e-05, MSE(pi1): 1.062e-02, MSE(pi2): 8.242e-05, MSE(pi3): 1.521e-03\n",
      "Epoch 49000, Train loss: 9.729e+02, Test loss: 4.368e+04, MSE(e): 7.186e-05, MSE(pi1): 1.038e-02, MSE(pi2): 8.223e-05, MSE(pi3): 1.504e-03\n",
      "Epoch 49100, Train loss: 9.690e+02, Test loss: 4.358e+04, MSE(e): 7.168e-05, MSE(pi1): 1.031e-02, MSE(pi2): 8.205e-05, MSE(pi3): 1.490e-03\n",
      "Epoch 49200, Train loss: 9.657e+02, Test loss: 4.340e+04, MSE(e): 7.155e-05, MSE(pi1): 1.025e-02, MSE(pi2): 8.189e-05, MSE(pi3): 1.476e-03\n",
      "Epoch 49300, Train loss: 9.682e+02, Test loss: 4.345e+04, MSE(e): 7.200e-05, MSE(pi1): 1.017e-02, MSE(pi2): 8.204e-05, MSE(pi3): 1.465e-03\n",
      "Epoch 49400, Train loss: 9.593e+02, Test loss: 4.325e+04, MSE(e): 7.115e-05, MSE(pi1): 1.027e-02, MSE(pi2): 8.154e-05, MSE(pi3): 1.450e-03\n",
      "Epoch 49500, Train loss: 9.920e+02, Test loss: 4.343e+04, MSE(e): 7.473e-05, MSE(pi1): 9.883e-03, MSE(pi2): 8.304e-05, MSE(pi3): 1.458e-03\n",
      "Epoch 49600, Train loss: 9.516e+02, Test loss: 4.305e+04, MSE(e): 7.083e-05, MSE(pi1): 9.906e-03, MSE(pi2): 8.120e-05, MSE(pi3): 1.441e-03\n",
      "Epoch 49700, Train loss: 9.483e+02, Test loss: 4.290e+04, MSE(e): 7.064e-05, MSE(pi1): 9.902e-03, MSE(pi2): 8.102e-05, MSE(pi3): 1.428e-03\n",
      "Epoch 49800, Train loss: 9.444e+02, Test loss: 4.279e+04, MSE(e): 7.052e-05, MSE(pi1): 9.830e-03, MSE(pi2): 8.087e-05, MSE(pi3): 1.409e-03\n",
      "Epoch 49900, Train loss: 9.405e+02, Test loss: 4.272e+04, MSE(e): 7.030e-05, MSE(pi1): 9.711e-03, MSE(pi2): 8.069e-05, MSE(pi3): 1.403e-03\n",
      "Epoch 50000, Train loss: 9.371e+02, Test loss: 4.259e+04, MSE(e): 7.013e-05, MSE(pi1): 9.662e-03, MSE(pi2): 8.053e-05, MSE(pi3): 1.391e-03\n",
      "Epoch 50100, Train loss: 9.338e+02, Test loss: 4.249e+04, MSE(e): 6.997e-05, MSE(pi1): 9.598e-03, MSE(pi2): 8.036e-05, MSE(pi3): 1.381e-03\n",
      "Epoch 50200, Train loss: 9.307e+02, Test loss: 4.240e+04, MSE(e): 6.981e-05, MSE(pi1): 9.524e-03, MSE(pi2): 8.020e-05, MSE(pi3): 1.373e-03\n",
      "Epoch 50300, Train loss: 9.276e+02, Test loss: 4.228e+04, MSE(e): 6.965e-05, MSE(pi1): 9.457e-03, MSE(pi2): 8.004e-05, MSE(pi3): 1.364e-03\n",
      "Epoch 50400, Train loss: 9.245e+02, Test loss: 4.224e+04, MSE(e): 6.949e-05, MSE(pi1): 9.424e-03, MSE(pi2): 7.988e-05, MSE(pi3): 1.353e-03\n",
      "Epoch 50500, Train loss: 9.218e+02, Test loss: 4.208e+04, MSE(e): 6.933e-05, MSE(pi1): 9.446e-03, MSE(pi2): 7.972e-05, MSE(pi3): 1.339e-03\n",
      "Epoch 50600, Train loss: 9.181e+02, Test loss: 4.198e+04, MSE(e): 6.917e-05, MSE(pi1): 9.271e-03, MSE(pi2): 7.956e-05, MSE(pi3): 1.337e-03\n",
      "Epoch 50700, Train loss: 9.190e+02, Test loss: 4.196e+04, MSE(e): 6.937e-05, MSE(pi1): 9.304e-03, MSE(pi2): 7.958e-05, MSE(pi3): 1.322e-03\n",
      "Epoch 50800, Train loss: 9.131e+02, Test loss: 4.176e+04, MSE(e): 6.886e-05, MSE(pi1): 9.248e-03, MSE(pi2): 7.925e-05, MSE(pi3): 1.320e-03\n",
      "Epoch 50900, Train loss: 9.241e+02, Test loss: 4.187e+04, MSE(e): 6.947e-05, MSE(pi1): 1.003e-02, MSE(pi2): 7.945e-05, MSE(pi3): 1.291e-03\n",
      "Epoch 51000, Train loss: 9.075e+02, Test loss: 4.155e+04, MSE(e): 6.864e-05, MSE(pi1): 9.089e-03, MSE(pi2): 7.895e-05, MSE(pi3): 1.301e-03\n",
      "Epoch 51100, Train loss: 9.058e+02, Test loss: 4.161e+04, MSE(e): 6.859e-05, MSE(pi1): 9.006e-03, MSE(pi2): 7.887e-05, MSE(pi3): 1.297e-03\n",
      "Epoch 51200, Train loss: 9.006e+02, Test loss: 4.138e+04, MSE(e): 6.823e-05, MSE(pi1): 8.922e-03, MSE(pi2): 7.861e-05, MSE(pi3): 1.290e-03\n",
      "Epoch 51300, Train loss: 9.029e+02, Test loss: 4.129e+04, MSE(e): 6.808e-05, MSE(pi1): 9.092e-03, MSE(pi2): 7.846e-05, MSE(pi3): 1.311e-03\n",
      "Epoch 51400, Train loss: 8.965e+02, Test loss: 4.129e+04, MSE(e): 6.806e-05, MSE(pi1): 8.758e-03, MSE(pi2): 7.837e-05, MSE(pi3): 1.282e-03\n",
      "Epoch 51500, Train loss: 8.924e+02, Test loss: 4.109e+04, MSE(e): 6.777e-05, MSE(pi1): 8.727e-03, MSE(pi2): 7.814e-05, MSE(pi3): 1.273e-03\n",
      "Epoch 51600, Train loss: 8.922e+02, Test loss: 4.105e+04, MSE(e): 6.763e-05, MSE(pi1): 8.728e-03, MSE(pi2): 7.799e-05, MSE(pi3): 1.286e-03\n",
      "Epoch 51700, Train loss: 8.873e+02, Test loss: 4.095e+04, MSE(e): 6.749e-05, MSE(pi1): 8.604e-03, MSE(pi2): 7.785e-05, MSE(pi3): 1.262e-03\n",
      "Epoch 51800, Train loss: 8.872e+02, Test loss: 4.089e+04, MSE(e): 6.740e-05, MSE(pi1): 8.674e-03, MSE(pi2): 7.773e-05, MSE(pi3): 1.264e-03\n",
      "Epoch 51900, Train loss: 8.849e+02, Test loss: 4.074e+04, MSE(e): 6.718e-05, MSE(pi1): 8.997e-03, MSE(pi2): 7.753e-05, MSE(pi3): 1.231e-03\n",
      "Epoch 52000, Train loss: 8.799e+02, Test loss: 4.064e+04, MSE(e): 6.703e-05, MSE(pi1): 8.445e-03, MSE(pi2): 7.738e-05, MSE(pi3): 1.251e-03\n",
      "Epoch 52100, Train loss: 8.775e+02, Test loss: 4.047e+04, MSE(e): 6.693e-05, MSE(pi1): 8.428e-03, MSE(pi2): 7.725e-05, MSE(pi3): 1.239e-03\n",
      "Epoch 52200, Train loss: 8.748e+02, Test loss: 4.046e+04, MSE(e): 6.678e-05, MSE(pi1): 8.366e-03, MSE(pi2): 7.711e-05, MSE(pi3): 1.233e-03\n",
      "Epoch 52300, Train loss: 8.719e+02, Test loss: 4.036e+04, MSE(e): 6.659e-05, MSE(pi1): 8.339e-03, MSE(pi2): 7.693e-05, MSE(pi3): 1.226e-03\n",
      "Epoch 52400, Train loss: 8.696e+02, Test loss: 4.027e+04, MSE(e): 6.645e-05, MSE(pi1): 8.268e-03, MSE(pi2): 7.678e-05, MSE(pi3): 1.224e-03\n",
      "Epoch 52500, Train loss: 8.674e+02, Test loss: 4.018e+04, MSE(e): 6.632e-05, MSE(pi1): 8.238e-03, MSE(pi2): 7.664e-05, MSE(pi3): 1.217e-03\n",
      "Epoch 52600, Train loss: 8.678e+02, Test loss: 4.003e+04, MSE(e): 6.619e-05, MSE(pi1): 8.513e-03, MSE(pi2): 7.650e-05, MSE(pi3): 1.206e-03\n",
      "Epoch 52700, Train loss: 8.626e+02, Test loss: 4.002e+04, MSE(e): 6.602e-05, MSE(pi1): 8.140e-03, MSE(pi2): 7.635e-05, MSE(pi3): 1.209e-03\n",
      "Epoch 52800, Train loss: 8.656e+02, Test loss: 4.000e+04, MSE(e): 6.620e-05, MSE(pi1): 8.488e-03, MSE(pi2): 7.631e-05, MSE(pi3): 1.186e-03\n",
      "Epoch 52900, Train loss: 8.583e+02, Test loss: 3.985e+04, MSE(e): 6.574e-05, MSE(pi1): 8.120e-03, MSE(pi2): 7.606e-05, MSE(pi3): 1.196e-03\n",
      "Epoch 53000, Train loss: 8.561e+02, Test loss: 3.975e+04, MSE(e): 6.562e-05, MSE(pi1): 8.016e-03, MSE(pi2): 7.591e-05, MSE(pi3): 1.196e-03\n",
      "Epoch 53100, Train loss: 8.552e+02, Test loss: 3.977e+04, MSE(e): 6.561e-05, MSE(pi1): 8.004e-03, MSE(pi2): 7.585e-05, MSE(pi3): 1.189e-03\n",
      "Epoch 53200, Train loss: 8.518e+02, Test loss: 3.961e+04, MSE(e): 6.533e-05, MSE(pi1): 7.879e-03, MSE(pi2): 7.563e-05, MSE(pi3): 1.196e-03\n",
      "Epoch 53300, Train loss: 8.514e+02, Test loss: 3.958e+04, MSE(e): 6.522e-05, MSE(pi1): 7.965e-03, MSE(pi2): 7.550e-05, MSE(pi3): 1.195e-03\n",
      "Epoch 53400, Train loss: 8.623e+02, Test loss: 3.966e+04, MSE(e): 6.649e-05, MSE(pi1): 7.798e-03, MSE(pi2): 7.601e-05, MSE(pi3): 1.194e-03\n",
      "Epoch 53500, Train loss: 8.480e+02, Test loss: 3.931e+04, MSE(e): 6.519e-05, MSE(pi1): 7.837e-03, MSE(pi2): 7.540e-05, MSE(pi3): 1.176e-03\n",
      "Epoch 53600, Train loss: 8.439e+02, Test loss: 3.930e+04, MSE(e): 6.484e-05, MSE(pi1): 7.728e-03, MSE(pi2): 7.509e-05, MSE(pi3): 1.181e-03\n",
      "Epoch 53700, Train loss: 8.444e+02, Test loss: 3.933e+04, MSE(e): 6.500e-05, MSE(pi1): 7.721e-03, MSE(pi2): 7.509e-05, MSE(pi3): 1.172e-03\n",
      "Epoch 53800, Train loss: 8.390e+02, Test loss: 3.911e+04, MSE(e): 6.452e-05, MSE(pi1): 7.667e-03, MSE(pi2): 7.478e-05, MSE(pi3): 1.171e-03\n",
      "Epoch 53900, Train loss: 8.381e+02, Test loss: 3.909e+04, MSE(e): 6.446e-05, MSE(pi1): 7.637e-03, MSE(pi2): 7.467e-05, MSE(pi3): 1.170e-03\n",
      "Epoch 54000, Train loss: 8.351e+02, Test loss: 3.895e+04, MSE(e): 6.427e-05, MSE(pi1): 7.621e-03, MSE(pi2): 7.450e-05, MSE(pi3): 1.161e-03\n",
      "Epoch 54100, Train loss: 8.332e+02, Test loss: 3.888e+04, MSE(e): 6.414e-05, MSE(pi1): 7.582e-03, MSE(pi2): 7.437e-05, MSE(pi3): 1.159e-03\n",
      "Epoch 54200, Train loss: 8.312e+02, Test loss: 3.882e+04, MSE(e): 6.401e-05, MSE(pi1): 7.525e-03, MSE(pi2): 7.424e-05, MSE(pi3): 1.158e-03\n",
      "Epoch 54300, Train loss: 8.310e+02, Test loss: 3.883e+04, MSE(e): 6.405e-05, MSE(pi1): 7.457e-03, MSE(pi2): 7.419e-05, MSE(pi3): 1.159e-03\n",
      "Epoch 54400, Train loss: 8.297e+02, Test loss: 3.865e+04, MSE(e): 6.390e-05, MSE(pi1): 7.660e-03, MSE(pi2): 7.401e-05, MSE(pi3): 1.140e-03\n",
      "Epoch 54500, Train loss: 8.264e+02, Test loss: 3.863e+04, MSE(e): 6.368e-05, MSE(pi1): 7.469e-03, MSE(pi2): 7.386e-05, MSE(pi3): 1.148e-03\n",
      "Epoch 54600, Train loss: 8.241e+02, Test loss: 3.856e+04, MSE(e): 6.353e-05, MSE(pi1): 7.423e-03, MSE(pi2): 7.371e-05, MSE(pi3): 1.145e-03\n",
      "Epoch 54700, Train loss: 8.257e+02, Test loss: 3.844e+04, MSE(e): 6.362e-05, MSE(pi1): 7.463e-03, MSE(pi2): 7.365e-05, MSE(pi3): 1.148e-03\n",
      "Epoch 54800, Train loss: 8.227e+02, Test loss: 3.838e+04, MSE(e): 6.325e-05, MSE(pi1): 7.401e-03, MSE(pi2): 7.341e-05, MSE(pi3): 1.162e-03\n",
      "Epoch 54900, Train loss: 8.181e+02, Test loss: 3.826e+04, MSE(e): 6.311e-05, MSE(pi1): 7.348e-03, MSE(pi2): 7.328e-05, MSE(pi3): 1.135e-03\n",
      "Epoch 55000, Train loss: 8.298e+02, Test loss: 3.816e+04, MSE(e): 6.352e-05, MSE(pi1): 7.877e-03, MSE(pi2): 7.334e-05, MSE(pi3): 1.158e-03\n",
      "Epoch 55100, Train loss: 8.165e+02, Test loss: 3.814e+04, MSE(e): 6.291e-05, MSE(pi1): 7.439e-03, MSE(pi2): 7.305e-05, MSE(pi3): 1.129e-03\n",
      "Epoch 55200, Train loss: 8.130e+02, Test loss: 3.807e+04, MSE(e): 6.273e-05, MSE(pi1): 7.183e-03, MSE(pi2): 7.288e-05, MSE(pi3): 1.139e-03\n",
      "Epoch 55300, Train loss: 8.115e+02, Test loss: 3.802e+04, MSE(e): 6.261e-05, MSE(pi1): 7.220e-03, MSE(pi2): 7.275e-05, MSE(pi3): 1.131e-03\n",
      "Epoch 55400, Train loss: 8.093e+02, Test loss: 3.795e+04, MSE(e): 6.249e-05, MSE(pi1): 7.187e-03, MSE(pi2): 7.262e-05, MSE(pi3): 1.124e-03\n",
      "Epoch 55500, Train loss: 8.141e+02, Test loss: 3.771e+04, MSE(e): 6.301e-05, MSE(pi1): 7.164e-03, MSE(pi2): 7.271e-05, MSE(pi3): 1.123e-03\n",
      "Epoch 55600, Train loss: 8.062e+02, Test loss: 3.780e+04, MSE(e): 6.224e-05, MSE(pi1): 7.198e-03, MSE(pi2): 7.236e-05, MSE(pi3): 1.117e-03\n",
      "Epoch 55700, Train loss: 8.042e+02, Test loss: 3.771e+04, MSE(e): 6.212e-05, MSE(pi1): 7.075e-03, MSE(pi2): 7.222e-05, MSE(pi3): 1.121e-03\n",
      "Epoch 55800, Train loss: 8.025e+02, Test loss: 3.767e+04, MSE(e): 6.200e-05, MSE(pi1): 7.080e-03, MSE(pi2): 7.210e-05, MSE(pi3): 1.117e-03\n",
      "Epoch 55900, Train loss: 8.010e+02, Test loss: 3.758e+04, MSE(e): 6.188e-05, MSE(pi1): 7.086e-03, MSE(pi2): 7.197e-05, MSE(pi3): 1.113e-03\n",
      "Epoch 56000, Train loss: 7.991e+02, Test loss: 3.753e+04, MSE(e): 6.176e-05, MSE(pi1): 6.985e-03, MSE(pi2): 7.184e-05, MSE(pi3): 1.116e-03\n",
      "Epoch 56100, Train loss: 8.057e+02, Test loss: 3.757e+04, MSE(e): 6.228e-05, MSE(pi1): 7.133e-03, MSE(pi2): 7.208e-05, MSE(pi3): 1.115e-03\n",
      "Epoch 56200, Train loss: 7.960e+02, Test loss: 3.741e+04, MSE(e): 6.152e-05, MSE(pi1): 6.994e-03, MSE(pi2): 7.158e-05, MSE(pi3): 1.108e-03\n",
      "Epoch 56300, Train loss: 8.049e+02, Test loss: 3.751e+04, MSE(e): 6.237e-05, MSE(pi1): 7.048e-03, MSE(pi2): 7.194e-05, MSE(pi3): 1.107e-03\n",
      "Epoch 56400, Train loss: 7.954e+02, Test loss: 3.736e+04, MSE(e): 6.155e-05, MSE(pi1): 6.857e-03, MSE(pi2): 7.147e-05, MSE(pi3): 1.112e-03\n",
      "Epoch 56500, Train loss: 7.930e+02, Test loss: 3.714e+04, MSE(e): 6.135e-05, MSE(pi1): 6.889e-03, MSE(pi2): 7.125e-05, MSE(pi3): 1.105e-03\n",
      "Epoch 56600, Train loss: 7.903e+02, Test loss: 3.722e+04, MSE(e): 6.109e-05, MSE(pi1): 6.836e-03, MSE(pi2): 7.109e-05, MSE(pi3): 1.109e-03\n",
      "Epoch 56700, Train loss: 7.891e+02, Test loss: 3.707e+04, MSE(e): 6.098e-05, MSE(pi1): 6.847e-03, MSE(pi2): 7.098e-05, MSE(pi3): 1.107e-03\n",
      "Epoch 56800, Train loss: 7.872e+02, Test loss: 3.708e+04, MSE(e): 6.087e-05, MSE(pi1): 6.864e-03, MSE(pi2): 7.085e-05, MSE(pi3): 1.098e-03\n",
      "Epoch 56900, Train loss: 7.848e+02, Test loss: 3.696e+04, MSE(e): 6.070e-05, MSE(pi1): 6.775e-03, MSE(pi2): 7.070e-05, MSE(pi3): 1.100e-03\n",
      "Epoch 57000, Train loss: 7.857e+02, Test loss: 3.692e+04, MSE(e): 6.068e-05, MSE(pi1): 7.049e-03, MSE(pi2): 7.064e-05, MSE(pi3): 1.083e-03\n",
      "Epoch 57100, Train loss: 7.818e+02, Test loss: 3.685e+04, MSE(e): 6.048e-05, MSE(pi1): 6.730e-03, MSE(pi2): 7.045e-05, MSE(pi3): 1.097e-03\n",
      "Epoch 57200, Train loss: 7.825e+02, Test loss: 3.670e+04, MSE(e): 6.057e-05, MSE(pi1): 6.759e-03, MSE(pi2): 7.039e-05, MSE(pi3): 1.091e-03\n",
      "Epoch 57300, Train loss: 7.882e+02, Test loss: 3.678e+04, MSE(e): 6.079e-05, MSE(pi1): 6.943e-03, MSE(pi2): 7.047e-05, MSE(pi3): 1.109e-03\n",
      "Epoch 57400, Train loss: 7.787e+02, Test loss: 3.667e+04, MSE(e): 6.016e-05, MSE(pi1): 6.912e-03, MSE(pi2): 7.009e-05, MSE(pi3): 1.080e-03\n",
      "Epoch 57500, Train loss: 7.794e+02, Test loss: 3.665e+04, MSE(e): 6.004e-05, MSE(pi1): 6.828e-03, MSE(pi2): 6.996e-05, MSE(pi3): 1.106e-03\n",
      "Epoch 57600, Train loss: 7.801e+02, Test loss: 3.659e+04, MSE(e): 6.022e-05, MSE(pi1): 7.055e-03, MSE(pi2): 7.000e-05, MSE(pi3): 1.072e-03\n",
      "Epoch 57700, Train loss: 7.730e+02, Test loss: 3.650e+04, MSE(e): 5.981e-05, MSE(pi1): 6.598e-03, MSE(pi2): 6.972e-05, MSE(pi3): 1.089e-03\n",
      "Epoch 57800, Train loss: 7.717e+02, Test loss: 3.648e+04, MSE(e): 5.971e-05, MSE(pi1): 6.544e-03, MSE(pi2): 6.960e-05, MSE(pi3): 1.091e-03\n",
      "Epoch 57900, Train loss: 7.704e+02, Test loss: 3.643e+04, MSE(e): 5.959e-05, MSE(pi1): 6.641e-03, MSE(pi2): 6.947e-05, MSE(pi3): 1.081e-03\n",
      "Epoch 58000, Train loss: 7.727e+02, Test loss: 3.637e+04, MSE(e): 5.953e-05, MSE(pi1): 6.998e-03, MSE(pi2): 6.937e-05, MSE(pi3): 1.073e-03\n",
      "Epoch 58100, Train loss: 7.730e+02, Test loss: 3.640e+04, MSE(e): 5.946e-05, MSE(pi1): 6.766e-03, MSE(pi2): 6.928e-05, MSE(pi3): 1.107e-03\n",
      "Epoch 58200, Train loss: 7.679e+02, Test loss: 3.619e+04, MSE(e): 5.927e-05, MSE(pi1): 6.847e-03, MSE(pi2): 6.911e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 58300, Train loss: 7.646e+02, Test loss: 3.615e+04, MSE(e): 5.915e-05, MSE(pi1): 6.491e-03, MSE(pi2): 6.899e-05, MSE(pi3): 1.082e-03\n",
      "Epoch 58400, Train loss: 7.633e+02, Test loss: 3.615e+04, MSE(e): 5.906e-05, MSE(pi1): 6.464e-03, MSE(pi2): 6.888e-05, MSE(pi3): 1.080e-03\n",
      "Epoch 58500, Train loss: 7.618e+02, Test loss: 3.608e+04, MSE(e): 5.895e-05, MSE(pi1): 6.436e-03, MSE(pi2): 6.876e-05, MSE(pi3): 1.079e-03\n",
      "Epoch 58600, Train loss: 7.604e+02, Test loss: 3.604e+04, MSE(e): 5.884e-05, MSE(pi1): 6.452e-03, MSE(pi2): 6.864e-05, MSE(pi3): 1.074e-03\n",
      "Epoch 58700, Train loss: 7.589e+02, Test loss: 3.597e+04, MSE(e): 5.872e-05, MSE(pi1): 6.385e-03, MSE(pi2): 6.851e-05, MSE(pi3): 1.078e-03\n",
      "Epoch 58800, Train loss: 7.587e+02, Test loss: 3.585e+04, MSE(e): 5.873e-05, MSE(pi1): 6.419e-03, MSE(pi2): 6.842e-05, MSE(pi3): 1.072e-03\n",
      "Epoch 58900, Train loss: 7.761e+02, Test loss: 3.564e+04, MSE(e): 6.048e-05, MSE(pi1): 6.450e-03, MSE(pi2): 6.902e-05, MSE(pi3): 1.068e-03\n",
      "Epoch 59000, Train loss: 7.549e+02, Test loss: 3.583e+04, MSE(e): 5.840e-05, MSE(pi1): 6.310e-03, MSE(pi2): 6.815e-05, MSE(pi3): 1.077e-03\n",
      "Epoch 59100, Train loss: 7.535e+02, Test loss: 3.576e+04, MSE(e): 5.829e-05, MSE(pi1): 6.359e-03, MSE(pi2): 6.803e-05, MSE(pi3): 1.069e-03\n",
      "Epoch 59200, Train loss: 7.522e+02, Test loss: 3.567e+04, MSE(e): 5.819e-05, MSE(pi1): 6.363e-03, MSE(pi2): 6.792e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 59300, Train loss: 7.513e+02, Test loss: 3.560e+04, MSE(e): 5.813e-05, MSE(pi1): 6.326e-03, MSE(pi2): 6.781e-05, MSE(pi3): 1.067e-03\n",
      "Epoch 59400, Train loss: 7.504e+02, Test loss: 3.558e+04, MSE(e): 5.799e-05, MSE(pi1): 6.454e-03, MSE(pi2): 6.769e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 59500, Train loss: 7.487e+02, Test loss: 3.552e+04, MSE(e): 5.789e-05, MSE(pi1): 6.334e-03, MSE(pi2): 6.759e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 59600, Train loss: 7.470e+02, Test loss: 3.551e+04, MSE(e): 5.778e-05, MSE(pi1): 6.269e-03, MSE(pi2): 6.745e-05, MSE(pi3): 1.064e-03\n",
      "Epoch 59700, Train loss: 7.463e+02, Test loss: 3.546e+04, MSE(e): 5.768e-05, MSE(pi1): 6.389e-03, MSE(pi2): 6.735e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 59800, Train loss: 7.451e+02, Test loss: 3.542e+04, MSE(e): 5.757e-05, MSE(pi1): 6.383e-03, MSE(pi2): 6.722e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 59900, Train loss: 7.430e+02, Test loss: 3.536e+04, MSE(e): 5.746e-05, MSE(pi1): 6.200e-03, MSE(pi2): 6.710e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 60000, Train loss: 7.532e+02, Test loss: 3.540e+04, MSE(e): 5.756e-05, MSE(pi1): 6.827e-03, MSE(pi2): 6.710e-05, MSE(pi3): 1.092e-03\n",
      "Epoch 60100, Train loss: 7.405e+02, Test loss: 3.528e+04, MSE(e): 5.726e-05, MSE(pi1): 6.169e-03, MSE(pi2): 6.688e-05, MSE(pi3): 1.061e-03\n",
      "Epoch 60200, Train loss: 7.444e+02, Test loss: 3.523e+04, MSE(e): 5.761e-05, MSE(pi1): 6.247e-03, MSE(pi2): 6.700e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 60300, Train loss: 7.380e+02, Test loss: 3.518e+04, MSE(e): 5.706e-05, MSE(pi1): 6.181e-03, MSE(pi2): 6.665e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 60400, Train loss: 7.374e+02, Test loss: 3.516e+04, MSE(e): 5.696e-05, MSE(pi1): 6.102e-03, MSE(pi2): 6.654e-05, MSE(pi3): 1.067e-03\n",
      "Epoch 60500, Train loss: 7.373e+02, Test loss: 3.515e+04, MSE(e): 5.689e-05, MSE(pi1): 6.161e-03, MSE(pi2): 6.644e-05, MSE(pi3): 1.067e-03\n",
      "Epoch 60600, Train loss: 7.354e+02, Test loss: 3.511e+04, MSE(e): 5.679e-05, MSE(pi1): 6.220e-03, MSE(pi2): 6.633e-05, MSE(pi3): 1.052e-03\n",
      "Epoch 60700, Train loss: 7.346e+02, Test loss: 3.509e+04, MSE(e): 5.669e-05, MSE(pi1): 6.276e-03, MSE(pi2): 6.622e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 60800, Train loss: 7.321e+02, Test loss: 3.498e+04, MSE(e): 5.656e-05, MSE(pi1): 6.157e-03, MSE(pi2): 6.608e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 60900, Train loss: 7.383e+02, Test loss: 3.478e+04, MSE(e): 5.722e-05, MSE(pi1): 6.069e-03, MSE(pi2): 6.625e-05, MSE(pi3): 1.054e-03\n",
      "Epoch 61000, Train loss: 7.314e+02, Test loss: 3.480e+04, MSE(e): 5.640e-05, MSE(pi1): 6.353e-03, MSE(pi2): 6.589e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 61100, Train loss: 7.284e+02, Test loss: 3.488e+04, MSE(e): 5.630e-05, MSE(pi1): 6.015e-03, MSE(pi2): 6.578e-05, MSE(pi3): 1.052e-03\n",
      "Epoch 61200, Train loss: 7.286e+02, Test loss: 3.488e+04, MSE(e): 5.628e-05, MSE(pi1): 5.995e-03, MSE(pi2): 6.570e-05, MSE(pi3): 1.058e-03\n",
      "Epoch 61300, Train loss: 7.264e+02, Test loss: 3.480e+04, MSE(e): 5.612e-05, MSE(pi1): 6.021e-03, MSE(pi2): 6.556e-05, MSE(pi3): 1.050e-03\n",
      "Epoch 61400, Train loss: 7.246e+02, Test loss: 3.471e+04, MSE(e): 5.598e-05, MSE(pi1): 5.984e-03, MSE(pi2): 6.541e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 61500, Train loss: 7.238e+02, Test loss: 3.470e+04, MSE(e): 5.587e-05, MSE(pi1): 5.943e-03, MSE(pi2): 6.531e-05, MSE(pi3): 1.056e-03\n",
      "Epoch 61600, Train loss: 7.239e+02, Test loss: 3.461e+04, MSE(e): 5.578e-05, MSE(pi1): 6.309e-03, MSE(pi2): 6.520e-05, MSE(pi3): 1.030e-03\n",
      "Epoch 61700, Train loss: 7.251e+02, Test loss: 3.464e+04, MSE(e): 5.599e-05, MSE(pi1): 6.023e-03, MSE(pi2): 6.523e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 61800, Train loss: 7.197e+02, Test loss: 3.455e+04, MSE(e): 5.558e-05, MSE(pi1): 5.927e-03, MSE(pi2): 6.497e-05, MSE(pi3): 1.046e-03\n",
      "Epoch 61900, Train loss: 7.245e+02, Test loss: 3.458e+04, MSE(e): 5.551e-05, MSE(pi1): 6.222e-03, MSE(pi2): 6.488e-05, MSE(pi3): 1.071e-03\n",
      "Epoch 62000, Train loss: 7.177e+02, Test loss: 3.455e+04, MSE(e): 5.541e-05, MSE(pi1): 5.865e-03, MSE(pi2): 6.477e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 62100, Train loss: 7.204e+02, Test loss: 3.458e+04, MSE(e): 5.561e-05, MSE(pi1): 5.850e-03, MSE(pi2): 6.482e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 62200, Train loss: 7.160e+02, Test loss: 3.440e+04, MSE(e): 5.521e-05, MSE(pi1): 6.100e-03, MSE(pi2): 6.454e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 62300, Train loss: 7.144e+02, Test loss: 3.436e+04, MSE(e): 5.515e-05, MSE(pi1): 5.873e-03, MSE(pi2): 6.444e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 62400, Train loss: 7.131e+02, Test loss: 3.438e+04, MSE(e): 5.502e-05, MSE(pi1): 5.831e-03, MSE(pi2): 6.433e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 62500, Train loss: 7.123e+02, Test loss: 3.430e+04, MSE(e): 5.493e-05, MSE(pi1): 6.014e-03, MSE(pi2): 6.422e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 62600, Train loss: 7.265e+02, Test loss: 3.456e+04, MSE(e): 5.638e-05, MSE(pi1): 5.843e-03, MSE(pi2): 6.483e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 62700, Train loss: 7.106e+02, Test loss: 3.417e+04, MSE(e): 5.479e-05, MSE(pi1): 5.794e-03, MSE(pi2): 6.405e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 62800, Train loss: 7.092e+02, Test loss: 3.412e+04, MSE(e): 5.473e-05, MSE(pi1): 5.862e-03, MSE(pi2): 6.393e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 62900, Train loss: 7.425e+02, Test loss: 3.391e+04, MSE(e): 5.802e-05, MSE(pi1): 5.847e-03, MSE(pi2): 6.522e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 63000, Train loss: 7.069e+02, Test loss: 3.420e+04, MSE(e): 5.452e-05, MSE(pi1): 5.816e-03, MSE(pi2): 6.373e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 63100, Train loss: 7.052e+02, Test loss: 3.408e+04, MSE(e): 5.438e-05, MSE(pi1): 5.746e-03, MSE(pi2): 6.359e-05, MSE(pi3): 1.039e-03\n",
      "Epoch 63200, Train loss: 7.066e+02, Test loss: 3.394e+04, MSE(e): 5.452e-05, MSE(pi1): 5.887e-03, MSE(pi2): 6.356e-05, MSE(pi3): 1.024e-03\n",
      "Epoch 63300, Train loss: 7.046e+02, Test loss: 3.410e+04, MSE(e): 5.437e-05, MSE(pi1): 5.746e-03, MSE(pi2): 6.348e-05, MSE(pi3): 1.033e-03\n",
      "Epoch 63400, Train loss: 7.032e+02, Test loss: 3.392e+04, MSE(e): 5.416e-05, MSE(pi1): 5.714e-03, MSE(pi2): 6.332e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 63500, Train loss: 7.123e+02, Test loss: 3.419e+04, MSE(e): 5.446e-05, MSE(pi1): 6.203e-03, MSE(pi2): 6.337e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 63600, Train loss: 6.999e+02, Test loss: 3.392e+04, MSE(e): 5.392e-05, MSE(pi1): 5.733e-03, MSE(pi2): 6.307e-05, MSE(pi3): 1.033e-03\n",
      "Epoch 63700, Train loss: 6.994e+02, Test loss: 3.384e+04, MSE(e): 5.391e-05, MSE(pi1): 5.716e-03, MSE(pi2): 6.299e-05, MSE(pi3): 1.030e-03\n",
      "Epoch 63800, Train loss: 6.974e+02, Test loss: 3.387e+04, MSE(e): 5.375e-05, MSE(pi1): 5.698e-03, MSE(pi2): 6.287e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 63900, Train loss: 6.966e+02, Test loss: 3.381e+04, MSE(e): 5.367e-05, MSE(pi1): 5.775e-03, MSE(pi2): 6.277e-05, MSE(pi3): 1.022e-03\n",
      "Epoch 64000, Train loss: 6.955e+02, Test loss: 3.376e+04, MSE(e): 5.359e-05, MSE(pi1): 5.728e-03, MSE(pi2): 6.267e-05, MSE(pi3): 1.023e-03\n",
      "Epoch 64100, Train loss: 6.942e+02, Test loss: 3.376e+04, MSE(e): 5.348e-05, MSE(pi1): 5.677e-03, MSE(pi2): 6.257e-05, MSE(pi3): 1.025e-03\n",
      "Epoch 64200, Train loss: 6.987e+02, Test loss: 3.366e+04, MSE(e): 5.394e-05, MSE(pi1): 5.712e-03, MSE(pi2): 6.266e-05, MSE(pi3): 1.021e-03\n",
      "Epoch 64300, Train loss: 6.927e+02, Test loss: 3.369e+04, MSE(e): 5.331e-05, MSE(pi1): 5.777e-03, MSE(pi2): 6.237e-05, MSE(pi3): 1.017e-03\n",
      "Epoch 64400, Train loss: 6.912e+02, Test loss: 3.366e+04, MSE(e): 5.323e-05, MSE(pi1): 5.644e-03, MSE(pi2): 6.228e-05, MSE(pi3): 1.024e-03\n",
      "Epoch 64500, Train loss: 6.901e+02, Test loss: 3.363e+04, MSE(e): 5.314e-05, MSE(pi1): 5.646e-03, MSE(pi2): 6.217e-05, MSE(pi3): 1.022e-03\n",
      "Epoch 64600, Train loss: 6.909e+02, Test loss: 3.364e+04, MSE(e): 5.318e-05, MSE(pi1): 5.539e-03, MSE(pi2): 6.214e-05, MSE(pi3): 1.036e-03\n",
      "Epoch 64700, Train loss: 6.909e+02, Test loss: 3.351e+04, MSE(e): 5.324e-05, MSE(pi1): 5.689e-03, MSE(pi2): 6.205e-05, MSE(pi3): 1.015e-03\n",
      "Epoch 64800, Train loss: 6.907e+02, Test loss: 3.358e+04, MSE(e): 5.318e-05, MSE(pi1): 5.667e-03, MSE(pi2): 6.207e-05, MSE(pi3): 1.022e-03\n",
      "Epoch 64900, Train loss: 6.999e+02, Test loss: 3.341e+04, MSE(e): 5.290e-05, MSE(pi1): 7.105e-03, MSE(pi2): 6.183e-05, MSE(pi3): 9.985e-04\n",
      "Epoch 65000, Train loss: 6.883e+02, Test loss: 3.352e+04, MSE(e): 5.272e-05, MSE(pi1): 5.695e-03, MSE(pi2): 6.168e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 65100, Train loss: 6.842e+02, Test loss: 3.350e+04, MSE(e): 5.265e-05, MSE(pi1): 5.553e-03, MSE(pi2): 6.160e-05, MSE(pi3): 1.021e-03\n",
      "Epoch 65200, Train loss: 6.868e+02, Test loss: 3.356e+04, MSE(e): 5.280e-05, MSE(pi1): 5.525e-03, MSE(pi2): 6.161e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 65300, Train loss: 6.820e+02, Test loss: 3.341e+04, MSE(e): 5.246e-05, MSE(pi1): 5.545e-03, MSE(pi2): 6.138e-05, MSE(pi3): 1.019e-03\n",
      "Epoch 65400, Train loss: 6.810e+02, Test loss: 3.337e+04, MSE(e): 5.237e-05, MSE(pi1): 5.583e-03, MSE(pi2): 6.128e-05, MSE(pi3): 1.014e-03\n",
      "Epoch 65500, Train loss: 6.801e+02, Test loss: 3.336e+04, MSE(e): 5.230e-05, MSE(pi1): 5.521e-03, MSE(pi2): 6.120e-05, MSE(pi3): 1.018e-03\n",
      "Epoch 65600, Train loss: 6.796e+02, Test loss: 3.329e+04, MSE(e): 5.226e-05, MSE(pi1): 5.555e-03, MSE(pi2): 6.110e-05, MSE(pi3): 1.014e-03\n",
      "Epoch 65700, Train loss: 6.835e+02, Test loss: 3.341e+04, MSE(e): 5.268e-05, MSE(pi1): 5.475e-03, MSE(pi2): 6.127e-05, MSE(pi3): 1.019e-03\n",
      "Epoch 65800, Train loss: 6.774e+02, Test loss: 3.326e+04, MSE(e): 5.205e-05, MSE(pi1): 5.559e-03, MSE(pi2): 6.090e-05, MSE(pi3): 1.013e-03\n",
      "Epoch 65900, Train loss: 6.764e+02, Test loss: 3.322e+04, MSE(e): 5.199e-05, MSE(pi1): 5.510e-03, MSE(pi2): 6.081e-05, MSE(pi3): 1.013e-03\n",
      "Epoch 66000, Train loss: 6.858e+02, Test loss: 3.343e+04, MSE(e): 5.255e-05, MSE(pi1): 6.019e-03, MSE(pi2): 6.103e-05, MSE(pi3): 1.001e-03\n",
      "Epoch 66100, Train loss: 6.757e+02, Test loss: 3.311e+04, MSE(e): 5.190e-05, MSE(pi1): 5.589e-03, MSE(pi2): 6.069e-05, MSE(pi3): 1.008e-03\n",
      "Epoch 66200, Train loss: 6.737e+02, Test loss: 3.320e+04, MSE(e): 5.173e-05, MSE(pi1): 5.420e-03, MSE(pi2): 6.053e-05, MSE(pi3): 1.021e-03\n",
      "Epoch 66300, Train loss: 6.722e+02, Test loss: 3.313e+04, MSE(e): 5.164e-05, MSE(pi1): 5.488e-03, MSE(pi2): 6.042e-05, MSE(pi3): 1.009e-03\n",
      "Epoch 66400, Train loss: 6.727e+02, Test loss: 3.302e+04, MSE(e): 5.170e-05, MSE(pi1): 5.518e-03, MSE(pi2): 6.037e-05, MSE(pi3): 1.005e-03\n",
      "Epoch 66500, Train loss: 6.717e+02, Test loss: 3.294e+04, MSE(e): 5.156e-05, MSE(pi1): 5.600e-03, MSE(pi2): 6.026e-05, MSE(pi3): 1.000e-03\n",
      "Epoch 66600, Train loss: 6.741e+02, Test loss: 3.305e+04, MSE(e): 5.140e-05, MSE(pi1): 5.714e-03, MSE(pi2): 6.014e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 66700, Train loss: 6.684e+02, Test loss: 3.301e+04, MSE(e): 5.132e-05, MSE(pi1): 5.418e-03, MSE(pi2): 6.005e-05, MSE(pi3): 1.010e-03\n",
      "Epoch 66800, Train loss: 6.689e+02, Test loss: 3.296e+04, MSE(e): 5.134e-05, MSE(pi1): 5.542e-03, MSE(pi2): 5.998e-05, MSE(pi3): 1.000e-03\n",
      "Epoch 66900, Train loss: 6.684e+02, Test loss: 3.289e+04, MSE(e): 5.121e-05, MSE(pi1): 5.620e-03, MSE(pi2): 5.988e-05, MSE(pi3): 9.995e-04\n",
      "Epoch 67000, Train loss: 6.656e+02, Test loss: 3.293e+04, MSE(e): 5.108e-05, MSE(pi1): 5.415e-03, MSE(pi2): 5.977e-05, MSE(pi3): 1.006e-03\n",
      "Epoch 67100, Train loss: 6.646e+02, Test loss: 3.291e+04, MSE(e): 5.100e-05, MSE(pi1): 5.398e-03, MSE(pi2): 5.968e-05, MSE(pi3): 1.006e-03\n",
      "Epoch 67200, Train loss: 6.851e+02, Test loss: 3.323e+04, MSE(e): 5.306e-05, MSE(pi1): 5.318e-03, MSE(pi2): 6.055e-05, MSE(pi3): 1.012e-03\n",
      "Epoch 67300, Train loss: 6.632e+02, Test loss: 3.285e+04, MSE(e): 5.085e-05, MSE(pi1): 5.410e-03, MSE(pi2): 5.950e-05, MSE(pi3): 1.005e-03\n",
      "Epoch 67400, Train loss: 6.639e+02, Test loss: 3.293e+04, MSE(e): 5.095e-05, MSE(pi1): 5.360e-03, MSE(pi2): 5.950e-05, MSE(pi3): 1.007e-03\n",
      "Epoch 67500, Train loss: 6.695e+02, Test loss: 3.272e+04, MSE(e): 5.138e-05, MSE(pi1): 5.723e-03, MSE(pi2): 5.957e-05, MSE(pi3): 9.843e-04\n",
      "Epoch 67600, Train loss: 6.603e+02, Test loss: 3.281e+04, MSE(e): 5.063e-05, MSE(pi1): 5.311e-03, MSE(pi2): 5.924e-05, MSE(pi3): 1.008e-03\n",
      "Epoch 67700, Train loss: 6.592e+02, Test loss: 3.273e+04, MSE(e): 5.054e-05, MSE(pi1): 5.341e-03, MSE(pi2): 5.914e-05, MSE(pi3): 1.004e-03\n",
      "Epoch 67800, Train loss: 6.584e+02, Test loss: 3.274e+04, MSE(e): 5.046e-05, MSE(pi1): 5.374e-03, MSE(pi2): 5.905e-05, MSE(pi3): 9.998e-04\n",
      "Epoch 67900, Train loss: 6.574e+02, Test loss: 3.271e+04, MSE(e): 5.039e-05, MSE(pi1): 5.337e-03, MSE(pi2): 5.896e-05, MSE(pi3): 1.001e-03\n",
      "Epoch 68000, Train loss: 6.568e+02, Test loss: 3.269e+04, MSE(e): 5.032e-05, MSE(pi1): 5.406e-03, MSE(pi2): 5.888e-05, MSE(pi3): 9.951e-04\n",
      "Epoch 68100, Train loss: 6.568e+02, Test loss: 3.266e+04, MSE(e): 5.024e-05, MSE(pi1): 5.341e-03, MSE(pi2): 5.878e-05, MSE(pi3): 1.009e-03\n",
      "Epoch 68200, Train loss: 6.549e+02, Test loss: 3.266e+04, MSE(e): 5.017e-05, MSE(pi1): 5.349e-03, MSE(pi2): 5.871e-05, MSE(pi3): 9.964e-04\n",
      "Epoch 68300, Train loss: 6.562e+02, Test loss: 3.259e+04, MSE(e): 5.017e-05, MSE(pi1): 5.291e-03, MSE(pi2): 5.866e-05, MSE(pi3): 1.016e-03\n",
      "Epoch 68400, Train loss: 6.566e+02, Test loss: 3.266e+04, MSE(e): 5.029e-05, MSE(pi1): 5.273e-03, MSE(pi2): 5.868e-05, MSE(pi3): 1.010e-03\n",
      "Epoch 68500, Train loss: 6.544e+02, Test loss: 3.261e+04, MSE(e): 5.014e-05, MSE(pi1): 5.249e-03, MSE(pi2): 5.855e-05, MSE(pi3): 1.004e-03\n",
      "Epoch 68600, Train loss: 6.535e+02, Test loss: 3.241e+04, MSE(e): 4.996e-05, MSE(pi1): 5.489e-03, MSE(pi2): 5.841e-05, MSE(pi3): 9.897e-04\n",
      "Epoch 68700, Train loss: 6.506e+02, Test loss: 3.251e+04, MSE(e): 4.978e-05, MSE(pi1): 5.248e-03, MSE(pi2): 5.825e-05, MSE(pi3): 1.002e-03\n",
      "Epoch 68800, Train loss: 6.505e+02, Test loss: 3.254e+04, MSE(e): 4.979e-05, MSE(pi1): 5.262e-03, MSE(pi2): 5.821e-05, MSE(pi3): 9.989e-04\n",
      "Epoch 68900, Train loss: 6.770e+02, Test loss: 3.290e+04, MSE(e): 5.246e-05, MSE(pi1): 5.117e-03, MSE(pi2): 5.934e-05, MSE(pi3): 1.012e-03\n",
      "Epoch 69000, Train loss: 6.485e+02, Test loss: 3.239e+04, MSE(e): 4.960e-05, MSE(pi1): 5.239e-03, MSE(pi2): 5.803e-05, MSE(pi3): 1.000e-03\n",
      "Epoch 69100, Train loss: 6.492e+02, Test loss: 3.242e+04, MSE(e): 4.959e-05, MSE(pi1): 5.349e-03, MSE(pi2): 5.797e-05, MSE(pi3): 9.982e-04\n",
      "Epoch 69200, Train loss: 6.484e+02, Test loss: 3.249e+04, MSE(e): 4.963e-05, MSE(pi1): 5.280e-03, MSE(pi2): 5.793e-05, MSE(pi3): 9.925e-04\n",
      "Epoch 69300, Train loss: 6.647e+02, Test loss: 3.192e+04, MSE(e): 5.128e-05, MSE(pi1): 5.374e-03, MSE(pi2): 5.857e-05, MSE(pi3): 9.814e-04\n",
      "Epoch 69400, Train loss: 6.599e+02, Test loss: 3.217e+04, MSE(e): 5.077e-05, MSE(pi1): 5.312e-03, MSE(pi2): 5.822e-05, MSE(pi3): 9.909e-04\n",
      "Epoch 69500, Train loss: 6.456e+02, Test loss: 3.233e+04, MSE(e): 4.924e-05, MSE(pi1): 5.354e-03, MSE(pi2): 5.758e-05, MSE(pi3): 9.961e-04\n",
      "Epoch 69600, Train loss: 6.427e+02, Test loss: 3.230e+04, MSE(e): 4.913e-05, MSE(pi1): 5.246e-03, MSE(pi2): 5.749e-05, MSE(pi3): 9.888e-04\n",
      "Epoch 69700, Train loss: 6.443e+02, Test loss: 3.222e+04, MSE(e): 4.929e-05, MSE(pi1): 5.190e-03, MSE(pi2): 5.748e-05, MSE(pi3): 9.941e-04\n",
      "Epoch 69800, Train loss: 6.417e+02, Test loss: 3.232e+04, MSE(e): 4.902e-05, MSE(pi1): 5.194e-03, MSE(pi2): 5.733e-05, MSE(pi3): 9.952e-04\n",
      "Epoch 69900, Train loss: 6.410e+02, Test loss: 3.224e+04, MSE(e): 4.893e-05, MSE(pi1): 5.178e-03, MSE(pi2): 5.724e-05, MSE(pi3): 9.984e-04\n",
      "Epoch 70000, Train loss: 6.438e+02, Test loss: 3.205e+04, MSE(e): 4.927e-05, MSE(pi1): 5.240e-03, MSE(pi2): 5.745e-05, MSE(pi3): 9.868e-04\n",
      "Epoch 70100, Train loss: 6.391e+02, Test loss: 3.223e+04, MSE(e): 4.880e-05, MSE(pi1): 5.123e-03, MSE(pi2): 5.709e-05, MSE(pi3): 9.979e-04\n",
      "Epoch 70200, Train loss: 6.394e+02, Test loss: 3.227e+04, MSE(e): 4.879e-05, MSE(pi1): 5.119e-03, MSE(pi2): 5.703e-05, MSE(pi3): 1.003e-03\n",
      "Epoch 70300, Train loss: 6.374e+02, Test loss: 3.215e+04, MSE(e): 4.864e-05, MSE(pi1): 5.154e-03, MSE(pi2): 5.690e-05, MSE(pi3): 9.939e-04\n",
      "Epoch 70400, Train loss: 6.379e+02, Test loss: 3.226e+04, MSE(e): 4.874e-05, MSE(pi1): 5.102e-03, MSE(pi2): 5.691e-05, MSE(pi3): 9.945e-04\n",
      "Epoch 70500, Train loss: 6.362e+02, Test loss: 3.217e+04, MSE(e): 4.857e-05, MSE(pi1): 5.193e-03, MSE(pi2): 5.679e-05, MSE(pi3): 9.850e-04\n",
      "Epoch 70600, Train loss: 6.393e+02, Test loss: 3.210e+04, MSE(e): 4.856e-05, MSE(pi1): 5.738e-03, MSE(pi2): 5.675e-05, MSE(pi3): 9.620e-04\n",
      "Epoch 70700, Train loss: 6.357e+02, Test loss: 3.217e+04, MSE(e): 4.849e-05, MSE(pi1): 5.197e-03, MSE(pi2): 5.664e-05, MSE(pi3): 9.882e-04\n",
      "Epoch 70800, Train loss: 6.341e+02, Test loss: 3.198e+04, MSE(e): 4.841e-05, MSE(pi1): 5.175e-03, MSE(pi2): 5.652e-05, MSE(pi3): 9.817e-04\n",
      "Epoch 70900, Train loss: 6.393e+02, Test loss: 3.193e+04, MSE(e): 4.870e-05, MSE(pi1): 5.331e-03, MSE(pi2): 5.657e-05, MSE(pi3): 9.894e-04\n",
      "Epoch 71000, Train loss: 6.326e+02, Test loss: 3.207e+04, MSE(e): 4.828e-05, MSE(pi1): 5.128e-03, MSE(pi2): 5.640e-05, MSE(pi3): 9.847e-04\n",
      "Epoch 71100, Train loss: 6.319e+02, Test loss: 3.211e+04, MSE(e): 4.819e-05, MSE(pi1): 5.059e-03, MSE(pi2): 5.630e-05, MSE(pi3): 9.939e-04\n",
      "Epoch 71200, Train loss: 6.324e+02, Test loss: 3.215e+04, MSE(e): 4.820e-05, MSE(pi1): 5.062e-03, MSE(pi2): 5.625e-05, MSE(pi3): 9.967e-04\n",
      "Epoch 71300, Train loss: 6.308e+02, Test loss: 3.213e+04, MSE(e): 4.808e-05, MSE(pi1): 5.010e-03, MSE(pi2): 5.615e-05, MSE(pi3): 9.978e-04\n",
      "Epoch 71400, Train loss: 6.283e+02, Test loss: 3.201e+04, MSE(e): 4.786e-05, MSE(pi1): 5.210e-03, MSE(pi2): 5.599e-05, MSE(pi3): 9.757e-04\n",
      "Epoch 71500, Train loss: 6.270e+02, Test loss: 3.198e+04, MSE(e): 4.778e-05, MSE(pi1): 5.091e-03, MSE(pi2): 5.590e-05, MSE(pi3): 9.820e-04\n",
      "Epoch 71600, Train loss: 6.263e+02, Test loss: 3.197e+04, MSE(e): 4.772e-05, MSE(pi1): 5.085e-03, MSE(pi2): 5.582e-05, MSE(pi3): 9.818e-04\n",
      "Epoch 71700, Train loss: 6.257e+02, Test loss: 3.198e+04, MSE(e): 4.765e-05, MSE(pi1): 5.091e-03, MSE(pi2): 5.574e-05, MSE(pi3): 9.821e-04\n",
      "Epoch 71800, Train loss: 6.246e+02, Test loss: 3.196e+04, MSE(e): 4.758e-05, MSE(pi1): 5.047e-03, MSE(pi2): 5.566e-05, MSE(pi3): 9.834e-04\n",
      "Epoch 71900, Train loss: 6.241e+02, Test loss: 3.190e+04, MSE(e): 4.754e-05, MSE(pi1): 5.081e-03, MSE(pi2): 5.558e-05, MSE(pi3): 9.790e-04\n",
      "Epoch 72000, Train loss: 6.235e+02, Test loss: 3.189e+04, MSE(e): 4.746e-05, MSE(pi1): 5.126e-03, MSE(pi2): 5.550e-05, MSE(pi3): 9.759e-04\n",
      "Epoch 72100, Train loss: 6.238e+02, Test loss: 3.194e+04, MSE(e): 4.738e-05, MSE(pi1): 5.053e-03, MSE(pi2): 5.542e-05, MSE(pi3): 9.941e-04\n",
      "Epoch 72200, Train loss: 6.266e+02, Test loss: 3.178e+04, MSE(e): 4.742e-05, MSE(pi1): 5.601e-03, MSE(pi2): 5.542e-05, MSE(pi3): 9.631e-04\n",
      "Epoch 72300, Train loss: 6.225e+02, Test loss: 3.191e+04, MSE(e): 4.724e-05, MSE(pi1): 5.371e-03, MSE(pi2): 5.526e-05, MSE(pi3): 9.630e-04\n",
      "Epoch 72400, Train loss: 6.464e+02, Test loss: 3.157e+04, MSE(e): 4.975e-05, MSE(pi1): 5.225e-03, MSE(pi2): 5.618e-05, MSE(pi3): 9.657e-04\n",
      "Epoch 72500, Train loss: 6.249e+02, Test loss: 3.199e+04, MSE(e): 4.768e-05, MSE(pi1): 5.023e-03, MSE(pi2): 5.541e-05, MSE(pi3): 9.784e-04\n",
      "Epoch 72600, Train loss: 6.189e+02, Test loss: 3.185e+04, MSE(e): 4.704e-05, MSE(pi1): 5.011e-03, MSE(pi2): 5.502e-05, MSE(pi3): 9.831e-04\n",
      "Epoch 72700, Train loss: 6.181e+02, Test loss: 3.187e+04, MSE(e): 4.697e-05, MSE(pi1): 4.982e-03, MSE(pi2): 5.495e-05, MSE(pi3): 9.856e-04\n",
      "Epoch 72800, Train loss: 6.369e+02, Test loss: 3.197e+04, MSE(e): 4.886e-05, MSE(pi1): 4.883e-03, MSE(pi2): 5.577e-05, MSE(pi3): 9.936e-04\n",
      "Epoch 72900, Train loss: 6.231e+02, Test loss: 3.177e+04, MSE(e): 4.687e-05, MSE(pi1): 5.862e-03, MSE(pi2): 5.481e-05, MSE(pi3): 9.571e-04\n",
      "Epoch 73000, Train loss: 6.184e+02, Test loss: 3.174e+04, MSE(e): 4.707e-05, MSE(pi1): 5.092e-03, MSE(pi2): 5.481e-05, MSE(pi3): 9.678e-04\n",
      "Epoch 73100, Train loss: 6.154e+02, Test loss: 3.189e+04, MSE(e): 4.677e-05, MSE(pi1): 4.896e-03, MSE(pi2): 5.468e-05, MSE(pi3): 9.869e-04\n",
      "Epoch 73200, Train loss: 6.137e+02, Test loss: 3.180e+04, MSE(e): 4.663e-05, MSE(pi1): 4.981e-03, MSE(pi2): 5.456e-05, MSE(pi3): 9.753e-04\n",
      "Epoch 73300, Train loss: 6.133e+02, Test loss: 3.180e+04, MSE(e): 4.657e-05, MSE(pi1): 4.945e-03, MSE(pi2): 5.448e-05, MSE(pi3): 9.803e-04\n",
      "Epoch 73400, Train loss: 6.123e+02, Test loss: 3.177e+04, MSE(e): 4.651e-05, MSE(pi1): 4.946e-03, MSE(pi2): 5.441e-05, MSE(pi3): 9.773e-04\n",
      "Epoch 73500, Train loss: 6.129e+02, Test loss: 3.171e+04, MSE(e): 4.654e-05, MSE(pi1): 4.917e-03, MSE(pi2): 5.436e-05, MSE(pi3): 9.826e-04\n",
      "Epoch 73600, Train loss: 6.245e+02, Test loss: 3.172e+04, MSE(e): 4.641e-05, MSE(pi1): 6.704e-03, MSE(pi2): 5.427e-05, MSE(pi3): 9.330e-04\n",
      "Epoch 73700, Train loss: 6.159e+02, Test loss: 3.166e+04, MSE(e): 4.673e-05, MSE(pi1): 5.277e-03, MSE(pi2): 5.435e-05, MSE(pi3): 9.576e-04\n",
      "Epoch 73800, Train loss: 6.229e+02, Test loss: 3.170e+04, MSE(e): 4.630e-05, MSE(pi1): 6.573e-03, MSE(pi2): 5.411e-05, MSE(pi3): 9.416e-04\n",
      "Epoch 73900, Train loss: 6.088e+02, Test loss: 3.172e+04, MSE(e): 4.620e-05, MSE(pi1): 4.908e-03, MSE(pi2): 5.405e-05, MSE(pi3): 9.762e-04\n",
      "Epoch 74000, Train loss: 6.530e+02, Test loss: 3.210e+04, MSE(e): 4.997e-05, MSE(pi1): 5.205e-03, MSE(pi2): 5.565e-05, MSE(pi3): 1.012e-03\n",
      "Epoch 74100, Train loss: 6.169e+02, Test loss: 3.163e+04, MSE(e): 4.617e-05, MSE(pi1): 5.520e-03, MSE(pi2): 5.392e-05, MSE(pi3): 9.998e-04\n",
      "Epoch 74200, Train loss: 6.073e+02, Test loss: 3.172e+04, MSE(e): 4.608e-05, MSE(pi1): 4.936e-03, MSE(pi2): 5.386e-05, MSE(pi3): 9.707e-04\n",
      "Epoch 74300, Train loss: 6.058e+02, Test loss: 3.164e+04, MSE(e): 4.594e-05, MSE(pi1): 4.917e-03, MSE(pi2): 5.374e-05, MSE(pi3): 9.713e-04\n",
      "Epoch 74400, Train loss: 6.057e+02, Test loss: 3.166e+04, MSE(e): 4.593e-05, MSE(pi1): 4.963e-03, MSE(pi2): 5.371e-05, MSE(pi3): 9.674e-04\n",
      "Epoch 74500, Train loss: 6.047e+02, Test loss: 3.170e+04, MSE(e): 4.583e-05, MSE(pi1): 5.000e-03, MSE(pi2): 5.361e-05, MSE(pi3): 9.636e-04\n",
      "Epoch 74600, Train loss: 6.038e+02, Test loss: 3.163e+04, MSE(e): 4.575e-05, MSE(pi1): 4.953e-03, MSE(pi2): 5.352e-05, MSE(pi3): 9.670e-04\n",
      "Epoch 74700, Train loss: 6.029e+02, Test loss: 3.162e+04, MSE(e): 4.569e-05, MSE(pi1): 4.901e-03, MSE(pi2): 5.345e-05, MSE(pi3): 9.692e-04\n",
      "Epoch 74800, Train loss: 6.023e+02, Test loss: 3.157e+04, MSE(e): 4.564e-05, MSE(pi1): 4.886e-03, MSE(pi2): 5.338e-05, MSE(pi3): 9.698e-04\n",
      "Epoch 74900, Train loss: 6.017e+02, Test loss: 3.163e+04, MSE(e): 4.558e-05, MSE(pi1): 4.837e-03, MSE(pi2): 5.331e-05, MSE(pi3): 9.751e-04\n",
      "Epoch 75000, Train loss: 6.092e+02, Test loss: 3.144e+04, MSE(e): 4.632e-05, MSE(pi1): 4.995e-03, MSE(pi2): 5.353e-05, MSE(pi3): 9.598e-04\n",
      "Epoch 75100, Train loss: 6.178e+02, Test loss: 3.190e+04, MSE(e): 4.717e-05, MSE(pi1): 4.718e-03, MSE(pi2): 5.394e-05, MSE(pi3): 9.896e-04\n",
      "Epoch 75200, Train loss: 6.026e+02, Test loss: 3.142e+04, MSE(e): 4.570e-05, MSE(pi1): 4.903e-03, MSE(pi2): 5.320e-05, MSE(pi3): 9.653e-04\n",
      "Epoch 75300, Train loss: 6.040e+02, Test loss: 3.154e+04, MSE(e): 4.534e-05, MSE(pi1): 5.597e-03, MSE(pi2): 5.302e-05, MSE(pi3): 9.464e-04\n",
      "Epoch 75400, Train loss: 6.005e+02, Test loss: 3.146e+04, MSE(e): 4.539e-05, MSE(pi1): 5.138e-03, MSE(pi2): 5.306e-05, MSE(pi3): 9.512e-04\n",
      "Epoch 75500, Train loss: 5.977e+02, Test loss: 3.152e+04, MSE(e): 4.521e-05, MSE(pi1): 4.965e-03, MSE(pi2): 5.288e-05, MSE(pi3): 9.593e-04\n",
      "Epoch 75600, Train loss: 6.021e+02, Test loss: 3.144e+04, MSE(e): 4.531e-05, MSE(pi1): 5.013e-03, MSE(pi2): 5.287e-05, MSE(pi3): 9.880e-04\n",
      "Epoch 75700, Train loss: 5.959e+02, Test loss: 3.150e+04, MSE(e): 4.509e-05, MSE(pi1): 4.848e-03, MSE(pi2): 5.275e-05, MSE(pi3): 9.652e-04\n",
      "Epoch 75800, Train loss: 5.953e+02, Test loss: 3.148e+04, MSE(e): 4.503e-05, MSE(pi1): 4.838e-03, MSE(pi2): 5.268e-05, MSE(pi3): 9.658e-04\n",
      "Epoch 75900, Train loss: 6.031e+02, Test loss: 3.124e+04, MSE(e): 4.579e-05, MSE(pi1): 4.882e-03, MSE(pi2): 5.289e-05, MSE(pi3): 9.639e-04\n",
      "Epoch 76000, Train loss: 5.940e+02, Test loss: 3.147e+04, MSE(e): 4.491e-05, MSE(pi1): 4.832e-03, MSE(pi2): 5.254e-05, MSE(pi3): 9.644e-04\n",
      "Epoch 76100, Train loss: 5.948e+02, Test loss: 3.137e+04, MSE(e): 4.495e-05, MSE(pi1): 4.803e-03, MSE(pi2): 5.250e-05, MSE(pi3): 9.717e-04\n",
      "Epoch 76200, Train loss: 6.059e+02, Test loss: 3.169e+04, MSE(e): 4.518e-05, MSE(pi1): 5.637e-03, MSE(pi2): 5.258e-05, MSE(pi3): 9.770e-04\n",
      "Epoch 76300, Train loss: 5.954e+02, Test loss: 3.142e+04, MSE(e): 4.475e-05, MSE(pi1): 5.000e-03, MSE(pi2): 5.234e-05, MSE(pi3): 9.790e-04\n",
      "Epoch 76400, Train loss: 5.965e+02, Test loss: 3.137e+04, MSE(e): 4.519e-05, MSE(pi1): 4.859e-03, MSE(pi2): 5.246e-05, MSE(pi3): 9.600e-04\n",
      "Epoch 76500, Train loss: 5.927e+02, Test loss: 3.141e+04, MSE(e): 4.463e-05, MSE(pi1): 5.150e-03, MSE(pi2): 5.220e-05, MSE(pi3): 9.484e-04\n",
      "Epoch 76600, Train loss: 5.995e+02, Test loss: 3.181e+04, MSE(e): 4.482e-05, MSE(pi1): 5.840e-03, MSE(pi2): 5.226e-05, MSE(pi3): 9.286e-04\n",
      "Epoch 76700, Train loss: 5.894e+02, Test loss: 3.139e+04, MSE(e): 4.452e-05, MSE(pi1): 4.829e-03, MSE(pi2): 5.207e-05, MSE(pi3): 9.589e-04\n",
      "Epoch 76800, Train loss: 5.905e+02, Test loss: 3.131e+04, MSE(e): 4.463e-05, MSE(pi1): 4.802e-03, MSE(pi2): 5.206e-05, MSE(pi3): 9.614e-04\n",
      "Epoch 76900, Train loss: 5.952e+02, Test loss: 3.122e+04, MSE(e): 4.510e-05, MSE(pi1): 4.814e-03, MSE(pi2): 5.219e-05, MSE(pi3): 9.602e-04\n",
      "Epoch 77000, Train loss: 5.881e+02, Test loss: 3.128e+04, MSE(e): 4.440e-05, MSE(pi1): 4.762e-03, MSE(pi2): 5.188e-05, MSE(pi3): 9.645e-04\n",
      "Epoch 77100, Train loss: 5.921e+02, Test loss: 3.119e+04, MSE(e): 4.480e-05, MSE(pi1): 4.849e-03, MSE(pi2): 5.198e-05, MSE(pi3): 9.551e-04\n",
      "Epoch 77200, Train loss: 5.884e+02, Test loss: 3.135e+04, MSE(e): 4.424e-05, MSE(pi1): 4.926e-03, MSE(pi2): 5.174e-05, MSE(pi3): 9.666e-04\n",
      "Epoch 77300, Train loss: 5.889e+02, Test loss: 3.128e+04, MSE(e): 4.441e-05, MSE(pi1): 4.917e-03, MSE(pi2): 5.175e-05, MSE(pi3): 9.555e-04\n",
      "Epoch 77400, Train loss: 5.858e+02, Test loss: 3.123e+04, MSE(e): 4.421e-05, MSE(pi1): 4.801e-03, MSE(pi2): 5.163e-05, MSE(pi3): 9.563e-04\n",
      "Epoch 77500, Train loss: 5.842e+02, Test loss: 3.131e+04, MSE(e): 4.407e-05, MSE(pi1): 4.776e-03, MSE(pi2): 5.154e-05, MSE(pi3): 9.573e-04\n",
      "Epoch 77600, Train loss: 5.851e+02, Test loss: 3.125e+04, MSE(e): 4.404e-05, MSE(pi1): 5.037e-03, MSE(pi2): 5.148e-05, MSE(pi3): 9.427e-04\n",
      "Epoch 77700, Train loss: 5.831e+02, Test loss: 3.128e+04, MSE(e): 4.397e-05, MSE(pi1): 4.781e-03, MSE(pi2): 5.142e-05, MSE(pi3): 9.556e-04\n",
      "Epoch 77800, Train loss: 5.829e+02, Test loss: 3.125e+04, MSE(e): 4.391e-05, MSE(pi1): 4.890e-03, MSE(pi2): 5.135e-05, MSE(pi3): 9.485e-04\n",
      "Epoch 77900, Train loss: 5.835e+02, Test loss: 3.120e+04, MSE(e): 4.393e-05, MSE(pi1): 4.734e-03, MSE(pi2): 5.130e-05, MSE(pi3): 9.686e-04\n",
      "Epoch 78000, Train loss: 5.828e+02, Test loss: 3.131e+04, MSE(e): 4.380e-05, MSE(pi1): 5.071e-03, MSE(pi2): 5.122e-05, MSE(pi3): 9.404e-04\n",
      "Epoch 78100, Train loss: 5.805e+02, Test loss: 3.123e+04, MSE(e): 4.374e-05, MSE(pi1): 4.758e-03, MSE(pi2): 5.115e-05, MSE(pi3): 9.546e-04\n",
      "Epoch 78200, Train loss: 5.800e+02, Test loss: 3.125e+04, MSE(e): 4.369e-05, MSE(pi1): 4.708e-03, MSE(pi2): 5.110e-05, MSE(pi3): 9.593e-04\n",
      "Epoch 78300, Train loss: 5.803e+02, Test loss: 3.119e+04, MSE(e): 4.369e-05, MSE(pi1): 4.742e-03, MSE(pi2): 5.104e-05, MSE(pi3): 9.589e-04\n",
      "Epoch 78400, Train loss: 5.787e+02, Test loss: 3.120e+04, MSE(e): 4.358e-05, MSE(pi1): 4.730e-03, MSE(pi2): 5.096e-05, MSE(pi3): 9.553e-04\n",
      "Epoch 78500, Train loss: 5.783e+02, Test loss: 3.117e+04, MSE(e): 4.353e-05, MSE(pi1): 4.794e-03, MSE(pi2): 5.090e-05, MSE(pi3): 9.504e-04\n",
      "Epoch 78600, Train loss: 5.778e+02, Test loss: 3.118e+04, MSE(e): 4.347e-05, MSE(pi1): 4.720e-03, MSE(pi2): 5.084e-05, MSE(pi3): 9.582e-04\n",
      "Epoch 78700, Train loss: 5.770e+02, Test loss: 3.116e+04, MSE(e): 4.344e-05, MSE(pi1): 4.723e-03, MSE(pi2): 5.077e-05, MSE(pi3): 9.540e-04\n",
      "Epoch 78800, Train loss: 5.762e+02, Test loss: 3.118e+04, MSE(e): 4.337e-05, MSE(pi1): 4.717e-03, MSE(pi2): 5.072e-05, MSE(pi3): 9.533e-04\n",
      "Epoch 78900, Train loss: 5.801e+02, Test loss: 3.116e+04, MSE(e): 4.333e-05, MSE(pi1): 5.366e-03, MSE(pi2): 5.066e-05, MSE(pi3): 9.307e-04\n",
      "Epoch 79000, Train loss: 5.764e+02, Test loss: 3.116e+04, MSE(e): 4.328e-05, MSE(pi1): 4.709e-03, MSE(pi2): 5.059e-05, MSE(pi3): 9.645e-04\n",
      "Epoch 79100, Train loss: 5.748e+02, Test loss: 3.117e+04, MSE(e): 4.322e-05, MSE(pi1): 4.662e-03, MSE(pi2): 5.053e-05, MSE(pi3): 9.593e-04\n",
      "Epoch 79200, Train loss: 5.809e+02, Test loss: 3.129e+04, MSE(e): 4.383e-05, MSE(pi1): 4.679e-03, MSE(pi2): 5.079e-05, MSE(pi3): 9.569e-04\n",
      "Epoch 79300, Train loss: 6.019e+02, Test loss: 3.082e+04, MSE(e): 4.595e-05, MSE(pi1): 4.801e-03, MSE(pi2): 5.151e-05, MSE(pi3): 9.437e-04\n",
      "Epoch 79400, Train loss: 5.743e+02, Test loss: 3.098e+04, MSE(e): 4.320e-05, MSE(pi1): 4.838e-03, MSE(pi2): 5.038e-05, MSE(pi3): 9.394e-04\n",
      "Epoch 79500, Train loss: 5.725e+02, Test loss: 3.113e+04, MSE(e): 4.302e-05, MSE(pi1): 4.671e-03, MSE(pi2): 5.028e-05, MSE(pi3): 9.556e-04\n",
      "Epoch 79600, Train loss: 5.715e+02, Test loss: 3.110e+04, MSE(e): 4.295e-05, MSE(pi1): 4.686e-03, MSE(pi2): 5.022e-05, MSE(pi3): 9.502e-04\n",
      "Epoch 79700, Train loss: 5.867e+02, Test loss: 3.107e+04, MSE(e): 4.293e-05, MSE(pi1): 6.578e-03, MSE(pi2): 5.015e-05, MSE(pi3): 9.158e-04\n",
      "Epoch 79800, Train loss: 5.717e+02, Test loss: 3.098e+04, MSE(e): 4.289e-05, MSE(pi1): 4.888e-03, MSE(pi2): 5.010e-05, MSE(pi3): 9.395e-04\n",
      "Epoch 79900, Train loss: 6.042e+02, Test loss: 3.076e+04, MSE(e): 4.605e-05, MSE(pi1): 5.072e-03, MSE(pi2): 5.132e-05, MSE(pi3): 9.286e-04\n",
      "Epoch 80000, Train loss: 5.727e+02, Test loss: 3.104e+04, MSE(e): 4.275e-05, MSE(pi1): 4.899e-03, MSE(pi2): 4.997e-05, MSE(pi3): 9.617e-04\n",
      "Epoch 80100, Train loss: 5.695e+02, Test loss: 3.104e+04, MSE(e): 4.269e-05, MSE(pi1): 4.707e-03, MSE(pi2): 4.991e-05, MSE(pi3): 9.548e-04\n",
      "Epoch 80200, Train loss: 5.721e+02, Test loss: 3.086e+04, MSE(e): 4.295e-05, MSE(pi1): 4.991e-03, MSE(pi2): 5.006e-05, MSE(pi3): 9.272e-04\n",
      "Epoch 80300, Train loss: 5.701e+02, Test loss: 3.109e+04, MSE(e): 4.278e-05, MSE(pi1): 4.721e-03, MSE(pi2): 4.989e-05, MSE(pi3): 9.503e-04\n",
      "Epoch 80400, Train loss: 5.742e+02, Test loss: 3.107e+04, MSE(e): 4.323e-05, MSE(pi1): 4.748e-03, MSE(pi2): 5.004e-05, MSE(pi3): 9.442e-04\n",
      "Epoch 80500, Train loss: 5.702e+02, Test loss: 3.108e+04, MSE(e): 4.254e-05, MSE(pi1): 5.104e-03, MSE(pi2): 4.970e-05, MSE(pi3): 9.371e-04\n",
      "Epoch 80600, Train loss: 5.659e+02, Test loss: 3.099e+04, MSE(e): 4.245e-05, MSE(pi1): 4.699e-03, MSE(pi2): 4.962e-05, MSE(pi3): 9.437e-04\n",
      "Epoch 80700, Train loss: 5.653e+02, Test loss: 3.096e+04, MSE(e): 4.241e-05, MSE(pi1): 4.631e-03, MSE(pi2): 4.955e-05, MSE(pi3): 9.488e-04\n",
      "Epoch 80800, Train loss: 5.653e+02, Test loss: 3.095e+04, MSE(e): 4.235e-05, MSE(pi1): 4.776e-03, MSE(pi2): 4.949e-05, MSE(pi3): 9.402e-04\n",
      "Epoch 80900, Train loss: 5.651e+02, Test loss: 3.094e+04, MSE(e): 4.231e-05, MSE(pi1): 4.807e-03, MSE(pi2): 4.944e-05, MSE(pi3): 9.388e-04\n",
      "Epoch 81000, Train loss: 5.690e+02, Test loss: 3.120e+04, MSE(e): 4.269e-05, MSE(pi1): 4.532e-03, MSE(pi2): 4.963e-05, MSE(pi3): 9.670e-04\n",
      "Epoch 81100, Train loss: 5.634e+02, Test loss: 3.094e+04, MSE(e): 4.219e-05, MSE(pi1): 4.594e-03, MSE(pi2): 4.931e-05, MSE(pi3): 9.550e-04\n",
      "Epoch 81200, Train loss: 5.638e+02, Test loss: 3.096e+04, MSE(e): 4.216e-05, MSE(pi1): 4.953e-03, MSE(pi2): 4.926e-05, MSE(pi3): 9.265e-04\n",
      "Epoch 81300, Train loss: 5.623e+02, Test loss: 3.096e+04, MSE(e): 4.215e-05, MSE(pi1): 4.675e-03, MSE(pi2): 4.923e-05, MSE(pi3): 9.401e-04\n",
      "Epoch 81400, Train loss: 5.619e+02, Test loss: 3.089e+04, MSE(e): 4.206e-05, MSE(pi1): 4.772e-03, MSE(pi2): 4.915e-05, MSE(pi3): 9.354e-04\n",
      "Epoch 81500, Train loss: 5.607e+02, Test loss: 3.093e+04, MSE(e): 4.200e-05, MSE(pi1): 4.550e-03, MSE(pi2): 4.908e-05, MSE(pi3): 9.513e-04\n",
      "Epoch 81600, Train loss: 5.633e+02, Test loss: 3.106e+04, MSE(e): 4.224e-05, MSE(pi1): 4.725e-03, MSE(pi2): 4.916e-05, MSE(pi3): 9.360e-04\n",
      "Epoch 81700, Train loss: 5.612e+02, Test loss: 3.097e+04, MSE(e): 4.194e-05, MSE(pi1): 4.582e-03, MSE(pi2): 4.899e-05, MSE(pi3): 9.588e-04\n",
      "Epoch 81800, Train loss: 5.592e+02, Test loss: 3.089e+04, MSE(e): 4.185e-05, MSE(pi1): 4.672e-03, MSE(pi2): 4.891e-05, MSE(pi3): 9.389e-04\n",
      "Epoch 81900, Train loss: 5.584e+02, Test loss: 3.087e+04, MSE(e): 4.180e-05, MSE(pi1): 4.583e-03, MSE(pi2): 4.885e-05, MSE(pi3): 9.446e-04\n",
      "Epoch 82000, Train loss: 5.579e+02, Test loss: 3.085e+04, MSE(e): 4.176e-05, MSE(pi1): 4.588e-03, MSE(pi2): 4.879e-05, MSE(pi3): 9.439e-04\n",
      "Epoch 82100, Train loss: 5.579e+02, Test loss: 3.091e+04, MSE(e): 4.177e-05, MSE(pi1): 4.612e-03, MSE(pi2): 4.877e-05, MSE(pi3): 9.410e-04\n",
      "Epoch 82200, Train loss: 5.585e+02, Test loss: 3.092e+04, MSE(e): 4.180e-05, MSE(pi1): 4.655e-03, MSE(pi2): 4.875e-05, MSE(pi3): 9.389e-04\n",
      "Epoch 82300, Train loss: 5.604e+02, Test loss: 3.099e+04, MSE(e): 4.201e-05, MSE(pi1): 4.618e-03, MSE(pi2): 4.881e-05, MSE(pi3): 9.405e-04\n",
      "Epoch 82400, Train loss: 5.625e+02, Test loss: 3.071e+04, MSE(e): 4.198e-05, MSE(pi1): 4.870e-03, MSE(pi2): 4.871e-05, MSE(pi3): 9.391e-04\n",
      "Epoch 82500, Train loss: 5.561e+02, Test loss: 3.077e+04, MSE(e): 4.157e-05, MSE(pi1): 4.704e-03, MSE(pi2): 4.853e-05, MSE(pi3): 9.332e-04\n",
      "Epoch 82600, Train loss: 5.546e+02, Test loss: 3.080e+04, MSE(e): 4.147e-05, MSE(pi1): 4.600e-03, MSE(pi2): 4.845e-05, MSE(pi3): 9.385e-04\n",
      "Epoch 82700, Train loss: 5.541e+02, Test loss: 3.082e+04, MSE(e): 4.143e-05, MSE(pi1): 4.558e-03, MSE(pi2): 4.840e-05, MSE(pi3): 9.420e-04\n",
      "Epoch 82800, Train loss: 5.535e+02, Test loss: 3.079e+04, MSE(e): 4.138e-05, MSE(pi1): 4.561e-03, MSE(pi2): 4.834e-05, MSE(pi3): 9.410e-04\n",
      "Epoch 82900, Train loss: 5.542e+02, Test loss: 3.089e+04, MSE(e): 4.144e-05, MSE(pi1): 4.623e-03, MSE(pi2): 4.834e-05, MSE(pi3): 9.356e-04\n",
      "Epoch 83000, Train loss: 5.528e+02, Test loss: 3.077e+04, MSE(e): 4.129e-05, MSE(pi1): 4.588e-03, MSE(pi2): 4.823e-05, MSE(pi3): 9.397e-04\n",
      "Epoch 83100, Train loss: 5.520e+02, Test loss: 3.078e+04, MSE(e): 4.124e-05, MSE(pi1): 4.543e-03, MSE(pi2): 4.818e-05, MSE(pi3): 9.407e-04\n",
      "Epoch 83200, Train loss: 5.657e+02, Test loss: 3.097e+04, MSE(e): 4.252e-05, MSE(pi1): 4.352e-03, MSE(pi2): 4.877e-05, MSE(pi3): 9.692e-04\n",
      "Epoch 83300, Train loss: 5.525e+02, Test loss: 3.079e+04, MSE(e): 4.117e-05, MSE(pi1): 4.717e-03, MSE(pi2): 4.808e-05, MSE(pi3): 9.360e-04\n",
      "Epoch 83400, Train loss: 5.789e+02, Test loss: 3.047e+04, MSE(e): 4.371e-05, MSE(pi1): 5.079e-03, MSE(pi2): 4.902e-05, MSE(pi3): 9.097e-04\n",
      "Epoch 83500, Train loss: 5.503e+02, Test loss: 3.075e+04, MSE(e): 4.107e-05, MSE(pi1): 4.541e-03, MSE(pi2): 4.796e-05, MSE(pi3): 9.416e-04\n",
      "Epoch 83600, Train loss: 5.498e+02, Test loss: 3.069e+04, MSE(e): 4.105e-05, MSE(pi1): 4.539e-03, MSE(pi2): 4.791e-05, MSE(pi3): 9.386e-04\n",
      "Epoch 83700, Train loss: 5.600e+02, Test loss: 3.056e+04, MSE(e): 4.206e-05, MSE(pi1): 4.600e-03, MSE(pi2): 4.827e-05, MSE(pi3): 9.337e-04\n",
      "Epoch 83800, Train loss: 5.494e+02, Test loss: 3.077e+04, MSE(e): 4.101e-05, MSE(pi1): 4.511e-03, MSE(pi2): 4.784e-05, MSE(pi3): 9.407e-04\n",
      "Epoch 83900, Train loss: 5.507e+02, Test loss: 3.068e+04, MSE(e): 4.093e-05, MSE(pi1): 4.554e-03, MSE(pi2): 4.778e-05, MSE(pi3): 9.585e-04\n",
      "Epoch 84000, Train loss: 5.483e+02, Test loss: 3.068e+04, MSE(e): 4.092e-05, MSE(pi1): 4.543e-03, MSE(pi2): 4.772e-05, MSE(pi3): 9.359e-04\n",
      "Epoch 84100, Train loss: 5.472e+02, Test loss: 3.074e+04, MSE(e): 4.082e-05, MSE(pi1): 4.475e-03, MSE(pi2): 4.765e-05, MSE(pi3): 9.419e-04\n",
      "Epoch 84200, Train loss: 5.532e+02, Test loss: 3.071e+04, MSE(e): 4.075e-05, MSE(pi1): 4.909e-03, MSE(pi2): 4.758e-05, MSE(pi3): 9.655e-04\n",
      "Epoch 84300, Train loss: 5.459e+02, Test loss: 3.069e+04, MSE(e): 4.070e-05, MSE(pi1): 4.500e-03, MSE(pi2): 4.753e-05, MSE(pi3): 9.381e-04\n",
      "Epoch 84400, Train loss: 5.454e+02, Test loss: 3.064e+04, MSE(e): 4.066e-05, MSE(pi1): 4.543e-03, MSE(pi2): 4.747e-05, MSE(pi3): 9.338e-04\n",
      "Epoch 84500, Train loss: 5.467e+02, Test loss: 3.072e+04, MSE(e): 4.069e-05, MSE(pi1): 4.493e-03, MSE(pi2): 4.746e-05, MSE(pi3): 9.485e-04\n",
      "Epoch 84600, Train loss: 5.446e+02, Test loss: 3.061e+04, MSE(e): 4.057e-05, MSE(pi1): 4.482e-03, MSE(pi2): 4.737e-05, MSE(pi3): 9.404e-04\n",
      "Epoch 84700, Train loss: 5.439e+02, Test loss: 3.065e+04, MSE(e): 4.053e-05, MSE(pi1): 4.504e-03, MSE(pi2): 4.732e-05, MSE(pi3): 9.353e-04\n",
      "Epoch 84800, Train loss: 5.435e+02, Test loss: 3.066e+04, MSE(e): 4.049e-05, MSE(pi1): 4.517e-03, MSE(pi2): 4.727e-05, MSE(pi3): 9.337e-04\n",
      "Epoch 84900, Train loss: 5.437e+02, Test loss: 3.063e+04, MSE(e): 4.044e-05, MSE(pi1): 4.583e-03, MSE(pi2): 4.721e-05, MSE(pi3): 9.343e-04\n",
      "Epoch 85000, Train loss: 5.462e+02, Test loss: 3.048e+04, MSE(e): 4.065e-05, MSE(pi1): 4.710e-03, MSE(pi2): 4.724e-05, MSE(pi3): 9.256e-04\n",
      "Epoch 85100, Train loss: 5.447e+02, Test loss: 3.061e+04, MSE(e): 4.060e-05, MSE(pi1): 4.480e-03, MSE(pi2): 4.725e-05, MSE(pi3): 9.390e-04\n",
      "Epoch 85200, Train loss: 5.545e+02, Test loss: 3.039e+04, MSE(e): 4.149e-05, MSE(pi1): 4.688e-03, MSE(pi2): 4.750e-05, MSE(pi3): 9.273e-04\n",
      "Epoch 85300, Train loss: 5.417e+02, Test loss: 3.054e+04, MSE(e): 4.034e-05, MSE(pi1): 4.550e-03, MSE(pi2): 4.702e-05, MSE(pi3): 9.278e-04\n",
      "Epoch 85400, Train loss: 5.419e+02, Test loss: 3.054e+04, MSE(e): 4.027e-05, MSE(pi1): 4.747e-03, MSE(pi2): 4.696e-05, MSE(pi3): 9.169e-04\n",
      "Epoch 85500, Train loss: 5.418e+02, Test loss: 3.049e+04, MSE(e): 4.021e-05, MSE(pi1): 4.553e-03, MSE(pi2): 4.690e-05, MSE(pi3): 9.414e-04\n",
      "Epoch 85600, Train loss: 5.393e+02, Test loss: 3.055e+04, MSE(e): 4.013e-05, MSE(pi1): 4.485e-03, MSE(pi2): 4.684e-05, MSE(pi3): 9.316e-04\n",
      "Epoch 85700, Train loss: 5.403e+02, Test loss: 3.062e+04, MSE(e): 4.022e-05, MSE(pi1): 4.442e-03, MSE(pi2): 4.687e-05, MSE(pi3): 9.358e-04\n",
      "Epoch 85800, Train loss: 5.384e+02, Test loss: 3.054e+04, MSE(e): 4.004e-05, MSE(pi1): 4.462e-03, MSE(pi2): 4.674e-05, MSE(pi3): 9.330e-04\n",
      "Epoch 85900, Train loss: 5.379e+02, Test loss: 3.053e+04, MSE(e): 4.000e-05, MSE(pi1): 4.477e-03, MSE(pi2): 4.669e-05, MSE(pi3): 9.308e-04\n",
      "Epoch 86000, Train loss: 5.721e+02, Test loss: 3.101e+04, MSE(e): 4.276e-05, MSE(pi1): 4.900e-03, MSE(pi2): 4.780e-05, MSE(pi3): 9.547e-04\n",
      "Epoch 86100, Train loss: 5.372e+02, Test loss: 3.052e+04, MSE(e): 3.992e-05, MSE(pi1): 4.528e-03, MSE(pi2): 4.659e-05, MSE(pi3): 9.272e-04\n",
      "Epoch 86200, Train loss: 5.365e+02, Test loss: 3.054e+04, MSE(e): 3.988e-05, MSE(pi1): 4.433e-03, MSE(pi2): 4.654e-05, MSE(pi3): 9.336e-04\n",
      "Epoch 86300, Train loss: 5.438e+02, Test loss: 3.049e+04, MSE(e): 3.985e-05, MSE(pi1): 5.495e-03, MSE(pi2): 4.649e-05, MSE(pi3): 9.034e-04\n",
      "Epoch 86400, Train loss: 5.359e+02, Test loss: 3.054e+04, MSE(e): 3.980e-05, MSE(pi1): 4.376e-03, MSE(pi2): 4.644e-05, MSE(pi3): 9.404e-04\n",
      "Epoch 86500, Train loss: 5.374e+02, Test loss: 3.054e+04, MSE(e): 3.976e-05, MSE(pi1): 4.531e-03, MSE(pi2): 4.639e-05, MSE(pi3): 9.449e-04\n",
      "Epoch 86600, Train loss: 5.367e+02, Test loss: 3.056e+04, MSE(e): 3.991e-05, MSE(pi1): 4.501e-03, MSE(pi2): 4.645e-05, MSE(pi3): 9.261e-04\n",
      "Epoch 86700, Train loss: 5.356e+02, Test loss: 3.053e+04, MSE(e): 3.968e-05, MSE(pi1): 4.352e-03, MSE(pi2): 4.630e-05, MSE(pi3): 9.517e-04\n",
      "Epoch 86800, Train loss: 5.342e+02, Test loss: 3.045e+04, MSE(e): 3.963e-05, MSE(pi1): 4.433e-03, MSE(pi2): 4.623e-05, MSE(pi3): 9.355e-04\n",
      "Epoch 86900, Train loss: 5.340e+02, Test loss: 3.042e+04, MSE(e): 3.962e-05, MSE(pi1): 4.588e-03, MSE(pi2): 4.619e-05, MSE(pi3): 9.193e-04\n",
      "Epoch 87000, Train loss: 5.337e+02, Test loss: 3.048e+04, MSE(e): 3.961e-05, MSE(pi1): 4.429e-03, MSE(pi2): 4.618e-05, MSE(pi3): 9.326e-04\n",
      "Epoch 87100, Train loss: 5.410e+02, Test loss: 3.061e+04, MSE(e): 3.963e-05, MSE(pi1): 4.781e-03, MSE(pi2): 4.616e-05, MSE(pi3): 9.682e-04\n",
      "Epoch 87200, Train loss: 5.336e+02, Test loss: 3.047e+04, MSE(e): 3.946e-05, MSE(pi1): 4.534e-03, MSE(pi2): 4.604e-05, MSE(pi3): 9.358e-04\n",
      "Epoch 87300, Train loss: 5.344e+02, Test loss: 3.041e+04, MSE(e): 3.944e-05, MSE(pi1): 4.899e-03, MSE(pi2): 4.598e-05, MSE(pi3): 9.099e-04\n",
      "Epoch 87400, Train loss: 5.337e+02, Test loss: 3.032e+04, MSE(e): 3.957e-05, MSE(pi1): 4.378e-03, MSE(pi2): 4.600e-05, MSE(pi3): 9.421e-04\n",
      "Epoch 87500, Train loss: 5.329e+02, Test loss: 3.045e+04, MSE(e): 3.935e-05, MSE(pi1): 4.469e-03, MSE(pi2): 4.590e-05, MSE(pi3): 9.462e-04\n",
      "Epoch 87600, Train loss: 5.321e+02, Test loss: 3.044e+04, MSE(e): 3.930e-05, MSE(pi1): 4.430e-03, MSE(pi2): 4.584e-05, MSE(pi3): 9.476e-04\n",
      "Epoch 87700, Train loss: 5.314e+02, Test loss: 3.036e+04, MSE(e): 3.929e-05, MSE(pi1): 4.490e-03, MSE(pi2): 4.582e-05, MSE(pi3): 9.353e-04\n",
      "Epoch 87800, Train loss: 5.298e+02, Test loss: 3.037e+04, MSE(e): 3.926e-05, MSE(pi1): 4.476e-03, MSE(pi2): 4.578e-05, MSE(pi3): 9.232e-04\n",
      "Epoch 87900, Train loss: 5.300e+02, Test loss: 3.033e+04, MSE(e): 3.925e-05, MSE(pi1): 4.614e-03, MSE(pi2): 4.574e-05, MSE(pi3): 9.127e-04\n",
      "Epoch 88000, Train loss: 5.320e+02, Test loss: 3.026e+04, MSE(e): 3.947e-05, MSE(pi1): 4.410e-03, MSE(pi2): 4.575e-05, MSE(pi3): 9.320e-04\n",
      "Epoch 88100, Train loss: 5.311e+02, Test loss: 3.039e+04, MSE(e): 3.942e-05, MSE(pi1): 4.368e-03, MSE(pi2): 4.577e-05, MSE(pi3): 9.322e-04\n",
      "Epoch 88200, Train loss: 5.727e+02, Test loss: 3.077e+04, MSE(e): 4.356e-05, MSE(pi1): 4.359e-03, MSE(pi2): 4.752e-05, MSE(pi3): 9.346e-04\n",
      "Epoch 88300, Train loss: 5.271e+02, Test loss: 3.030e+04, MSE(e): 3.902e-05, MSE(pi1): 4.472e-03, MSE(pi2): 4.550e-05, MSE(pi3): 9.209e-04\n",
      "Epoch 88400, Train loss: 5.263e+02, Test loss: 3.034e+04, MSE(e): 3.897e-05, MSE(pi1): 4.457e-03, MSE(pi2): 4.544e-05, MSE(pi3): 9.201e-04\n",
      "Epoch 88500, Train loss: 5.279e+02, Test loss: 3.021e+04, MSE(e): 3.913e-05, MSE(pi1): 4.427e-03, MSE(pi2): 4.546e-05, MSE(pi3): 9.232e-04\n",
      "Epoch 88600, Train loss: 5.254e+02, Test loss: 3.033e+04, MSE(e): 3.889e-05, MSE(pi1): 4.362e-03, MSE(pi2): 4.535e-05, MSE(pi3): 9.288e-04\n",
      "Epoch 88700, Train loss: 5.250e+02, Test loss: 3.031e+04, MSE(e): 3.886e-05, MSE(pi1): 4.388e-03, MSE(pi2): 4.531e-05, MSE(pi3): 9.249e-04\n",
      "Epoch 88800, Train loss: 5.343e+02, Test loss: 3.027e+04, MSE(e): 3.890e-05, MSE(pi1): 5.562e-03, MSE(pi2): 4.527e-05, MSE(pi3): 8.968e-04\n",
      "Epoch 88900, Train loss: 5.241e+02, Test loss: 3.032e+04, MSE(e): 3.877e-05, MSE(pi1): 4.362e-03, MSE(pi2): 4.520e-05, MSE(pi3): 9.278e-04\n",
      "Epoch 89000, Train loss: 5.273e+02, Test loss: 3.018e+04, MSE(e): 3.909e-05, MSE(pi1): 4.410e-03, MSE(pi2): 4.529e-05, MSE(pi3): 9.230e-04\n",
      "Epoch 89100, Train loss: 5.246e+02, Test loss: 3.023e+04, MSE(e): 3.872e-05, MSE(pi1): 4.609e-03, MSE(pi2): 4.513e-05, MSE(pi3): 9.127e-04\n",
      "Epoch 89200, Train loss: 5.231e+02, Test loss: 3.026e+04, MSE(e): 3.866e-05, MSE(pi1): 4.454e-03, MSE(pi2): 4.506e-05, MSE(pi3): 9.192e-04\n",
      "Epoch 89300, Train loss: 5.261e+02, Test loss: 3.016e+04, MSE(e): 3.896e-05, MSE(pi1): 4.318e-03, MSE(pi2): 4.514e-05, MSE(pi3): 9.335e-04\n",
      "Epoch 89400, Train loss: 5.232e+02, Test loss: 3.029e+04, MSE(e): 3.858e-05, MSE(pi1): 4.336e-03, MSE(pi2): 4.497e-05, MSE(pi3): 9.399e-04\n",
      "Epoch 89500, Train loss: 5.234e+02, Test loss: 3.013e+04, MSE(e): 3.873e-05, MSE(pi1): 4.430e-03, MSE(pi2): 4.499e-05, MSE(pi3): 9.173e-04\n",
      "Epoch 89600, Train loss: 5.212e+02, Test loss: 3.026e+04, MSE(e): 3.850e-05, MSE(pi1): 4.365e-03, MSE(pi2): 4.488e-05, MSE(pi3): 9.250e-04\n",
      "Epoch 89700, Train loss: 5.255e+02, Test loss: 3.030e+04, MSE(e): 3.847e-05, MSE(pi1): 4.573e-03, MSE(pi2): 4.484e-05, MSE(pi3): 9.496e-04\n",
      "Epoch 89800, Train loss: 5.237e+02, Test loss: 3.032e+04, MSE(e): 3.848e-05, MSE(pi1): 4.451e-03, MSE(pi2): 4.483e-05, MSE(pi3): 9.432e-04\n",
      "Epoch 89900, Train loss: 5.204e+02, Test loss: 3.031e+04, MSE(e): 3.841e-05, MSE(pi1): 4.532e-03, MSE(pi2): 4.475e-05, MSE(pi3): 9.098e-04\n",
      "Epoch 90000, Train loss: 5.207e+02, Test loss: 3.015e+04, MSE(e): 3.837e-05, MSE(pi1): 4.576e-03, MSE(pi2): 4.470e-05, MSE(pi3): 9.114e-04\n",
      "Epoch 90100, Train loss: 5.191e+02, Test loss: 3.025e+04, MSE(e): 3.832e-05, MSE(pi1): 4.323e-03, MSE(pi2): 4.465e-05, MSE(pi3): 9.264e-04\n",
      "Epoch 90200, Train loss: 5.191e+02, Test loss: 3.018e+04, MSE(e): 3.827e-05, MSE(pi1): 4.488e-03, MSE(pi2): 4.460e-05, MSE(pi3): 9.141e-04\n",
      "Epoch 90300, Train loss: 5.180e+02, Test loss: 3.019e+04, MSE(e): 3.823e-05, MSE(pi1): 4.324e-03, MSE(pi2): 4.455e-05, MSE(pi3): 9.246e-04\n",
      "Epoch 90400, Train loss: 5.198e+02, Test loss: 3.027e+04, MSE(e): 3.841e-05, MSE(pi1): 4.356e-03, MSE(pi2): 4.462e-05, MSE(pi3): 9.211e-04\n",
      "Epoch 90500, Train loss: 5.171e+02, Test loss: 3.018e+04, MSE(e): 3.815e-05, MSE(pi1): 4.389e-03, MSE(pi2): 4.446e-05, MSE(pi3): 9.165e-04\n",
      "Epoch 90600, Train loss: 5.167e+02, Test loss: 3.016e+04, MSE(e): 3.812e-05, MSE(pi1): 4.349e-03, MSE(pi2): 4.441e-05, MSE(pi3): 9.198e-04\n",
      "Epoch 90700, Train loss: 5.175e+02, Test loss: 3.011e+04, MSE(e): 3.816e-05, MSE(pi1): 4.448e-03, MSE(pi2): 4.441e-05, MSE(pi3): 9.132e-04\n",
      "Epoch 90800, Train loss: 5.174e+02, Test loss: 3.018e+04, MSE(e): 3.814e-05, MSE(pi1): 4.505e-03, MSE(pi2): 4.438e-05, MSE(pi3): 9.089e-04\n",
      "Epoch 90900, Train loss: 5.180e+02, Test loss: 3.023e+04, MSE(e): 3.825e-05, MSE(pi1): 4.331e-03, MSE(pi2): 4.440e-05, MSE(pi3): 9.215e-04\n",
      "Epoch 91000, Train loss: 5.164e+02, Test loss: 3.023e+04, MSE(e): 3.808e-05, MSE(pi1): 4.342e-03, MSE(pi2): 4.429e-05, MSE(pi3): 9.208e-04\n",
      "Epoch 91100, Train loss: 5.165e+02, Test loss: 3.013e+04, MSE(e): 3.808e-05, MSE(pi1): 4.533e-03, MSE(pi2): 4.427e-05, MSE(pi3): 9.035e-04\n",
      "Epoch 91200, Train loss: 5.188e+02, Test loss: 3.015e+04, MSE(e): 3.789e-05, MSE(pi1): 4.604e-03, MSE(pi2): 4.414e-05, MSE(pi3): 9.385e-04\n",
      "Epoch 91300, Train loss: 5.137e+02, Test loss: 3.013e+04, MSE(e): 3.785e-05, MSE(pi1): 4.316e-03, MSE(pi2): 4.409e-05, MSE(pi3): 9.201e-04\n",
      "Epoch 91400, Train loss: 5.171e+02, Test loss: 3.002e+04, MSE(e): 3.820e-05, MSE(pi1): 4.318e-03, MSE(pi2): 4.419e-05, MSE(pi3): 9.193e-04\n",
      "Epoch 91500, Train loss: 5.161e+02, Test loss: 3.016e+04, MSE(e): 3.779e-05, MSE(pi1): 4.470e-03, MSE(pi2): 4.401e-05, MSE(pi3): 9.341e-04\n",
      "Epoch 91600, Train loss: 5.146e+02, Test loss: 3.017e+04, MSE(e): 3.795e-05, MSE(pi1): 4.307e-03, MSE(pi2): 4.406e-05, MSE(pi3): 9.198e-04\n",
      "Epoch 91700, Train loss: 5.122e+02, Test loss: 3.008e+04, MSE(e): 3.770e-05, MSE(pi1): 4.366e-03, MSE(pi2): 4.391e-05, MSE(pi3): 9.141e-04\n",
      "Epoch 91800, Train loss: 5.116e+02, Test loss: 3.008e+04, MSE(e): 3.766e-05, MSE(pi1): 4.316e-03, MSE(pi2): 4.387e-05, MSE(pi3): 9.172e-04\n",
      "Epoch 91900, Train loss: 5.114e+02, Test loss: 3.011e+04, MSE(e): 3.764e-05, MSE(pi1): 4.270e-03, MSE(pi2): 4.383e-05, MSE(pi3): 9.225e-04\n",
      "Epoch 92000, Train loss: 5.110e+02, Test loss: 3.005e+04, MSE(e): 3.762e-05, MSE(pi1): 4.324e-03, MSE(pi2): 4.378e-05, MSE(pi3): 9.156e-04\n",
      "Epoch 92100, Train loss: 5.111e+02, Test loss: 3.006e+04, MSE(e): 3.756e-05, MSE(pi1): 4.384e-03, MSE(pi2): 4.373e-05, MSE(pi3): 9.165e-04\n",
      "Epoch 92200, Train loss: 5.102e+02, Test loss: 3.003e+04, MSE(e): 3.754e-05, MSE(pi1): 4.274e-03, MSE(pi2): 4.369e-05, MSE(pi3): 9.201e-04\n",
      "Epoch 92300, Train loss: 5.109e+02, Test loss: 2.999e+04, MSE(e): 3.760e-05, MSE(pi1): 4.355e-03, MSE(pi2): 4.368e-05, MSE(pi3): 9.132e-04\n",
      "Epoch 92400, Train loss: 5.213e+02, Test loss: 3.021e+04, MSE(e): 3.836e-05, MSE(pi1): 4.364e-03, MSE(pi2): 4.400e-05, MSE(pi3): 9.396e-04\n",
      "Epoch 92500, Train loss: 5.171e+02, Test loss: 2.986e+04, MSE(e): 3.767e-05, MSE(pi1): 4.848e-03, MSE(pi2): 4.371e-05, MSE(pi3): 9.189e-04\n",
      "Epoch 92600, Train loss: 5.085e+02, Test loss: 3.003e+04, MSE(e): 3.740e-05, MSE(pi1): 4.296e-03, MSE(pi2): 4.353e-05, MSE(pi3): 9.156e-04\n",
      "Epoch 92700, Train loss: 5.084e+02, Test loss: 3.000e+04, MSE(e): 3.737e-05, MSE(pi1): 4.310e-03, MSE(pi2): 4.349e-05, MSE(pi3): 9.160e-04\n",
      "Epoch 92800, Train loss: 5.074e+02, Test loss: 3.002e+04, MSE(e): 3.730e-05, MSE(pi1): 4.276e-03, MSE(pi2): 4.342e-05, MSE(pi3): 9.168e-04\n",
      "Epoch 92900, Train loss: 5.097e+02, Test loss: 3.012e+04, MSE(e): 3.745e-05, MSE(pi1): 4.266e-03, MSE(pi2): 4.348e-05, MSE(pi3): 9.248e-04\n",
      "Epoch 93000, Train loss: 5.071e+02, Test loss: 3.002e+04, MSE(e): 3.726e-05, MSE(pi1): 4.347e-03, MSE(pi2): 4.334e-05, MSE(pi3): 9.101e-04\n",
      "Epoch 93100, Train loss: 5.071e+02, Test loss: 3.000e+04, MSE(e): 3.723e-05, MSE(pi1): 4.397e-03, MSE(pi2): 4.332e-05, MSE(pi3): 9.073e-04\n",
      "Epoch 93200, Train loss: 5.059e+02, Test loss: 2.997e+04, MSE(e): 3.715e-05, MSE(pi1): 4.285e-03, MSE(pi2): 4.325e-05, MSE(pi3): 9.142e-04\n",
      "Epoch 93300, Train loss: 5.062e+02, Test loss: 2.994e+04, MSE(e): 3.717e-05, MSE(pi1): 4.329e-03, MSE(pi2): 4.322e-05, MSE(pi3): 9.115e-04\n",
      "Epoch 93400, Train loss: 5.178e+02, Test loss: 3.020e+04, MSE(e): 3.829e-05, MSE(pi1): 4.440e-03, MSE(pi2): 4.370e-05, MSE(pi3): 9.046e-04\n",
      "Epoch 93500, Train loss: 5.060e+02, Test loss: 3.004e+04, MSE(e): 3.715e-05, MSE(pi1): 4.336e-03, MSE(pi2): 4.317e-05, MSE(pi3): 9.112e-04\n",
      "Epoch 93600, Train loss: 5.064e+02, Test loss: 3.003e+04, MSE(e): 3.716e-05, MSE(pi1): 4.461e-03, MSE(pi2): 4.314e-05, MSE(pi3): 9.015e-04\n",
      "Epoch 93700, Train loss: 5.129e+02, Test loss: 3.012e+04, MSE(e): 3.787e-05, MSE(pi1): 4.251e-03, MSE(pi2): 4.345e-05, MSE(pi3): 9.156e-04\n",
      "Epoch 93800, Train loss: 5.035e+02, Test loss: 2.995e+04, MSE(e): 3.694e-05, MSE(pi1): 4.275e-03, MSE(pi2): 4.299e-05, MSE(pi3): 9.133e-04\n",
      "Epoch 93900, Train loss: 5.037e+02, Test loss: 2.999e+04, MSE(e): 3.697e-05, MSE(pi1): 4.248e-03, MSE(pi2): 4.298e-05, MSE(pi3): 9.150e-04\n",
      "Epoch 94000, Train loss: 5.033e+02, Test loss: 2.997e+04, MSE(e): 3.689e-05, MSE(pi1): 4.219e-03, MSE(pi2): 4.291e-05, MSE(pi3): 9.217e-04\n",
      "Epoch 94100, Train loss: 5.022e+02, Test loss: 2.992e+04, MSE(e): 3.683e-05, MSE(pi1): 4.262e-03, MSE(pi2): 4.286e-05, MSE(pi3): 9.126e-04\n",
      "Epoch 94200, Train loss: 5.034e+02, Test loss: 2.984e+04, MSE(e): 3.694e-05, MSE(pi1): 4.323e-03, MSE(pi2): 4.286e-05, MSE(pi3): 9.070e-04\n",
      "Epoch 94300, Train loss: 5.018e+02, Test loss: 2.987e+04, MSE(e): 3.678e-05, MSE(pi1): 4.249e-03, MSE(pi2): 4.278e-05, MSE(pi3): 9.139e-04\n",
      "Epoch 94400, Train loss: 5.011e+02, Test loss: 2.990e+04, MSE(e): 3.673e-05, MSE(pi1): 4.231e-03, MSE(pi2): 4.273e-05, MSE(pi3): 9.146e-04\n",
      "Epoch 94500, Train loss: 5.010e+02, Test loss: 2.991e+04, MSE(e): 3.671e-05, MSE(pi1): 4.281e-03, MSE(pi2): 4.270e-05, MSE(pi3): 9.105e-04\n",
      "Epoch 94600, Train loss: 5.012e+02, Test loss: 2.993e+04, MSE(e): 3.675e-05, MSE(pi1): 4.247e-03, MSE(pi2): 4.269e-05, MSE(pi3): 9.122e-04\n",
      "Epoch 94700, Train loss: 5.088e+02, Test loss: 2.971e+04, MSE(e): 3.748e-05, MSE(pi1): 4.357e-03, MSE(pi2): 4.293e-05, MSE(pi3): 9.037e-04\n",
      "Epoch 94800, Train loss: 4.996e+02, Test loss: 2.992e+04, MSE(e): 3.659e-05, MSE(pi1): 4.211e-03, MSE(pi2): 4.256e-05, MSE(pi3): 9.150e-04\n",
      "Epoch 94900, Train loss: 4.996e+02, Test loss: 2.984e+04, MSE(e): 3.659e-05, MSE(pi1): 4.300e-03, MSE(pi2): 4.253e-05, MSE(pi3): 9.067e-04\n",
      "Epoch 95000, Train loss: 4.988e+02, Test loss: 2.984e+04, MSE(e): 3.652e-05, MSE(pi1): 4.237e-03, MSE(pi2): 4.247e-05, MSE(pi3): 9.118e-04\n",
      "Epoch 95100, Train loss: 4.986e+02, Test loss: 2.980e+04, MSE(e): 3.651e-05, MSE(pi1): 4.263e-03, MSE(pi2): 4.244e-05, MSE(pi3): 9.087e-04\n",
      "Epoch 95200, Train loss: 5.001e+02, Test loss: 2.992e+04, MSE(e): 3.666e-05, MSE(pi1): 4.209e-03, MSE(pi2): 4.250e-05, MSE(pi3): 9.137e-04\n",
      "Epoch 95300, Train loss: 4.994e+02, Test loss: 2.986e+04, MSE(e): 3.643e-05, MSE(pi1): 4.511e-03, MSE(pi2): 4.235e-05, MSE(pi3): 8.995e-04\n",
      "Epoch 95400, Train loss: 4.972e+02, Test loss: 2.984e+04, MSE(e): 3.638e-05, MSE(pi1): 4.223e-03, MSE(pi2): 4.231e-05, MSE(pi3): 9.112e-04\n",
      "Epoch 95500, Train loss: 5.073e+02, Test loss: 2.970e+04, MSE(e): 3.736e-05, MSE(pi1): 4.326e-03, MSE(pi2): 4.267e-05, MSE(pi3): 9.042e-04\n",
      "Epoch 95600, Train loss: 4.964e+02, Test loss: 2.981e+04, MSE(e): 3.631e-05, MSE(pi1): 4.228e-03, MSE(pi2): 4.222e-05, MSE(pi3): 9.099e-04\n",
      "Epoch 95700, Train loss: 5.235e+02, Test loss: 3.000e+04, MSE(e): 3.880e-05, MSE(pi1): 4.460e-03, MSE(pi2): 4.332e-05, MSE(pi3): 9.083e-04\n",
      "Epoch 95800, Train loss: 4.959e+02, Test loss: 2.981e+04, MSE(e): 3.625e-05, MSE(pi1): 4.170e-03, MSE(pi2): 4.214e-05, MSE(pi3): 9.165e-04\n",
      "Epoch 95900, Train loss: 4.953e+02, Test loss: 2.980e+04, MSE(e): 3.621e-05, MSE(pi1): 4.215e-03, MSE(pi2): 4.210e-05, MSE(pi3): 9.100e-04\n",
      "Epoch 96000, Train loss: 5.009e+02, Test loss: 2.965e+04, MSE(e): 3.676e-05, MSE(pi1): 4.296e-03, MSE(pi2): 4.228e-05, MSE(pi3): 9.032e-04\n",
      "Epoch 96100, Train loss: 4.958e+02, Test loss: 2.985e+04, MSE(e): 3.626e-05, MSE(pi1): 4.238e-03, MSE(pi2): 4.208e-05, MSE(pi3): 9.082e-04\n",
      "Epoch 96200, Train loss: 4.987e+02, Test loss: 2.962e+04, MSE(e): 3.656e-05, MSE(pi1): 4.270e-03, MSE(pi2): 4.214e-05, MSE(pi3): 9.042e-04\n",
      "Epoch 96300, Train loss: 4.941e+02, Test loss: 2.979e+04, MSE(e): 3.607e-05, MSE(pi1): 4.225e-03, MSE(pi2): 4.193e-05, MSE(pi3): 9.107e-04\n",
      "Epoch 96400, Train loss: 4.967e+02, Test loss: 2.961e+04, MSE(e): 3.623e-05, MSE(pi1): 4.557e-03, MSE(pi2): 4.201e-05, MSE(pi3): 8.884e-04\n",
      "Epoch 96500, Train loss: 4.940e+02, Test loss: 2.981e+04, MSE(e): 3.603e-05, MSE(pi1): 4.166e-03, MSE(pi2): 4.187e-05, MSE(pi3): 9.199e-04\n",
      "Epoch 96600, Train loss: 4.926e+02, Test loss: 2.973e+04, MSE(e): 3.597e-05, MSE(pi1): 4.196e-03, MSE(pi2): 4.181e-05, MSE(pi3): 9.093e-04\n",
      "Epoch 96700, Train loss: 4.922e+02, Test loss: 2.973e+04, MSE(e): 3.593e-05, MSE(pi1): 4.196e-03, MSE(pi2): 4.177e-05, MSE(pi3): 9.090e-04\n",
      "Epoch 96800, Train loss: 4.919e+02, Test loss: 2.974e+04, MSE(e): 3.590e-05, MSE(pi1): 4.179e-03, MSE(pi2): 4.173e-05, MSE(pi3): 9.103e-04\n",
      "Epoch 96900, Train loss: 5.010e+02, Test loss: 2.983e+04, MSE(e): 3.681e-05, MSE(pi1): 4.110e-03, MSE(pi2): 4.211e-05, MSE(pi3): 9.175e-04\n",
      "Epoch 97000, Train loss: 4.920e+02, Test loss: 2.971e+04, MSE(e): 3.583e-05, MSE(pi1): 4.170e-03, MSE(pi2): 4.164e-05, MSE(pi3): 9.196e-04\n",
      "Epoch 97100, Train loss: 4.921e+02, Test loss: 2.971e+04, MSE(e): 3.580e-05, MSE(pi1): 4.227e-03, MSE(pi2): 4.160e-05, MSE(pi3): 9.180e-04\n",
      "Epoch 97200, Train loss: 4.986e+02, Test loss: 2.984e+04, MSE(e): 3.601e-05, MSE(pi1): 4.459e-03, MSE(pi2): 4.167e-05, MSE(pi3): 9.383e-04\n",
      "Epoch 97300, Train loss: 4.968e+02, Test loss: 2.958e+04, MSE(e): 3.622e-05, MSE(pi1): 4.364e-03, MSE(pi2): 4.171e-05, MSE(pi3): 9.095e-04\n",
      "Epoch 97400, Train loss: 4.907e+02, Test loss: 2.964e+04, MSE(e): 3.579e-05, MSE(pi1): 4.155e-03, MSE(pi2): 4.151e-05, MSE(pi3): 9.123e-04\n",
      "Epoch 97500, Train loss: 4.897e+02, Test loss: 2.973e+04, MSE(e): 3.570e-05, MSE(pi1): 4.132e-03, MSE(pi2): 4.146e-05, MSE(pi3): 9.139e-04\n",
      "Epoch 97600, Train loss: 4.891e+02, Test loss: 2.963e+04, MSE(e): 3.565e-05, MSE(pi1): 4.218e-03, MSE(pi2): 4.140e-05, MSE(pi3): 9.044e-04\n",
      "Epoch 97700, Train loss: 4.886e+02, Test loss: 2.967e+04, MSE(e): 3.561e-05, MSE(pi1): 4.169e-03, MSE(pi2): 4.136e-05, MSE(pi3): 9.079e-04\n",
      "Epoch 97800, Train loss: 4.907e+02, Test loss: 2.961e+04, MSE(e): 3.567e-05, MSE(pi1): 4.452e-03, MSE(pi2): 4.135e-05, MSE(pi3): 8.950e-04\n",
      "Epoch 97900, Train loss: 4.936e+02, Test loss: 2.962e+04, MSE(e): 3.557e-05, MSE(pi1): 4.953e-03, MSE(pi2): 4.128e-05, MSE(pi3): 8.832e-04\n",
      "Epoch 98000, Train loss: 4.879e+02, Test loss: 2.966e+04, MSE(e): 3.550e-05, MSE(pi1): 4.235e-03, MSE(pi2): 4.124e-05, MSE(pi3): 9.046e-04\n",
      "Epoch 98100, Train loss: 4.873e+02, Test loss: 2.963e+04, MSE(e): 3.547e-05, MSE(pi1): 4.246e-03, MSE(pi2): 4.120e-05, MSE(pi3): 9.010e-04\n",
      "Epoch 98200, Train loss: 4.875e+02, Test loss: 2.962e+04, MSE(e): 3.544e-05, MSE(pi1): 4.345e-03, MSE(pi2): 4.116e-05, MSE(pi3): 8.965e-04\n",
      "Epoch 98300, Train loss: 4.873e+02, Test loss: 2.966e+04, MSE(e): 3.549e-05, MSE(pi1): 4.169e-03, MSE(pi2): 4.117e-05, MSE(pi3): 9.059e-04\n",
      "Epoch 98400, Train loss: 4.889e+02, Test loss: 2.962e+04, MSE(e): 3.565e-05, MSE(pi1): 4.261e-03, MSE(pi2): 4.118e-05, MSE(pi3): 8.977e-04\n",
      "Epoch 98500, Train loss: 4.856e+02, Test loss: 2.961e+04, MSE(e): 3.534e-05, MSE(pi1): 4.148e-03, MSE(pi2): 4.104e-05, MSE(pi3): 9.072e-04\n",
      "Epoch 98600, Train loss: 4.855e+02, Test loss: 2.958e+04, MSE(e): 3.531e-05, MSE(pi1): 4.197e-03, MSE(pi2): 4.100e-05, MSE(pi3): 9.036e-04\n",
      "Epoch 98700, Train loss: 4.922e+02, Test loss: 2.947e+04, MSE(e): 3.598e-05, MSE(pi1): 4.252e-03, MSE(pi2): 4.124e-05, MSE(pi3): 8.982e-04\n",
      "Epoch 98800, Train loss: 4.855e+02, Test loss: 2.963e+04, MSE(e): 3.525e-05, MSE(pi1): 4.196e-03, MSE(pi2): 4.092e-05, MSE(pi3): 9.101e-04\n",
      "Epoch 98900, Train loss: 4.848e+02, Test loss: 2.961e+04, MSE(e): 3.527e-05, MSE(pi1): 4.134e-03, MSE(pi2): 4.091e-05, MSE(pi3): 9.072e-04\n",
      "Epoch 99000, Train loss: 4.861e+02, Test loss: 2.953e+04, MSE(e): 3.536e-05, MSE(pi1): 4.138e-03, MSE(pi2): 4.092e-05, MSE(pi3): 9.105e-04\n",
      "Epoch 99100, Train loss: 4.997e+02, Test loss: 2.925e+04, MSE(e): 3.669e-05, MSE(pi1): 4.340e-03, MSE(pi2): 4.141e-05, MSE(pi3): 8.932e-04\n",
      "Epoch 99200, Train loss: 4.863e+02, Test loss: 2.948e+04, MSE(e): 3.538e-05, MSE(pi1): 4.287e-03, MSE(pi2): 4.086e-05, MSE(pi3): 8.954e-04\n",
      "Epoch 99300, Train loss: 4.858e+02, Test loss: 2.956e+04, MSE(e): 3.508e-05, MSE(pi1): 4.289e-03, MSE(pi2): 4.072e-05, MSE(pi3): 9.206e-04\n",
      "Epoch 99400, Train loss: 4.826e+02, Test loss: 2.952e+04, MSE(e): 3.507e-05, MSE(pi1): 4.171e-03, MSE(pi2): 4.068e-05, MSE(pi3): 9.020e-04\n",
      "Epoch 99500, Train loss: 4.891e+02, Test loss: 2.976e+04, MSE(e): 3.570e-05, MSE(pi1): 4.043e-03, MSE(pi2): 4.095e-05, MSE(pi3): 9.159e-04\n",
      "Epoch 99600, Train loss: 4.817e+02, Test loss: 2.951e+04, MSE(e): 3.498e-05, MSE(pi1): 4.191e-03, MSE(pi2): 4.060e-05, MSE(pi3): 8.996e-04\n",
      "Epoch 99700, Train loss: 4.998e+02, Test loss: 2.956e+04, MSE(e): 3.678e-05, MSE(pi1): 4.111e-03, MSE(pi2): 4.141e-05, MSE(pi3): 9.084e-04\n",
      "Epoch 99800, Train loss: 4.841e+02, Test loss: 2.949e+04, MSE(e): 3.493e-05, MSE(pi1): 4.480e-03, MSE(pi2): 4.053e-05, MSE(pi3): 8.998e-04\n",
      "Epoch 99900, Train loss: 5.086e+02, Test loss: 2.987e+04, MSE(e): 3.737e-05, MSE(pi1): 4.385e-03, MSE(pi2): 4.157e-05, MSE(pi3): 9.109e-04\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 18000\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "second_lr = 1e-4\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
