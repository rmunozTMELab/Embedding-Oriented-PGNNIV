{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear/model_autoencoder_AE\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear/model_autoencoder_NN\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/non_linear/non_linear_1000.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/non_linear')\n",
    "MODEL_RESULTS_AE_PATH = os.path.join(ROOT_PATH, r'results/non_linear/model_autoencoder_AE')\n",
    "MODEL_RESULTS_PGNNIV_PATH = os.path.join(ROOT_PATH, r'results/non_linear/model_autoencoder_NN')\n",
    "\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_AE_PATH)\n",
    "create_folder(MODEL_RESULTS_PGNNIV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear/non_linear_1000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 800\n",
      "Validation dataset length: 200\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length for the autoencoder: 400\n",
      "Dataset length for the PGNNIV: 400\n"
     ]
    }
   ],
   "source": [
    "N_data_AE = len(X_train)//2\n",
    "N_data_NN = len(X_train) - len(X_train)//2\n",
    "prop_data_NN = 1 - N_data_AE/(N_data_NN + N_data_AE)\n",
    "\n",
    "print(\"Dataset length for the autoencoder:\", N_data_AE)\n",
    "print(\"Dataset length for the PGNNIV:\", N_data_NN)\n",
    "\n",
    "X_AE, X_NN, y_AE, y_NN, K_AE, K_NN, f_AE, f_NN = train_test_split(X_train, y_train, K_train, f_train, test_size=prop_data_NN, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos para el autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_AE, y_test_AE = train_test_split(y_AE, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train_AE = TensOps(y_train_AE.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test_AE = TensOps(y_test_AE.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos para la PGNNIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_NN, X_test_NN, y_train_NN, y_test_NN, K_train_NN, K_test_NN, f_train_NN, f_test_NN = train_test_split(X_NN, y_NN, K_NN, f_NN, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_NN = X_train_NN.to(DEVICE)\n",
    "X_test_NN = X_test_NN.to(DEVICE)\n",
    "\n",
    "y_train_NN = TensOps(y_train_NN.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test_NN = TensOps(y_test_NN.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train_NN = TensOps(K_train_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test_NN = TensOps(K_test_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train_NN = TensOps(f_train_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test_NN = TensOps(f_test_NN.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Autoencoder\n",
    "from trainers.train import train_autoencoder_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_input_shape = y_train_AE.values[0].shape\n",
    "latent_space_dim = [15, 10, 3, 10, 15]\n",
    "autoencoder_output_shape = y_train_AE.values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = y_train_AE.values\n",
    "y_train = y_train_AE\n",
    "\n",
    "X_test = y_test_AE.values\n",
    "y_test = y_test_AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 5.316e+01, Test loss: 4.328e+01\n",
      "Epoch 100, Train loss: 5.224e-01, Test loss: 5.029e-01\n",
      "Epoch 200, Train loss: 4.676e-01, Test loss: 5.330e-01\n",
      "Epoch 300, Train loss: 4.573e-01, Test loss: 4.865e-01\n",
      "Epoch 400, Train loss: 4.501e-01, Test loss: 4.735e-01\n",
      "Epoch 500, Train loss: 4.443e-01, Test loss: 4.681e-01\n",
      "Epoch 600, Train loss: 4.475e-01, Test loss: 4.629e-01\n",
      "Epoch 700, Train loss: 4.427e-01, Test loss: 4.597e-01\n",
      "Epoch 800, Train loss: 4.459e-01, Test loss: 4.713e-01\n",
      "Epoch 900, Train loss: 4.469e-01, Test loss: 4.594e-01\n",
      "Epoch 1000, Train loss: 4.502e-01, Test loss: 4.634e-01\n",
      "Epoch 1100, Train loss: 4.549e-01, Test loss: 4.643e-01\n",
      "Epoch 1200, Train loss: 4.556e-01, Test loss: 4.628e-01\n",
      "Epoch 1300, Train loss: 4.590e-01, Test loss: 4.663e-01\n",
      "Epoch 1400, Train loss: 4.487e-01, Test loss: 4.631e-01\n",
      "Epoch 1500, Train loss: 4.463e-01, Test loss: 4.684e-01\n",
      "Epoch 1600, Train loss: 4.475e-01, Test loss: 4.638e-01\n",
      "Epoch 1700, Train loss: 4.462e-01, Test loss: 4.617e-01\n",
      "Epoch 1800, Train loss: 2.278e-01, Test loss: 2.659e-01\n",
      "Epoch 1900, Train loss: 2.008e-01, Test loss: 2.676e-01\n",
      "Epoch 2000, Train loss: 2.013e-01, Test loss: 2.443e-01\n",
      "Epoch 2100, Train loss: 1.921e-01, Test loss: 2.216e-01\n",
      "Epoch 2200, Train loss: 1.930e-01, Test loss: 2.207e-01\n",
      "Epoch 2300, Train loss: 1.909e-01, Test loss: 2.195e-01\n",
      "Epoch 2400, Train loss: 2.514e-01, Test loss: 2.828e-01\n",
      "Epoch 2500, Train loss: 1.910e-01, Test loss: 2.198e-01\n",
      "Epoch 2600, Train loss: 1.919e-01, Test loss: 2.206e-01\n",
      "Epoch 2700, Train loss: 1.916e-01, Test loss: 2.178e-01\n",
      "Epoch 2800, Train loss: 2.594e-01, Test loss: 2.946e-01\n",
      "Epoch 2900, Train loss: 1.864e-01, Test loss: 2.200e-01\n",
      "Epoch 3000, Train loss: 3.930e-02, Test loss: 3.806e-02\n",
      "Epoch 3100, Train loss: 1.483e-02, Test loss: 9.827e-03\n",
      "Epoch 3200, Train loss: 6.844e-03, Test loss: 5.458e-03\n",
      "Epoch 3300, Train loss: 2.138e-02, Test loss: 1.978e-02\n",
      "Epoch 3400, Train loss: 6.459e-03, Test loss: 6.221e-03\n",
      "Epoch 3500, Train loss: 8.700e-03, Test loss: 6.434e-03\n",
      "Epoch 3600, Train loss: 1.403e-02, Test loss: 7.074e-02\n",
      "Epoch 3700, Train loss: 3.515e-03, Test loss: 4.345e-03\n",
      "Epoch 3800, Train loss: 3.617e-03, Test loss: 3.679e-03\n",
      "Epoch 3900, Train loss: 7.968e-03, Test loss: 7.771e-03\n",
      "Epoch 4000, Train loss: 3.415e-03, Test loss: 4.401e-03\n",
      "Epoch 4100, Train loss: 1.375e-02, Test loss: 3.978e-02\n",
      "Epoch 4200, Train loss: 6.072e-03, Test loss: 5.838e-03\n",
      "Epoch 4300, Train loss: 4.224e-03, Test loss: 5.423e-03\n",
      "Epoch 4400, Train loss: 1.396e-02, Test loss: 6.718e-03\n",
      "Epoch 4500, Train loss: 8.120e-03, Test loss: 1.119e-02\n",
      "Epoch 4600, Train loss: 2.742e-03, Test loss: 3.368e-03\n",
      "Epoch 4700, Train loss: 4.972e-03, Test loss: 3.545e-03\n",
      "Epoch 4800, Train loss: 6.951e-03, Test loss: 5.320e-03\n",
      "Epoch 4900, Train loss: 2.544e-02, Test loss: 1.143e-02\n",
      "Epoch 5000, Train loss: 4.246e-03, Test loss: 3.142e-03\n",
      "Epoch 5100, Train loss: 3.207e-03, Test loss: 5.781e-03\n",
      "Epoch 5200, Train loss: 3.745e-03, Test loss: 4.902e-03\n",
      "Epoch 5300, Train loss: 1.451e-02, Test loss: 3.036e-02\n",
      "Epoch 5400, Train loss: 2.347e-03, Test loss: 4.678e-03\n",
      "Epoch 5500, Train loss: 3.255e-03, Test loss: 7.720e-03\n",
      "Epoch 5600, Train loss: 2.967e-03, Test loss: 2.555e-03\n",
      "Epoch 5700, Train loss: 4.121e-03, Test loss: 1.030e-02\n",
      "Epoch 5800, Train loss: 1.387e-03, Test loss: 1.901e-03\n",
      "Epoch 5900, Train loss: 2.447e-03, Test loss: 1.768e-03\n",
      "Epoch 6000, Train loss: 4.960e-03, Test loss: 2.011e-03\n",
      "Epoch 6100, Train loss: 4.943e-03, Test loss: 2.744e-03\n",
      "Epoch 6200, Train loss: 5.063e-03, Test loss: 2.662e-03\n",
      "Epoch 6300, Train loss: 3.811e-03, Test loss: 2.166e-03\n",
      "Epoch 6400, Train loss: 1.194e-03, Test loss: 1.273e-03\n",
      "Epoch 6500, Train loss: 1.671e-03, Test loss: 1.425e-03\n",
      "Epoch 6600, Train loss: 1.262e-03, Test loss: 2.088e-03\n",
      "Epoch 6700, Train loss: 2.885e-02, Test loss: 1.344e-02\n",
      "Epoch 6800, Train loss: 1.458e-03, Test loss: 4.151e-03\n",
      "Epoch 6900, Train loss: 2.451e-03, Test loss: 1.739e-03\n",
      "Epoch 7000, Train loss: 2.829e-03, Test loss: 3.952e-03\n",
      "Epoch 7100, Train loss: 2.053e-03, Test loss: 5.752e-03\n",
      "Epoch 7200, Train loss: 7.802e-03, Test loss: 1.187e-02\n",
      "Epoch 7300, Train loss: 2.755e-03, Test loss: 1.756e-03\n",
      "Epoch 7400, Train loss: 2.257e-03, Test loss: 3.365e-03\n",
      "Epoch 7500, Train loss: 1.644e-02, Test loss: 1.863e-02\n",
      "Epoch 7600, Train loss: 1.951e-03, Test loss: 1.836e-03\n",
      "Epoch 7700, Train loss: 2.029e-03, Test loss: 2.188e-03\n",
      "Epoch 7800, Train loss: 1.235e-02, Test loss: 5.336e-03\n",
      "Epoch 7900, Train loss: 1.309e-02, Test loss: 5.365e-03\n",
      "Epoch 8000, Train loss: 2.816e-03, Test loss: 6.173e-03\n",
      "Epoch 8100, Train loss: 6.604e-03, Test loss: 2.941e-03\n",
      "Epoch 8200, Train loss: 2.590e-03, Test loss: 5.089e-03\n",
      "Epoch 8300, Train loss: 7.731e-03, Test loss: 1.290e-02\n",
      "Epoch 8400, Train loss: 1.400e-03, Test loss: 2.424e-03\n",
      "Epoch 8500, Train loss: 1.847e-03, Test loss: 3.275e-03\n",
      "Epoch 8600, Train loss: 7.348e-03, Test loss: 1.159e-02\n",
      "Epoch 8700, Train loss: 3.769e-03, Test loss: 1.013e-02\n",
      "Epoch 8800, Train loss: 5.398e-03, Test loss: 2.445e-03\n",
      "Epoch 8900, Train loss: 5.343e-03, Test loss: 3.523e-03\n",
      "Epoch 9000, Train loss: 2.807e-03, Test loss: 5.210e-03\n",
      "Epoch 9100, Train loss: 2.243e-03, Test loss: 2.813e-03\n",
      "Epoch 9200, Train loss: 9.340e-03, Test loss: 3.284e-03\n",
      "Epoch 9300, Train loss: 5.756e-03, Test loss: 7.399e-03\n",
      "Epoch 9400, Train loss: 7.408e-03, Test loss: 4.683e-03\n",
      "Epoch 9500, Train loss: 9.433e-03, Test loss: 1.171e-02\n",
      "Epoch 9600, Train loss: 2.695e-03, Test loss: 5.387e-03\n",
      "Epoch 9700, Train loss: 4.760e-03, Test loss: 2.019e-03\n",
      "Epoch 9800, Train loss: 2.790e-02, Test loss: 1.792e-02\n",
      "Epoch 9900, Train loss: 4.044e-03, Test loss: 2.335e-03\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder(autoencoder_input_shape, latent_space_dim, autoencoder_output_shape).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-2)\n",
    "\n",
    "start_epoch = 0\n",
    "n_epochs = 10000\n",
    "batch_size = 64\n",
    "n_checkpoint = 10\n",
    "new_lr = None\n",
    "\n",
    "train_autoencoder_loop(autoencoder, optimizer, X_train, y_train, X_test, y_test,  \n",
    "                       n_checkpoint, start_epoch, n_epochs, batch_size, MODEL_RESULTS_AE_PATH, DEVICE, new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 9000.\n",
      "Epoch 9000, Train loss: 2.644e-03, Test loss: 2.650e-03\n",
      "Epoch 9100, Train loss: 5.754e-04, Test loss: 1.011e-03\n",
      "Epoch 9200, Train loss: 5.651e-04, Test loss: 9.925e-04\n",
      "Epoch 9300, Train loss: 5.541e-04, Test loss: 9.728e-04\n",
      "Epoch 9400, Train loss: 5.429e-04, Test loss: 9.531e-04\n",
      "Epoch 9500, Train loss: 5.321e-04, Test loss: 9.347e-04\n",
      "Epoch 9600, Train loss: 5.222e-04, Test loss: 9.182e-04\n",
      "Epoch 9700, Train loss: 5.133e-04, Test loss: 9.039e-04\n",
      "Epoch 9800, Train loss: 5.055e-04, Test loss: 8.916e-04\n",
      "Epoch 9900, Train loss: 4.984e-04, Test loss: 8.809e-04\n",
      "Epoch 10000, Train loss: 4.916e-04, Test loss: 8.713e-04\n",
      "Epoch 10100, Train loss: 4.846e-04, Test loss: 8.623e-04\n",
      "Epoch 10200, Train loss: 4.771e-04, Test loss: 8.533e-04\n",
      "Epoch 10300, Train loss: 4.689e-04, Test loss: 8.440e-04\n",
      "Epoch 10400, Train loss: 4.601e-04, Test loss: 8.342e-04\n",
      "Epoch 10500, Train loss: 4.510e-04, Test loss: 8.241e-04\n",
      "Epoch 10600, Train loss: 4.420e-04, Test loss: 8.136e-04\n",
      "Epoch 10700, Train loss: 4.331e-04, Test loss: 8.030e-04\n",
      "Epoch 10800, Train loss: 4.246e-04, Test loss: 7.924e-04\n",
      "Epoch 10900, Train loss: 4.165e-04, Test loss: 7.819e-04\n",
      "Epoch 11000, Train loss: 4.087e-04, Test loss: 7.715e-04\n",
      "Epoch 11100, Train loss: 4.012e-04, Test loss: 7.614e-04\n",
      "Epoch 11200, Train loss: 3.941e-04, Test loss: 7.515e-04\n",
      "Epoch 11300, Train loss: 3.874e-04, Test loss: 7.419e-04\n",
      "Epoch 11400, Train loss: 3.809e-04, Test loss: 7.325e-04\n",
      "Epoch 11500, Train loss: 3.747e-04, Test loss: 7.234e-04\n",
      "Epoch 11600, Train loss: 3.687e-04, Test loss: 7.145e-04\n",
      "Epoch 11700, Train loss: 3.630e-04, Test loss: 7.058e-04\n",
      "Epoch 11800, Train loss: 3.575e-04, Test loss: 6.974e-04\n",
      "Epoch 11900, Train loss: 3.522e-04, Test loss: 6.892e-04\n",
      "Epoch 12000, Train loss: 3.470e-04, Test loss: 6.812e-04\n",
      "Epoch 12100, Train loss: 3.420e-04, Test loss: 6.734e-04\n",
      "Epoch 12200, Train loss: 3.372e-04, Test loss: 6.658e-04\n",
      "Epoch 12300, Train loss: 3.326e-04, Test loss: 6.584e-04\n",
      "Epoch 12400, Train loss: 3.281e-04, Test loss: 6.511e-04\n",
      "Epoch 12500, Train loss: 3.237e-04, Test loss: 6.440e-04\n",
      "Epoch 12600, Train loss: 3.194e-04, Test loss: 6.371e-04\n",
      "Epoch 12700, Train loss: 3.153e-04, Test loss: 6.304e-04\n",
      "Epoch 12800, Train loss: 3.113e-04, Test loss: 6.238e-04\n",
      "Epoch 12900, Train loss: 3.074e-04, Test loss: 6.173e-04\n",
      "Epoch 13000, Train loss: 3.036e-04, Test loss: 6.109e-04\n",
      "Epoch 13100, Train loss: 2.998e-04, Test loss: 6.047e-04\n",
      "Epoch 13200, Train loss: 2.962e-04, Test loss: 5.987e-04\n",
      "Epoch 13300, Train loss: 2.927e-04, Test loss: 5.927e-04\n",
      "Epoch 13400, Train loss: 2.893e-04, Test loss: 5.869e-04\n",
      "Epoch 13500, Train loss: 2.859e-04, Test loss: 5.812e-04\n",
      "Epoch 13600, Train loss: 2.827e-04, Test loss: 5.756e-04\n",
      "Epoch 13700, Train loss: 2.795e-04, Test loss: 5.701e-04\n",
      "Epoch 13800, Train loss: 2.764e-04, Test loss: 5.647e-04\n",
      "Epoch 13900, Train loss: 2.734e-04, Test loss: 5.595e-04\n",
      "Epoch 14000, Train loss: 2.704e-04, Test loss: 5.543e-04\n",
      "Epoch 14100, Train loss: 2.676e-04, Test loss: 5.492e-04\n",
      "Epoch 14200, Train loss: 2.647e-04, Test loss: 5.442e-04\n",
      "Epoch 14300, Train loss: 2.620e-04, Test loss: 5.393e-04\n",
      "Epoch 14400, Train loss: 2.593e-04, Test loss: 5.345e-04\n",
      "Epoch 14500, Train loss: 2.567e-04, Test loss: 5.298e-04\n",
      "Epoch 14600, Train loss: 2.541e-04, Test loss: 5.251e-04\n",
      "Epoch 14700, Train loss: 2.516e-04, Test loss: 5.206e-04\n",
      "Epoch 14800, Train loss: 2.492e-04, Test loss: 5.161e-04\n",
      "Epoch 14900, Train loss: 2.468e-04, Test loss: 5.117e-04\n",
      "Epoch 15000, Train loss: 2.445e-04, Test loss: 5.073e-04\n",
      "Epoch 15100, Train loss: 2.422e-04, Test loss: 5.031e-04\n",
      "Epoch 15200, Train loss: 2.400e-04, Test loss: 4.989e-04\n",
      "Epoch 15300, Train loss: 2.378e-04, Test loss: 4.948e-04\n",
      "Epoch 15400, Train loss: 2.356e-04, Test loss: 4.907e-04\n",
      "Epoch 15500, Train loss: 2.335e-04, Test loss: 4.867e-04\n",
      "Epoch 15600, Train loss: 2.280e-04, Test loss: 4.501e-04\n",
      "Epoch 15700, Train loss: 2.245e-04, Test loss: 4.333e-04\n",
      "Epoch 15800, Train loss: 2.222e-04, Test loss: 4.266e-04\n",
      "Epoch 15900, Train loss: 2.204e-04, Test loss: 4.210e-04\n",
      "Epoch 16000, Train loss: 2.186e-04, Test loss: 4.158e-04\n",
      "Epoch 16100, Train loss: 2.169e-04, Test loss: 4.110e-04\n",
      "Epoch 16200, Train loss: 2.152e-04, Test loss: 4.065e-04\n",
      "Epoch 16300, Train loss: 2.136e-04, Test loss: 4.023e-04\n",
      "Epoch 16400, Train loss: 2.120e-04, Test loss: 3.984e-04\n",
      "Epoch 16500, Train loss: 2.104e-04, Test loss: 3.946e-04\n",
      "Epoch 16600, Train loss: 2.088e-04, Test loss: 3.910e-04\n",
      "Epoch 16700, Train loss: 2.072e-04, Test loss: 3.876e-04\n",
      "Epoch 16800, Train loss: 2.057e-04, Test loss: 3.843e-04\n",
      "Epoch 16900, Train loss: 2.042e-04, Test loss: 3.811e-04\n",
      "Epoch 17000, Train loss: 2.027e-04, Test loss: 3.780e-04\n",
      "Epoch 17100, Train loss: 2.012e-04, Test loss: 3.750e-04\n",
      "Epoch 17200, Train loss: 1.998e-04, Test loss: 3.721e-04\n",
      "Epoch 17300, Train loss: 1.984e-04, Test loss: 3.693e-04\n",
      "Epoch 17400, Train loss: 1.970e-04, Test loss: 3.666e-04\n",
      "Epoch 17500, Train loss: 1.956e-04, Test loss: 3.639e-04\n",
      "Epoch 17600, Train loss: 1.943e-04, Test loss: 3.613e-04\n",
      "Epoch 17700, Train loss: 1.930e-04, Test loss: 3.588e-04\n",
      "Epoch 17800, Train loss: 1.917e-04, Test loss: 3.563e-04\n",
      "Epoch 17900, Train loss: 1.904e-04, Test loss: 3.539e-04\n",
      "Epoch 18000, Train loss: 1.891e-04, Test loss: 3.515e-04\n",
      "Epoch 18100, Train loss: 1.880e-04, Test loss: 3.492e-04\n",
      "Epoch 18200, Train loss: 1.867e-04, Test loss: 3.470e-04\n",
      "Epoch 18300, Train loss: 1.856e-04, Test loss: 3.447e-04\n",
      "Epoch 18400, Train loss: 1.844e-04, Test loss: 3.426e-04\n",
      "Epoch 18500, Train loss: 1.833e-04, Test loss: 3.403e-04\n",
      "Epoch 18600, Train loss: 1.822e-04, Test loss: 3.386e-04\n",
      "Epoch 18700, Train loss: 1.810e-04, Test loss: 3.359e-04\n",
      "Epoch 18800, Train loss: 1.804e-04, Test loss: 3.346e-04\n",
      "Epoch 18900, Train loss: 1.788e-04, Test loss: 3.317e-04\n",
      "Epoch 19000, Train loss: 1.785e-04, Test loss: 3.305e-04\n",
      "Epoch 19100, Train loss: 1.769e-04, Test loss: 3.278e-04\n",
      "Epoch 19200, Train loss: 1.764e-04, Test loss: 3.265e-04\n",
      "Epoch 19300, Train loss: 1.750e-04, Test loss: 3.241e-04\n",
      "Epoch 19400, Train loss: 1.744e-04, Test loss: 3.228e-04\n",
      "Epoch 19500, Train loss: 1.731e-04, Test loss: 3.205e-04\n",
      "Epoch 19600, Train loss: 1.724e-04, Test loss: 3.191e-04\n",
      "Epoch 19700, Train loss: 1.713e-04, Test loss: 3.172e-04\n",
      "Epoch 19800, Train loss: 1.704e-04, Test loss: 3.156e-04\n",
      "Epoch 19900, Train loss: 1.693e-04, Test loss: 3.143e-04\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 9000\n",
    "n_epochs = 20000\n",
    "batch_size = 64\n",
    "n_checkpoint = 10\n",
    "new_lr = 1e-4\n",
    "\n",
    "train_autoencoder_loop(autoencoder, optimizer, X_train, y_train, X_test, y_test,  \n",
    "                       n_checkpoint, start_epoch, n_epochs, batch_size, MODEL_RESULTS_AE_PATH, DEVICE, new_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGNNIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from models.ae_nonlinear_model import AutoencoderNonlinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive network architecture\n",
    "input_shape = X_train_NN[0].shape\n",
    "predictive_layers = [15, 10, 3]\n",
    "predictive_output = y_train_NN.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train_NN)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train_NN)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1_layer.weight: requires_grad=False\n",
      "hidden1_layer.bias: requires_grad=False\n",
      "hidden2_layer.weight: requires_grad=False\n",
      "hidden2_layer.bias: requires_grad=False\n",
      "output_layer.weight: requires_grad=False\n",
      "output_layer.bias: requires_grad=False\n"
     ]
    }
   ],
   "source": [
    "pretrained_decoder = autoencoder.decoder\n",
    "\n",
    "for param in pretrained_decoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in pretrained_decoder.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 1.533e+08, Test loss: 1.442e+08, MSE(e): 7.498e+00, MSE(pi1): 7.584e+03, MSE(pi2): 4.479e+00, MSE(pi3): 2.480e+01\n",
      "Epoch 100, Train loss: 2.688e+06, Test loss: 3.126e+06, MSE(e): 2.668e-01, MSE(pi1): 5.695e-01, MSE(pi2): 1.865e-01, MSE(pi3): 1.351e-01\n",
      "Epoch 200, Train loss: 2.257e+05, Test loss: 5.338e+05, MSE(e): 2.147e-02, MSE(pi1): 2.141e-01, MSE(pi2): 1.313e-02, MSE(pi3): 8.846e-02\n",
      "Epoch 300, Train loss: 1.203e+05, Test loss: 3.343e+05, MSE(e): 1.108e-02, MSE(pi1): 2.000e-01, MSE(pi2): 6.981e-03, MSE(pi3): 7.525e-02\n",
      "Epoch 400, Train loss: 9.473e+04, Test loss: 2.508e+05, MSE(e): 8.648e-03, MSE(pi1): 1.870e-01, MSE(pi2): 5.323e-03, MSE(pi3): 6.373e-02\n",
      "Epoch 500, Train loss: 8.483e+04, Test loss: 1.927e+05, MSE(e): 7.759e-03, MSE(pi1): 1.851e-01, MSE(pi2): 4.582e-03, MSE(pi3): 5.381e-02\n",
      "Epoch 600, Train loss: 6.673e+04, Test loss: 1.714e+05, MSE(e): 6.069e-03, MSE(pi1): 1.617e-01, MSE(pi2): 3.392e-03, MSE(pi3): 4.413e-02\n",
      "Epoch 700, Train loss: 6.040e+04, Test loss: 1.626e+05, MSE(e): 5.538e-03, MSE(pi1): 1.472e-01, MSE(pi2): 3.014e-03, MSE(pi3): 3.549e-02\n",
      "Epoch 800, Train loss: 2.579e+04, Test loss: 1.111e+05, MSE(e): 2.036e-03, MSE(pi1): 2.532e-01, MSE(pi2): 1.451e-03, MSE(pi3): 2.895e-02\n",
      "Epoch 900, Train loss: 4.142e+04, Test loss: 1.038e+05, MSE(e): 3.437e-03, MSE(pi1): 4.335e-01, MSE(pi2): 2.033e-03, MSE(pi3): 2.710e-02\n",
      "Epoch 1000, Train loss: 3.678e+04, Test loss: 8.942e+04, MSE(e): 3.204e-03, MSE(pi1): 2.387e-01, MSE(pi2): 1.872e-03, MSE(pi3): 2.347e-02\n",
      "Epoch 1100, Train loss: 3.457e+04, Test loss: 8.577e+04, MSE(e): 2.983e-03, MSE(pi1): 2.561e-01, MSE(pi2): 1.767e-03, MSE(pi3): 2.176e-02\n",
      "Epoch 1200, Train loss: 5.618e+04, Test loss: 7.851e+04, MSE(e): 5.052e-03, MSE(pi1): 3.566e-01, MSE(pi2): 2.649e-03, MSE(pi3): 2.089e-02\n",
      "Epoch 1300, Train loss: 2.769e+04, Test loss: 9.106e+04, MSE(e): 2.424e-03, MSE(pi1): 1.509e-01, MSE(pi2): 1.392e-03, MSE(pi3): 1.932e-02\n",
      "Epoch 1400, Train loss: 2.456e+04, Test loss: 6.801e+04, MSE(e): 2.090e-03, MSE(pi1): 1.772e-01, MSE(pi2): 1.164e-03, MSE(pi3): 1.888e-02\n",
      "Epoch 1500, Train loss: 1.133e+04, Test loss: 6.543e+04, MSE(e): 8.032e-04, MSE(pi1): 1.380e-01, MSE(pi2): 6.129e-04, MSE(pi3): 1.919e-02\n",
      "Epoch 1600, Train loss: 2.888e+04, Test loss: 8.451e+04, MSE(e): 2.393e-03, MSE(pi1): 3.015e-01, MSE(pi2): 1.479e-03, MSE(pi3): 1.933e-02\n",
      "Epoch 1700, Train loss: 9.281e+03, Test loss: 5.875e+04, MSE(e): 6.219e-04, MSE(pi1): 1.205e-01, MSE(pi2): 4.718e-04, MSE(pi3): 1.857e-02\n",
      "Epoch 1800, Train loss: 1.065e+04, Test loss: 5.836e+04, MSE(e): 7.215e-04, MSE(pi1): 1.568e-01, MSE(pi2): 5.362e-04, MSE(pi3): 1.868e-02\n",
      "Epoch 1900, Train loss: 2.047e+04, Test loss: 6.035e+04, MSE(e): 1.707e-03, MSE(pi1): 1.469e-01, MSE(pi2): 1.151e-03, MSE(pi3): 1.936e-02\n",
      "Epoch 2000, Train loss: 1.037e+05, Test loss: 7.137e+04, MSE(e): 9.951e-03, MSE(pi1): 2.399e-01, MSE(pi2): 4.352e-03, MSE(pi3): 1.761e-02\n",
      "Epoch 2100, Train loss: 9.192e+03, Test loss: 5.095e+04, MSE(e): 6.229e-04, MSE(pi1): 1.214e-01, MSE(pi2): 4.439e-04, MSE(pi3): 1.748e-02\n",
      "Epoch 2200, Train loss: 3.080e+04, Test loss: 5.206e+04, MSE(e): 2.787e-03, MSE(pi1): 1.223e-01, MSE(pi2): 1.289e-03, MSE(pi3): 1.707e-02\n",
      "Epoch 2300, Train loss: 2.961e+04, Test loss: 5.122e+04, MSE(e): 2.687e-03, MSE(pi1): 1.074e-01, MSE(pi2): 1.305e-03, MSE(pi3): 1.666e-02\n",
      "Epoch 2400, Train loss: 3.116e+04, Test loss: 6.555e+04, MSE(e): 2.849e-03, MSE(pi1): 9.952e-02, MSE(pi2): 1.389e-03, MSE(pi3): 1.674e-02\n",
      "Epoch 2500, Train loss: 9.853e+03, Test loss: 5.436e+04, MSE(e): 7.167e-04, MSE(pi1): 1.186e-01, MSE(pi2): 5.004e-04, MSE(pi3): 1.499e-02\n",
      "Epoch 2600, Train loss: 7.019e+03, Test loss: 4.144e+04, MSE(e): 4.582e-04, MSE(pi1): 9.407e-02, MSE(pi2): 3.484e-04, MSE(pi3): 1.496e-02\n",
      "Epoch 2700, Train loss: 9.249e+03, Test loss: 4.026e+04, MSE(e): 6.936e-04, MSE(pi1): 9.199e-02, MSE(pi2): 4.686e-04, MSE(pi3): 1.393e-02\n",
      "Epoch 2800, Train loss: 7.046e+03, Test loss: 3.804e+04, MSE(e): 4.887e-04, MSE(pi1): 8.935e-02, MSE(pi2): 3.536e-04, MSE(pi3): 1.265e-02\n",
      "Epoch 2900, Train loss: 5.545e+03, Test loss: 3.739e+04, MSE(e): 4.035e-04, MSE(pi1): 5.784e-02, MSE(pi2): 3.212e-04, MSE(pi3): 9.316e-03\n",
      "Epoch 3000, Train loss: 8.328e+03, Test loss: 3.508e+04, MSE(e): 7.197e-04, MSE(pi1): 4.832e-02, MSE(pi2): 4.386e-04, MSE(pi3): 6.470e-03\n",
      "Epoch 3100, Train loss: 7.844e+03, Test loss: 4.458e+04, MSE(e): 6.900e-04, MSE(pi1): 5.123e-02, MSE(pi2): 4.475e-04, MSE(pi3): 4.308e-03\n",
      "Epoch 3200, Train loss: 3.360e+04, Test loss: 4.662e+04, MSE(e): 3.289e-03, MSE(pi1): 3.574e-02, MSE(pi2): 1.540e-03, MSE(pi3): 3.542e-03\n",
      "Epoch 3300, Train loss: 1.184e+04, Test loss: 3.719e+04, MSE(e): 1.134e-03, MSE(pi1): 2.458e-02, MSE(pi2): 6.701e-04, MSE(pi3): 2.518e-03\n",
      "Epoch 3400, Train loss: 7.844e+03, Test loss: 3.633e+04, MSE(e): 7.402e-04, MSE(pi1): 2.393e-02, MSE(pi2): 5.610e-04, MSE(pi3): 2.020e-03\n",
      "Epoch 3500, Train loss: 3.371e+04, Test loss: 5.416e+04, MSE(e): 3.066e-03, MSE(pi1): 1.057e-01, MSE(pi2): 1.440e-03, MSE(pi3): 1.987e-02\n",
      "Epoch 3600, Train loss: 1.405e+04, Test loss: 3.725e+04, MSE(e): 1.330e-03, MSE(pi1): 3.325e-02, MSE(pi2): 7.498e-04, MSE(pi3): 4.170e-03\n",
      "Epoch 3700, Train loss: 1.128e+04, Test loss: 3.632e+04, MSE(e): 1.080e-03, MSE(pi1): 2.238e-02, MSE(pi2): 6.881e-04, MSE(pi3): 2.613e-03\n",
      "Epoch 3800, Train loss: 5.906e+03, Test loss: 3.592e+04, MSE(e): 5.557e-04, MSE(pi1): 1.472e-02, MSE(pi2): 4.434e-04, MSE(pi3): 2.010e-03\n",
      "Epoch 3900, Train loss: 7.490e+03, Test loss: 3.129e+04, MSE(e): 7.168e-04, MSE(pi1): 1.392e-02, MSE(pi2): 5.287e-04, MSE(pi3): 1.822e-03\n",
      "Epoch 4000, Train loss: 9.546e+03, Test loss: 3.127e+04, MSE(e): 9.226e-04, MSE(pi1): 1.865e-02, MSE(pi2): 5.749e-04, MSE(pi3): 1.330e-03\n",
      "Epoch 4100, Train loss: 1.339e+04, Test loss: 3.337e+04, MSE(e): 1.308e-03, MSE(pi1): 1.624e-02, MSE(pi2): 6.895e-04, MSE(pi3): 1.519e-03\n",
      "Epoch 4200, Train loss: 2.329e+04, Test loss: 3.608e+04, MSE(e): 2.291e-03, MSE(pi1): 2.313e-02, MSE(pi2): 1.078e-03, MSE(pi3): 1.434e-03\n",
      "Epoch 4300, Train loss: 1.889e+04, Test loss: 4.330e+04, MSE(e): 1.852e-03, MSE(pi1): 2.822e-02, MSE(pi2): 9.483e-04, MSE(pi3): 8.254e-04\n",
      "Epoch 4400, Train loss: 3.759e+03, Test loss: 2.979e+04, MSE(e): 3.513e-04, MSE(pi1): 1.481e-02, MSE(pi2): 3.061e-04, MSE(pi3): 9.757e-04\n",
      "Epoch 4500, Train loss: 1.726e+04, Test loss: 3.335e+04, MSE(e): 1.700e-03, MSE(pi1): 1.786e-02, MSE(pi2): 8.636e-04, MSE(pi3): 7.873e-04\n",
      "Epoch 4600, Train loss: 4.914e+04, Test loss: 6.166e+04, MSE(e): 4.888e-03, MSE(pi1): 1.595e-02, MSE(pi2): 2.212e-03, MSE(pi3): 9.795e-04\n",
      "Epoch 4700, Train loss: 2.929e+04, Test loss: 4.082e+04, MSE(e): 2.902e-03, MSE(pi1): 1.457e-02, MSE(pi2): 1.332e-03, MSE(pi3): 1.178e-03\n",
      "Epoch 4800, Train loss: 8.531e+03, Test loss: 3.155e+04, MSE(e): 8.320e-04, MSE(pi1): 9.703e-03, MSE(pi2): 4.895e-04, MSE(pi3): 1.139e-03\n",
      "Epoch 4900, Train loss: 6.666e+03, Test loss: 3.111e+04, MSE(e): 6.447e-04, MSE(pi1): 1.003e-02, MSE(pi2): 4.146e-04, MSE(pi3): 1.185e-03\n",
      "Epoch 5000, Train loss: 7.495e+04, Test loss: 6.728e+04, MSE(e): 7.470e-03, MSE(pi1): 1.492e-02, MSE(pi2): 3.220e-03, MSE(pi3): 9.561e-04\n",
      "Epoch 5100, Train loss: 5.891e+03, Test loss: 3.296e+04, MSE(e): 5.690e-04, MSE(pi1): 7.689e-03, MSE(pi2): 4.012e-04, MSE(pi3): 1.237e-03\n",
      "Epoch 5200, Train loss: 9.448e+03, Test loss: 3.103e+04, MSE(e): 9.256e-04, MSE(pi1): 7.657e-03, MSE(pi2): 5.585e-04, MSE(pi3): 1.157e-03\n",
      "Epoch 5300, Train loss: 3.771e+03, Test loss: 3.082e+04, MSE(e): 3.552e-04, MSE(pi1): 9.207e-03, MSE(pi2): 3.016e-04, MSE(pi3): 1.270e-03\n",
      "Epoch 5400, Train loss: 6.004e+03, Test loss: 3.263e+04, MSE(e): 5.815e-04, MSE(pi1): 7.377e-03, MSE(pi2): 3.941e-04, MSE(pi3): 1.157e-03\n",
      "Epoch 5500, Train loss: 7.963e+03, Test loss: 4.433e+04, MSE(e): 7.729e-04, MSE(pi1): 7.652e-03, MSE(pi2): 4.820e-04, MSE(pi3): 1.572e-03\n",
      "Epoch 5600, Train loss: 7.673e+03, Test loss: 3.484e+04, MSE(e): 7.334e-04, MSE(pi1): 1.600e-02, MSE(pi2): 4.506e-04, MSE(pi3): 1.783e-03\n",
      "Epoch 5700, Train loss: 7.543e+03, Test loss: 3.856e+04, MSE(e): 7.341e-04, MSE(pi1): 7.366e-03, MSE(pi2): 4.874e-04, MSE(pi3): 1.281e-03\n",
      "Epoch 5800, Train loss: 2.335e+04, Test loss: 3.829e+04, MSE(e): 2.311e-03, MSE(pi1): 1.457e-02, MSE(pi2): 1.155e-03, MSE(pi3): 9.498e-04\n",
      "Epoch 5900, Train loss: 7.730e+03, Test loss: 3.069e+04, MSE(e): 7.498e-04, MSE(pi1): 1.180e-02, MSE(pi2): 4.903e-04, MSE(pi3): 1.137e-03\n",
      "Epoch 6000, Train loss: 5.117e+03, Test loss: 3.165e+04, MSE(e): 4.905e-04, MSE(pi1): 7.617e-03, MSE(pi2): 3.549e-04, MSE(pi3): 1.352e-03\n",
      "Epoch 6100, Train loss: 3.708e+03, Test loss: 3.060e+04, MSE(e): 3.513e-04, MSE(pi1): 7.818e-03, MSE(pi2): 2.827e-04, MSE(pi3): 1.166e-03\n",
      "Epoch 6200, Train loss: 1.389e+04, Test loss: 3.666e+04, MSE(e): 1.366e-03, MSE(pi1): 1.092e-02, MSE(pi2): 7.075e-04, MSE(pi3): 1.183e-03\n",
      "Epoch 6300, Train loss: 4.104e+04, Test loss: 5.077e+04, MSE(e): 4.079e-03, MSE(pi1): 1.105e-02, MSE(pi2): 1.877e-03, MSE(pi3): 1.383e-03\n",
      "Epoch 6400, Train loss: 4.074e+04, Test loss: 5.748e+04, MSE(e): 4.053e-03, MSE(pi1): 7.865e-03, MSE(pi2): 1.936e-03, MSE(pi3): 1.259e-03\n",
      "Epoch 6500, Train loss: 4.642e+03, Test loss: 3.321e+04, MSE(e): 4.444e-04, MSE(pi1): 6.485e-03, MSE(pi2): 3.435e-04, MSE(pi3): 1.321e-03\n",
      "Epoch 6600, Train loss: 8.703e+03, Test loss: 3.685e+04, MSE(e): 8.508e-04, MSE(pi1): 6.593e-03, MSE(pi2): 4.965e-04, MSE(pi3): 1.283e-03\n",
      "Epoch 6700, Train loss: 2.805e+04, Test loss: 4.786e+04, MSE(e): 2.785e-03, MSE(pi1): 8.507e-03, MSE(pi2): 1.364e-03, MSE(pi3): 1.128e-03\n",
      "Epoch 6800, Train loss: 9.994e+03, Test loss: 3.520e+04, MSE(e): 9.773e-04, MSE(pi1): 1.162e-02, MSE(pi2): 6.919e-04, MSE(pi3): 1.035e-03\n",
      "Epoch 6900, Train loss: 5.011e+03, Test loss: 3.119e+04, MSE(e): 4.810e-04, MSE(pi1): 6.524e-03, MSE(pi2): 3.665e-04, MSE(pi3): 1.361e-03\n",
      "Epoch 7000, Train loss: 8.395e+03, Test loss: 3.374e+04, MSE(e): 8.191e-04, MSE(pi1): 7.578e-03, MSE(pi2): 4.970e-04, MSE(pi3): 1.271e-03\n",
      "Epoch 7100, Train loss: 8.777e+03, Test loss: 3.808e+04, MSE(e): 8.524e-04, MSE(pi1): 7.569e-03, MSE(pi2): 6.281e-04, MSE(pi3): 1.758e-03\n",
      "Epoch 7200, Train loss: 6.595e+03, Test loss: 3.674e+04, MSE(e): 6.386e-04, MSE(pi1): 6.132e-03, MSE(pi2): 4.768e-04, MSE(pi3): 1.473e-03\n",
      "Epoch 7300, Train loss: 8.358e+03, Test loss: 3.873e+04, MSE(e): 8.135e-04, MSE(pi1): 1.001e-02, MSE(pi2): 4.890e-04, MSE(pi3): 1.221e-03\n",
      "Epoch 7400, Train loss: 1.176e+04, Test loss: 3.682e+04, MSE(e): 1.155e-03, MSE(pi1): 7.746e-03, MSE(pi2): 6.543e-04, MSE(pi3): 1.289e-03\n",
      "Epoch 7500, Train loss: 1.196e+04, Test loss: 3.497e+04, MSE(e): 1.175e-03, MSE(pi1): 6.409e-03, MSE(pi2): 6.818e-04, MSE(pi3): 1.465e-03\n",
      "Epoch 7600, Train loss: 5.456e+03, Test loss: 3.138e+04, MSE(e): 5.270e-04, MSE(pi1): 6.913e-03, MSE(pi2): 3.631e-04, MSE(pi3): 1.163e-03\n",
      "Epoch 7700, Train loss: 6.211e+03, Test loss: 3.138e+04, MSE(e): 6.024e-04, MSE(pi1): 7.567e-03, MSE(pi2): 4.563e-04, MSE(pi3): 1.113e-03\n",
      "Epoch 7800, Train loss: 6.401e+03, Test loss: 3.166e+04, MSE(e): 6.212e-04, MSE(pi1): 6.767e-03, MSE(pi2): 4.654e-04, MSE(pi3): 1.216e-03\n",
      "Epoch 7900, Train loss: 1.375e+04, Test loss: 3.582e+04, MSE(e): 1.353e-03, MSE(pi1): 6.012e-03, MSE(pi2): 7.582e-04, MSE(pi3): 1.563e-03\n",
      "Epoch 8000, Train loss: 4.281e+03, Test loss: 3.033e+04, MSE(e): 4.103e-04, MSE(pi1): 6.703e-03, MSE(pi2): 3.132e-04, MSE(pi3): 1.104e-03\n",
      "Epoch 8100, Train loss: 9.020e+03, Test loss: 3.206e+04, MSE(e): 8.837e-04, MSE(pi1): 7.536e-03, MSE(pi2): 5.098e-04, MSE(pi3): 1.074e-03\n",
      "Epoch 8200, Train loss: 7.235e+03, Test loss: 3.066e+04, MSE(e): 7.049e-04, MSE(pi1): 5.043e-03, MSE(pi2): 4.648e-04, MSE(pi3): 1.354e-03\n",
      "Epoch 8300, Train loss: 8.519e+03, Test loss: 3.533e+04, MSE(e): 8.339e-04, MSE(pi1): 7.854e-03, MSE(pi2): 5.891e-04, MSE(pi3): 1.012e-03\n",
      "Epoch 8400, Train loss: 3.129e+04, Test loss: 3.981e+04, MSE(e): 3.111e-03, MSE(pi1): 5.269e-03, MSE(pi2): 1.451e-03, MSE(pi3): 1.246e-03\n",
      "Epoch 8500, Train loss: 5.911e+03, Test loss: 3.345e+04, MSE(e): 5.717e-04, MSE(pi1): 6.696e-03, MSE(pi2): 4.241e-04, MSE(pi3): 1.260e-03\n",
      "Epoch 8600, Train loss: 3.883e+04, Test loss: 5.245e+04, MSE(e): 3.863e-03, MSE(pi1): 8.283e-03, MSE(pi2): 1.852e-03, MSE(pi3): 1.099e-03\n",
      "Epoch 8700, Train loss: 8.948e+03, Test loss: 3.298e+04, MSE(e): 8.749e-04, MSE(pi1): 7.187e-03, MSE(pi2): 5.235e-04, MSE(pi3): 1.261e-03\n",
      "Epoch 8800, Train loss: 6.264e+03, Test loss: 3.567e+04, MSE(e): 6.081e-04, MSE(pi1): 6.310e-03, MSE(pi2): 4.041e-04, MSE(pi3): 1.198e-03\n",
      "Epoch 8900, Train loss: 3.100e+04, Test loss: 4.160e+04, MSE(e): 3.082e-03, MSE(pi1): 6.375e-03, MSE(pi2): 1.436e-03, MSE(pi3): 1.234e-03\n",
      "Epoch 9000, Train loss: 1.912e+04, Test loss: 3.365e+04, MSE(e): 1.894e-03, MSE(pi1): 7.095e-03, MSE(pi2): 1.020e-03, MSE(pi3): 1.152e-03\n",
      "Epoch 9100, Train loss: 3.236e+04, Test loss: 4.395e+04, MSE(e): 3.219e-03, MSE(pi1): 5.726e-03, MSE(pi2): 1.492e-03, MSE(pi3): 1.193e-03\n",
      "Epoch 9200, Train loss: 1.205e+04, Test loss: 3.406e+04, MSE(e): 1.187e-03, MSE(pi1): 6.532e-03, MSE(pi2): 6.498e-04, MSE(pi3): 1.147e-03\n",
      "Epoch 9300, Train loss: 6.181e+03, Test loss: 3.047e+04, MSE(e): 5.978e-04, MSE(pi1): 5.446e-03, MSE(pi2): 4.150e-04, MSE(pi3): 1.480e-03\n",
      "Epoch 9400, Train loss: 6.968e+03, Test loss: 3.201e+04, MSE(e): 6.796e-04, MSE(pi1): 4.735e-03, MSE(pi2): 4.452e-04, MSE(pi3): 1.235e-03\n",
      "Epoch 9500, Train loss: 1.175e+04, Test loss: 3.338e+04, MSE(e): 1.155e-03, MSE(pi1): 8.860e-03, MSE(pi2): 7.478e-04, MSE(pi3): 1.104e-03\n",
      "Epoch 9600, Train loss: 1.422e+04, Test loss: 3.780e+04, MSE(e): 1.402e-03, MSE(pi1): 5.093e-03, MSE(pi2): 7.620e-04, MSE(pi3): 1.509e-03\n",
      "Epoch 9700, Train loss: 4.961e+03, Test loss: 3.245e+04, MSE(e): 4.777e-04, MSE(pi1): 4.570e-03, MSE(pi2): 3.750e-04, MSE(pi3): 1.380e-03\n",
      "Epoch 9800, Train loss: 5.452e+03, Test loss: 4.023e+04, MSE(e): 5.271e-04, MSE(pi1): 5.385e-03, MSE(pi2): 4.238e-04, MSE(pi3): 1.272e-03\n",
      "Epoch 9900, Train loss: 5.095e+03, Test loss: 2.972e+04, MSE(e): 4.910e-04, MSE(pi1): 6.245e-03, MSE(pi2): 3.586e-04, MSE(pi3): 1.219e-03\n",
      "\n",
      "Training process finished after 10000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoencoderNonlinearModel(input_shape, predictive_layers, pretrained_decoder, predictive_output, explanatory_input,\n",
    "                                   explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 10000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(model, optimizer, X_train_NN, y_train_NN, f_train_NN, X_test_NN, y_test_NN, f_test_NN,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PGNNIV_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 9000.\n",
      "Epoch 9000, Train loss: 5.889e+03, Test loss: 3.161e+04, MSE(e): 5.716e-04, MSE(pi1): 5.649e-03, MSE(pi2): 3.967e-04, MSE(pi3): 1.154e-03\n",
      "Epoch 9100, Train loss: 2.682e+03, Test loss: 3.013e+04, MSE(e): 2.529e-04, MSE(pi1): 5.262e-03, MSE(pi2): 2.314e-04, MSE(pi3): 1.006e-03\n",
      "Epoch 9200, Train loss: 2.576e+03, Test loss: 2.988e+04, MSE(e): 2.423e-04, MSE(pi1): 5.270e-03, MSE(pi2): 2.258e-04, MSE(pi3): 1.002e-03\n",
      "Epoch 9300, Train loss: 2.525e+03, Test loss: 2.958e+04, MSE(e): 2.372e-04, MSE(pi1): 5.276e-03, MSE(pi2): 2.224e-04, MSE(pi3): 9.994e-04\n",
      "Epoch 9400, Train loss: 2.496e+03, Test loss: 2.936e+04, MSE(e): 2.343e-04, MSE(pi1): 5.276e-03, MSE(pi2): 2.201e-04, MSE(pi3): 9.978e-04\n",
      "Epoch 9500, Train loss: 2.478e+03, Test loss: 2.923e+04, MSE(e): 2.325e-04, MSE(pi1): 5.270e-03, MSE(pi2): 2.185e-04, MSE(pi3): 9.968e-04\n",
      "Epoch 9600, Train loss: 2.464e+03, Test loss: 2.917e+04, MSE(e): 2.312e-04, MSE(pi1): 5.262e-03, MSE(pi2): 2.174e-04, MSE(pi3): 9.961e-04\n",
      "Epoch 9700, Train loss: 2.453e+03, Test loss: 2.914e+04, MSE(e): 2.301e-04, MSE(pi1): 5.255e-03, MSE(pi2): 2.166e-04, MSE(pi3): 9.953e-04\n",
      "Epoch 9800, Train loss: 2.444e+03, Test loss: 2.913e+04, MSE(e): 2.291e-04, MSE(pi1): 5.248e-03, MSE(pi2): 2.160e-04, MSE(pi3): 9.944e-04\n",
      "Epoch 9900, Train loss: 2.434e+03, Test loss: 2.911e+04, MSE(e): 2.282e-04, MSE(pi1): 5.243e-03, MSE(pi2): 2.155e-04, MSE(pi3): 9.934e-04\n",
      "Epoch 10000, Train loss: 2.425e+03, Test loss: 2.909e+04, MSE(e): 2.273e-04, MSE(pi1): 5.240e-03, MSE(pi2): 2.149e-04, MSE(pi3): 9.921e-04\n",
      "Epoch 10100, Train loss: 2.415e+03, Test loss: 2.906e+04, MSE(e): 2.264e-04, MSE(pi1): 5.239e-03, MSE(pi2): 2.144e-04, MSE(pi3): 9.907e-04\n",
      "Epoch 10200, Train loss: 2.405e+03, Test loss: 2.902e+04, MSE(e): 2.254e-04, MSE(pi1): 5.239e-03, MSE(pi2): 2.138e-04, MSE(pi3): 9.892e-04\n",
      "Epoch 10300, Train loss: 2.395e+03, Test loss: 2.898e+04, MSE(e): 2.244e-04, MSE(pi1): 5.240e-03, MSE(pi2): 2.133e-04, MSE(pi3): 9.877e-04\n",
      "Epoch 10400, Train loss: 2.385e+03, Test loss: 2.893e+04, MSE(e): 2.233e-04, MSE(pi1): 5.240e-03, MSE(pi2): 2.127e-04, MSE(pi3): 9.864e-04\n",
      "Epoch 10500, Train loss: 2.374e+03, Test loss: 2.888e+04, MSE(e): 2.223e-04, MSE(pi1): 5.238e-03, MSE(pi2): 2.121e-04, MSE(pi3): 9.852e-04\n",
      "Epoch 10600, Train loss: 2.364e+03, Test loss: 2.883e+04, MSE(e): 2.213e-04, MSE(pi1): 5.236e-03, MSE(pi2): 2.115e-04, MSE(pi3): 9.841e-04\n",
      "Epoch 10700, Train loss: 2.354e+03, Test loss: 2.878e+04, MSE(e): 2.203e-04, MSE(pi1): 5.233e-03, MSE(pi2): 2.110e-04, MSE(pi3): 9.832e-04\n",
      "Epoch 10800, Train loss: 2.344e+03, Test loss: 2.872e+04, MSE(e): 2.193e-04, MSE(pi1): 5.230e-03, MSE(pi2): 2.104e-04, MSE(pi3): 9.823e-04\n",
      "Epoch 10900, Train loss: 2.334e+03, Test loss: 2.867e+04, MSE(e): 2.184e-04, MSE(pi1): 5.227e-03, MSE(pi2): 2.099e-04, MSE(pi3): 9.815e-04\n",
      "Epoch 11000, Train loss: 2.325e+03, Test loss: 2.862e+04, MSE(e): 2.175e-04, MSE(pi1): 5.223e-03, MSE(pi2): 2.093e-04, MSE(pi3): 9.808e-04\n",
      "Epoch 11100, Train loss: 2.316e+03, Test loss: 2.857e+04, MSE(e): 2.166e-04, MSE(pi1): 5.220e-03, MSE(pi2): 2.088e-04, MSE(pi3): 9.800e-04\n",
      "Epoch 11200, Train loss: 2.308e+03, Test loss: 2.852e+04, MSE(e): 2.157e-04, MSE(pi1): 5.217e-03, MSE(pi2): 2.083e-04, MSE(pi3): 9.793e-04\n",
      "Epoch 11300, Train loss: 2.299e+03, Test loss: 2.846e+04, MSE(e): 2.149e-04, MSE(pi1): 5.214e-03, MSE(pi2): 2.079e-04, MSE(pi3): 9.786e-04\n",
      "Epoch 11400, Train loss: 2.291e+03, Test loss: 2.841e+04, MSE(e): 2.141e-04, MSE(pi1): 5.210e-03, MSE(pi2): 2.074e-04, MSE(pi3): 9.779e-04\n",
      "Epoch 11500, Train loss: 2.283e+03, Test loss: 2.836e+04, MSE(e): 2.133e-04, MSE(pi1): 5.207e-03, MSE(pi2): 2.069e-04, MSE(pi3): 9.773e-04\n",
      "Epoch 11600, Train loss: 2.276e+03, Test loss: 2.831e+04, MSE(e): 2.126e-04, MSE(pi1): 5.204e-03, MSE(pi2): 2.065e-04, MSE(pi3): 9.766e-04\n",
      "Epoch 11700, Train loss: 2.268e+03, Test loss: 2.826e+04, MSE(e): 2.118e-04, MSE(pi1): 5.201e-03, MSE(pi2): 2.061e-04, MSE(pi3): 9.760e-04\n",
      "Epoch 11800, Train loss: 2.261e+03, Test loss: 2.821e+04, MSE(e): 2.111e-04, MSE(pi1): 5.198e-03, MSE(pi2): 2.057e-04, MSE(pi3): 9.754e-04\n",
      "Epoch 11900, Train loss: 2.254e+03, Test loss: 2.816e+04, MSE(e): 2.104e-04, MSE(pi1): 5.195e-03, MSE(pi2): 2.053e-04, MSE(pi3): 9.748e-04\n",
      "Epoch 12000, Train loss: 2.247e+03, Test loss: 2.811e+04, MSE(e): 2.097e-04, MSE(pi1): 5.192e-03, MSE(pi2): 2.049e-04, MSE(pi3): 9.742e-04\n",
      "Epoch 12100, Train loss: 2.240e+03, Test loss: 2.806e+04, MSE(e): 2.091e-04, MSE(pi1): 5.189e-03, MSE(pi2): 2.045e-04, MSE(pi3): 9.736e-04\n",
      "Epoch 12200, Train loss: 2.234e+03, Test loss: 2.802e+04, MSE(e): 2.084e-04, MSE(pi1): 5.186e-03, MSE(pi2): 2.041e-04, MSE(pi3): 9.730e-04\n",
      "Epoch 12300, Train loss: 2.227e+03, Test loss: 2.797e+04, MSE(e): 2.078e-04, MSE(pi1): 5.183e-03, MSE(pi2): 2.038e-04, MSE(pi3): 9.725e-04\n",
      "Epoch 12400, Train loss: 2.221e+03, Test loss: 2.792e+04, MSE(e): 2.072e-04, MSE(pi1): 5.180e-03, MSE(pi2): 2.034e-04, MSE(pi3): 9.720e-04\n",
      "Epoch 12500, Train loss: 2.215e+03, Test loss: 2.787e+04, MSE(e): 2.066e-04, MSE(pi1): 5.177e-03, MSE(pi2): 2.031e-04, MSE(pi3): 9.714e-04\n",
      "Epoch 12600, Train loss: 2.209e+03, Test loss: 2.783e+04, MSE(e): 2.060e-04, MSE(pi1): 5.174e-03, MSE(pi2): 2.028e-04, MSE(pi3): 9.709e-04\n",
      "Epoch 12700, Train loss: 2.203e+03, Test loss: 2.778e+04, MSE(e): 2.054e-04, MSE(pi1): 5.171e-03, MSE(pi2): 2.025e-04, MSE(pi3): 9.704e-04\n",
      "Epoch 12800, Train loss: 2.197e+03, Test loss: 2.773e+04, MSE(e): 2.049e-04, MSE(pi1): 5.168e-03, MSE(pi2): 2.021e-04, MSE(pi3): 9.699e-04\n",
      "Epoch 12900, Train loss: 2.192e+03, Test loss: 2.769e+04, MSE(e): 2.043e-04, MSE(pi1): 5.165e-03, MSE(pi2): 2.018e-04, MSE(pi3): 9.694e-04\n",
      "Epoch 13000, Train loss: 2.186e+03, Test loss: 2.764e+04, MSE(e): 2.038e-04, MSE(pi1): 5.162e-03, MSE(pi2): 2.015e-04, MSE(pi3): 9.690e-04\n",
      "Epoch 13100, Train loss: 2.181e+03, Test loss: 2.760e+04, MSE(e): 2.032e-04, MSE(pi1): 5.159e-03, MSE(pi2): 2.013e-04, MSE(pi3): 9.685e-04\n",
      "Epoch 13200, Train loss: 2.176e+03, Test loss: 2.756e+04, MSE(e): 2.027e-04, MSE(pi1): 5.156e-03, MSE(pi2): 2.010e-04, MSE(pi3): 9.681e-04\n",
      "Epoch 13300, Train loss: 2.171e+03, Test loss: 2.751e+04, MSE(e): 2.022e-04, MSE(pi1): 5.153e-03, MSE(pi2): 2.007e-04, MSE(pi3): 9.676e-04\n",
      "Epoch 13400, Train loss: 2.166e+03, Test loss: 2.747e+04, MSE(e): 2.017e-04, MSE(pi1): 5.150e-03, MSE(pi2): 2.004e-04, MSE(pi3): 9.672e-04\n",
      "Epoch 13500, Train loss: 2.161e+03, Test loss: 2.743e+04, MSE(e): 2.012e-04, MSE(pi1): 5.147e-03, MSE(pi2): 2.002e-04, MSE(pi3): 9.668e-04\n",
      "Epoch 13600, Train loss: 2.156e+03, Test loss: 2.739e+04, MSE(e): 2.008e-04, MSE(pi1): 5.144e-03, MSE(pi2): 1.999e-04, MSE(pi3): 9.664e-04\n",
      "Epoch 13700, Train loss: 2.151e+03, Test loss: 2.735e+04, MSE(e): 2.003e-04, MSE(pi1): 5.141e-03, MSE(pi2): 1.997e-04, MSE(pi3): 9.660e-04\n",
      "Epoch 13800, Train loss: 2.147e+03, Test loss: 2.731e+04, MSE(e): 1.998e-04, MSE(pi1): 5.137e-03, MSE(pi2): 1.994e-04, MSE(pi3): 9.656e-04\n",
      "Epoch 13900, Train loss: 2.142e+03, Test loss: 2.727e+04, MSE(e): 1.994e-04, MSE(pi1): 5.134e-03, MSE(pi2): 1.992e-04, MSE(pi3): 9.652e-04\n",
      "Epoch 14000, Train loss: 2.138e+03, Test loss: 2.723e+04, MSE(e): 1.990e-04, MSE(pi1): 5.131e-03, MSE(pi2): 1.990e-04, MSE(pi3): 9.648e-04\n",
      "Epoch 14100, Train loss: 2.133e+03, Test loss: 2.719e+04, MSE(e): 1.985e-04, MSE(pi1): 5.128e-03, MSE(pi2): 1.988e-04, MSE(pi3): 9.644e-04\n",
      "Epoch 14200, Train loss: 2.129e+03, Test loss: 2.716e+04, MSE(e): 1.981e-04, MSE(pi1): 5.125e-03, MSE(pi2): 1.985e-04, MSE(pi3): 9.641e-04\n",
      "Epoch 14300, Train loss: 2.125e+03, Test loss: 2.712e+04, MSE(e): 1.977e-04, MSE(pi1): 5.122e-03, MSE(pi2): 1.983e-04, MSE(pi3): 9.637e-04\n",
      "Epoch 14400, Train loss: 2.121e+03, Test loss: 2.708e+04, MSE(e): 1.973e-04, MSE(pi1): 5.119e-03, MSE(pi2): 1.981e-04, MSE(pi3): 9.633e-04\n",
      "Epoch 14500, Train loss: 2.116e+03, Test loss: 2.705e+04, MSE(e): 1.969e-04, MSE(pi1): 5.115e-03, MSE(pi2): 1.979e-04, MSE(pi3): 9.630e-04\n",
      "Epoch 14600, Train loss: 2.113e+03, Test loss: 2.701e+04, MSE(e): 1.965e-04, MSE(pi1): 5.112e-03, MSE(pi2): 1.977e-04, MSE(pi3): 9.626e-04\n",
      "Epoch 14700, Train loss: 2.109e+03, Test loss: 2.698e+04, MSE(e): 1.961e-04, MSE(pi1): 5.109e-03, MSE(pi2): 1.975e-04, MSE(pi3): 9.623e-04\n",
      "Epoch 14800, Train loss: 2.105e+03, Test loss: 2.695e+04, MSE(e): 1.957e-04, MSE(pi1): 5.106e-03, MSE(pi2): 1.973e-04, MSE(pi3): 9.620e-04\n",
      "Epoch 14900, Train loss: 2.101e+03, Test loss: 2.691e+04, MSE(e): 1.954e-04, MSE(pi1): 5.102e-03, MSE(pi2): 1.971e-04, MSE(pi3): 9.617e-04\n",
      "Epoch 15000, Train loss: 2.097e+03, Test loss: 2.688e+04, MSE(e): 1.950e-04, MSE(pi1): 5.099e-03, MSE(pi2): 1.969e-04, MSE(pi3): 9.613e-04\n",
      "Epoch 15100, Train loss: 2.094e+03, Test loss: 2.685e+04, MSE(e): 1.946e-04, MSE(pi1): 5.096e-03, MSE(pi2): 1.968e-04, MSE(pi3): 9.610e-04\n",
      "Epoch 15200, Train loss: 2.090e+03, Test loss: 2.682e+04, MSE(e): 1.943e-04, MSE(pi1): 5.092e-03, MSE(pi2): 1.966e-04, MSE(pi3): 9.607e-04\n",
      "Epoch 15300, Train loss: 2.087e+03, Test loss: 2.679e+04, MSE(e): 1.940e-04, MSE(pi1): 5.089e-03, MSE(pi2): 1.964e-04, MSE(pi3): 9.604e-04\n",
      "Epoch 15400, Train loss: 2.083e+03, Test loss: 2.676e+04, MSE(e): 1.936e-04, MSE(pi1): 5.086e-03, MSE(pi2): 1.963e-04, MSE(pi3): 9.601e-04\n",
      "Epoch 15500, Train loss: 2.080e+03, Test loss: 2.673e+04, MSE(e): 1.933e-04, MSE(pi1): 5.082e-03, MSE(pi2): 1.961e-04, MSE(pi3): 9.598e-04\n",
      "Epoch 15600, Train loss: 2.077e+03, Test loss: 2.670e+04, MSE(e): 1.930e-04, MSE(pi1): 5.079e-03, MSE(pi2): 1.959e-04, MSE(pi3): 9.595e-04\n",
      "Epoch 15700, Train loss: 2.073e+03, Test loss: 2.668e+04, MSE(e): 1.926e-04, MSE(pi1): 5.076e-03, MSE(pi2): 1.958e-04, MSE(pi3): 9.593e-04\n",
      "Epoch 15800, Train loss: 2.070e+03, Test loss: 2.665e+04, MSE(e): 1.923e-04, MSE(pi1): 5.072e-03, MSE(pi2): 1.956e-04, MSE(pi3): 9.590e-04\n",
      "Epoch 15900, Train loss: 2.067e+03, Test loss: 2.662e+04, MSE(e): 1.920e-04, MSE(pi1): 5.069e-03, MSE(pi2): 1.955e-04, MSE(pi3): 9.587e-04\n",
      "Epoch 16000, Train loss: 2.064e+03, Test loss: 2.660e+04, MSE(e): 1.917e-04, MSE(pi1): 5.065e-03, MSE(pi2): 1.953e-04, MSE(pi3): 9.584e-04\n",
      "Epoch 16100, Train loss: 2.061e+03, Test loss: 2.657e+04, MSE(e): 1.914e-04, MSE(pi1): 5.061e-03, MSE(pi2): 1.952e-04, MSE(pi3): 9.582e-04\n",
      "Epoch 16200, Train loss: 2.058e+03, Test loss: 2.655e+04, MSE(e): 1.911e-04, MSE(pi1): 5.058e-03, MSE(pi2): 1.950e-04, MSE(pi3): 9.579e-04\n",
      "Epoch 16300, Train loss: 2.055e+03, Test loss: 2.652e+04, MSE(e): 1.908e-04, MSE(pi1): 5.054e-03, MSE(pi2): 1.949e-04, MSE(pi3): 9.576e-04\n",
      "Epoch 16400, Train loss: 2.052e+03, Test loss: 2.650e+04, MSE(e): 1.905e-04, MSE(pi1): 5.050e-03, MSE(pi2): 1.947e-04, MSE(pi3): 9.574e-04\n",
      "Epoch 16500, Train loss: 2.049e+03, Test loss: 2.648e+04, MSE(e): 1.903e-04, MSE(pi1): 5.046e-03, MSE(pi2): 1.946e-04, MSE(pi3): 9.571e-04\n",
      "Epoch 16600, Train loss: 2.046e+03, Test loss: 2.645e+04, MSE(e): 1.900e-04, MSE(pi1): 5.042e-03, MSE(pi2): 1.945e-04, MSE(pi3): 9.569e-04\n",
      "Epoch 16700, Train loss: 2.043e+03, Test loss: 2.643e+04, MSE(e): 1.897e-04, MSE(pi1): 5.037e-03, MSE(pi2): 1.943e-04, MSE(pi3): 9.566e-04\n",
      "Epoch 16800, Train loss: 2.041e+03, Test loss: 2.641e+04, MSE(e): 1.895e-04, MSE(pi1): 5.033e-03, MSE(pi2): 1.942e-04, MSE(pi3): 9.564e-04\n",
      "Epoch 16900, Train loss: 2.038e+03, Test loss: 2.639e+04, MSE(e): 1.892e-04, MSE(pi1): 5.029e-03, MSE(pi2): 1.941e-04, MSE(pi3): 9.562e-04\n",
      "Epoch 17000, Train loss: 2.035e+03, Test loss: 2.637e+04, MSE(e): 1.889e-04, MSE(pi1): 5.024e-03, MSE(pi2): 1.940e-04, MSE(pi3): 9.560e-04\n",
      "Epoch 17100, Train loss: 2.033e+03, Test loss: 2.635e+04, MSE(e): 1.887e-04, MSE(pi1): 5.019e-03, MSE(pi2): 1.938e-04, MSE(pi3): 9.558e-04\n",
      "Epoch 17200, Train loss: 2.030e+03, Test loss: 2.633e+04, MSE(e): 1.884e-04, MSE(pi1): 5.013e-03, MSE(pi2): 1.937e-04, MSE(pi3): 9.556e-04\n",
      "Epoch 17300, Train loss: 2.028e+03, Test loss: 2.631e+04, MSE(e): 1.882e-04, MSE(pi1): 5.011e-03, MSE(pi2): 1.936e-04, MSE(pi3): 9.552e-04\n",
      "Epoch 17400, Train loss: 2.025e+03, Test loss: 2.629e+04, MSE(e): 1.879e-04, MSE(pi1): 5.006e-03, MSE(pi2): 1.935e-04, MSE(pi3): 9.550e-04\n",
      "Epoch 17500, Train loss: 2.023e+03, Test loss: 2.628e+04, MSE(e): 1.877e-04, MSE(pi1): 5.000e-03, MSE(pi2): 1.934e-04, MSE(pi3): 9.548e-04\n",
      "Epoch 17600, Train loss: 2.020e+03, Test loss: 2.626e+04, MSE(e): 1.875e-04, MSE(pi1): 4.995e-03, MSE(pi2): 1.933e-04, MSE(pi3): 9.546e-04\n",
      "Epoch 17700, Train loss: 2.018e+03, Test loss: 2.624e+04, MSE(e): 1.872e-04, MSE(pi1): 4.990e-03, MSE(pi2): 1.931e-04, MSE(pi3): 9.544e-04\n",
      "Epoch 17800, Train loss: 2.016e+03, Test loss: 2.623e+04, MSE(e): 1.870e-04, MSE(pi1): 4.984e-03, MSE(pi2): 1.930e-04, MSE(pi3): 9.542e-04\n",
      "Epoch 17900, Train loss: 2.013e+03, Test loss: 2.621e+04, MSE(e): 1.868e-04, MSE(pi1): 4.978e-03, MSE(pi2): 1.929e-04, MSE(pi3): 9.540e-04\n",
      "Epoch 18000, Train loss: 2.011e+03, Test loss: 2.619e+04, MSE(e): 1.866e-04, MSE(pi1): 4.972e-03, MSE(pi2): 1.928e-04, MSE(pi3): 9.537e-04\n",
      "Epoch 18100, Train loss: 2.009e+03, Test loss: 2.618e+04, MSE(e): 1.863e-04, MSE(pi1): 4.966e-03, MSE(pi2): 1.927e-04, MSE(pi3): 9.536e-04\n",
      "Epoch 18200, Train loss: 2.006e+03, Test loss: 2.616e+04, MSE(e): 1.861e-04, MSE(pi1): 4.960e-03, MSE(pi2): 1.926e-04, MSE(pi3): 9.534e-04\n",
      "Epoch 18300, Train loss: 2.004e+03, Test loss: 2.615e+04, MSE(e): 1.859e-04, MSE(pi1): 4.953e-03, MSE(pi2): 1.925e-04, MSE(pi3): 9.532e-04\n",
      "Epoch 18400, Train loss: 2.002e+03, Test loss: 2.613e+04, MSE(e): 1.857e-04, MSE(pi1): 4.947e-03, MSE(pi2): 1.924e-04, MSE(pi3): 9.530e-04\n",
      "Epoch 18500, Train loss: 2.000e+03, Test loss: 2.612e+04, MSE(e): 1.855e-04, MSE(pi1): 4.940e-03, MSE(pi2): 1.923e-04, MSE(pi3): 9.528e-04\n",
      "Epoch 18600, Train loss: 1.998e+03, Test loss: 2.611e+04, MSE(e): 1.853e-04, MSE(pi1): 4.933e-03, MSE(pi2): 1.922e-04, MSE(pi3): 9.526e-04\n",
      "Epoch 18700, Train loss: 1.996e+03, Test loss: 2.609e+04, MSE(e): 1.851e-04, MSE(pi1): 4.926e-03, MSE(pi2): 1.921e-04, MSE(pi3): 9.524e-04\n",
      "Epoch 18800, Train loss: 1.994e+03, Test loss: 2.608e+04, MSE(e): 1.849e-04, MSE(pi1): 4.919e-03, MSE(pi2): 1.920e-04, MSE(pi3): 9.522e-04\n",
      "Epoch 18900, Train loss: 1.992e+03, Test loss: 2.607e+04, MSE(e): 1.847e-04, MSE(pi1): 4.911e-03, MSE(pi2): 1.920e-04, MSE(pi3): 9.521e-04\n",
      "Epoch 19000, Train loss: 1.990e+03, Test loss: 2.606e+04, MSE(e): 1.845e-04, MSE(pi1): 4.905e-03, MSE(pi2): 1.919e-04, MSE(pi3): 9.518e-04\n",
      "Epoch 19100, Train loss: 1.988e+03, Test loss: 2.605e+04, MSE(e): 1.843e-04, MSE(pi1): 4.897e-03, MSE(pi2): 1.918e-04, MSE(pi3): 9.517e-04\n",
      "Epoch 19200, Train loss: 1.986e+03, Test loss: 2.603e+04, MSE(e): 1.841e-04, MSE(pi1): 4.889e-03, MSE(pi2): 1.917e-04, MSE(pi3): 9.515e-04\n",
      "Epoch 19300, Train loss: 1.984e+03, Test loss: 2.602e+04, MSE(e): 1.839e-04, MSE(pi1): 4.881e-03, MSE(pi2): 1.916e-04, MSE(pi3): 9.513e-04\n",
      "Epoch 19400, Train loss: 1.982e+03, Test loss: 2.601e+04, MSE(e): 1.838e-04, MSE(pi1): 4.873e-03, MSE(pi2): 1.915e-04, MSE(pi3): 9.512e-04\n",
      "Epoch 19500, Train loss: 1.980e+03, Test loss: 2.600e+04, MSE(e): 1.836e-04, MSE(pi1): 4.865e-03, MSE(pi2): 1.914e-04, MSE(pi3): 9.510e-04\n",
      "Epoch 19600, Train loss: 1.978e+03, Test loss: 2.599e+04, MSE(e): 1.834e-04, MSE(pi1): 4.856e-03, MSE(pi2): 1.914e-04, MSE(pi3): 9.508e-04\n",
      "Epoch 19700, Train loss: 1.976e+03, Test loss: 2.598e+04, MSE(e): 1.832e-04, MSE(pi1): 4.848e-03, MSE(pi2): 1.913e-04, MSE(pi3): 9.507e-04\n",
      "Epoch 19800, Train loss: 1.974e+03, Test loss: 2.597e+04, MSE(e): 1.831e-04, MSE(pi1): 4.840e-03, MSE(pi2): 1.912e-04, MSE(pi3): 9.505e-04\n",
      "Epoch 19900, Train loss: 1.972e+03, Test loss: 2.596e+04, MSE(e): 1.829e-04, MSE(pi1): 4.831e-03, MSE(pi2): 1.911e-04, MSE(pi3): 9.504e-04\n",
      "Epoch 20000, Train loss: 1.971e+03, Test loss: 2.595e+04, MSE(e): 1.827e-04, MSE(pi1): 4.823e-03, MSE(pi2): 1.910e-04, MSE(pi3): 9.502e-04\n",
      "Epoch 20100, Train loss: 1.969e+03, Test loss: 2.594e+04, MSE(e): 1.825e-04, MSE(pi1): 4.815e-03, MSE(pi2): 1.910e-04, MSE(pi3): 9.501e-04\n",
      "Epoch 20200, Train loss: 1.967e+03, Test loss: 2.593e+04, MSE(e): 1.824e-04, MSE(pi1): 4.801e-03, MSE(pi2): 1.909e-04, MSE(pi3): 9.503e-04\n",
      "Epoch 20300, Train loss: 1.965e+03, Test loss: 2.592e+04, MSE(e): 1.822e-04, MSE(pi1): 4.795e-03, MSE(pi2): 1.908e-04, MSE(pi3): 9.500e-04\n",
      "Epoch 20400, Train loss: 1.964e+03, Test loss: 2.592e+04, MSE(e): 1.821e-04, MSE(pi1): 4.788e-03, MSE(pi2): 1.907e-04, MSE(pi3): 9.498e-04\n",
      "Epoch 20500, Train loss: 1.962e+03, Test loss: 2.591e+04, MSE(e): 1.819e-04, MSE(pi1): 4.780e-03, MSE(pi2): 1.907e-04, MSE(pi3): 9.496e-04\n",
      "Epoch 20600, Train loss: 1.960e+03, Test loss: 2.590e+04, MSE(e): 1.817e-04, MSE(pi1): 4.773e-03, MSE(pi2): 1.906e-04, MSE(pi3): 9.493e-04\n",
      "Epoch 20700, Train loss: 1.959e+03, Test loss: 2.589e+04, MSE(e): 1.816e-04, MSE(pi1): 4.765e-03, MSE(pi2): 1.905e-04, MSE(pi3): 9.492e-04\n",
      "Epoch 20800, Train loss: 1.957e+03, Test loss: 2.588e+04, MSE(e): 1.814e-04, MSE(pi1): 4.758e-03, MSE(pi2): 1.905e-04, MSE(pi3): 9.489e-04\n",
      "Epoch 20900, Train loss: 1.955e+03, Test loss: 2.588e+04, MSE(e): 1.813e-04, MSE(pi1): 4.751e-03, MSE(pi2): 1.904e-04, MSE(pi3): 9.487e-04\n",
      "Epoch 21000, Train loss: 1.954e+03, Test loss: 2.587e+04, MSE(e): 1.811e-04, MSE(pi1): 4.743e-03, MSE(pi2): 1.903e-04, MSE(pi3): 9.486e-04\n",
      "Epoch 21100, Train loss: 1.952e+03, Test loss: 2.586e+04, MSE(e): 1.810e-04, MSE(pi1): 4.739e-03, MSE(pi2): 1.902e-04, MSE(pi3): 9.481e-04\n",
      "Epoch 21200, Train loss: 1.951e+03, Test loss: 2.586e+04, MSE(e): 1.808e-04, MSE(pi1): 4.729e-03, MSE(pi2): 1.902e-04, MSE(pi3): 9.482e-04\n",
      "Epoch 21300, Train loss: 1.949e+03, Test loss: 2.585e+04, MSE(e): 1.807e-04, MSE(pi1): 4.719e-03, MSE(pi2): 1.901e-04, MSE(pi3): 9.483e-04\n",
      "Epoch 21400, Train loss: 1.948e+03, Test loss: 2.584e+04, MSE(e): 1.805e-04, MSE(pi1): 4.717e-03, MSE(pi2): 1.900e-04, MSE(pi3): 9.477e-04\n",
      "Epoch 21500, Train loss: 1.946e+03, Test loss: 2.584e+04, MSE(e): 1.804e-04, MSE(pi1): 4.708e-03, MSE(pi2): 1.900e-04, MSE(pi3): 9.476e-04\n",
      "Epoch 21600, Train loss: 1.945e+03, Test loss: 2.583e+04, MSE(e): 1.803e-04, MSE(pi1): 4.705e-03, MSE(pi2): 1.899e-04, MSE(pi3): 9.472e-04\n",
      "Epoch 21700, Train loss: 1.943e+03, Test loss: 2.582e+04, MSE(e): 1.801e-04, MSE(pi1): 4.697e-03, MSE(pi2): 1.899e-04, MSE(pi3): 9.471e-04\n",
      "Epoch 21800, Train loss: 1.942e+03, Test loss: 2.582e+04, MSE(e): 1.800e-04, MSE(pi1): 4.688e-03, MSE(pi2): 1.898e-04, MSE(pi3): 9.472e-04\n",
      "Epoch 21900, Train loss: 1.940e+03, Test loss: 2.581e+04, MSE(e): 1.798e-04, MSE(pi1): 4.687e-03, MSE(pi2): 1.897e-04, MSE(pi3): 9.465e-04\n",
      "Epoch 22000, Train loss: 1.939e+03, Test loss: 2.581e+04, MSE(e): 1.797e-04, MSE(pi1): 4.678e-03, MSE(pi2): 1.897e-04, MSE(pi3): 9.466e-04\n",
      "Epoch 22100, Train loss: 1.937e+03, Test loss: 2.580e+04, MSE(e): 1.796e-04, MSE(pi1): 4.676e-03, MSE(pi2): 1.896e-04, MSE(pi3): 9.461e-04\n",
      "Epoch 22200, Train loss: 1.936e+03, Test loss: 2.580e+04, MSE(e): 1.794e-04, MSE(pi1): 4.669e-03, MSE(pi2): 1.896e-04, MSE(pi3): 9.460e-04\n",
      "Epoch 22300, Train loss: 1.934e+03, Test loss: 2.579e+04, MSE(e): 1.793e-04, MSE(pi1): 4.660e-03, MSE(pi2): 1.895e-04, MSE(pi3): 9.461e-04\n",
      "Epoch 22400, Train loss: 1.933e+03, Test loss: 2.578e+04, MSE(e): 1.792e-04, MSE(pi1): 4.660e-03, MSE(pi2): 1.894e-04, MSE(pi3): 9.454e-04\n",
      "Epoch 22500, Train loss: 1.932e+03, Test loss: 2.578e+04, MSE(e): 1.790e-04, MSE(pi1): 4.652e-03, MSE(pi2): 1.894e-04, MSE(pi3): 9.454e-04\n",
      "Epoch 22600, Train loss: 1.930e+03, Test loss: 2.578e+04, MSE(e): 1.789e-04, MSE(pi1): 4.649e-03, MSE(pi2): 1.893e-04, MSE(pi3): 9.450e-04\n",
      "Epoch 22700, Train loss: 1.929e+03, Test loss: 2.577e+04, MSE(e): 1.788e-04, MSE(pi1): 4.644e-03, MSE(pi2): 1.893e-04, MSE(pi3): 9.448e-04\n",
      "Epoch 22800, Train loss: 1.928e+03, Test loss: 2.577e+04, MSE(e): 1.787e-04, MSE(pi1): 4.636e-03, MSE(pi2): 1.892e-04, MSE(pi3): 9.449e-04\n",
      "Epoch 22900, Train loss: 1.926e+03, Test loss: 2.576e+04, MSE(e): 1.785e-04, MSE(pi1): 4.639e-03, MSE(pi2): 1.892e-04, MSE(pi3): 9.441e-04\n",
      "Epoch 23000, Train loss: 1.925e+03, Test loss: 2.576e+04, MSE(e): 1.784e-04, MSE(pi1): 4.630e-03, MSE(pi2): 1.891e-04, MSE(pi3): 9.442e-04\n",
      "Epoch 23100, Train loss: 1.924e+03, Test loss: 2.575e+04, MSE(e): 1.783e-04, MSE(pi1): 4.623e-03, MSE(pi2): 1.891e-04, MSE(pi3): 9.442e-04\n",
      "Epoch 23200, Train loss: 1.923e+03, Test loss: 2.575e+04, MSE(e): 1.782e-04, MSE(pi1): 4.625e-03, MSE(pi2): 1.890e-04, MSE(pi3): 9.434e-04\n",
      "Epoch 23300, Train loss: 1.921e+03, Test loss: 2.574e+04, MSE(e): 1.781e-04, MSE(pi1): 4.617e-03, MSE(pi2): 1.890e-04, MSE(pi3): 9.436e-04\n",
      "Epoch 23400, Train loss: 1.920e+03, Test loss: 2.574e+04, MSE(e): 1.779e-04, MSE(pi1): 4.611e-03, MSE(pi2): 1.889e-04, MSE(pi3): 9.435e-04\n",
      "Epoch 23500, Train loss: 1.919e+03, Test loss: 2.574e+04, MSE(e): 1.778e-04, MSE(pi1): 4.613e-03, MSE(pi2): 1.889e-04, MSE(pi3): 9.428e-04\n",
      "Epoch 23600, Train loss: 1.918e+03, Test loss: 2.573e+04, MSE(e): 1.777e-04, MSE(pi1): 4.605e-03, MSE(pi2): 1.888e-04, MSE(pi3): 9.429e-04\n",
      "Epoch 23700, Train loss: 1.916e+03, Test loss: 2.573e+04, MSE(e): 1.776e-04, MSE(pi1): 4.601e-03, MSE(pi2): 1.888e-04, MSE(pi3): 9.427e-04\n",
      "Epoch 23800, Train loss: 1.915e+03, Test loss: 2.573e+04, MSE(e): 1.775e-04, MSE(pi1): 4.602e-03, MSE(pi2): 1.887e-04, MSE(pi3): 9.421e-04\n",
      "Epoch 23900, Train loss: 1.914e+03, Test loss: 2.572e+04, MSE(e): 1.774e-04, MSE(pi1): 4.596e-03, MSE(pi2): 1.887e-04, MSE(pi3): 9.420e-04\n",
      "Epoch 24000, Train loss: 1.913e+03, Test loss: 2.572e+04, MSE(e): 1.773e-04, MSE(pi1): 4.589e-03, MSE(pi2): 1.886e-04, MSE(pi3): 9.422e-04\n",
      "Epoch 24100, Train loss: 1.912e+03, Test loss: 2.572e+04, MSE(e): 1.772e-04, MSE(pi1): 4.590e-03, MSE(pi2): 1.886e-04, MSE(pi3): 9.415e-04\n",
      "Epoch 24200, Train loss: 1.911e+03, Test loss: 2.571e+04, MSE(e): 1.770e-04, MSE(pi1): 4.588e-03, MSE(pi2): 1.885e-04, MSE(pi3): 9.412e-04\n",
      "Epoch 24300, Train loss: 1.909e+03, Test loss: 2.571e+04, MSE(e): 1.769e-04, MSE(pi1): 4.581e-03, MSE(pi2): 1.885e-04, MSE(pi3): 9.413e-04\n",
      "Epoch 24400, Train loss: 1.908e+03, Test loss: 2.571e+04, MSE(e): 1.768e-04, MSE(pi1): 4.579e-03, MSE(pi2): 1.884e-04, MSE(pi3): 9.411e-04\n",
      "Epoch 24500, Train loss: 1.907e+03, Test loss: 2.570e+04, MSE(e): 1.767e-04, MSE(pi1): 4.576e-03, MSE(pi2): 1.884e-04, MSE(pi3): 9.408e-04\n",
      "Epoch 24600, Train loss: 1.906e+03, Test loss: 2.570e+04, MSE(e): 1.766e-04, MSE(pi1): 4.577e-03, MSE(pi2): 1.883e-04, MSE(pi3): 9.403e-04\n",
      "Epoch 24700, Train loss: 1.905e+03, Test loss: 2.570e+04, MSE(e): 1.765e-04, MSE(pi1): 4.571e-03, MSE(pi2): 1.883e-04, MSE(pi3): 9.403e-04\n",
      "Epoch 24800, Train loss: 1.904e+03, Test loss: 2.569e+04, MSE(e): 1.764e-04, MSE(pi1): 4.565e-03, MSE(pi2): 1.882e-04, MSE(pi3): 9.403e-04\n",
      "Epoch 24900, Train loss: 1.903e+03, Test loss: 2.569e+04, MSE(e): 1.763e-04, MSE(pi1): 4.567e-03, MSE(pi2): 1.882e-04, MSE(pi3): 9.398e-04\n",
      "Epoch 25000, Train loss: 1.902e+03, Test loss: 2.569e+04, MSE(e): 1.762e-04, MSE(pi1): 4.563e-03, MSE(pi2): 1.881e-04, MSE(pi3): 9.396e-04\n",
      "Epoch 25100, Train loss: 1.901e+03, Test loss: 2.569e+04, MSE(e): 1.761e-04, MSE(pi1): 4.565e-03, MSE(pi2): 1.881e-04, MSE(pi3): 9.390e-04\n",
      "Epoch 25200, Train loss: 1.900e+03, Test loss: 2.568e+04, MSE(e): 1.760e-04, MSE(pi1): 4.557e-03, MSE(pi2): 1.881e-04, MSE(pi3): 9.393e-04\n",
      "Epoch 25300, Train loss: 1.899e+03, Test loss: 2.568e+04, MSE(e): 1.759e-04, MSE(pi1): 4.556e-03, MSE(pi2): 1.880e-04, MSE(pi3): 9.390e-04\n",
      "Epoch 25400, Train loss: 1.898e+03, Test loss: 2.568e+04, MSE(e): 1.758e-04, MSE(pi1): 4.554e-03, MSE(pi2): 1.880e-04, MSE(pi3): 9.387e-04\n",
      "Epoch 25500, Train loss: 1.897e+03, Test loss: 2.568e+04, MSE(e): 1.757e-04, MSE(pi1): 4.552e-03, MSE(pi2): 1.879e-04, MSE(pi3): 9.385e-04\n",
      "Epoch 25600, Train loss: 1.896e+03, Test loss: 2.568e+04, MSE(e): 1.756e-04, MSE(pi1): 4.549e-03, MSE(pi2): 1.879e-04, MSE(pi3): 9.383e-04\n",
      "Epoch 25700, Train loss: 1.895e+03, Test loss: 2.567e+04, MSE(e): 1.755e-04, MSE(pi1): 4.547e-03, MSE(pi2): 1.879e-04, MSE(pi3): 9.381e-04\n",
      "Epoch 25800, Train loss: 1.894e+03, Test loss: 2.567e+04, MSE(e): 1.754e-04, MSE(pi1): 4.548e-03, MSE(pi2): 1.878e-04, MSE(pi3): 9.376e-04\n",
      "Epoch 25900, Train loss: 1.893e+03, Test loss: 2.567e+04, MSE(e): 1.753e-04, MSE(pi1): 4.543e-03, MSE(pi2): 1.878e-04, MSE(pi3): 9.376e-04\n",
      "Epoch 26000, Train loss: 1.892e+03, Test loss: 2.567e+04, MSE(e): 1.752e-04, MSE(pi1): 4.542e-03, MSE(pi2): 1.877e-04, MSE(pi3): 9.373e-04\n",
      "Epoch 26100, Train loss: 1.891e+03, Test loss: 2.567e+04, MSE(e): 1.751e-04, MSE(pi1): 4.539e-03, MSE(pi2): 1.877e-04, MSE(pi3): 9.371e-04\n",
      "Epoch 26200, Train loss: 1.890e+03, Test loss: 2.566e+04, MSE(e): 1.750e-04, MSE(pi1): 4.537e-03, MSE(pi2): 1.877e-04, MSE(pi3): 9.369e-04\n",
      "Epoch 26300, Train loss: 1.889e+03, Test loss: 2.566e+04, MSE(e): 1.749e-04, MSE(pi1): 4.539e-03, MSE(pi2): 1.876e-04, MSE(pi3): 9.365e-04\n",
      "Epoch 26400, Train loss: 1.888e+03, Test loss: 2.566e+04, MSE(e): 1.749e-04, MSE(pi1): 4.533e-03, MSE(pi2): 1.876e-04, MSE(pi3): 9.365e-04\n",
      "Epoch 26500, Train loss: 1.887e+03, Test loss: 2.566e+04, MSE(e): 1.748e-04, MSE(pi1): 4.533e-03, MSE(pi2): 1.875e-04, MSE(pi3): 9.362e-04\n",
      "Epoch 26600, Train loss: 1.886e+03, Test loss: 2.566e+04, MSE(e): 1.747e-04, MSE(pi1): 4.529e-03, MSE(pi2): 1.875e-04, MSE(pi3): 9.361e-04\n",
      "Epoch 26700, Train loss: 1.885e+03, Test loss: 2.566e+04, MSE(e): 1.746e-04, MSE(pi1): 4.532e-03, MSE(pi2): 1.875e-04, MSE(pi3): 9.356e-04\n",
      "Epoch 26800, Train loss: 1.884e+03, Test loss: 2.566e+04, MSE(e): 1.745e-04, MSE(pi1): 4.526e-03, MSE(pi2): 1.874e-04, MSE(pi3): 9.357e-04\n",
      "Epoch 26900, Train loss: 1.883e+03, Test loss: 2.565e+04, MSE(e): 1.744e-04, MSE(pi1): 4.527e-03, MSE(pi2): 1.874e-04, MSE(pi3): 9.353e-04\n",
      "Epoch 27000, Train loss: 1.882e+03, Test loss: 2.565e+04, MSE(e): 1.743e-04, MSE(pi1): 4.522e-03, MSE(pi2): 1.874e-04, MSE(pi3): 9.353e-04\n",
      "Epoch 27100, Train loss: 1.881e+03, Test loss: 2.565e+04, MSE(e): 1.742e-04, MSE(pi1): 4.525e-03, MSE(pi2): 1.873e-04, MSE(pi3): 9.348e-04\n",
      "Epoch 27200, Train loss: 1.880e+03, Test loss: 2.565e+04, MSE(e): 1.742e-04, MSE(pi1): 4.520e-03, MSE(pi2): 1.873e-04, MSE(pi3): 9.348e-04\n",
      "Epoch 27300, Train loss: 1.880e+03, Test loss: 2.565e+04, MSE(e): 1.741e-04, MSE(pi1): 4.520e-03, MSE(pi2): 1.873e-04, MSE(pi3): 9.345e-04\n",
      "Epoch 27400, Train loss: 1.879e+03, Test loss: 2.565e+04, MSE(e): 1.740e-04, MSE(pi1): 4.516e-03, MSE(pi2): 1.872e-04, MSE(pi3): 9.344e-04\n",
      "Epoch 27500, Train loss: 1.878e+03, Test loss: 2.565e+04, MSE(e): 1.739e-04, MSE(pi1): 4.519e-03, MSE(pi2): 1.872e-04, MSE(pi3): 9.339e-04\n",
      "Epoch 27600, Train loss: 1.877e+03, Test loss: 2.565e+04, MSE(e): 1.738e-04, MSE(pi1): 4.514e-03, MSE(pi2): 1.872e-04, MSE(pi3): 9.340e-04\n",
      "Epoch 27700, Train loss: 1.876e+03, Test loss: 2.565e+04, MSE(e): 1.737e-04, MSE(pi1): 4.514e-03, MSE(pi2): 1.871e-04, MSE(pi3): 9.337e-04\n",
      "Epoch 27800, Train loss: 1.875e+03, Test loss: 2.565e+04, MSE(e): 1.737e-04, MSE(pi1): 4.511e-03, MSE(pi2): 1.871e-04, MSE(pi3): 9.336e-04\n",
      "Epoch 27900, Train loss: 1.874e+03, Test loss: 2.564e+04, MSE(e): 1.736e-04, MSE(pi1): 4.513e-03, MSE(pi2): 1.871e-04, MSE(pi3): 9.331e-04\n",
      "Epoch 28000, Train loss: 1.873e+03, Test loss: 2.564e+04, MSE(e): 1.735e-04, MSE(pi1): 4.509e-03, MSE(pi2): 1.870e-04, MSE(pi3): 9.332e-04\n",
      "Epoch 28100, Train loss: 1.873e+03, Test loss: 2.564e+04, MSE(e): 1.734e-04, MSE(pi1): 4.509e-03, MSE(pi2): 1.870e-04, MSE(pi3): 9.329e-04\n",
      "Epoch 28200, Train loss: 1.872e+03, Test loss: 2.564e+04, MSE(e): 1.733e-04, MSE(pi1): 4.507e-03, MSE(pi2): 1.870e-04, MSE(pi3): 9.327e-04\n",
      "Epoch 28300, Train loss: 1.871e+03, Test loss: 2.564e+04, MSE(e): 1.732e-04, MSE(pi1): 4.508e-03, MSE(pi2): 1.869e-04, MSE(pi3): 9.323e-04\n",
      "Epoch 28400, Train loss: 1.870e+03, Test loss: 2.564e+04, MSE(e): 1.732e-04, MSE(pi1): 4.504e-03, MSE(pi2): 1.869e-04, MSE(pi3): 9.324e-04\n",
      "Epoch 28500, Train loss: 1.869e+03, Test loss: 2.564e+04, MSE(e): 1.731e-04, MSE(pi1): 4.504e-03, MSE(pi2): 1.869e-04, MSE(pi3): 9.320e-04\n",
      "Epoch 28600, Train loss: 1.869e+03, Test loss: 2.564e+04, MSE(e): 1.730e-04, MSE(pi1): 4.502e-03, MSE(pi2): 1.868e-04, MSE(pi3): 9.319e-04\n",
      "Epoch 28700, Train loss: 1.868e+03, Test loss: 2.564e+04, MSE(e): 1.729e-04, MSE(pi1): 4.504e-03, MSE(pi2): 1.868e-04, MSE(pi3): 9.314e-04\n",
      "Epoch 28800, Train loss: 1.867e+03, Test loss: 2.564e+04, MSE(e): 1.729e-04, MSE(pi1): 4.500e-03, MSE(pi2): 1.868e-04, MSE(pi3): 9.315e-04\n",
      "Epoch 28900, Train loss: 1.866e+03, Test loss: 2.564e+04, MSE(e): 1.728e-04, MSE(pi1): 4.501e-03, MSE(pi2): 1.867e-04, MSE(pi3): 9.312e-04\n",
      "Epoch 29000, Train loss: 1.865e+03, Test loss: 2.564e+04, MSE(e): 1.727e-04, MSE(pi1): 4.496e-03, MSE(pi2): 1.867e-04, MSE(pi3): 9.313e-04\n",
      "Epoch 29100, Train loss: 1.865e+03, Test loss: 2.564e+04, MSE(e): 1.726e-04, MSE(pi1): 4.499e-03, MSE(pi2): 1.867e-04, MSE(pi3): 9.307e-04\n",
      "Epoch 29200, Train loss: 1.864e+03, Test loss: 2.564e+04, MSE(e): 1.726e-04, MSE(pi1): 4.496e-03, MSE(pi2): 1.867e-04, MSE(pi3): 9.306e-04\n",
      "Epoch 29300, Train loss: 1.863e+03, Test loss: 2.564e+04, MSE(e): 1.725e-04, MSE(pi1): 4.495e-03, MSE(pi2): 1.866e-04, MSE(pi3): 9.305e-04\n",
      "Epoch 29400, Train loss: 1.862e+03, Test loss: 2.564e+04, MSE(e): 1.724e-04, MSE(pi1): 4.492e-03, MSE(pi2): 1.866e-04, MSE(pi3): 9.305e-04\n",
      "Epoch 29500, Train loss: 1.862e+03, Test loss: 2.564e+04, MSE(e): 1.723e-04, MSE(pi1): 4.496e-03, MSE(pi2): 1.866e-04, MSE(pi3): 9.299e-04\n",
      "Epoch 29600, Train loss: 1.861e+03, Test loss: 2.564e+04, MSE(e): 1.723e-04, MSE(pi1): 4.493e-03, MSE(pi2): 1.865e-04, MSE(pi3): 9.298e-04\n",
      "Epoch 29700, Train loss: 1.860e+03, Test loss: 2.564e+04, MSE(e): 1.722e-04, MSE(pi1): 4.489e-03, MSE(pi2): 1.865e-04, MSE(pi3): 9.299e-04\n",
      "Epoch 29800, Train loss: 1.859e+03, Test loss: 2.564e+04, MSE(e): 1.721e-04, MSE(pi1): 4.489e-03, MSE(pi2): 1.865e-04, MSE(pi3): 9.296e-04\n",
      "Epoch 29900, Train loss: 1.859e+03, Test loss: 2.564e+04, MSE(e): 1.721e-04, MSE(pi1): 4.493e-03, MSE(pi2): 1.865e-04, MSE(pi3): 9.291e-04\n",
      "Epoch 30000, Train loss: 1.858e+03, Test loss: 2.564e+04, MSE(e): 1.720e-04, MSE(pi1): 4.490e-03, MSE(pi2): 1.864e-04, MSE(pi3): 9.290e-04\n",
      "Epoch 30100, Train loss: 1.857e+03, Test loss: 2.564e+04, MSE(e): 1.719e-04, MSE(pi1): 4.488e-03, MSE(pi2): 1.864e-04, MSE(pi3): 9.289e-04\n",
      "Epoch 30200, Train loss: 1.856e+03, Test loss: 2.564e+04, MSE(e): 1.718e-04, MSE(pi1): 4.486e-03, MSE(pi2): 1.864e-04, MSE(pi3): 9.289e-04\n",
      "Epoch 30300, Train loss: 1.856e+03, Test loss: 2.564e+04, MSE(e): 1.718e-04, MSE(pi1): 4.483e-03, MSE(pi2): 1.863e-04, MSE(pi3): 9.288e-04\n",
      "Epoch 30400, Train loss: 1.855e+03, Test loss: 2.564e+04, MSE(e): 1.717e-04, MSE(pi1): 4.488e-03, MSE(pi2): 1.863e-04, MSE(pi3): 9.282e-04\n",
      "Epoch 30500, Train loss: 1.854e+03, Test loss: 2.564e+04, MSE(e): 1.716e-04, MSE(pi1): 4.485e-03, MSE(pi2): 1.863e-04, MSE(pi3): 9.281e-04\n",
      "Epoch 30600, Train loss: 1.854e+03, Test loss: 2.564e+04, MSE(e): 1.716e-04, MSE(pi1): 4.483e-03, MSE(pi2): 1.863e-04, MSE(pi3): 9.280e-04\n",
      "Epoch 30700, Train loss: 1.853e+03, Test loss: 2.564e+04, MSE(e): 1.715e-04, MSE(pi1): 4.481e-03, MSE(pi2): 1.862e-04, MSE(pi3): 9.280e-04\n",
      "Epoch 30800, Train loss: 1.852e+03, Test loss: 2.565e+04, MSE(e): 1.714e-04, MSE(pi1): 4.484e-03, MSE(pi2): 1.862e-04, MSE(pi3): 9.275e-04\n",
      "Epoch 30900, Train loss: 1.851e+03, Test loss: 2.565e+04, MSE(e): 1.714e-04, MSE(pi1): 4.482e-03, MSE(pi2): 1.862e-04, MSE(pi3): 9.273e-04\n",
      "Epoch 31000, Train loss: 1.851e+03, Test loss: 2.565e+04, MSE(e): 1.713e-04, MSE(pi1): 4.481e-03, MSE(pi2): 1.862e-04, MSE(pi3): 9.272e-04\n",
      "Epoch 31100, Train loss: 1.850e+03, Test loss: 2.565e+04, MSE(e): 1.712e-04, MSE(pi1): 4.481e-03, MSE(pi2): 1.861e-04, MSE(pi3): 9.271e-04\n",
      "Epoch 31200, Train loss: 1.849e+03, Test loss: 2.565e+04, MSE(e): 1.712e-04, MSE(pi1): 4.475e-03, MSE(pi2): 1.861e-04, MSE(pi3): 9.272e-04\n",
      "Epoch 31300, Train loss: 1.849e+03, Test loss: 2.565e+04, MSE(e): 1.711e-04, MSE(pi1): 4.482e-03, MSE(pi2): 1.861e-04, MSE(pi3): 9.264e-04\n",
      "Epoch 31400, Train loss: 1.848e+03, Test loss: 2.565e+04, MSE(e): 1.710e-04, MSE(pi1): 4.476e-03, MSE(pi2): 1.861e-04, MSE(pi3): 9.266e-04\n",
      "Epoch 31500, Train loss: 1.847e+03, Test loss: 2.565e+04, MSE(e): 1.710e-04, MSE(pi1): 4.474e-03, MSE(pi2): 1.860e-04, MSE(pi3): 9.264e-04\n",
      "Epoch 31600, Train loss: 1.847e+03, Test loss: 2.565e+04, MSE(e): 1.709e-04, MSE(pi1): 4.479e-03, MSE(pi2): 1.860e-04, MSE(pi3): 9.260e-04\n",
      "Epoch 31700, Train loss: 1.846e+03, Test loss: 2.565e+04, MSE(e): 1.709e-04, MSE(pi1): 4.472e-03, MSE(pi2): 1.860e-04, MSE(pi3): 9.264e-04\n",
      "Epoch 31800, Train loss: 1.845e+03, Test loss: 2.565e+04, MSE(e): 1.708e-04, MSE(pi1): 4.478e-03, MSE(pi2): 1.860e-04, MSE(pi3): 9.256e-04\n",
      "Epoch 31900, Train loss: 1.845e+03, Test loss: 2.566e+04, MSE(e): 1.707e-04, MSE(pi1): 4.476e-03, MSE(pi2): 1.859e-04, MSE(pi3): 9.256e-04\n",
      "Epoch 32000, Train loss: 1.844e+03, Test loss: 2.566e+04, MSE(e): 1.707e-04, MSE(pi1): 4.470e-03, MSE(pi2): 1.859e-04, MSE(pi3): 9.261e-04\n",
      "Epoch 32100, Train loss: 1.843e+03, Test loss: 2.566e+04, MSE(e): 1.706e-04, MSE(pi1): 4.473e-03, MSE(pi2): 1.859e-04, MSE(pi3): 9.256e-04\n",
      "Epoch 32200, Train loss: 1.843e+03, Test loss: 2.566e+04, MSE(e): 1.705e-04, MSE(pi1): 4.472e-03, MSE(pi2): 1.859e-04, MSE(pi3): 9.253e-04\n",
      "Epoch 32300, Train loss: 1.842e+03, Test loss: 2.566e+04, MSE(e): 1.705e-04, MSE(pi1): 4.470e-03, MSE(pi2): 1.859e-04, MSE(pi3): 9.251e-04\n",
      "Epoch 32400, Train loss: 1.842e+03, Test loss: 2.566e+04, MSE(e): 1.704e-04, MSE(pi1): 4.474e-03, MSE(pi2): 1.858e-04, MSE(pi3): 9.245e-04\n",
      "Epoch 32500, Train loss: 1.841e+03, Test loss: 2.566e+04, MSE(e): 1.704e-04, MSE(pi1): 4.466e-03, MSE(pi2): 1.858e-04, MSE(pi3): 9.250e-04\n",
      "Epoch 32600, Train loss: 1.840e+03, Test loss: 2.567e+04, MSE(e): 1.703e-04, MSE(pi1): 4.467e-03, MSE(pi2): 1.858e-04, MSE(pi3): 9.246e-04\n",
      "Epoch 32700, Train loss: 1.840e+03, Test loss: 2.567e+04, MSE(e): 1.702e-04, MSE(pi1): 4.470e-03, MSE(pi2): 1.858e-04, MSE(pi3): 9.242e-04\n",
      "Epoch 32800, Train loss: 1.839e+03, Test loss: 2.567e+04, MSE(e): 1.702e-04, MSE(pi1): 4.472e-03, MSE(pi2): 1.857e-04, MSE(pi3): 9.237e-04\n",
      "Epoch 32900, Train loss: 1.838e+03, Test loss: 2.567e+04, MSE(e): 1.701e-04, MSE(pi1): 4.463e-03, MSE(pi2): 1.857e-04, MSE(pi3): 9.243e-04\n",
      "Epoch 33000, Train loss: 1.838e+03, Test loss: 2.567e+04, MSE(e): 1.701e-04, MSE(pi1): 4.462e-03, MSE(pi2): 1.857e-04, MSE(pi3): 9.243e-04\n",
      "Epoch 33100, Train loss: 1.837e+03, Test loss: 2.567e+04, MSE(e): 1.700e-04, MSE(pi1): 4.468e-03, MSE(pi2): 1.857e-04, MSE(pi3): 9.235e-04\n",
      "Epoch 33200, Train loss: 1.837e+03, Test loss: 2.568e+04, MSE(e): 1.700e-04, MSE(pi1): 4.469e-03, MSE(pi2): 1.857e-04, MSE(pi3): 9.230e-04\n",
      "Epoch 33300, Train loss: 1.836e+03, Test loss: 2.568e+04, MSE(e): 1.699e-04, MSE(pi1): 4.467e-03, MSE(pi2): 1.856e-04, MSE(pi3): 9.232e-04\n",
      "Epoch 33400, Train loss: 1.836e+03, Test loss: 2.568e+04, MSE(e): 1.698e-04, MSE(pi1): 4.459e-03, MSE(pi2): 1.856e-04, MSE(pi3): 9.238e-04\n",
      "Epoch 33500, Train loss: 1.835e+03, Test loss: 2.568e+04, MSE(e): 1.698e-04, MSE(pi1): 4.463e-03, MSE(pi2): 1.856e-04, MSE(pi3): 9.231e-04\n",
      "Epoch 33600, Train loss: 1.834e+03, Test loss: 2.568e+04, MSE(e): 1.697e-04, MSE(pi1): 4.465e-03, MSE(pi2): 1.856e-04, MSE(pi3): 9.226e-04\n",
      "Epoch 33700, Train loss: 1.834e+03, Test loss: 2.569e+04, MSE(e): 1.697e-04, MSE(pi1): 4.466e-03, MSE(pi2): 1.856e-04, MSE(pi3): 9.222e-04\n",
      "Epoch 33800, Train loss: 1.833e+03, Test loss: 2.569e+04, MSE(e): 1.696e-04, MSE(pi1): 4.459e-03, MSE(pi2): 1.855e-04, MSE(pi3): 9.229e-04\n",
      "Epoch 33900, Train loss: 1.833e+03, Test loss: 2.569e+04, MSE(e): 1.696e-04, MSE(pi1): 4.458e-03, MSE(pi2): 1.855e-04, MSE(pi3): 9.228e-04\n",
      "Epoch 34000, Train loss: 1.832e+03, Test loss: 2.569e+04, MSE(e): 1.695e-04, MSE(pi1): 4.464e-03, MSE(pi2): 1.855e-04, MSE(pi3): 9.220e-04\n",
      "Epoch 34100, Train loss: 1.831e+03, Test loss: 2.570e+04, MSE(e): 1.695e-04, MSE(pi1): 4.464e-03, MSE(pi2): 1.855e-04, MSE(pi3): 9.216e-04\n",
      "Epoch 34200, Train loss: 1.831e+03, Test loss: 2.570e+04, MSE(e): 1.694e-04, MSE(pi1): 4.462e-03, MSE(pi2): 1.855e-04, MSE(pi3): 9.217e-04\n",
      "Epoch 34300, Train loss: 1.830e+03, Test loss: 2.570e+04, MSE(e): 1.693e-04, MSE(pi1): 4.453e-03, MSE(pi2): 1.855e-04, MSE(pi3): 9.225e-04\n",
      "Epoch 34400, Train loss: 1.830e+03, Test loss: 2.570e+04, MSE(e): 1.693e-04, MSE(pi1): 4.453e-03, MSE(pi2): 1.854e-04, MSE(pi3): 9.222e-04\n",
      "Epoch 34500, Train loss: 1.829e+03, Test loss: 2.571e+04, MSE(e): 1.692e-04, MSE(pi1): 4.460e-03, MSE(pi2): 1.854e-04, MSE(pi3): 9.213e-04\n",
      "Epoch 34600, Train loss: 1.829e+03, Test loss: 2.571e+04, MSE(e): 1.692e-04, MSE(pi1): 4.462e-03, MSE(pi2): 1.854e-04, MSE(pi3): 9.208e-04\n",
      "Epoch 34700, Train loss: 1.828e+03, Test loss: 2.571e+04, MSE(e): 1.691e-04, MSE(pi1): 4.461e-03, MSE(pi2): 1.854e-04, MSE(pi3): 9.215e-04\n",
      "Epoch 34800, Train loss: 1.828e+03, Test loss: 2.571e+04, MSE(e): 1.691e-04, MSE(pi1): 4.448e-03, MSE(pi2): 1.854e-04, MSE(pi3): 9.226e-04\n",
      "Epoch 34900, Train loss: 1.827e+03, Test loss: 2.572e+04, MSE(e): 1.690e-04, MSE(pi1): 4.453e-03, MSE(pi2): 1.853e-04, MSE(pi3): 9.218e-04\n",
      "Epoch 35000, Train loss: 1.827e+03, Test loss: 2.572e+04, MSE(e): 1.690e-04, MSE(pi1): 4.453e-03, MSE(pi2): 1.853e-04, MSE(pi3): 9.209e-04\n",
      "Epoch 35100, Train loss: 1.826e+03, Test loss: 2.572e+04, MSE(e): 1.689e-04, MSE(pi1): 4.457e-03, MSE(pi2): 1.853e-04, MSE(pi3): 9.205e-04\n",
      "Epoch 35200, Train loss: 1.826e+03, Test loss: 2.572e+04, MSE(e): 1.689e-04, MSE(pi1): 4.455e-03, MSE(pi2): 1.853e-04, MSE(pi3): 9.206e-04\n",
      "Epoch 35300, Train loss: 1.825e+03, Test loss: 2.573e+04, MSE(e): 1.688e-04, MSE(pi1): 4.450e-03, MSE(pi2): 1.853e-04, MSE(pi3): 9.208e-04\n",
      "Epoch 35400, Train loss: 1.824e+03, Test loss: 2.573e+04, MSE(e): 1.688e-04, MSE(pi1): 4.449e-03, MSE(pi2): 1.853e-04, MSE(pi3): 9.210e-04\n",
      "Epoch 35500, Train loss: 1.824e+03, Test loss: 2.573e+04, MSE(e): 1.687e-04, MSE(pi1): 4.448e-03, MSE(pi2): 1.852e-04, MSE(pi3): 9.212e-04\n",
      "Epoch 35600, Train loss: 1.823e+03, Test loss: 2.574e+04, MSE(e): 1.687e-04, MSE(pi1): 4.448e-03, MSE(pi2): 1.852e-04, MSE(pi3): 9.211e-04\n",
      "Epoch 35700, Train loss: 1.823e+03, Test loss: 2.574e+04, MSE(e): 1.686e-04, MSE(pi1): 4.442e-03, MSE(pi2): 1.852e-04, MSE(pi3): 9.215e-04\n",
      "Epoch 35800, Train loss: 1.822e+03, Test loss: 2.574e+04, MSE(e): 1.686e-04, MSE(pi1): 4.443e-03, MSE(pi2): 1.852e-04, MSE(pi3): 9.211e-04\n",
      "Epoch 35900, Train loss: 1.822e+03, Test loss: 2.574e+04, MSE(e): 1.685e-04, MSE(pi1): 4.440e-03, MSE(pi2): 1.852e-04, MSE(pi3): 9.207e-04\n",
      "Epoch 36000, Train loss: 1.821e+03, Test loss: 2.575e+04, MSE(e): 1.685e-04, MSE(pi1): 4.446e-03, MSE(pi2): 1.852e-04, MSE(pi3): 9.201e-04\n",
      "Epoch 36100, Train loss: 1.821e+03, Test loss: 2.575e+04, MSE(e): 1.684e-04, MSE(pi1): 4.441e-03, MSE(pi2): 1.851e-04, MSE(pi3): 9.207e-04\n",
      "Epoch 36200, Train loss: 1.820e+03, Test loss: 2.575e+04, MSE(e): 1.684e-04, MSE(pi1): 4.443e-03, MSE(pi2): 1.851e-04, MSE(pi3): 9.206e-04\n",
      "Epoch 36300, Train loss: 1.820e+03, Test loss: 2.576e+04, MSE(e): 1.683e-04, MSE(pi1): 4.448e-03, MSE(pi2): 1.851e-04, MSE(pi3): 9.190e-04\n",
      "Epoch 36400, Train loss: 1.819e+03, Test loss: 2.576e+04, MSE(e): 1.683e-04, MSE(pi1): 4.444e-03, MSE(pi2): 1.851e-04, MSE(pi3): 9.194e-04\n",
      "Epoch 36500, Train loss: 1.819e+03, Test loss: 2.576e+04, MSE(e): 1.682e-04, MSE(pi1): 4.445e-03, MSE(pi2): 1.851e-04, MSE(pi3): 9.191e-04\n",
      "Epoch 36600, Train loss: 1.818e+03, Test loss: 2.577e+04, MSE(e): 1.682e-04, MSE(pi1): 4.448e-03, MSE(pi2): 1.851e-04, MSE(pi3): 9.185e-04\n",
      "Epoch 36700, Train loss: 1.818e+03, Test loss: 2.577e+04, MSE(e): 1.681e-04, MSE(pi1): 4.448e-03, MSE(pi2): 1.851e-04, MSE(pi3): 9.185e-04\n",
      "Epoch 36800, Train loss: 1.817e+03, Test loss: 2.577e+04, MSE(e): 1.681e-04, MSE(pi1): 4.438e-03, MSE(pi2): 1.850e-04, MSE(pi3): 9.192e-04\n",
      "Epoch 36900, Train loss: 1.817e+03, Test loss: 2.578e+04, MSE(e): 1.680e-04, MSE(pi1): 4.446e-03, MSE(pi2): 1.850e-04, MSE(pi3): 9.184e-04\n",
      "Epoch 37000, Train loss: 1.816e+03, Test loss: 2.578e+04, MSE(e): 1.680e-04, MSE(pi1): 4.441e-03, MSE(pi2): 1.850e-04, MSE(pi3): 9.186e-04\n",
      "Epoch 37100, Train loss: 1.816e+03, Test loss: 2.578e+04, MSE(e): 1.680e-04, MSE(pi1): 4.439e-03, MSE(pi2): 1.850e-04, MSE(pi3): 9.186e-04\n",
      "Epoch 37200, Train loss: 1.816e+03, Test loss: 2.579e+04, MSE(e): 1.679e-04, MSE(pi1): 4.436e-03, MSE(pi2): 1.850e-04, MSE(pi3): 9.197e-04\n",
      "Epoch 37300, Train loss: 1.815e+03, Test loss: 2.579e+04, MSE(e): 1.679e-04, MSE(pi1): 4.428e-03, MSE(pi2): 1.850e-04, MSE(pi3): 9.212e-04\n",
      "Epoch 37400, Train loss: 1.815e+03, Test loss: 2.579e+04, MSE(e): 1.678e-04, MSE(pi1): 4.430e-03, MSE(pi2): 1.850e-04, MSE(pi3): 9.197e-04\n",
      "Epoch 37500, Train loss: 1.814e+03, Test loss: 2.580e+04, MSE(e): 1.678e-04, MSE(pi1): 4.434e-03, MSE(pi2): 1.849e-04, MSE(pi3): 9.189e-04\n",
      "Epoch 37600, Train loss: 1.814e+03, Test loss: 2.580e+04, MSE(e): 1.677e-04, MSE(pi1): 4.434e-03, MSE(pi2): 1.849e-04, MSE(pi3): 9.191e-04\n",
      "Epoch 37700, Train loss: 1.813e+03, Test loss: 2.580e+04, MSE(e): 1.677e-04, MSE(pi1): 4.425e-03, MSE(pi2): 1.849e-04, MSE(pi3): 9.198e-04\n",
      "Epoch 37800, Train loss: 1.813e+03, Test loss: 2.581e+04, MSE(e): 1.676e-04, MSE(pi1): 4.432e-03, MSE(pi2): 1.849e-04, MSE(pi3): 9.185e-04\n",
      "Epoch 37900, Train loss: 1.812e+03, Test loss: 2.581e+04, MSE(e): 1.676e-04, MSE(pi1): 4.426e-03, MSE(pi2): 1.849e-04, MSE(pi3): 9.199e-04\n",
      "Epoch 38000, Train loss: 1.812e+03, Test loss: 2.582e+04, MSE(e): 1.676e-04, MSE(pi1): 4.427e-03, MSE(pi2): 1.849e-04, MSE(pi3): 9.190e-04\n",
      "Epoch 38100, Train loss: 1.811e+03, Test loss: 2.582e+04, MSE(e): 1.675e-04, MSE(pi1): 4.419e-03, MSE(pi2): 1.849e-04, MSE(pi3): 9.197e-04\n",
      "Epoch 38200, Train loss: 1.811e+03, Test loss: 2.582e+04, MSE(e): 1.675e-04, MSE(pi1): 4.422e-03, MSE(pi2): 1.849e-04, MSE(pi3): 9.195e-04\n",
      "Epoch 38300, Train loss: 1.810e+03, Test loss: 2.583e+04, MSE(e): 1.674e-04, MSE(pi1): 4.428e-03, MSE(pi2): 1.848e-04, MSE(pi3): 9.184e-04\n",
      "Epoch 38400, Train loss: 1.810e+03, Test loss: 2.583e+04, MSE(e): 1.674e-04, MSE(pi1): 4.420e-03, MSE(pi2): 1.848e-04, MSE(pi3): 9.196e-04\n",
      "Epoch 38500, Train loss: 1.810e+03, Test loss: 2.584e+04, MSE(e): 1.673e-04, MSE(pi1): 4.428e-03, MSE(pi2): 1.848e-04, MSE(pi3): 9.178e-04\n",
      "Epoch 38600, Train loss: 1.809e+03, Test loss: 2.584e+04, MSE(e): 1.673e-04, MSE(pi1): 4.424e-03, MSE(pi2): 1.848e-04, MSE(pi3): 9.187e-04\n",
      "Epoch 38700, Train loss: 1.809e+03, Test loss: 2.584e+04, MSE(e): 1.672e-04, MSE(pi1): 4.423e-03, MSE(pi2): 1.848e-04, MSE(pi3): 9.183e-04\n",
      "Epoch 38800, Train loss: 1.808e+03, Test loss: 2.585e+04, MSE(e): 1.672e-04, MSE(pi1): 4.417e-03, MSE(pi2): 1.848e-04, MSE(pi3): 9.192e-04\n",
      "Epoch 38900, Train loss: 1.808e+03, Test loss: 2.585e+04, MSE(e): 1.672e-04, MSE(pi1): 4.423e-03, MSE(pi2): 1.848e-04, MSE(pi3): 9.177e-04\n",
      "Epoch 39000, Train loss: 1.807e+03, Test loss: 2.585e+04, MSE(e): 1.671e-04, MSE(pi1): 4.414e-03, MSE(pi2): 1.847e-04, MSE(pi3): 9.188e-04\n",
      "Epoch 39100, Train loss: 1.808e+03, Test loss: 2.586e+04, MSE(e): 1.672e-04, MSE(pi1): 4.415e-03, MSE(pi2): 1.848e-04, MSE(pi3): 9.186e-04\n",
      "Epoch 39200, Train loss: 1.805e+03, Test loss: 2.586e+04, MSE(e): 1.669e-04, MSE(pi1): 4.412e-03, MSE(pi2): 1.847e-04, MSE(pi3): 9.187e-04\n",
      "Epoch 39300, Train loss: 1.809e+03, Test loss: 2.586e+04, MSE(e): 1.673e-04, MSE(pi1): 4.414e-03, MSE(pi2): 1.848e-04, MSE(pi3): 9.181e-04\n",
      "Epoch 39400, Train loss: 1.804e+03, Test loss: 2.587e+04, MSE(e): 1.668e-04, MSE(pi1): 4.418e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.172e-04\n",
      "Epoch 39500, Train loss: 1.807e+03, Test loss: 2.587e+04, MSE(e): 1.671e-04, MSE(pi1): 4.415e-03, MSE(pi2): 1.848e-04, MSE(pi3): 9.186e-04\n",
      "Epoch 39600, Train loss: 1.803e+03, Test loss: 2.588e+04, MSE(e): 1.667e-04, MSE(pi1): 4.408e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.186e-04\n",
      "Epoch 39700, Train loss: 1.806e+03, Test loss: 2.587e+04, MSE(e): 1.670e-04, MSE(pi1): 4.413e-03, MSE(pi2): 1.847e-04, MSE(pi3): 9.174e-04\n",
      "Epoch 39800, Train loss: 1.802e+03, Test loss: 2.589e+04, MSE(e): 1.666e-04, MSE(pi1): 4.408e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.183e-04\n",
      "Epoch 39900, Train loss: 1.804e+03, Test loss: 2.588e+04, MSE(e): 1.668e-04, MSE(pi1): 4.422e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.161e-04\n",
      "Epoch 40000, Train loss: 1.802e+03, Test loss: 2.590e+04, MSE(e): 1.666e-04, MSE(pi1): 4.410e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.175e-04\n",
      "Epoch 40100, Train loss: 1.802e+03, Test loss: 2.589e+04, MSE(e): 1.666e-04, MSE(pi1): 4.403e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.179e-04\n",
      "Epoch 40200, Train loss: 1.801e+03, Test loss: 2.591e+04, MSE(e): 1.665e-04, MSE(pi1): 4.411e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.183e-04\n",
      "Epoch 40300, Train loss: 1.801e+03, Test loss: 2.589e+04, MSE(e): 1.665e-04, MSE(pi1): 4.395e-03, MSE(pi2): 1.845e-04, MSE(pi3): 9.190e-04\n",
      "Epoch 40400, Train loss: 1.802e+03, Test loss: 2.592e+04, MSE(e): 1.666e-04, MSE(pi1): 4.407e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.174e-04\n",
      "Epoch 40500, Train loss: 1.800e+03, Test loss: 2.590e+04, MSE(e): 1.664e-04, MSE(pi1): 4.398e-03, MSE(pi2): 1.845e-04, MSE(pi3): 9.182e-04\n",
      "Epoch 40600, Train loss: 1.804e+03, Test loss: 2.592e+04, MSE(e): 1.668e-04, MSE(pi1): 4.407e-03, MSE(pi2): 1.847e-04, MSE(pi3): 9.169e-04\n",
      "Epoch 40700, Train loss: 1.799e+03, Test loss: 2.592e+04, MSE(e): 1.663e-04, MSE(pi1): 4.392e-03, MSE(pi2): 1.845e-04, MSE(pi3): 9.185e-04\n",
      "Epoch 40800, Train loss: 1.803e+03, Test loss: 2.592e+04, MSE(e): 1.667e-04, MSE(pi1): 4.416e-03, MSE(pi2): 1.847e-04, MSE(pi3): 9.153e-04\n",
      "Epoch 40900, Train loss: 1.798e+03, Test loss: 2.593e+04, MSE(e): 1.662e-04, MSE(pi1): 4.397e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.184e-04\n",
      "Epoch 41000, Train loss: 1.800e+03, Test loss: 2.592e+04, MSE(e): 1.664e-04, MSE(pi1): 4.404e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.167e-04\n",
      "Epoch 41100, Train loss: 1.797e+03, Test loss: 2.594e+04, MSE(e): 1.661e-04, MSE(pi1): 4.390e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.190e-04\n",
      "Epoch 41200, Train loss: 1.798e+03, Test loss: 2.593e+04, MSE(e): 1.662e-04, MSE(pi1): 4.420e-03, MSE(pi2): 1.845e-04, MSE(pi3): 9.141e-04\n",
      "Epoch 41300, Train loss: 1.796e+03, Test loss: 2.595e+04, MSE(e): 1.661e-04, MSE(pi1): 4.403e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.158e-04\n",
      "Epoch 41400, Train loss: 1.796e+03, Test loss: 2.594e+04, MSE(e): 1.660e-04, MSE(pi1): 4.401e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.158e-04\n",
      "Epoch 41500, Train loss: 1.800e+03, Test loss: 2.596e+04, MSE(e): 1.664e-04, MSE(pi1): 4.414e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.152e-04\n",
      "Epoch 41600, Train loss: 1.795e+03, Test loss: 2.595e+04, MSE(e): 1.659e-04, MSE(pi1): 4.432e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.134e-04\n",
      "Epoch 41700, Train loss: 1.800e+03, Test loss: 2.595e+04, MSE(e): 1.664e-04, MSE(pi1): 4.410e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.144e-04\n",
      "Epoch 41800, Train loss: 1.794e+03, Test loss: 2.597e+04, MSE(e): 1.658e-04, MSE(pi1): 4.418e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.139e-04\n",
      "Epoch 41900, Train loss: 1.796e+03, Test loss: 2.596e+04, MSE(e): 1.660e-04, MSE(pi1): 4.410e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.143e-04\n",
      "Epoch 42000, Train loss: 1.793e+03, Test loss: 2.598e+04, MSE(e): 1.657e-04, MSE(pi1): 4.406e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.146e-04\n",
      "Epoch 42100, Train loss: 1.794e+03, Test loss: 2.597e+04, MSE(e): 1.658e-04, MSE(pi1): 4.403e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.146e-04\n",
      "Epoch 42200, Train loss: 1.796e+03, Test loss: 2.600e+04, MSE(e): 1.660e-04, MSE(pi1): 4.416e-03, MSE(pi2): 1.845e-04, MSE(pi3): 9.132e-04\n",
      "Epoch 42300, Train loss: 1.792e+03, Test loss: 2.598e+04, MSE(e): 1.657e-04, MSE(pi1): 4.413e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.139e-04\n",
      "Epoch 42400, Train loss: 1.798e+03, Test loss: 2.598e+04, MSE(e): 1.662e-04, MSE(pi1): 4.399e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.158e-04\n",
      "Epoch 42500, Train loss: 1.791e+03, Test loss: 2.600e+04, MSE(e): 1.655e-04, MSE(pi1): 4.413e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.133e-04\n",
      "Epoch 42600, Train loss: 1.793e+03, Test loss: 2.599e+04, MSE(e): 1.658e-04, MSE(pi1): 4.401e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.141e-04\n",
      "Epoch 42700, Train loss: 1.790e+03, Test loss: 2.602e+04, MSE(e): 1.655e-04, MSE(pi1): 4.412e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.137e-04\n",
      "Epoch 42800, Train loss: 1.791e+03, Test loss: 2.600e+04, MSE(e): 1.655e-04, MSE(pi1): 4.392e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.148e-04\n",
      "Epoch 42900, Train loss: 1.797e+03, Test loss: 2.602e+04, MSE(e): 1.661e-04, MSE(pi1): 4.414e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.131e-04\n",
      "Epoch 43000, Train loss: 1.790e+03, Test loss: 2.601e+04, MSE(e): 1.654e-04, MSE(pi1): 4.400e-03, MSE(pi2): 1.842e-04, MSE(pi3): 9.140e-04\n",
      "Epoch 43100, Train loss: 1.793e+03, Test loss: 2.601e+04, MSE(e): 1.657e-04, MSE(pi1): 4.411e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.130e-04\n",
      "Epoch 43200, Train loss: 1.788e+03, Test loss: 2.603e+04, MSE(e): 1.653e-04, MSE(pi1): 4.386e-03, MSE(pi2): 1.842e-04, MSE(pi3): 9.151e-04\n",
      "Epoch 43300, Train loss: 1.790e+03, Test loss: 2.602e+04, MSE(e): 1.654e-04, MSE(pi1): 4.418e-03, MSE(pi2): 1.842e-04, MSE(pi3): 9.119e-04\n",
      "Epoch 43400, Train loss: 1.792e+03, Test loss: 2.606e+04, MSE(e): 1.657e-04, MSE(pi1): 4.388e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.144e-04\n",
      "Epoch 43500, Train loss: 1.788e+03, Test loss: 2.603e+04, MSE(e): 1.652e-04, MSE(pi1): 4.393e-03, MSE(pi2): 1.842e-04, MSE(pi3): 9.142e-04\n",
      "Epoch 43600, Train loss: 1.792e+03, Test loss: 2.603e+04, MSE(e): 1.656e-04, MSE(pi1): 4.398e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.147e-04\n",
      "Epoch 43700, Train loss: 1.787e+03, Test loss: 2.605e+04, MSE(e): 1.651e-04, MSE(pi1): 4.379e-03, MSE(pi2): 1.842e-04, MSE(pi3): 9.157e-04\n",
      "Epoch 43800, Train loss: 1.788e+03, Test loss: 2.604e+04, MSE(e): 1.652e-04, MSE(pi1): 4.397e-03, MSE(pi2): 1.842e-04, MSE(pi3): 9.156e-04\n",
      "Epoch 43900, Train loss: 1.791e+03, Test loss: 2.608e+04, MSE(e): 1.655e-04, MSE(pi1): 4.371e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.159e-04\n",
      "Epoch 44000, Train loss: 1.786e+03, Test loss: 2.606e+04, MSE(e): 1.651e-04, MSE(pi1): 4.386e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.156e-04\n",
      "Epoch 44100, Train loss: 1.789e+03, Test loss: 2.605e+04, MSE(e): 1.654e-04, MSE(pi1): 4.376e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.157e-04\n",
      "Epoch 44200, Train loss: 1.785e+03, Test loss: 2.608e+04, MSE(e): 1.649e-04, MSE(pi1): 4.386e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.156e-04\n",
      "Epoch 44300, Train loss: 1.786e+03, Test loss: 2.606e+04, MSE(e): 1.651e-04, MSE(pi1): 4.378e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.163e-04\n",
      "Epoch 44400, Train loss: 1.793e+03, Test loss: 2.609e+04, MSE(e): 1.658e-04, MSE(pi1): 4.367e-03, MSE(pi2): 1.846e-04, MSE(pi3): 9.158e-04\n",
      "Epoch 44500, Train loss: 1.785e+03, Test loss: 2.608e+04, MSE(e): 1.649e-04, MSE(pi1): 4.389e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.153e-04\n",
      "Epoch 44600, Train loss: 1.786e+03, Test loss: 2.607e+04, MSE(e): 1.651e-04, MSE(pi1): 4.370e-03, MSE(pi2): 1.842e-04, MSE(pi3): 9.159e-04\n",
      "Epoch 44700, Train loss: 1.783e+03, Test loss: 2.611e+04, MSE(e): 1.648e-04, MSE(pi1): 4.361e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.179e-04\n",
      "Epoch 44800, Train loss: 1.784e+03, Test loss: 2.609e+04, MSE(e): 1.649e-04, MSE(pi1): 4.380e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.138e-04\n",
      "Epoch 44900, Train loss: 1.788e+03, Test loss: 2.609e+04, MSE(e): 1.653e-04, MSE(pi1): 4.374e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.150e-04\n",
      "Epoch 45000, Train loss: 1.782e+03, Test loss: 2.611e+04, MSE(e): 1.647e-04, MSE(pi1): 4.382e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.149e-04\n",
      "Epoch 45100, Train loss: 1.784e+03, Test loss: 2.610e+04, MSE(e): 1.648e-04, MSE(pi1): 4.368e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.150e-04\n",
      "Epoch 45200, Train loss: 1.791e+03, Test loss: 2.613e+04, MSE(e): 1.656e-04, MSE(pi1): 4.388e-03, MSE(pi2): 1.845e-04, MSE(pi3): 9.156e-04\n",
      "Epoch 45300, Train loss: 1.782e+03, Test loss: 2.612e+04, MSE(e): 1.646e-04, MSE(pi1): 4.373e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.151e-04\n",
      "Epoch 45400, Train loss: 1.783e+03, Test loss: 2.611e+04, MSE(e): 1.648e-04, MSE(pi1): 4.378e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.139e-04\n",
      "Epoch 45500, Train loss: 1.781e+03, Test loss: 2.616e+04, MSE(e): 1.645e-04, MSE(pi1): 4.351e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.162e-04\n",
      "Epoch 45600, Train loss: 1.781e+03, Test loss: 2.613e+04, MSE(e): 1.646e-04, MSE(pi1): 4.371e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.156e-04\n",
      "Epoch 45700, Train loss: 1.783e+03, Test loss: 2.612e+04, MSE(e): 1.648e-04, MSE(pi1): 4.390e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.123e-04\n",
      "Epoch 45800, Train loss: 1.779e+03, Test loss: 2.616e+04, MSE(e): 1.644e-04, MSE(pi1): 4.348e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.171e-04\n",
      "Epoch 45900, Train loss: 1.781e+03, Test loss: 2.614e+04, MSE(e): 1.645e-04, MSE(pi1): 4.362e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.157e-04\n",
      "Epoch 46000, Train loss: 1.784e+03, Test loss: 2.614e+04, MSE(e): 1.649e-04, MSE(pi1): 4.387e-03, MSE(pi2): 1.842e-04, MSE(pi3): 9.128e-04\n",
      "Epoch 46100, Train loss: 1.778e+03, Test loss: 2.617e+04, MSE(e): 1.643e-04, MSE(pi1): 4.366e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.137e-04\n",
      "Epoch 46200, Train loss: 1.780e+03, Test loss: 2.615e+04, MSE(e): 1.645e-04, MSE(pi1): 4.378e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.123e-04\n",
      "Epoch 46300, Train loss: 1.784e+03, Test loss: 2.616e+04, MSE(e): 1.649e-04, MSE(pi1): 4.384e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.118e-04\n",
      "Epoch 46400, Train loss: 1.778e+03, Test loss: 2.618e+04, MSE(e): 1.642e-04, MSE(pi1): 4.387e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.115e-04\n",
      "Epoch 46500, Train loss: 1.779e+03, Test loss: 2.616e+04, MSE(e): 1.644e-04, MSE(pi1): 4.368e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.135e-04\n",
      "Epoch 46600, Train loss: 1.785e+03, Test loss: 2.617e+04, MSE(e): 1.649e-04, MSE(pi1): 4.386e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.118e-04\n",
      "Epoch 46700, Train loss: 1.777e+03, Test loss: 2.619e+04, MSE(e): 1.642e-04, MSE(pi1): 4.380e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.117e-04\n",
      "Epoch 46800, Train loss: 1.778e+03, Test loss: 2.618e+04, MSE(e): 1.643e-04, MSE(pi1): 4.394e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.106e-04\n",
      "Epoch 46900, Train loss: 1.784e+03, Test loss: 2.619e+04, MSE(e): 1.649e-04, MSE(pi1): 4.379e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.119e-04\n",
      "Epoch 47000, Train loss: 1.776e+03, Test loss: 2.621e+04, MSE(e): 1.641e-04, MSE(pi1): 4.371e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.122e-04\n",
      "Epoch 47100, Train loss: 1.777e+03, Test loss: 2.619e+04, MSE(e): 1.642e-04, MSE(pi1): 4.392e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.101e-04\n",
      "Epoch 47200, Train loss: 1.782e+03, Test loss: 2.620e+04, MSE(e): 1.647e-04, MSE(pi1): 4.391e-03, MSE(pi2): 1.842e-04, MSE(pi3): 9.103e-04\n",
      "Epoch 47300, Train loss: 1.775e+03, Test loss: 2.622e+04, MSE(e): 1.640e-04, MSE(pi1): 4.381e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.113e-04\n",
      "Epoch 47400, Train loss: 1.776e+03, Test loss: 2.621e+04, MSE(e): 1.641e-04, MSE(pi1): 4.378e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.114e-04\n",
      "Epoch 47500, Train loss: 1.779e+03, Test loss: 2.621e+04, MSE(e): 1.644e-04, MSE(pi1): 4.387e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.100e-04\n",
      "Epoch 47600, Train loss: 1.774e+03, Test loss: 2.624e+04, MSE(e): 1.639e-04, MSE(pi1): 4.368e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.122e-04\n",
      "Epoch 47700, Train loss: 1.775e+03, Test loss: 2.622e+04, MSE(e): 1.640e-04, MSE(pi1): 4.375e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.114e-04\n",
      "Epoch 47800, Train loss: 1.777e+03, Test loss: 2.622e+04, MSE(e): 1.642e-04, MSE(pi1): 4.394e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.093e-04\n",
      "Epoch 47900, Train loss: 1.773e+03, Test loss: 2.626e+04, MSE(e): 1.638e-04, MSE(pi1): 4.363e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.118e-04\n",
      "Epoch 48000, Train loss: 1.774e+03, Test loss: 2.624e+04, MSE(e): 1.639e-04, MSE(pi1): 4.374e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.114e-04\n",
      "Epoch 48100, Train loss: 1.775e+03, Test loss: 2.623e+04, MSE(e): 1.640e-04, MSE(pi1): 4.369e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.118e-04\n",
      "Epoch 48200, Train loss: 1.772e+03, Test loss: 2.630e+04, MSE(e): 1.637e-04, MSE(pi1): 4.346e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.134e-04\n",
      "Epoch 48300, Train loss: 1.773e+03, Test loss: 2.626e+04, MSE(e): 1.638e-04, MSE(pi1): 4.371e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.115e-04\n",
      "Epoch 48400, Train loss: 1.774e+03, Test loss: 2.625e+04, MSE(e): 1.639e-04, MSE(pi1): 4.405e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.092e-04\n",
      "Epoch 48500, Train loss: 1.783e+03, Test loss: 2.627e+04, MSE(e): 1.648e-04, MSE(pi1): 4.355e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.122e-04\n",
      "Epoch 48600, Train loss: 1.772e+03, Test loss: 2.628e+04, MSE(e): 1.637e-04, MSE(pi1): 4.372e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.115e-04\n",
      "Epoch 48700, Train loss: 1.773e+03, Test loss: 2.627e+04, MSE(e): 1.638e-04, MSE(pi1): 4.365e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.112e-04\n",
      "Epoch 48800, Train loss: 1.775e+03, Test loss: 2.627e+04, MSE(e): 1.640e-04, MSE(pi1): 4.399e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.080e-04\n",
      "Epoch 48900, Train loss: 1.770e+03, Test loss: 2.631e+04, MSE(e): 1.635e-04, MSE(pi1): 4.358e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.115e-04\n",
      "Epoch 49000, Train loss: 1.771e+03, Test loss: 2.629e+04, MSE(e): 1.637e-04, MSE(pi1): 4.366e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.109e-04\n",
      "Epoch 49100, Train loss: 1.772e+03, Test loss: 2.628e+04, MSE(e): 1.637e-04, MSE(pi1): 4.377e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.094e-04\n",
      "Epoch 49200, Train loss: 1.779e+03, Test loss: 2.635e+04, MSE(e): 1.644e-04, MSE(pi1): 4.372e-03, MSE(pi2): 1.843e-04, MSE(pi3): 9.105e-04\n",
      "Epoch 49300, Train loss: 1.770e+03, Test loss: 2.631e+04, MSE(e): 1.635e-04, MSE(pi1): 4.352e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.116e-04\n",
      "Epoch 49400, Train loss: 1.771e+03, Test loss: 2.630e+04, MSE(e): 1.636e-04, MSE(pi1): 4.389e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.088e-04\n",
      "Epoch 49500, Train loss: 1.773e+03, Test loss: 2.630e+04, MSE(e): 1.638e-04, MSE(pi1): 4.363e-03, MSE(pi2): 1.840e-04, MSE(pi3): 9.108e-04\n",
      "Epoch 49600, Train loss: 1.768e+03, Test loss: 2.634e+04, MSE(e): 1.633e-04, MSE(pi1): 4.360e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.105e-04\n",
      "Epoch 49700, Train loss: 1.770e+03, Test loss: 2.632e+04, MSE(e): 1.635e-04, MSE(pi1): 4.363e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.103e-04\n",
      "Epoch 49800, Train loss: 1.770e+03, Test loss: 2.631e+04, MSE(e): 1.636e-04, MSE(pi1): 4.382e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.093e-04\n",
      "Epoch 49900, Train loss: 1.782e+03, Test loss: 2.635e+04, MSE(e): 1.647e-04, MSE(pi1): 4.340e-03, MSE(pi2): 1.845e-04, MSE(pi3): 9.127e-04\n",
      "Epoch 50000, Train loss: 1.768e+03, Test loss: 2.635e+04, MSE(e): 1.633e-04, MSE(pi1): 4.367e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.099e-04\n",
      "Epoch 50100, Train loss: 1.769e+03, Test loss: 2.633e+04, MSE(e): 1.634e-04, MSE(pi1): 4.378e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.086e-04\n",
      "Epoch 50200, Train loss: 1.770e+03, Test loss: 2.633e+04, MSE(e): 1.635e-04, MSE(pi1): 4.363e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.097e-04\n",
      "Epoch 50300, Train loss: 1.765e+03, Test loss: 2.639e+04, MSE(e): 1.631e-04, MSE(pi1): 4.321e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.135e-04\n",
      "Epoch 50400, Train loss: 1.767e+03, Test loss: 2.636e+04, MSE(e): 1.633e-04, MSE(pi1): 4.372e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.098e-04\n",
      "Epoch 50500, Train loss: 1.768e+03, Test loss: 2.635e+04, MSE(e): 1.633e-04, MSE(pi1): 4.373e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.086e-04\n",
      "Epoch 50600, Train loss: 1.770e+03, Test loss: 2.635e+04, MSE(e): 1.635e-04, MSE(pi1): 4.378e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.083e-04\n",
      "Epoch 50700, Train loss: 1.765e+03, Test loss: 2.640e+04, MSE(e): 1.630e-04, MSE(pi1): 4.349e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.114e-04\n",
      "Epoch 50800, Train loss: 1.767e+03, Test loss: 2.637e+04, MSE(e): 1.632e-04, MSE(pi1): 4.352e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.104e-04\n",
      "Epoch 50900, Train loss: 1.767e+03, Test loss: 2.636e+04, MSE(e): 1.633e-04, MSE(pi1): 4.379e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.079e-04\n",
      "Epoch 51000, Train loss: 1.770e+03, Test loss: 2.637e+04, MSE(e): 1.635e-04, MSE(pi1): 4.386e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.093e-04\n",
      "Epoch 51100, Train loss: 1.764e+03, Test loss: 2.641e+04, MSE(e): 1.629e-04, MSE(pi1): 4.336e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.123e-04\n",
      "Epoch 51200, Train loss: 1.766e+03, Test loss: 2.639e+04, MSE(e): 1.631e-04, MSE(pi1): 4.347e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.108e-04\n",
      "Epoch 51300, Train loss: 1.766e+03, Test loss: 2.638e+04, MSE(e): 1.632e-04, MSE(pi1): 4.391e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.068e-04\n",
      "Epoch 51400, Train loss: 1.768e+03, Test loss: 2.639e+04, MSE(e): 1.634e-04, MSE(pi1): 4.376e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.078e-04\n",
      "Epoch 51500, Train loss: 1.763e+03, Test loss: 2.643e+04, MSE(e): 1.628e-04, MSE(pi1): 4.335e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.114e-04\n",
      "Epoch 51600, Train loss: 1.765e+03, Test loss: 2.641e+04, MSE(e): 1.630e-04, MSE(pi1): 4.352e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.093e-04\n",
      "Epoch 51700, Train loss: 1.765e+03, Test loss: 2.640e+04, MSE(e): 1.631e-04, MSE(pi1): 4.380e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.077e-04\n",
      "Epoch 51800, Train loss: 1.767e+03, Test loss: 2.640e+04, MSE(e): 1.632e-04, MSE(pi1): 4.332e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.116e-04\n",
      "Epoch 51900, Train loss: 1.762e+03, Test loss: 2.646e+04, MSE(e): 1.627e-04, MSE(pi1): 4.364e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.093e-04\n",
      "Epoch 52000, Train loss: 1.764e+03, Test loss: 2.643e+04, MSE(e): 1.629e-04, MSE(pi1): 4.348e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.102e-04\n",
      "Epoch 52100, Train loss: 1.764e+03, Test loss: 2.642e+04, MSE(e): 1.630e-04, MSE(pi1): 4.375e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.075e-04\n",
      "Epoch 52200, Train loss: 1.765e+03, Test loss: 2.642e+04, MSE(e): 1.630e-04, MSE(pi1): 4.365e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.082e-04\n",
      "Epoch 52300, Train loss: 1.761e+03, Test loss: 2.648e+04, MSE(e): 1.626e-04, MSE(pi1): 4.308e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.143e-04\n",
      "Epoch 52400, Train loss: 1.762e+03, Test loss: 2.645e+04, MSE(e): 1.628e-04, MSE(pi1): 4.397e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.064e-04\n",
      "Epoch 52500, Train loss: 1.763e+03, Test loss: 2.644e+04, MSE(e): 1.629e-04, MSE(pi1): 4.346e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.093e-04\n",
      "Epoch 52600, Train loss: 1.763e+03, Test loss: 2.643e+04, MSE(e): 1.629e-04, MSE(pi1): 4.371e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.076e-04\n",
      "Epoch 52700, Train loss: 1.775e+03, Test loss: 2.647e+04, MSE(e): 1.641e-04, MSE(pi1): 4.341e-03, MSE(pi2): 1.844e-04, MSE(pi3): 9.106e-04\n",
      "Epoch 52800, Train loss: 1.761e+03, Test loss: 2.648e+04, MSE(e): 1.626e-04, MSE(pi1): 4.370e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.078e-04\n",
      "Epoch 52900, Train loss: 1.762e+03, Test loss: 2.646e+04, MSE(e): 1.627e-04, MSE(pi1): 4.344e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.090e-04\n",
      "Epoch 53000, Train loss: 1.762e+03, Test loss: 2.645e+04, MSE(e): 1.628e-04, MSE(pi1): 4.345e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.095e-04\n",
      "Epoch 53100, Train loss: 1.763e+03, Test loss: 2.646e+04, MSE(e): 1.629e-04, MSE(pi1): 4.376e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.068e-04\n",
      "Epoch 53200, Train loss: 1.759e+03, Test loss: 2.652e+04, MSE(e): 1.624e-04, MSE(pi1): 4.324e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.108e-04\n",
      "Epoch 53300, Train loss: 1.760e+03, Test loss: 2.649e+04, MSE(e): 1.626e-04, MSE(pi1): 4.332e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.107e-04\n",
      "Epoch 53400, Train loss: 1.761e+03, Test loss: 2.648e+04, MSE(e): 1.627e-04, MSE(pi1): 4.372e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.068e-04\n",
      "Epoch 53500, Train loss: 1.761e+03, Test loss: 2.647e+04, MSE(e): 1.627e-04, MSE(pi1): 4.355e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.079e-04\n",
      "Epoch 53600, Train loss: 1.768e+03, Test loss: 2.650e+04, MSE(e): 1.633e-04, MSE(pi1): 4.312e-03, MSE(pi2): 1.841e-04, MSE(pi3): 9.128e-04\n",
      "Epoch 53700, Train loss: 1.758e+03, Test loss: 2.653e+04, MSE(e): 1.624e-04, MSE(pi1): 4.352e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.102e-04\n",
      "Epoch 53800, Train loss: 1.760e+03, Test loss: 2.650e+04, MSE(e): 1.625e-04, MSE(pi1): 4.353e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.079e-04\n",
      "Epoch 53900, Train loss: 1.760e+03, Test loss: 2.649e+04, MSE(e): 1.626e-04, MSE(pi1): 4.362e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.070e-04\n",
      "Epoch 54000, Train loss: 1.760e+03, Test loss: 2.650e+04, MSE(e): 1.626e-04, MSE(pi1): 4.351e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.080e-04\n",
      "Epoch 54100, Train loss: 1.780e+03, Test loss: 2.658e+04, MSE(e): 1.645e-04, MSE(pi1): 4.335e-03, MSE(pi2): 1.849e-04, MSE(pi3): 9.112e-04\n",
      "Epoch 54200, Train loss: 1.758e+03, Test loss: 2.654e+04, MSE(e): 1.623e-04, MSE(pi1): 4.339e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.084e-04\n",
      "Epoch 54300, Train loss: 1.759e+03, Test loss: 2.652e+04, MSE(e): 1.624e-04, MSE(pi1): 4.361e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.068e-04\n",
      "Epoch 54400, Train loss: 1.759e+03, Test loss: 2.651e+04, MSE(e): 1.625e-04, MSE(pi1): 4.383e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.064e-04\n",
      "Epoch 54500, Train loss: 1.759e+03, Test loss: 2.652e+04, MSE(e): 1.625e-04, MSE(pi1): 4.329e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.094e-04\n",
      "Epoch 54600, Train loss: 1.762e+03, Test loss: 2.664e+04, MSE(e): 1.628e-04, MSE(pi1): 4.321e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.103e-04\n",
      "Epoch 54700, Train loss: 1.757e+03, Test loss: 2.656e+04, MSE(e): 1.622e-04, MSE(pi1): 4.337e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.090e-04\n",
      "Epoch 54800, Train loss: 1.758e+03, Test loss: 2.654e+04, MSE(e): 1.623e-04, MSE(pi1): 4.370e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.058e-04\n",
      "Epoch 54900, Train loss: 1.758e+03, Test loss: 2.653e+04, MSE(e): 1.624e-04, MSE(pi1): 4.366e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.059e-04\n",
      "Epoch 55000, Train loss: 1.758e+03, Test loss: 2.654e+04, MSE(e): 1.623e-04, MSE(pi1): 4.346e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.086e-04\n",
      "Epoch 55100, Train loss: 1.780e+03, Test loss: 2.660e+04, MSE(e): 1.645e-04, MSE(pi1): 4.286e-03, MSE(pi2): 1.849e-04, MSE(pi3): 9.155e-04\n",
      "Epoch 55200, Train loss: 1.755e+03, Test loss: 2.659e+04, MSE(e): 1.621e-04, MSE(pi1): 4.327e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.104e-04\n",
      "Epoch 55300, Train loss: 1.757e+03, Test loss: 2.657e+04, MSE(e): 1.622e-04, MSE(pi1): 4.339e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.079e-04\n",
      "Epoch 55400, Train loss: 1.757e+03, Test loss: 2.656e+04, MSE(e): 1.623e-04, MSE(pi1): 4.358e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.065e-04\n",
      "Epoch 55500, Train loss: 1.757e+03, Test loss: 2.656e+04, MSE(e): 1.622e-04, MSE(pi1): 4.369e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.056e-04\n",
      "Epoch 55600, Train loss: 1.761e+03, Test loss: 2.658e+04, MSE(e): 1.627e-04, MSE(pi1): 4.348e-03, MSE(pi2): 1.839e-04, MSE(pi3): 9.077e-04\n",
      "Epoch 55700, Train loss: 1.754e+03, Test loss: 2.662e+04, MSE(e): 1.619e-04, MSE(pi1): 4.327e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.091e-04\n",
      "Epoch 55800, Train loss: 1.755e+03, Test loss: 2.660e+04, MSE(e): 1.621e-04, MSE(pi1): 4.311e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.113e-04\n",
      "Epoch 55900, Train loss: 1.756e+03, Test loss: 2.658e+04, MSE(e): 1.622e-04, MSE(pi1): 4.375e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.053e-04\n",
      "Epoch 56000, Train loss: 1.756e+03, Test loss: 2.658e+04, MSE(e): 1.621e-04, MSE(pi1): 4.344e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.070e-04\n",
      "Epoch 56100, Train loss: 1.756e+03, Test loss: 2.659e+04, MSE(e): 1.621e-04, MSE(pi1): 4.343e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.073e-04\n",
      "Epoch 56200, Train loss: 1.752e+03, Test loss: 2.666e+04, MSE(e): 1.618e-04, MSE(pi1): 4.309e-03, MSE(pi2): 1.833e-04, MSE(pi3): 9.107e-04\n",
      "Epoch 56300, Train loss: 1.753e+03, Test loss: 2.663e+04, MSE(e): 1.619e-04, MSE(pi1): 4.357e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.070e-04\n",
      "Epoch 56400, Train loss: 1.755e+03, Test loss: 2.661e+04, MSE(e): 1.620e-04, MSE(pi1): 4.367e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.049e-04\n",
      "Epoch 56500, Train loss: 1.755e+03, Test loss: 2.660e+04, MSE(e): 1.621e-04, MSE(pi1): 4.369e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.049e-04\n",
      "Epoch 56600, Train loss: 1.754e+03, Test loss: 2.660e+04, MSE(e): 1.620e-04, MSE(pi1): 4.315e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.091e-04\n",
      "Epoch 56700, Train loss: 1.758e+03, Test loss: 2.662e+04, MSE(e): 1.623e-04, MSE(pi1): 4.304e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.114e-04\n",
      "Epoch 56800, Train loss: 1.751e+03, Test loss: 2.667e+04, MSE(e): 1.617e-04, MSE(pi1): 4.305e-03, MSE(pi2): 1.834e-04, MSE(pi3): 9.120e-04\n",
      "Epoch 56900, Train loss: 1.753e+03, Test loss: 2.664e+04, MSE(e): 1.619e-04, MSE(pi1): 4.334e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.075e-04\n",
      "Epoch 57000, Train loss: 1.754e+03, Test loss: 2.663e+04, MSE(e): 1.619e-04, MSE(pi1): 4.378e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.034e-04\n",
      "Epoch 57100, Train loss: 1.753e+03, Test loss: 2.662e+04, MSE(e): 1.619e-04, MSE(pi1): 4.337e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.067e-04\n",
      "Epoch 57200, Train loss: 1.752e+03, Test loss: 2.663e+04, MSE(e): 1.618e-04, MSE(pi1): 4.332e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.073e-04\n",
      "Epoch 57300, Train loss: 1.753e+03, Test loss: 2.664e+04, MSE(e): 1.619e-04, MSE(pi1): 4.311e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.095e-04\n",
      "Epoch 57400, Train loss: 1.750e+03, Test loss: 2.672e+04, MSE(e): 1.615e-04, MSE(pi1): 4.290e-03, MSE(pi2): 1.834e-04, MSE(pi3): 9.112e-04\n",
      "Epoch 57500, Train loss: 1.751e+03, Test loss: 2.669e+04, MSE(e): 1.617e-04, MSE(pi1): 4.391e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.037e-04\n",
      "Epoch 57600, Train loss: 1.752e+03, Test loss: 2.667e+04, MSE(e): 1.618e-04, MSE(pi1): 4.355e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.054e-04\n",
      "Epoch 57700, Train loss: 1.753e+03, Test loss: 2.666e+04, MSE(e): 1.618e-04, MSE(pi1): 4.332e-03, MSE(pi2): 1.836e-04, MSE(pi3): 9.069e-04\n",
      "Epoch 57800, Train loss: 1.752e+03, Test loss: 2.666e+04, MSE(e): 1.618e-04, MSE(pi1): 4.317e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.089e-04\n",
      "Epoch 57900, Train loss: 1.757e+03, Test loss: 2.668e+04, MSE(e): 1.623e-04, MSE(pi1): 4.290e-03, MSE(pi2): 1.838e-04, MSE(pi3): 9.110e-04\n",
      "Epoch 58000, Train loss: 1.749e+03, Test loss: 2.671e+04, MSE(e): 1.615e-04, MSE(pi1): 4.359e-03, MSE(pi2): 1.834e-04, MSE(pi3): 9.049e-04\n",
      "Epoch 58100, Train loss: 1.751e+03, Test loss: 2.669e+04, MSE(e): 1.617e-04, MSE(pi1): 4.339e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.063e-04\n",
      "Epoch 58200, Train loss: 1.751e+03, Test loss: 2.667e+04, MSE(e): 1.617e-04, MSE(pi1): 4.306e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.086e-04\n",
      "Epoch 58300, Train loss: 1.751e+03, Test loss: 2.667e+04, MSE(e): 1.617e-04, MSE(pi1): 4.303e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.091e-04\n",
      "Epoch 58400, Train loss: 1.750e+03, Test loss: 2.667e+04, MSE(e): 1.615e-04, MSE(pi1): 4.367e-03, MSE(pi2): 1.834e-04, MSE(pi3): 9.048e-04\n",
      "Epoch 58500, Train loss: 1.749e+03, Test loss: 2.668e+04, MSE(e): 1.615e-04, MSE(pi1): 4.310e-03, MSE(pi2): 1.833e-04, MSE(pi3): 9.098e-04\n",
      "Epoch 58600, Train loss: 1.748e+03, Test loss: 2.669e+04, MSE(e): 1.614e-04, MSE(pi1): 4.336e-03, MSE(pi2): 1.833e-04, MSE(pi3): 9.061e-04\n",
      "Epoch 58700, Train loss: 1.747e+03, Test loss: 2.669e+04, MSE(e): 1.613e-04, MSE(pi1): 4.332e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.063e-04\n",
      "Epoch 58800, Train loss: 1.747e+03, Test loss: 2.669e+04, MSE(e): 1.613e-04, MSE(pi1): 4.371e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.036e-04\n",
      "Epoch 58900, Train loss: 1.747e+03, Test loss: 2.669e+04, MSE(e): 1.612e-04, MSE(pi1): 4.319e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.075e-04\n",
      "Epoch 59000, Train loss: 1.746e+03, Test loss: 2.669e+04, MSE(e): 1.612e-04, MSE(pi1): 4.332e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.056e-04\n",
      "Epoch 59100, Train loss: 1.746e+03, Test loss: 2.669e+04, MSE(e): 1.612e-04, MSE(pi1): 4.312e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.083e-04\n",
      "Epoch 59200, Train loss: 1.746e+03, Test loss: 2.668e+04, MSE(e): 1.612e-04, MSE(pi1): 4.304e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.086e-04\n",
      "Epoch 59300, Train loss: 1.746e+03, Test loss: 2.668e+04, MSE(e): 1.611e-04, MSE(pi1): 4.348e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.057e-04\n",
      "Epoch 59400, Train loss: 1.745e+03, Test loss: 2.668e+04, MSE(e): 1.611e-04, MSE(pi1): 4.343e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.055e-04\n",
      "Epoch 59500, Train loss: 1.745e+03, Test loss: 2.668e+04, MSE(e): 1.611e-04, MSE(pi1): 4.309e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.080e-04\n",
      "Epoch 59600, Train loss: 1.745e+03, Test loss: 2.668e+04, MSE(e): 1.611e-04, MSE(pi1): 4.303e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.084e-04\n",
      "Epoch 59700, Train loss: 1.745e+03, Test loss: 2.668e+04, MSE(e): 1.610e-04, MSE(pi1): 4.329e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.079e-04\n",
      "Epoch 59800, Train loss: 1.744e+03, Test loss: 2.668e+04, MSE(e): 1.610e-04, MSE(pi1): 4.285e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.097e-04\n",
      "Epoch 59900, Train loss: 1.744e+03, Test loss: 2.668e+04, MSE(e): 1.610e-04, MSE(pi1): 4.350e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.049e-04\n",
      "Epoch 60000, Train loss: 1.744e+03, Test loss: 2.668e+04, MSE(e): 1.610e-04, MSE(pi1): 4.314e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.073e-04\n",
      "Epoch 60100, Train loss: 1.744e+03, Test loss: 2.668e+04, MSE(e): 1.610e-04, MSE(pi1): 4.296e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.088e-04\n",
      "Epoch 60200, Train loss: 1.743e+03, Test loss: 2.668e+04, MSE(e): 1.609e-04, MSE(pi1): 4.283e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.097e-04\n",
      "Epoch 60300, Train loss: 1.743e+03, Test loss: 2.669e+04, MSE(e): 1.609e-04, MSE(pi1): 4.339e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.057e-04\n",
      "Epoch 60400, Train loss: 1.743e+03, Test loss: 2.669e+04, MSE(e): 1.609e-04, MSE(pi1): 4.331e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.071e-04\n",
      "Epoch 60500, Train loss: 1.743e+03, Test loss: 2.669e+04, MSE(e): 1.609e-04, MSE(pi1): 4.304e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.081e-04\n",
      "Epoch 60600, Train loss: 1.743e+03, Test loss: 2.670e+04, MSE(e): 1.608e-04, MSE(pi1): 4.298e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.088e-04\n",
      "Epoch 60700, Train loss: 1.742e+03, Test loss: 2.670e+04, MSE(e): 1.608e-04, MSE(pi1): 4.313e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.069e-04\n",
      "Epoch 60800, Train loss: 1.742e+03, Test loss: 2.670e+04, MSE(e): 1.608e-04, MSE(pi1): 4.318e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.063e-04\n",
      "Epoch 60900, Train loss: 1.742e+03, Test loss: 2.670e+04, MSE(e): 1.608e-04, MSE(pi1): 4.316e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.064e-04\n",
      "Epoch 61000, Train loss: 1.742e+03, Test loss: 2.671e+04, MSE(e): 1.608e-04, MSE(pi1): 4.297e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.080e-04\n",
      "Epoch 61100, Train loss: 1.741e+03, Test loss: 2.671e+04, MSE(e): 1.607e-04, MSE(pi1): 4.289e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.089e-04\n",
      "Epoch 61200, Train loss: 1.741e+03, Test loss: 2.671e+04, MSE(e): 1.607e-04, MSE(pi1): 4.288e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.088e-04\n",
      "Epoch 61300, Train loss: 1.741e+03, Test loss: 2.672e+04, MSE(e): 1.607e-04, MSE(pi1): 4.284e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.088e-04\n",
      "Epoch 61400, Train loss: 1.741e+03, Test loss: 2.672e+04, MSE(e): 1.607e-04, MSE(pi1): 4.337e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.054e-04\n",
      "Epoch 61500, Train loss: 1.741e+03, Test loss: 2.673e+04, MSE(e): 1.607e-04, MSE(pi1): 4.285e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.089e-04\n",
      "Epoch 61600, Train loss: 1.740e+03, Test loss: 2.673e+04, MSE(e): 1.606e-04, MSE(pi1): 4.307e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.067e-04\n",
      "Epoch 61700, Train loss: 1.740e+03, Test loss: 2.673e+04, MSE(e): 1.606e-04, MSE(pi1): 4.320e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.067e-04\n",
      "Epoch 61800, Train loss: 1.740e+03, Test loss: 2.674e+04, MSE(e): 1.606e-04, MSE(pi1): 4.307e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.066e-04\n",
      "Epoch 61900, Train loss: 1.740e+03, Test loss: 2.674e+04, MSE(e): 1.606e-04, MSE(pi1): 4.326e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.050e-04\n",
      "Epoch 62000, Train loss: 1.740e+03, Test loss: 2.675e+04, MSE(e): 1.606e-04, MSE(pi1): 4.305e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.073e-04\n",
      "Epoch 62100, Train loss: 1.739e+03, Test loss: 2.675e+04, MSE(e): 1.605e-04, MSE(pi1): 4.278e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.098e-04\n",
      "Epoch 62200, Train loss: 1.739e+03, Test loss: 2.675e+04, MSE(e): 1.605e-04, MSE(pi1): 4.296e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.082e-04\n",
      "Epoch 62300, Train loss: 1.739e+03, Test loss: 2.676e+04, MSE(e): 1.605e-04, MSE(pi1): 4.322e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.071e-04\n",
      "Epoch 62400, Train loss: 1.739e+03, Test loss: 2.676e+04, MSE(e): 1.605e-04, MSE(pi1): 4.293e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.075e-04\n",
      "Epoch 62500, Train loss: 1.739e+03, Test loss: 2.677e+04, MSE(e): 1.605e-04, MSE(pi1): 4.342e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.050e-04\n",
      "Epoch 62600, Train loss: 1.738e+03, Test loss: 2.677e+04, MSE(e): 1.605e-04, MSE(pi1): 4.296e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.069e-04\n",
      "Epoch 62700, Train loss: 1.738e+03, Test loss: 2.677e+04, MSE(e): 1.604e-04, MSE(pi1): 4.338e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.039e-04\n",
      "Epoch 62800, Train loss: 1.738e+03, Test loss: 2.678e+04, MSE(e): 1.604e-04, MSE(pi1): 4.322e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.048e-04\n",
      "Epoch 62900, Train loss: 1.738e+03, Test loss: 2.678e+04, MSE(e): 1.604e-04, MSE(pi1): 4.294e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.076e-04\n",
      "Epoch 63000, Train loss: 1.738e+03, Test loss: 2.679e+04, MSE(e): 1.604e-04, MSE(pi1): 4.268e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.092e-04\n",
      "Epoch 63100, Train loss: 1.737e+03, Test loss: 2.679e+04, MSE(e): 1.604e-04, MSE(pi1): 4.275e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.086e-04\n",
      "Epoch 63200, Train loss: 1.737e+03, Test loss: 2.680e+04, MSE(e): 1.603e-04, MSE(pi1): 4.276e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.095e-04\n",
      "Epoch 63300, Train loss: 1.737e+03, Test loss: 2.680e+04, MSE(e): 1.603e-04, MSE(pi1): 4.279e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.088e-04\n",
      "Epoch 63400, Train loss: 1.737e+03, Test loss: 2.680e+04, MSE(e): 1.603e-04, MSE(pi1): 4.336e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.040e-04\n",
      "Epoch 63500, Train loss: 1.737e+03, Test loss: 2.681e+04, MSE(e): 1.603e-04, MSE(pi1): 4.311e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.055e-04\n",
      "Epoch 63600, Train loss: 1.737e+03, Test loss: 2.681e+04, MSE(e): 1.603e-04, MSE(pi1): 4.276e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.089e-04\n",
      "Epoch 63700, Train loss: 1.736e+03, Test loss: 2.682e+04, MSE(e): 1.603e-04, MSE(pi1): 4.285e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.084e-04\n",
      "Epoch 63800, Train loss: 1.736e+03, Test loss: 2.682e+04, MSE(e): 1.602e-04, MSE(pi1): 4.300e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.065e-04\n",
      "Epoch 63900, Train loss: 1.736e+03, Test loss: 2.682e+04, MSE(e): 1.602e-04, MSE(pi1): 4.317e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.050e-04\n",
      "Epoch 64000, Train loss: 1.736e+03, Test loss: 2.683e+04, MSE(e): 1.602e-04, MSE(pi1): 4.286e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.082e-04\n",
      "Epoch 64100, Train loss: 1.736e+03, Test loss: 2.683e+04, MSE(e): 1.602e-04, MSE(pi1): 4.253e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.100e-04\n",
      "Epoch 64200, Train loss: 1.736e+03, Test loss: 2.684e+04, MSE(e): 1.602e-04, MSE(pi1): 4.308e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.070e-04\n",
      "Epoch 64300, Train loss: 1.735e+03, Test loss: 2.684e+04, MSE(e): 1.602e-04, MSE(pi1): 4.287e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.071e-04\n",
      "Epoch 64400, Train loss: 1.735e+03, Test loss: 2.685e+04, MSE(e): 1.601e-04, MSE(pi1): 4.311e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.054e-04\n",
      "Epoch 64500, Train loss: 1.735e+03, Test loss: 2.685e+04, MSE(e): 1.601e-04, MSE(pi1): 4.320e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.048e-04\n",
      "Epoch 64600, Train loss: 1.735e+03, Test loss: 2.685e+04, MSE(e): 1.601e-04, MSE(pi1): 4.293e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.067e-04\n",
      "Epoch 64700, Train loss: 1.735e+03, Test loss: 2.686e+04, MSE(e): 1.601e-04, MSE(pi1): 4.290e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.070e-04\n",
      "Epoch 64800, Train loss: 1.734e+03, Test loss: 2.686e+04, MSE(e): 1.601e-04, MSE(pi1): 4.300e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.061e-04\n",
      "Epoch 64900, Train loss: 1.734e+03, Test loss: 2.687e+04, MSE(e): 1.601e-04, MSE(pi1): 4.283e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.071e-04\n",
      "Epoch 65000, Train loss: 1.734e+03, Test loss: 2.687e+04, MSE(e): 1.600e-04, MSE(pi1): 4.291e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.061e-04\n",
      "Epoch 65100, Train loss: 1.734e+03, Test loss: 2.687e+04, MSE(e): 1.600e-04, MSE(pi1): 4.257e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.098e-04\n",
      "Epoch 65200, Train loss: 1.734e+03, Test loss: 2.688e+04, MSE(e): 1.600e-04, MSE(pi1): 4.269e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.088e-04\n",
      "Epoch 65300, Train loss: 1.734e+03, Test loss: 2.688e+04, MSE(e): 1.600e-04, MSE(pi1): 4.308e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.071e-04\n",
      "Epoch 65400, Train loss: 1.733e+03, Test loss: 2.689e+04, MSE(e): 1.600e-04, MSE(pi1): 4.293e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.061e-04\n",
      "Epoch 65500, Train loss: 1.733e+03, Test loss: 2.689e+04, MSE(e): 1.600e-04, MSE(pi1): 4.289e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.070e-04\n",
      "Epoch 65600, Train loss: 1.733e+03, Test loss: 2.690e+04, MSE(e): 1.599e-04, MSE(pi1): 4.240e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.120e-04\n",
      "Epoch 65700, Train loss: 1.733e+03, Test loss: 2.690e+04, MSE(e): 1.599e-04, MSE(pi1): 4.255e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.116e-04\n",
      "Epoch 65800, Train loss: 1.733e+03, Test loss: 2.690e+04, MSE(e): 1.599e-04, MSE(pi1): 4.250e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.117e-04\n",
      "Epoch 65900, Train loss: 1.733e+03, Test loss: 2.691e+04, MSE(e): 1.599e-04, MSE(pi1): 4.309e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.050e-04\n",
      "Epoch 66000, Train loss: 1.733e+03, Test loss: 2.691e+04, MSE(e): 1.599e-04, MSE(pi1): 4.269e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.098e-04\n",
      "Epoch 66100, Train loss: 1.732e+03, Test loss: 2.692e+04, MSE(e): 1.599e-04, MSE(pi1): 4.279e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.093e-04\n",
      "Epoch 66200, Train loss: 1.732e+03, Test loss: 2.692e+04, MSE(e): 1.598e-04, MSE(pi1): 4.253e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.105e-04\n",
      "Epoch 66300, Train loss: 1.732e+03, Test loss: 2.693e+04, MSE(e): 1.598e-04, MSE(pi1): 4.269e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.107e-04\n",
      "Epoch 66400, Train loss: 1.732e+03, Test loss: 2.693e+04, MSE(e): 1.598e-04, MSE(pi1): 4.302e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.068e-04\n",
      "Epoch 66500, Train loss: 1.732e+03, Test loss: 2.693e+04, MSE(e): 1.598e-04, MSE(pi1): 4.266e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.107e-04\n",
      "Epoch 66600, Train loss: 1.732e+03, Test loss: 2.694e+04, MSE(e): 1.598e-04, MSE(pi1): 4.261e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.142e-04\n",
      "Epoch 66700, Train loss: 1.731e+03, Test loss: 2.694e+04, MSE(e): 1.598e-04, MSE(pi1): 4.254e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.107e-04\n",
      "Epoch 66800, Train loss: 1.731e+03, Test loss: 2.695e+04, MSE(e): 1.597e-04, MSE(pi1): 4.263e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.091e-04\n",
      "Epoch 66900, Train loss: 1.731e+03, Test loss: 2.695e+04, MSE(e): 1.597e-04, MSE(pi1): 4.301e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.059e-04\n",
      "Epoch 67000, Train loss: 1.731e+03, Test loss: 2.695e+04, MSE(e): 1.597e-04, MSE(pi1): 4.240e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.124e-04\n",
      "Epoch 67100, Train loss: 1.731e+03, Test loss: 2.696e+04, MSE(e): 1.597e-04, MSE(pi1): 4.239e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.125e-04\n",
      "Epoch 67200, Train loss: 1.730e+03, Test loss: 2.696e+04, MSE(e): 1.597e-04, MSE(pi1): 4.244e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.110e-04\n",
      "Epoch 67300, Train loss: 1.731e+03, Test loss: 2.697e+04, MSE(e): 1.597e-04, MSE(pi1): 4.230e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.140e-04\n",
      "Epoch 67400, Train loss: 1.730e+03, Test loss: 2.697e+04, MSE(e): 1.596e-04, MSE(pi1): 4.292e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.048e-04\n",
      "Epoch 67500, Train loss: 1.730e+03, Test loss: 2.697e+04, MSE(e): 1.596e-04, MSE(pi1): 4.275e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.078e-04\n",
      "Epoch 67600, Train loss: 1.730e+03, Test loss: 2.698e+04, MSE(e): 1.596e-04, MSE(pi1): 4.269e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.088e-04\n",
      "Epoch 67700, Train loss: 1.730e+03, Test loss: 2.698e+04, MSE(e): 1.596e-04, MSE(pi1): 4.261e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.110e-04\n",
      "Epoch 67800, Train loss: 1.730e+03, Test loss: 2.699e+04, MSE(e): 1.596e-04, MSE(pi1): 4.237e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.131e-04\n",
      "Epoch 67900, Train loss: 1.730e+03, Test loss: 2.699e+04, MSE(e): 1.596e-04, MSE(pi1): 4.307e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.075e-04\n",
      "Epoch 68000, Train loss: 1.729e+03, Test loss: 2.700e+04, MSE(e): 1.596e-04, MSE(pi1): 4.264e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.096e-04\n",
      "Epoch 68100, Train loss: 1.729e+03, Test loss: 2.700e+04, MSE(e): 1.595e-04, MSE(pi1): 4.273e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.082e-04\n",
      "Epoch 68200, Train loss: 1.729e+03, Test loss: 2.700e+04, MSE(e): 1.595e-04, MSE(pi1): 4.247e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.128e-04\n",
      "Epoch 68300, Train loss: 1.729e+03, Test loss: 2.701e+04, MSE(e): 1.595e-04, MSE(pi1): 4.241e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.123e-04\n",
      "Epoch 68400, Train loss: 1.729e+03, Test loss: 2.701e+04, MSE(e): 1.595e-04, MSE(pi1): 4.271e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.085e-04\n",
      "Epoch 68500, Train loss: 1.729e+03, Test loss: 2.702e+04, MSE(e): 1.595e-04, MSE(pi1): 4.253e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.100e-04\n",
      "Epoch 68600, Train loss: 1.729e+03, Test loss: 2.702e+04, MSE(e): 1.595e-04, MSE(pi1): 4.293e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.073e-04\n",
      "Epoch 68700, Train loss: 1.728e+03, Test loss: 2.703e+04, MSE(e): 1.594e-04, MSE(pi1): 4.246e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.094e-04\n",
      "Epoch 68800, Train loss: 1.728e+03, Test loss: 2.703e+04, MSE(e): 1.594e-04, MSE(pi1): 4.258e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.111e-04\n",
      "Epoch 68900, Train loss: 1.728e+03, Test loss: 2.704e+04, MSE(e): 1.594e-04, MSE(pi1): 4.249e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.114e-04\n",
      "Epoch 69000, Train loss: 1.728e+03, Test loss: 2.705e+04, MSE(e): 1.594e-04, MSE(pi1): 4.276e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.071e-04\n",
      "Epoch 69100, Train loss: 1.728e+03, Test loss: 2.706e+04, MSE(e): 1.594e-04, MSE(pi1): 4.279e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.079e-04\n",
      "Epoch 69200, Train loss: 1.729e+03, Test loss: 2.715e+04, MSE(e): 1.595e-04, MSE(pi1): 4.258e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.118e-04\n",
      "Epoch 69300, Train loss: 1.730e+03, Test loss: 2.714e+04, MSE(e): 1.596e-04, MSE(pi1): 4.281e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.105e-04\n",
      "Epoch 69400, Train loss: 1.731e+03, Test loss: 2.713e+04, MSE(e): 1.597e-04, MSE(pi1): 4.255e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.092e-04\n",
      "Epoch 69500, Train loss: 1.732e+03, Test loss: 2.713e+04, MSE(e): 1.598e-04, MSE(pi1): 4.275e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.083e-04\n",
      "Epoch 69600, Train loss: 1.732e+03, Test loss: 2.714e+04, MSE(e): 1.598e-04, MSE(pi1): 4.282e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.103e-04\n",
      "Epoch 69700, Train loss: 1.732e+03, Test loss: 2.714e+04, MSE(e): 1.598e-04, MSE(pi1): 4.279e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.059e-04\n",
      "Epoch 69800, Train loss: 1.734e+03, Test loss: 2.715e+04, MSE(e): 1.600e-04, MSE(pi1): 4.277e-03, MSE(pi2): 1.834e-04, MSE(pi3): 9.098e-04\n",
      "Epoch 69900, Train loss: 1.730e+03, Test loss: 2.714e+04, MSE(e): 1.596e-04, MSE(pi1): 4.283e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.059e-04\n",
      "Epoch 70000, Train loss: 1.730e+03, Test loss: 2.712e+04, MSE(e): 1.596e-04, MSE(pi1): 4.244e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.097e-04\n",
      "Epoch 70100, Train loss: 1.739e+03, Test loss: 2.711e+04, MSE(e): 1.606e-04, MSE(pi1): 4.294e-03, MSE(pi2): 1.837e-04, MSE(pi3): 9.034e-04\n",
      "Epoch 70200, Train loss: 1.729e+03, Test loss: 2.714e+04, MSE(e): 1.595e-04, MSE(pi1): 4.276e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.061e-04\n",
      "Epoch 70300, Train loss: 1.730e+03, Test loss: 2.712e+04, MSE(e): 1.597e-04, MSE(pi1): 4.279e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.047e-04\n",
      "Epoch 70400, Train loss: 1.734e+03, Test loss: 2.712e+04, MSE(e): 1.600e-04, MSE(pi1): 4.272e-03, MSE(pi2): 1.834e-04, MSE(pi3): 9.068e-04\n",
      "Epoch 70500, Train loss: 1.728e+03, Test loss: 2.715e+04, MSE(e): 1.595e-04, MSE(pi1): 4.248e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.090e-04\n",
      "Epoch 70600, Train loss: 1.729e+03, Test loss: 2.711e+04, MSE(e): 1.596e-04, MSE(pi1): 4.311e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.030e-04\n",
      "Epoch 70700, Train loss: 1.731e+03, Test loss: 2.710e+04, MSE(e): 1.597e-04, MSE(pi1): 4.264e-03, MSE(pi2): 1.833e-04, MSE(pi3): 9.080e-04\n",
      "Epoch 70800, Train loss: 1.727e+03, Test loss: 2.717e+04, MSE(e): 1.593e-04, MSE(pi1): 4.240e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.140e-04\n",
      "Epoch 70900, Train loss: 1.729e+03, Test loss: 2.714e+04, MSE(e): 1.595e-04, MSE(pi1): 4.267e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.088e-04\n",
      "Epoch 71000, Train loss: 1.730e+03, Test loss: 2.712e+04, MSE(e): 1.596e-04, MSE(pi1): 4.298e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.031e-04\n",
      "Epoch 71100, Train loss: 1.734e+03, Test loss: 2.712e+04, MSE(e): 1.601e-04, MSE(pi1): 4.252e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.090e-04\n",
      "Epoch 71200, Train loss: 1.727e+03, Test loss: 2.716e+04, MSE(e): 1.594e-04, MSE(pi1): 4.243e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.123e-04\n",
      "Epoch 71300, Train loss: 1.729e+03, Test loss: 2.713e+04, MSE(e): 1.595e-04, MSE(pi1): 4.267e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.066e-04\n",
      "Epoch 71400, Train loss: 1.730e+03, Test loss: 2.711e+04, MSE(e): 1.596e-04, MSE(pi1): 4.237e-03, MSE(pi2): 1.833e-04, MSE(pi3): 9.112e-04\n",
      "Epoch 71500, Train loss: 1.731e+03, Test loss: 2.713e+04, MSE(e): 1.598e-04, MSE(pi1): 4.290e-03, MSE(pi2): 1.834e-04, MSE(pi3): 9.040e-04\n",
      "Epoch 71600, Train loss: 1.726e+03, Test loss: 2.719e+04, MSE(e): 1.592e-04, MSE(pi1): 4.243e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.103e-04\n",
      "Epoch 71700, Train loss: 1.728e+03, Test loss: 2.715e+04, MSE(e): 1.594e-04, MSE(pi1): 4.274e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.077e-04\n",
      "Epoch 71800, Train loss: 1.729e+03, Test loss: 2.714e+04, MSE(e): 1.595e-04, MSE(pi1): 4.272e-03, MSE(pi2): 1.833e-04, MSE(pi3): 9.084e-04\n",
      "Epoch 71900, Train loss: 1.730e+03, Test loss: 2.714e+04, MSE(e): 1.597e-04, MSE(pi1): 4.288e-03, MSE(pi2): 1.834e-04, MSE(pi3): 9.055e-04\n",
      "Epoch 72000, Train loss: 1.725e+03, Test loss: 2.721e+04, MSE(e): 1.592e-04, MSE(pi1): 4.258e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.063e-04\n",
      "Epoch 72100, Train loss: 1.727e+03, Test loss: 2.717e+04, MSE(e): 1.594e-04, MSE(pi1): 4.272e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.049e-04\n",
      "Epoch 72200, Train loss: 1.728e+03, Test loss: 2.715e+04, MSE(e): 1.595e-04, MSE(pi1): 4.255e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.068e-04\n",
      "Epoch 72300, Train loss: 1.728e+03, Test loss: 2.714e+04, MSE(e): 1.594e-04, MSE(pi1): 4.273e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.046e-04\n",
      "Epoch 72400, Train loss: 1.727e+03, Test loss: 2.715e+04, MSE(e): 1.594e-04, MSE(pi1): 4.289e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.036e-04\n",
      "Epoch 72500, Train loss: 1.727e+03, Test loss: 2.717e+04, MSE(e): 1.594e-04, MSE(pi1): 4.291e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.021e-04\n",
      "Epoch 72600, Train loss: 1.724e+03, Test loss: 2.727e+04, MSE(e): 1.591e-04, MSE(pi1): 4.248e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.056e-04\n",
      "Epoch 72700, Train loss: 1.726e+03, Test loss: 2.723e+04, MSE(e): 1.592e-04, MSE(pi1): 4.278e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.040e-04\n",
      "Epoch 72800, Train loss: 1.727e+03, Test loss: 2.720e+04, MSE(e): 1.594e-04, MSE(pi1): 4.305e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.008e-04\n",
      "Epoch 72900, Train loss: 1.728e+03, Test loss: 2.719e+04, MSE(e): 1.594e-04, MSE(pi1): 4.331e-03, MSE(pi2): 1.833e-04, MSE(pi3): 9.001e-04\n",
      "Epoch 73000, Train loss: 1.731e+03, Test loss: 2.719e+04, MSE(e): 1.598e-04, MSE(pi1): 4.306e-03, MSE(pi2): 1.835e-04, MSE(pi3): 9.011e-04\n",
      "Epoch 73100, Train loss: 1.724e+03, Test loss: 2.723e+04, MSE(e): 1.591e-04, MSE(pi1): 4.277e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.030e-04\n",
      "Epoch 73200, Train loss: 1.726e+03, Test loss: 2.720e+04, MSE(e): 1.593e-04, MSE(pi1): 4.303e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.030e-04\n",
      "Epoch 73300, Train loss: 1.727e+03, Test loss: 2.718e+04, MSE(e): 1.593e-04, MSE(pi1): 4.270e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.039e-04\n",
      "Epoch 73400, Train loss: 1.725e+03, Test loss: 2.718e+04, MSE(e): 1.592e-04, MSE(pi1): 4.284e-03, MSE(pi2): 1.832e-04, MSE(pi3): 9.030e-04\n",
      "Epoch 73500, Train loss: 1.724e+03, Test loss: 2.718e+04, MSE(e): 1.591e-04, MSE(pi1): 4.269e-03, MSE(pi2): 1.831e-04, MSE(pi3): 9.042e-04\n",
      "Epoch 73600, Train loss: 1.724e+03, Test loss: 2.719e+04, MSE(e): 1.590e-04, MSE(pi1): 4.267e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.050e-04\n",
      "Epoch 73700, Train loss: 1.724e+03, Test loss: 2.718e+04, MSE(e): 1.590e-04, MSE(pi1): 4.281e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.059e-04\n",
      "Epoch 73800, Train loss: 1.723e+03, Test loss: 2.718e+04, MSE(e): 1.590e-04, MSE(pi1): 4.228e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.079e-04\n",
      "Epoch 73900, Train loss: 1.723e+03, Test loss: 2.717e+04, MSE(e): 1.590e-04, MSE(pi1): 4.214e-03, MSE(pi2): 1.830e-04, MSE(pi3): 9.107e-04\n",
      "Epoch 74000, Train loss: 1.723e+03, Test loss: 2.717e+04, MSE(e): 1.589e-04, MSE(pi1): 4.241e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.067e-04\n",
      "Epoch 74100, Train loss: 1.723e+03, Test loss: 2.716e+04, MSE(e): 1.589e-04, MSE(pi1): 4.243e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.088e-04\n",
      "Epoch 74200, Train loss: 1.722e+03, Test loss: 2.716e+04, MSE(e): 1.589e-04, MSE(pi1): 4.254e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.058e-04\n",
      "Epoch 74300, Train loss: 1.722e+03, Test loss: 2.716e+04, MSE(e): 1.589e-04, MSE(pi1): 4.243e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.065e-04\n",
      "Epoch 74400, Train loss: 1.722e+03, Test loss: 2.716e+04, MSE(e): 1.589e-04, MSE(pi1): 4.231e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.092e-04\n",
      "Epoch 74500, Train loss: 1.722e+03, Test loss: 2.716e+04, MSE(e): 1.589e-04, MSE(pi1): 4.279e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.033e-04\n",
      "Epoch 74600, Train loss: 1.722e+03, Test loss: 2.716e+04, MSE(e): 1.588e-04, MSE(pi1): 4.329e-03, MSE(pi2): 1.829e-04, MSE(pi3): 8.993e-04\n",
      "Epoch 74700, Train loss: 1.722e+03, Test loss: 2.716e+04, MSE(e): 1.588e-04, MSE(pi1): 4.228e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.086e-04\n",
      "Epoch 74800, Train loss: 1.721e+03, Test loss: 2.717e+04, MSE(e): 1.588e-04, MSE(pi1): 4.272e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.029e-04\n",
      "Epoch 74900, Train loss: 1.721e+03, Test loss: 2.717e+04, MSE(e): 1.588e-04, MSE(pi1): 4.211e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.097e-04\n",
      "Epoch 75000, Train loss: 1.721e+03, Test loss: 2.717e+04, MSE(e): 1.588e-04, MSE(pi1): 4.274e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.028e-04\n",
      "Epoch 75100, Train loss: 1.721e+03, Test loss: 2.717e+04, MSE(e): 1.588e-04, MSE(pi1): 4.217e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.087e-04\n",
      "Epoch 75200, Train loss: 1.721e+03, Test loss: 2.717e+04, MSE(e): 1.588e-04, MSE(pi1): 4.244e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.049e-04\n",
      "Epoch 75300, Train loss: 1.721e+03, Test loss: 2.718e+04, MSE(e): 1.587e-04, MSE(pi1): 4.268e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.038e-04\n",
      "Epoch 75400, Train loss: 1.720e+03, Test loss: 2.718e+04, MSE(e): 1.587e-04, MSE(pi1): 4.256e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.041e-04\n",
      "Epoch 75500, Train loss: 1.720e+03, Test loss: 2.718e+04, MSE(e): 1.587e-04, MSE(pi1): 4.254e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.045e-04\n",
      "Epoch 75600, Train loss: 1.720e+03, Test loss: 2.719e+04, MSE(e): 1.587e-04, MSE(pi1): 4.251e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.058e-04\n",
      "Epoch 75700, Train loss: 1.720e+03, Test loss: 2.719e+04, MSE(e): 1.587e-04, MSE(pi1): 4.219e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.076e-04\n",
      "Epoch 75800, Train loss: 1.720e+03, Test loss: 2.719e+04, MSE(e): 1.587e-04, MSE(pi1): 4.250e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.092e-04\n",
      "Epoch 75900, Train loss: 1.720e+03, Test loss: 2.719e+04, MSE(e): 1.587e-04, MSE(pi1): 4.243e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.069e-04\n",
      "Epoch 76000, Train loss: 1.720e+03, Test loss: 2.720e+04, MSE(e): 1.587e-04, MSE(pi1): 4.273e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.047e-04\n",
      "Epoch 76100, Train loss: 1.720e+03, Test loss: 2.720e+04, MSE(e): 1.586e-04, MSE(pi1): 4.253e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.040e-04\n",
      "Epoch 76200, Train loss: 1.720e+03, Test loss: 2.720e+04, MSE(e): 1.586e-04, MSE(pi1): 4.273e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.031e-04\n",
      "Epoch 76300, Train loss: 1.720e+03, Test loss: 2.720e+04, MSE(e): 1.586e-04, MSE(pi1): 4.273e-03, MSE(pi2): 1.829e-04, MSE(pi3): 9.055e-04\n",
      "Epoch 76400, Train loss: 1.719e+03, Test loss: 2.721e+04, MSE(e): 1.586e-04, MSE(pi1): 4.240e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.086e-04\n",
      "Epoch 76500, Train loss: 1.719e+03, Test loss: 2.721e+04, MSE(e): 1.586e-04, MSE(pi1): 4.205e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.107e-04\n",
      "Epoch 76600, Train loss: 1.720e+03, Test loss: 2.721e+04, MSE(e): 1.586e-04, MSE(pi1): 4.223e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.151e-04\n",
      "Epoch 76700, Train loss: 1.719e+03, Test loss: 2.721e+04, MSE(e): 1.586e-04, MSE(pi1): 4.264e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.034e-04\n",
      "Epoch 76800, Train loss: 1.719e+03, Test loss: 2.722e+04, MSE(e): 1.586e-04, MSE(pi1): 4.272e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.020e-04\n",
      "Epoch 76900, Train loss: 1.719e+03, Test loss: 2.722e+04, MSE(e): 1.585e-04, MSE(pi1): 4.269e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.039e-04\n",
      "Epoch 77000, Train loss: 1.718e+03, Test loss: 2.722e+04, MSE(e): 1.585e-04, MSE(pi1): 4.220e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.073e-04\n",
      "Epoch 77100, Train loss: 1.718e+03, Test loss: 2.722e+04, MSE(e): 1.585e-04, MSE(pi1): 4.224e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.075e-04\n",
      "Epoch 77200, Train loss: 1.718e+03, Test loss: 2.723e+04, MSE(e): 1.585e-04, MSE(pi1): 4.228e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.056e-04\n",
      "Epoch 77300, Train loss: 1.718e+03, Test loss: 2.723e+04, MSE(e): 1.585e-04, MSE(pi1): 4.275e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.031e-04\n",
      "Epoch 77400, Train loss: 1.718e+03, Test loss: 2.723e+04, MSE(e): 1.585e-04, MSE(pi1): 4.324e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.007e-04\n",
      "Epoch 77500, Train loss: 1.718e+03, Test loss: 2.724e+04, MSE(e): 1.585e-04, MSE(pi1): 4.236e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.084e-04\n",
      "Epoch 77600, Train loss: 1.718e+03, Test loss: 2.724e+04, MSE(e): 1.585e-04, MSE(pi1): 4.255e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.035e-04\n",
      "Epoch 77700, Train loss: 1.718e+03, Test loss: 2.724e+04, MSE(e): 1.584e-04, MSE(pi1): 4.273e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.017e-04\n",
      "Epoch 77800, Train loss: 1.717e+03, Test loss: 2.724e+04, MSE(e): 1.584e-04, MSE(pi1): 4.205e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.086e-04\n",
      "Epoch 77900, Train loss: 1.717e+03, Test loss: 2.725e+04, MSE(e): 1.584e-04, MSE(pi1): 4.231e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.056e-04\n",
      "Epoch 78000, Train loss: 1.717e+03, Test loss: 2.725e+04, MSE(e): 1.584e-04, MSE(pi1): 4.244e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.053e-04\n",
      "Epoch 78100, Train loss: 1.718e+03, Test loss: 2.725e+04, MSE(e): 1.584e-04, MSE(pi1): 4.269e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.064e-04\n",
      "Epoch 78200, Train loss: 1.717e+03, Test loss: 2.725e+04, MSE(e): 1.584e-04, MSE(pi1): 4.218e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.086e-04\n",
      "Epoch 78300, Train loss: 1.717e+03, Test loss: 2.726e+04, MSE(e): 1.584e-04, MSE(pi1): 4.203e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.102e-04\n",
      "Epoch 78400, Train loss: 1.717e+03, Test loss: 2.726e+04, MSE(e): 1.584e-04, MSE(pi1): 4.217e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.106e-04\n",
      "Epoch 78500, Train loss: 1.716e+03, Test loss: 2.726e+04, MSE(e): 1.584e-04, MSE(pi1): 4.243e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.037e-04\n",
      "Epoch 78600, Train loss: 1.716e+03, Test loss: 2.726e+04, MSE(e): 1.583e-04, MSE(pi1): 4.252e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.028e-04\n",
      "Epoch 78700, Train loss: 1.717e+03, Test loss: 2.727e+04, MSE(e): 1.583e-04, MSE(pi1): 4.301e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.008e-04\n",
      "Epoch 78800, Train loss: 1.716e+03, Test loss: 2.727e+04, MSE(e): 1.583e-04, MSE(pi1): 4.198e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.094e-04\n",
      "Epoch 78900, Train loss: 1.716e+03, Test loss: 2.727e+04, MSE(e): 1.583e-04, MSE(pi1): 4.196e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.093e-04\n",
      "Epoch 79000, Train loss: 1.716e+03, Test loss: 2.727e+04, MSE(e): 1.583e-04, MSE(pi1): 4.237e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.050e-04\n",
      "Epoch 79100, Train loss: 1.716e+03, Test loss: 2.728e+04, MSE(e): 1.583e-04, MSE(pi1): 4.224e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.091e-04\n",
      "Epoch 79200, Train loss: 1.716e+03, Test loss: 2.728e+04, MSE(e): 1.583e-04, MSE(pi1): 4.249e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.043e-04\n",
      "Epoch 79300, Train loss: 1.716e+03, Test loss: 2.728e+04, MSE(e): 1.583e-04, MSE(pi1): 4.266e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.022e-04\n",
      "Epoch 79400, Train loss: 1.716e+03, Test loss: 2.728e+04, MSE(e): 1.583e-04, MSE(pi1): 4.294e-03, MSE(pi2): 1.828e-04, MSE(pi3): 8.998e-04\n",
      "Epoch 79500, Train loss: 1.716e+03, Test loss: 2.729e+04, MSE(e): 1.582e-04, MSE(pi1): 4.251e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.047e-04\n",
      "Epoch 79600, Train loss: 1.715e+03, Test loss: 2.729e+04, MSE(e): 1.582e-04, MSE(pi1): 4.314e-03, MSE(pi2): 1.828e-04, MSE(pi3): 8.984e-04\n",
      "Epoch 79700, Train loss: 1.715e+03, Test loss: 2.729e+04, MSE(e): 1.582e-04, MSE(pi1): 4.318e-03, MSE(pi2): 1.828e-04, MSE(pi3): 8.989e-04\n",
      "Epoch 79800, Train loss: 1.715e+03, Test loss: 2.730e+04, MSE(e): 1.582e-04, MSE(pi1): 4.245e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.037e-04\n",
      "Epoch 79900, Train loss: 1.715e+03, Test loss: 2.730e+04, MSE(e): 1.582e-04, MSE(pi1): 4.206e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.080e-04\n",
      "Epoch 80000, Train loss: 1.715e+03, Test loss: 2.730e+04, MSE(e): 1.582e-04, MSE(pi1): 4.243e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.040e-04\n",
      "Epoch 80100, Train loss: 1.715e+03, Test loss: 2.730e+04, MSE(e): 1.582e-04, MSE(pi1): 4.250e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.038e-04\n",
      "Epoch 80200, Train loss: 1.715e+03, Test loss: 2.731e+04, MSE(e): 1.582e-04, MSE(pi1): 4.265e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.019e-04\n",
      "Epoch 80300, Train loss: 1.715e+03, Test loss: 2.731e+04, MSE(e): 1.582e-04, MSE(pi1): 4.213e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.077e-04\n",
      "Epoch 80400, Train loss: 1.715e+03, Test loss: 2.731e+04, MSE(e): 1.581e-04, MSE(pi1): 4.201e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.106e-04\n",
      "Epoch 80500, Train loss: 1.714e+03, Test loss: 2.731e+04, MSE(e): 1.581e-04, MSE(pi1): 4.226e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.061e-04\n",
      "Epoch 80600, Train loss: 1.714e+03, Test loss: 2.731e+04, MSE(e): 1.581e-04, MSE(pi1): 4.176e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.108e-04\n",
      "Epoch 80700, Train loss: 1.714e+03, Test loss: 2.732e+04, MSE(e): 1.581e-04, MSE(pi1): 4.290e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.018e-04\n",
      "Epoch 80800, Train loss: 1.714e+03, Test loss: 2.732e+04, MSE(e): 1.581e-04, MSE(pi1): 4.219e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.056e-04\n",
      "Epoch 80900, Train loss: 1.714e+03, Test loss: 2.732e+04, MSE(e): 1.581e-04, MSE(pi1): 4.255e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.027e-04\n",
      "Epoch 81000, Train loss: 1.714e+03, Test loss: 2.732e+04, MSE(e): 1.581e-04, MSE(pi1): 4.308e-03, MSE(pi2): 1.828e-04, MSE(pi3): 8.980e-04\n",
      "Epoch 81100, Train loss: 1.714e+03, Test loss: 2.733e+04, MSE(e): 1.581e-04, MSE(pi1): 4.226e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.073e-04\n",
      "Epoch 81200, Train loss: 1.713e+03, Test loss: 2.733e+04, MSE(e): 1.581e-04, MSE(pi1): 4.208e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.057e-04\n",
      "Epoch 81300, Train loss: 1.714e+03, Test loss: 2.733e+04, MSE(e): 1.580e-04, MSE(pi1): 4.348e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.000e-04\n",
      "Epoch 81400, Train loss: 1.714e+03, Test loss: 2.733e+04, MSE(e): 1.580e-04, MSE(pi1): 4.195e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.115e-04\n",
      "Epoch 81500, Train loss: 1.713e+03, Test loss: 2.734e+04, MSE(e): 1.580e-04, MSE(pi1): 4.239e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.026e-04\n",
      "Epoch 81600, Train loss: 1.713e+03, Test loss: 2.734e+04, MSE(e): 1.580e-04, MSE(pi1): 4.204e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.099e-04\n",
      "Epoch 81700, Train loss: 1.713e+03, Test loss: 2.734e+04, MSE(e): 1.580e-04, MSE(pi1): 4.235e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.046e-04\n",
      "Epoch 81800, Train loss: 1.714e+03, Test loss: 2.734e+04, MSE(e): 1.580e-04, MSE(pi1): 4.247e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.122e-04\n",
      "Epoch 81900, Train loss: 1.713e+03, Test loss: 2.735e+04, MSE(e): 1.580e-04, MSE(pi1): 4.236e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.099e-04\n",
      "Epoch 82000, Train loss: 1.714e+03, Test loss: 2.735e+04, MSE(e): 1.580e-04, MSE(pi1): 4.230e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.132e-04\n",
      "Epoch 82100, Train loss: 1.713e+03, Test loss: 2.735e+04, MSE(e): 1.580e-04, MSE(pi1): 4.258e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.019e-04\n",
      "Epoch 82200, Train loss: 1.712e+03, Test loss: 2.735e+04, MSE(e): 1.580e-04, MSE(pi1): 4.271e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.006e-04\n",
      "Epoch 82300, Train loss: 1.713e+03, Test loss: 2.735e+04, MSE(e): 1.579e-04, MSE(pi1): 4.280e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.021e-04\n",
      "Epoch 82400, Train loss: 1.712e+03, Test loss: 2.736e+04, MSE(e): 1.579e-04, MSE(pi1): 4.249e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.025e-04\n",
      "Epoch 82500, Train loss: 1.712e+03, Test loss: 2.736e+04, MSE(e): 1.579e-04, MSE(pi1): 4.220e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.073e-04\n",
      "Epoch 82600, Train loss: 1.712e+03, Test loss: 2.736e+04, MSE(e): 1.579e-04, MSE(pi1): 4.178e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.105e-04\n",
      "Epoch 82700, Train loss: 1.712e+03, Test loss: 2.736e+04, MSE(e): 1.579e-04, MSE(pi1): 4.226e-03, MSE(pi2): 1.828e-04, MSE(pi3): 9.054e-04\n",
      "Epoch 82800, Train loss: 1.713e+03, Test loss: 2.736e+04, MSE(e): 1.579e-04, MSE(pi1): 4.243e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.119e-04\n",
      "Epoch 82900, Train loss: 1.712e+03, Test loss: 2.737e+04, MSE(e): 1.579e-04, MSE(pi1): 4.242e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.073e-04\n",
      "Epoch 83000, Train loss: 1.712e+03, Test loss: 2.737e+04, MSE(e): 1.579e-04, MSE(pi1): 4.217e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.051e-04\n",
      "Epoch 83100, Train loss: 1.712e+03, Test loss: 2.737e+04, MSE(e): 1.579e-04, MSE(pi1): 4.203e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.075e-04\n",
      "Epoch 83200, Train loss: 1.711e+03, Test loss: 2.737e+04, MSE(e): 1.579e-04, MSE(pi1): 4.208e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.056e-04\n",
      "Epoch 83300, Train loss: 1.712e+03, Test loss: 2.737e+04, MSE(e): 1.578e-04, MSE(pi1): 4.295e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.002e-04\n",
      "Epoch 83400, Train loss: 1.711e+03, Test loss: 2.738e+04, MSE(e): 1.578e-04, MSE(pi1): 4.231e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.035e-04\n",
      "Epoch 83500, Train loss: 1.711e+03, Test loss: 2.738e+04, MSE(e): 1.578e-04, MSE(pi1): 4.252e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.041e-04\n",
      "Epoch 83600, Train loss: 1.711e+03, Test loss: 2.738e+04, MSE(e): 1.578e-04, MSE(pi1): 4.197e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.064e-04\n",
      "Epoch 83700, Train loss: 1.712e+03, Test loss: 2.738e+04, MSE(e): 1.578e-04, MSE(pi1): 4.299e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.065e-04\n",
      "Epoch 83800, Train loss: 1.711e+03, Test loss: 2.738e+04, MSE(e): 1.578e-04, MSE(pi1): 4.262e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.996e-04\n",
      "Epoch 83900, Train loss: 1.711e+03, Test loss: 2.739e+04, MSE(e): 1.578e-04, MSE(pi1): 4.222e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.059e-04\n",
      "Epoch 84000, Train loss: 1.712e+03, Test loss: 2.739e+04, MSE(e): 1.578e-04, MSE(pi1): 4.385e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.986e-04\n",
      "Epoch 84100, Train loss: 1.711e+03, Test loss: 2.739e+04, MSE(e): 1.578e-04, MSE(pi1): 4.175e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.103e-04\n",
      "Epoch 84200, Train loss: 1.710e+03, Test loss: 2.739e+04, MSE(e): 1.578e-04, MSE(pi1): 4.244e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.032e-04\n",
      "Epoch 84300, Train loss: 1.711e+03, Test loss: 2.740e+04, MSE(e): 1.577e-04, MSE(pi1): 4.275e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.020e-04\n",
      "Epoch 84400, Train loss: 1.710e+03, Test loss: 2.740e+04, MSE(e): 1.577e-04, MSE(pi1): 4.251e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.018e-04\n",
      "Epoch 84500, Train loss: 1.710e+03, Test loss: 2.740e+04, MSE(e): 1.577e-04, MSE(pi1): 4.291e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.010e-04\n",
      "Epoch 84600, Train loss: 1.710e+03, Test loss: 2.740e+04, MSE(e): 1.577e-04, MSE(pi1): 4.253e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.043e-04\n",
      "Epoch 84700, Train loss: 1.710e+03, Test loss: 2.740e+04, MSE(e): 1.577e-04, MSE(pi1): 4.252e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.019e-04\n",
      "Epoch 84800, Train loss: 1.710e+03, Test loss: 2.741e+04, MSE(e): 1.577e-04, MSE(pi1): 4.264e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.009e-04\n",
      "Epoch 84900, Train loss: 1.710e+03, Test loss: 2.741e+04, MSE(e): 1.577e-04, MSE(pi1): 4.208e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.052e-04\n",
      "Epoch 85000, Train loss: 1.710e+03, Test loss: 2.741e+04, MSE(e): 1.577e-04, MSE(pi1): 4.254e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.012e-04\n",
      "Epoch 85100, Train loss: 1.709e+03, Test loss: 2.741e+04, MSE(e): 1.577e-04, MSE(pi1): 4.227e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.025e-04\n",
      "Epoch 85200, Train loss: 1.709e+03, Test loss: 2.741e+04, MSE(e): 1.577e-04, MSE(pi1): 4.200e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.055e-04\n",
      "Epoch 85300, Train loss: 1.709e+03, Test loss: 2.741e+04, MSE(e): 1.576e-04, MSE(pi1): 4.235e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.019e-04\n",
      "Epoch 85400, Train loss: 1.709e+03, Test loss: 2.742e+04, MSE(e): 1.576e-04, MSE(pi1): 4.162e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.098e-04\n",
      "Epoch 85500, Train loss: 1.709e+03, Test loss: 2.742e+04, MSE(e): 1.576e-04, MSE(pi1): 4.229e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.032e-04\n",
      "Epoch 85600, Train loss: 1.709e+03, Test loss: 2.742e+04, MSE(e): 1.576e-04, MSE(pi1): 4.229e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.034e-04\n",
      "Epoch 85700, Train loss: 1.709e+03, Test loss: 2.742e+04, MSE(e): 1.576e-04, MSE(pi1): 4.242e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.025e-04\n",
      "Epoch 85800, Train loss: 1.709e+03, Test loss: 2.742e+04, MSE(e): 1.576e-04, MSE(pi1): 4.215e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.037e-04\n",
      "Epoch 85900, Train loss: 1.709e+03, Test loss: 2.743e+04, MSE(e): 1.576e-04, MSE(pi1): 4.181e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.067e-04\n",
      "Epoch 86000, Train loss: 1.709e+03, Test loss: 2.743e+04, MSE(e): 1.576e-04, MSE(pi1): 4.250e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.037e-04\n",
      "Epoch 86100, Train loss: 1.708e+03, Test loss: 2.743e+04, MSE(e): 1.576e-04, MSE(pi1): 4.177e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.065e-04\n",
      "Epoch 86200, Train loss: 1.709e+03, Test loss: 2.743e+04, MSE(e): 1.576e-04, MSE(pi1): 4.207e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.101e-04\n",
      "Epoch 86300, Train loss: 1.708e+03, Test loss: 2.743e+04, MSE(e): 1.576e-04, MSE(pi1): 4.241e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.016e-04\n",
      "Epoch 86400, Train loss: 1.708e+03, Test loss: 2.744e+04, MSE(e): 1.575e-04, MSE(pi1): 4.224e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.021e-04\n",
      "Epoch 86500, Train loss: 1.709e+03, Test loss: 2.744e+04, MSE(e): 1.575e-04, MSE(pi1): 4.306e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.015e-04\n",
      "Epoch 86600, Train loss: 1.708e+03, Test loss: 2.744e+04, MSE(e): 1.575e-04, MSE(pi1): 4.269e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.007e-04\n",
      "Epoch 86700, Train loss: 1.708e+03, Test loss: 2.744e+04, MSE(e): 1.575e-04, MSE(pi1): 4.256e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.002e-04\n",
      "Epoch 86800, Train loss: 1.708e+03, Test loss: 2.744e+04, MSE(e): 1.575e-04, MSE(pi1): 4.202e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.059e-04\n",
      "Epoch 86900, Train loss: 1.708e+03, Test loss: 2.745e+04, MSE(e): 1.575e-04, MSE(pi1): 4.180e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.070e-04\n",
      "Epoch 87000, Train loss: 1.708e+03, Test loss: 2.745e+04, MSE(e): 1.575e-04, MSE(pi1): 4.269e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.017e-04\n",
      "Epoch 87100, Train loss: 1.708e+03, Test loss: 2.745e+04, MSE(e): 1.575e-04, MSE(pi1): 4.299e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.972e-04\n",
      "Epoch 87200, Train loss: 1.707e+03, Test loss: 2.745e+04, MSE(e): 1.575e-04, MSE(pi1): 4.234e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.013e-04\n",
      "Epoch 87300, Train loss: 1.707e+03, Test loss: 2.745e+04, MSE(e): 1.575e-04, MSE(pi1): 4.224e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.019e-04\n",
      "Epoch 87400, Train loss: 1.707e+03, Test loss: 2.745e+04, MSE(e): 1.575e-04, MSE(pi1): 4.234e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.027e-04\n",
      "Epoch 87500, Train loss: 1.708e+03, Test loss: 2.746e+04, MSE(e): 1.574e-04, MSE(pi1): 4.271e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.027e-04\n",
      "Epoch 87600, Train loss: 1.707e+03, Test loss: 2.746e+04, MSE(e): 1.574e-04, MSE(pi1): 4.206e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.046e-04\n",
      "Epoch 87700, Train loss: 1.707e+03, Test loss: 2.746e+04, MSE(e): 1.574e-04, MSE(pi1): 4.176e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.087e-04\n",
      "Epoch 87800, Train loss: 1.707e+03, Test loss: 2.746e+04, MSE(e): 1.574e-04, MSE(pi1): 4.199e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.073e-04\n",
      "Epoch 87900, Train loss: 1.707e+03, Test loss: 2.746e+04, MSE(e): 1.574e-04, MSE(pi1): 4.205e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.097e-04\n",
      "Epoch 88000, Train loss: 1.707e+03, Test loss: 2.747e+04, MSE(e): 1.574e-04, MSE(pi1): 4.302e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.984e-04\n",
      "Epoch 88100, Train loss: 1.707e+03, Test loss: 2.747e+04, MSE(e): 1.574e-04, MSE(pi1): 4.252e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.003e-04\n",
      "Epoch 88200, Train loss: 1.706e+03, Test loss: 2.747e+04, MSE(e): 1.574e-04, MSE(pi1): 4.234e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.010e-04\n",
      "Epoch 88300, Train loss: 1.706e+03, Test loss: 2.747e+04, MSE(e): 1.574e-04, MSE(pi1): 4.200e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.056e-04\n",
      "Epoch 88400, Train loss: 1.707e+03, Test loss: 2.747e+04, MSE(e): 1.574e-04, MSE(pi1): 4.157e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.118e-04\n",
      "Epoch 88500, Train loss: 1.707e+03, Test loss: 2.747e+04, MSE(e): 1.574e-04, MSE(pi1): 4.188e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.115e-04\n",
      "Epoch 88600, Train loss: 1.706e+03, Test loss: 2.748e+04, MSE(e): 1.573e-04, MSE(pi1): 4.251e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.020e-04\n",
      "Epoch 88700, Train loss: 1.706e+03, Test loss: 2.748e+04, MSE(e): 1.573e-04, MSE(pi1): 4.182e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.052e-04\n",
      "Epoch 88800, Train loss: 1.706e+03, Test loss: 2.748e+04, MSE(e): 1.573e-04, MSE(pi1): 4.179e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.075e-04\n",
      "Epoch 88900, Train loss: 1.706e+03, Test loss: 2.748e+04, MSE(e): 1.573e-04, MSE(pi1): 4.254e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.997e-04\n",
      "Epoch 89000, Train loss: 1.706e+03, Test loss: 2.748e+04, MSE(e): 1.573e-04, MSE(pi1): 4.241e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.004e-04\n",
      "Epoch 89100, Train loss: 1.706e+03, Test loss: 2.748e+04, MSE(e): 1.573e-04, MSE(pi1): 4.261e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.987e-04\n",
      "Epoch 89200, Train loss: 1.706e+03, Test loss: 2.749e+04, MSE(e): 1.573e-04, MSE(pi1): 4.258e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.996e-04\n",
      "Epoch 89300, Train loss: 1.706e+03, Test loss: 2.749e+04, MSE(e): 1.573e-04, MSE(pi1): 4.277e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.995e-04\n",
      "Epoch 89400, Train loss: 1.705e+03, Test loss: 2.749e+04, MSE(e): 1.573e-04, MSE(pi1): 4.221e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.030e-04\n",
      "Epoch 89500, Train loss: 1.705e+03, Test loss: 2.749e+04, MSE(e): 1.573e-04, MSE(pi1): 4.167e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.075e-04\n",
      "Epoch 89600, Train loss: 1.706e+03, Test loss: 2.749e+04, MSE(e): 1.573e-04, MSE(pi1): 4.166e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.118e-04\n",
      "Epoch 89700, Train loss: 1.705e+03, Test loss: 2.749e+04, MSE(e): 1.573e-04, MSE(pi1): 4.258e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.007e-04\n",
      "Epoch 89800, Train loss: 1.705e+03, Test loss: 2.749e+04, MSE(e): 1.572e-04, MSE(pi1): 4.313e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.970e-04\n",
      "Epoch 89900, Train loss: 1.705e+03, Test loss: 2.750e+04, MSE(e): 1.572e-04, MSE(pi1): 4.217e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.058e-04\n",
      "Epoch 90000, Train loss: 1.705e+03, Test loss: 2.750e+04, MSE(e): 1.572e-04, MSE(pi1): 4.181e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.068e-04\n",
      "Epoch 90100, Train loss: 1.705e+03, Test loss: 2.750e+04, MSE(e): 1.572e-04, MSE(pi1): 4.248e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.009e-04\n",
      "Epoch 90200, Train loss: 1.705e+03, Test loss: 2.750e+04, MSE(e): 1.572e-04, MSE(pi1): 4.187e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.050e-04\n",
      "Epoch 90300, Train loss: 1.705e+03, Test loss: 2.750e+04, MSE(e): 1.572e-04, MSE(pi1): 4.215e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.051e-04\n",
      "Epoch 90400, Train loss: 1.705e+03, Test loss: 2.750e+04, MSE(e): 1.572e-04, MSE(pi1): 4.174e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.105e-04\n",
      "Epoch 90500, Train loss: 1.705e+03, Test loss: 2.751e+04, MSE(e): 1.572e-04, MSE(pi1): 4.194e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.069e-04\n",
      "Epoch 90600, Train loss: 1.704e+03, Test loss: 2.751e+04, MSE(e): 1.572e-04, MSE(pi1): 4.180e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.069e-04\n",
      "Epoch 90700, Train loss: 1.704e+03, Test loss: 2.751e+04, MSE(e): 1.572e-04, MSE(pi1): 4.224e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.017e-04\n",
      "Epoch 90800, Train loss: 1.704e+03, Test loss: 2.751e+04, MSE(e): 1.572e-04, MSE(pi1): 4.172e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.071e-04\n",
      "Epoch 90900, Train loss: 1.704e+03, Test loss: 2.751e+04, MSE(e): 1.571e-04, MSE(pi1): 4.168e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.064e-04\n",
      "Epoch 91000, Train loss: 1.704e+03, Test loss: 2.751e+04, MSE(e): 1.571e-04, MSE(pi1): 4.161e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.085e-04\n",
      "Epoch 91100, Train loss: 1.704e+03, Test loss: 2.751e+04, MSE(e): 1.571e-04, MSE(pi1): 4.215e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.047e-04\n",
      "Epoch 91200, Train loss: 1.704e+03, Test loss: 2.751e+04, MSE(e): 1.571e-04, MSE(pi1): 4.246e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.988e-04\n",
      "Epoch 91300, Train loss: 1.704e+03, Test loss: 2.752e+04, MSE(e): 1.571e-04, MSE(pi1): 4.187e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.044e-04\n",
      "Epoch 91400, Train loss: 1.704e+03, Test loss: 2.752e+04, MSE(e): 1.571e-04, MSE(pi1): 4.185e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.048e-04\n",
      "Epoch 91500, Train loss: 1.704e+03, Test loss: 2.752e+04, MSE(e): 1.571e-04, MSE(pi1): 4.164e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.128e-04\n",
      "Epoch 91600, Train loss: 1.703e+03, Test loss: 2.752e+04, MSE(e): 1.571e-04, MSE(pi1): 4.205e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.026e-04\n",
      "Epoch 91700, Train loss: 1.703e+03, Test loss: 2.752e+04, MSE(e): 1.571e-04, MSE(pi1): 4.203e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.025e-04\n",
      "Epoch 91800, Train loss: 1.704e+03, Test loss: 2.752e+04, MSE(e): 1.571e-04, MSE(pi1): 4.245e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.033e-04\n",
      "Epoch 91900, Train loss: 1.704e+03, Test loss: 2.752e+04, MSE(e): 1.571e-04, MSE(pi1): 4.218e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.083e-04\n",
      "Epoch 92000, Train loss: 1.703e+03, Test loss: 2.753e+04, MSE(e): 1.571e-04, MSE(pi1): 4.231e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.009e-04\n",
      "Epoch 92100, Train loss: 1.703e+03, Test loss: 2.753e+04, MSE(e): 1.570e-04, MSE(pi1): 4.175e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.053e-04\n",
      "Epoch 92200, Train loss: 1.704e+03, Test loss: 2.753e+04, MSE(e): 1.570e-04, MSE(pi1): 4.185e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.124e-04\n",
      "Epoch 92300, Train loss: 1.703e+03, Test loss: 2.753e+04, MSE(e): 1.570e-04, MSE(pi1): 4.234e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.005e-04\n",
      "Epoch 92400, Train loss: 1.703e+03, Test loss: 2.753e+04, MSE(e): 1.570e-04, MSE(pi1): 4.200e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.029e-04\n",
      "Epoch 92500, Train loss: 1.703e+03, Test loss: 2.753e+04, MSE(e): 1.570e-04, MSE(pi1): 4.190e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.043e-04\n",
      "Epoch 92600, Train loss: 1.703e+03, Test loss: 2.753e+04, MSE(e): 1.570e-04, MSE(pi1): 4.210e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.062e-04\n",
      "Epoch 92700, Train loss: 1.703e+03, Test loss: 2.754e+04, MSE(e): 1.570e-04, MSE(pi1): 4.197e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.052e-04\n",
      "Epoch 92800, Train loss: 1.703e+03, Test loss: 2.754e+04, MSE(e): 1.570e-04, MSE(pi1): 4.180e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.074e-04\n",
      "Epoch 92900, Train loss: 1.702e+03, Test loss: 2.754e+04, MSE(e): 1.570e-04, MSE(pi1): 4.206e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.023e-04\n",
      "Epoch 93000, Train loss: 1.702e+03, Test loss: 2.754e+04, MSE(e): 1.570e-04, MSE(pi1): 4.228e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.011e-04\n",
      "Epoch 93100, Train loss: 1.702e+03, Test loss: 2.754e+04, MSE(e): 1.570e-04, MSE(pi1): 4.186e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.054e-04\n",
      "Epoch 93200, Train loss: 1.702e+03, Test loss: 2.754e+04, MSE(e): 1.570e-04, MSE(pi1): 4.205e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.051e-04\n",
      "Epoch 93300, Train loss: 1.702e+03, Test loss: 2.754e+04, MSE(e): 1.570e-04, MSE(pi1): 4.186e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.043e-04\n",
      "Epoch 93400, Train loss: 1.702e+03, Test loss: 2.754e+04, MSE(e): 1.569e-04, MSE(pi1): 4.160e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.082e-04\n",
      "Epoch 93500, Train loss: 1.702e+03, Test loss: 2.755e+04, MSE(e): 1.569e-04, MSE(pi1): 4.193e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.030e-04\n",
      "Epoch 93600, Train loss: 1.702e+03, Test loss: 2.755e+04, MSE(e): 1.569e-04, MSE(pi1): 4.310e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.961e-04\n",
      "Epoch 93700, Train loss: 1.702e+03, Test loss: 2.755e+04, MSE(e): 1.569e-04, MSE(pi1): 4.237e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.057e-04\n",
      "Epoch 93800, Train loss: 1.702e+03, Test loss: 2.755e+04, MSE(e): 1.569e-04, MSE(pi1): 4.191e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.064e-04\n",
      "Epoch 93900, Train loss: 1.702e+03, Test loss: 2.755e+04, MSE(e): 1.569e-04, MSE(pi1): 4.199e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.031e-04\n",
      "Epoch 94000, Train loss: 1.701e+03, Test loss: 2.755e+04, MSE(e): 1.569e-04, MSE(pi1): 4.182e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.024e-04\n",
      "Epoch 94100, Train loss: 1.702e+03, Test loss: 2.755e+04, MSE(e): 1.569e-04, MSE(pi1): 4.222e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.026e-04\n",
      "Epoch 94200, Train loss: 1.701e+03, Test loss: 2.755e+04, MSE(e): 1.569e-04, MSE(pi1): 4.206e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.012e-04\n",
      "Epoch 94300, Train loss: 1.701e+03, Test loss: 2.756e+04, MSE(e): 1.569e-04, MSE(pi1): 4.233e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.006e-04\n",
      "Epoch 94400, Train loss: 1.701e+03, Test loss: 2.756e+04, MSE(e): 1.569e-04, MSE(pi1): 4.237e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.997e-04\n",
      "Epoch 94500, Train loss: 1.701e+03, Test loss: 2.756e+04, MSE(e): 1.569e-04, MSE(pi1): 4.182e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.053e-04\n",
      "Epoch 94600, Train loss: 1.701e+03, Test loss: 2.756e+04, MSE(e): 1.569e-04, MSE(pi1): 4.157e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.058e-04\n",
      "Epoch 94700, Train loss: 1.701e+03, Test loss: 2.756e+04, MSE(e): 1.568e-04, MSE(pi1): 4.206e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.022e-04\n",
      "Epoch 94800, Train loss: 1.701e+03, Test loss: 2.756e+04, MSE(e): 1.568e-04, MSE(pi1): 4.220e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.009e-04\n",
      "Epoch 94900, Train loss: 1.701e+03, Test loss: 2.756e+04, MSE(e): 1.568e-04, MSE(pi1): 4.291e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.975e-04\n",
      "Epoch 95000, Train loss: 1.701e+03, Test loss: 2.756e+04, MSE(e): 1.568e-04, MSE(pi1): 4.255e-03, MSE(pi2): 1.827e-04, MSE(pi3): 8.992e-04\n",
      "Epoch 95100, Train loss: 1.700e+03, Test loss: 2.757e+04, MSE(e): 1.568e-04, MSE(pi1): 4.188e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.020e-04\n",
      "Epoch 95200, Train loss: 1.700e+03, Test loss: 2.757e+04, MSE(e): 1.568e-04, MSE(pi1): 4.143e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.076e-04\n",
      "Epoch 95300, Train loss: 1.702e+03, Test loss: 2.757e+04, MSE(e): 1.568e-04, MSE(pi1): 4.243e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.130e-04\n",
      "Epoch 95400, Train loss: 1.700e+03, Test loss: 2.757e+04, MSE(e): 1.568e-04, MSE(pi1): 4.199e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.021e-04\n",
      "Epoch 95500, Train loss: 1.700e+03, Test loss: 2.757e+04, MSE(e): 1.568e-04, MSE(pi1): 4.191e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.031e-04\n",
      "Epoch 95600, Train loss: 1.700e+03, Test loss: 2.757e+04, MSE(e): 1.568e-04, MSE(pi1): 4.186e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.016e-04\n",
      "Epoch 95700, Train loss: 1.700e+03, Test loss: 2.757e+04, MSE(e): 1.568e-04, MSE(pi1): 4.188e-03, MSE(pi2): 1.827e-04, MSE(pi3): 9.043e-04\n",
      "Epoch 95800, Train loss: 1.700e+03, Test loss: 2.757e+04, MSE(e): 1.568e-04, MSE(pi1): 4.246e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.012e-04\n",
      "Epoch 95900, Train loss: 1.700e+03, Test loss: 2.757e+04, MSE(e): 1.568e-04, MSE(pi1): 4.147e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.108e-04\n",
      "Epoch 96000, Train loss: 1.700e+03, Test loss: 2.758e+04, MSE(e): 1.567e-04, MSE(pi1): 4.175e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.041e-04\n",
      "Epoch 96100, Train loss: 1.700e+03, Test loss: 2.758e+04, MSE(e): 1.567e-04, MSE(pi1): 4.209e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.021e-04\n",
      "Epoch 96200, Train loss: 1.700e+03, Test loss: 2.758e+04, MSE(e): 1.567e-04, MSE(pi1): 4.329e-03, MSE(pi2): 1.826e-04, MSE(pi3): 8.957e-04\n",
      "Epoch 96300, Train loss: 1.700e+03, Test loss: 2.758e+04, MSE(e): 1.567e-04, MSE(pi1): 4.196e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.063e-04\n",
      "Epoch 96400, Train loss: 1.700e+03, Test loss: 2.758e+04, MSE(e): 1.567e-04, MSE(pi1): 4.194e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.035e-04\n",
      "Epoch 96500, Train loss: 1.699e+03, Test loss: 2.758e+04, MSE(e): 1.567e-04, MSE(pi1): 4.160e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.052e-04\n",
      "Epoch 96600, Train loss: 1.700e+03, Test loss: 2.758e+04, MSE(e): 1.567e-04, MSE(pi1): 4.161e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.110e-04\n",
      "Epoch 96700, Train loss: 1.699e+03, Test loss: 2.758e+04, MSE(e): 1.567e-04, MSE(pi1): 4.212e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.015e-04\n",
      "Epoch 96800, Train loss: 1.699e+03, Test loss: 2.759e+04, MSE(e): 1.567e-04, MSE(pi1): 4.169e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.054e-04\n",
      "Epoch 96900, Train loss: 1.699e+03, Test loss: 2.759e+04, MSE(e): 1.567e-04, MSE(pi1): 4.260e-03, MSE(pi2): 1.826e-04, MSE(pi3): 8.972e-04\n",
      "Epoch 97000, Train loss: 1.699e+03, Test loss: 2.759e+04, MSE(e): 1.567e-04, MSE(pi1): 4.294e-03, MSE(pi2): 1.826e-04, MSE(pi3): 8.945e-04\n",
      "Epoch 97100, Train loss: 1.699e+03, Test loss: 2.759e+04, MSE(e): 1.567e-04, MSE(pi1): 4.220e-03, MSE(pi2): 1.826e-04, MSE(pi3): 8.988e-04\n",
      "Epoch 97200, Train loss: 1.699e+03, Test loss: 2.759e+04, MSE(e): 1.567e-04, MSE(pi1): 4.194e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.006e-04\n",
      "Epoch 97300, Train loss: 1.699e+03, Test loss: 2.759e+04, MSE(e): 1.567e-04, MSE(pi1): 4.167e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.093e-04\n",
      "Epoch 97400, Train loss: 1.699e+03, Test loss: 2.759e+04, MSE(e): 1.566e-04, MSE(pi1): 4.132e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.106e-04\n",
      "Epoch 97500, Train loss: 1.699e+03, Test loss: 2.759e+04, MSE(e): 1.566e-04, MSE(pi1): 4.199e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.023e-04\n",
      "Epoch 97600, Train loss: 1.699e+03, Test loss: 2.759e+04, MSE(e): 1.566e-04, MSE(pi1): 4.224e-03, MSE(pi2): 1.826e-04, MSE(pi3): 8.987e-04\n",
      "Epoch 97700, Train loss: 1.699e+03, Test loss: 2.759e+04, MSE(e): 1.566e-04, MSE(pi1): 4.161e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.057e-04\n",
      "Epoch 97800, Train loss: 1.699e+03, Test loss: 2.760e+04, MSE(e): 1.566e-04, MSE(pi1): 4.196e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.018e-04\n",
      "Epoch 97900, Train loss: 1.698e+03, Test loss: 2.760e+04, MSE(e): 1.566e-04, MSE(pi1): 4.215e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.004e-04\n",
      "Epoch 98000, Train loss: 1.699e+03, Test loss: 2.760e+04, MSE(e): 1.566e-04, MSE(pi1): 4.265e-03, MSE(pi2): 1.826e-04, MSE(pi3): 8.968e-04\n",
      "Epoch 98100, Train loss: 1.699e+03, Test loss: 2.760e+04, MSE(e): 1.566e-04, MSE(pi1): 4.202e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.048e-04\n",
      "Epoch 98200, Train loss: 1.698e+03, Test loss: 2.760e+04, MSE(e): 1.566e-04, MSE(pi1): 4.162e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.041e-04\n",
      "Epoch 98300, Train loss: 1.698e+03, Test loss: 2.760e+04, MSE(e): 1.566e-04, MSE(pi1): 4.182e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.025e-04\n",
      "Epoch 98400, Train loss: 1.698e+03, Test loss: 2.760e+04, MSE(e): 1.566e-04, MSE(pi1): 4.182e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.017e-04\n",
      "Epoch 98500, Train loss: 1.698e+03, Test loss: 2.760e+04, MSE(e): 1.566e-04, MSE(pi1): 4.194e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.030e-04\n",
      "Epoch 98600, Train loss: 1.698e+03, Test loss: 2.760e+04, MSE(e): 1.566e-04, MSE(pi1): 4.168e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.031e-04\n",
      "Epoch 98700, Train loss: 1.698e+03, Test loss: 2.760e+04, MSE(e): 1.566e-04, MSE(pi1): 4.195e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.040e-04\n",
      "Epoch 98800, Train loss: 1.699e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.217e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.075e-04\n",
      "Epoch 98900, Train loss: 1.698e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.199e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.021e-04\n",
      "Epoch 99000, Train loss: 1.698e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.238e-03, MSE(pi2): 1.826e-04, MSE(pi3): 8.976e-04\n",
      "Epoch 99100, Train loss: 1.697e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.190e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.012e-04\n",
      "Epoch 99200, Train loss: 1.698e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.184e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.074e-04\n",
      "Epoch 99300, Train loss: 1.697e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.192e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.015e-04\n",
      "Epoch 99400, Train loss: 1.697e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.182e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.015e-04\n",
      "Epoch 99500, Train loss: 1.697e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.150e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.048e-04\n",
      "Epoch 99600, Train loss: 1.697e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.161e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.059e-04\n",
      "Epoch 99700, Train loss: 1.697e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.190e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.038e-04\n",
      "Epoch 99800, Train loss: 1.697e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.199e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.037e-04\n",
      "Epoch 99900, Train loss: 1.697e+03, Test loss: 2.761e+04, MSE(e): 1.565e-04, MSE(pi1): 4.151e-03, MSE(pi2): 1.826e-04, MSE(pi3): 9.060e-04\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 9000\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64 \n",
    "n_checkpoints = 100\n",
    "\n",
    "second_lr = 1e-4\n",
    "\n",
    "train_loop(model, optimizer, X_train_NN, y_train_NN, f_train_NN, X_test_NN, y_test_NN, f_test_NN,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PGNNIV_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
