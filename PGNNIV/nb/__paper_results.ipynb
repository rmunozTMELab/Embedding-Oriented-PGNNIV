{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is a draft for combining results between two different codes for a same paper.\n",
    "\n",
    "In next versions of the code it will be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../python'))\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "# import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "custom_seed = 42\n",
    "np.random.seed(custom_seed)\n",
    "# tf.random.set_seed(custom_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar datos y resultados\n",
    "def cargar_datos_y_resultados(nombre_modelo):\n",
    "    carpeta_datos = r'C:\\Users\\usuario\\Desktop\\rmunozTMELab\\PGNNIV_2D\\data_1e4'\n",
    "    nombre_archivo_datos = f'{nombre_modelo}_data.pkl'\n",
    "    archivo_pickle = os.path.join(carpeta_datos, nombre_archivo_datos)\n",
    "\n",
    "    with open(archivo_pickle, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # Load first training\n",
    "    carpeta_resultados = r'C:\\Users\\usuario\\Desktop\\rmunozTMELab\\PGNNIV_2D\\results_28052024'\n",
    "    nombre_archivo_first_train = f'{nombre_modelo}_results\\{nombre_modelo}_first_train.pkl'\n",
    "    archivo_pickle = os.path.join(carpeta_resultados, nombre_archivo_first_train)\n",
    "\n",
    "    with open(archivo_pickle, 'rb') as f:\n",
    "        results_first_train_pkl = pickle.load(f)\n",
    "\n",
    "    results_first_train = results_first_train_pkl['training']\n",
    "    predictions_predictive_first_train = results_first_train_pkl['predictions_pred']\n",
    "    predictions_explanatory_first_train = results_first_train_pkl['predictions_exp']\n",
    "\n",
    "    # # Load new training\n",
    "    carpeta_resultados = r'C:\\Users\\usuario\\Desktop\\rmunozTMELab\\PGNNIV_2D\\results_28052024'\n",
    "    nombre_archivo_new_train = f'{nombre_modelo}_results\\{nombre_modelo}_new_train.pkl'\n",
    "    archivo_pickle = os.path.join(carpeta_resultados, nombre_archivo_new_train)\n",
    "\n",
    "    with open(archivo_pickle, 'rb') as f:\n",
    "        results_new_train_pkl = pickle.load(f)\n",
    "\n",
    "    results_new_train = results_new_train_pkl['training']\n",
    "    predictions_predictive_new_train = results_new_train_pkl['predictions_pred']\n",
    "    predictions_explanatory_new_train = results_new_train_pkl['predictions_exp']\n",
    "\n",
    "    return data, results_first_train, predictions_predictive_first_train, predictions_explanatory_first_train, results_new_train, predictions_predictive_new_train, predictions_explanatory_new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a la función para el modelo \"non_lineal\"\n",
    "data_non_lineal, results_first_train_non_lineal, predictions_predictive_first_train_non_lineal, predictions_explanatory_first_train_non_lineal, results_new_train_non_lineal, predictions_predictive_new_train_non_lineal, predictions_explanatory_new_train_non_lineal = cargar_datos_y_resultados(\"non_lineal\")\n",
    "\n",
    "# Llamar a la función para el modelo \"two_dimensions_non_lineal\"\n",
    "data_nontwo_dimensions_non_lineal, results_first_train_nontwo_dimensions_non_lineal, predictions_predictive_first_train_nontwo_dimensions_non_lineal, predictions_explanatory_first_train_nontwo_dimensions_non_lineal, results_new_train_nontwo_dimensions_non_lineal, predictions_predictive_new_train_nontwo_dimensions_non_lineal, predictions_explanatory_new_train_nontwo_dimensions_non_lineal = cargar_datos_y_resultados(\"two_dimensions_non_lineal\")\n",
    "\n",
    "# Llamar a la función para el modelo \"two_dimension_heterogeneous\"\n",
    "data_two_dimension_heterogeneous, results_first_train_two_dimension_heterogeneous, predictions_predictive_first_train_two_dimension_heterogeneous, predictions_explanatory_first_train_two_dimension_heterogeneous, results_new_train_two_dimension_heterogeneous, predictions_predictive_new_train_two_dimension_heterogeneous, predictions_explanatory_new_train_two_dimension_heterogeneous = cargar_datos_y_resultados(\"two_dimensions_heterogeneous\")\n",
    "\n",
    "# Llamar a la función para el modelo \"lineal_heterogeneous\"\n",
    "data_lineal_heterogeneous, results_first_train_lineal_heterogeneous, predictions_predictive_first_train_lineal_heterogeneous, predictions_explanatory_first_train_lineal_heterogeneous, results_new_train_lineal_heterogeneous, predictions_predictive_new_train_lineal_heterogeneous, predictions_explanatory_new_train_lineal_heterogeneous = cargar_datos_y_resultados(\"lineal_heterogeneous\")\n",
    "\n",
    "# Llamar a la función para el modelo \"lineal_homogeneous\"\n",
    "data_lineal_homogeneous, results_first_train_lineal_homogeneous, predictions_predictive_first_train_lineal_homogeneous, predictions_explanatory_first_train_lineal_homogeneous, results_new_train_lineal_homogeneous, predictions_predictive_new_train_lineal_homogeneous, predictions_explanatory_new_train_lineal_homogeneous = cargar_datos_y_resultados(\"lineal_homogeneous\")\n",
    "\n",
    "# Llamar a la función para el modelo \"tensorial\"\n",
    "data_tensorial, results_first_train_tensorial, predictions_predictive_first_train_tensorial, predictions_explanatory_first_train_tensorial, results_new_train_tensorial, predictions_predictive_new_train_tensorial, predictions_explanatory_new_train_tensorial = cargar_datos_y_resultados(\"tensorial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a la función para el modelo \"two_dimensions_non_lineal_P4\"\n",
    "data_nontwo_dimensions_non_lineal_P4, results_first_train_nontwo_dimensions_non_lineal_P4, predictions_predictive_first_train_nontwo_dimensions_non_lineal_P4, predictions_explanatory_first_train_nontwo_dimensions_non_lineal_P4, results_new_train_nontwo_dimensions_non_lineal_P4, predictions_predictive_new_train_nontwo_dimensions_non_lineal_P4, predictions_explanatory_new_train_nontwo_dimensions_non_lineal_P4 = cargar_datos_y_resultados(\"two_dimensions_non_lineal_P4_02102024\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = data_non_lineal['n_data']\n",
    "n_discretization = data_non_lineal['n_discretization']\n",
    "x_step_size = data_non_lineal['x_step_size']\n",
    "y_step_size = data_non_lineal['y_step_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(data, window_size=50):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, window, mode='valid')\n",
    "\n",
    "def cm_to_in(cm):\n",
    "    return cm * 0.393701\n",
    "\n",
    "def normalize_list(lst):\n",
    "    max_value = max(lst)\n",
    "    return [x / max_value for x in lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parámetros de las gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth = 1.5  \n",
    "title_fontsize = 14  \n",
    "label_fontsize = 14  \n",
    "legend_fontsize = 12 \n",
    "tick_fontsize = 11  \n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "posX = cm_to_in(10) # posición de la esquina inferior izquierda de la imagen en X\n",
    "posY = cm_to_in(10) # posición de la esquina inferior izquierda de la imagen en Y\n",
    "width = cm_to_in(12)  # ancho de la imagen\n",
    "height = cm_to_in(8) # alto de la imagen\n",
    "\n",
    "color = [0.1, 0, 0.8]  # triplete RGB, valores entre 0 y 1\n",
    "subplot_adjust_left = cm_to_in(0.15)\n",
    "subplot_adjust_bottom = cm_to_in(0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de las curvas de entrenamiento (non lineal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar los resultados de los modelos no lineales\n",
    "train_total_loss_list_non_lineal = results_first_train_non_lineal['train_total_loss_list'] + results_new_train_non_lineal['train_total_loss_list']\n",
    "test_total_loss_list_non_lineal = results_first_train_non_lineal['test_total_loss_list'] + results_new_train_non_lineal['test_total_loss_list']\n",
    "train_total_MSE_list_non_lineal = results_first_train_non_lineal['train_total_MSE_list'] + results_new_train_non_lineal['train_total_MSE_list']\n",
    "test_total_MSE_list_non_lineal = results_first_train_non_lineal['test_total_MSE_list'] + results_new_train_non_lineal['test_total_MSE_list']\n",
    "\n",
    "train_total_loss_list_nontwo_dimensions_non_lineal = results_first_train_nontwo_dimensions_non_lineal['train_total_loss_list'] + results_new_train_nontwo_dimensions_non_lineal['train_total_loss_list']\n",
    "test_total_loss_list_nontwo_dimensions_non_lineal = results_first_train_nontwo_dimensions_non_lineal['test_total_loss_list'] + results_new_train_nontwo_dimensions_non_lineal['test_total_loss_list']\n",
    "train_total_MSE_list_nontwo_dimensions_non_lineal = results_first_train_nontwo_dimensions_non_lineal['train_total_MSE_list'] + results_new_train_nontwo_dimensions_non_lineal['train_total_MSE_list']\n",
    "test_total_MSE_list_nontwo_dimensions_non_lineal = results_first_train_nontwo_dimensions_non_lineal['test_total_MSE_list'] + results_new_train_nontwo_dimensions_non_lineal['test_total_MSE_list']\n",
    "\n",
    "# Combinar los resultados del modelo two_dimension_heterogeneous\n",
    "train_total_loss_list_two_dimension_heterogeneous = results_first_train_two_dimension_heterogeneous['train_total_loss_list'] + results_new_train_two_dimension_heterogeneous['train_total_loss_list']\n",
    "test_total_loss_list_two_dimension_heterogeneous = results_first_train_two_dimension_heterogeneous['test_total_loss_list'] + results_new_train_two_dimension_heterogeneous['test_total_loss_list']\n",
    "train_total_MSE_list_two_dimension_heterogeneous = results_first_train_two_dimension_heterogeneous['train_total_MSE_list'] + results_new_train_two_dimension_heterogeneous['train_total_MSE_list']\n",
    "test_total_MSE_list_two_dimension_heterogeneous = results_first_train_two_dimension_heterogeneous['test_total_MSE_list'] + results_new_train_two_dimension_heterogeneous['test_total_MSE_list']\n",
    "\n",
    "# Combinar los resultados del modelo lineal_heterogeneous\n",
    "train_total_loss_list_lineal_heterogeneous = results_first_train_lineal_heterogeneous['train_total_loss_list'] + results_new_train_lineal_heterogeneous['train_total_loss_list']\n",
    "test_total_loss_list_lineal_heterogeneous = results_first_train_lineal_heterogeneous['test_total_loss_list'] + results_new_train_lineal_heterogeneous['test_total_loss_list']\n",
    "train_total_MSE_list_lineal_heterogeneous = results_first_train_lineal_heterogeneous['train_total_MSE_list'] + results_new_train_lineal_heterogeneous['train_total_MSE_list']\n",
    "test_total_MSE_list_lineal_heterogeneous = results_first_train_lineal_heterogeneous['test_total_MSE_list'] + results_new_train_lineal_heterogeneous['test_total_MSE_list']\n",
    "\n",
    "# Combinar los resultados del modelo lineal_homogeneous\n",
    "train_total_loss_list_lineal_homogeneous = results_first_train_lineal_homogeneous['train_total_loss_list'] + results_new_train_lineal_homogeneous['train_total_loss_list']\n",
    "test_total_loss_list_lineal_homogeneous = results_first_train_lineal_homogeneous['test_total_loss_list'] + results_new_train_lineal_homogeneous['test_total_loss_list']\n",
    "train_total_MSE_list_lineal_homogeneous = results_first_train_lineal_homogeneous['train_total_MSE_list'] + results_new_train_lineal_homogeneous['train_total_MSE_list']\n",
    "test_total_MSE_list_lineal_homogeneous = results_first_train_lineal_homogeneous['test_total_MSE_list'] + results_new_train_lineal_homogeneous['test_total_MSE_list']\n",
    "\n",
    "# Cargar y combinar los resultados para el modelo tensorial\n",
    "data_tensorial, results_first_train_tensorial, predictions_predictive_first_train_tensorial, predictions_explanatory_first_train_tensorial, results_new_train_tensorial, predictions_predictive_new_train_tensorial, predictions_explanatory_new_train_tensorial = cargar_datos_y_resultados(\"tensorial\")\n",
    "train_total_loss_list_tensorial = results_first_train_tensorial['train_total_loss_list'] + results_new_train_tensorial['train_total_loss_list']\n",
    "test_total_loss_list_tensorial = results_first_train_tensorial['test_total_loss_list'] + results_new_train_tensorial['test_total_loss_list']\n",
    "train_total_MSE_list_tensorial = results_first_train_tensorial['train_total_MSE_list'] + results_new_train_tensorial['train_total_MSE_list']\n",
    "test_total_MSE_list_tensorial = results_first_train_tensorial['test_total_MSE_list'] + results_new_train_tensorial['test_total_MSE_list']\n",
    "\n",
    "# Combinar los resultados de los modelos no lineales\n",
    "\n",
    "train_total_loss_list_nontwo_dimensions_non_lineal_P4 = results_first_train_nontwo_dimensions_non_lineal_P4['train_total_loss_list'] + results_new_train_nontwo_dimensions_non_lineal_P4['train_total_loss_list']\n",
    "test_total_loss_list_nontwo_dimensions_non_lineal_P4 = results_first_train_nontwo_dimensions_non_lineal_P4['test_total_loss_list'] + results_new_train_nontwo_dimensions_non_lineal_P4['test_total_loss_list']\n",
    "train_total_MSE_list_nontwo_dimensions_non_lineal_P4 = results_first_train_nontwo_dimensions_non_lineal_P4['train_total_MSE_list'] + results_new_train_nontwo_dimensions_non_lineal_P4['train_total_MSE_list']\n",
    "test_total_MSE_list_nontwo_dimensions_non_lineal_P4 = results_first_train_nontwo_dimensions_non_lineal_P4['test_total_MSE_list'] + results_new_train_nontwo_dimensions_non_lineal_P4['test_total_MSE_list']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "from vecopsciml.operators import zero_order as zo\n",
    "from vecopsciml.algebra import zero_order as azo\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from models.non_constant_diffusivity import NonConstantDiffusivityNeuralNetwork\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from utils.checkpoints import load_results\n",
    "from trainers.train import train_loop\n",
    "\n",
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'C:\\Users\\usuario\\Desktop\\rmunozTMELab\\Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data\\non_linear\\non_linear.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results\\non_linear')\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'results\\non_linear\\model_paper')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)\n",
    "\n",
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()\n",
    "\n",
    "# Tratamiento de los datos para dividirlos en train y test\n",
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = TensOps(torch.tensor(dataset['y_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_train = TensOps(torch.tensor(dataset['k_train'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "X_np = X_train\n",
    "y_np = y_train.values\n",
    "K_np = K_train.values\n",
    "\n",
    "X_train_np, X_test_np, y_train_np, y_test_np, K_train_np, K_test_np = train_test_split(X_np, y_np, K_np, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train_np\n",
    "X_test = X_test_np\n",
    "\n",
    "y_train = TensOps(y_train_np, space_dimension=y_train.space_dim, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test_np, space_dimension=y_train.space_dim, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train_np, space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test_np, space_dimension=K_train.space_dim, contravariance=0, covariance=0)\n",
    "\n",
    "# Arquitectura del modelo\n",
    "input_shape = X_train[0].shape  # [1, 10, 8]\n",
    "hidden1_dim = 150\n",
    "hidden2_dim = 150\n",
    "output_shape = y_train.values[0].shape  # [1, 10, 10]\n",
    "\n",
    "# Se carga el modelo y el optimizador\n",
    "model = NonConstantDiffusivityNeuralNetwork(input_shape, hidden1_dim, hidden2_dim, output_shape, n_filters=5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "model, optimizer, lists = load_results(model, optimizer, MODEL_RESULTS_PATH, map_location=torch.device('cpu'))\n",
    "\n",
    "train_total_loss_list = lists['train_total_loss_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "# plt.subplots_adjust(left=subplot_adjust_left, bottom=subplot_adjust_bottom) \n",
    "\n",
    "# plt.plot(smooth_curve(train_total_loss_list_non_lineal), label='P5', color='red', linestyle='-')\n",
    "plt.plot(smooth_curve(train_total_loss_list_nontwo_dimensions_non_lineal)/3000, label='NL1', color='black', linestyle='-')\n",
    "plt.plot(smooth_curve(train_total_loss_list), label='NL2', color='green', linestyle='-')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "# plt.title('Lineal homogeneous learning curve (MSE)', fontsize=title_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.savefig(os.path.join(MODEL_RESULTS_PATH, f'training_nonlinear.pdf'), bbox_inches='tight', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "# plt.subplots_adjust(left=subplot_adjust_left, bottom=subplot_adjust_bottom) \n",
    "\n",
    "# plt.plot(smooth_curve(train_total_loss_list_lineal_homogeneous), label='P1', color='red', linestyle='-')\n",
    "# plt.plot(smooth_curve(train_total_loss_list_lineal_heterogeneous), label='P2', color='blue', linestyle='-')\n",
    "plt.plot(smooth_curve(train_total_loss_list_two_dimension_heterogeneous)/3000, label='H', color='blue', linestyle='-')\n",
    "plt.plot(smooth_curve(train_total_loss_list_tensorial)/3000, label='A', color='red', linestyle='-')\n",
    "\n",
    "# plt.plot(test_total_loss_list_lineal_homogeneous, label='Total loss train', color='blue', linestyle=':')\n",
    "# plt.plot(test_total_loss_list_lineal_heterogeneous, label='Total loss train', color='red', linestyle=':')\n",
    "# plt.plot(test_total_loss_list_tensorial, label='Total loss train', color='black', linestyle=':')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "# plt.savefig(os.path.join(r'overleaf_plots', f'homogeneous_heterogeneous_problems_training.pdf'), bbox_inches='tight', dpi=600)\n",
    "plt.savefig(os.path.join(MODEL_RESULTS_PATH, f'homogeneous_heterogeneous_problems_training.pdf'), bbox_inches='tight', dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
