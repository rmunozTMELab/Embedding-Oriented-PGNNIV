{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import GPUtil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import gc\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from utils.checkpoints import load_results\n",
    "\n",
    "from architectures.pgnniv_baseline import PGNNIVBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_100\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_100/transfer\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear/sigmoid_nonlinear.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_100')\n",
    "\n",
    "PRETRAINED_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/non_linear_1000_0/baseline_model_10')\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_100/transfer')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_TRANSFERLEARNING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear/sigmoid_nonlinear.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 80\n",
      "Validation dataset length: 20\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X_train, y_train, K_train, f_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other parameters\n",
    "n_filters_explanatory = 5\n",
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_autoencoder = PretrainedAutoencoder(autoencoder_input_shape, latent_space_dim, autoencoder_output_shape).to(DEVICE)\n",
    "pretrained_pgnniv = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(pretrained_pgnniv.parameters(), lr=1e-4)\n",
    "pretrained_pgnniv, optimizer, lists = load_results(pretrained_pgnniv, optimizer, PRETRAINED_RESULTS_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f833422acc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgnniv_pretrained_encoder = pretrained_pgnniv.encoder\n",
    "pgnniv_pretrained_decoder = pretrained_pgnniv.decoder\n",
    "pgnniv_pretrained_exp = pretrained_pgnniv.explanatory\n",
    "\n",
    "for param in pgnniv_pretrained_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in pgnniv_pretrained_decoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pgnniv_pretrained_exp.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def reinitialize_model(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            # Reinitialize Conv2d weights and biases\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            # Reinitialize Linear weights and biases\n",
    "            nn.init.kaiming_uniform_(module.weight, a=math.sqrt(5))\n",
    "            if module.bias is not None:\n",
    "                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(module.weight)\n",
    "                bound = 1 / math.sqrt(fan_in)\n",
    "                nn.init.uniform_(module.bias, -bound, bound)\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            # Reinitialize BatchNorm layers\n",
    "            nn.init.constant_(module.weight, 1)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "\n",
    "# reinitialize_model(pgnniv_pretrained_decoder)\n",
    "# reinitialize_model(pgnniv_pretrained_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 2.900e+08, Test loss: 4.963e+08, MSE(e): 2.896e+01, MSE(pi1): 2.193e+01, MSE(pi2): 1.262e+01, MSE(pi3): 1.571e+00\n",
      "Epoch 100, Train loss: 2.325e+08, Test loss: 3.933e+08, MSE(e): 2.321e+01, MSE(pi1): 2.336e+01, MSE(pi2): 1.014e+01, MSE(pi3): 1.630e+00\n",
      "Epoch 200, Train loss: 1.967e+08, Test loss: 3.205e+08, MSE(e): 1.962e+01, MSE(pi1): 2.500e+01, MSE(pi2): 8.505e+00, MSE(pi3): 1.693e+00\n",
      "Epoch 300, Train loss: 1.743e+08, Test loss: 2.736e+08, MSE(e): 1.739e+01, MSE(pi1): 2.566e+01, MSE(pi2): 7.455e+00, MSE(pi3): 1.727e+00\n",
      "Epoch 400, Train loss: 1.588e+08, Test loss: 2.425e+08, MSE(e): 1.584e+01, MSE(pi1): 2.524e+01, MSE(pi2): 6.738e+00, MSE(pi3): 1.718e+00\n",
      "Epoch 500, Train loss: 1.468e+08, Test loss: 2.199e+08, MSE(e): 1.463e+01, MSE(pi1): 2.431e+01, MSE(pi2): 6.198e+00, MSE(pi3): 1.674e+00\n",
      "Epoch 600, Train loss: 1.368e+08, Test loss: 2.020e+08, MSE(e): 1.364e+01, MSE(pi1): 2.325e+01, MSE(pi2): 5.761e+00, MSE(pi3): 1.597e+00\n",
      "Epoch 700, Train loss: 1.283e+08, Test loss: 1.869e+08, MSE(e): 1.280e+01, MSE(pi1): 2.202e+01, MSE(pi2): 5.391e+00, MSE(pi3): 1.498e+00\n",
      "Epoch 800, Train loss: 1.206e+08, Test loss: 1.735e+08, MSE(e): 1.203e+01, MSE(pi1): 2.056e+01, MSE(pi2): 5.065e+00, MSE(pi3): 1.394e+00\n",
      "Epoch 900, Train loss: 1.130e+08, Test loss: 1.607e+08, MSE(e): 1.127e+01, MSE(pi1): 1.911e+01, MSE(pi2): 4.763e+00, MSE(pi3): 1.298e+00\n",
      "Epoch 1000, Train loss: 1.048e+08, Test loss: 1.481e+08, MSE(e): 1.045e+01, MSE(pi1): 1.809e+01, MSE(pi2): 4.493e+00, MSE(pi3): 1.217e+00\n",
      "Epoch 1100, Train loss: 9.788e+07, Test loss: 1.403e+08, MSE(e): 9.760e+00, MSE(pi1): 1.698e+01, MSE(pi2): 4.323e+00, MSE(pi3): 1.144e+00\n",
      "Epoch 1200, Train loss: 9.356e+07, Test loss: 1.378e+08, MSE(e): 9.331e+00, MSE(pi1): 1.445e+01, MSE(pi2): 4.204e+00, MSE(pi3): 1.058e+00\n",
      "Epoch 1300, Train loss: 9.052e+07, Test loss: 1.361e+08, MSE(e): 9.031e+00, MSE(pi1): 1.109e+01, MSE(pi2): 4.093e+00, MSE(pi3): 9.873e-01\n",
      "Epoch 1400, Train loss: 8.814e+07, Test loss: 1.347e+08, MSE(e): 8.794e+00, MSE(pi1): 9.402e+00, MSE(pi2): 3.991e+00, MSE(pi3): 9.346e-01\n",
      "Epoch 1500, Train loss: 8.613e+07, Test loss: 1.336e+08, MSE(e): 8.596e+00, MSE(pi1): 8.465e+00, MSE(pi2): 3.898e+00, MSE(pi3): 8.749e-01\n",
      "Epoch 1600, Train loss: 8.437e+07, Test loss: 1.328e+08, MSE(e): 8.421e+00, MSE(pi1): 7.790e+00, MSE(pi2): 3.814e+00, MSE(pi3): 8.229e-01\n",
      "Epoch 1700, Train loss: 8.277e+07, Test loss: 1.321e+08, MSE(e): 8.261e+00, MSE(pi1): 7.287e+00, MSE(pi2): 3.735e+00, MSE(pi3): 7.800e-01\n",
      "Epoch 1800, Train loss: 8.125e+07, Test loss: 1.315e+08, MSE(e): 8.110e+00, MSE(pi1): 6.899e+00, MSE(pi2): 3.659e+00, MSE(pi3): 7.446e-01\n",
      "Epoch 1900, Train loss: 7.976e+07, Test loss: 1.309e+08, MSE(e): 7.962e+00, MSE(pi1): 6.586e+00, MSE(pi2): 3.585e+00, MSE(pi3): 7.151e-01\n",
      "Epoch 2000, Train loss: 7.827e+07, Test loss: 1.303e+08, MSE(e): 7.814e+00, MSE(pi1): 6.321e+00, MSE(pi2): 3.511e+00, MSE(pi3): 6.899e-01\n",
      "Epoch 2100, Train loss: 7.675e+07, Test loss: 1.296e+08, MSE(e): 7.661e+00, MSE(pi1): 6.085e+00, MSE(pi2): 3.436e+00, MSE(pi3): 6.679e-01\n",
      "Epoch 2200, Train loss: 7.514e+07, Test loss: 1.288e+08, MSE(e): 7.501e+00, MSE(pi1): 5.860e+00, MSE(pi2): 3.358e+00, MSE(pi3): 6.482e-01\n",
      "Epoch 2300, Train loss: 7.343e+07, Test loss: 1.277e+08, MSE(e): 7.331e+00, MSE(pi1): 5.630e+00, MSE(pi2): 3.276e+00, MSE(pi3): 6.296e-01\n",
      "Epoch 2400, Train loss: 7.160e+07, Test loss: 1.264e+08, MSE(e): 7.148e+00, MSE(pi1): 5.395e+00, MSE(pi2): 3.189e+00, MSE(pi3): 6.111e-01\n",
      "Epoch 2500, Train loss: 6.962e+07, Test loss: 1.248e+08, MSE(e): 6.950e+00, MSE(pi1): 5.178e+00, MSE(pi2): 3.097e+00, MSE(pi3): 5.920e-01\n",
      "Epoch 2600, Train loss: 6.750e+07, Test loss: 1.229e+08, MSE(e): 6.739e+00, MSE(pi1): 4.988e+00, MSE(pi2): 3.000e+00, MSE(pi3): 5.733e-01\n",
      "Epoch 2700, Train loss: 6.523e+07, Test loss: 1.206e+08, MSE(e): 6.513e+00, MSE(pi1): 4.815e+00, MSE(pi2): 2.898e+00, MSE(pi3): 5.552e-01\n",
      "Epoch 2800, Train loss: 6.284e+07, Test loss: 1.178e+08, MSE(e): 6.274e+00, MSE(pi1): 4.639e+00, MSE(pi2): 2.792e+00, MSE(pi3): 5.376e-01\n",
      "Epoch 2900, Train loss: 6.032e+07, Test loss: 1.146e+08, MSE(e): 6.022e+00, MSE(pi1): 4.446e+00, MSE(pi2): 2.683e+00, MSE(pi3): 5.201e-01\n",
      "Epoch 3000, Train loss: 5.768e+07, Test loss: 1.109e+08, MSE(e): 5.758e+00, MSE(pi1): 4.236e+00, MSE(pi2): 2.570e+00, MSE(pi3): 5.024e-01\n",
      "Epoch 3100, Train loss: 5.489e+07, Test loss: 1.070e+08, MSE(e): 5.480e+00, MSE(pi1): 4.015e+00, MSE(pi2): 2.455e+00, MSE(pi3): 4.844e-01\n",
      "Epoch 3200, Train loss: 5.196e+07, Test loss: 1.028e+08, MSE(e): 5.188e+00, MSE(pi1): 3.795e+00, MSE(pi2): 2.335e+00, MSE(pi3): 4.665e-01\n",
      "Epoch 3300, Train loss: 4.891e+07, Test loss: 9.822e+07, MSE(e): 4.882e+00, MSE(pi1): 3.580e+00, MSE(pi2): 2.212e+00, MSE(pi3): 4.490e-01\n",
      "Epoch 3400, Train loss: 4.574e+07, Test loss: 9.345e+07, MSE(e): 4.566e+00, MSE(pi1): 3.373e+00, MSE(pi2): 2.086e+00, MSE(pi3): 4.319e-01\n",
      "Epoch 3500, Train loss: 4.251e+07, Test loss: 8.847e+07, MSE(e): 4.243e+00, MSE(pi1): 3.177e+00, MSE(pi2): 1.958e+00, MSE(pi3): 4.151e-01\n",
      "Epoch 3600, Train loss: 3.924e+07, Test loss: 8.324e+07, MSE(e): 3.917e+00, MSE(pi1): 2.990e+00, MSE(pi2): 1.829e+00, MSE(pi3): 3.988e-01\n",
      "Epoch 3700, Train loss: 3.599e+07, Test loss: 7.777e+07, MSE(e): 3.592e+00, MSE(pi1): 2.816e+00, MSE(pi2): 1.702e+00, MSE(pi3): 3.828e-01\n",
      "Epoch 3800, Train loss: 3.281e+07, Test loss: 7.210e+07, MSE(e): 3.274e+00, MSE(pi1): 2.657e+00, MSE(pi2): 1.577e+00, MSE(pi3): 3.672e-01\n",
      "Epoch 3900, Train loss: 2.974e+07, Test loss: 6.640e+07, MSE(e): 2.968e+00, MSE(pi1): 2.519e+00, MSE(pi2): 1.458e+00, MSE(pi3): 3.518e-01\n",
      "Epoch 4000, Train loss: 2.686e+07, Test loss: 6.086e+07, MSE(e): 2.680e+00, MSE(pi1): 2.403e+00, MSE(pi2): 1.345e+00, MSE(pi3): 3.367e-01\n",
      "Epoch 4100, Train loss: 2.423e+07, Test loss: 5.569e+07, MSE(e): 2.418e+00, MSE(pi1): 2.309e+00, MSE(pi2): 1.239e+00, MSE(pi3): 3.223e-01\n",
      "Epoch 4200, Train loss: 2.193e+07, Test loss: 5.109e+07, MSE(e): 2.187e+00, MSE(pi1): 2.234e+00, MSE(pi2): 1.143e+00, MSE(pi3): 3.088e-01\n",
      "Epoch 4300, Train loss: 1.999e+07, Test loss: 4.722e+07, MSE(e): 1.994e+00, MSE(pi1): 2.171e+00, MSE(pi2): 1.057e+00, MSE(pi3): 2.968e-01\n",
      "Epoch 4400, Train loss: 1.841e+07, Test loss: 4.411e+07, MSE(e): 1.836e+00, MSE(pi1): 2.111e+00, MSE(pi2): 9.828e-01, MSE(pi3): 2.863e-01\n",
      "Epoch 4500, Train loss: 1.713e+07, Test loss: 4.171e+07, MSE(e): 1.708e+00, MSE(pi1): 2.051e+00, MSE(pi2): 9.188e-01, MSE(pi3): 2.771e-01\n",
      "Epoch 4600, Train loss: 1.608e+07, Test loss: 3.992e+07, MSE(e): 1.604e+00, MSE(pi1): 1.988e+00, MSE(pi2): 8.639e-01, MSE(pi3): 2.689e-01\n",
      "Epoch 4700, Train loss: 1.521e+07, Test loss: 3.860e+07, MSE(e): 1.517e+00, MSE(pi1): 1.924e+00, MSE(pi2): 8.166e-01, MSE(pi3): 2.615e-01\n",
      "Epoch 4800, Train loss: 1.447e+07, Test loss: 3.763e+07, MSE(e): 1.443e+00, MSE(pi1): 1.861e+00, MSE(pi2): 7.754e-01, MSE(pi3): 2.548e-01\n",
      "Epoch 4900, Train loss: 1.383e+07, Test loss: 3.693e+07, MSE(e): 1.378e+00, MSE(pi1): 1.800e+00, MSE(pi2): 7.393e-01, MSE(pi3): 2.485e-01\n",
      "Epoch 5000, Train loss: 1.325e+07, Test loss: 3.642e+07, MSE(e): 1.321e+00, MSE(pi1): 1.743e+00, MSE(pi2): 7.071e-01, MSE(pi3): 2.427e-01\n",
      "Epoch 5100, Train loss: 1.274e+07, Test loss: 3.605e+07, MSE(e): 1.270e+00, MSE(pi1): 1.691e+00, MSE(pi2): 6.783e-01, MSE(pi3): 2.373e-01\n",
      "Epoch 5200, Train loss: 1.226e+07, Test loss: 3.578e+07, MSE(e): 1.222e+00, MSE(pi1): 1.644e+00, MSE(pi2): 6.521e-01, MSE(pi3): 2.323e-01\n",
      "Epoch 5300, Train loss: 1.182e+07, Test loss: 3.559e+07, MSE(e): 1.178e+00, MSE(pi1): 1.600e+00, MSE(pi2): 6.281e-01, MSE(pi3): 2.275e-01\n",
      "Epoch 5400, Train loss: 1.141e+07, Test loss: 3.546e+07, MSE(e): 1.137e+00, MSE(pi1): 1.560e+00, MSE(pi2): 6.059e-01, MSE(pi3): 2.231e-01\n",
      "Epoch 5500, Train loss: 1.102e+07, Test loss: 3.537e+07, MSE(e): 1.098e+00, MSE(pi1): 1.521e+00, MSE(pi2): 5.852e-01, MSE(pi3): 2.188e-01\n",
      "Epoch 5600, Train loss: 1.065e+07, Test loss: 3.532e+07, MSE(e): 1.061e+00, MSE(pi1): 1.484e+00, MSE(pi2): 5.657e-01, MSE(pi3): 2.148e-01\n",
      "Epoch 5700, Train loss: 1.029e+07, Test loss: 3.530e+07, MSE(e): 1.025e+00, MSE(pi1): 1.447e+00, MSE(pi2): 5.473e-01, MSE(pi3): 2.109e-01\n",
      "Epoch 5800, Train loss: 9.947e+06, Test loss: 3.529e+07, MSE(e): 9.912e-01, MSE(pi1): 1.411e+00, MSE(pi2): 5.298e-01, MSE(pi3): 2.072e-01\n",
      "Epoch 5900, Train loss: 9.615e+06, Test loss: 3.528e+07, MSE(e): 9.580e-01, MSE(pi1): 1.375e+00, MSE(pi2): 5.131e-01, MSE(pi3): 2.036e-01\n",
      "Epoch 6000, Train loss: 9.291e+06, Test loss: 3.527e+07, MSE(e): 9.257e-01, MSE(pi1): 1.341e+00, MSE(pi2): 4.971e-01, MSE(pi3): 2.001e-01\n",
      "Epoch 6100, Train loss: 8.974e+06, Test loss: 3.525e+07, MSE(e): 8.941e-01, MSE(pi1): 1.307e+00, MSE(pi2): 4.815e-01, MSE(pi3): 1.967e-01\n",
      "Epoch 6200, Train loss: 8.663e+06, Test loss: 3.520e+07, MSE(e): 8.630e-01, MSE(pi1): 1.274e+00, MSE(pi2): 4.664e-01, MSE(pi3): 1.935e-01\n",
      "Epoch 6300, Train loss: 8.355e+06, Test loss: 3.512e+07, MSE(e): 8.323e-01, MSE(pi1): 1.243e+00, MSE(pi2): 4.517e-01, MSE(pi3): 1.903e-01\n",
      "Epoch 6400, Train loss: 8.050e+06, Test loss: 3.500e+07, MSE(e): 8.019e-01, MSE(pi1): 1.213e+00, MSE(pi2): 4.373e-01, MSE(pi3): 1.872e-01\n",
      "Epoch 6500, Train loss: 7.747e+06, Test loss: 3.483e+07, MSE(e): 7.717e-01, MSE(pi1): 1.184e+00, MSE(pi2): 4.231e-01, MSE(pi3): 1.842e-01\n",
      "Epoch 6600, Train loss: 7.448e+06, Test loss: 3.461e+07, MSE(e): 7.418e-01, MSE(pi1): 1.156e+00, MSE(pi2): 4.091e-01, MSE(pi3): 1.813e-01\n",
      "Epoch 6700, Train loss: 7.155e+06, Test loss: 3.433e+07, MSE(e): 7.125e-01, MSE(pi1): 1.129e+00, MSE(pi2): 3.954e-01, MSE(pi3): 1.785e-01\n",
      "Epoch 6800, Train loss: 6.868e+06, Test loss: 3.400e+07, MSE(e): 6.839e-01, MSE(pi1): 1.104e+00, MSE(pi2): 3.820e-01, MSE(pi3): 1.757e-01\n",
      "Epoch 6900, Train loss: 6.591e+06, Test loss: 3.361e+07, MSE(e): 6.562e-01, MSE(pi1): 1.078e+00, MSE(pi2): 3.690e-01, MSE(pi3): 1.730e-01\n",
      "Epoch 7000, Train loss: 6.325e+06, Test loss: 3.318e+07, MSE(e): 6.297e-01, MSE(pi1): 1.054e+00, MSE(pi2): 3.564e-01, MSE(pi3): 1.704e-01\n",
      "Epoch 7100, Train loss: 6.072e+06, Test loss: 3.270e+07, MSE(e): 6.044e-01, MSE(pi1): 1.030e+00, MSE(pi2): 3.442e-01, MSE(pi3): 1.679e-01\n",
      "Epoch 7200, Train loss: 5.833e+06, Test loss: 3.219e+07, MSE(e): 5.806e-01, MSE(pi1): 1.007e+00, MSE(pi2): 3.326e-01, MSE(pi3): 1.656e-01\n",
      "Epoch 7300, Train loss: 5.608e+06, Test loss: 3.165e+07, MSE(e): 5.581e-01, MSE(pi1): 9.845e-01, MSE(pi2): 3.215e-01, MSE(pi3): 1.634e-01\n",
      "Epoch 7400, Train loss: 5.398e+06, Test loss: 3.109e+07, MSE(e): 5.372e-01, MSE(pi1): 9.628e-01, MSE(pi2): 3.111e-01, MSE(pi3): 1.613e-01\n",
      "Epoch 7500, Train loss: 5.203e+06, Test loss: 3.051e+07, MSE(e): 5.177e-01, MSE(pi1): 9.418e-01, MSE(pi2): 3.012e-01, MSE(pi3): 1.594e-01\n",
      "Epoch 7600, Train loss: 5.022e+06, Test loss: 2.994e+07, MSE(e): 4.997e-01, MSE(pi1): 9.213e-01, MSE(pi2): 2.920e-01, MSE(pi3): 1.576e-01\n",
      "Epoch 7700, Train loss: 4.855e+06, Test loss: 2.938e+07, MSE(e): 4.830e-01, MSE(pi1): 9.013e-01, MSE(pi2): 2.833e-01, MSE(pi3): 1.559e-01\n",
      "Epoch 7800, Train loss: 4.702e+06, Test loss: 2.884e+07, MSE(e): 4.677e-01, MSE(pi1): 8.816e-01, MSE(pi2): 2.753e-01, MSE(pi3): 1.543e-01\n",
      "Epoch 7900, Train loss: 4.561e+06, Test loss: 2.833e+07, MSE(e): 4.536e-01, MSE(pi1): 8.622e-01, MSE(pi2): 2.679e-01, MSE(pi3): 1.528e-01\n",
      "Epoch 8000, Train loss: 4.430e+06, Test loss: 2.786e+07, MSE(e): 4.407e-01, MSE(pi1): 8.429e-01, MSE(pi2): 2.610e-01, MSE(pi3): 1.513e-01\n",
      "Epoch 8100, Train loss: 4.310e+06, Test loss: 2.743e+07, MSE(e): 4.287e-01, MSE(pi1): 8.239e-01, MSE(pi2): 2.545e-01, MSE(pi3): 1.498e-01\n",
      "Epoch 8200, Train loss: 4.199e+06, Test loss: 2.704e+07, MSE(e): 4.176e-01, MSE(pi1): 8.050e-01, MSE(pi2): 2.485e-01, MSE(pi3): 1.484e-01\n",
      "Epoch 8300, Train loss: 4.095e+06, Test loss: 2.668e+07, MSE(e): 4.072e-01, MSE(pi1): 7.864e-01, MSE(pi2): 2.428e-01, MSE(pi3): 1.470e-01\n",
      "Epoch 8400, Train loss: 3.998e+06, Test loss: 2.637e+07, MSE(e): 3.975e-01, MSE(pi1): 7.683e-01, MSE(pi2): 2.375e-01, MSE(pi3): 1.456e-01\n",
      "Epoch 8500, Train loss: 3.907e+06, Test loss: 2.610e+07, MSE(e): 3.884e-01, MSE(pi1): 7.505e-01, MSE(pi2): 2.325e-01, MSE(pi3): 1.442e-01\n",
      "Epoch 8600, Train loss: 3.821e+06, Test loss: 2.585e+07, MSE(e): 3.799e-01, MSE(pi1): 7.334e-01, MSE(pi2): 2.278e-01, MSE(pi3): 1.429e-01\n",
      "Epoch 8700, Train loss: 3.739e+06, Test loss: 2.565e+07, MSE(e): 3.717e-01, MSE(pi1): 7.169e-01, MSE(pi2): 2.233e-01, MSE(pi3): 1.415e-01\n",
      "Epoch 8800, Train loss: 3.661e+06, Test loss: 2.547e+07, MSE(e): 3.640e-01, MSE(pi1): 7.010e-01, MSE(pi2): 2.190e-01, MSE(pi3): 1.402e-01\n",
      "Epoch 8900, Train loss: 3.587e+06, Test loss: 2.531e+07, MSE(e): 3.566e-01, MSE(pi1): 6.858e-01, MSE(pi2): 2.149e-01, MSE(pi3): 1.388e-01\n",
      "Epoch 9000, Train loss: 3.515e+06, Test loss: 2.518e+07, MSE(e): 3.494e-01, MSE(pi1): 6.714e-01, MSE(pi2): 2.110e-01, MSE(pi3): 1.374e-01\n",
      "Epoch 9100, Train loss: 3.446e+06, Test loss: 2.506e+07, MSE(e): 3.426e-01, MSE(pi1): 6.576e-01, MSE(pi2): 2.073e-01, MSE(pi3): 1.361e-01\n",
      "Epoch 9200, Train loss: 3.380e+06, Test loss: 2.497e+07, MSE(e): 3.360e-01, MSE(pi1): 6.444e-01, MSE(pi2): 2.036e-01, MSE(pi3): 1.347e-01\n",
      "Epoch 9300, Train loss: 3.315e+06, Test loss: 2.489e+07, MSE(e): 3.295e-01, MSE(pi1): 6.317e-01, MSE(pi2): 2.001e-01, MSE(pi3): 1.333e-01\n",
      "Epoch 9400, Train loss: 3.252e+06, Test loss: 2.482e+07, MSE(e): 3.233e-01, MSE(pi1): 6.196e-01, MSE(pi2): 1.967e-01, MSE(pi3): 1.319e-01\n",
      "Epoch 9500, Train loss: 3.191e+06, Test loss: 2.477e+07, MSE(e): 3.172e-01, MSE(pi1): 6.079e-01, MSE(pi2): 1.933e-01, MSE(pi3): 1.305e-01\n",
      "Epoch 9600, Train loss: 3.131e+06, Test loss: 2.472e+07, MSE(e): 3.112e-01, MSE(pi1): 5.967e-01, MSE(pi2): 1.900e-01, MSE(pi3): 1.290e-01\n",
      "Epoch 9700, Train loss: 3.073e+06, Test loss: 2.468e+07, MSE(e): 3.054e-01, MSE(pi1): 5.854e-01, MSE(pi2): 1.868e-01, MSE(pi3): 1.277e-01\n",
      "Epoch 9800, Train loss: 3.016e+06, Test loss: 2.466e+07, MSE(e): 2.997e-01, MSE(pi1): 5.752e-01, MSE(pi2): 1.836e-01, MSE(pi3): 1.262e-01\n",
      "Epoch 9900, Train loss: 2.960e+06, Test loss: 2.464e+07, MSE(e): 2.942e-01, MSE(pi1): 5.649e-01, MSE(pi2): 1.805e-01, MSE(pi3): 1.247e-01\n",
      "Epoch 10000, Train loss: 2.906e+06, Test loss: 2.462e+07, MSE(e): 2.888e-01, MSE(pi1): 5.546e-01, MSE(pi2): 1.775e-01, MSE(pi3): 1.233e-01\n",
      "Epoch 10100, Train loss: 2.854e+06, Test loss: 2.463e+07, MSE(e): 2.836e-01, MSE(pi1): 5.450e-01, MSE(pi2): 1.746e-01, MSE(pi3): 1.218e-01\n",
      "Epoch 10200, Train loss: 2.804e+06, Test loss: 2.462e+07, MSE(e): 2.786e-01, MSE(pi1): 5.349e-01, MSE(pi2): 1.717e-01, MSE(pi3): 1.205e-01\n",
      "Epoch 10300, Train loss: 2.756e+06, Test loss: 2.463e+07, MSE(e): 2.739e-01, MSE(pi1): 5.254e-01, MSE(pi2): 1.689e-01, MSE(pi3): 1.191e-01\n",
      "Epoch 10400, Train loss: 2.710e+06, Test loss: 2.463e+07, MSE(e): 2.693e-01, MSE(pi1): 5.161e-01, MSE(pi2): 1.662e-01, MSE(pi3): 1.178e-01\n",
      "Epoch 10500, Train loss: 2.667e+06, Test loss: 2.465e+07, MSE(e): 2.650e-01, MSE(pi1): 5.074e-01, MSE(pi2): 1.637e-01, MSE(pi3): 1.166e-01\n",
      "Epoch 10600, Train loss: 2.626e+06, Test loss: 2.466e+07, MSE(e): 2.609e-01, MSE(pi1): 4.995e-01, MSE(pi2): 1.612e-01, MSE(pi3): 1.154e-01\n",
      "Epoch 10700, Train loss: 2.587e+06, Test loss: 2.467e+07, MSE(e): 2.570e-01, MSE(pi1): 4.906e-01, MSE(pi2): 1.588e-01, MSE(pi3): 1.143e-01\n",
      "Epoch 10800, Train loss: 2.550e+06, Test loss: 2.468e+07, MSE(e): 2.534e-01, MSE(pi1): 4.836e-01, MSE(pi2): 1.566e-01, MSE(pi3): 1.132e-01\n",
      "Epoch 10900, Train loss: 2.515e+06, Test loss: 2.469e+07, MSE(e): 2.499e-01, MSE(pi1): 4.767e-01, MSE(pi2): 1.544e-01, MSE(pi3): 1.121e-01\n",
      "Epoch 11000, Train loss: 2.482e+06, Test loss: 2.468e+07, MSE(e): 2.466e-01, MSE(pi1): 4.701e-01, MSE(pi2): 1.524e-01, MSE(pi3): 1.111e-01\n",
      "Epoch 11100, Train loss: 2.451e+06, Test loss: 2.467e+07, MSE(e): 2.435e-01, MSE(pi1): 4.638e-01, MSE(pi2): 1.504e-01, MSE(pi3): 1.102e-01\n",
      "Epoch 11200, Train loss: 2.422e+06, Test loss: 2.466e+07, MSE(e): 2.406e-01, MSE(pi1): 4.583e-01, MSE(pi2): 1.486e-01, MSE(pi3): 1.093e-01\n",
      "Epoch 11300, Train loss: 2.394e+06, Test loss: 2.464e+07, MSE(e): 2.379e-01, MSE(pi1): 4.529e-01, MSE(pi2): 1.469e-01, MSE(pi3): 1.085e-01\n",
      "Epoch 11400, Train loss: 2.368e+06, Test loss: 2.462e+07, MSE(e): 2.353e-01, MSE(pi1): 4.480e-01, MSE(pi2): 1.452e-01, MSE(pi3): 1.077e-01\n",
      "Epoch 11500, Train loss: 2.343e+06, Test loss: 2.459e+07, MSE(e): 2.328e-01, MSE(pi1): 4.435e-01, MSE(pi2): 1.437e-01, MSE(pi3): 1.069e-01\n",
      "Epoch 11600, Train loss: 2.320e+06, Test loss: 2.457e+07, MSE(e): 2.305e-01, MSE(pi1): 4.391e-01, MSE(pi2): 1.422e-01, MSE(pi3): 1.061e-01\n",
      "Epoch 11700, Train loss: 2.298e+06, Test loss: 2.453e+07, MSE(e): 2.283e-01, MSE(pi1): 4.345e-01, MSE(pi2): 1.409e-01, MSE(pi3): 1.054e-01\n",
      "Epoch 11800, Train loss: 2.276e+06, Test loss: 2.450e+07, MSE(e): 2.261e-01, MSE(pi1): 4.308e-01, MSE(pi2): 1.395e-01, MSE(pi3): 1.047e-01\n",
      "Epoch 11900, Train loss: 2.256e+06, Test loss: 2.446e+07, MSE(e): 2.241e-01, MSE(pi1): 4.269e-01, MSE(pi2): 1.383e-01, MSE(pi3): 1.041e-01\n",
      "Epoch 12000, Train loss: 2.237e+06, Test loss: 2.441e+07, MSE(e): 2.222e-01, MSE(pi1): 4.229e-01, MSE(pi2): 1.371e-01, MSE(pi3): 1.035e-01\n",
      "Epoch 12100, Train loss: 2.219e+06, Test loss: 2.439e+07, MSE(e): 2.204e-01, MSE(pi1): 4.195e-01, MSE(pi2): 1.359e-01, MSE(pi3): 1.029e-01\n",
      "Epoch 12200, Train loss: 2.201e+06, Test loss: 2.435e+07, MSE(e): 2.186e-01, MSE(pi1): 4.163e-01, MSE(pi2): 1.348e-01, MSE(pi3): 1.023e-01\n",
      "Epoch 12300, Train loss: 2.183e+06, Test loss: 2.432e+07, MSE(e): 2.169e-01, MSE(pi1): 4.129e-01, MSE(pi2): 1.338e-01, MSE(pi3): 1.017e-01\n",
      "Epoch 12400, Train loss: 2.167e+06, Test loss: 2.429e+07, MSE(e): 2.152e-01, MSE(pi1): 4.102e-01, MSE(pi2): 1.327e-01, MSE(pi3): 1.011e-01\n",
      "Epoch 12500, Train loss: 2.150e+06, Test loss: 2.424e+07, MSE(e): 2.136e-01, MSE(pi1): 4.069e-01, MSE(pi2): 1.317e-01, MSE(pi3): 1.007e-01\n",
      "Epoch 12600, Train loss: 2.134e+06, Test loss: 2.422e+07, MSE(e): 2.120e-01, MSE(pi1): 4.043e-01, MSE(pi2): 1.307e-01, MSE(pi3): 1.001e-01\n",
      "Epoch 12700, Train loss: 2.119e+06, Test loss: 2.419e+07, MSE(e): 2.105e-01, MSE(pi1): 4.016e-01, MSE(pi2): 1.297e-01, MSE(pi3): 9.960e-02\n",
      "Epoch 12800, Train loss: 2.104e+06, Test loss: 2.417e+07, MSE(e): 2.090e-01, MSE(pi1): 3.989e-01, MSE(pi2): 1.288e-01, MSE(pi3): 9.910e-02\n",
      "Epoch 12900, Train loss: 2.089e+06, Test loss: 2.414e+07, MSE(e): 2.075e-01, MSE(pi1): 3.963e-01, MSE(pi2): 1.279e-01, MSE(pi3): 9.864e-02\n",
      "Epoch 13000, Train loss: 2.074e+06, Test loss: 2.411e+07, MSE(e): 2.060e-01, MSE(pi1): 3.940e-01, MSE(pi2): 1.269e-01, MSE(pi3): 9.817e-02\n",
      "Epoch 13100, Train loss: 2.059e+06, Test loss: 2.409e+07, MSE(e): 2.046e-01, MSE(pi1): 3.916e-01, MSE(pi2): 1.260e-01, MSE(pi3): 9.771e-02\n",
      "Epoch 13200, Train loss: 2.045e+06, Test loss: 2.406e+07, MSE(e): 2.031e-01, MSE(pi1): 3.891e-01, MSE(pi2): 1.251e-01, MSE(pi3): 9.730e-02\n",
      "Epoch 13300, Train loss: 2.031e+06, Test loss: 2.403e+07, MSE(e): 2.017e-01, MSE(pi1): 3.868e-01, MSE(pi2): 1.243e-01, MSE(pi3): 9.686e-02\n",
      "Epoch 13400, Train loss: 2.016e+06, Test loss: 2.399e+07, MSE(e): 2.003e-01, MSE(pi1): 3.858e-01, MSE(pi2): 1.234e-01, MSE(pi3): 9.647e-02\n",
      "Epoch 13500, Train loss: 2.002e+06, Test loss: 2.399e+07, MSE(e): 1.988e-01, MSE(pi1): 3.831e-01, MSE(pi2): 1.225e-01, MSE(pi3): 9.590e-02\n",
      "Epoch 13600, Train loss: 1.988e+06, Test loss: 2.393e+07, MSE(e): 1.975e-01, MSE(pi1): 3.801e-01, MSE(pi2): 1.216e-01, MSE(pi3): 9.573e-02\n",
      "Epoch 13700, Train loss: 1.974e+06, Test loss: 2.394e+07, MSE(e): 1.960e-01, MSE(pi1): 3.782e-01, MSE(pi2): 1.208e-01, MSE(pi3): 9.508e-02\n",
      "Epoch 13800, Train loss: 1.960e+06, Test loss: 2.392e+07, MSE(e): 1.946e-01, MSE(pi1): 3.761e-01, MSE(pi2): 1.199e-01, MSE(pi3): 9.463e-02\n",
      "Epoch 13900, Train loss: 1.946e+06, Test loss: 2.389e+07, MSE(e): 1.932e-01, MSE(pi1): 3.737e-01, MSE(pi2): 1.190e-01, MSE(pi3): 9.422e-02\n",
      "Epoch 14000, Train loss: 1.932e+06, Test loss: 2.387e+07, MSE(e): 1.918e-01, MSE(pi1): 3.716e-01, MSE(pi2): 1.182e-01, MSE(pi3): 9.377e-02\n",
      "Epoch 14100, Train loss: 1.917e+06, Test loss: 2.385e+07, MSE(e): 1.904e-01, MSE(pi1): 3.694e-01, MSE(pi2): 1.173e-01, MSE(pi3): 9.331e-02\n",
      "Epoch 14200, Train loss: 1.903e+06, Test loss: 2.382e+07, MSE(e): 1.890e-01, MSE(pi1): 3.672e-01, MSE(pi2): 1.165e-01, MSE(pi3): 9.284e-02\n",
      "Epoch 14300, Train loss: 1.889e+06, Test loss: 2.380e+07, MSE(e): 1.876e-01, MSE(pi1): 3.651e-01, MSE(pi2): 1.156e-01, MSE(pi3): 9.239e-02\n",
      "Epoch 14400, Train loss: 1.875e+06, Test loss: 2.377e+07, MSE(e): 1.862e-01, MSE(pi1): 3.625e-01, MSE(pi2): 1.148e-01, MSE(pi3): 9.195e-02\n",
      "Epoch 14500, Train loss: 1.860e+06, Test loss: 2.377e+07, MSE(e): 1.847e-01, MSE(pi1): 3.615e-01, MSE(pi2): 1.139e-01, MSE(pi3): 9.134e-02\n",
      "Epoch 14600, Train loss: 1.846e+06, Test loss: 2.373e+07, MSE(e): 1.833e-01, MSE(pi1): 3.584e-01, MSE(pi2): 1.130e-01, MSE(pi3): 9.094e-02\n",
      "Epoch 14700, Train loss: 1.831e+06, Test loss: 2.373e+07, MSE(e): 1.819e-01, MSE(pi1): 3.643e-01, MSE(pi2): 1.122e-01, MSE(pi3): 9.024e-02\n",
      "Epoch 14800, Train loss: 1.817e+06, Test loss: 2.369e+07, MSE(e): 1.804e-01, MSE(pi1): 3.549e-01, MSE(pi2): 1.113e-01, MSE(pi3): 8.993e-02\n",
      "Epoch 14900, Train loss: 1.802e+06, Test loss: 2.366e+07, MSE(e): 1.789e-01, MSE(pi1): 3.526e-01, MSE(pi2): 1.104e-01, MSE(pi3): 8.936e-02\n",
      "Epoch 15000, Train loss: 1.787e+06, Test loss: 2.364e+07, MSE(e): 1.775e-01, MSE(pi1): 3.496e-01, MSE(pi2): 1.095e-01, MSE(pi3): 8.889e-02\n",
      "Epoch 15100, Train loss: 1.772e+06, Test loss: 2.362e+07, MSE(e): 1.760e-01, MSE(pi1): 3.476e-01, MSE(pi2): 1.087e-01, MSE(pi3): 8.833e-02\n",
      "Epoch 15200, Train loss: 1.757e+06, Test loss: 2.360e+07, MSE(e): 1.745e-01, MSE(pi1): 3.453e-01, MSE(pi2): 1.078e-01, MSE(pi3): 8.782e-02\n",
      "Epoch 15300, Train loss: 1.742e+06, Test loss: 2.358e+07, MSE(e): 1.730e-01, MSE(pi1): 3.429e-01, MSE(pi2): 1.069e-01, MSE(pi3): 8.727e-02\n",
      "Epoch 15400, Train loss: 1.727e+06, Test loss: 2.358e+07, MSE(e): 1.715e-01, MSE(pi1): 3.418e-01, MSE(pi2): 1.060e-01, MSE(pi3): 8.666e-02\n",
      "Epoch 15500, Train loss: 1.712e+06, Test loss: 2.354e+07, MSE(e): 1.700e-01, MSE(pi1): 3.387e-01, MSE(pi2): 1.051e-01, MSE(pi3): 8.613e-02\n",
      "Epoch 15600, Train loss: 1.697e+06, Test loss: 2.351e+07, MSE(e): 1.685e-01, MSE(pi1): 3.360e-01, MSE(pi2): 1.042e-01, MSE(pi3): 8.560e-02\n",
      "Epoch 15700, Train loss: 1.682e+06, Test loss: 2.348e+07, MSE(e): 1.670e-01, MSE(pi1): 3.353e-01, MSE(pi2): 1.033e-01, MSE(pi3): 8.512e-02\n",
      "Epoch 15800, Train loss: 1.666e+06, Test loss: 2.348e+07, MSE(e): 1.654e-01, MSE(pi1): 3.317e-01, MSE(pi2): 1.024e-01, MSE(pi3): 8.439e-02\n",
      "Epoch 15900, Train loss: 1.651e+06, Test loss: 2.346e+07, MSE(e): 1.639e-01, MSE(pi1): 3.292e-01, MSE(pi2): 1.015e-01, MSE(pi3): 8.385e-02\n",
      "Epoch 16000, Train loss: 1.636e+06, Test loss: 2.344e+07, MSE(e): 1.624e-01, MSE(pi1): 3.271e-01, MSE(pi2): 1.007e-01, MSE(pi3): 8.323e-02\n",
      "Epoch 16100, Train loss: 1.621e+06, Test loss: 2.343e+07, MSE(e): 1.610e-01, MSE(pi1): 3.249e-01, MSE(pi2): 9.979e-02, MSE(pi3): 8.264e-02\n",
      "Epoch 16200, Train loss: 1.606e+06, Test loss: 2.341e+07, MSE(e): 1.595e-01, MSE(pi1): 3.251e-01, MSE(pi2): 9.893e-02, MSE(pi3): 8.198e-02\n",
      "Epoch 16300, Train loss: 1.591e+06, Test loss: 2.339e+07, MSE(e): 1.580e-01, MSE(pi1): 3.204e-01, MSE(pi2): 9.806e-02, MSE(pi3): 8.143e-02\n",
      "Epoch 16400, Train loss: 1.576e+06, Test loss: 2.337e+07, MSE(e): 1.565e-01, MSE(pi1): 3.177e-01, MSE(pi2): 9.720e-02, MSE(pi3): 8.088e-02\n",
      "Epoch 16500, Train loss: 1.562e+06, Test loss: 2.336e+07, MSE(e): 1.550e-01, MSE(pi1): 3.154e-01, MSE(pi2): 9.635e-02, MSE(pi3): 8.029e-02\n",
      "Epoch 16600, Train loss: 1.547e+06, Test loss: 2.336e+07, MSE(e): 1.536e-01, MSE(pi1): 3.143e-01, MSE(pi2): 9.551e-02, MSE(pi3): 7.956e-02\n",
      "Epoch 16700, Train loss: 1.532e+06, Test loss: 2.333e+07, MSE(e): 1.521e-01, MSE(pi1): 3.114e-01, MSE(pi2): 9.467e-02, MSE(pi3): 7.918e-02\n",
      "Epoch 16800, Train loss: 1.518e+06, Test loss: 2.332e+07, MSE(e): 1.507e-01, MSE(pi1): 3.083e-01, MSE(pi2): 9.383e-02, MSE(pi3): 7.852e-02\n",
      "Epoch 16900, Train loss: 1.503e+06, Test loss: 2.329e+07, MSE(e): 1.492e-01, MSE(pi1): 3.068e-01, MSE(pi2): 9.298e-02, MSE(pi3): 7.793e-02\n",
      "Epoch 17000, Train loss: 1.489e+06, Test loss: 2.328e+07, MSE(e): 1.478e-01, MSE(pi1): 3.034e-01, MSE(pi2): 9.216e-02, MSE(pi3): 7.735e-02\n",
      "Epoch 17100, Train loss: 1.474e+06, Test loss: 2.327e+07, MSE(e): 1.464e-01, MSE(pi1): 3.006e-01, MSE(pi2): 9.132e-02, MSE(pi3): 7.683e-02\n",
      "Epoch 17200, Train loss: 1.461e+06, Test loss: 2.325e+07, MSE(e): 1.450e-01, MSE(pi1): 2.990e-01, MSE(pi2): 9.052e-02, MSE(pi3): 7.622e-02\n",
      "Epoch 17300, Train loss: 1.446e+06, Test loss: 2.323e+07, MSE(e): 1.436e-01, MSE(pi1): 3.003e-01, MSE(pi2): 8.968e-02, MSE(pi3): 7.560e-02\n",
      "Epoch 17400, Train loss: 1.432e+06, Test loss: 2.321e+07, MSE(e): 1.421e-01, MSE(pi1): 2.940e-01, MSE(pi2): 8.884e-02, MSE(pi3): 7.510e-02\n",
      "Epoch 17500, Train loss: 1.417e+06, Test loss: 2.320e+07, MSE(e): 1.407e-01, MSE(pi1): 2.922e-01, MSE(pi2): 8.799e-02, MSE(pi3): 7.454e-02\n",
      "Epoch 17600, Train loss: 1.403e+06, Test loss: 2.318e+07, MSE(e): 1.393e-01, MSE(pi1): 2.889e-01, MSE(pi2): 8.714e-02, MSE(pi3): 7.386e-02\n",
      "Epoch 17700, Train loss: 1.389e+06, Test loss: 2.316e+07, MSE(e): 1.378e-01, MSE(pi1): 2.866e-01, MSE(pi2): 8.629e-02, MSE(pi3): 7.324e-02\n",
      "Epoch 17800, Train loss: 1.374e+06, Test loss: 2.313e+07, MSE(e): 1.364e-01, MSE(pi1): 2.834e-01, MSE(pi2): 8.542e-02, MSE(pi3): 7.275e-02\n",
      "Epoch 17900, Train loss: 1.360e+06, Test loss: 2.311e+07, MSE(e): 1.350e-01, MSE(pi1): 2.854e-01, MSE(pi2): 8.456e-02, MSE(pi3): 7.205e-02\n",
      "Epoch 18000, Train loss: 1.346e+06, Test loss: 2.309e+07, MSE(e): 1.336e-01, MSE(pi1): 2.788e-01, MSE(pi2): 8.369e-02, MSE(pi3): 7.143e-02\n",
      "Epoch 18100, Train loss: 1.331e+06, Test loss: 2.305e+07, MSE(e): 1.321e-01, MSE(pi1): 2.760e-01, MSE(pi2): 8.280e-02, MSE(pi3): 7.093e-02\n",
      "Epoch 18200, Train loss: 1.317e+06, Test loss: 2.305e+07, MSE(e): 1.307e-01, MSE(pi1): 2.765e-01, MSE(pi2): 8.192e-02, MSE(pi3): 6.991e-02\n",
      "Epoch 18300, Train loss: 1.302e+06, Test loss: 2.301e+07, MSE(e): 1.292e-01, MSE(pi1): 2.706e-01, MSE(pi2): 8.102e-02, MSE(pi3): 6.954e-02\n",
      "Epoch 18400, Train loss: 1.287e+06, Test loss: 2.299e+07, MSE(e): 1.278e-01, MSE(pi1): 2.680e-01, MSE(pi2): 8.011e-02, MSE(pi3): 6.888e-02\n",
      "Epoch 18500, Train loss: 1.273e+06, Test loss: 2.296e+07, MSE(e): 1.263e-01, MSE(pi1): 2.651e-01, MSE(pi2): 7.922e-02, MSE(pi3): 6.825e-02\n",
      "Epoch 18600, Train loss: 1.258e+06, Test loss: 2.293e+07, MSE(e): 1.249e-01, MSE(pi1): 2.622e-01, MSE(pi2): 7.832e-02, MSE(pi3): 6.758e-02\n",
      "Epoch 18700, Train loss: 1.244e+06, Test loss: 2.291e+07, MSE(e): 1.235e-01, MSE(pi1): 2.595e-01, MSE(pi2): 7.743e-02, MSE(pi3): 6.702e-02\n",
      "Epoch 18800, Train loss: 1.230e+06, Test loss: 2.290e+07, MSE(e): 1.220e-01, MSE(pi1): 2.572e-01, MSE(pi2): 7.653e-02, MSE(pi3): 6.617e-02\n",
      "Epoch 18900, Train loss: 1.215e+06, Test loss: 2.285e+07, MSE(e): 1.206e-01, MSE(pi1): 2.541e-01, MSE(pi2): 7.562e-02, MSE(pi3): 6.580e-02\n",
      "Epoch 19000, Train loss: 1.201e+06, Test loss: 2.283e+07, MSE(e): 1.192e-01, MSE(pi1): 2.502e-01, MSE(pi2): 7.473e-02, MSE(pi3): 6.501e-02\n",
      "Epoch 19100, Train loss: 1.187e+06, Test loss: 2.281e+07, MSE(e): 1.178e-01, MSE(pi1): 2.477e-01, MSE(pi2): 7.385e-02, MSE(pi3): 6.436e-02\n",
      "Epoch 19200, Train loss: 1.173e+06, Test loss: 2.278e+07, MSE(e): 1.164e-01, MSE(pi1): 2.441e-01, MSE(pi2): 7.298e-02, MSE(pi3): 6.382e-02\n",
      "Epoch 19300, Train loss: 1.160e+06, Test loss: 2.277e+07, MSE(e): 1.151e-01, MSE(pi1): 2.417e-01, MSE(pi2): 7.213e-02, MSE(pi3): 6.313e-02\n",
      "Epoch 19400, Train loss: 1.147e+06, Test loss: 2.278e+07, MSE(e): 1.138e-01, MSE(pi1): 2.456e-01, MSE(pi2): 7.131e-02, MSE(pi3): 6.221e-02\n",
      "Epoch 19500, Train loss: 1.133e+06, Test loss: 2.273e+07, MSE(e): 1.125e-01, MSE(pi1): 2.367e-01, MSE(pi2): 7.046e-02, MSE(pi3): 6.191e-02\n",
      "Epoch 19600, Train loss: 1.120e+06, Test loss: 2.271e+07, MSE(e): 1.112e-01, MSE(pi1): 2.343e-01, MSE(pi2): 6.964e-02, MSE(pi3): 6.132e-02\n",
      "Epoch 19700, Train loss: 1.108e+06, Test loss: 2.269e+07, MSE(e): 1.099e-01, MSE(pi1): 2.320e-01, MSE(pi2): 6.885e-02, MSE(pi3): 6.075e-02\n",
      "Epoch 19800, Train loss: 1.096e+06, Test loss: 2.267e+07, MSE(e): 1.087e-01, MSE(pi1): 2.298e-01, MSE(pi2): 6.807e-02, MSE(pi3): 6.019e-02\n",
      "Epoch 19900, Train loss: 1.084e+06, Test loss: 2.267e+07, MSE(e): 1.075e-01, MSE(pi1): 2.287e-01, MSE(pi2): 6.731e-02, MSE(pi3): 5.949e-02\n",
      "Epoch 20000, Train loss: 1.072e+06, Test loss: 2.264e+07, MSE(e): 1.064e-01, MSE(pi1): 2.271e-01, MSE(pi2): 6.655e-02, MSE(pi3): 5.919e-02\n",
      "Epoch 20100, Train loss: 1.060e+06, Test loss: 2.263e+07, MSE(e): 1.052e-01, MSE(pi1): 2.238e-01, MSE(pi2): 6.581e-02, MSE(pi3): 5.854e-02\n",
      "Epoch 20200, Train loss: 1.049e+06, Test loss: 2.262e+07, MSE(e): 1.041e-01, MSE(pi1): 2.219e-01, MSE(pi2): 6.509e-02, MSE(pi3): 5.801e-02\n",
      "Epoch 20300, Train loss: 1.038e+06, Test loss: 2.260e+07, MSE(e): 1.030e-01, MSE(pi1): 2.202e-01, MSE(pi2): 6.439e-02, MSE(pi3): 5.749e-02\n",
      "Epoch 20400, Train loss: 1.028e+06, Test loss: 2.259e+07, MSE(e): 1.020e-01, MSE(pi1): 2.237e-01, MSE(pi2): 6.371e-02, MSE(pi3): 5.678e-02\n",
      "Epoch 20500, Train loss: 1.017e+06, Test loss: 2.258e+07, MSE(e): 1.009e-01, MSE(pi1): 2.167e-01, MSE(pi2): 6.304e-02, MSE(pi3): 5.651e-02\n",
      "Epoch 20600, Train loss: 1.007e+06, Test loss: 2.256e+07, MSE(e): 9.992e-02, MSE(pi1): 2.151e-01, MSE(pi2): 6.238e-02, MSE(pi3): 5.602e-02\n",
      "Epoch 20700, Train loss: 9.971e+05, Test loss: 2.255e+07, MSE(e): 9.893e-02, MSE(pi1): 2.135e-01, MSE(pi2): 6.174e-02, MSE(pi3): 5.556e-02\n",
      "Epoch 20800, Train loss: 9.876e+05, Test loss: 2.254e+07, MSE(e): 9.799e-02, MSE(pi1): 2.132e-01, MSE(pi2): 6.112e-02, MSE(pi3): 5.517e-02\n",
      "Epoch 20900, Train loss: 9.784e+05, Test loss: 2.251e+07, MSE(e): 9.707e-02, MSE(pi1): 2.111e-01, MSE(pi2): 6.051e-02, MSE(pi3): 5.491e-02\n",
      "Epoch 21000, Train loss: 9.691e+05, Test loss: 2.253e+07, MSE(e): 9.615e-02, MSE(pi1): 2.091e-01, MSE(pi2): 5.992e-02, MSE(pi3): 5.421e-02\n",
      "Epoch 21100, Train loss: 9.601e+05, Test loss: 2.252e+07, MSE(e): 9.526e-02, MSE(pi1): 2.078e-01, MSE(pi2): 5.933e-02, MSE(pi3): 5.379e-02\n",
      "Epoch 21200, Train loss: 9.514e+05, Test loss: 2.251e+07, MSE(e): 9.440e-02, MSE(pi1): 2.060e-01, MSE(pi2): 5.876e-02, MSE(pi3): 5.342e-02\n",
      "Epoch 21300, Train loss: 9.429e+05, Test loss: 2.251e+07, MSE(e): 9.355e-02, MSE(pi1): 2.051e-01, MSE(pi2): 5.820e-02, MSE(pi3): 5.294e-02\n",
      "Epoch 21400, Train loss: 9.348e+05, Test loss: 2.251e+07, MSE(e): 9.274e-02, MSE(pi1): 2.038e-01, MSE(pi2): 5.767e-02, MSE(pi3): 5.255e-02\n",
      "Epoch 21500, Train loss: 9.273e+05, Test loss: 2.247e+07, MSE(e): 9.199e-02, MSE(pi1): 2.034e-01, MSE(pi2): 5.716e-02, MSE(pi3): 5.251e-02\n",
      "Epoch 21600, Train loss: 9.189e+05, Test loss: 2.250e+07, MSE(e): 9.116e-02, MSE(pi1): 2.015e-01, MSE(pi2): 5.663e-02, MSE(pi3): 5.177e-02\n",
      "Epoch 21700, Train loss: 9.112e+05, Test loss: 2.250e+07, MSE(e): 9.040e-02, MSE(pi1): 2.003e-01, MSE(pi2): 5.612e-02, MSE(pi3): 5.138e-02\n",
      "Epoch 21800, Train loss: 9.038e+05, Test loss: 2.250e+07, MSE(e): 8.966e-02, MSE(pi1): 1.988e-01, MSE(pi2): 5.563e-02, MSE(pi3): 5.110e-02\n",
      "Epoch 21900, Train loss: 8.964e+05, Test loss: 2.251e+07, MSE(e): 8.893e-02, MSE(pi1): 1.986e-01, MSE(pi2): 5.514e-02, MSE(pi3): 5.061e-02\n",
      "Epoch 22000, Train loss: 8.893e+05, Test loss: 2.252e+07, MSE(e): 8.822e-02, MSE(pi1): 1.969e-01, MSE(pi2): 5.467e-02, MSE(pi3): 5.032e-02\n",
      "Epoch 22100, Train loss: 8.825e+05, Test loss: 2.251e+07, MSE(e): 8.755e-02, MSE(pi1): 1.957e-01, MSE(pi2): 5.422e-02, MSE(pi3): 5.009e-02\n",
      "Epoch 22200, Train loss: 8.756e+05, Test loss: 2.253e+07, MSE(e): 8.686e-02, MSE(pi1): 1.953e-01, MSE(pi2): 5.376e-02, MSE(pi3): 4.970e-02\n",
      "Epoch 22300, Train loss: 8.690e+05, Test loss: 2.254e+07, MSE(e): 8.621e-02, MSE(pi1): 1.940e-01, MSE(pi2): 5.332e-02, MSE(pi3): 4.932e-02\n",
      "Epoch 22400, Train loss: 8.626e+05, Test loss: 2.252e+07, MSE(e): 8.557e-02, MSE(pi1): 1.928e-01, MSE(pi2): 5.289e-02, MSE(pi3): 4.907e-02\n",
      "Epoch 22500, Train loss: 8.565e+05, Test loss: 2.256e+07, MSE(e): 8.496e-02, MSE(pi1): 1.919e-01, MSE(pi2): 5.249e-02, MSE(pi3): 4.871e-02\n",
      "Epoch 22600, Train loss: 8.504e+05, Test loss: 2.258e+07, MSE(e): 8.436e-02, MSE(pi1): 1.911e-01, MSE(pi2): 5.208e-02, MSE(pi3): 4.838e-02\n",
      "Epoch 22700, Train loss: 8.445e+05, Test loss: 2.260e+07, MSE(e): 8.377e-02, MSE(pi1): 1.901e-01, MSE(pi2): 5.169e-02, MSE(pi3): 4.808e-02\n",
      "Epoch 22800, Train loss: 8.387e+05, Test loss: 2.260e+07, MSE(e): 8.320e-02, MSE(pi1): 1.894e-01, MSE(pi2): 5.130e-02, MSE(pi3): 4.781e-02\n",
      "Epoch 22900, Train loss: 8.331e+05, Test loss: 2.263e+07, MSE(e): 8.264e-02, MSE(pi1): 1.883e-01, MSE(pi2): 5.092e-02, MSE(pi3): 4.753e-02\n",
      "Epoch 23000, Train loss: 8.276e+05, Test loss: 2.265e+07, MSE(e): 8.210e-02, MSE(pi1): 1.875e-01, MSE(pi2): 5.055e-02, MSE(pi3): 4.725e-02\n",
      "Epoch 23100, Train loss: 8.232e+05, Test loss: 2.271e+07, MSE(e): 8.165e-02, MSE(pi1): 1.892e-01, MSE(pi2): 5.024e-02, MSE(pi3): 4.671e-02\n",
      "Epoch 23200, Train loss: 8.170e+05, Test loss: 2.270e+07, MSE(e): 8.104e-02, MSE(pi1): 1.868e-01, MSE(pi2): 4.984e-02, MSE(pi3): 4.670e-02\n",
      "Epoch 23300, Train loss: 8.119e+05, Test loss: 2.272e+07, MSE(e): 8.054e-02, MSE(pi1): 1.851e-01, MSE(pi2): 4.949e-02, MSE(pi3): 4.647e-02\n",
      "Epoch 23400, Train loss: 8.071e+05, Test loss: 2.274e+07, MSE(e): 8.005e-02, MSE(pi1): 1.840e-01, MSE(pi2): 4.916e-02, MSE(pi3): 4.632e-02\n",
      "Epoch 23500, Train loss: 8.021e+05, Test loss: 2.277e+07, MSE(e): 7.956e-02, MSE(pi1): 1.837e-01, MSE(pi2): 4.883e-02, MSE(pi3): 4.596e-02\n",
      "Epoch 23600, Train loss: 7.974e+05, Test loss: 2.279e+07, MSE(e): 7.910e-02, MSE(pi1): 1.827e-01, MSE(pi2): 4.851e-02, MSE(pi3): 4.577e-02\n",
      "Epoch 23700, Train loss: 7.929e+05, Test loss: 2.282e+07, MSE(e): 7.865e-02, MSE(pi1): 1.823e-01, MSE(pi2): 4.820e-02, MSE(pi3): 4.550e-02\n",
      "Epoch 23800, Train loss: 7.884e+05, Test loss: 2.285e+07, MSE(e): 7.820e-02, MSE(pi1): 1.815e-01, MSE(pi2): 4.789e-02, MSE(pi3): 4.536e-02\n",
      "Epoch 23900, Train loss: 7.841e+05, Test loss: 2.287e+07, MSE(e): 7.778e-02, MSE(pi1): 1.810e-01, MSE(pi2): 4.760e-02, MSE(pi3): 4.506e-02\n",
      "Epoch 24000, Train loss: 7.799e+05, Test loss: 2.291e+07, MSE(e): 7.735e-02, MSE(pi1): 1.806e-01, MSE(pi2): 4.731e-02, MSE(pi3): 4.481e-02\n",
      "Epoch 24100, Train loss: 7.757e+05, Test loss: 2.293e+07, MSE(e): 7.694e-02, MSE(pi1): 1.796e-01, MSE(pi2): 4.702e-02, MSE(pi3): 4.465e-02\n",
      "Epoch 24200, Train loss: 7.717e+05, Test loss: 2.296e+07, MSE(e): 7.654e-02, MSE(pi1): 1.802e-01, MSE(pi2): 4.674e-02, MSE(pi3): 4.444e-02\n",
      "Epoch 24300, Train loss: 7.678e+05, Test loss: 2.297e+07, MSE(e): 7.615e-02, MSE(pi1): 1.806e-01, MSE(pi2): 4.647e-02, MSE(pi3): 4.424e-02\n",
      "Epoch 24400, Train loss: 7.639e+05, Test loss: 2.301e+07, MSE(e): 7.576e-02, MSE(pi1): 1.779e-01, MSE(pi2): 4.621e-02, MSE(pi3): 4.404e-02\n",
      "Epoch 24500, Train loss: 7.601e+05, Test loss: 2.304e+07, MSE(e): 7.539e-02, MSE(pi1): 1.772e-01, MSE(pi2): 4.595e-02, MSE(pi3): 4.388e-02\n",
      "Epoch 24600, Train loss: 7.564e+05, Test loss: 2.307e+07, MSE(e): 7.503e-02, MSE(pi1): 1.771e-01, MSE(pi2): 4.569e-02, MSE(pi3): 4.369e-02\n",
      "Epoch 24700, Train loss: 7.529e+05, Test loss: 2.310e+07, MSE(e): 7.468e-02, MSE(pi1): 1.762e-01, MSE(pi2): 4.545e-02, MSE(pi3): 4.351e-02\n",
      "Epoch 24800, Train loss: 7.494e+05, Test loss: 2.312e+07, MSE(e): 7.433e-02, MSE(pi1): 1.760e-01, MSE(pi2): 4.521e-02, MSE(pi3): 4.333e-02\n",
      "Epoch 24900, Train loss: 7.460e+05, Test loss: 2.316e+07, MSE(e): 7.399e-02, MSE(pi1): 1.752e-01, MSE(pi2): 4.498e-02, MSE(pi3): 4.316e-02\n",
      "Epoch 25000, Train loss: 7.427e+05, Test loss: 2.318e+07, MSE(e): 7.366e-02, MSE(pi1): 1.746e-01, MSE(pi2): 4.475e-02, MSE(pi3): 4.303e-02\n",
      "Epoch 25100, Train loss: 7.395e+05, Test loss: 2.321e+07, MSE(e): 7.334e-02, MSE(pi1): 1.741e-01, MSE(pi2): 4.452e-02, MSE(pi3): 4.285e-02\n",
      "Epoch 25200, Train loss: 7.363e+05, Test loss: 2.324e+07, MSE(e): 7.303e-02, MSE(pi1): 1.737e-01, MSE(pi2): 4.430e-02, MSE(pi3): 4.269e-02\n",
      "Epoch 25300, Train loss: 7.334e+05, Test loss: 2.324e+07, MSE(e): 7.274e-02, MSE(pi1): 1.729e-01, MSE(pi2): 4.410e-02, MSE(pi3): 4.266e-02\n",
      "Epoch 25400, Train loss: 7.303e+05, Test loss: 2.328e+07, MSE(e): 7.242e-02, MSE(pi1): 1.723e-01, MSE(pi2): 4.388e-02, MSE(pi3): 4.249e-02\n",
      "Epoch 25500, Train loss: 7.272e+05, Test loss: 2.333e+07, MSE(e): 7.212e-02, MSE(pi1): 1.727e-01, MSE(pi2): 4.367e-02, MSE(pi3): 4.225e-02\n",
      "Epoch 25600, Train loss: 7.244e+05, Test loss: 2.337e+07, MSE(e): 7.185e-02, MSE(pi1): 1.731e-01, MSE(pi2): 4.348e-02, MSE(pi3): 4.195e-02\n",
      "Epoch 25700, Train loss: 7.215e+05, Test loss: 2.337e+07, MSE(e): 7.154e-02, MSE(pi1): 1.784e-01, MSE(pi2): 4.327e-02, MSE(pi3): 4.217e-02\n",
      "Epoch 25800, Train loss: 7.187e+05, Test loss: 2.342e+07, MSE(e): 7.128e-02, MSE(pi1): 1.720e-01, MSE(pi2): 4.309e-02, MSE(pi3): 4.173e-02\n",
      "Epoch 25900, Train loss: 7.159e+05, Test loss: 2.342e+07, MSE(e): 7.100e-02, MSE(pi1): 1.764e-01, MSE(pi2): 4.289e-02, MSE(pi3): 4.152e-02\n",
      "Epoch 26000, Train loss: 7.132e+05, Test loss: 2.345e+07, MSE(e): 7.073e-02, MSE(pi1): 1.706e-01, MSE(pi2): 4.271e-02, MSE(pi3): 4.150e-02\n",
      "Epoch 26100, Train loss: 7.114e+05, Test loss: 2.350e+07, MSE(e): 7.055e-02, MSE(pi1): 1.738e-01, MSE(pi2): 4.257e-02, MSE(pi3): 4.114e-02\n",
      "Epoch 26200, Train loss: 7.080e+05, Test loss: 2.349e+07, MSE(e): 7.021e-02, MSE(pi1): 1.699e-01, MSE(pi2): 4.235e-02, MSE(pi3): 4.129e-02\n",
      "Epoch 26300, Train loss: 7.055e+05, Test loss: 2.349e+07, MSE(e): 6.996e-02, MSE(pi1): 1.695e-01, MSE(pi2): 4.217e-02, MSE(pi3): 4.124e-02\n",
      "Epoch 26400, Train loss: 7.030e+05, Test loss: 2.354e+07, MSE(e): 6.972e-02, MSE(pi1): 1.688e-01, MSE(pi2): 4.200e-02, MSE(pi3): 4.105e-02\n",
      "Epoch 26500, Train loss: 7.005e+05, Test loss: 2.357e+07, MSE(e): 6.947e-02, MSE(pi1): 1.686e-01, MSE(pi2): 4.183e-02, MSE(pi3): 4.096e-02\n",
      "Epoch 26600, Train loss: 6.981e+05, Test loss: 2.359e+07, MSE(e): 6.923e-02, MSE(pi1): 1.682e-01, MSE(pi2): 4.167e-02, MSE(pi3): 4.080e-02\n",
      "Epoch 26700, Train loss: 6.969e+05, Test loss: 2.357e+07, MSE(e): 6.910e-02, MSE(pi1): 1.740e-01, MSE(pi2): 4.155e-02, MSE(pi3): 4.126e-02\n",
      "Epoch 26800, Train loss: 6.934e+05, Test loss: 2.363e+07, MSE(e): 6.876e-02, MSE(pi1): 1.675e-01, MSE(pi2): 4.134e-02, MSE(pi3): 4.058e-02\n",
      "Epoch 26900, Train loss: 6.911e+05, Test loss: 2.365e+07, MSE(e): 6.853e-02, MSE(pi1): 1.671e-01, MSE(pi2): 4.119e-02, MSE(pi3): 4.048e-02\n",
      "Epoch 27000, Train loss: 6.888e+05, Test loss: 2.369e+07, MSE(e): 6.830e-02, MSE(pi1): 1.677e-01, MSE(pi2): 4.103e-02, MSE(pi3): 4.035e-02\n",
      "Epoch 27100, Train loss: 6.866e+05, Test loss: 2.370e+07, MSE(e): 6.808e-02, MSE(pi1): 1.665e-01, MSE(pi2): 4.088e-02, MSE(pi3): 4.025e-02\n",
      "Epoch 27200, Train loss: 6.843e+05, Test loss: 2.373e+07, MSE(e): 6.786e-02, MSE(pi1): 1.662e-01, MSE(pi2): 4.073e-02, MSE(pi3): 4.013e-02\n",
      "Epoch 27300, Train loss: 6.822e+05, Test loss: 2.375e+07, MSE(e): 6.765e-02, MSE(pi1): 1.657e-01, MSE(pi2): 4.058e-02, MSE(pi3): 4.004e-02\n",
      "Epoch 27400, Train loss: 6.808e+05, Test loss: 2.380e+07, MSE(e): 6.751e-02, MSE(pi1): 1.690e-01, MSE(pi2): 4.047e-02, MSE(pi3): 3.978e-02\n",
      "Epoch 27500, Train loss: 6.779e+05, Test loss: 2.379e+07, MSE(e): 6.722e-02, MSE(pi1): 1.659e-01, MSE(pi2): 4.028e-02, MSE(pi3): 3.979e-02\n",
      "Epoch 27600, Train loss: 6.758e+05, Test loss: 2.382e+07, MSE(e): 6.701e-02, MSE(pi1): 1.654e-01, MSE(pi2): 4.014e-02, MSE(pi3): 3.966e-02\n",
      "Epoch 27700, Train loss: 6.738e+05, Test loss: 2.386e+07, MSE(e): 6.681e-02, MSE(pi1): 1.698e-01, MSE(pi2): 4.000e-02, MSE(pi3): 3.943e-02\n",
      "Epoch 27800, Train loss: 6.716e+05, Test loss: 2.386e+07, MSE(e): 6.659e-02, MSE(pi1): 1.643e-01, MSE(pi2): 3.985e-02, MSE(pi3): 3.952e-02\n",
      "Epoch 27900, Train loss: 6.695e+05, Test loss: 2.388e+07, MSE(e): 6.639e-02, MSE(pi1): 1.645e-01, MSE(pi2): 3.971e-02, MSE(pi3): 3.940e-02\n",
      "Epoch 28000, Train loss: 6.676e+05, Test loss: 2.393e+07, MSE(e): 6.620e-02, MSE(pi1): 1.646e-01, MSE(pi2): 3.959e-02, MSE(pi3): 3.921e-02\n",
      "Epoch 28100, Train loss: 6.655e+05, Test loss: 2.393e+07, MSE(e): 6.599e-02, MSE(pi1): 1.634e-01, MSE(pi2): 3.944e-02, MSE(pi3): 3.923e-02\n",
      "Epoch 28200, Train loss: 6.641e+05, Test loss: 2.391e+07, MSE(e): 6.585e-02, MSE(pi1): 1.628e-01, MSE(pi2): 3.933e-02, MSE(pi3): 3.936e-02\n",
      "Epoch 28300, Train loss: 6.615e+05, Test loss: 2.397e+07, MSE(e): 6.560e-02, MSE(pi1): 1.630e-01, MSE(pi2): 3.918e-02, MSE(pi3): 3.903e-02\n",
      "Epoch 28400, Train loss: 6.597e+05, Test loss: 2.397e+07, MSE(e): 6.541e-02, MSE(pi1): 1.621e-01, MSE(pi2): 3.905e-02, MSE(pi3): 3.904e-02\n",
      "Epoch 28500, Train loss: 6.576e+05, Test loss: 2.402e+07, MSE(e): 6.521e-02, MSE(pi1): 1.623e-01, MSE(pi2): 3.891e-02, MSE(pi3): 3.884e-02\n",
      "Epoch 28600, Train loss: 6.557e+05, Test loss: 2.404e+07, MSE(e): 6.502e-02, MSE(pi1): 1.621e-01, MSE(pi2): 3.878e-02, MSE(pi3): 3.874e-02\n",
      "Epoch 28700, Train loss: 6.538e+05, Test loss: 2.408e+07, MSE(e): 6.483e-02, MSE(pi1): 1.623e-01, MSE(pi2): 3.865e-02, MSE(pi3): 3.858e-02\n",
      "Epoch 28800, Train loss: 6.519e+05, Test loss: 2.409e+07, MSE(e): 6.464e-02, MSE(pi1): 1.640e-01, MSE(pi2): 3.852e-02, MSE(pi3): 3.856e-02\n",
      "Epoch 28900, Train loss: 6.500e+05, Test loss: 2.412e+07, MSE(e): 6.446e-02, MSE(pi1): 1.617e-01, MSE(pi2): 3.840e-02, MSE(pi3): 3.841e-02\n",
      "Epoch 29000, Train loss: 6.481e+05, Test loss: 2.414e+07, MSE(e): 6.426e-02, MSE(pi1): 1.614e-01, MSE(pi2): 3.827e-02, MSE(pi3): 3.836e-02\n",
      "Epoch 29100, Train loss: 6.463e+05, Test loss: 2.417e+07, MSE(e): 6.408e-02, MSE(pi1): 1.610e-01, MSE(pi2): 3.815e-02, MSE(pi3): 3.825e-02\n",
      "Epoch 29200, Train loss: 6.444e+05, Test loss: 2.419e+07, MSE(e): 6.389e-02, MSE(pi1): 1.606e-01, MSE(pi2): 3.802e-02, MSE(pi3): 3.819e-02\n",
      "Epoch 29300, Train loss: 6.426e+05, Test loss: 2.421e+07, MSE(e): 6.371e-02, MSE(pi1): 1.603e-01, MSE(pi2): 3.790e-02, MSE(pi3): 3.809e-02\n",
      "Epoch 29400, Train loss: 6.408e+05, Test loss: 2.424e+07, MSE(e): 6.353e-02, MSE(pi1): 1.601e-01, MSE(pi2): 3.778e-02, MSE(pi3): 3.801e-02\n",
      "Epoch 29500, Train loss: 6.390e+05, Test loss: 2.426e+07, MSE(e): 6.335e-02, MSE(pi1): 1.597e-01, MSE(pi2): 3.765e-02, MSE(pi3): 3.793e-02\n",
      "Epoch 29600, Train loss: 6.372e+05, Test loss: 2.429e+07, MSE(e): 6.318e-02, MSE(pi1): 1.595e-01, MSE(pi2): 3.754e-02, MSE(pi3): 3.783e-02\n",
      "Epoch 29700, Train loss: 6.364e+05, Test loss: 2.428e+07, MSE(e): 6.310e-02, MSE(pi1): 1.608e-01, MSE(pi2): 3.746e-02, MSE(pi3): 3.809e-02\n",
      "Epoch 29800, Train loss: 6.336e+05, Test loss: 2.434e+07, MSE(e): 6.282e-02, MSE(pi1): 1.600e-01, MSE(pi2): 3.730e-02, MSE(pi3): 3.761e-02\n",
      "Epoch 29900, Train loss: 6.318e+05, Test loss: 2.437e+07, MSE(e): 6.264e-02, MSE(pi1): 1.588e-01, MSE(pi2): 3.718e-02, MSE(pi3): 3.756e-02\n",
      "Epoch 30000, Train loss: 6.300e+05, Test loss: 2.440e+07, MSE(e): 6.246e-02, MSE(pi1): 1.586e-01, MSE(pi2): 3.706e-02, MSE(pi3): 3.747e-02\n",
      "Epoch 30100, Train loss: 6.282e+05, Test loss: 2.443e+07, MSE(e): 6.229e-02, MSE(pi1): 1.585e-01, MSE(pi2): 3.694e-02, MSE(pi3): 3.738e-02\n",
      "Epoch 30200, Train loss: 6.266e+05, Test loss: 2.443e+07, MSE(e): 6.213e-02, MSE(pi1): 1.576e-01, MSE(pi2): 3.683e-02, MSE(pi3): 3.741e-02\n",
      "Epoch 30300, Train loss: 6.247e+05, Test loss: 2.449e+07, MSE(e): 6.194e-02, MSE(pi1): 1.580e-01, MSE(pi2): 3.671e-02, MSE(pi3): 3.720e-02\n",
      "Epoch 30400, Train loss: 6.230e+05, Test loss: 2.452e+07, MSE(e): 6.177e-02, MSE(pi1): 1.577e-01, MSE(pi2): 3.659e-02, MSE(pi3): 3.713e-02\n",
      "Epoch 30500, Train loss: 6.212e+05, Test loss: 2.455e+07, MSE(e): 6.159e-02, MSE(pi1): 1.575e-01, MSE(pi2): 3.647e-02, MSE(pi3): 3.704e-02\n",
      "Epoch 30600, Train loss: 6.196e+05, Test loss: 2.460e+07, MSE(e): 6.143e-02, MSE(pi1): 1.581e-01, MSE(pi2): 3.636e-02, MSE(pi3): 3.684e-02\n",
      "Epoch 30700, Train loss: 6.178e+05, Test loss: 2.461e+07, MSE(e): 6.125e-02, MSE(pi1): 1.571e-01, MSE(pi2): 3.624e-02, MSE(pi3): 3.686e-02\n",
      "Epoch 30800, Train loss: 6.160e+05, Test loss: 2.465e+07, MSE(e): 6.108e-02, MSE(pi1): 1.567e-01, MSE(pi2): 3.613e-02, MSE(pi3): 3.679e-02\n",
      "Epoch 30900, Train loss: 6.147e+05, Test loss: 2.472e+07, MSE(e): 6.094e-02, MSE(pi1): 1.583e-01, MSE(pi2): 3.603e-02, MSE(pi3): 3.650e-02\n",
      "Epoch 31000, Train loss: 6.126e+05, Test loss: 2.471e+07, MSE(e): 6.073e-02, MSE(pi1): 1.608e-01, MSE(pi2): 3.590e-02, MSE(pi3): 3.657e-02\n",
      "Epoch 31100, Train loss: 6.114e+05, Test loss: 2.478e+07, MSE(e): 6.061e-02, MSE(pi1): 1.580e-01, MSE(pi2): 3.581e-02, MSE(pi3): 3.636e-02\n",
      "Epoch 31200, Train loss: 6.093e+05, Test loss: 2.478e+07, MSE(e): 6.040e-02, MSE(pi1): 1.574e-01, MSE(pi2): 3.568e-02, MSE(pi3): 3.646e-02\n",
      "Epoch 31300, Train loss: 6.076e+05, Test loss: 2.481e+07, MSE(e): 6.023e-02, MSE(pi1): 1.622e-01, MSE(pi2): 3.556e-02, MSE(pi3): 3.622e-02\n",
      "Epoch 31400, Train loss: 6.058e+05, Test loss: 2.485e+07, MSE(e): 6.006e-02, MSE(pi1): 1.556e-01, MSE(pi2): 3.545e-02, MSE(pi3): 3.625e-02\n",
      "Epoch 31500, Train loss: 6.041e+05, Test loss: 2.489e+07, MSE(e): 5.989e-02, MSE(pi1): 1.570e-01, MSE(pi2): 3.534e-02, MSE(pi3): 3.609e-02\n",
      "Epoch 31600, Train loss: 6.024e+05, Test loss: 2.493e+07, MSE(e): 5.972e-02, MSE(pi1): 1.557e-01, MSE(pi2): 3.523e-02, MSE(pi3): 3.603e-02\n",
      "Epoch 31700, Train loss: 6.007e+05, Test loss: 2.496e+07, MSE(e): 5.955e-02, MSE(pi1): 1.556e-01, MSE(pi2): 3.511e-02, MSE(pi3): 3.607e-02\n",
      "Epoch 31800, Train loss: 5.990e+05, Test loss: 2.500e+07, MSE(e): 5.939e-02, MSE(pi1): 1.548e-01, MSE(pi2): 3.500e-02, MSE(pi3): 3.590e-02\n",
      "Epoch 31900, Train loss: 5.974e+05, Test loss: 2.504e+07, MSE(e): 5.922e-02, MSE(pi1): 1.543e-01, MSE(pi2): 3.489e-02, MSE(pi3): 3.589e-02\n",
      "Epoch 32000, Train loss: 5.957e+05, Test loss: 2.508e+07, MSE(e): 5.906e-02, MSE(pi1): 1.544e-01, MSE(pi2): 3.478e-02, MSE(pi3): 3.573e-02\n",
      "Epoch 32100, Train loss: 5.941e+05, Test loss: 2.513e+07, MSE(e): 5.890e-02, MSE(pi1): 1.551e-01, MSE(pi2): 3.468e-02, MSE(pi3): 3.555e-02\n",
      "Epoch 32200, Train loss: 5.924e+05, Test loss: 2.516e+07, MSE(e): 5.872e-02, MSE(pi1): 1.540e-01, MSE(pi2): 3.457e-02, MSE(pi3): 3.556e-02\n",
      "Epoch 32300, Train loss: 5.907e+05, Test loss: 2.520e+07, MSE(e): 5.856e-02, MSE(pi1): 1.538e-01, MSE(pi2): 3.446e-02, MSE(pi3): 3.548e-02\n",
      "Epoch 32400, Train loss: 5.891e+05, Test loss: 2.524e+07, MSE(e): 5.839e-02, MSE(pi1): 1.540e-01, MSE(pi2): 3.435e-02, MSE(pi3): 3.540e-02\n",
      "Epoch 32500, Train loss: 5.874e+05, Test loss: 2.528e+07, MSE(e): 5.823e-02, MSE(pi1): 1.545e-01, MSE(pi2): 3.424e-02, MSE(pi3): 3.539e-02\n",
      "Epoch 32600, Train loss: 5.857e+05, Test loss: 2.533e+07, MSE(e): 5.807e-02, MSE(pi1): 1.539e-01, MSE(pi2): 3.413e-02, MSE(pi3): 3.516e-02\n",
      "Epoch 32700, Train loss: 5.843e+05, Test loss: 2.534e+07, MSE(e): 5.793e-02, MSE(pi1): 1.528e-01, MSE(pi2): 3.403e-02, MSE(pi3): 3.525e-02\n",
      "Epoch 32800, Train loss: 5.824e+05, Test loss: 2.541e+07, MSE(e): 5.773e-02, MSE(pi1): 1.539e-01, MSE(pi2): 3.391e-02, MSE(pi3): 3.499e-02\n",
      "Epoch 32900, Train loss: 5.808e+05, Test loss: 2.546e+07, MSE(e): 5.757e-02, MSE(pi1): 1.527e-01, MSE(pi2): 3.381e-02, MSE(pi3): 3.497e-02\n",
      "Epoch 33000, Train loss: 5.792e+05, Test loss: 2.552e+07, MSE(e): 5.742e-02, MSE(pi1): 1.532e-01, MSE(pi2): 3.371e-02, MSE(pi3): 3.482e-02\n",
      "Epoch 33100, Train loss: 5.775e+05, Test loss: 2.555e+07, MSE(e): 5.724e-02, MSE(pi1): 1.524e-01, MSE(pi2): 3.359e-02, MSE(pi3): 3.479e-02\n",
      "Epoch 33200, Train loss: 5.759e+05, Test loss: 2.560e+07, MSE(e): 5.708e-02, MSE(pi1): 1.523e-01, MSE(pi2): 3.349e-02, MSE(pi3): 3.469e-02\n",
      "Epoch 33300, Train loss: 5.743e+05, Test loss: 2.564e+07, MSE(e): 5.692e-02, MSE(pi1): 1.523e-01, MSE(pi2): 3.339e-02, MSE(pi3): 3.460e-02\n",
      "Epoch 33400, Train loss: 5.726e+05, Test loss: 2.570e+07, MSE(e): 5.676e-02, MSE(pi1): 1.520e-01, MSE(pi2): 3.328e-02, MSE(pi3): 3.451e-02\n",
      "Epoch 33500, Train loss: 5.710e+05, Test loss: 2.573e+07, MSE(e): 5.660e-02, MSE(pi1): 1.520e-01, MSE(pi2): 3.317e-02, MSE(pi3): 3.447e-02\n",
      "Epoch 33600, Train loss: 5.694e+05, Test loss: 2.579e+07, MSE(e): 5.644e-02, MSE(pi1): 1.516e-01, MSE(pi2): 3.307e-02, MSE(pi3): 3.436e-02\n",
      "Epoch 33700, Train loss: 5.685e+05, Test loss: 2.589e+07, MSE(e): 5.635e-02, MSE(pi1): 1.533e-01, MSE(pi2): 3.301e-02, MSE(pi3): 3.410e-02\n",
      "Epoch 33800, Train loss: 5.661e+05, Test loss: 2.589e+07, MSE(e): 5.612e-02, MSE(pi1): 1.512e-01, MSE(pi2): 3.286e-02, MSE(pi3): 3.420e-02\n",
      "Epoch 33900, Train loss: 5.647e+05, Test loss: 2.596e+07, MSE(e): 5.597e-02, MSE(pi1): 1.518e-01, MSE(pi2): 3.277e-02, MSE(pi3): 3.405e-02\n",
      "Epoch 34000, Train loss: 5.629e+05, Test loss: 2.599e+07, MSE(e): 5.580e-02, MSE(pi1): 1.509e-01, MSE(pi2): 3.265e-02, MSE(pi3): 3.404e-02\n",
      "Epoch 34100, Train loss: 5.613e+05, Test loss: 2.604e+07, MSE(e): 5.564e-02, MSE(pi1): 1.529e-01, MSE(pi2): 3.255e-02, MSE(pi3): 3.387e-02\n",
      "Epoch 34200, Train loss: 5.597e+05, Test loss: 2.609e+07, MSE(e): 5.548e-02, MSE(pi1): 1.514e-01, MSE(pi2): 3.245e-02, MSE(pi3): 3.386e-02\n",
      "Epoch 34300, Train loss: 5.581e+05, Test loss: 2.615e+07, MSE(e): 5.532e-02, MSE(pi1): 1.504e-01, MSE(pi2): 3.235e-02, MSE(pi3): 3.379e-02\n",
      "Epoch 34400, Train loss: 5.565e+05, Test loss: 2.620e+07, MSE(e): 5.516e-02, MSE(pi1): 1.502e-01, MSE(pi2): 3.225e-02, MSE(pi3): 3.375e-02\n",
      "Epoch 34500, Train loss: 5.549e+05, Test loss: 2.626e+07, MSE(e): 5.500e-02, MSE(pi1): 1.504e-01, MSE(pi2): 3.214e-02, MSE(pi3): 3.359e-02\n",
      "Epoch 34600, Train loss: 5.533e+05, Test loss: 2.631e+07, MSE(e): 5.485e-02, MSE(pi1): 1.500e-01, MSE(pi2): 3.204e-02, MSE(pi3): 3.353e-02\n",
      "Epoch 34700, Train loss: 5.518e+05, Test loss: 2.637e+07, MSE(e): 5.469e-02, MSE(pi1): 1.501e-01, MSE(pi2): 3.194e-02, MSE(pi3): 3.344e-02\n",
      "Epoch 34800, Train loss: 5.505e+05, Test loss: 2.639e+07, MSE(e): 5.456e-02, MSE(pi1): 1.496e-01, MSE(pi2): 3.186e-02, MSE(pi3): 3.362e-02\n",
      "Epoch 34900, Train loss: 5.486e+05, Test loss: 2.648e+07, MSE(e): 5.437e-02, MSE(pi1): 1.494e-01, MSE(pi2): 3.174e-02, MSE(pi3): 3.330e-02\n",
      "Epoch 35000, Train loss: 5.470e+05, Test loss: 2.653e+07, MSE(e): 5.422e-02, MSE(pi1): 1.501e-01, MSE(pi2): 3.164e-02, MSE(pi3): 3.320e-02\n",
      "Epoch 35100, Train loss: 5.462e+05, Test loss: 2.656e+07, MSE(e): 5.413e-02, MSE(pi1): 1.498e-01, MSE(pi2): 3.158e-02, MSE(pi3): 3.339e-02\n",
      "Epoch 35200, Train loss: 5.439e+05, Test loss: 2.665e+07, MSE(e): 5.391e-02, MSE(pi1): 1.490e-01, MSE(pi2): 3.145e-02, MSE(pi3): 3.306e-02\n",
      "Epoch 35300, Train loss: 5.423e+05, Test loss: 2.671e+07, MSE(e): 5.375e-02, MSE(pi1): 1.487e-01, MSE(pi2): 3.135e-02, MSE(pi3): 3.302e-02\n",
      "Epoch 35400, Train loss: 5.408e+05, Test loss: 2.678e+07, MSE(e): 5.360e-02, MSE(pi1): 1.486e-01, MSE(pi2): 3.125e-02, MSE(pi3): 3.295e-02\n",
      "Epoch 35500, Train loss: 5.393e+05, Test loss: 2.683e+07, MSE(e): 5.344e-02, MSE(pi1): 1.494e-01, MSE(pi2): 3.115e-02, MSE(pi3): 3.294e-02\n",
      "Epoch 35600, Train loss: 5.377e+05, Test loss: 2.690e+07, MSE(e): 5.330e-02, MSE(pi1): 1.489e-01, MSE(pi2): 3.106e-02, MSE(pi3): 3.269e-02\n",
      "Epoch 35700, Train loss: 5.362e+05, Test loss: 2.695e+07, MSE(e): 5.314e-02, MSE(pi1): 1.553e-01, MSE(pi2): 3.096e-02, MSE(pi3): 3.252e-02\n",
      "Epoch 35800, Train loss: 5.352e+05, Test loss: 2.706e+07, MSE(e): 5.304e-02, MSE(pi1): 1.495e-01, MSE(pi2): 3.090e-02, MSE(pi3): 3.243e-02\n",
      "Epoch 35900, Train loss: 5.331e+05, Test loss: 2.707e+07, MSE(e): 5.284e-02, MSE(pi1): 1.480e-01, MSE(pi2): 3.077e-02, MSE(pi3): 3.251e-02\n",
      "Epoch 36000, Train loss: 5.317e+05, Test loss: 2.715e+07, MSE(e): 5.270e-02, MSE(pi1): 1.486e-01, MSE(pi2): 3.068e-02, MSE(pi3): 3.235e-02\n",
      "Epoch 36100, Train loss: 5.301e+05, Test loss: 2.720e+07, MSE(e): 5.253e-02, MSE(pi1): 1.477e-01, MSE(pi2): 3.058e-02, MSE(pi3): 3.236e-02\n",
      "Epoch 36200, Train loss: 5.286e+05, Test loss: 2.727e+07, MSE(e): 5.238e-02, MSE(pi1): 1.503e-01, MSE(pi2): 3.049e-02, MSE(pi3): 3.243e-02\n",
      "Epoch 36300, Train loss: 5.271e+05, Test loss: 2.731e+07, MSE(e): 5.223e-02, MSE(pi1): 1.486e-01, MSE(pi2): 3.039e-02, MSE(pi3): 3.216e-02\n",
      "Epoch 36400, Train loss: 5.256e+05, Test loss: 2.739e+07, MSE(e): 5.209e-02, MSE(pi1): 1.485e-01, MSE(pi2): 3.030e-02, MSE(pi3): 3.207e-02\n",
      "Epoch 36500, Train loss: 5.241e+05, Test loss: 2.745e+07, MSE(e): 5.194e-02, MSE(pi1): 1.471e-01, MSE(pi2): 3.021e-02, MSE(pi3): 3.206e-02\n",
      "Epoch 36600, Train loss: 5.226e+05, Test loss: 2.752e+07, MSE(e): 5.179e-02, MSE(pi1): 1.469e-01, MSE(pi2): 3.011e-02, MSE(pi3): 3.199e-02\n",
      "Epoch 36700, Train loss: 5.211e+05, Test loss: 2.757e+07, MSE(e): 5.164e-02, MSE(pi1): 1.469e-01, MSE(pi2): 3.002e-02, MSE(pi3): 3.194e-02\n",
      "Epoch 36800, Train loss: 5.196e+05, Test loss: 2.766e+07, MSE(e): 5.149e-02, MSE(pi1): 1.483e-01, MSE(pi2): 2.993e-02, MSE(pi3): 3.176e-02\n",
      "Epoch 36900, Train loss: 5.181e+05, Test loss: 2.773e+07, MSE(e): 5.134e-02, MSE(pi1): 1.467e-01, MSE(pi2): 2.984e-02, MSE(pi3): 3.175e-02\n",
      "Epoch 37000, Train loss: 5.166e+05, Test loss: 2.781e+07, MSE(e): 5.119e-02, MSE(pi1): 1.473e-01, MSE(pi2): 2.975e-02, MSE(pi3): 3.167e-02\n",
      "Epoch 37100, Train loss: 5.151e+05, Test loss: 2.786e+07, MSE(e): 5.105e-02, MSE(pi1): 1.463e-01, MSE(pi2): 2.966e-02, MSE(pi3): 3.163e-02\n",
      "Epoch 37200, Train loss: 5.137e+05, Test loss: 2.793e+07, MSE(e): 5.090e-02, MSE(pi1): 1.461e-01, MSE(pi2): 2.957e-02, MSE(pi3): 3.157e-02\n",
      "Epoch 37300, Train loss: 5.122e+05, Test loss: 2.800e+07, MSE(e): 5.075e-02, MSE(pi1): 1.462e-01, MSE(pi2): 2.947e-02, MSE(pi3): 3.146e-02\n",
      "Epoch 37400, Train loss: 5.107e+05, Test loss: 2.807e+07, MSE(e): 5.061e-02, MSE(pi1): 1.459e-01, MSE(pi2): 2.939e-02, MSE(pi3): 3.139e-02\n",
      "Epoch 37500, Train loss: 5.093e+05, Test loss: 2.812e+07, MSE(e): 5.047e-02, MSE(pi1): 1.457e-01, MSE(pi2): 2.930e-02, MSE(pi3): 3.137e-02\n",
      "Epoch 37600, Train loss: 5.078e+05, Test loss: 2.820e+07, MSE(e): 5.032e-02, MSE(pi1): 1.457e-01, MSE(pi2): 2.921e-02, MSE(pi3): 3.126e-02\n",
      "Epoch 37700, Train loss: 5.063e+05, Test loss: 2.828e+07, MSE(e): 5.017e-02, MSE(pi1): 1.455e-01, MSE(pi2): 2.912e-02, MSE(pi3): 3.118e-02\n",
      "Epoch 37800, Train loss: 5.049e+05, Test loss: 2.835e+07, MSE(e): 5.003e-02, MSE(pi1): 1.456e-01, MSE(pi2): 2.903e-02, MSE(pi3): 3.108e-02\n",
      "Epoch 37900, Train loss: 5.035e+05, Test loss: 2.845e+07, MSE(e): 4.989e-02, MSE(pi1): 1.458e-01, MSE(pi2): 2.895e-02, MSE(pi3): 3.096e-02\n",
      "Epoch 38000, Train loss: 5.020e+05, Test loss: 2.850e+07, MSE(e): 4.974e-02, MSE(pi1): 1.463e-01, MSE(pi2): 2.885e-02, MSE(pi3): 3.095e-02\n",
      "Epoch 38100, Train loss: 5.006e+05, Test loss: 2.857e+07, MSE(e): 4.960e-02, MSE(pi1): 1.452e-01, MSE(pi2): 2.877e-02, MSE(pi3): 3.088e-02\n",
      "Epoch 38200, Train loss: 4.991e+05, Test loss: 2.864e+07, MSE(e): 4.946e-02, MSE(pi1): 1.460e-01, MSE(pi2): 2.868e-02, MSE(pi3): 3.079e-02\n",
      "Epoch 38300, Train loss: 4.977e+05, Test loss: 2.871e+07, MSE(e): 4.932e-02, MSE(pi1): 1.449e-01, MSE(pi2): 2.859e-02, MSE(pi3): 3.074e-02\n",
      "Epoch 38400, Train loss: 4.964e+05, Test loss: 2.876e+07, MSE(e): 4.919e-02, MSE(pi1): 1.450e-01, MSE(pi2): 2.851e-02, MSE(pi3): 3.081e-02\n",
      "Epoch 38500, Train loss: 4.949e+05, Test loss: 2.886e+07, MSE(e): 4.904e-02, MSE(pi1): 1.447e-01, MSE(pi2): 2.842e-02, MSE(pi3): 3.060e-02\n",
      "Epoch 38600, Train loss: 4.935e+05, Test loss: 2.892e+07, MSE(e): 4.890e-02, MSE(pi1): 1.447e-01, MSE(pi2): 2.834e-02, MSE(pi3): 3.055e-02\n",
      "Epoch 38700, Train loss: 4.922e+05, Test loss: 2.901e+07, MSE(e): 4.876e-02, MSE(pi1): 1.513e-01, MSE(pi2): 2.826e-02, MSE(pi3): 3.068e-02\n",
      "Epoch 38800, Train loss: 4.912e+05, Test loss: 2.904e+07, MSE(e): 4.867e-02, MSE(pi1): 1.441e-01, MSE(pi2): 2.820e-02, MSE(pi3): 3.055e-02\n",
      "Epoch 38900, Train loss: 4.893e+05, Test loss: 2.916e+07, MSE(e): 4.848e-02, MSE(pi1): 1.442e-01, MSE(pi2): 2.809e-02, MSE(pi3): 3.034e-02\n",
      "Epoch 39000, Train loss: 4.879e+05, Test loss: 2.923e+07, MSE(e): 4.834e-02, MSE(pi1): 1.442e-01, MSE(pi2): 2.800e-02, MSE(pi3): 3.027e-02\n",
      "Epoch 39100, Train loss: 4.866e+05, Test loss: 2.930e+07, MSE(e): 4.821e-02, MSE(pi1): 1.439e-01, MSE(pi2): 2.792e-02, MSE(pi3): 3.019e-02\n",
      "Epoch 39200, Train loss: 4.852e+05, Test loss: 2.937e+07, MSE(e): 4.807e-02, MSE(pi1): 1.437e-01, MSE(pi2): 2.784e-02, MSE(pi3): 3.016e-02\n",
      "Epoch 39300, Train loss: 4.838e+05, Test loss: 2.946e+07, MSE(e): 4.793e-02, MSE(pi1): 1.448e-01, MSE(pi2): 2.776e-02, MSE(pi3): 3.002e-02\n",
      "Epoch 39400, Train loss: 4.824e+05, Test loss: 2.952e+07, MSE(e): 4.779e-02, MSE(pi1): 1.445e-01, MSE(pi2): 2.767e-02, MSE(pi3): 2.999e-02\n",
      "Epoch 39500, Train loss: 4.811e+05, Test loss: 2.963e+07, MSE(e): 4.767e-02, MSE(pi1): 1.445e-01, MSE(pi2): 2.760e-02, MSE(pi3): 2.993e-02\n",
      "Epoch 39600, Train loss: 4.798e+05, Test loss: 2.969e+07, MSE(e): 4.752e-02, MSE(pi1): 1.557e-01, MSE(pi2): 2.751e-02, MSE(pi3): 2.961e-02\n",
      "Epoch 39700, Train loss: 4.783e+05, Test loss: 2.977e+07, MSE(e): 4.738e-02, MSE(pi1): 1.433e-01, MSE(pi2): 2.742e-02, MSE(pi3): 2.978e-02\n",
      "Epoch 39800, Train loss: 4.770e+05, Test loss: 2.984e+07, MSE(e): 4.725e-02, MSE(pi1): 1.510e-01, MSE(pi2): 2.734e-02, MSE(pi3): 2.958e-02\n",
      "Epoch 39900, Train loss: 4.755e+05, Test loss: 2.993e+07, MSE(e): 4.711e-02, MSE(pi1): 1.435e-01, MSE(pi2): 2.726e-02, MSE(pi3): 2.964e-02\n",
      "Epoch 40000, Train loss: 4.742e+05, Test loss: 2.999e+07, MSE(e): 4.698e-02, MSE(pi1): 1.431e-01, MSE(pi2): 2.718e-02, MSE(pi3): 2.958e-02\n",
      "Epoch 40100, Train loss: 4.728e+05, Test loss: 3.007e+07, MSE(e): 4.684e-02, MSE(pi1): 1.429e-01, MSE(pi2): 2.710e-02, MSE(pi3): 2.953e-02\n",
      "Epoch 40200, Train loss: 4.716e+05, Test loss: 3.016e+07, MSE(e): 4.672e-02, MSE(pi1): 1.431e-01, MSE(pi2): 2.703e-02, MSE(pi3): 2.941e-02\n",
      "Epoch 40300, Train loss: 4.702e+05, Test loss: 3.023e+07, MSE(e): 4.658e-02, MSE(pi1): 1.449e-01, MSE(pi2): 2.694e-02, MSE(pi3): 2.930e-02\n",
      "Epoch 40400, Train loss: 4.688e+05, Test loss: 3.031e+07, MSE(e): 4.645e-02, MSE(pi1): 1.425e-01, MSE(pi2): 2.687e-02, MSE(pi3): 2.933e-02\n",
      "Epoch 40500, Train loss: 4.675e+05, Test loss: 3.038e+07, MSE(e): 4.631e-02, MSE(pi1): 1.426e-01, MSE(pi2): 2.679e-02, MSE(pi3): 2.927e-02\n",
      "Epoch 40600, Train loss: 4.665e+05, Test loss: 3.050e+07, MSE(e): 4.621e-02, MSE(pi1): 1.433e-01, MSE(pi2): 2.672e-02, MSE(pi3): 2.910e-02\n",
      "Epoch 40700, Train loss: 4.649e+05, Test loss: 3.054e+07, MSE(e): 4.605e-02, MSE(pi1): 1.423e-01, MSE(pi2): 2.663e-02, MSE(pi3): 2.913e-02\n",
      "Epoch 40800, Train loss: 4.636e+05, Test loss: 3.062e+07, MSE(e): 4.592e-02, MSE(pi1): 1.420e-01, MSE(pi2): 2.655e-02, MSE(pi3): 2.909e-02\n",
      "Epoch 40900, Train loss: 4.623e+05, Test loss: 3.069e+07, MSE(e): 4.579e-02, MSE(pi1): 1.420e-01, MSE(pi2): 2.647e-02, MSE(pi3): 2.901e-02\n",
      "Epoch 41000, Train loss: 4.610e+05, Test loss: 3.077e+07, MSE(e): 4.566e-02, MSE(pi1): 1.418e-01, MSE(pi2): 2.640e-02, MSE(pi3): 2.895e-02\n",
      "Epoch 41100, Train loss: 4.597e+05, Test loss: 3.085e+07, MSE(e): 4.553e-02, MSE(pi1): 1.414e-01, MSE(pi2): 2.632e-02, MSE(pi3): 2.894e-02\n",
      "Epoch 41200, Train loss: 4.584e+05, Test loss: 3.094e+07, MSE(e): 4.541e-02, MSE(pi1): 1.419e-01, MSE(pi2): 2.625e-02, MSE(pi3): 2.878e-02\n",
      "Epoch 41300, Train loss: 4.571e+05, Test loss: 3.100e+07, MSE(e): 4.528e-02, MSE(pi1): 1.436e-01, MSE(pi2): 2.617e-02, MSE(pi3): 2.879e-02\n",
      "Epoch 41400, Train loss: 4.558e+05, Test loss: 3.108e+07, MSE(e): 4.515e-02, MSE(pi1): 1.413e-01, MSE(pi2): 2.609e-02, MSE(pi3): 2.871e-02\n",
      "Epoch 41500, Train loss: 4.545e+05, Test loss: 3.116e+07, MSE(e): 4.502e-02, MSE(pi1): 1.415e-01, MSE(pi2): 2.602e-02, MSE(pi3): 2.862e-02\n",
      "Epoch 41600, Train loss: 4.538e+05, Test loss: 3.118e+07, MSE(e): 4.495e-02, MSE(pi1): 1.406e-01, MSE(pi2): 2.597e-02, MSE(pi3): 2.875e-02\n",
      "Epoch 41700, Train loss: 4.526e+05, Test loss: 3.137e+07, MSE(e): 4.483e-02, MSE(pi1): 1.429e-01, MSE(pi2): 2.590e-02, MSE(pi3): 2.844e-02\n",
      "Epoch 41800, Train loss: 4.507e+05, Test loss: 3.139e+07, MSE(e): 4.464e-02, MSE(pi1): 1.411e-01, MSE(pi2): 2.579e-02, MSE(pi3): 2.844e-02\n",
      "Epoch 41900, Train loss: 4.495e+05, Test loss: 3.147e+07, MSE(e): 4.452e-02, MSE(pi1): 1.413e-01, MSE(pi2): 2.572e-02, MSE(pi3): 2.841e-02\n",
      "Epoch 42000, Train loss: 4.491e+05, Test loss: 3.160e+07, MSE(e): 4.448e-02, MSE(pi1): 1.424e-01, MSE(pi2): 2.570e-02, MSE(pi3): 2.821e-02\n",
      "Epoch 42100, Train loss: 4.470e+05, Test loss: 3.162e+07, MSE(e): 4.427e-02, MSE(pi1): 1.404e-01, MSE(pi2): 2.557e-02, MSE(pi3): 2.829e-02\n",
      "Epoch 42200, Train loss: 4.457e+05, Test loss: 3.169e+07, MSE(e): 4.415e-02, MSE(pi1): 1.403e-01, MSE(pi2): 2.550e-02, MSE(pi3): 2.823e-02\n",
      "Epoch 42300, Train loss: 4.445e+05, Test loss: 3.177e+07, MSE(e): 4.402e-02, MSE(pi1): 1.404e-01, MSE(pi2): 2.543e-02, MSE(pi3): 2.816e-02\n",
      "Epoch 42400, Train loss: 4.433e+05, Test loss: 3.185e+07, MSE(e): 4.390e-02, MSE(pi1): 1.456e-01, MSE(pi2): 2.536e-02, MSE(pi3): 2.807e-02\n",
      "Epoch 42500, Train loss: 4.420e+05, Test loss: 3.192e+07, MSE(e): 4.378e-02, MSE(pi1): 1.399e-01, MSE(pi2): 2.528e-02, MSE(pi3): 2.806e-02\n",
      "Epoch 42600, Train loss: 4.408e+05, Test loss: 3.200e+07, MSE(e): 4.366e-02, MSE(pi1): 1.400e-01, MSE(pi2): 2.521e-02, MSE(pi3): 2.800e-02\n",
      "Epoch 42700, Train loss: 4.396e+05, Test loss: 3.207e+07, MSE(e): 4.354e-02, MSE(pi1): 1.397e-01, MSE(pi2): 2.514e-02, MSE(pi3): 2.794e-02\n",
      "Epoch 42800, Train loss: 4.384e+05, Test loss: 3.215e+07, MSE(e): 4.342e-02, MSE(pi1): 1.395e-01, MSE(pi2): 2.507e-02, MSE(pi3): 2.789e-02\n",
      "Epoch 42900, Train loss: 4.372e+05, Test loss: 3.223e+07, MSE(e): 4.330e-02, MSE(pi1): 1.395e-01, MSE(pi2): 2.500e-02, MSE(pi3): 2.782e-02\n",
      "Epoch 43000, Train loss: 4.360e+05, Test loss: 3.229e+07, MSE(e): 4.318e-02, MSE(pi1): 1.392e-01, MSE(pi2): 2.493e-02, MSE(pi3): 2.780e-02\n",
      "Epoch 43100, Train loss: 4.349e+05, Test loss: 3.236e+07, MSE(e): 4.306e-02, MSE(pi1): 1.426e-01, MSE(pi2): 2.486e-02, MSE(pi3): 2.765e-02\n",
      "Epoch 43200, Train loss: 4.336e+05, Test loss: 3.244e+07, MSE(e): 4.295e-02, MSE(pi1): 1.392e-01, MSE(pi2): 2.480e-02, MSE(pi3): 2.766e-02\n",
      "Epoch 43300, Train loss: 4.328e+05, Test loss: 3.249e+07, MSE(e): 4.286e-02, MSE(pi1): 1.386e-01, MSE(pi2): 2.474e-02, MSE(pi3): 2.776e-02\n",
      "Epoch 43400, Train loss: 4.313e+05, Test loss: 3.258e+07, MSE(e): 4.272e-02, MSE(pi1): 1.388e-01, MSE(pi2): 2.466e-02, MSE(pi3): 2.755e-02\n",
      "Epoch 43500, Train loss: 4.302e+05, Test loss: 3.265e+07, MSE(e): 4.260e-02, MSE(pi1): 1.387e-01, MSE(pi2): 2.459e-02, MSE(pi3): 2.749e-02\n",
      "Epoch 43600, Train loss: 4.290e+05, Test loss: 3.273e+07, MSE(e): 4.249e-02, MSE(pi1): 1.386e-01, MSE(pi2): 2.452e-02, MSE(pi3): 2.744e-02\n",
      "Epoch 43700, Train loss: 4.278e+05, Test loss: 3.280e+07, MSE(e): 4.237e-02, MSE(pi1): 1.386e-01, MSE(pi2): 2.446e-02, MSE(pi3): 2.738e-02\n",
      "Epoch 43800, Train loss: 4.267e+05, Test loss: 3.287e+07, MSE(e): 4.226e-02, MSE(pi1): 1.382e-01, MSE(pi2): 2.439e-02, MSE(pi3): 2.734e-02\n",
      "Epoch 43900, Train loss: 4.256e+05, Test loss: 3.294e+07, MSE(e): 4.214e-02, MSE(pi1): 1.382e-01, MSE(pi2): 2.433e-02, MSE(pi3): 2.728e-02\n",
      "Epoch 44000, Train loss: 4.244e+05, Test loss: 3.301e+07, MSE(e): 4.203e-02, MSE(pi1): 1.379e-01, MSE(pi2): 2.426e-02, MSE(pi3): 2.724e-02\n",
      "Epoch 44100, Train loss: 4.235e+05, Test loss: 3.310e+07, MSE(e): 4.193e-02, MSE(pi1): 1.498e-01, MSE(pi2): 2.420e-02, MSE(pi3): 2.690e-02\n",
      "Epoch 44200, Train loss: 4.222e+05, Test loss: 3.315e+07, MSE(e): 4.180e-02, MSE(pi1): 1.377e-01, MSE(pi2): 2.413e-02, MSE(pi3): 2.712e-02\n",
      "Epoch 44300, Train loss: 4.210e+05, Test loss: 3.322e+07, MSE(e): 4.169e-02, MSE(pi1): 1.375e-01, MSE(pi2): 2.406e-02, MSE(pi3): 2.708e-02\n",
      "Epoch 44400, Train loss: 4.199e+05, Test loss: 3.330e+07, MSE(e): 4.158e-02, MSE(pi1): 1.377e-01, MSE(pi2): 2.400e-02, MSE(pi3): 2.699e-02\n",
      "Epoch 44500, Train loss: 4.188e+05, Test loss: 3.335e+07, MSE(e): 4.147e-02, MSE(pi1): 1.380e-01, MSE(pi2): 2.393e-02, MSE(pi3): 2.700e-02\n",
      "Epoch 44600, Train loss: 4.177e+05, Test loss: 3.341e+07, MSE(e): 4.136e-02, MSE(pi1): 1.371e-01, MSE(pi2): 2.387e-02, MSE(pi3): 2.693e-02\n",
      "Epoch 44700, Train loss: 4.166e+05, Test loss: 3.347e+07, MSE(e): 4.125e-02, MSE(pi1): 1.368e-01, MSE(pi2): 2.380e-02, MSE(pi3): 2.691e-02\n",
      "Epoch 44800, Train loss: 4.155e+05, Test loss: 3.356e+07, MSE(e): 4.114e-02, MSE(pi1): 1.373e-01, MSE(pi2): 2.374e-02, MSE(pi3): 2.678e-02\n",
      "Epoch 44900, Train loss: 4.147e+05, Test loss: 3.365e+07, MSE(e): 4.106e-02, MSE(pi1): 1.379e-01, MSE(pi2): 2.369e-02, MSE(pi3): 2.665e-02\n",
      "Epoch 45000, Train loss: 4.133e+05, Test loss: 3.369e+07, MSE(e): 4.093e-02, MSE(pi1): 1.367e-01, MSE(pi2): 2.361e-02, MSE(pi3): 2.670e-02\n",
      "Epoch 45100, Train loss: 4.140e+05, Test loss: 3.386e+07, MSE(e): 4.100e-02, MSE(pi1): 1.392e-01, MSE(pi2): 2.365e-02, MSE(pi3): 2.649e-02\n",
      "Epoch 45200, Train loss: 4.112e+05, Test loss: 3.382e+07, MSE(e): 4.071e-02, MSE(pi1): 1.364e-01, MSE(pi2): 2.349e-02, MSE(pi3): 2.660e-02\n",
      "Epoch 45300, Train loss: 4.111e+05, Test loss: 3.395e+07, MSE(e): 4.070e-02, MSE(pi1): 1.389e-01, MSE(pi2): 2.348e-02, MSE(pi3): 2.646e-02\n",
      "Epoch 45400, Train loss: 4.090e+05, Test loss: 3.395e+07, MSE(e): 4.050e-02, MSE(pi1): 1.361e-01, MSE(pi2): 2.336e-02, MSE(pi3): 2.650e-02\n",
      "Epoch 45500, Train loss: 4.080e+05, Test loss: 3.402e+07, MSE(e): 4.040e-02, MSE(pi1): 1.359e-01, MSE(pi2): 2.330e-02, MSE(pi3): 2.645e-02\n",
      "Epoch 45600, Train loss: 4.069e+05, Test loss: 3.407e+07, MSE(e): 4.029e-02, MSE(pi1): 1.357e-01, MSE(pi2): 2.324e-02, MSE(pi3): 2.644e-02\n",
      "Epoch 45700, Train loss: 4.065e+05, Test loss: 3.408e+07, MSE(e): 4.025e-02, MSE(pi1): 1.350e-01, MSE(pi2): 2.321e-02, MSE(pi3): 2.653e-02\n",
      "Epoch 45800, Train loss: 4.049e+05, Test loss: 3.419e+07, MSE(e): 4.009e-02, MSE(pi1): 1.353e-01, MSE(pi2): 2.312e-02, MSE(pi3): 2.634e-02\n",
      "Epoch 45900, Train loss: 4.038e+05, Test loss: 3.427e+07, MSE(e): 3.998e-02, MSE(pi1): 1.357e-01, MSE(pi2): 2.306e-02, MSE(pi3): 2.622e-02\n",
      "Epoch 46000, Train loss: 4.028e+05, Test loss: 3.434e+07, MSE(e): 3.988e-02, MSE(pi1): 1.352e-01, MSE(pi2): 2.300e-02, MSE(pi3): 2.620e-02\n",
      "Epoch 46100, Train loss: 4.022e+05, Test loss: 3.444e+07, MSE(e): 3.982e-02, MSE(pi1): 1.364e-01, MSE(pi2): 2.296e-02, MSE(pi3): 2.602e-02\n",
      "Epoch 46200, Train loss: 4.014e+05, Test loss: 3.453e+07, MSE(e): 3.974e-02, MSE(pi1): 1.420e-01, MSE(pi2): 2.292e-02, MSE(pi3): 2.607e-02\n",
      "Epoch 46300, Train loss: 3.997e+05, Test loss: 3.451e+07, MSE(e): 3.957e-02, MSE(pi1): 1.350e-01, MSE(pi2): 2.282e-02, MSE(pi3): 2.604e-02\n",
      "Epoch 46400, Train loss: 3.987e+05, Test loss: 3.457e+07, MSE(e): 3.947e-02, MSE(pi1): 1.346e-01, MSE(pi2): 2.276e-02, MSE(pi3): 2.600e-02\n",
      "Epoch 46500, Train loss: 3.982e+05, Test loss: 3.467e+07, MSE(e): 3.942e-02, MSE(pi1): 1.392e-01, MSE(pi2): 2.273e-02, MSE(pi3): 2.600e-02\n",
      "Epoch 46600, Train loss: 3.967e+05, Test loss: 3.469e+07, MSE(e): 3.927e-02, MSE(pi1): 1.342e-01, MSE(pi2): 2.265e-02, MSE(pi3): 2.591e-02\n",
      "Epoch 46700, Train loss: 3.958e+05, Test loss: 3.474e+07, MSE(e): 3.918e-02, MSE(pi1): 1.355e-01, MSE(pi2): 2.259e-02, MSE(pi3): 2.589e-02\n",
      "Epoch 46800, Train loss: 3.947e+05, Test loss: 3.481e+07, MSE(e): 3.908e-02, MSE(pi1): 1.339e-01, MSE(pi2): 2.253e-02, MSE(pi3): 2.582e-02\n",
      "Epoch 46900, Train loss: 3.938e+05, Test loss: 3.487e+07, MSE(e): 3.898e-02, MSE(pi1): 1.340e-01, MSE(pi2): 2.248e-02, MSE(pi3): 2.574e-02\n",
      "Epoch 47000, Train loss: 3.928e+05, Test loss: 3.492e+07, MSE(e): 3.889e-02, MSE(pi1): 1.337e-01, MSE(pi2): 2.242e-02, MSE(pi3): 2.571e-02\n",
      "Epoch 47100, Train loss: 3.918e+05, Test loss: 3.498e+07, MSE(e): 3.879e-02, MSE(pi1): 1.334e-01, MSE(pi2): 2.236e-02, MSE(pi3): 2.568e-02\n",
      "Epoch 47200, Train loss: 3.911e+05, Test loss: 3.509e+07, MSE(e): 3.872e-02, MSE(pi1): 1.367e-01, MSE(pi2): 2.232e-02, MSE(pi3): 2.547e-02\n",
      "Epoch 47300, Train loss: 3.899e+05, Test loss: 3.508e+07, MSE(e): 3.860e-02, MSE(pi1): 1.336e-01, MSE(pi2): 2.226e-02, MSE(pi3): 2.555e-02\n",
      "Epoch 47400, Train loss: 3.890e+05, Test loss: 3.514e+07, MSE(e): 3.851e-02, MSE(pi1): 1.329e-01, MSE(pi2): 2.220e-02, MSE(pi3): 2.555e-02\n",
      "Epoch 47500, Train loss: 3.881e+05, Test loss: 3.519e+07, MSE(e): 3.842e-02, MSE(pi1): 1.327e-01, MSE(pi2): 2.215e-02, MSE(pi3): 2.550e-02\n",
      "Epoch 47600, Train loss: 3.872e+05, Test loss: 3.526e+07, MSE(e): 3.833e-02, MSE(pi1): 1.333e-01, MSE(pi2): 2.210e-02, MSE(pi3): 2.537e-02\n",
      "Epoch 47700, Train loss: 3.862e+05, Test loss: 3.530e+07, MSE(e): 3.823e-02, MSE(pi1): 1.324e-01, MSE(pi2): 2.204e-02, MSE(pi3): 2.540e-02\n",
      "Epoch 47800, Train loss: 3.853e+05, Test loss: 3.534e+07, MSE(e): 3.814e-02, MSE(pi1): 1.319e-01, MSE(pi2): 2.199e-02, MSE(pi3): 2.542e-02\n",
      "Epoch 47900, Train loss: 3.844e+05, Test loss: 3.540e+07, MSE(e): 3.805e-02, MSE(pi1): 1.320e-01, MSE(pi2): 2.193e-02, MSE(pi3): 2.532e-02\n",
      "Epoch 48000, Train loss: 3.835e+05, Test loss: 3.544e+07, MSE(e): 3.796e-02, MSE(pi1): 1.318e-01, MSE(pi2): 2.188e-02, MSE(pi3): 2.528e-02\n",
      "Epoch 48100, Train loss: 3.826e+05, Test loss: 3.550e+07, MSE(e): 3.787e-02, MSE(pi1): 1.317e-01, MSE(pi2): 2.183e-02, MSE(pi3): 2.524e-02\n",
      "Epoch 48200, Train loss: 3.819e+05, Test loss: 3.550e+07, MSE(e): 3.780e-02, MSE(pi1): 1.375e-01, MSE(pi2): 2.178e-02, MSE(pi3): 2.515e-02\n",
      "Epoch 48300, Train loss: 3.808e+05, Test loss: 3.559e+07, MSE(e): 3.769e-02, MSE(pi1): 1.313e-01, MSE(pi2): 2.173e-02, MSE(pi3): 2.513e-02\n",
      "Epoch 48400, Train loss: 3.799e+05, Test loss: 3.564e+07, MSE(e): 3.761e-02, MSE(pi1): 1.313e-01, MSE(pi2): 2.167e-02, MSE(pi3): 2.508e-02\n",
      "Epoch 48500, Train loss: 3.790e+05, Test loss: 3.569e+07, MSE(e): 3.752e-02, MSE(pi1): 1.325e-01, MSE(pi2): 2.162e-02, MSE(pi3): 2.499e-02\n",
      "Epoch 48600, Train loss: 3.782e+05, Test loss: 3.574e+07, MSE(e): 3.743e-02, MSE(pi1): 1.307e-01, MSE(pi2): 2.157e-02, MSE(pi3): 2.501e-02\n",
      "Epoch 48700, Train loss: 3.773e+05, Test loss: 3.579e+07, MSE(e): 3.735e-02, MSE(pi1): 1.306e-01, MSE(pi2): 2.152e-02, MSE(pi3): 2.496e-02\n",
      "Epoch 48800, Train loss: 3.764e+05, Test loss: 3.581e+07, MSE(e): 3.726e-02, MSE(pi1): 1.311e-01, MSE(pi2): 2.147e-02, MSE(pi3): 2.492e-02\n",
      "Epoch 48900, Train loss: 3.757e+05, Test loss: 3.584e+07, MSE(e): 3.718e-02, MSE(pi1): 1.307e-01, MSE(pi2): 2.143e-02, MSE(pi3): 2.504e-02\n",
      "Epoch 49000, Train loss: 3.747e+05, Test loss: 3.592e+07, MSE(e): 3.709e-02, MSE(pi1): 1.300e-01, MSE(pi2): 2.137e-02, MSE(pi3): 2.484e-02\n",
      "Epoch 49100, Train loss: 3.738e+05, Test loss: 3.596e+07, MSE(e): 3.700e-02, MSE(pi1): 1.305e-01, MSE(pi2): 2.132e-02, MSE(pi3): 2.490e-02\n",
      "Epoch 49200, Train loss: 3.730e+05, Test loss: 3.602e+07, MSE(e): 3.692e-02, MSE(pi1): 1.300e-01, MSE(pi2): 2.127e-02, MSE(pi3): 2.480e-02\n",
      "Epoch 49300, Train loss: 3.727e+05, Test loss: 3.599e+07, MSE(e): 3.688e-02, MSE(pi1): 1.362e-01, MSE(pi2): 2.125e-02, MSE(pi3): 2.503e-02\n",
      "Epoch 49400, Train loss: 3.713e+05, Test loss: 3.608e+07, MSE(e): 3.675e-02, MSE(pi1): 1.309e-01, MSE(pi2): 2.117e-02, MSE(pi3): 2.460e-02\n",
      "Epoch 49500, Train loss: 3.705e+05, Test loss: 3.613e+07, MSE(e): 3.667e-02, MSE(pi1): 1.292e-01, MSE(pi2): 2.113e-02, MSE(pi3): 2.460e-02\n",
      "Epoch 49600, Train loss: 3.696e+05, Test loss: 3.616e+07, MSE(e): 3.658e-02, MSE(pi1): 1.290e-01, MSE(pi2): 2.108e-02, MSE(pi3): 2.458e-02\n",
      "Epoch 49700, Train loss: 3.688e+05, Test loss: 3.621e+07, MSE(e): 3.650e-02, MSE(pi1): 1.299e-01, MSE(pi2): 2.103e-02, MSE(pi3): 2.448e-02\n",
      "Epoch 49800, Train loss: 3.680e+05, Test loss: 3.625e+07, MSE(e): 3.642e-02, MSE(pi1): 1.286e-01, MSE(pi2): 2.098e-02, MSE(pi3): 2.451e-02\n",
      "Epoch 49900, Train loss: 3.672e+05, Test loss: 3.627e+07, MSE(e): 3.634e-02, MSE(pi1): 1.307e-01, MSE(pi2): 2.094e-02, MSE(pi3): 2.463e-02\n",
      "\n",
      "Training process finished after 50000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "params_to_update = filter(lambda p: p.requires_grad, pretrained_pgnniv.parameters())\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=3e-4)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "train_loop(pretrained_pgnniv, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_epoch = n_epochs-1\n",
    "# n_epochs = 20000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 5\n",
    "\n",
    "# second_lr = 3e-4\n",
    "\n",
    "# train_loop(pretrained_pgnniv, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8333352720>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
