{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import GPUtil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import gc\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from utils.checkpoints import load_results\n",
    "\n",
    "from architectures.pgnniv_baseline import PGNNIVBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_100\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_100/transfer\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear_100/sigmoid_nonlinear_100.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_100')\n",
    "\n",
    "PRETRAINED_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/non_linear_1000_0/baseline_model_10')\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_100/transfer')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_TRANSFERLEARNING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear_100/sigmoid_nonlinear_100.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 80\n",
      "Validation dataset length: 20\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X_train, y_train, K_train, f_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other parameters\n",
    "n_filters_explanatory = 5\n",
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_autoencoder = PretrainedAutoencoder(autoencoder_input_shape, latent_space_dim, autoencoder_output_shape).to(DEVICE)\n",
    "pretrained_pgnniv = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(pretrained_pgnniv.parameters(), lr=1e-4)\n",
    "pretrained_pgnniv, optimizer, lists = load_results(pretrained_pgnniv, optimizer, PRETRAINED_RESULTS_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f76f7266d80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgnniv_pretrained_encoder = pretrained_pgnniv.encoder\n",
    "pgnniv_pretrained_decoder = pretrained_pgnniv.decoder\n",
    "pgnniv_pretrained_exp = pretrained_pgnniv.explanatory\n",
    "\n",
    "for param in pgnniv_pretrained_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in pgnniv_pretrained_decoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pgnniv_pretrained_exp.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def reinitialize_model(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            # Reinitialize Conv2d weights and biases\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            # Reinitialize Linear weights and biases\n",
    "            nn.init.kaiming_uniform_(module.weight, a=math.sqrt(5))\n",
    "            if module.bias is not None:\n",
    "                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(module.weight)\n",
    "                bound = 1 / math.sqrt(fan_in)\n",
    "                nn.init.uniform_(module.bias, -bound, bound)\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            # Reinitialize BatchNorm layers\n",
    "            nn.init.constant_(module.weight, 1)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "\n",
    "# reinitialize_model(pgnniv_pretrained_decoder)\n",
    "# reinitialize_model(pgnniv_pretrained_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 2.900e+08, Test loss: 4.963e+08, MSE(e): 2.896e+01, MSE(pi1): 2.193e+01, MSE(pi2): 1.262e+01, MSE(pi3): 1.571e+00\n",
      "Epoch 100, Train loss: 2.325e+08, Test loss: 3.933e+08, MSE(e): 2.321e+01, MSE(pi1): 2.336e+01, MSE(pi2): 1.014e+01, MSE(pi3): 1.630e+00\n",
      "Epoch 200, Train loss: 1.967e+08, Test loss: 3.205e+08, MSE(e): 1.962e+01, MSE(pi1): 2.500e+01, MSE(pi2): 8.505e+00, MSE(pi3): 1.693e+00\n",
      "Epoch 300, Train loss: 1.743e+08, Test loss: 2.736e+08, MSE(e): 1.739e+01, MSE(pi1): 2.566e+01, MSE(pi2): 7.455e+00, MSE(pi3): 1.727e+00\n",
      "Epoch 400, Train loss: 1.588e+08, Test loss: 2.425e+08, MSE(e): 1.584e+01, MSE(pi1): 2.524e+01, MSE(pi2): 6.738e+00, MSE(pi3): 1.718e+00\n",
      "Epoch 500, Train loss: 1.468e+08, Test loss: 2.199e+08, MSE(e): 1.463e+01, MSE(pi1): 2.431e+01, MSE(pi2): 6.198e+00, MSE(pi3): 1.674e+00\n",
      "Epoch 600, Train loss: 1.368e+08, Test loss: 2.020e+08, MSE(e): 1.364e+01, MSE(pi1): 2.325e+01, MSE(pi2): 5.761e+00, MSE(pi3): 1.597e+00\n",
      "Epoch 700, Train loss: 1.283e+08, Test loss: 1.869e+08, MSE(e): 1.280e+01, MSE(pi1): 2.202e+01, MSE(pi2): 5.391e+00, MSE(pi3): 1.498e+00\n",
      "Epoch 800, Train loss: 1.206e+08, Test loss: 1.735e+08, MSE(e): 1.203e+01, MSE(pi1): 2.056e+01, MSE(pi2): 5.065e+00, MSE(pi3): 1.394e+00\n",
      "Epoch 900, Train loss: 1.130e+08, Test loss: 1.607e+08, MSE(e): 1.127e+01, MSE(pi1): 1.911e+01, MSE(pi2): 4.763e+00, MSE(pi3): 1.298e+00\n",
      "Epoch 1000, Train loss: 1.048e+08, Test loss: 1.481e+08, MSE(e): 1.045e+01, MSE(pi1): 1.809e+01, MSE(pi2): 4.493e+00, MSE(pi3): 1.217e+00\n",
      "Epoch 1100, Train loss: 9.788e+07, Test loss: 1.403e+08, MSE(e): 9.760e+00, MSE(pi1): 1.698e+01, MSE(pi2): 4.323e+00, MSE(pi3): 1.144e+00\n",
      "Epoch 1200, Train loss: 9.356e+07, Test loss: 1.378e+08, MSE(e): 9.331e+00, MSE(pi1): 1.445e+01, MSE(pi2): 4.204e+00, MSE(pi3): 1.058e+00\n",
      "Epoch 1300, Train loss: 9.052e+07, Test loss: 1.361e+08, MSE(e): 9.031e+00, MSE(pi1): 1.109e+01, MSE(pi2): 4.093e+00, MSE(pi3): 9.873e-01\n",
      "Epoch 1400, Train loss: 8.814e+07, Test loss: 1.347e+08, MSE(e): 8.794e+00, MSE(pi1): 9.402e+00, MSE(pi2): 3.991e+00, MSE(pi3): 9.346e-01\n",
      "Epoch 1500, Train loss: 8.613e+07, Test loss: 1.336e+08, MSE(e): 8.596e+00, MSE(pi1): 8.465e+00, MSE(pi2): 3.898e+00, MSE(pi3): 8.749e-01\n",
      "Epoch 1600, Train loss: 8.437e+07, Test loss: 1.328e+08, MSE(e): 8.421e+00, MSE(pi1): 7.790e+00, MSE(pi2): 3.814e+00, MSE(pi3): 8.229e-01\n",
      "Epoch 1700, Train loss: 8.277e+07, Test loss: 1.321e+08, MSE(e): 8.261e+00, MSE(pi1): 7.287e+00, MSE(pi2): 3.735e+00, MSE(pi3): 7.800e-01\n",
      "Epoch 1800, Train loss: 8.125e+07, Test loss: 1.315e+08, MSE(e): 8.110e+00, MSE(pi1): 6.899e+00, MSE(pi2): 3.659e+00, MSE(pi3): 7.446e-01\n",
      "Epoch 1900, Train loss: 7.976e+07, Test loss: 1.309e+08, MSE(e): 7.962e+00, MSE(pi1): 6.586e+00, MSE(pi2): 3.585e+00, MSE(pi3): 7.151e-01\n",
      "Epoch 2000, Train loss: 7.827e+07, Test loss: 1.303e+08, MSE(e): 7.814e+00, MSE(pi1): 6.321e+00, MSE(pi2): 3.511e+00, MSE(pi3): 6.899e-01\n",
      "Epoch 2100, Train loss: 7.675e+07, Test loss: 1.296e+08, MSE(e): 7.661e+00, MSE(pi1): 6.085e+00, MSE(pi2): 3.436e+00, MSE(pi3): 6.679e-01\n",
      "Epoch 2200, Train loss: 7.514e+07, Test loss: 1.288e+08, MSE(e): 7.501e+00, MSE(pi1): 5.860e+00, MSE(pi2): 3.358e+00, MSE(pi3): 6.482e-01\n",
      "Epoch 2300, Train loss: 7.343e+07, Test loss: 1.277e+08, MSE(e): 7.331e+00, MSE(pi1): 5.630e+00, MSE(pi2): 3.276e+00, MSE(pi3): 6.296e-01\n",
      "Epoch 2400, Train loss: 7.160e+07, Test loss: 1.264e+08, MSE(e): 7.148e+00, MSE(pi1): 5.395e+00, MSE(pi2): 3.189e+00, MSE(pi3): 6.111e-01\n",
      "Epoch 2500, Train loss: 6.962e+07, Test loss: 1.248e+08, MSE(e): 6.950e+00, MSE(pi1): 5.178e+00, MSE(pi2): 3.097e+00, MSE(pi3): 5.920e-01\n",
      "Epoch 2600, Train loss: 6.750e+07, Test loss: 1.229e+08, MSE(e): 6.739e+00, MSE(pi1): 4.988e+00, MSE(pi2): 3.000e+00, MSE(pi3): 5.733e-01\n",
      "Epoch 2700, Train loss: 6.523e+07, Test loss: 1.206e+08, MSE(e): 6.513e+00, MSE(pi1): 4.815e+00, MSE(pi2): 2.898e+00, MSE(pi3): 5.552e-01\n",
      "Epoch 2800, Train loss: 6.284e+07, Test loss: 1.178e+08, MSE(e): 6.274e+00, MSE(pi1): 4.639e+00, MSE(pi2): 2.792e+00, MSE(pi3): 5.376e-01\n",
      "Epoch 2900, Train loss: 6.032e+07, Test loss: 1.146e+08, MSE(e): 6.022e+00, MSE(pi1): 4.446e+00, MSE(pi2): 2.683e+00, MSE(pi3): 5.201e-01\n",
      "Epoch 3000, Train loss: 5.768e+07, Test loss: 1.109e+08, MSE(e): 5.758e+00, MSE(pi1): 4.236e+00, MSE(pi2): 2.570e+00, MSE(pi3): 5.024e-01\n",
      "Epoch 3100, Train loss: 5.489e+07, Test loss: 1.070e+08, MSE(e): 5.480e+00, MSE(pi1): 4.015e+00, MSE(pi2): 2.455e+00, MSE(pi3): 4.844e-01\n",
      "Epoch 3200, Train loss: 5.196e+07, Test loss: 1.028e+08, MSE(e): 5.188e+00, MSE(pi1): 3.795e+00, MSE(pi2): 2.335e+00, MSE(pi3): 4.665e-01\n",
      "Epoch 3300, Train loss: 4.891e+07, Test loss: 9.822e+07, MSE(e): 4.882e+00, MSE(pi1): 3.580e+00, MSE(pi2): 2.212e+00, MSE(pi3): 4.490e-01\n",
      "Epoch 3400, Train loss: 4.574e+07, Test loss: 9.345e+07, MSE(e): 4.566e+00, MSE(pi1): 3.373e+00, MSE(pi2): 2.086e+00, MSE(pi3): 4.319e-01\n",
      "Epoch 3500, Train loss: 4.251e+07, Test loss: 8.847e+07, MSE(e): 4.243e+00, MSE(pi1): 3.177e+00, MSE(pi2): 1.958e+00, MSE(pi3): 4.151e-01\n",
      "Epoch 3600, Train loss: 3.924e+07, Test loss: 8.324e+07, MSE(e): 3.917e+00, MSE(pi1): 2.990e+00, MSE(pi2): 1.829e+00, MSE(pi3): 3.988e-01\n",
      "Epoch 3700, Train loss: 3.599e+07, Test loss: 7.777e+07, MSE(e): 3.592e+00, MSE(pi1): 2.816e+00, MSE(pi2): 1.702e+00, MSE(pi3): 3.828e-01\n",
      "Epoch 3800, Train loss: 3.281e+07, Test loss: 7.210e+07, MSE(e): 3.274e+00, MSE(pi1): 2.657e+00, MSE(pi2): 1.577e+00, MSE(pi3): 3.672e-01\n",
      "Epoch 3900, Train loss: 2.974e+07, Test loss: 6.640e+07, MSE(e): 2.968e+00, MSE(pi1): 2.519e+00, MSE(pi2): 1.458e+00, MSE(pi3): 3.518e-01\n",
      "Epoch 4000, Train loss: 2.686e+07, Test loss: 6.086e+07, MSE(e): 2.680e+00, MSE(pi1): 2.403e+00, MSE(pi2): 1.345e+00, MSE(pi3): 3.367e-01\n",
      "Epoch 4100, Train loss: 2.423e+07, Test loss: 5.569e+07, MSE(e): 2.418e+00, MSE(pi1): 2.309e+00, MSE(pi2): 1.239e+00, MSE(pi3): 3.223e-01\n",
      "Epoch 4200, Train loss: 2.193e+07, Test loss: 5.109e+07, MSE(e): 2.187e+00, MSE(pi1): 2.234e+00, MSE(pi2): 1.143e+00, MSE(pi3): 3.088e-01\n",
      "Epoch 4300, Train loss: 1.999e+07, Test loss: 4.722e+07, MSE(e): 1.994e+00, MSE(pi1): 2.171e+00, MSE(pi2): 1.057e+00, MSE(pi3): 2.968e-01\n",
      "Epoch 4400, Train loss: 1.841e+07, Test loss: 4.411e+07, MSE(e): 1.836e+00, MSE(pi1): 2.111e+00, MSE(pi2): 9.828e-01, MSE(pi3): 2.863e-01\n",
      "Epoch 4500, Train loss: 1.713e+07, Test loss: 4.171e+07, MSE(e): 1.708e+00, MSE(pi1): 2.051e+00, MSE(pi2): 9.188e-01, MSE(pi3): 2.771e-01\n",
      "Epoch 4600, Train loss: 1.608e+07, Test loss: 3.992e+07, MSE(e): 1.604e+00, MSE(pi1): 1.988e+00, MSE(pi2): 8.639e-01, MSE(pi3): 2.689e-01\n",
      "Epoch 4700, Train loss: 1.521e+07, Test loss: 3.860e+07, MSE(e): 1.517e+00, MSE(pi1): 1.924e+00, MSE(pi2): 8.166e-01, MSE(pi3): 2.615e-01\n",
      "Epoch 4800, Train loss: 1.447e+07, Test loss: 3.763e+07, MSE(e): 1.443e+00, MSE(pi1): 1.861e+00, MSE(pi2): 7.754e-01, MSE(pi3): 2.548e-01\n",
      "Epoch 4900, Train loss: 1.383e+07, Test loss: 3.693e+07, MSE(e): 1.378e+00, MSE(pi1): 1.800e+00, MSE(pi2): 7.393e-01, MSE(pi3): 2.485e-01\n",
      "Epoch 5000, Train loss: 1.325e+07, Test loss: 3.642e+07, MSE(e): 1.321e+00, MSE(pi1): 1.743e+00, MSE(pi2): 7.071e-01, MSE(pi3): 2.427e-01\n",
      "Epoch 5100, Train loss: 1.274e+07, Test loss: 3.605e+07, MSE(e): 1.270e+00, MSE(pi1): 1.691e+00, MSE(pi2): 6.783e-01, MSE(pi3): 2.373e-01\n",
      "Epoch 5200, Train loss: 1.226e+07, Test loss: 3.578e+07, MSE(e): 1.222e+00, MSE(pi1): 1.644e+00, MSE(pi2): 6.521e-01, MSE(pi3): 2.323e-01\n",
      "Epoch 5300, Train loss: 1.182e+07, Test loss: 3.559e+07, MSE(e): 1.178e+00, MSE(pi1): 1.600e+00, MSE(pi2): 6.281e-01, MSE(pi3): 2.275e-01\n",
      "Epoch 5400, Train loss: 1.141e+07, Test loss: 3.546e+07, MSE(e): 1.137e+00, MSE(pi1): 1.560e+00, MSE(pi2): 6.059e-01, MSE(pi3): 2.231e-01\n",
      "Epoch 5500, Train loss: 1.102e+07, Test loss: 3.537e+07, MSE(e): 1.098e+00, MSE(pi1): 1.521e+00, MSE(pi2): 5.852e-01, MSE(pi3): 2.188e-01\n",
      "Epoch 5600, Train loss: 1.065e+07, Test loss: 3.532e+07, MSE(e): 1.061e+00, MSE(pi1): 1.484e+00, MSE(pi2): 5.657e-01, MSE(pi3): 2.148e-01\n",
      "Epoch 5700, Train loss: 1.029e+07, Test loss: 3.530e+07, MSE(e): 1.025e+00, MSE(pi1): 1.447e+00, MSE(pi2): 5.473e-01, MSE(pi3): 2.109e-01\n",
      "Epoch 5800, Train loss: 9.947e+06, Test loss: 3.529e+07, MSE(e): 9.912e-01, MSE(pi1): 1.411e+00, MSE(pi2): 5.298e-01, MSE(pi3): 2.072e-01\n",
      "Epoch 5900, Train loss: 9.615e+06, Test loss: 3.528e+07, MSE(e): 9.580e-01, MSE(pi1): 1.375e+00, MSE(pi2): 5.131e-01, MSE(pi3): 2.036e-01\n",
      "Epoch 6000, Train loss: 9.291e+06, Test loss: 3.527e+07, MSE(e): 9.257e-01, MSE(pi1): 1.341e+00, MSE(pi2): 4.971e-01, MSE(pi3): 2.001e-01\n",
      "Epoch 6100, Train loss: 8.974e+06, Test loss: 3.525e+07, MSE(e): 8.941e-01, MSE(pi1): 1.307e+00, MSE(pi2): 4.815e-01, MSE(pi3): 1.967e-01\n",
      "Epoch 6200, Train loss: 8.663e+06, Test loss: 3.520e+07, MSE(e): 8.630e-01, MSE(pi1): 1.274e+00, MSE(pi2): 4.664e-01, MSE(pi3): 1.935e-01\n",
      "Epoch 6300, Train loss: 8.355e+06, Test loss: 3.512e+07, MSE(e): 8.323e-01, MSE(pi1): 1.243e+00, MSE(pi2): 4.517e-01, MSE(pi3): 1.903e-01\n",
      "Epoch 6400, Train loss: 8.050e+06, Test loss: 3.500e+07, MSE(e): 8.019e-01, MSE(pi1): 1.213e+00, MSE(pi2): 4.373e-01, MSE(pi3): 1.872e-01\n",
      "Epoch 6500, Train loss: 7.747e+06, Test loss: 3.483e+07, MSE(e): 7.717e-01, MSE(pi1): 1.184e+00, MSE(pi2): 4.231e-01, MSE(pi3): 1.842e-01\n",
      "Epoch 6600, Train loss: 7.448e+06, Test loss: 3.461e+07, MSE(e): 7.418e-01, MSE(pi1): 1.156e+00, MSE(pi2): 4.091e-01, MSE(pi3): 1.813e-01\n",
      "Epoch 6700, Train loss: 7.155e+06, Test loss: 3.433e+07, MSE(e): 7.125e-01, MSE(pi1): 1.129e+00, MSE(pi2): 3.954e-01, MSE(pi3): 1.785e-01\n",
      "Epoch 6800, Train loss: 6.868e+06, Test loss: 3.400e+07, MSE(e): 6.839e-01, MSE(pi1): 1.104e+00, MSE(pi2): 3.820e-01, MSE(pi3): 1.757e-01\n",
      "Epoch 6900, Train loss: 6.591e+06, Test loss: 3.361e+07, MSE(e): 6.562e-01, MSE(pi1): 1.078e+00, MSE(pi2): 3.690e-01, MSE(pi3): 1.730e-01\n",
      "Epoch 7000, Train loss: 6.325e+06, Test loss: 3.318e+07, MSE(e): 6.297e-01, MSE(pi1): 1.054e+00, MSE(pi2): 3.564e-01, MSE(pi3): 1.704e-01\n",
      "Epoch 7100, Train loss: 6.072e+06, Test loss: 3.270e+07, MSE(e): 6.044e-01, MSE(pi1): 1.030e+00, MSE(pi2): 3.442e-01, MSE(pi3): 1.679e-01\n",
      "Epoch 7200, Train loss: 5.833e+06, Test loss: 3.219e+07, MSE(e): 5.806e-01, MSE(pi1): 1.007e+00, MSE(pi2): 3.326e-01, MSE(pi3): 1.656e-01\n",
      "Epoch 7300, Train loss: 5.608e+06, Test loss: 3.165e+07, MSE(e): 5.581e-01, MSE(pi1): 9.845e-01, MSE(pi2): 3.215e-01, MSE(pi3): 1.634e-01\n",
      "Epoch 7400, Train loss: 5.398e+06, Test loss: 3.109e+07, MSE(e): 5.372e-01, MSE(pi1): 9.628e-01, MSE(pi2): 3.111e-01, MSE(pi3): 1.613e-01\n",
      "Epoch 7500, Train loss: 5.203e+06, Test loss: 3.051e+07, MSE(e): 5.177e-01, MSE(pi1): 9.418e-01, MSE(pi2): 3.012e-01, MSE(pi3): 1.594e-01\n",
      "Epoch 7600, Train loss: 5.022e+06, Test loss: 2.994e+07, MSE(e): 4.997e-01, MSE(pi1): 9.213e-01, MSE(pi2): 2.920e-01, MSE(pi3): 1.576e-01\n",
      "Epoch 7700, Train loss: 4.855e+06, Test loss: 2.938e+07, MSE(e): 4.830e-01, MSE(pi1): 9.013e-01, MSE(pi2): 2.833e-01, MSE(pi3): 1.559e-01\n",
      "Epoch 7800, Train loss: 4.702e+06, Test loss: 2.884e+07, MSE(e): 4.677e-01, MSE(pi1): 8.816e-01, MSE(pi2): 2.753e-01, MSE(pi3): 1.543e-01\n",
      "Epoch 7900, Train loss: 4.561e+06, Test loss: 2.833e+07, MSE(e): 4.536e-01, MSE(pi1): 8.622e-01, MSE(pi2): 2.679e-01, MSE(pi3): 1.528e-01\n",
      "Epoch 8000, Train loss: 4.430e+06, Test loss: 2.786e+07, MSE(e): 4.407e-01, MSE(pi1): 8.429e-01, MSE(pi2): 2.610e-01, MSE(pi3): 1.513e-01\n",
      "Epoch 8100, Train loss: 4.310e+06, Test loss: 2.743e+07, MSE(e): 4.287e-01, MSE(pi1): 8.239e-01, MSE(pi2): 2.545e-01, MSE(pi3): 1.498e-01\n",
      "Epoch 8200, Train loss: 4.199e+06, Test loss: 2.704e+07, MSE(e): 4.176e-01, MSE(pi1): 8.050e-01, MSE(pi2): 2.485e-01, MSE(pi3): 1.484e-01\n",
      "Epoch 8300, Train loss: 4.095e+06, Test loss: 2.668e+07, MSE(e): 4.072e-01, MSE(pi1): 7.864e-01, MSE(pi2): 2.428e-01, MSE(pi3): 1.470e-01\n",
      "Epoch 8400, Train loss: 3.998e+06, Test loss: 2.637e+07, MSE(e): 3.975e-01, MSE(pi1): 7.683e-01, MSE(pi2): 2.375e-01, MSE(pi3): 1.456e-01\n",
      "Epoch 8500, Train loss: 3.907e+06, Test loss: 2.610e+07, MSE(e): 3.884e-01, MSE(pi1): 7.505e-01, MSE(pi2): 2.325e-01, MSE(pi3): 1.442e-01\n",
      "Epoch 8600, Train loss: 3.821e+06, Test loss: 2.585e+07, MSE(e): 3.799e-01, MSE(pi1): 7.334e-01, MSE(pi2): 2.278e-01, MSE(pi3): 1.429e-01\n",
      "Epoch 8700, Train loss: 3.739e+06, Test loss: 2.565e+07, MSE(e): 3.717e-01, MSE(pi1): 7.169e-01, MSE(pi2): 2.233e-01, MSE(pi3): 1.415e-01\n",
      "Epoch 8800, Train loss: 3.661e+06, Test loss: 2.547e+07, MSE(e): 3.640e-01, MSE(pi1): 7.010e-01, MSE(pi2): 2.190e-01, MSE(pi3): 1.402e-01\n",
      "Epoch 8900, Train loss: 3.587e+06, Test loss: 2.531e+07, MSE(e): 3.566e-01, MSE(pi1): 6.858e-01, MSE(pi2): 2.149e-01, MSE(pi3): 1.388e-01\n",
      "Epoch 9000, Train loss: 3.515e+06, Test loss: 2.518e+07, MSE(e): 3.494e-01, MSE(pi1): 6.714e-01, MSE(pi2): 2.110e-01, MSE(pi3): 1.374e-01\n",
      "Epoch 9100, Train loss: 3.446e+06, Test loss: 2.506e+07, MSE(e): 3.426e-01, MSE(pi1): 6.576e-01, MSE(pi2): 2.073e-01, MSE(pi3): 1.361e-01\n",
      "Epoch 9200, Train loss: 3.380e+06, Test loss: 2.497e+07, MSE(e): 3.360e-01, MSE(pi1): 6.444e-01, MSE(pi2): 2.036e-01, MSE(pi3): 1.347e-01\n",
      "Epoch 9300, Train loss: 3.315e+06, Test loss: 2.489e+07, MSE(e): 3.295e-01, MSE(pi1): 6.317e-01, MSE(pi2): 2.001e-01, MSE(pi3): 1.333e-01\n",
      "Epoch 9400, Train loss: 3.252e+06, Test loss: 2.482e+07, MSE(e): 3.233e-01, MSE(pi1): 6.196e-01, MSE(pi2): 1.967e-01, MSE(pi3): 1.319e-01\n",
      "Epoch 9500, Train loss: 3.191e+06, Test loss: 2.477e+07, MSE(e): 3.172e-01, MSE(pi1): 6.079e-01, MSE(pi2): 1.933e-01, MSE(pi3): 1.305e-01\n",
      "Epoch 9600, Train loss: 3.131e+06, Test loss: 2.472e+07, MSE(e): 3.112e-01, MSE(pi1): 5.967e-01, MSE(pi2): 1.900e-01, MSE(pi3): 1.290e-01\n",
      "Epoch 9700, Train loss: 3.073e+06, Test loss: 2.468e+07, MSE(e): 3.054e-01, MSE(pi1): 5.854e-01, MSE(pi2): 1.868e-01, MSE(pi3): 1.277e-01\n",
      "Epoch 9800, Train loss: 3.016e+06, Test loss: 2.466e+07, MSE(e): 2.997e-01, MSE(pi1): 5.752e-01, MSE(pi2): 1.836e-01, MSE(pi3): 1.262e-01\n",
      "Epoch 9900, Train loss: 2.960e+06, Test loss: 2.464e+07, MSE(e): 2.942e-01, MSE(pi1): 5.649e-01, MSE(pi2): 1.805e-01, MSE(pi3): 1.247e-01\n",
      "Epoch 10000, Train loss: 2.906e+06, Test loss: 2.462e+07, MSE(e): 2.888e-01, MSE(pi1): 5.546e-01, MSE(pi2): 1.775e-01, MSE(pi3): 1.233e-01\n",
      "Epoch 10100, Train loss: 2.854e+06, Test loss: 2.463e+07, MSE(e): 2.836e-01, MSE(pi1): 5.450e-01, MSE(pi2): 1.746e-01, MSE(pi3): 1.218e-01\n",
      "Epoch 10200, Train loss: 2.804e+06, Test loss: 2.462e+07, MSE(e): 2.786e-01, MSE(pi1): 5.349e-01, MSE(pi2): 1.717e-01, MSE(pi3): 1.205e-01\n",
      "Epoch 10300, Train loss: 2.756e+06, Test loss: 2.463e+07, MSE(e): 2.739e-01, MSE(pi1): 5.254e-01, MSE(pi2): 1.689e-01, MSE(pi3): 1.191e-01\n",
      "Epoch 10400, Train loss: 2.710e+06, Test loss: 2.463e+07, MSE(e): 2.693e-01, MSE(pi1): 5.161e-01, MSE(pi2): 1.662e-01, MSE(pi3): 1.178e-01\n",
      "Epoch 10500, Train loss: 2.667e+06, Test loss: 2.465e+07, MSE(e): 2.650e-01, MSE(pi1): 5.074e-01, MSE(pi2): 1.637e-01, MSE(pi3): 1.166e-01\n",
      "Epoch 10600, Train loss: 2.626e+06, Test loss: 2.466e+07, MSE(e): 2.609e-01, MSE(pi1): 4.995e-01, MSE(pi2): 1.612e-01, MSE(pi3): 1.154e-01\n",
      "Epoch 10700, Train loss: 2.587e+06, Test loss: 2.467e+07, MSE(e): 2.570e-01, MSE(pi1): 4.906e-01, MSE(pi2): 1.588e-01, MSE(pi3): 1.143e-01\n",
      "Epoch 10800, Train loss: 2.550e+06, Test loss: 2.468e+07, MSE(e): 2.534e-01, MSE(pi1): 4.836e-01, MSE(pi2): 1.566e-01, MSE(pi3): 1.132e-01\n",
      "Epoch 10900, Train loss: 2.515e+06, Test loss: 2.469e+07, MSE(e): 2.499e-01, MSE(pi1): 4.767e-01, MSE(pi2): 1.544e-01, MSE(pi3): 1.121e-01\n",
      "Epoch 11000, Train loss: 2.482e+06, Test loss: 2.468e+07, MSE(e): 2.466e-01, MSE(pi1): 4.701e-01, MSE(pi2): 1.524e-01, MSE(pi3): 1.111e-01\n",
      "Epoch 11100, Train loss: 2.451e+06, Test loss: 2.467e+07, MSE(e): 2.435e-01, MSE(pi1): 4.638e-01, MSE(pi2): 1.504e-01, MSE(pi3): 1.102e-01\n",
      "Epoch 11200, Train loss: 2.422e+06, Test loss: 2.466e+07, MSE(e): 2.406e-01, MSE(pi1): 4.583e-01, MSE(pi2): 1.486e-01, MSE(pi3): 1.093e-01\n",
      "Epoch 11300, Train loss: 2.394e+06, Test loss: 2.464e+07, MSE(e): 2.379e-01, MSE(pi1): 4.529e-01, MSE(pi2): 1.469e-01, MSE(pi3): 1.085e-01\n",
      "Epoch 11400, Train loss: 2.368e+06, Test loss: 2.462e+07, MSE(e): 2.353e-01, MSE(pi1): 4.480e-01, MSE(pi2): 1.452e-01, MSE(pi3): 1.077e-01\n",
      "Epoch 11500, Train loss: 2.343e+06, Test loss: 2.459e+07, MSE(e): 2.328e-01, MSE(pi1): 4.435e-01, MSE(pi2): 1.437e-01, MSE(pi3): 1.069e-01\n",
      "Epoch 11600, Train loss: 2.320e+06, Test loss: 2.457e+07, MSE(e): 2.305e-01, MSE(pi1): 4.391e-01, MSE(pi2): 1.422e-01, MSE(pi3): 1.061e-01\n",
      "Epoch 11700, Train loss: 2.298e+06, Test loss: 2.453e+07, MSE(e): 2.283e-01, MSE(pi1): 4.345e-01, MSE(pi2): 1.409e-01, MSE(pi3): 1.054e-01\n",
      "Epoch 11800, Train loss: 2.276e+06, Test loss: 2.450e+07, MSE(e): 2.261e-01, MSE(pi1): 4.308e-01, MSE(pi2): 1.395e-01, MSE(pi3): 1.047e-01\n",
      "Epoch 11900, Train loss: 2.256e+06, Test loss: 2.446e+07, MSE(e): 2.241e-01, MSE(pi1): 4.269e-01, MSE(pi2): 1.383e-01, MSE(pi3): 1.041e-01\n",
      "Epoch 12000, Train loss: 2.237e+06, Test loss: 2.441e+07, MSE(e): 2.222e-01, MSE(pi1): 4.229e-01, MSE(pi2): 1.371e-01, MSE(pi3): 1.035e-01\n",
      "Epoch 12100, Train loss: 2.219e+06, Test loss: 2.439e+07, MSE(e): 2.204e-01, MSE(pi1): 4.195e-01, MSE(pi2): 1.359e-01, MSE(pi3): 1.029e-01\n",
      "Epoch 12200, Train loss: 2.201e+06, Test loss: 2.435e+07, MSE(e): 2.186e-01, MSE(pi1): 4.163e-01, MSE(pi2): 1.348e-01, MSE(pi3): 1.023e-01\n",
      "Epoch 12300, Train loss: 2.183e+06, Test loss: 2.432e+07, MSE(e): 2.169e-01, MSE(pi1): 4.129e-01, MSE(pi2): 1.338e-01, MSE(pi3): 1.017e-01\n",
      "Epoch 12400, Train loss: 2.167e+06, Test loss: 2.429e+07, MSE(e): 2.152e-01, MSE(pi1): 4.102e-01, MSE(pi2): 1.327e-01, MSE(pi3): 1.011e-01\n",
      "Epoch 12500, Train loss: 2.150e+06, Test loss: 2.424e+07, MSE(e): 2.136e-01, MSE(pi1): 4.069e-01, MSE(pi2): 1.317e-01, MSE(pi3): 1.007e-01\n",
      "Epoch 12600, Train loss: 2.134e+06, Test loss: 2.422e+07, MSE(e): 2.120e-01, MSE(pi1): 4.043e-01, MSE(pi2): 1.307e-01, MSE(pi3): 1.001e-01\n",
      "Epoch 12700, Train loss: 2.119e+06, Test loss: 2.419e+07, MSE(e): 2.105e-01, MSE(pi1): 4.016e-01, MSE(pi2): 1.297e-01, MSE(pi3): 9.960e-02\n",
      "Epoch 12800, Train loss: 2.104e+06, Test loss: 2.417e+07, MSE(e): 2.090e-01, MSE(pi1): 3.989e-01, MSE(pi2): 1.288e-01, MSE(pi3): 9.910e-02\n",
      "Epoch 12900, Train loss: 2.089e+06, Test loss: 2.414e+07, MSE(e): 2.075e-01, MSE(pi1): 3.963e-01, MSE(pi2): 1.279e-01, MSE(pi3): 9.864e-02\n",
      "Epoch 13000, Train loss: 2.074e+06, Test loss: 2.411e+07, MSE(e): 2.060e-01, MSE(pi1): 3.940e-01, MSE(pi2): 1.269e-01, MSE(pi3): 9.817e-02\n",
      "Epoch 13100, Train loss: 2.059e+06, Test loss: 2.409e+07, MSE(e): 2.046e-01, MSE(pi1): 3.916e-01, MSE(pi2): 1.260e-01, MSE(pi3): 9.771e-02\n",
      "Epoch 13200, Train loss: 2.045e+06, Test loss: 2.406e+07, MSE(e): 2.031e-01, MSE(pi1): 3.891e-01, MSE(pi2): 1.251e-01, MSE(pi3): 9.730e-02\n",
      "Epoch 13300, Train loss: 2.031e+06, Test loss: 2.403e+07, MSE(e): 2.017e-01, MSE(pi1): 3.868e-01, MSE(pi2): 1.243e-01, MSE(pi3): 9.686e-02\n",
      "Epoch 13400, Train loss: 2.016e+06, Test loss: 2.399e+07, MSE(e): 2.003e-01, MSE(pi1): 3.858e-01, MSE(pi2): 1.234e-01, MSE(pi3): 9.647e-02\n",
      "Epoch 13500, Train loss: 2.002e+06, Test loss: 2.399e+07, MSE(e): 1.988e-01, MSE(pi1): 3.831e-01, MSE(pi2): 1.225e-01, MSE(pi3): 9.590e-02\n",
      "Epoch 13600, Train loss: 1.988e+06, Test loss: 2.393e+07, MSE(e): 1.975e-01, MSE(pi1): 3.801e-01, MSE(pi2): 1.216e-01, MSE(pi3): 9.573e-02\n",
      "Epoch 13700, Train loss: 1.974e+06, Test loss: 2.394e+07, MSE(e): 1.960e-01, MSE(pi1): 3.782e-01, MSE(pi2): 1.208e-01, MSE(pi3): 9.508e-02\n",
      "Epoch 13800, Train loss: 1.960e+06, Test loss: 2.392e+07, MSE(e): 1.946e-01, MSE(pi1): 3.761e-01, MSE(pi2): 1.199e-01, MSE(pi3): 9.463e-02\n",
      "Epoch 13900, Train loss: 1.946e+06, Test loss: 2.389e+07, MSE(e): 1.932e-01, MSE(pi1): 3.737e-01, MSE(pi2): 1.190e-01, MSE(pi3): 9.422e-02\n",
      "Epoch 14000, Train loss: 1.932e+06, Test loss: 2.387e+07, MSE(e): 1.918e-01, MSE(pi1): 3.716e-01, MSE(pi2): 1.182e-01, MSE(pi3): 9.377e-02\n",
      "Epoch 14100, Train loss: 1.917e+06, Test loss: 2.385e+07, MSE(e): 1.904e-01, MSE(pi1): 3.694e-01, MSE(pi2): 1.173e-01, MSE(pi3): 9.331e-02\n",
      "Epoch 14200, Train loss: 1.903e+06, Test loss: 2.382e+07, MSE(e): 1.890e-01, MSE(pi1): 3.672e-01, MSE(pi2): 1.165e-01, MSE(pi3): 9.284e-02\n",
      "Epoch 14300, Train loss: 1.889e+06, Test loss: 2.380e+07, MSE(e): 1.876e-01, MSE(pi1): 3.651e-01, MSE(pi2): 1.156e-01, MSE(pi3): 9.239e-02\n",
      "Epoch 14400, Train loss: 1.875e+06, Test loss: 2.377e+07, MSE(e): 1.862e-01, MSE(pi1): 3.625e-01, MSE(pi2): 1.148e-01, MSE(pi3): 9.195e-02\n",
      "Epoch 14500, Train loss: 1.860e+06, Test loss: 2.377e+07, MSE(e): 1.847e-01, MSE(pi1): 3.615e-01, MSE(pi2): 1.139e-01, MSE(pi3): 9.134e-02\n",
      "Epoch 14600, Train loss: 1.846e+06, Test loss: 2.373e+07, MSE(e): 1.833e-01, MSE(pi1): 3.584e-01, MSE(pi2): 1.130e-01, MSE(pi3): 9.094e-02\n",
      "Epoch 14700, Train loss: 1.831e+06, Test loss: 2.373e+07, MSE(e): 1.819e-01, MSE(pi1): 3.643e-01, MSE(pi2): 1.122e-01, MSE(pi3): 9.024e-02\n",
      "Epoch 14800, Train loss: 1.817e+06, Test loss: 2.369e+07, MSE(e): 1.804e-01, MSE(pi1): 3.549e-01, MSE(pi2): 1.113e-01, MSE(pi3): 8.993e-02\n",
      "Epoch 14900, Train loss: 1.802e+06, Test loss: 2.366e+07, MSE(e): 1.789e-01, MSE(pi1): 3.526e-01, MSE(pi2): 1.104e-01, MSE(pi3): 8.936e-02\n",
      "Epoch 15000, Train loss: 1.787e+06, Test loss: 2.364e+07, MSE(e): 1.775e-01, MSE(pi1): 3.496e-01, MSE(pi2): 1.095e-01, MSE(pi3): 8.889e-02\n",
      "Epoch 15100, Train loss: 1.772e+06, Test loss: 2.362e+07, MSE(e): 1.760e-01, MSE(pi1): 3.476e-01, MSE(pi2): 1.087e-01, MSE(pi3): 8.833e-02\n",
      "Epoch 15200, Train loss: 1.757e+06, Test loss: 2.360e+07, MSE(e): 1.745e-01, MSE(pi1): 3.453e-01, MSE(pi2): 1.078e-01, MSE(pi3): 8.782e-02\n",
      "Epoch 15300, Train loss: 1.742e+06, Test loss: 2.358e+07, MSE(e): 1.730e-01, MSE(pi1): 3.429e-01, MSE(pi2): 1.069e-01, MSE(pi3): 8.727e-02\n",
      "Epoch 15400, Train loss: 1.727e+06, Test loss: 2.358e+07, MSE(e): 1.715e-01, MSE(pi1): 3.418e-01, MSE(pi2): 1.060e-01, MSE(pi3): 8.666e-02\n",
      "Epoch 15500, Train loss: 1.712e+06, Test loss: 2.354e+07, MSE(e): 1.700e-01, MSE(pi1): 3.387e-01, MSE(pi2): 1.051e-01, MSE(pi3): 8.613e-02\n",
      "Epoch 15600, Train loss: 1.697e+06, Test loss: 2.351e+07, MSE(e): 1.685e-01, MSE(pi1): 3.360e-01, MSE(pi2): 1.042e-01, MSE(pi3): 8.560e-02\n",
      "Epoch 15700, Train loss: 1.682e+06, Test loss: 2.348e+07, MSE(e): 1.670e-01, MSE(pi1): 3.353e-01, MSE(pi2): 1.033e-01, MSE(pi3): 8.512e-02\n",
      "Epoch 15800, Train loss: 1.666e+06, Test loss: 2.348e+07, MSE(e): 1.654e-01, MSE(pi1): 3.317e-01, MSE(pi2): 1.024e-01, MSE(pi3): 8.439e-02\n",
      "Epoch 15900, Train loss: 1.651e+06, Test loss: 2.346e+07, MSE(e): 1.639e-01, MSE(pi1): 3.292e-01, MSE(pi2): 1.015e-01, MSE(pi3): 8.385e-02\n",
      "Epoch 16000, Train loss: 1.636e+06, Test loss: 2.344e+07, MSE(e): 1.624e-01, MSE(pi1): 3.271e-01, MSE(pi2): 1.007e-01, MSE(pi3): 8.323e-02\n",
      "Epoch 16100, Train loss: 1.621e+06, Test loss: 2.343e+07, MSE(e): 1.610e-01, MSE(pi1): 3.249e-01, MSE(pi2): 9.979e-02, MSE(pi3): 8.264e-02\n",
      "Epoch 16200, Train loss: 1.606e+06, Test loss: 2.341e+07, MSE(e): 1.595e-01, MSE(pi1): 3.251e-01, MSE(pi2): 9.893e-02, MSE(pi3): 8.198e-02\n",
      "Epoch 16300, Train loss: 1.591e+06, Test loss: 2.339e+07, MSE(e): 1.580e-01, MSE(pi1): 3.204e-01, MSE(pi2): 9.806e-02, MSE(pi3): 8.143e-02\n",
      "Epoch 16400, Train loss: 1.576e+06, Test loss: 2.337e+07, MSE(e): 1.565e-01, MSE(pi1): 3.177e-01, MSE(pi2): 9.720e-02, MSE(pi3): 8.088e-02\n",
      "Epoch 16500, Train loss: 1.562e+06, Test loss: 2.336e+07, MSE(e): 1.550e-01, MSE(pi1): 3.154e-01, MSE(pi2): 9.635e-02, MSE(pi3): 8.029e-02\n",
      "Epoch 16600, Train loss: 1.547e+06, Test loss: 2.336e+07, MSE(e): 1.536e-01, MSE(pi1): 3.143e-01, MSE(pi2): 9.551e-02, MSE(pi3): 7.956e-02\n",
      "Epoch 16700, Train loss: 1.532e+06, Test loss: 2.333e+07, MSE(e): 1.521e-01, MSE(pi1): 3.114e-01, MSE(pi2): 9.467e-02, MSE(pi3): 7.918e-02\n",
      "Epoch 16800, Train loss: 1.518e+06, Test loss: 2.332e+07, MSE(e): 1.507e-01, MSE(pi1): 3.083e-01, MSE(pi2): 9.383e-02, MSE(pi3): 7.852e-02\n",
      "Epoch 16900, Train loss: 1.503e+06, Test loss: 2.329e+07, MSE(e): 1.492e-01, MSE(pi1): 3.068e-01, MSE(pi2): 9.298e-02, MSE(pi3): 7.793e-02\n",
      "Epoch 17000, Train loss: 1.489e+06, Test loss: 2.328e+07, MSE(e): 1.478e-01, MSE(pi1): 3.034e-01, MSE(pi2): 9.216e-02, MSE(pi3): 7.735e-02\n",
      "Epoch 17100, Train loss: 1.474e+06, Test loss: 2.327e+07, MSE(e): 1.464e-01, MSE(pi1): 3.006e-01, MSE(pi2): 9.132e-02, MSE(pi3): 7.683e-02\n",
      "Epoch 17200, Train loss: 1.461e+06, Test loss: 2.325e+07, MSE(e): 1.450e-01, MSE(pi1): 2.990e-01, MSE(pi2): 9.052e-02, MSE(pi3): 7.622e-02\n",
      "Epoch 17300, Train loss: 1.446e+06, Test loss: 2.323e+07, MSE(e): 1.436e-01, MSE(pi1): 3.003e-01, MSE(pi2): 8.968e-02, MSE(pi3): 7.560e-02\n",
      "Epoch 17400, Train loss: 1.432e+06, Test loss: 2.321e+07, MSE(e): 1.421e-01, MSE(pi1): 2.940e-01, MSE(pi2): 8.884e-02, MSE(pi3): 7.510e-02\n",
      "Epoch 17500, Train loss: 1.417e+06, Test loss: 2.320e+07, MSE(e): 1.407e-01, MSE(pi1): 2.922e-01, MSE(pi2): 8.799e-02, MSE(pi3): 7.454e-02\n",
      "Epoch 17600, Train loss: 1.403e+06, Test loss: 2.318e+07, MSE(e): 1.393e-01, MSE(pi1): 2.889e-01, MSE(pi2): 8.714e-02, MSE(pi3): 7.386e-02\n",
      "Epoch 17700, Train loss: 1.389e+06, Test loss: 2.316e+07, MSE(e): 1.378e-01, MSE(pi1): 2.866e-01, MSE(pi2): 8.629e-02, MSE(pi3): 7.324e-02\n",
      "Epoch 17800, Train loss: 1.374e+06, Test loss: 2.313e+07, MSE(e): 1.364e-01, MSE(pi1): 2.834e-01, MSE(pi2): 8.542e-02, MSE(pi3): 7.275e-02\n",
      "Epoch 17900, Train loss: 1.360e+06, Test loss: 2.311e+07, MSE(e): 1.350e-01, MSE(pi1): 2.854e-01, MSE(pi2): 8.456e-02, MSE(pi3): 7.205e-02\n",
      "Epoch 18000, Train loss: 1.346e+06, Test loss: 2.309e+07, MSE(e): 1.336e-01, MSE(pi1): 2.788e-01, MSE(pi2): 8.369e-02, MSE(pi3): 7.143e-02\n",
      "Epoch 18100, Train loss: 1.331e+06, Test loss: 2.305e+07, MSE(e): 1.321e-01, MSE(pi1): 2.760e-01, MSE(pi2): 8.280e-02, MSE(pi3): 7.093e-02\n",
      "Epoch 18200, Train loss: 1.317e+06, Test loss: 2.305e+07, MSE(e): 1.307e-01, MSE(pi1): 2.765e-01, MSE(pi2): 8.192e-02, MSE(pi3): 6.991e-02\n",
      "Epoch 18300, Train loss: 1.302e+06, Test loss: 2.301e+07, MSE(e): 1.292e-01, MSE(pi1): 2.706e-01, MSE(pi2): 8.102e-02, MSE(pi3): 6.954e-02\n",
      "Epoch 18400, Train loss: 1.287e+06, Test loss: 2.299e+07, MSE(e): 1.278e-01, MSE(pi1): 2.680e-01, MSE(pi2): 8.011e-02, MSE(pi3): 6.888e-02\n",
      "Epoch 18500, Train loss: 1.273e+06, Test loss: 2.296e+07, MSE(e): 1.263e-01, MSE(pi1): 2.651e-01, MSE(pi2): 7.922e-02, MSE(pi3): 6.825e-02\n",
      "Epoch 18600, Train loss: 1.258e+06, Test loss: 2.293e+07, MSE(e): 1.249e-01, MSE(pi1): 2.622e-01, MSE(pi2): 7.832e-02, MSE(pi3): 6.758e-02\n",
      "Epoch 18700, Train loss: 1.244e+06, Test loss: 2.291e+07, MSE(e): 1.235e-01, MSE(pi1): 2.595e-01, MSE(pi2): 7.743e-02, MSE(pi3): 6.702e-02\n",
      "Epoch 18800, Train loss: 1.230e+06, Test loss: 2.290e+07, MSE(e): 1.220e-01, MSE(pi1): 2.572e-01, MSE(pi2): 7.653e-02, MSE(pi3): 6.617e-02\n",
      "Epoch 18900, Train loss: 1.215e+06, Test loss: 2.285e+07, MSE(e): 1.206e-01, MSE(pi1): 2.541e-01, MSE(pi2): 7.562e-02, MSE(pi3): 6.580e-02\n",
      "Epoch 19000, Train loss: 1.201e+06, Test loss: 2.283e+07, MSE(e): 1.192e-01, MSE(pi1): 2.502e-01, MSE(pi2): 7.473e-02, MSE(pi3): 6.501e-02\n",
      "Epoch 19100, Train loss: 1.187e+06, Test loss: 2.281e+07, MSE(e): 1.178e-01, MSE(pi1): 2.477e-01, MSE(pi2): 7.385e-02, MSE(pi3): 6.436e-02\n",
      "Epoch 19200, Train loss: 1.173e+06, Test loss: 2.278e+07, MSE(e): 1.164e-01, MSE(pi1): 2.441e-01, MSE(pi2): 7.298e-02, MSE(pi3): 6.382e-02\n",
      "Epoch 19300, Train loss: 1.160e+06, Test loss: 2.277e+07, MSE(e): 1.151e-01, MSE(pi1): 2.417e-01, MSE(pi2): 7.213e-02, MSE(pi3): 6.313e-02\n",
      "Epoch 19400, Train loss: 1.147e+06, Test loss: 2.278e+07, MSE(e): 1.138e-01, MSE(pi1): 2.456e-01, MSE(pi2): 7.131e-02, MSE(pi3): 6.221e-02\n",
      "Epoch 19500, Train loss: 1.133e+06, Test loss: 2.273e+07, MSE(e): 1.125e-01, MSE(pi1): 2.367e-01, MSE(pi2): 7.046e-02, MSE(pi3): 6.191e-02\n",
      "Epoch 19600, Train loss: 1.120e+06, Test loss: 2.271e+07, MSE(e): 1.112e-01, MSE(pi1): 2.343e-01, MSE(pi2): 6.964e-02, MSE(pi3): 6.132e-02\n",
      "Epoch 19700, Train loss: 1.108e+06, Test loss: 2.269e+07, MSE(e): 1.099e-01, MSE(pi1): 2.320e-01, MSE(pi2): 6.885e-02, MSE(pi3): 6.075e-02\n",
      "Epoch 19800, Train loss: 1.096e+06, Test loss: 2.267e+07, MSE(e): 1.087e-01, MSE(pi1): 2.298e-01, MSE(pi2): 6.807e-02, MSE(pi3): 6.019e-02\n",
      "Epoch 19900, Train loss: 1.084e+06, Test loss: 2.267e+07, MSE(e): 1.075e-01, MSE(pi1): 2.287e-01, MSE(pi2): 6.731e-02, MSE(pi3): 5.949e-02\n",
      "Epoch 20000, Train loss: 1.072e+06, Test loss: 2.264e+07, MSE(e): 1.064e-01, MSE(pi1): 2.271e-01, MSE(pi2): 6.655e-02, MSE(pi3): 5.919e-02\n",
      "Epoch 20100, Train loss: 1.060e+06, Test loss: 2.263e+07, MSE(e): 1.052e-01, MSE(pi1): 2.238e-01, MSE(pi2): 6.581e-02, MSE(pi3): 5.854e-02\n",
      "Epoch 20200, Train loss: 1.049e+06, Test loss: 2.262e+07, MSE(e): 1.041e-01, MSE(pi1): 2.219e-01, MSE(pi2): 6.509e-02, MSE(pi3): 5.801e-02\n",
      "Epoch 20300, Train loss: 1.038e+06, Test loss: 2.260e+07, MSE(e): 1.030e-01, MSE(pi1): 2.202e-01, MSE(pi2): 6.439e-02, MSE(pi3): 5.749e-02\n",
      "Epoch 20400, Train loss: 1.028e+06, Test loss: 2.259e+07, MSE(e): 1.020e-01, MSE(pi1): 2.237e-01, MSE(pi2): 6.371e-02, MSE(pi3): 5.678e-02\n",
      "Epoch 20500, Train loss: 1.017e+06, Test loss: 2.258e+07, MSE(e): 1.009e-01, MSE(pi1): 2.167e-01, MSE(pi2): 6.304e-02, MSE(pi3): 5.651e-02\n",
      "Epoch 20600, Train loss: 1.007e+06, Test loss: 2.256e+07, MSE(e): 9.992e-02, MSE(pi1): 2.151e-01, MSE(pi2): 6.238e-02, MSE(pi3): 5.602e-02\n",
      "Epoch 20700, Train loss: 9.971e+05, Test loss: 2.255e+07, MSE(e): 9.893e-02, MSE(pi1): 2.135e-01, MSE(pi2): 6.174e-02, MSE(pi3): 5.556e-02\n",
      "Epoch 20800, Train loss: 9.876e+05, Test loss: 2.254e+07, MSE(e): 9.799e-02, MSE(pi1): 2.132e-01, MSE(pi2): 6.112e-02, MSE(pi3): 5.517e-02\n",
      "Epoch 20900, Train loss: 9.784e+05, Test loss: 2.251e+07, MSE(e): 9.707e-02, MSE(pi1): 2.111e-01, MSE(pi2): 6.051e-02, MSE(pi3): 5.491e-02\n",
      "Epoch 21000, Train loss: 9.691e+05, Test loss: 2.253e+07, MSE(e): 9.615e-02, MSE(pi1): 2.091e-01, MSE(pi2): 5.992e-02, MSE(pi3): 5.421e-02\n",
      "Epoch 21100, Train loss: 9.601e+05, Test loss: 2.252e+07, MSE(e): 9.526e-02, MSE(pi1): 2.078e-01, MSE(pi2): 5.933e-02, MSE(pi3): 5.379e-02\n",
      "Epoch 21200, Train loss: 9.514e+05, Test loss: 2.251e+07, MSE(e): 9.440e-02, MSE(pi1): 2.060e-01, MSE(pi2): 5.876e-02, MSE(pi3): 5.342e-02\n",
      "Epoch 21300, Train loss: 9.429e+05, Test loss: 2.251e+07, MSE(e): 9.355e-02, MSE(pi1): 2.051e-01, MSE(pi2): 5.820e-02, MSE(pi3): 5.294e-02\n",
      "Epoch 21400, Train loss: 9.348e+05, Test loss: 2.251e+07, MSE(e): 9.274e-02, MSE(pi1): 2.038e-01, MSE(pi2): 5.767e-02, MSE(pi3): 5.255e-02\n",
      "Epoch 21500, Train loss: 9.273e+05, Test loss: 2.247e+07, MSE(e): 9.199e-02, MSE(pi1): 2.034e-01, MSE(pi2): 5.716e-02, MSE(pi3): 5.251e-02\n",
      "Epoch 21600, Train loss: 9.189e+05, Test loss: 2.250e+07, MSE(e): 9.116e-02, MSE(pi1): 2.015e-01, MSE(pi2): 5.663e-02, MSE(pi3): 5.177e-02\n",
      "Epoch 21700, Train loss: 9.112e+05, Test loss: 2.250e+07, MSE(e): 9.040e-02, MSE(pi1): 2.003e-01, MSE(pi2): 5.612e-02, MSE(pi3): 5.138e-02\n",
      "Epoch 21800, Train loss: 9.038e+05, Test loss: 2.250e+07, MSE(e): 8.966e-02, MSE(pi1): 1.988e-01, MSE(pi2): 5.563e-02, MSE(pi3): 5.110e-02\n",
      "Epoch 21900, Train loss: 8.964e+05, Test loss: 2.251e+07, MSE(e): 8.893e-02, MSE(pi1): 1.986e-01, MSE(pi2): 5.514e-02, MSE(pi3): 5.061e-02\n",
      "Epoch 22000, Train loss: 8.893e+05, Test loss: 2.252e+07, MSE(e): 8.822e-02, MSE(pi1): 1.969e-01, MSE(pi2): 5.467e-02, MSE(pi3): 5.032e-02\n",
      "Epoch 22100, Train loss: 8.825e+05, Test loss: 2.251e+07, MSE(e): 8.755e-02, MSE(pi1): 1.957e-01, MSE(pi2): 5.422e-02, MSE(pi3): 5.009e-02\n",
      "Epoch 22200, Train loss: 8.756e+05, Test loss: 2.253e+07, MSE(e): 8.686e-02, MSE(pi1): 1.953e-01, MSE(pi2): 5.376e-02, MSE(pi3): 4.970e-02\n",
      "Epoch 22300, Train loss: 8.690e+05, Test loss: 2.254e+07, MSE(e): 8.621e-02, MSE(pi1): 1.940e-01, MSE(pi2): 5.332e-02, MSE(pi3): 4.932e-02\n",
      "Epoch 22400, Train loss: 8.626e+05, Test loss: 2.252e+07, MSE(e): 8.557e-02, MSE(pi1): 1.928e-01, MSE(pi2): 5.289e-02, MSE(pi3): 4.907e-02\n",
      "Epoch 22500, Train loss: 8.565e+05, Test loss: 2.256e+07, MSE(e): 8.496e-02, MSE(pi1): 1.919e-01, MSE(pi2): 5.249e-02, MSE(pi3): 4.871e-02\n",
      "Epoch 22600, Train loss: 8.504e+05, Test loss: 2.258e+07, MSE(e): 8.436e-02, MSE(pi1): 1.911e-01, MSE(pi2): 5.208e-02, MSE(pi3): 4.838e-02\n",
      "Epoch 22700, Train loss: 8.445e+05, Test loss: 2.260e+07, MSE(e): 8.377e-02, MSE(pi1): 1.901e-01, MSE(pi2): 5.169e-02, MSE(pi3): 4.808e-02\n",
      "Epoch 22800, Train loss: 8.387e+05, Test loss: 2.260e+07, MSE(e): 8.320e-02, MSE(pi1): 1.894e-01, MSE(pi2): 5.130e-02, MSE(pi3): 4.781e-02\n",
      "Epoch 22900, Train loss: 8.331e+05, Test loss: 2.263e+07, MSE(e): 8.264e-02, MSE(pi1): 1.883e-01, MSE(pi2): 5.092e-02, MSE(pi3): 4.753e-02\n",
      "Epoch 23000, Train loss: 8.276e+05, Test loss: 2.265e+07, MSE(e): 8.210e-02, MSE(pi1): 1.875e-01, MSE(pi2): 5.055e-02, MSE(pi3): 4.725e-02\n",
      "Epoch 23100, Train loss: 8.232e+05, Test loss: 2.271e+07, MSE(e): 8.165e-02, MSE(pi1): 1.892e-01, MSE(pi2): 5.024e-02, MSE(pi3): 4.671e-02\n",
      "Epoch 23200, Train loss: 8.170e+05, Test loss: 2.270e+07, MSE(e): 8.104e-02, MSE(pi1): 1.868e-01, MSE(pi2): 4.984e-02, MSE(pi3): 4.670e-02\n",
      "Epoch 23300, Train loss: 8.119e+05, Test loss: 2.272e+07, MSE(e): 8.054e-02, MSE(pi1): 1.851e-01, MSE(pi2): 4.949e-02, MSE(pi3): 4.647e-02\n",
      "Epoch 23400, Train loss: 8.071e+05, Test loss: 2.274e+07, MSE(e): 8.005e-02, MSE(pi1): 1.840e-01, MSE(pi2): 4.916e-02, MSE(pi3): 4.632e-02\n",
      "Epoch 23500, Train loss: 8.021e+05, Test loss: 2.277e+07, MSE(e): 7.956e-02, MSE(pi1): 1.837e-01, MSE(pi2): 4.883e-02, MSE(pi3): 4.596e-02\n",
      "Epoch 23600, Train loss: 7.974e+05, Test loss: 2.279e+07, MSE(e): 7.910e-02, MSE(pi1): 1.827e-01, MSE(pi2): 4.851e-02, MSE(pi3): 4.577e-02\n",
      "Epoch 23700, Train loss: 7.929e+05, Test loss: 2.282e+07, MSE(e): 7.865e-02, MSE(pi1): 1.823e-01, MSE(pi2): 4.820e-02, MSE(pi3): 4.550e-02\n",
      "Epoch 23800, Train loss: 7.884e+05, Test loss: 2.285e+07, MSE(e): 7.820e-02, MSE(pi1): 1.815e-01, MSE(pi2): 4.789e-02, MSE(pi3): 4.536e-02\n",
      "Epoch 23900, Train loss: 7.841e+05, Test loss: 2.287e+07, MSE(e): 7.778e-02, MSE(pi1): 1.810e-01, MSE(pi2): 4.760e-02, MSE(pi3): 4.506e-02\n",
      "Epoch 24000, Train loss: 7.799e+05, Test loss: 2.291e+07, MSE(e): 7.735e-02, MSE(pi1): 1.806e-01, MSE(pi2): 4.731e-02, MSE(pi3): 4.481e-02\n",
      "Epoch 24100, Train loss: 7.757e+05, Test loss: 2.293e+07, MSE(e): 7.694e-02, MSE(pi1): 1.796e-01, MSE(pi2): 4.702e-02, MSE(pi3): 4.465e-02\n",
      "Epoch 24200, Train loss: 7.717e+05, Test loss: 2.296e+07, MSE(e): 7.654e-02, MSE(pi1): 1.802e-01, MSE(pi2): 4.674e-02, MSE(pi3): 4.444e-02\n",
      "Epoch 24300, Train loss: 7.678e+05, Test loss: 2.297e+07, MSE(e): 7.615e-02, MSE(pi1): 1.806e-01, MSE(pi2): 4.647e-02, MSE(pi3): 4.424e-02\n",
      "Epoch 24400, Train loss: 7.639e+05, Test loss: 2.301e+07, MSE(e): 7.576e-02, MSE(pi1): 1.779e-01, MSE(pi2): 4.621e-02, MSE(pi3): 4.404e-02\n",
      "Epoch 24500, Train loss: 7.601e+05, Test loss: 2.304e+07, MSE(e): 7.539e-02, MSE(pi1): 1.772e-01, MSE(pi2): 4.595e-02, MSE(pi3): 4.388e-02\n",
      "Epoch 24600, Train loss: 7.564e+05, Test loss: 2.307e+07, MSE(e): 7.503e-02, MSE(pi1): 1.771e-01, MSE(pi2): 4.569e-02, MSE(pi3): 4.369e-02\n",
      "Epoch 24700, Train loss: 7.529e+05, Test loss: 2.310e+07, MSE(e): 7.468e-02, MSE(pi1): 1.762e-01, MSE(pi2): 4.545e-02, MSE(pi3): 4.351e-02\n",
      "Epoch 24800, Train loss: 7.494e+05, Test loss: 2.312e+07, MSE(e): 7.433e-02, MSE(pi1): 1.760e-01, MSE(pi2): 4.521e-02, MSE(pi3): 4.333e-02\n",
      "Epoch 24900, Train loss: 7.460e+05, Test loss: 2.316e+07, MSE(e): 7.399e-02, MSE(pi1): 1.752e-01, MSE(pi2): 4.498e-02, MSE(pi3): 4.316e-02\n",
      "Epoch 25000, Train loss: 7.427e+05, Test loss: 2.318e+07, MSE(e): 7.366e-02, MSE(pi1): 1.746e-01, MSE(pi2): 4.475e-02, MSE(pi3): 4.303e-02\n",
      "Epoch 25100, Train loss: 7.395e+05, Test loss: 2.321e+07, MSE(e): 7.334e-02, MSE(pi1): 1.741e-01, MSE(pi2): 4.452e-02, MSE(pi3): 4.285e-02\n",
      "Epoch 25200, Train loss: 7.363e+05, Test loss: 2.324e+07, MSE(e): 7.303e-02, MSE(pi1): 1.737e-01, MSE(pi2): 4.430e-02, MSE(pi3): 4.269e-02\n",
      "Epoch 25300, Train loss: 7.334e+05, Test loss: 2.324e+07, MSE(e): 7.274e-02, MSE(pi1): 1.729e-01, MSE(pi2): 4.410e-02, MSE(pi3): 4.266e-02\n",
      "Epoch 25400, Train loss: 7.303e+05, Test loss: 2.328e+07, MSE(e): 7.242e-02, MSE(pi1): 1.723e-01, MSE(pi2): 4.388e-02, MSE(pi3): 4.249e-02\n",
      "Epoch 25500, Train loss: 7.272e+05, Test loss: 2.333e+07, MSE(e): 7.212e-02, MSE(pi1): 1.727e-01, MSE(pi2): 4.367e-02, MSE(pi3): 4.225e-02\n",
      "Epoch 25600, Train loss: 7.244e+05, Test loss: 2.337e+07, MSE(e): 7.185e-02, MSE(pi1): 1.731e-01, MSE(pi2): 4.348e-02, MSE(pi3): 4.195e-02\n",
      "Epoch 25700, Train loss: 7.215e+05, Test loss: 2.337e+07, MSE(e): 7.154e-02, MSE(pi1): 1.784e-01, MSE(pi2): 4.327e-02, MSE(pi3): 4.217e-02\n",
      "Epoch 25800, Train loss: 7.187e+05, Test loss: 2.342e+07, MSE(e): 7.128e-02, MSE(pi1): 1.720e-01, MSE(pi2): 4.309e-02, MSE(pi3): 4.173e-02\n",
      "Epoch 25900, Train loss: 7.159e+05, Test loss: 2.342e+07, MSE(e): 7.100e-02, MSE(pi1): 1.764e-01, MSE(pi2): 4.289e-02, MSE(pi3): 4.152e-02\n",
      "Epoch 26000, Train loss: 7.132e+05, Test loss: 2.345e+07, MSE(e): 7.073e-02, MSE(pi1): 1.706e-01, MSE(pi2): 4.271e-02, MSE(pi3): 4.150e-02\n",
      "Epoch 26100, Train loss: 7.114e+05, Test loss: 2.350e+07, MSE(e): 7.055e-02, MSE(pi1): 1.738e-01, MSE(pi2): 4.257e-02, MSE(pi3): 4.114e-02\n",
      "Epoch 26200, Train loss: 7.080e+05, Test loss: 2.349e+07, MSE(e): 7.021e-02, MSE(pi1): 1.699e-01, MSE(pi2): 4.235e-02, MSE(pi3): 4.129e-02\n",
      "Epoch 26300, Train loss: 7.055e+05, Test loss: 2.349e+07, MSE(e): 6.996e-02, MSE(pi1): 1.695e-01, MSE(pi2): 4.217e-02, MSE(pi3): 4.124e-02\n",
      "Epoch 26400, Train loss: 7.030e+05, Test loss: 2.354e+07, MSE(e): 6.972e-02, MSE(pi1): 1.688e-01, MSE(pi2): 4.200e-02, MSE(pi3): 4.105e-02\n",
      "Epoch 26500, Train loss: 7.005e+05, Test loss: 2.357e+07, MSE(e): 6.947e-02, MSE(pi1): 1.686e-01, MSE(pi2): 4.183e-02, MSE(pi3): 4.096e-02\n",
      "Epoch 26600, Train loss: 6.981e+05, Test loss: 2.359e+07, MSE(e): 6.923e-02, MSE(pi1): 1.682e-01, MSE(pi2): 4.167e-02, MSE(pi3): 4.080e-02\n",
      "Epoch 26700, Train loss: 6.969e+05, Test loss: 2.357e+07, MSE(e): 6.910e-02, MSE(pi1): 1.740e-01, MSE(pi2): 4.155e-02, MSE(pi3): 4.126e-02\n",
      "Epoch 26800, Train loss: 6.934e+05, Test loss: 2.363e+07, MSE(e): 6.876e-02, MSE(pi1): 1.675e-01, MSE(pi2): 4.134e-02, MSE(pi3): 4.058e-02\n",
      "Epoch 26900, Train loss: 6.911e+05, Test loss: 2.365e+07, MSE(e): 6.853e-02, MSE(pi1): 1.671e-01, MSE(pi2): 4.119e-02, MSE(pi3): 4.048e-02\n",
      "Epoch 27000, Train loss: 6.888e+05, Test loss: 2.369e+07, MSE(e): 6.830e-02, MSE(pi1): 1.677e-01, MSE(pi2): 4.103e-02, MSE(pi3): 4.035e-02\n",
      "Epoch 27100, Train loss: 6.866e+05, Test loss: 2.370e+07, MSE(e): 6.808e-02, MSE(pi1): 1.665e-01, MSE(pi2): 4.088e-02, MSE(pi3): 4.025e-02\n",
      "Epoch 27200, Train loss: 6.843e+05, Test loss: 2.373e+07, MSE(e): 6.786e-02, MSE(pi1): 1.662e-01, MSE(pi2): 4.073e-02, MSE(pi3): 4.013e-02\n",
      "Epoch 27300, Train loss: 6.822e+05, Test loss: 2.375e+07, MSE(e): 6.765e-02, MSE(pi1): 1.657e-01, MSE(pi2): 4.058e-02, MSE(pi3): 4.004e-02\n",
      "Epoch 27400, Train loss: 6.808e+05, Test loss: 2.380e+07, MSE(e): 6.751e-02, MSE(pi1): 1.690e-01, MSE(pi2): 4.047e-02, MSE(pi3): 3.978e-02\n",
      "Epoch 27500, Train loss: 6.779e+05, Test loss: 2.379e+07, MSE(e): 6.722e-02, MSE(pi1): 1.659e-01, MSE(pi2): 4.028e-02, MSE(pi3): 3.979e-02\n",
      "Epoch 27600, Train loss: 6.758e+05, Test loss: 2.382e+07, MSE(e): 6.701e-02, MSE(pi1): 1.654e-01, MSE(pi2): 4.014e-02, MSE(pi3): 3.966e-02\n",
      "Epoch 27700, Train loss: 6.738e+05, Test loss: 2.386e+07, MSE(e): 6.681e-02, MSE(pi1): 1.698e-01, MSE(pi2): 4.000e-02, MSE(pi3): 3.943e-02\n",
      "Epoch 27800, Train loss: 6.716e+05, Test loss: 2.386e+07, MSE(e): 6.659e-02, MSE(pi1): 1.643e-01, MSE(pi2): 3.985e-02, MSE(pi3): 3.952e-02\n",
      "Epoch 27900, Train loss: 6.695e+05, Test loss: 2.388e+07, MSE(e): 6.639e-02, MSE(pi1): 1.645e-01, MSE(pi2): 3.971e-02, MSE(pi3): 3.940e-02\n",
      "Epoch 28000, Train loss: 6.676e+05, Test loss: 2.393e+07, MSE(e): 6.620e-02, MSE(pi1): 1.646e-01, MSE(pi2): 3.959e-02, MSE(pi3): 3.921e-02\n",
      "Epoch 28100, Train loss: 6.655e+05, Test loss: 2.393e+07, MSE(e): 6.599e-02, MSE(pi1): 1.634e-01, MSE(pi2): 3.944e-02, MSE(pi3): 3.923e-02\n",
      "Epoch 28200, Train loss: 6.641e+05, Test loss: 2.391e+07, MSE(e): 6.585e-02, MSE(pi1): 1.628e-01, MSE(pi2): 3.933e-02, MSE(pi3): 3.936e-02\n",
      "Epoch 28300, Train loss: 6.615e+05, Test loss: 2.397e+07, MSE(e): 6.560e-02, MSE(pi1): 1.630e-01, MSE(pi2): 3.918e-02, MSE(pi3): 3.903e-02\n",
      "Epoch 28400, Train loss: 6.597e+05, Test loss: 2.397e+07, MSE(e): 6.541e-02, MSE(pi1): 1.621e-01, MSE(pi2): 3.905e-02, MSE(pi3): 3.904e-02\n",
      "Epoch 28500, Train loss: 6.576e+05, Test loss: 2.402e+07, MSE(e): 6.521e-02, MSE(pi1): 1.623e-01, MSE(pi2): 3.891e-02, MSE(pi3): 3.884e-02\n",
      "Epoch 28600, Train loss: 6.557e+05, Test loss: 2.404e+07, MSE(e): 6.502e-02, MSE(pi1): 1.621e-01, MSE(pi2): 3.878e-02, MSE(pi3): 3.874e-02\n",
      "Epoch 28700, Train loss: 6.538e+05, Test loss: 2.408e+07, MSE(e): 6.483e-02, MSE(pi1): 1.623e-01, MSE(pi2): 3.865e-02, MSE(pi3): 3.858e-02\n",
      "Epoch 28800, Train loss: 6.519e+05, Test loss: 2.409e+07, MSE(e): 6.464e-02, MSE(pi1): 1.640e-01, MSE(pi2): 3.852e-02, MSE(pi3): 3.856e-02\n",
      "Epoch 28900, Train loss: 6.500e+05, Test loss: 2.412e+07, MSE(e): 6.446e-02, MSE(pi1): 1.617e-01, MSE(pi2): 3.840e-02, MSE(pi3): 3.841e-02\n",
      "Epoch 29000, Train loss: 6.481e+05, Test loss: 2.414e+07, MSE(e): 6.426e-02, MSE(pi1): 1.614e-01, MSE(pi2): 3.827e-02, MSE(pi3): 3.836e-02\n",
      "Epoch 29100, Train loss: 6.463e+05, Test loss: 2.417e+07, MSE(e): 6.408e-02, MSE(pi1): 1.610e-01, MSE(pi2): 3.815e-02, MSE(pi3): 3.825e-02\n",
      "Epoch 29200, Train loss: 6.444e+05, Test loss: 2.419e+07, MSE(e): 6.389e-02, MSE(pi1): 1.606e-01, MSE(pi2): 3.802e-02, MSE(pi3): 3.819e-02\n",
      "Epoch 29300, Train loss: 6.426e+05, Test loss: 2.421e+07, MSE(e): 6.371e-02, MSE(pi1): 1.603e-01, MSE(pi2): 3.790e-02, MSE(pi3): 3.809e-02\n",
      "Epoch 29400, Train loss: 6.408e+05, Test loss: 2.424e+07, MSE(e): 6.353e-02, MSE(pi1): 1.601e-01, MSE(pi2): 3.778e-02, MSE(pi3): 3.801e-02\n",
      "Epoch 29500, Train loss: 6.390e+05, Test loss: 2.426e+07, MSE(e): 6.335e-02, MSE(pi1): 1.597e-01, MSE(pi2): 3.765e-02, MSE(pi3): 3.793e-02\n",
      "Epoch 29600, Train loss: 6.372e+05, Test loss: 2.429e+07, MSE(e): 6.318e-02, MSE(pi1): 1.595e-01, MSE(pi2): 3.754e-02, MSE(pi3): 3.783e-02\n",
      "Epoch 29700, Train loss: 6.364e+05, Test loss: 2.428e+07, MSE(e): 6.310e-02, MSE(pi1): 1.608e-01, MSE(pi2): 3.746e-02, MSE(pi3): 3.809e-02\n",
      "Epoch 29800, Train loss: 6.336e+05, Test loss: 2.434e+07, MSE(e): 6.282e-02, MSE(pi1): 1.600e-01, MSE(pi2): 3.730e-02, MSE(pi3): 3.761e-02\n",
      "Epoch 29900, Train loss: 6.318e+05, Test loss: 2.437e+07, MSE(e): 6.264e-02, MSE(pi1): 1.588e-01, MSE(pi2): 3.718e-02, MSE(pi3): 3.756e-02\n",
      "Epoch 30000, Train loss: 6.300e+05, Test loss: 2.440e+07, MSE(e): 6.246e-02, MSE(pi1): 1.586e-01, MSE(pi2): 3.706e-02, MSE(pi3): 3.747e-02\n",
      "Epoch 30100, Train loss: 6.282e+05, Test loss: 2.443e+07, MSE(e): 6.229e-02, MSE(pi1): 1.585e-01, MSE(pi2): 3.694e-02, MSE(pi3): 3.738e-02\n",
      "Epoch 30200, Train loss: 6.266e+05, Test loss: 2.443e+07, MSE(e): 6.213e-02, MSE(pi1): 1.576e-01, MSE(pi2): 3.683e-02, MSE(pi3): 3.741e-02\n",
      "Epoch 30300, Train loss: 6.247e+05, Test loss: 2.449e+07, MSE(e): 6.194e-02, MSE(pi1): 1.580e-01, MSE(pi2): 3.671e-02, MSE(pi3): 3.720e-02\n",
      "Epoch 30400, Train loss: 6.230e+05, Test loss: 2.452e+07, MSE(e): 6.177e-02, MSE(pi1): 1.577e-01, MSE(pi2): 3.659e-02, MSE(pi3): 3.713e-02\n",
      "Epoch 30500, Train loss: 6.212e+05, Test loss: 2.455e+07, MSE(e): 6.159e-02, MSE(pi1): 1.575e-01, MSE(pi2): 3.647e-02, MSE(pi3): 3.704e-02\n",
      "Epoch 30600, Train loss: 6.196e+05, Test loss: 2.460e+07, MSE(e): 6.143e-02, MSE(pi1): 1.581e-01, MSE(pi2): 3.636e-02, MSE(pi3): 3.684e-02\n",
      "Epoch 30700, Train loss: 6.178e+05, Test loss: 2.461e+07, MSE(e): 6.125e-02, MSE(pi1): 1.571e-01, MSE(pi2): 3.624e-02, MSE(pi3): 3.686e-02\n",
      "Epoch 30800, Train loss: 6.160e+05, Test loss: 2.465e+07, MSE(e): 6.108e-02, MSE(pi1): 1.567e-01, MSE(pi2): 3.613e-02, MSE(pi3): 3.679e-02\n",
      "Epoch 30900, Train loss: 6.147e+05, Test loss: 2.472e+07, MSE(e): 6.094e-02, MSE(pi1): 1.583e-01, MSE(pi2): 3.603e-02, MSE(pi3): 3.650e-02\n",
      "Epoch 31000, Train loss: 6.126e+05, Test loss: 2.471e+07, MSE(e): 6.073e-02, MSE(pi1): 1.608e-01, MSE(pi2): 3.590e-02, MSE(pi3): 3.657e-02\n",
      "Epoch 31100, Train loss: 6.114e+05, Test loss: 2.478e+07, MSE(e): 6.061e-02, MSE(pi1): 1.580e-01, MSE(pi2): 3.581e-02, MSE(pi3): 3.636e-02\n",
      "Epoch 31200, Train loss: 6.093e+05, Test loss: 2.478e+07, MSE(e): 6.040e-02, MSE(pi1): 1.574e-01, MSE(pi2): 3.568e-02, MSE(pi3): 3.646e-02\n",
      "Epoch 31300, Train loss: 6.076e+05, Test loss: 2.481e+07, MSE(e): 6.023e-02, MSE(pi1): 1.622e-01, MSE(pi2): 3.556e-02, MSE(pi3): 3.622e-02\n",
      "Epoch 31400, Train loss: 6.058e+05, Test loss: 2.485e+07, MSE(e): 6.006e-02, MSE(pi1): 1.556e-01, MSE(pi2): 3.545e-02, MSE(pi3): 3.625e-02\n",
      "Epoch 31500, Train loss: 6.041e+05, Test loss: 2.489e+07, MSE(e): 5.989e-02, MSE(pi1): 1.570e-01, MSE(pi2): 3.534e-02, MSE(pi3): 3.609e-02\n",
      "Epoch 31600, Train loss: 6.024e+05, Test loss: 2.493e+07, MSE(e): 5.972e-02, MSE(pi1): 1.557e-01, MSE(pi2): 3.523e-02, MSE(pi3): 3.603e-02\n",
      "Epoch 31700, Train loss: 6.007e+05, Test loss: 2.496e+07, MSE(e): 5.955e-02, MSE(pi1): 1.556e-01, MSE(pi2): 3.511e-02, MSE(pi3): 3.607e-02\n",
      "Epoch 31800, Train loss: 5.990e+05, Test loss: 2.500e+07, MSE(e): 5.939e-02, MSE(pi1): 1.548e-01, MSE(pi2): 3.500e-02, MSE(pi3): 3.590e-02\n",
      "Epoch 31900, Train loss: 5.974e+05, Test loss: 2.504e+07, MSE(e): 5.922e-02, MSE(pi1): 1.543e-01, MSE(pi2): 3.489e-02, MSE(pi3): 3.589e-02\n",
      "Epoch 32000, Train loss: 5.957e+05, Test loss: 2.508e+07, MSE(e): 5.906e-02, MSE(pi1): 1.544e-01, MSE(pi2): 3.478e-02, MSE(pi3): 3.573e-02\n",
      "Epoch 32100, Train loss: 5.941e+05, Test loss: 2.513e+07, MSE(e): 5.890e-02, MSE(pi1): 1.551e-01, MSE(pi2): 3.468e-02, MSE(pi3): 3.555e-02\n",
      "Epoch 32200, Train loss: 5.924e+05, Test loss: 2.516e+07, MSE(e): 5.872e-02, MSE(pi1): 1.540e-01, MSE(pi2): 3.457e-02, MSE(pi3): 3.556e-02\n",
      "Epoch 32300, Train loss: 5.907e+05, Test loss: 2.520e+07, MSE(e): 5.856e-02, MSE(pi1): 1.538e-01, MSE(pi2): 3.446e-02, MSE(pi3): 3.548e-02\n",
      "Epoch 32400, Train loss: 5.891e+05, Test loss: 2.524e+07, MSE(e): 5.839e-02, MSE(pi1): 1.540e-01, MSE(pi2): 3.435e-02, MSE(pi3): 3.540e-02\n",
      "Epoch 32500, Train loss: 5.874e+05, Test loss: 2.528e+07, MSE(e): 5.823e-02, MSE(pi1): 1.545e-01, MSE(pi2): 3.424e-02, MSE(pi3): 3.539e-02\n",
      "Epoch 32600, Train loss: 5.857e+05, Test loss: 2.533e+07, MSE(e): 5.807e-02, MSE(pi1): 1.539e-01, MSE(pi2): 3.413e-02, MSE(pi3): 3.516e-02\n",
      "Epoch 32700, Train loss: 5.843e+05, Test loss: 2.534e+07, MSE(e): 5.793e-02, MSE(pi1): 1.528e-01, MSE(pi2): 3.403e-02, MSE(pi3): 3.525e-02\n",
      "Epoch 32800, Train loss: 5.824e+05, Test loss: 2.541e+07, MSE(e): 5.773e-02, MSE(pi1): 1.539e-01, MSE(pi2): 3.391e-02, MSE(pi3): 3.499e-02\n",
      "Epoch 32900, Train loss: 5.808e+05, Test loss: 2.546e+07, MSE(e): 5.757e-02, MSE(pi1): 1.527e-01, MSE(pi2): 3.381e-02, MSE(pi3): 3.497e-02\n",
      "Epoch 33000, Train loss: 5.792e+05, Test loss: 2.552e+07, MSE(e): 5.742e-02, MSE(pi1): 1.532e-01, MSE(pi2): 3.371e-02, MSE(pi3): 3.482e-02\n",
      "Epoch 33100, Train loss: 5.775e+05, Test loss: 2.555e+07, MSE(e): 5.724e-02, MSE(pi1): 1.524e-01, MSE(pi2): 3.359e-02, MSE(pi3): 3.479e-02\n",
      "Epoch 33200, Train loss: 5.759e+05, Test loss: 2.560e+07, MSE(e): 5.708e-02, MSE(pi1): 1.523e-01, MSE(pi2): 3.349e-02, MSE(pi3): 3.469e-02\n",
      "Epoch 33300, Train loss: 5.743e+05, Test loss: 2.564e+07, MSE(e): 5.692e-02, MSE(pi1): 1.523e-01, MSE(pi2): 3.339e-02, MSE(pi3): 3.460e-02\n",
      "Epoch 33400, Train loss: 5.726e+05, Test loss: 2.570e+07, MSE(e): 5.676e-02, MSE(pi1): 1.520e-01, MSE(pi2): 3.328e-02, MSE(pi3): 3.451e-02\n",
      "Epoch 33500, Train loss: 5.710e+05, Test loss: 2.573e+07, MSE(e): 5.660e-02, MSE(pi1): 1.520e-01, MSE(pi2): 3.317e-02, MSE(pi3): 3.447e-02\n",
      "Epoch 33600, Train loss: 5.694e+05, Test loss: 2.579e+07, MSE(e): 5.644e-02, MSE(pi1): 1.516e-01, MSE(pi2): 3.307e-02, MSE(pi3): 3.436e-02\n",
      "Epoch 33700, Train loss: 5.685e+05, Test loss: 2.589e+07, MSE(e): 5.635e-02, MSE(pi1): 1.533e-01, MSE(pi2): 3.301e-02, MSE(pi3): 3.410e-02\n",
      "Epoch 33800, Train loss: 5.661e+05, Test loss: 2.589e+07, MSE(e): 5.612e-02, MSE(pi1): 1.512e-01, MSE(pi2): 3.286e-02, MSE(pi3): 3.420e-02\n",
      "Epoch 33900, Train loss: 5.647e+05, Test loss: 2.596e+07, MSE(e): 5.597e-02, MSE(pi1): 1.518e-01, MSE(pi2): 3.277e-02, MSE(pi3): 3.405e-02\n",
      "Epoch 34000, Train loss: 5.629e+05, Test loss: 2.599e+07, MSE(e): 5.580e-02, MSE(pi1): 1.509e-01, MSE(pi2): 3.265e-02, MSE(pi3): 3.404e-02\n",
      "Epoch 34100, Train loss: 5.613e+05, Test loss: 2.604e+07, MSE(e): 5.564e-02, MSE(pi1): 1.529e-01, MSE(pi2): 3.255e-02, MSE(pi3): 3.387e-02\n",
      "Epoch 34200, Train loss: 5.597e+05, Test loss: 2.609e+07, MSE(e): 5.548e-02, MSE(pi1): 1.514e-01, MSE(pi2): 3.245e-02, MSE(pi3): 3.386e-02\n",
      "Epoch 34300, Train loss: 5.581e+05, Test loss: 2.615e+07, MSE(e): 5.532e-02, MSE(pi1): 1.504e-01, MSE(pi2): 3.235e-02, MSE(pi3): 3.379e-02\n",
      "Epoch 34400, Train loss: 5.565e+05, Test loss: 2.620e+07, MSE(e): 5.516e-02, MSE(pi1): 1.502e-01, MSE(pi2): 3.225e-02, MSE(pi3): 3.375e-02\n",
      "Epoch 34500, Train loss: 5.549e+05, Test loss: 2.626e+07, MSE(e): 5.500e-02, MSE(pi1): 1.504e-01, MSE(pi2): 3.214e-02, MSE(pi3): 3.359e-02\n",
      "Epoch 34600, Train loss: 5.533e+05, Test loss: 2.631e+07, MSE(e): 5.485e-02, MSE(pi1): 1.500e-01, MSE(pi2): 3.204e-02, MSE(pi3): 3.353e-02\n",
      "Epoch 34700, Train loss: 5.518e+05, Test loss: 2.637e+07, MSE(e): 5.469e-02, MSE(pi1): 1.501e-01, MSE(pi2): 3.194e-02, MSE(pi3): 3.344e-02\n",
      "Epoch 34800, Train loss: 5.505e+05, Test loss: 2.639e+07, MSE(e): 5.456e-02, MSE(pi1): 1.496e-01, MSE(pi2): 3.186e-02, MSE(pi3): 3.362e-02\n",
      "Epoch 34900, Train loss: 5.486e+05, Test loss: 2.648e+07, MSE(e): 5.437e-02, MSE(pi1): 1.494e-01, MSE(pi2): 3.174e-02, MSE(pi3): 3.330e-02\n",
      "Epoch 35000, Train loss: 5.470e+05, Test loss: 2.653e+07, MSE(e): 5.422e-02, MSE(pi1): 1.501e-01, MSE(pi2): 3.164e-02, MSE(pi3): 3.320e-02\n",
      "Epoch 35100, Train loss: 5.462e+05, Test loss: 2.656e+07, MSE(e): 5.413e-02, MSE(pi1): 1.498e-01, MSE(pi2): 3.158e-02, MSE(pi3): 3.339e-02\n",
      "Epoch 35200, Train loss: 5.439e+05, Test loss: 2.665e+07, MSE(e): 5.391e-02, MSE(pi1): 1.490e-01, MSE(pi2): 3.145e-02, MSE(pi3): 3.306e-02\n",
      "Epoch 35300, Train loss: 5.423e+05, Test loss: 2.671e+07, MSE(e): 5.375e-02, MSE(pi1): 1.487e-01, MSE(pi2): 3.135e-02, MSE(pi3): 3.302e-02\n",
      "Epoch 35400, Train loss: 5.408e+05, Test loss: 2.678e+07, MSE(e): 5.360e-02, MSE(pi1): 1.486e-01, MSE(pi2): 3.125e-02, MSE(pi3): 3.295e-02\n",
      "Epoch 35500, Train loss: 5.393e+05, Test loss: 2.683e+07, MSE(e): 5.344e-02, MSE(pi1): 1.494e-01, MSE(pi2): 3.115e-02, MSE(pi3): 3.294e-02\n",
      "Epoch 35600, Train loss: 5.377e+05, Test loss: 2.690e+07, MSE(e): 5.330e-02, MSE(pi1): 1.489e-01, MSE(pi2): 3.106e-02, MSE(pi3): 3.269e-02\n",
      "Epoch 35700, Train loss: 5.362e+05, Test loss: 2.695e+07, MSE(e): 5.314e-02, MSE(pi1): 1.553e-01, MSE(pi2): 3.096e-02, MSE(pi3): 3.252e-02\n",
      "Epoch 35800, Train loss: 5.352e+05, Test loss: 2.706e+07, MSE(e): 5.304e-02, MSE(pi1): 1.495e-01, MSE(pi2): 3.090e-02, MSE(pi3): 3.243e-02\n",
      "Epoch 35900, Train loss: 5.331e+05, Test loss: 2.707e+07, MSE(e): 5.284e-02, MSE(pi1): 1.480e-01, MSE(pi2): 3.077e-02, MSE(pi3): 3.251e-02\n",
      "Epoch 36000, Train loss: 5.317e+05, Test loss: 2.715e+07, MSE(e): 5.270e-02, MSE(pi1): 1.486e-01, MSE(pi2): 3.068e-02, MSE(pi3): 3.235e-02\n",
      "Epoch 36100, Train loss: 5.301e+05, Test loss: 2.720e+07, MSE(e): 5.253e-02, MSE(pi1): 1.477e-01, MSE(pi2): 3.058e-02, MSE(pi3): 3.236e-02\n",
      "Epoch 36200, Train loss: 5.286e+05, Test loss: 2.727e+07, MSE(e): 5.238e-02, MSE(pi1): 1.503e-01, MSE(pi2): 3.049e-02, MSE(pi3): 3.243e-02\n",
      "Epoch 36300, Train loss: 5.271e+05, Test loss: 2.731e+07, MSE(e): 5.223e-02, MSE(pi1): 1.486e-01, MSE(pi2): 3.039e-02, MSE(pi3): 3.216e-02\n",
      "Epoch 36400, Train loss: 5.256e+05, Test loss: 2.739e+07, MSE(e): 5.209e-02, MSE(pi1): 1.485e-01, MSE(pi2): 3.030e-02, MSE(pi3): 3.207e-02\n",
      "Epoch 36500, Train loss: 5.241e+05, Test loss: 2.745e+07, MSE(e): 5.194e-02, MSE(pi1): 1.471e-01, MSE(pi2): 3.021e-02, MSE(pi3): 3.206e-02\n",
      "Epoch 36600, Train loss: 5.226e+05, Test loss: 2.752e+07, MSE(e): 5.179e-02, MSE(pi1): 1.469e-01, MSE(pi2): 3.011e-02, MSE(pi3): 3.199e-02\n",
      "Epoch 36700, Train loss: 5.211e+05, Test loss: 2.757e+07, MSE(e): 5.164e-02, MSE(pi1): 1.469e-01, MSE(pi2): 3.002e-02, MSE(pi3): 3.194e-02\n",
      "Epoch 36800, Train loss: 5.196e+05, Test loss: 2.766e+07, MSE(e): 5.149e-02, MSE(pi1): 1.483e-01, MSE(pi2): 2.993e-02, MSE(pi3): 3.176e-02\n",
      "Epoch 36900, Train loss: 5.181e+05, Test loss: 2.773e+07, MSE(e): 5.134e-02, MSE(pi1): 1.467e-01, MSE(pi2): 2.984e-02, MSE(pi3): 3.175e-02\n",
      "Epoch 37000, Train loss: 5.166e+05, Test loss: 2.781e+07, MSE(e): 5.119e-02, MSE(pi1): 1.473e-01, MSE(pi2): 2.975e-02, MSE(pi3): 3.167e-02\n",
      "Epoch 37100, Train loss: 5.151e+05, Test loss: 2.786e+07, MSE(e): 5.105e-02, MSE(pi1): 1.463e-01, MSE(pi2): 2.966e-02, MSE(pi3): 3.163e-02\n",
      "Epoch 37200, Train loss: 5.137e+05, Test loss: 2.793e+07, MSE(e): 5.090e-02, MSE(pi1): 1.461e-01, MSE(pi2): 2.957e-02, MSE(pi3): 3.157e-02\n",
      "Epoch 37300, Train loss: 5.122e+05, Test loss: 2.800e+07, MSE(e): 5.075e-02, MSE(pi1): 1.462e-01, MSE(pi2): 2.947e-02, MSE(pi3): 3.146e-02\n",
      "Epoch 37400, Train loss: 5.107e+05, Test loss: 2.807e+07, MSE(e): 5.061e-02, MSE(pi1): 1.459e-01, MSE(pi2): 2.939e-02, MSE(pi3): 3.139e-02\n",
      "Epoch 37500, Train loss: 5.093e+05, Test loss: 2.812e+07, MSE(e): 5.047e-02, MSE(pi1): 1.457e-01, MSE(pi2): 2.930e-02, MSE(pi3): 3.137e-02\n",
      "Epoch 37600, Train loss: 5.078e+05, Test loss: 2.820e+07, MSE(e): 5.032e-02, MSE(pi1): 1.457e-01, MSE(pi2): 2.921e-02, MSE(pi3): 3.126e-02\n",
      "Epoch 37700, Train loss: 5.063e+05, Test loss: 2.828e+07, MSE(e): 5.017e-02, MSE(pi1): 1.455e-01, MSE(pi2): 2.912e-02, MSE(pi3): 3.118e-02\n",
      "Epoch 37800, Train loss: 5.049e+05, Test loss: 2.835e+07, MSE(e): 5.003e-02, MSE(pi1): 1.456e-01, MSE(pi2): 2.903e-02, MSE(pi3): 3.108e-02\n",
      "Epoch 37900, Train loss: 5.035e+05, Test loss: 2.845e+07, MSE(e): 4.989e-02, MSE(pi1): 1.458e-01, MSE(pi2): 2.895e-02, MSE(pi3): 3.096e-02\n",
      "Epoch 38000, Train loss: 5.020e+05, Test loss: 2.850e+07, MSE(e): 4.974e-02, MSE(pi1): 1.463e-01, MSE(pi2): 2.885e-02, MSE(pi3): 3.095e-02\n",
      "Epoch 38100, Train loss: 5.006e+05, Test loss: 2.857e+07, MSE(e): 4.960e-02, MSE(pi1): 1.452e-01, MSE(pi2): 2.877e-02, MSE(pi3): 3.088e-02\n",
      "Epoch 38200, Train loss: 4.991e+05, Test loss: 2.864e+07, MSE(e): 4.946e-02, MSE(pi1): 1.460e-01, MSE(pi2): 2.868e-02, MSE(pi3): 3.079e-02\n",
      "Epoch 38300, Train loss: 4.977e+05, Test loss: 2.871e+07, MSE(e): 4.932e-02, MSE(pi1): 1.449e-01, MSE(pi2): 2.859e-02, MSE(pi3): 3.074e-02\n",
      "Epoch 38400, Train loss: 4.964e+05, Test loss: 2.876e+07, MSE(e): 4.919e-02, MSE(pi1): 1.450e-01, MSE(pi2): 2.851e-02, MSE(pi3): 3.081e-02\n",
      "Epoch 38500, Train loss: 4.949e+05, Test loss: 2.886e+07, MSE(e): 4.904e-02, MSE(pi1): 1.447e-01, MSE(pi2): 2.842e-02, MSE(pi3): 3.060e-02\n",
      "Epoch 38600, Train loss: 4.935e+05, Test loss: 2.892e+07, MSE(e): 4.890e-02, MSE(pi1): 1.447e-01, MSE(pi2): 2.834e-02, MSE(pi3): 3.055e-02\n",
      "Epoch 38700, Train loss: 4.922e+05, Test loss: 2.901e+07, MSE(e): 4.876e-02, MSE(pi1): 1.513e-01, MSE(pi2): 2.826e-02, MSE(pi3): 3.068e-02\n",
      "Epoch 38800, Train loss: 4.912e+05, Test loss: 2.904e+07, MSE(e): 4.867e-02, MSE(pi1): 1.441e-01, MSE(pi2): 2.820e-02, MSE(pi3): 3.055e-02\n",
      "Epoch 38900, Train loss: 4.893e+05, Test loss: 2.916e+07, MSE(e): 4.848e-02, MSE(pi1): 1.442e-01, MSE(pi2): 2.809e-02, MSE(pi3): 3.034e-02\n",
      "Epoch 39000, Train loss: 4.879e+05, Test loss: 2.923e+07, MSE(e): 4.834e-02, MSE(pi1): 1.442e-01, MSE(pi2): 2.800e-02, MSE(pi3): 3.027e-02\n",
      "Epoch 39100, Train loss: 4.866e+05, Test loss: 2.930e+07, MSE(e): 4.821e-02, MSE(pi1): 1.439e-01, MSE(pi2): 2.792e-02, MSE(pi3): 3.019e-02\n",
      "Epoch 39200, Train loss: 4.852e+05, Test loss: 2.937e+07, MSE(e): 4.807e-02, MSE(pi1): 1.437e-01, MSE(pi2): 2.784e-02, MSE(pi3): 3.016e-02\n",
      "Epoch 39300, Train loss: 4.838e+05, Test loss: 2.946e+07, MSE(e): 4.793e-02, MSE(pi1): 1.448e-01, MSE(pi2): 2.776e-02, MSE(pi3): 3.002e-02\n",
      "Epoch 39400, Train loss: 4.824e+05, Test loss: 2.952e+07, MSE(e): 4.779e-02, MSE(pi1): 1.445e-01, MSE(pi2): 2.767e-02, MSE(pi3): 2.999e-02\n",
      "Epoch 39500, Train loss: 4.811e+05, Test loss: 2.963e+07, MSE(e): 4.767e-02, MSE(pi1): 1.445e-01, MSE(pi2): 2.760e-02, MSE(pi3): 2.993e-02\n",
      "Epoch 39600, Train loss: 4.798e+05, Test loss: 2.969e+07, MSE(e): 4.752e-02, MSE(pi1): 1.557e-01, MSE(pi2): 2.751e-02, MSE(pi3): 2.961e-02\n",
      "Epoch 39700, Train loss: 4.783e+05, Test loss: 2.977e+07, MSE(e): 4.738e-02, MSE(pi1): 1.433e-01, MSE(pi2): 2.742e-02, MSE(pi3): 2.978e-02\n",
      "Epoch 39800, Train loss: 4.770e+05, Test loss: 2.984e+07, MSE(e): 4.725e-02, MSE(pi1): 1.510e-01, MSE(pi2): 2.734e-02, MSE(pi3): 2.958e-02\n",
      "Epoch 39900, Train loss: 4.755e+05, Test loss: 2.993e+07, MSE(e): 4.711e-02, MSE(pi1): 1.435e-01, MSE(pi2): 2.726e-02, MSE(pi3): 2.964e-02\n",
      "Epoch 40000, Train loss: 4.742e+05, Test loss: 2.999e+07, MSE(e): 4.698e-02, MSE(pi1): 1.431e-01, MSE(pi2): 2.718e-02, MSE(pi3): 2.958e-02\n",
      "Epoch 40100, Train loss: 4.728e+05, Test loss: 3.007e+07, MSE(e): 4.684e-02, MSE(pi1): 1.429e-01, MSE(pi2): 2.710e-02, MSE(pi3): 2.953e-02\n",
      "Epoch 40200, Train loss: 4.716e+05, Test loss: 3.016e+07, MSE(e): 4.672e-02, MSE(pi1): 1.431e-01, MSE(pi2): 2.703e-02, MSE(pi3): 2.941e-02\n",
      "Epoch 40300, Train loss: 4.702e+05, Test loss: 3.023e+07, MSE(e): 4.658e-02, MSE(pi1): 1.449e-01, MSE(pi2): 2.694e-02, MSE(pi3): 2.930e-02\n",
      "Epoch 40400, Train loss: 4.688e+05, Test loss: 3.031e+07, MSE(e): 4.645e-02, MSE(pi1): 1.425e-01, MSE(pi2): 2.687e-02, MSE(pi3): 2.933e-02\n",
      "Epoch 40500, Train loss: 4.675e+05, Test loss: 3.038e+07, MSE(e): 4.631e-02, MSE(pi1): 1.426e-01, MSE(pi2): 2.679e-02, MSE(pi3): 2.927e-02\n",
      "Epoch 40600, Train loss: 4.665e+05, Test loss: 3.050e+07, MSE(e): 4.621e-02, MSE(pi1): 1.433e-01, MSE(pi2): 2.672e-02, MSE(pi3): 2.910e-02\n",
      "Epoch 40700, Train loss: 4.649e+05, Test loss: 3.054e+07, MSE(e): 4.605e-02, MSE(pi1): 1.423e-01, MSE(pi2): 2.663e-02, MSE(pi3): 2.913e-02\n",
      "Epoch 40800, Train loss: 4.636e+05, Test loss: 3.062e+07, MSE(e): 4.592e-02, MSE(pi1): 1.420e-01, MSE(pi2): 2.655e-02, MSE(pi3): 2.909e-02\n",
      "Epoch 40900, Train loss: 4.623e+05, Test loss: 3.069e+07, MSE(e): 4.579e-02, MSE(pi1): 1.420e-01, MSE(pi2): 2.647e-02, MSE(pi3): 2.901e-02\n",
      "Epoch 41000, Train loss: 4.610e+05, Test loss: 3.077e+07, MSE(e): 4.566e-02, MSE(pi1): 1.418e-01, MSE(pi2): 2.640e-02, MSE(pi3): 2.895e-02\n",
      "Epoch 41100, Train loss: 4.597e+05, Test loss: 3.085e+07, MSE(e): 4.553e-02, MSE(pi1): 1.414e-01, MSE(pi2): 2.632e-02, MSE(pi3): 2.894e-02\n",
      "Epoch 41200, Train loss: 4.584e+05, Test loss: 3.094e+07, MSE(e): 4.541e-02, MSE(pi1): 1.419e-01, MSE(pi2): 2.625e-02, MSE(pi3): 2.878e-02\n",
      "Epoch 41300, Train loss: 4.571e+05, Test loss: 3.100e+07, MSE(e): 4.528e-02, MSE(pi1): 1.436e-01, MSE(pi2): 2.617e-02, MSE(pi3): 2.879e-02\n",
      "Epoch 41400, Train loss: 4.558e+05, Test loss: 3.108e+07, MSE(e): 4.515e-02, MSE(pi1): 1.413e-01, MSE(pi2): 2.609e-02, MSE(pi3): 2.871e-02\n",
      "Epoch 41500, Train loss: 4.545e+05, Test loss: 3.116e+07, MSE(e): 4.502e-02, MSE(pi1): 1.415e-01, MSE(pi2): 2.602e-02, MSE(pi3): 2.862e-02\n",
      "Epoch 41600, Train loss: 4.538e+05, Test loss: 3.118e+07, MSE(e): 4.495e-02, MSE(pi1): 1.406e-01, MSE(pi2): 2.597e-02, MSE(pi3): 2.875e-02\n",
      "Epoch 41700, Train loss: 4.526e+05, Test loss: 3.137e+07, MSE(e): 4.483e-02, MSE(pi1): 1.429e-01, MSE(pi2): 2.590e-02, MSE(pi3): 2.844e-02\n",
      "Epoch 41800, Train loss: 4.507e+05, Test loss: 3.139e+07, MSE(e): 4.464e-02, MSE(pi1): 1.411e-01, MSE(pi2): 2.579e-02, MSE(pi3): 2.844e-02\n",
      "Epoch 41900, Train loss: 4.495e+05, Test loss: 3.147e+07, MSE(e): 4.452e-02, MSE(pi1): 1.413e-01, MSE(pi2): 2.572e-02, MSE(pi3): 2.841e-02\n",
      "Epoch 42000, Train loss: 4.491e+05, Test loss: 3.160e+07, MSE(e): 4.448e-02, MSE(pi1): 1.424e-01, MSE(pi2): 2.570e-02, MSE(pi3): 2.821e-02\n",
      "Epoch 42100, Train loss: 4.470e+05, Test loss: 3.162e+07, MSE(e): 4.427e-02, MSE(pi1): 1.404e-01, MSE(pi2): 2.557e-02, MSE(pi3): 2.829e-02\n",
      "Epoch 42200, Train loss: 4.457e+05, Test loss: 3.169e+07, MSE(e): 4.415e-02, MSE(pi1): 1.403e-01, MSE(pi2): 2.550e-02, MSE(pi3): 2.823e-02\n",
      "Epoch 42300, Train loss: 4.445e+05, Test loss: 3.177e+07, MSE(e): 4.402e-02, MSE(pi1): 1.404e-01, MSE(pi2): 2.543e-02, MSE(pi3): 2.816e-02\n",
      "Epoch 42400, Train loss: 4.433e+05, Test loss: 3.185e+07, MSE(e): 4.390e-02, MSE(pi1): 1.456e-01, MSE(pi2): 2.536e-02, MSE(pi3): 2.807e-02\n",
      "Epoch 42500, Train loss: 4.420e+05, Test loss: 3.192e+07, MSE(e): 4.378e-02, MSE(pi1): 1.399e-01, MSE(pi2): 2.528e-02, MSE(pi3): 2.806e-02\n",
      "Epoch 42600, Train loss: 4.408e+05, Test loss: 3.200e+07, MSE(e): 4.366e-02, MSE(pi1): 1.400e-01, MSE(pi2): 2.521e-02, MSE(pi3): 2.800e-02\n",
      "Epoch 42700, Train loss: 4.396e+05, Test loss: 3.207e+07, MSE(e): 4.354e-02, MSE(pi1): 1.397e-01, MSE(pi2): 2.514e-02, MSE(pi3): 2.794e-02\n",
      "Epoch 42800, Train loss: 4.384e+05, Test loss: 3.215e+07, MSE(e): 4.342e-02, MSE(pi1): 1.395e-01, MSE(pi2): 2.507e-02, MSE(pi3): 2.789e-02\n",
      "Epoch 42900, Train loss: 4.372e+05, Test loss: 3.223e+07, MSE(e): 4.330e-02, MSE(pi1): 1.395e-01, MSE(pi2): 2.500e-02, MSE(pi3): 2.782e-02\n",
      "Epoch 43000, Train loss: 4.360e+05, Test loss: 3.229e+07, MSE(e): 4.318e-02, MSE(pi1): 1.392e-01, MSE(pi2): 2.493e-02, MSE(pi3): 2.780e-02\n",
      "Epoch 43100, Train loss: 4.349e+05, Test loss: 3.236e+07, MSE(e): 4.306e-02, MSE(pi1): 1.426e-01, MSE(pi2): 2.486e-02, MSE(pi3): 2.765e-02\n",
      "Epoch 43200, Train loss: 4.336e+05, Test loss: 3.244e+07, MSE(e): 4.295e-02, MSE(pi1): 1.392e-01, MSE(pi2): 2.480e-02, MSE(pi3): 2.766e-02\n",
      "Epoch 43300, Train loss: 4.328e+05, Test loss: 3.249e+07, MSE(e): 4.286e-02, MSE(pi1): 1.386e-01, MSE(pi2): 2.474e-02, MSE(pi3): 2.776e-02\n",
      "Epoch 43400, Train loss: 4.313e+05, Test loss: 3.258e+07, MSE(e): 4.272e-02, MSE(pi1): 1.388e-01, MSE(pi2): 2.466e-02, MSE(pi3): 2.755e-02\n",
      "Epoch 43500, Train loss: 4.302e+05, Test loss: 3.265e+07, MSE(e): 4.260e-02, MSE(pi1): 1.387e-01, MSE(pi2): 2.459e-02, MSE(pi3): 2.749e-02\n",
      "Epoch 43600, Train loss: 4.290e+05, Test loss: 3.273e+07, MSE(e): 4.249e-02, MSE(pi1): 1.386e-01, MSE(pi2): 2.452e-02, MSE(pi3): 2.744e-02\n",
      "Epoch 43700, Train loss: 4.278e+05, Test loss: 3.280e+07, MSE(e): 4.237e-02, MSE(pi1): 1.386e-01, MSE(pi2): 2.446e-02, MSE(pi3): 2.738e-02\n",
      "Epoch 43800, Train loss: 4.267e+05, Test loss: 3.287e+07, MSE(e): 4.226e-02, MSE(pi1): 1.382e-01, MSE(pi2): 2.439e-02, MSE(pi3): 2.734e-02\n",
      "Epoch 43900, Train loss: 4.256e+05, Test loss: 3.294e+07, MSE(e): 4.214e-02, MSE(pi1): 1.382e-01, MSE(pi2): 2.433e-02, MSE(pi3): 2.728e-02\n",
      "Epoch 44000, Train loss: 4.244e+05, Test loss: 3.301e+07, MSE(e): 4.203e-02, MSE(pi1): 1.379e-01, MSE(pi2): 2.426e-02, MSE(pi3): 2.724e-02\n",
      "Epoch 44100, Train loss: 4.235e+05, Test loss: 3.310e+07, MSE(e): 4.193e-02, MSE(pi1): 1.498e-01, MSE(pi2): 2.420e-02, MSE(pi3): 2.690e-02\n",
      "Epoch 44200, Train loss: 4.222e+05, Test loss: 3.315e+07, MSE(e): 4.180e-02, MSE(pi1): 1.377e-01, MSE(pi2): 2.413e-02, MSE(pi3): 2.712e-02\n",
      "Epoch 44300, Train loss: 4.210e+05, Test loss: 3.322e+07, MSE(e): 4.169e-02, MSE(pi1): 1.375e-01, MSE(pi2): 2.406e-02, MSE(pi3): 2.708e-02\n",
      "Epoch 44400, Train loss: 4.199e+05, Test loss: 3.330e+07, MSE(e): 4.158e-02, MSE(pi1): 1.377e-01, MSE(pi2): 2.400e-02, MSE(pi3): 2.699e-02\n",
      "Epoch 44500, Train loss: 4.188e+05, Test loss: 3.335e+07, MSE(e): 4.147e-02, MSE(pi1): 1.380e-01, MSE(pi2): 2.393e-02, MSE(pi3): 2.700e-02\n",
      "Epoch 44600, Train loss: 4.177e+05, Test loss: 3.341e+07, MSE(e): 4.136e-02, MSE(pi1): 1.371e-01, MSE(pi2): 2.387e-02, MSE(pi3): 2.693e-02\n",
      "Epoch 44700, Train loss: 4.166e+05, Test loss: 3.347e+07, MSE(e): 4.125e-02, MSE(pi1): 1.368e-01, MSE(pi2): 2.380e-02, MSE(pi3): 2.691e-02\n",
      "Epoch 44800, Train loss: 4.155e+05, Test loss: 3.356e+07, MSE(e): 4.114e-02, MSE(pi1): 1.373e-01, MSE(pi2): 2.374e-02, MSE(pi3): 2.678e-02\n",
      "Epoch 44900, Train loss: 4.147e+05, Test loss: 3.365e+07, MSE(e): 4.106e-02, MSE(pi1): 1.379e-01, MSE(pi2): 2.369e-02, MSE(pi3): 2.665e-02\n",
      "Epoch 45000, Train loss: 4.133e+05, Test loss: 3.369e+07, MSE(e): 4.093e-02, MSE(pi1): 1.367e-01, MSE(pi2): 2.361e-02, MSE(pi3): 2.670e-02\n",
      "Epoch 45100, Train loss: 4.140e+05, Test loss: 3.386e+07, MSE(e): 4.100e-02, MSE(pi1): 1.392e-01, MSE(pi2): 2.365e-02, MSE(pi3): 2.649e-02\n",
      "Epoch 45200, Train loss: 4.112e+05, Test loss: 3.382e+07, MSE(e): 4.071e-02, MSE(pi1): 1.364e-01, MSE(pi2): 2.349e-02, MSE(pi3): 2.660e-02\n",
      "Epoch 45300, Train loss: 4.111e+05, Test loss: 3.395e+07, MSE(e): 4.070e-02, MSE(pi1): 1.389e-01, MSE(pi2): 2.348e-02, MSE(pi3): 2.646e-02\n",
      "Epoch 45400, Train loss: 4.090e+05, Test loss: 3.395e+07, MSE(e): 4.050e-02, MSE(pi1): 1.361e-01, MSE(pi2): 2.336e-02, MSE(pi3): 2.650e-02\n",
      "Epoch 45500, Train loss: 4.080e+05, Test loss: 3.402e+07, MSE(e): 4.040e-02, MSE(pi1): 1.359e-01, MSE(pi2): 2.330e-02, MSE(pi3): 2.645e-02\n",
      "Epoch 45600, Train loss: 4.069e+05, Test loss: 3.407e+07, MSE(e): 4.029e-02, MSE(pi1): 1.357e-01, MSE(pi2): 2.324e-02, MSE(pi3): 2.644e-02\n",
      "Epoch 45700, Train loss: 4.065e+05, Test loss: 3.408e+07, MSE(e): 4.025e-02, MSE(pi1): 1.350e-01, MSE(pi2): 2.321e-02, MSE(pi3): 2.653e-02\n",
      "Epoch 45800, Train loss: 4.049e+05, Test loss: 3.419e+07, MSE(e): 4.009e-02, MSE(pi1): 1.353e-01, MSE(pi2): 2.312e-02, MSE(pi3): 2.634e-02\n",
      "Epoch 45900, Train loss: 4.038e+05, Test loss: 3.427e+07, MSE(e): 3.998e-02, MSE(pi1): 1.357e-01, MSE(pi2): 2.306e-02, MSE(pi3): 2.622e-02\n",
      "Epoch 46000, Train loss: 4.028e+05, Test loss: 3.434e+07, MSE(e): 3.988e-02, MSE(pi1): 1.352e-01, MSE(pi2): 2.300e-02, MSE(pi3): 2.620e-02\n",
      "Epoch 46100, Train loss: 4.022e+05, Test loss: 3.444e+07, MSE(e): 3.982e-02, MSE(pi1): 1.364e-01, MSE(pi2): 2.296e-02, MSE(pi3): 2.602e-02\n",
      "Epoch 46200, Train loss: 4.014e+05, Test loss: 3.453e+07, MSE(e): 3.974e-02, MSE(pi1): 1.420e-01, MSE(pi2): 2.292e-02, MSE(pi3): 2.607e-02\n",
      "Epoch 46300, Train loss: 3.997e+05, Test loss: 3.451e+07, MSE(e): 3.957e-02, MSE(pi1): 1.350e-01, MSE(pi2): 2.282e-02, MSE(pi3): 2.604e-02\n",
      "Epoch 46400, Train loss: 3.987e+05, Test loss: 3.457e+07, MSE(e): 3.947e-02, MSE(pi1): 1.346e-01, MSE(pi2): 2.276e-02, MSE(pi3): 2.600e-02\n",
      "Epoch 46500, Train loss: 3.982e+05, Test loss: 3.467e+07, MSE(e): 3.942e-02, MSE(pi1): 1.392e-01, MSE(pi2): 2.273e-02, MSE(pi3): 2.600e-02\n",
      "Epoch 46600, Train loss: 3.967e+05, Test loss: 3.469e+07, MSE(e): 3.927e-02, MSE(pi1): 1.342e-01, MSE(pi2): 2.265e-02, MSE(pi3): 2.591e-02\n",
      "Epoch 46700, Train loss: 3.958e+05, Test loss: 3.474e+07, MSE(e): 3.918e-02, MSE(pi1): 1.355e-01, MSE(pi2): 2.259e-02, MSE(pi3): 2.589e-02\n",
      "Epoch 46800, Train loss: 3.947e+05, Test loss: 3.481e+07, MSE(e): 3.908e-02, MSE(pi1): 1.339e-01, MSE(pi2): 2.253e-02, MSE(pi3): 2.582e-02\n",
      "Epoch 46900, Train loss: 3.938e+05, Test loss: 3.487e+07, MSE(e): 3.898e-02, MSE(pi1): 1.340e-01, MSE(pi2): 2.248e-02, MSE(pi3): 2.574e-02\n",
      "Epoch 47000, Train loss: 3.928e+05, Test loss: 3.492e+07, MSE(e): 3.889e-02, MSE(pi1): 1.337e-01, MSE(pi2): 2.242e-02, MSE(pi3): 2.571e-02\n",
      "Epoch 47100, Train loss: 3.918e+05, Test loss: 3.498e+07, MSE(e): 3.879e-02, MSE(pi1): 1.334e-01, MSE(pi2): 2.236e-02, MSE(pi3): 2.568e-02\n",
      "Epoch 47200, Train loss: 3.911e+05, Test loss: 3.509e+07, MSE(e): 3.872e-02, MSE(pi1): 1.367e-01, MSE(pi2): 2.232e-02, MSE(pi3): 2.547e-02\n",
      "Epoch 47300, Train loss: 3.899e+05, Test loss: 3.508e+07, MSE(e): 3.860e-02, MSE(pi1): 1.336e-01, MSE(pi2): 2.226e-02, MSE(pi3): 2.555e-02\n",
      "Epoch 47400, Train loss: 3.890e+05, Test loss: 3.514e+07, MSE(e): 3.851e-02, MSE(pi1): 1.329e-01, MSE(pi2): 2.220e-02, MSE(pi3): 2.555e-02\n",
      "Epoch 47500, Train loss: 3.881e+05, Test loss: 3.519e+07, MSE(e): 3.842e-02, MSE(pi1): 1.327e-01, MSE(pi2): 2.215e-02, MSE(pi3): 2.550e-02\n",
      "Epoch 47600, Train loss: 3.872e+05, Test loss: 3.526e+07, MSE(e): 3.833e-02, MSE(pi1): 1.333e-01, MSE(pi2): 2.210e-02, MSE(pi3): 2.537e-02\n",
      "Epoch 47700, Train loss: 3.862e+05, Test loss: 3.530e+07, MSE(e): 3.823e-02, MSE(pi1): 1.324e-01, MSE(pi2): 2.204e-02, MSE(pi3): 2.540e-02\n",
      "Epoch 47800, Train loss: 3.853e+05, Test loss: 3.534e+07, MSE(e): 3.814e-02, MSE(pi1): 1.319e-01, MSE(pi2): 2.199e-02, MSE(pi3): 2.542e-02\n",
      "Epoch 47900, Train loss: 3.844e+05, Test loss: 3.540e+07, MSE(e): 3.805e-02, MSE(pi1): 1.320e-01, MSE(pi2): 2.193e-02, MSE(pi3): 2.532e-02\n",
      "Epoch 48000, Train loss: 3.835e+05, Test loss: 3.544e+07, MSE(e): 3.796e-02, MSE(pi1): 1.318e-01, MSE(pi2): 2.188e-02, MSE(pi3): 2.528e-02\n",
      "Epoch 48100, Train loss: 3.826e+05, Test loss: 3.550e+07, MSE(e): 3.787e-02, MSE(pi1): 1.317e-01, MSE(pi2): 2.183e-02, MSE(pi3): 2.524e-02\n",
      "Epoch 48200, Train loss: 3.819e+05, Test loss: 3.550e+07, MSE(e): 3.780e-02, MSE(pi1): 1.375e-01, MSE(pi2): 2.178e-02, MSE(pi3): 2.515e-02\n",
      "Epoch 48300, Train loss: 3.808e+05, Test loss: 3.559e+07, MSE(e): 3.769e-02, MSE(pi1): 1.313e-01, MSE(pi2): 2.173e-02, MSE(pi3): 2.513e-02\n",
      "Epoch 48400, Train loss: 3.799e+05, Test loss: 3.564e+07, MSE(e): 3.761e-02, MSE(pi1): 1.313e-01, MSE(pi2): 2.167e-02, MSE(pi3): 2.508e-02\n",
      "Epoch 48500, Train loss: 3.790e+05, Test loss: 3.569e+07, MSE(e): 3.752e-02, MSE(pi1): 1.325e-01, MSE(pi2): 2.162e-02, MSE(pi3): 2.499e-02\n",
      "Epoch 48600, Train loss: 3.782e+05, Test loss: 3.574e+07, MSE(e): 3.743e-02, MSE(pi1): 1.307e-01, MSE(pi2): 2.157e-02, MSE(pi3): 2.501e-02\n",
      "Epoch 48700, Train loss: 3.773e+05, Test loss: 3.579e+07, MSE(e): 3.735e-02, MSE(pi1): 1.306e-01, MSE(pi2): 2.152e-02, MSE(pi3): 2.496e-02\n",
      "Epoch 48800, Train loss: 3.764e+05, Test loss: 3.581e+07, MSE(e): 3.726e-02, MSE(pi1): 1.311e-01, MSE(pi2): 2.147e-02, MSE(pi3): 2.492e-02\n",
      "Epoch 48900, Train loss: 3.757e+05, Test loss: 3.584e+07, MSE(e): 3.718e-02, MSE(pi1): 1.307e-01, MSE(pi2): 2.143e-02, MSE(pi3): 2.504e-02\n",
      "Epoch 49000, Train loss: 3.747e+05, Test loss: 3.592e+07, MSE(e): 3.709e-02, MSE(pi1): 1.300e-01, MSE(pi2): 2.137e-02, MSE(pi3): 2.484e-02\n",
      "Epoch 49100, Train loss: 3.738e+05, Test loss: 3.596e+07, MSE(e): 3.700e-02, MSE(pi1): 1.305e-01, MSE(pi2): 2.132e-02, MSE(pi3): 2.490e-02\n",
      "Epoch 49200, Train loss: 3.730e+05, Test loss: 3.602e+07, MSE(e): 3.692e-02, MSE(pi1): 1.300e-01, MSE(pi2): 2.127e-02, MSE(pi3): 2.480e-02\n",
      "Epoch 49300, Train loss: 3.727e+05, Test loss: 3.599e+07, MSE(e): 3.688e-02, MSE(pi1): 1.362e-01, MSE(pi2): 2.125e-02, MSE(pi3): 2.503e-02\n",
      "Epoch 49400, Train loss: 3.713e+05, Test loss: 3.608e+07, MSE(e): 3.675e-02, MSE(pi1): 1.309e-01, MSE(pi2): 2.117e-02, MSE(pi3): 2.460e-02\n",
      "Epoch 49500, Train loss: 3.705e+05, Test loss: 3.613e+07, MSE(e): 3.667e-02, MSE(pi1): 1.292e-01, MSE(pi2): 2.113e-02, MSE(pi3): 2.460e-02\n",
      "Epoch 49600, Train loss: 3.696e+05, Test loss: 3.616e+07, MSE(e): 3.658e-02, MSE(pi1): 1.290e-01, MSE(pi2): 2.108e-02, MSE(pi3): 2.458e-02\n",
      "Epoch 49700, Train loss: 3.688e+05, Test loss: 3.621e+07, MSE(e): 3.650e-02, MSE(pi1): 1.299e-01, MSE(pi2): 2.103e-02, MSE(pi3): 2.448e-02\n",
      "Epoch 49800, Train loss: 3.680e+05, Test loss: 3.625e+07, MSE(e): 3.642e-02, MSE(pi1): 1.286e-01, MSE(pi2): 2.098e-02, MSE(pi3): 2.451e-02\n",
      "Epoch 49900, Train loss: 3.672e+05, Test loss: 3.627e+07, MSE(e): 3.634e-02, MSE(pi1): 1.307e-01, MSE(pi2): 2.094e-02, MSE(pi3): 2.463e-02\n",
      "Epoch 50000, Train loss: 3.663e+05, Test loss: 3.632e+07, MSE(e): 3.626e-02, MSE(pi1): 1.281e-01, MSE(pi2): 2.089e-02, MSE(pi3): 2.442e-02\n",
      "Epoch 50100, Train loss: 3.655e+05, Test loss: 3.635e+07, MSE(e): 3.618e-02, MSE(pi1): 1.277e-01, MSE(pi2): 2.084e-02, MSE(pi3): 2.441e-02\n",
      "Epoch 50200, Train loss: 3.647e+05, Test loss: 3.639e+07, MSE(e): 3.610e-02, MSE(pi1): 1.277e-01, MSE(pi2): 2.079e-02, MSE(pi3): 2.433e-02\n",
      "Epoch 50300, Train loss: 3.639e+05, Test loss: 3.643e+07, MSE(e): 3.602e-02, MSE(pi1): 1.274e-01, MSE(pi2): 2.075e-02, MSE(pi3): 2.431e-02\n",
      "Epoch 50400, Train loss: 3.632e+05, Test loss: 3.646e+07, MSE(e): 3.594e-02, MSE(pi1): 1.309e-01, MSE(pi2): 2.070e-02, MSE(pi3): 2.414e-02\n",
      "Epoch 50500, Train loss: 3.624e+05, Test loss: 3.650e+07, MSE(e): 3.587e-02, MSE(pi1): 1.277e-01, MSE(pi2): 2.066e-02, MSE(pi3): 2.425e-02\n",
      "Epoch 50600, Train loss: 3.616e+05, Test loss: 3.653e+07, MSE(e): 3.579e-02, MSE(pi1): 1.268e-01, MSE(pi2): 2.061e-02, MSE(pi3): 2.421e-02\n",
      "Epoch 50700, Train loss: 3.608e+05, Test loss: 3.656e+07, MSE(e): 3.571e-02, MSE(pi1): 1.268e-01, MSE(pi2): 2.057e-02, MSE(pi3): 2.413e-02\n",
      "Epoch 50800, Train loss: 3.601e+05, Test loss: 3.655e+07, MSE(e): 3.564e-02, MSE(pi1): 1.262e-01, MSE(pi2): 2.053e-02, MSE(pi3): 2.417e-02\n",
      "Epoch 50900, Train loss: 3.593e+05, Test loss: 3.662e+07, MSE(e): 3.556e-02, MSE(pi1): 1.284e-01, MSE(pi2): 2.048e-02, MSE(pi3): 2.398e-02\n",
      "Epoch 51000, Train loss: 3.585e+05, Test loss: 3.665e+07, MSE(e): 3.548e-02, MSE(pi1): 1.263e-01, MSE(pi2): 2.043e-02, MSE(pi3): 2.401e-02\n",
      "Epoch 51100, Train loss: 3.579e+05, Test loss: 3.666e+07, MSE(e): 3.542e-02, MSE(pi1): 1.258e-01, MSE(pi2): 2.040e-02, MSE(pi3): 2.413e-02\n",
      "Epoch 51200, Train loss: 3.571e+05, Test loss: 3.673e+07, MSE(e): 3.534e-02, MSE(pi1): 1.270e-01, MSE(pi2): 2.035e-02, MSE(pi3): 2.392e-02\n",
      "Epoch 51300, Train loss: 3.563e+05, Test loss: 3.677e+07, MSE(e): 3.526e-02, MSE(pi1): 1.273e-01, MSE(pi2): 2.030e-02, MSE(pi3): 2.383e-02\n",
      "Epoch 51400, Train loss: 3.555e+05, Test loss: 3.677e+07, MSE(e): 3.518e-02, MSE(pi1): 1.253e-01, MSE(pi2): 2.026e-02, MSE(pi3): 2.386e-02\n",
      "Epoch 51500, Train loss: 3.547e+05, Test loss: 3.679e+07, MSE(e): 3.511e-02, MSE(pi1): 1.251e-01, MSE(pi2): 2.021e-02, MSE(pi3): 2.383e-02\n",
      "Epoch 51600, Train loss: 3.547e+05, Test loss: 3.686e+07, MSE(e): 3.510e-02, MSE(pi1): 1.287e-01, MSE(pi2): 2.021e-02, MSE(pi3): 2.371e-02\n",
      "Epoch 51700, Train loss: 3.533e+05, Test loss: 3.685e+07, MSE(e): 3.496e-02, MSE(pi1): 1.253e-01, MSE(pi2): 2.013e-02, MSE(pi3): 2.385e-02\n",
      "Epoch 51800, Train loss: 3.526e+05, Test loss: 3.685e+07, MSE(e): 3.489e-02, MSE(pi1): 1.259e-01, MSE(pi2): 2.009e-02, MSE(pi3): 2.382e-02\n",
      "Epoch 51900, Train loss: 3.518e+05, Test loss: 3.689e+07, MSE(e): 3.482e-02, MSE(pi1): 1.266e-01, MSE(pi2): 2.004e-02, MSE(pi3): 2.359e-02\n",
      "Epoch 52000, Train loss: 3.511e+05, Test loss: 3.692e+07, MSE(e): 3.475e-02, MSE(pi1): 1.240e-01, MSE(pi2): 2.000e-02, MSE(pi3): 2.365e-02\n",
      "Epoch 52100, Train loss: 3.504e+05, Test loss: 3.695e+07, MSE(e): 3.468e-02, MSE(pi1): 1.251e-01, MSE(pi2): 1.996e-02, MSE(pi3): 2.352e-02\n",
      "Epoch 52200, Train loss: 3.496e+05, Test loss: 3.696e+07, MSE(e): 3.460e-02, MSE(pi1): 1.238e-01, MSE(pi2): 1.992e-02, MSE(pi3): 2.355e-02\n",
      "Epoch 52300, Train loss: 3.489e+05, Test loss: 3.698e+07, MSE(e): 3.453e-02, MSE(pi1): 1.241e-01, MSE(pi2): 1.988e-02, MSE(pi3): 2.349e-02\n",
      "Epoch 52400, Train loss: 3.483e+05, Test loss: 3.704e+07, MSE(e): 3.447e-02, MSE(pi1): 1.249e-01, MSE(pi2): 1.984e-02, MSE(pi3): 2.355e-02\n",
      "Epoch 52500, Train loss: 3.476e+05, Test loss: 3.701e+07, MSE(e): 3.440e-02, MSE(pi1): 1.235e-01, MSE(pi2): 1.980e-02, MSE(pi3): 2.359e-02\n",
      "Epoch 52600, Train loss: 3.473e+05, Test loss: 3.698e+07, MSE(e): 3.437e-02, MSE(pi1): 1.241e-01, MSE(pi2): 1.978e-02, MSE(pi3): 2.357e-02\n",
      "Epoch 52700, Train loss: 3.461e+05, Test loss: 3.706e+07, MSE(e): 3.425e-02, MSE(pi1): 1.226e-01, MSE(pi2): 1.971e-02, MSE(pi3): 2.340e-02\n",
      "Epoch 52800, Train loss: 3.454e+05, Test loss: 3.708e+07, MSE(e): 3.418e-02, MSE(pi1): 1.227e-01, MSE(pi2): 1.967e-02, MSE(pi3): 2.341e-02\n",
      "Epoch 52900, Train loss: 3.447e+05, Test loss: 3.710e+07, MSE(e): 3.411e-02, MSE(pi1): 1.223e-01, MSE(pi2): 1.963e-02, MSE(pi3): 2.331e-02\n",
      "Epoch 53000, Train loss: 3.442e+05, Test loss: 3.707e+07, MSE(e): 3.407e-02, MSE(pi1): 1.222e-01, MSE(pi2): 1.960e-02, MSE(pi3): 2.334e-02\n",
      "Epoch 53100, Train loss: 3.433e+05, Test loss: 3.713e+07, MSE(e): 3.398e-02, MSE(pi1): 1.219e-01, MSE(pi2): 1.955e-02, MSE(pi3): 2.322e-02\n",
      "Epoch 53200, Train loss: 3.437e+05, Test loss: 3.707e+07, MSE(e): 3.401e-02, MSE(pi1): 1.214e-01, MSE(pi2): 1.957e-02, MSE(pi3): 2.343e-02\n",
      "Epoch 53300, Train loss: 3.420e+05, Test loss: 3.716e+07, MSE(e): 3.384e-02, MSE(pi1): 1.215e-01, MSE(pi2): 1.947e-02, MSE(pi3): 2.315e-02\n",
      "Epoch 53400, Train loss: 3.413e+05, Test loss: 3.718e+07, MSE(e): 3.377e-02, MSE(pi1): 1.212e-01, MSE(pi2): 1.943e-02, MSE(pi3): 2.313e-02\n",
      "Epoch 53500, Train loss: 3.406e+05, Test loss: 3.720e+07, MSE(e): 3.371e-02, MSE(pi1): 1.211e-01, MSE(pi2): 1.939e-02, MSE(pi3): 2.308e-02\n",
      "Epoch 53600, Train loss: 3.399e+05, Test loss: 3.721e+07, MSE(e): 3.364e-02, MSE(pi1): 1.215e-01, MSE(pi2): 1.935e-02, MSE(pi3): 2.300e-02\n",
      "Epoch 53700, Train loss: 3.392e+05, Test loss: 3.721e+07, MSE(e): 3.357e-02, MSE(pi1): 1.207e-01, MSE(pi2): 1.931e-02, MSE(pi3): 2.301e-02\n",
      "Epoch 53800, Train loss: 3.386e+05, Test loss: 3.724e+07, MSE(e): 3.351e-02, MSE(pi1): 1.229e-01, MSE(pi2): 1.928e-02, MSE(pi3): 2.313e-02\n",
      "Epoch 53900, Train loss: 3.379e+05, Test loss: 3.723e+07, MSE(e): 3.344e-02, MSE(pi1): 1.208e-01, MSE(pi2): 1.924e-02, MSE(pi3): 2.293e-02\n",
      "Epoch 54000, Train loss: 3.381e+05, Test loss: 3.717e+07, MSE(e): 3.344e-02, MSE(pi1): 1.387e-01, MSE(pi2): 1.924e-02, MSE(pi3): 2.285e-02\n",
      "Epoch 54100, Train loss: 3.366e+05, Test loss: 3.726e+07, MSE(e): 3.331e-02, MSE(pi1): 1.199e-01, MSE(pi2): 1.916e-02, MSE(pi3): 2.286e-02\n",
      "Epoch 54200, Train loss: 3.359e+05, Test loss: 3.727e+07, MSE(e): 3.324e-02, MSE(pi1): 1.197e-01, MSE(pi2): 1.912e-02, MSE(pi3): 2.283e-02\n",
      "Epoch 54300, Train loss: 3.353e+05, Test loss: 3.726e+07, MSE(e): 3.318e-02, MSE(pi1): 1.207e-01, MSE(pi2): 1.908e-02, MSE(pi3): 2.276e-02\n",
      "Epoch 54400, Train loss: 3.346e+05, Test loss: 3.729e+07, MSE(e): 3.311e-02, MSE(pi1): 1.193e-01, MSE(pi2): 1.904e-02, MSE(pi3): 2.275e-02\n",
      "Epoch 54500, Train loss: 3.339e+05, Test loss: 3.730e+07, MSE(e): 3.305e-02, MSE(pi1): 1.192e-01, MSE(pi2): 1.901e-02, MSE(pi3): 2.271e-02\n",
      "Epoch 54600, Train loss: 3.341e+05, Test loss: 3.739e+07, MSE(e): 3.306e-02, MSE(pi1): 1.218e-01, MSE(pi2): 1.901e-02, MSE(pi3): 2.259e-02\n",
      "Epoch 54700, Train loss: 3.326e+05, Test loss: 3.731e+07, MSE(e): 3.292e-02, MSE(pi1): 1.185e-01, MSE(pi2): 1.893e-02, MSE(pi3): 2.270e-02\n",
      "Epoch 54800, Train loss: 3.320e+05, Test loss: 3.732e+07, MSE(e): 3.285e-02, MSE(pi1): 1.185e-01, MSE(pi2): 1.889e-02, MSE(pi3): 2.262e-02\n",
      "Epoch 54900, Train loss: 3.314e+05, Test loss: 3.732e+07, MSE(e): 3.279e-02, MSE(pi1): 1.182e-01, MSE(pi2): 1.886e-02, MSE(pi3): 2.263e-02\n",
      "Epoch 55000, Train loss: 3.308e+05, Test loss: 3.736e+07, MSE(e): 3.274e-02, MSE(pi1): 1.187e-01, MSE(pi2): 1.883e-02, MSE(pi3): 2.247e-02\n",
      "Epoch 55100, Train loss: 3.301e+05, Test loss: 3.734e+07, MSE(e): 3.266e-02, MSE(pi1): 1.190e-01, MSE(pi2): 1.878e-02, MSE(pi3): 2.245e-02\n",
      "Epoch 55200, Train loss: 3.294e+05, Test loss: 3.734e+07, MSE(e): 3.260e-02, MSE(pi1): 1.178e-01, MSE(pi2): 1.874e-02, MSE(pi3): 2.247e-02\n",
      "Epoch 55300, Train loss: 3.288e+05, Test loss: 3.733e+07, MSE(e): 3.254e-02, MSE(pi1): 1.180e-01, MSE(pi2): 1.871e-02, MSE(pi3): 2.244e-02\n",
      "Epoch 55400, Train loss: 3.282e+05, Test loss: 3.735e+07, MSE(e): 3.247e-02, MSE(pi1): 1.186e-01, MSE(pi2): 1.867e-02, MSE(pi3): 2.256e-02\n",
      "Epoch 55500, Train loss: 3.275e+05, Test loss: 3.735e+07, MSE(e): 3.241e-02, MSE(pi1): 1.170e-01, MSE(pi2): 1.863e-02, MSE(pi3): 2.239e-02\n",
      "Epoch 55600, Train loss: 3.269e+05, Test loss: 3.736e+07, MSE(e): 3.235e-02, MSE(pi1): 1.169e-01, MSE(pi2): 1.860e-02, MSE(pi3): 2.234e-02\n",
      "Epoch 55700, Train loss: 3.280e+05, Test loss: 3.748e+07, MSE(e): 3.245e-02, MSE(pi1): 1.210e-01, MSE(pi2): 1.866e-02, MSE(pi3): 2.223e-02\n",
      "Epoch 55800, Train loss: 3.257e+05, Test loss: 3.736e+07, MSE(e): 3.223e-02, MSE(pi1): 1.165e-01, MSE(pi2): 1.853e-02, MSE(pi3): 2.227e-02\n",
      "Epoch 55900, Train loss: 3.251e+05, Test loss: 3.736e+07, MSE(e): 3.216e-02, MSE(pi1): 1.165e-01, MSE(pi2): 1.849e-02, MSE(pi3): 2.222e-02\n",
      "Epoch 56000, Train loss: 3.244e+05, Test loss: 3.736e+07, MSE(e): 3.210e-02, MSE(pi1): 1.163e-01, MSE(pi2): 1.846e-02, MSE(pi3): 2.220e-02\n",
      "Epoch 56100, Train loss: 3.238e+05, Test loss: 3.736e+07, MSE(e): 3.204e-02, MSE(pi1): 1.159e-01, MSE(pi2): 1.842e-02, MSE(pi3): 2.217e-02\n",
      "Epoch 56200, Train loss: 3.232e+05, Test loss: 3.736e+07, MSE(e): 3.198e-02, MSE(pi1): 1.157e-01, MSE(pi2): 1.838e-02, MSE(pi3): 2.214e-02\n",
      "Epoch 56300, Train loss: 3.226e+05, Test loss: 3.736e+07, MSE(e): 3.192e-02, MSE(pi1): 1.154e-01, MSE(pi2): 1.835e-02, MSE(pi3): 2.214e-02\n",
      "Epoch 56400, Train loss: 3.220e+05, Test loss: 3.736e+07, MSE(e): 3.186e-02, MSE(pi1): 1.153e-01, MSE(pi2): 1.831e-02, MSE(pi3): 2.208e-02\n",
      "Epoch 56500, Train loss: 3.214e+05, Test loss: 3.733e+07, MSE(e): 3.180e-02, MSE(pi1): 1.157e-01, MSE(pi2): 1.828e-02, MSE(pi3): 2.203e-02\n",
      "Epoch 56600, Train loss: 3.208e+05, Test loss: 3.735e+07, MSE(e): 3.174e-02, MSE(pi1): 1.149e-01, MSE(pi2): 1.824e-02, MSE(pi3): 2.202e-02\n",
      "Epoch 56700, Train loss: 3.202e+05, Test loss: 3.735e+07, MSE(e): 3.168e-02, MSE(pi1): 1.151e-01, MSE(pi2): 1.821e-02, MSE(pi3): 2.195e-02\n",
      "Epoch 56800, Train loss: 3.199e+05, Test loss: 3.732e+07, MSE(e): 3.165e-02, MSE(pi1): 1.164e-01, MSE(pi2): 1.819e-02, MSE(pi3): 2.204e-02\n",
      "Epoch 56900, Train loss: 3.190e+05, Test loss: 3.735e+07, MSE(e): 3.156e-02, MSE(pi1): 1.145e-01, MSE(pi2): 1.814e-02, MSE(pi3): 2.192e-02\n",
      "Epoch 57000, Train loss: 3.184e+05, Test loss: 3.734e+07, MSE(e): 3.150e-02, MSE(pi1): 1.141e-01, MSE(pi2): 1.810e-02, MSE(pi3): 2.189e-02\n",
      "Epoch 57100, Train loss: 3.178e+05, Test loss: 3.733e+07, MSE(e): 3.144e-02, MSE(pi1): 1.141e-01, MSE(pi2): 1.807e-02, MSE(pi3): 2.184e-02\n",
      "Epoch 57200, Train loss: 3.172e+05, Test loss: 3.735e+07, MSE(e): 3.138e-02, MSE(pi1): 1.160e-01, MSE(pi2): 1.803e-02, MSE(pi3): 2.196e-02\n",
      "Epoch 57300, Train loss: 3.170e+05, Test loss: 3.737e+07, MSE(e): 3.137e-02, MSE(pi1): 1.154e-01, MSE(pi2): 1.803e-02, MSE(pi3): 2.173e-02\n",
      "Epoch 57400, Train loss: 3.160e+05, Test loss: 3.733e+07, MSE(e): 3.127e-02, MSE(pi1): 1.134e-01, MSE(pi2): 1.797e-02, MSE(pi3): 2.174e-02\n",
      "Epoch 57500, Train loss: 3.154e+05, Test loss: 3.732e+07, MSE(e): 3.121e-02, MSE(pi1): 1.132e-01, MSE(pi2): 1.793e-02, MSE(pi3): 2.171e-02\n",
      "Epoch 57600, Train loss: 3.148e+05, Test loss: 3.732e+07, MSE(e): 3.115e-02, MSE(pi1): 1.131e-01, MSE(pi2): 1.790e-02, MSE(pi3): 2.167e-02\n",
      "Epoch 57700, Train loss: 3.146e+05, Test loss: 3.734e+07, MSE(e): 3.113e-02, MSE(pi1): 1.145e-01, MSE(pi2): 1.788e-02, MSE(pi3): 2.157e-02\n",
      "Epoch 57800, Train loss: 3.137e+05, Test loss: 3.730e+07, MSE(e): 3.103e-02, MSE(pi1): 1.148e-01, MSE(pi2): 1.783e-02, MSE(pi3): 2.153e-02\n",
      "Epoch 57900, Train loss: 3.131e+05, Test loss: 3.732e+07, MSE(e): 3.098e-02, MSE(pi1): 1.127e-01, MSE(pi2): 1.780e-02, MSE(pi3): 2.155e-02\n",
      "Epoch 58000, Train loss: 3.127e+05, Test loss: 3.726e+07, MSE(e): 3.094e-02, MSE(pi1): 1.122e-01, MSE(pi2): 1.777e-02, MSE(pi3): 2.171e-02\n",
      "Epoch 58100, Train loss: 3.119e+05, Test loss: 3.730e+07, MSE(e): 3.086e-02, MSE(pi1): 1.122e-01, MSE(pi2): 1.773e-02, MSE(pi3): 2.150e-02\n",
      "Epoch 58200, Train loss: 3.113e+05, Test loss: 3.729e+07, MSE(e): 3.080e-02, MSE(pi1): 1.143e-01, MSE(pi2): 1.770e-02, MSE(pi3): 2.156e-02\n",
      "Epoch 58300, Train loss: 3.110e+05, Test loss: 3.730e+07, MSE(e): 3.077e-02, MSE(pi1): 1.146e-01, MSE(pi2): 1.768e-02, MSE(pi3): 2.137e-02\n",
      "Epoch 58400, Train loss: 3.102e+05, Test loss: 3.727e+07, MSE(e): 3.069e-02, MSE(pi1): 1.118e-01, MSE(pi2): 1.763e-02, MSE(pi3): 2.150e-02\n",
      "Epoch 58500, Train loss: 3.096e+05, Test loss: 3.724e+07, MSE(e): 3.063e-02, MSE(pi1): 1.124e-01, MSE(pi2): 1.760e-02, MSE(pi3): 2.138e-02\n",
      "Epoch 58600, Train loss: 3.090e+05, Test loss: 3.725e+07, MSE(e): 3.057e-02, MSE(pi1): 1.110e-01, MSE(pi2): 1.756e-02, MSE(pi3): 2.138e-02\n",
      "Epoch 58700, Train loss: 3.084e+05, Test loss: 3.723e+07, MSE(e): 3.052e-02, MSE(pi1): 1.110e-01, MSE(pi2): 1.753e-02, MSE(pi3): 2.134e-02\n",
      "Epoch 58800, Train loss: 3.079e+05, Test loss: 3.724e+07, MSE(e): 3.046e-02, MSE(pi1): 1.109e-01, MSE(pi2): 1.750e-02, MSE(pi3): 2.132e-02\n",
      "Epoch 58900, Train loss: 3.073e+05, Test loss: 3.722e+07, MSE(e): 3.041e-02, MSE(pi1): 1.106e-01, MSE(pi2): 1.746e-02, MSE(pi3): 2.128e-02\n",
      "Epoch 59000, Train loss: 3.067e+05, Test loss: 3.723e+07, MSE(e): 3.035e-02, MSE(pi1): 1.107e-01, MSE(pi2): 1.743e-02, MSE(pi3): 2.125e-02\n",
      "Epoch 59100, Train loss: 3.062e+05, Test loss: 3.721e+07, MSE(e): 3.029e-02, MSE(pi1): 1.102e-01, MSE(pi2): 1.740e-02, MSE(pi3): 2.121e-02\n",
      "Epoch 59200, Train loss: 3.056e+05, Test loss: 3.720e+07, MSE(e): 3.024e-02, MSE(pi1): 1.104e-01, MSE(pi2): 1.737e-02, MSE(pi3): 2.116e-02\n",
      "Epoch 59300, Train loss: 3.075e+05, Test loss: 3.708e+07, MSE(e): 3.042e-02, MSE(pi1): 1.173e-01, MSE(pi2): 1.746e-02, MSE(pi3): 2.183e-02\n",
      "Epoch 59400, Train loss: 3.045e+05, Test loss: 3.718e+07, MSE(e): 3.013e-02, MSE(pi1): 1.097e-01, MSE(pi2): 1.730e-02, MSE(pi3): 2.112e-02\n",
      "Epoch 59500, Train loss: 3.039e+05, Test loss: 3.716e+07, MSE(e): 3.007e-02, MSE(pi1): 1.102e-01, MSE(pi2): 1.727e-02, MSE(pi3): 2.106e-02\n",
      "Epoch 59600, Train loss: 3.034e+05, Test loss: 3.716e+07, MSE(e): 3.001e-02, MSE(pi1): 1.093e-01, MSE(pi2): 1.724e-02, MSE(pi3): 2.106e-02\n",
      "Epoch 59700, Train loss: 3.028e+05, Test loss: 3.715e+07, MSE(e): 2.996e-02, MSE(pi1): 1.091e-01, MSE(pi2): 1.720e-02, MSE(pi3): 2.103e-02\n",
      "Epoch 59800, Train loss: 3.023e+05, Test loss: 3.717e+07, MSE(e): 2.991e-02, MSE(pi1): 1.093e-01, MSE(pi2): 1.718e-02, MSE(pi3): 2.095e-02\n",
      "Epoch 59900, Train loss: 3.017e+05, Test loss: 3.713e+07, MSE(e): 2.985e-02, MSE(pi1): 1.088e-01, MSE(pi2): 1.714e-02, MSE(pi3): 2.096e-02\n",
      "Epoch 60000, Train loss: 3.012e+05, Test loss: 3.710e+07, MSE(e): 2.980e-02, MSE(pi1): 1.090e-01, MSE(pi2): 1.711e-02, MSE(pi3): 2.094e-02\n",
      "Epoch 60100, Train loss: 3.006e+05, Test loss: 3.710e+07, MSE(e): 2.974e-02, MSE(pi1): 1.084e-01, MSE(pi2): 1.708e-02, MSE(pi3): 2.091e-02\n",
      "Epoch 60200, Train loss: 3.011e+05, Test loss: 3.717e+07, MSE(e): 2.979e-02, MSE(pi1): 1.108e-01, MSE(pi2): 1.711e-02, MSE(pi3): 2.070e-02\n",
      "Epoch 60300, Train loss: 2.995e+05, Test loss: 3.708e+07, MSE(e): 2.963e-02, MSE(pi1): 1.081e-01, MSE(pi2): 1.702e-02, MSE(pi3): 2.084e-02\n",
      "Epoch 60400, Train loss: 2.990e+05, Test loss: 3.707e+07, MSE(e): 2.958e-02, MSE(pi1): 1.078e-01, MSE(pi2): 1.698e-02, MSE(pi3): 2.082e-02\n",
      "Epoch 60500, Train loss: 2.984e+05, Test loss: 3.706e+07, MSE(e): 2.953e-02, MSE(pi1): 1.078e-01, MSE(pi2): 1.695e-02, MSE(pi3): 2.078e-02\n",
      "Epoch 60600, Train loss: 2.992e+05, Test loss: 3.715e+07, MSE(e): 2.960e-02, MSE(pi1): 1.108e-01, MSE(pi2): 1.700e-02, MSE(pi3): 2.067e-02\n",
      "Epoch 60700, Train loss: 2.973e+05, Test loss: 3.703e+07, MSE(e): 2.942e-02, MSE(pi1): 1.074e-01, MSE(pi2): 1.689e-02, MSE(pi3): 2.072e-02\n",
      "Epoch 60800, Train loss: 2.968e+05, Test loss: 3.701e+07, MSE(e): 2.937e-02, MSE(pi1): 1.072e-01, MSE(pi2): 1.686e-02, MSE(pi3): 2.072e-02\n",
      "Epoch 60900, Train loss: 2.963e+05, Test loss: 3.701e+07, MSE(e): 2.931e-02, MSE(pi1): 1.070e-01, MSE(pi2): 1.683e-02, MSE(pi3): 2.067e-02\n",
      "Epoch 61000, Train loss: 2.958e+05, Test loss: 3.701e+07, MSE(e): 2.926e-02, MSE(pi1): 1.072e-01, MSE(pi2): 1.680e-02, MSE(pi3): 2.063e-02\n",
      "Epoch 61100, Train loss: 2.952e+05, Test loss: 3.698e+07, MSE(e): 2.920e-02, MSE(pi1): 1.066e-01, MSE(pi2): 1.677e-02, MSE(pi3): 2.063e-02\n",
      "Epoch 61200, Train loss: 2.947e+05, Test loss: 3.696e+07, MSE(e): 2.915e-02, MSE(pi1): 1.076e-01, MSE(pi2): 1.674e-02, MSE(pi3): 2.056e-02\n",
      "Epoch 61300, Train loss: 2.941e+05, Test loss: 3.694e+07, MSE(e): 2.910e-02, MSE(pi1): 1.065e-01, MSE(pi2): 1.670e-02, MSE(pi3): 2.062e-02\n",
      "Epoch 61400, Train loss: 2.936e+05, Test loss: 3.696e+07, MSE(e): 2.905e-02, MSE(pi1): 1.065e-01, MSE(pi2): 1.668e-02, MSE(pi3): 2.048e-02\n",
      "Epoch 61500, Train loss: 2.930e+05, Test loss: 3.693e+07, MSE(e): 2.899e-02, MSE(pi1): 1.061e-01, MSE(pi2): 1.664e-02, MSE(pi3): 2.049e-02\n",
      "Epoch 61600, Train loss: 2.925e+05, Test loss: 3.692e+07, MSE(e): 2.894e-02, MSE(pi1): 1.061e-01, MSE(pi2): 1.661e-02, MSE(pi3): 2.045e-02\n",
      "Epoch 61700, Train loss: 2.920e+05, Test loss: 3.691e+07, MSE(e): 2.889e-02, MSE(pi1): 1.056e-01, MSE(pi2): 1.658e-02, MSE(pi3): 2.044e-02\n",
      "Epoch 61800, Train loss: 2.914e+05, Test loss: 3.689e+07, MSE(e): 2.883e-02, MSE(pi1): 1.055e-01, MSE(pi2): 1.655e-02, MSE(pi3): 2.041e-02\n",
      "Epoch 61900, Train loss: 2.909e+05, Test loss: 3.687e+07, MSE(e): 2.878e-02, MSE(pi1): 1.053e-01, MSE(pi2): 1.652e-02, MSE(pi3): 2.039e-02\n",
      "Epoch 62000, Train loss: 2.909e+05, Test loss: 3.689e+07, MSE(e): 2.877e-02, MSE(pi1): 1.112e-01, MSE(pi2): 1.652e-02, MSE(pi3): 2.045e-02\n",
      "Epoch 62100, Train loss: 2.899e+05, Test loss: 3.685e+07, MSE(e): 2.868e-02, MSE(pi1): 1.051e-01, MSE(pi2): 1.646e-02, MSE(pi3): 2.040e-02\n",
      "Epoch 62200, Train loss: 2.893e+05, Test loss: 3.683e+07, MSE(e): 2.863e-02, MSE(pi1): 1.048e-01, MSE(pi2): 1.643e-02, MSE(pi3): 2.029e-02\n",
      "Epoch 62300, Train loss: 2.888e+05, Test loss: 3.681e+07, MSE(e): 2.857e-02, MSE(pi1): 1.046e-01, MSE(pi2): 1.640e-02, MSE(pi3): 2.028e-02\n",
      "Epoch 62400, Train loss: 2.883e+05, Test loss: 3.680e+07, MSE(e): 2.852e-02, MSE(pi1): 1.046e-01, MSE(pi2): 1.637e-02, MSE(pi3): 2.026e-02\n",
      "Epoch 62500, Train loss: 2.879e+05, Test loss: 3.676e+07, MSE(e): 2.848e-02, MSE(pi1): 1.074e-01, MSE(pi2): 1.635e-02, MSE(pi3): 2.041e-02\n",
      "Epoch 62600, Train loss: 2.873e+05, Test loss: 3.677e+07, MSE(e): 2.842e-02, MSE(pi1): 1.041e-01, MSE(pi2): 1.631e-02, MSE(pi3): 2.018e-02\n",
      "Epoch 62700, Train loss: 2.868e+05, Test loss: 3.676e+07, MSE(e): 2.837e-02, MSE(pi1): 1.040e-01, MSE(pi2): 1.628e-02, MSE(pi3): 2.016e-02\n",
      "Epoch 62800, Train loss: 2.864e+05, Test loss: 3.670e+07, MSE(e): 2.833e-02, MSE(pi1): 1.043e-01, MSE(pi2): 1.626e-02, MSE(pi3): 2.018e-02\n",
      "Epoch 62900, Train loss: 2.858e+05, Test loss: 3.673e+07, MSE(e): 2.827e-02, MSE(pi1): 1.045e-01, MSE(pi2): 1.622e-02, MSE(pi3): 2.023e-02\n",
      "Epoch 63000, Train loss: 2.858e+05, Test loss: 3.677e+07, MSE(e): 2.827e-02, MSE(pi1): 1.048e-01, MSE(pi2): 1.623e-02, MSE(pi3): 2.000e-02\n",
      "Epoch 63100, Train loss: 2.847e+05, Test loss: 3.670e+07, MSE(e): 2.817e-02, MSE(pi1): 1.035e-01, MSE(pi2): 1.616e-02, MSE(pi3): 2.003e-02\n",
      "Epoch 63200, Train loss: 2.842e+05, Test loss: 3.669e+07, MSE(e): 2.812e-02, MSE(pi1): 1.033e-01, MSE(pi2): 1.614e-02, MSE(pi3): 2.000e-02\n",
      "Epoch 63300, Train loss: 2.837e+05, Test loss: 3.667e+07, MSE(e): 2.806e-02, MSE(pi1): 1.030e-01, MSE(pi2): 1.611e-02, MSE(pi3): 1.999e-02\n",
      "Epoch 63400, Train loss: 2.832e+05, Test loss: 3.665e+07, MSE(e): 2.801e-02, MSE(pi1): 1.028e-01, MSE(pi2): 1.608e-02, MSE(pi3): 1.998e-02\n",
      "Epoch 63500, Train loss: 2.827e+05, Test loss: 3.663e+07, MSE(e): 2.797e-02, MSE(pi1): 1.030e-01, MSE(pi2): 1.605e-02, MSE(pi3): 1.995e-02\n",
      "Epoch 63600, Train loss: 2.822e+05, Test loss: 3.663e+07, MSE(e): 2.791e-02, MSE(pi1): 1.025e-01, MSE(pi2): 1.602e-02, MSE(pi3): 1.999e-02\n",
      "Epoch 63700, Train loss: 2.817e+05, Test loss: 3.660e+07, MSE(e): 2.787e-02, MSE(pi1): 1.022e-01, MSE(pi2): 1.599e-02, MSE(pi3): 1.990e-02\n",
      "Epoch 63800, Train loss: 2.812e+05, Test loss: 3.660e+07, MSE(e): 2.782e-02, MSE(pi1): 1.021e-01, MSE(pi2): 1.596e-02, MSE(pi3): 1.986e-02\n",
      "Epoch 63900, Train loss: 2.807e+05, Test loss: 3.658e+07, MSE(e): 2.777e-02, MSE(pi1): 1.026e-01, MSE(pi2): 1.593e-02, MSE(pi3): 1.996e-02\n",
      "Epoch 64000, Train loss: 2.802e+05, Test loss: 3.654e+07, MSE(e): 2.772e-02, MSE(pi1): 1.021e-01, MSE(pi2): 1.591e-02, MSE(pi3): 1.983e-02\n",
      "Epoch 64100, Train loss: 2.797e+05, Test loss: 3.654e+07, MSE(e): 2.767e-02, MSE(pi1): 1.017e-01, MSE(pi2): 1.588e-02, MSE(pi3): 1.978e-02\n",
      "Epoch 64200, Train loss: 2.792e+05, Test loss: 3.653e+07, MSE(e): 2.762e-02, MSE(pi1): 1.015e-01, MSE(pi2): 1.585e-02, MSE(pi3): 1.976e-02\n",
      "Epoch 64300, Train loss: 2.787e+05, Test loss: 3.651e+07, MSE(e): 2.757e-02, MSE(pi1): 1.013e-01, MSE(pi2): 1.582e-02, MSE(pi3): 1.973e-02\n",
      "Epoch 64400, Train loss: 2.783e+05, Test loss: 3.647e+07, MSE(e): 2.753e-02, MSE(pi1): 1.008e-01, MSE(pi2): 1.580e-02, MSE(pi3): 1.979e-02\n",
      "Epoch 64500, Train loss: 2.777e+05, Test loss: 3.648e+07, MSE(e): 2.747e-02, MSE(pi1): 1.010e-01, MSE(pi2): 1.576e-02, MSE(pi3): 1.968e-02\n",
      "Epoch 64600, Train loss: 2.772e+05, Test loss: 3.647e+07, MSE(e): 2.743e-02, MSE(pi1): 1.009e-01, MSE(pi2): 1.574e-02, MSE(pi3): 1.964e-02\n",
      "Epoch 64700, Train loss: 2.768e+05, Test loss: 3.644e+07, MSE(e): 2.738e-02, MSE(pi1): 1.013e-01, MSE(pi2): 1.571e-02, MSE(pi3): 1.961e-02\n",
      "Epoch 64800, Train loss: 2.764e+05, Test loss: 3.647e+07, MSE(e): 2.735e-02, MSE(pi1): 1.013e-01, MSE(pi2): 1.569e-02, MSE(pi3): 1.952e-02\n",
      "Epoch 64900, Train loss: 2.758e+05, Test loss: 3.642e+07, MSE(e): 2.728e-02, MSE(pi1): 1.002e-01, MSE(pi2): 1.565e-02, MSE(pi3): 1.960e-02\n",
      "Epoch 65000, Train loss: 2.753e+05, Test loss: 3.641e+07, MSE(e): 2.723e-02, MSE(pi1): 1.001e-01, MSE(pi2): 1.562e-02, MSE(pi3): 1.958e-02\n",
      "Epoch 65100, Train loss: 2.748e+05, Test loss: 3.639e+07, MSE(e): 2.718e-02, MSE(pi1): 1.003e-01, MSE(pi2): 1.560e-02, MSE(pi3): 1.963e-02\n",
      "Epoch 65200, Train loss: 2.743e+05, Test loss: 3.638e+07, MSE(e): 2.714e-02, MSE(pi1): 9.985e-02, MSE(pi2): 1.557e-02, MSE(pi3): 1.950e-02\n",
      "Epoch 65300, Train loss: 2.738e+05, Test loss: 3.636e+07, MSE(e): 2.709e-02, MSE(pi1): 9.967e-02, MSE(pi2): 1.554e-02, MSE(pi3): 1.949e-02\n",
      "Epoch 65400, Train loss: 2.734e+05, Test loss: 3.634e+07, MSE(e): 2.704e-02, MSE(pi1): 9.948e-02, MSE(pi2): 1.551e-02, MSE(pi3): 1.947e-02\n",
      "Epoch 65500, Train loss: 2.729e+05, Test loss: 3.633e+07, MSE(e): 2.699e-02, MSE(pi1): 9.943e-02, MSE(pi2): 1.549e-02, MSE(pi3): 1.942e-02\n",
      "Epoch 65600, Train loss: 2.726e+05, Test loss: 3.627e+07, MSE(e): 2.696e-02, MSE(pi1): 1.014e-01, MSE(pi2): 1.547e-02, MSE(pi3): 1.941e-02\n",
      "Epoch 65700, Train loss: 2.719e+05, Test loss: 3.629e+07, MSE(e): 2.690e-02, MSE(pi1): 9.899e-02, MSE(pi2): 1.543e-02, MSE(pi3): 1.939e-02\n",
      "Epoch 65800, Train loss: 2.715e+05, Test loss: 3.627e+07, MSE(e): 2.685e-02, MSE(pi1): 1.011e-01, MSE(pi2): 1.540e-02, MSE(pi3): 1.932e-02\n",
      "Epoch 65900, Train loss: 2.710e+05, Test loss: 3.628e+07, MSE(e): 2.681e-02, MSE(pi1): 9.985e-02, MSE(pi2): 1.538e-02, MSE(pi3): 1.931e-02\n",
      "Epoch 66000, Train loss: 2.707e+05, Test loss: 3.621e+07, MSE(e): 2.677e-02, MSE(pi1): 9.887e-02, MSE(pi2): 1.536e-02, MSE(pi3): 1.941e-02\n",
      "Epoch 66100, Train loss: 2.700e+05, Test loss: 3.623e+07, MSE(e): 2.671e-02, MSE(pi1): 9.844e-02, MSE(pi2): 1.532e-02, MSE(pi3): 1.928e-02\n",
      "Epoch 66200, Train loss: 2.696e+05, Test loss: 3.621e+07, MSE(e): 2.666e-02, MSE(pi1): 9.816e-02, MSE(pi2): 1.529e-02, MSE(pi3): 1.927e-02\n",
      "Epoch 66300, Train loss: 2.691e+05, Test loss: 3.621e+07, MSE(e): 2.662e-02, MSE(pi1): 9.808e-02, MSE(pi2): 1.527e-02, MSE(pi3): 1.924e-02\n",
      "Epoch 66400, Train loss: 2.686e+05, Test loss: 3.618e+07, MSE(e): 2.657e-02, MSE(pi1): 9.790e-02, MSE(pi2): 1.524e-02, MSE(pi3): 1.922e-02\n",
      "Epoch 66500, Train loss: 2.692e+05, Test loss: 3.624e+07, MSE(e): 2.662e-02, MSE(pi1): 1.012e-01, MSE(pi2): 1.527e-02, MSE(pi3): 1.912e-02\n",
      "Epoch 66600, Train loss: 2.677e+05, Test loss: 3.615e+07, MSE(e): 2.648e-02, MSE(pi1): 9.851e-02, MSE(pi2): 1.519e-02, MSE(pi3): 1.916e-02\n",
      "Epoch 66700, Train loss: 2.673e+05, Test loss: 3.614e+07, MSE(e): 2.643e-02, MSE(pi1): 9.825e-02, MSE(pi2): 1.516e-02, MSE(pi3): 1.922e-02\n",
      "Epoch 66800, Train loss: 2.677e+05, Test loss: 3.607e+07, MSE(e): 2.647e-02, MSE(pi1): 1.014e-01, MSE(pi2): 1.518e-02, MSE(pi3): 1.922e-02\n",
      "Epoch 66900, Train loss: 2.663e+05, Test loss: 3.610e+07, MSE(e): 2.634e-02, MSE(pi1): 9.732e-02, MSE(pi2): 1.511e-02, MSE(pi3): 1.908e-02\n",
      "Epoch 67000, Train loss: 2.659e+05, Test loss: 3.607e+07, MSE(e): 2.630e-02, MSE(pi1): 9.688e-02, MSE(pi2): 1.508e-02, MSE(pi3): 1.910e-02\n",
      "Epoch 67100, Train loss: 2.654e+05, Test loss: 3.607e+07, MSE(e): 2.625e-02, MSE(pi1): 9.676e-02, MSE(pi2): 1.506e-02, MSE(pi3): 1.907e-02\n",
      "Epoch 67200, Train loss: 2.650e+05, Test loss: 3.606e+07, MSE(e): 2.621e-02, MSE(pi1): 9.675e-02, MSE(pi2): 1.503e-02, MSE(pi3): 1.902e-02\n",
      "Epoch 67300, Train loss: 2.646e+05, Test loss: 3.601e+07, MSE(e): 2.617e-02, MSE(pi1): 9.820e-02, MSE(pi2): 1.501e-02, MSE(pi3): 1.908e-02\n",
      "Epoch 67400, Train loss: 2.640e+05, Test loss: 3.603e+07, MSE(e): 2.612e-02, MSE(pi1): 9.635e-02, MSE(pi2): 1.498e-02, MSE(pi3): 1.898e-02\n",
      "Epoch 67500, Train loss: 2.636e+05, Test loss: 3.601e+07, MSE(e): 2.607e-02, MSE(pi1): 9.618e-02, MSE(pi2): 1.495e-02, MSE(pi3): 1.897e-02\n",
      "Epoch 67600, Train loss: 2.631e+05, Test loss: 3.600e+07, MSE(e): 2.603e-02, MSE(pi1): 9.602e-02, MSE(pi2): 1.493e-02, MSE(pi3): 1.894e-02\n",
      "Epoch 67700, Train loss: 2.627e+05, Test loss: 3.598e+07, MSE(e): 2.598e-02, MSE(pi1): 9.598e-02, MSE(pi2): 1.490e-02, MSE(pi3): 1.891e-02\n",
      "Epoch 67800, Train loss: 2.623e+05, Test loss: 3.598e+07, MSE(e): 2.594e-02, MSE(pi1): 9.608e-02, MSE(pi2): 1.488e-02, MSE(pi3): 1.886e-02\n",
      "Epoch 67900, Train loss: 2.619e+05, Test loss: 3.592e+07, MSE(e): 2.590e-02, MSE(pi1): 9.711e-02, MSE(pi2): 1.485e-02, MSE(pi3): 1.893e-02\n",
      "Epoch 68000, Train loss: 2.624e+05, Test loss: 3.588e+07, MSE(e): 2.594e-02, MSE(pi1): 1.010e-01, MSE(pi2): 1.488e-02, MSE(pi3): 1.902e-02\n",
      "Epoch 68100, Train loss: 2.609e+05, Test loss: 3.592e+07, MSE(e): 2.581e-02, MSE(pi1): 9.552e-02, MSE(pi2): 1.480e-02, MSE(pi3): 1.881e-02\n",
      "Epoch 68200, Train loss: 2.605e+05, Test loss: 3.589e+07, MSE(e): 2.577e-02, MSE(pi1): 9.570e-02, MSE(pi2): 1.478e-02, MSE(pi3): 1.882e-02\n",
      "Epoch 68300, Train loss: 2.600e+05, Test loss: 3.589e+07, MSE(e): 2.572e-02, MSE(pi1): 9.508e-02, MSE(pi2): 1.475e-02, MSE(pi3): 1.877e-02\n",
      "Epoch 68400, Train loss: 2.596e+05, Test loss: 3.587e+07, MSE(e): 2.567e-02, MSE(pi1): 9.489e-02, MSE(pi2): 1.472e-02, MSE(pi3): 1.876e-02\n",
      "Epoch 68500, Train loss: 2.592e+05, Test loss: 3.587e+07, MSE(e): 2.563e-02, MSE(pi1): 9.901e-02, MSE(pi2): 1.470e-02, MSE(pi3): 1.881e-02\n",
      "Epoch 68600, Train loss: 2.587e+05, Test loss: 3.584e+07, MSE(e): 2.559e-02, MSE(pi1): 9.442e-02, MSE(pi2): 1.467e-02, MSE(pi3): 1.876e-02\n",
      "Epoch 68700, Train loss: 2.583e+05, Test loss: 3.583e+07, MSE(e): 2.554e-02, MSE(pi1): 9.438e-02, MSE(pi2): 1.465e-02, MSE(pi3): 1.870e-02\n",
      "Epoch 68800, Train loss: 2.578e+05, Test loss: 3.581e+07, MSE(e): 2.550e-02, MSE(pi1): 9.434e-02, MSE(pi2): 1.462e-02, MSE(pi3): 1.868e-02\n",
      "Epoch 68900, Train loss: 2.574e+05, Test loss: 3.580e+07, MSE(e): 2.546e-02, MSE(pi1): 9.413e-02, MSE(pi2): 1.460e-02, MSE(pi3): 1.870e-02\n",
      "Epoch 69000, Train loss: 2.570e+05, Test loss: 3.578e+07, MSE(e): 2.542e-02, MSE(pi1): 9.392e-02, MSE(pi2): 1.457e-02, MSE(pi3): 1.864e-02\n",
      "Epoch 69100, Train loss: 2.566e+05, Test loss: 3.577e+07, MSE(e): 2.537e-02, MSE(pi1): 9.874e-02, MSE(pi2): 1.455e-02, MSE(pi3): 1.848e-02\n",
      "Epoch 69200, Train loss: 2.561e+05, Test loss: 3.576e+07, MSE(e): 2.533e-02, MSE(pi1): 9.363e-02, MSE(pi2): 1.452e-02, MSE(pi3): 1.862e-02\n",
      "Epoch 69300, Train loss: 2.559e+05, Test loss: 3.570e+07, MSE(e): 2.530e-02, MSE(pi1): 1.044e-01, MSE(pi2): 1.450e-02, MSE(pi3): 1.848e-02\n",
      "Epoch 69400, Train loss: 2.553e+05, Test loss: 3.573e+07, MSE(e): 2.524e-02, MSE(pi1): 9.337e-02, MSE(pi2): 1.447e-02, MSE(pi3): 1.854e-02\n",
      "Epoch 69500, Train loss: 2.549e+05, Test loss: 3.569e+07, MSE(e): 2.521e-02, MSE(pi1): 9.348e-02, MSE(pi2): 1.445e-02, MSE(pi3): 1.855e-02\n",
      "Epoch 69600, Train loss: 2.544e+05, Test loss: 3.570e+07, MSE(e): 2.516e-02, MSE(pi1): 9.308e-02, MSE(pi2): 1.442e-02, MSE(pi3): 1.850e-02\n",
      "Epoch 69700, Train loss: 2.540e+05, Test loss: 3.569e+07, MSE(e): 2.512e-02, MSE(pi1): 9.291e-02, MSE(pi2): 1.440e-02, MSE(pi3): 1.848e-02\n",
      "Epoch 69800, Train loss: 2.536e+05, Test loss: 3.563e+07, MSE(e): 2.508e-02, MSE(pi1): 9.361e-02, MSE(pi2): 1.438e-02, MSE(pi3): 1.845e-02\n",
      "Epoch 69900, Train loss: 2.532e+05, Test loss: 3.566e+07, MSE(e): 2.504e-02, MSE(pi1): 9.674e-02, MSE(pi2): 1.435e-02, MSE(pi3): 1.853e-02\n",
      "Epoch 70000, Train loss: 2.527e+05, Test loss: 3.565e+07, MSE(e): 2.499e-02, MSE(pi1): 9.257e-02, MSE(pi2): 1.433e-02, MSE(pi3): 1.840e-02\n",
      "Epoch 70100, Train loss: 2.523e+05, Test loss: 3.564e+07, MSE(e): 2.495e-02, MSE(pi1): 9.255e-02, MSE(pi2): 1.430e-02, MSE(pi3): 1.837e-02\n",
      "Epoch 70200, Train loss: 2.519e+05, Test loss: 3.562e+07, MSE(e): 2.491e-02, MSE(pi1): 9.226e-02, MSE(pi2): 1.428e-02, MSE(pi3): 1.837e-02\n",
      "Epoch 70300, Train loss: 2.517e+05, Test loss: 3.556e+07, MSE(e): 2.489e-02, MSE(pi1): 9.329e-02, MSE(pi2): 1.427e-02, MSE(pi3): 1.839e-02\n",
      "Epoch 70400, Train loss: 2.511e+05, Test loss: 3.559e+07, MSE(e): 2.483e-02, MSE(pi1): 9.197e-02, MSE(pi2): 1.423e-02, MSE(pi3): 1.833e-02\n",
      "Epoch 70500, Train loss: 2.507e+05, Test loss: 3.557e+07, MSE(e): 2.479e-02, MSE(pi1): 9.277e-02, MSE(pi2): 1.421e-02, MSE(pi3): 1.829e-02\n",
      "Epoch 70600, Train loss: 2.506e+05, Test loss: 3.550e+07, MSE(e): 2.477e-02, MSE(pi1): 9.832e-02, MSE(pi2): 1.420e-02, MSE(pi3): 1.825e-02\n",
      "Epoch 70700, Train loss: 2.498e+05, Test loss: 3.555e+07, MSE(e): 2.471e-02, MSE(pi1): 9.157e-02, MSE(pi2): 1.416e-02, MSE(pi3): 1.827e-02\n",
      "Epoch 70800, Train loss: 2.494e+05, Test loss: 3.553e+07, MSE(e): 2.467e-02, MSE(pi1): 9.140e-02, MSE(pi2): 1.414e-02, MSE(pi3): 1.827e-02\n",
      "Epoch 70900, Train loss: 2.490e+05, Test loss: 3.553e+07, MSE(e): 2.462e-02, MSE(pi1): 9.119e-02, MSE(pi2): 1.412e-02, MSE(pi3): 1.824e-02\n",
      "Epoch 71000, Train loss: 2.486e+05, Test loss: 3.551e+07, MSE(e): 2.459e-02, MSE(pi1): 9.119e-02, MSE(pi2): 1.409e-02, MSE(pi3): 1.822e-02\n",
      "Epoch 71100, Train loss: 2.482e+05, Test loss: 3.550e+07, MSE(e): 2.455e-02, MSE(pi1): 9.114e-02, MSE(pi2): 1.407e-02, MSE(pi3): 1.818e-02\n",
      "Epoch 71200, Train loss: 2.478e+05, Test loss: 3.547e+07, MSE(e): 2.451e-02, MSE(pi1): 9.077e-02, MSE(pi2): 1.405e-02, MSE(pi3): 1.820e-02\n",
      "Epoch 71300, Train loss: 2.478e+05, Test loss: 3.552e+07, MSE(e): 2.450e-02, MSE(pi1): 9.340e-02, MSE(pi2): 1.405e-02, MSE(pi3): 1.818e-02\n",
      "Epoch 71400, Train loss: 2.471e+05, Test loss: 3.543e+07, MSE(e): 2.444e-02, MSE(pi1): 9.031e-02, MSE(pi2): 1.401e-02, MSE(pi3): 1.826e-02\n",
      "Epoch 71500, Train loss: 2.477e+05, Test loss: 3.556e+07, MSE(e): 2.449e-02, MSE(pi1): 9.200e-02, MSE(pi2): 1.404e-02, MSE(pi3): 1.801e-02\n",
      "Epoch 71600, Train loss: 2.462e+05, Test loss: 3.544e+07, MSE(e): 2.435e-02, MSE(pi1): 9.019e-02, MSE(pi2): 1.395e-02, MSE(pi3): 1.810e-02\n",
      "Epoch 71700, Train loss: 2.461e+05, Test loss: 3.537e+07, MSE(e): 2.434e-02, MSE(pi1): 9.060e-02, MSE(pi2): 1.395e-02, MSE(pi3): 1.817e-02\n",
      "Epoch 71800, Train loss: 2.454e+05, Test loss: 3.542e+07, MSE(e): 2.427e-02, MSE(pi1): 8.997e-02, MSE(pi2): 1.391e-02, MSE(pi3): 1.806e-02\n",
      "Epoch 71900, Train loss: 2.450e+05, Test loss: 3.540e+07, MSE(e): 2.423e-02, MSE(pi1): 8.990e-02, MSE(pi2): 1.389e-02, MSE(pi3): 1.803e-02\n",
      "Epoch 72000, Train loss: 2.446e+05, Test loss: 3.539e+07, MSE(e): 2.419e-02, MSE(pi1): 8.978e-02, MSE(pi2): 1.386e-02, MSE(pi3): 1.802e-02\n",
      "Epoch 72100, Train loss: 2.446e+05, Test loss: 3.532e+07, MSE(e): 2.419e-02, MSE(pi1): 8.993e-02, MSE(pi2): 1.386e-02, MSE(pi3): 1.808e-02\n",
      "Epoch 72200, Train loss: 2.438e+05, Test loss: 3.537e+07, MSE(e): 2.411e-02, MSE(pi1): 8.944e-02, MSE(pi2): 1.382e-02, MSE(pi3): 1.798e-02\n",
      "Epoch 72300, Train loss: 2.434e+05, Test loss: 3.536e+07, MSE(e): 2.407e-02, MSE(pi1): 8.923e-02, MSE(pi2): 1.380e-02, MSE(pi3): 1.797e-02\n",
      "Epoch 72400, Train loss: 2.432e+05, Test loss: 3.531e+07, MSE(e): 2.405e-02, MSE(pi1): 9.072e-02, MSE(pi2): 1.378e-02, MSE(pi3): 1.808e-02\n",
      "Epoch 72500, Train loss: 2.427e+05, Test loss: 3.534e+07, MSE(e): 2.400e-02, MSE(pi1): 8.917e-02, MSE(pi2): 1.375e-02, MSE(pi3): 1.791e-02\n",
      "Epoch 72600, Train loss: 2.424e+05, Test loss: 3.536e+07, MSE(e): 2.397e-02, MSE(pi1): 8.977e-02, MSE(pi2): 1.374e-02, MSE(pi3): 1.788e-02\n",
      "Epoch 72700, Train loss: 2.419e+05, Test loss: 3.532e+07, MSE(e): 2.392e-02, MSE(pi1): 8.896e-02, MSE(pi2): 1.371e-02, MSE(pi3): 1.787e-02\n",
      "Epoch 72800, Train loss: 2.415e+05, Test loss: 3.530e+07, MSE(e): 2.388e-02, MSE(pi1): 8.864e-02, MSE(pi2): 1.369e-02, MSE(pi3): 1.787e-02\n",
      "Epoch 72900, Train loss: 2.412e+05, Test loss: 3.532e+07, MSE(e): 2.385e-02, MSE(pi1): 8.898e-02, MSE(pi2): 1.367e-02, MSE(pi3): 1.783e-02\n",
      "Epoch 73000, Train loss: 2.408e+05, Test loss: 3.527e+07, MSE(e): 2.381e-02, MSE(pi1): 8.908e-02, MSE(pi2): 1.364e-02, MSE(pi3): 1.782e-02\n",
      "Epoch 73100, Train loss: 2.404e+05, Test loss: 3.530e+07, MSE(e): 2.377e-02, MSE(pi1): 8.914e-02, MSE(pi2): 1.362e-02, MSE(pi3): 1.774e-02\n",
      "Epoch 73200, Train loss: 2.403e+05, Test loss: 3.521e+07, MSE(e): 2.376e-02, MSE(pi1): 8.868e-02, MSE(pi2): 1.361e-02, MSE(pi3): 1.790e-02\n",
      "Epoch 73300, Train loss: 2.396e+05, Test loss: 3.526e+07, MSE(e): 2.369e-02, MSE(pi1): 8.868e-02, MSE(pi2): 1.358e-02, MSE(pi3): 1.774e-02\n",
      "Epoch 73400, Train loss: 2.401e+05, Test loss: 3.517e+07, MSE(e): 2.374e-02, MSE(pi1): 8.732e-02, MSE(pi2): 1.360e-02, MSE(pi3): 1.799e-02\n",
      "Epoch 73500, Train loss: 2.389e+05, Test loss: 3.523e+07, MSE(e): 2.362e-02, MSE(pi1): 9.057e-02, MSE(pi2): 1.353e-02, MSE(pi3): 1.765e-02\n",
      "Epoch 73600, Train loss: 2.389e+05, Test loss: 3.521e+07, MSE(e): 2.362e-02, MSE(pi1): 9.186e-02, MSE(pi2): 1.353e-02, MSE(pi3): 1.794e-02\n",
      "Epoch 73700, Train loss: 2.381e+05, Test loss: 3.522e+07, MSE(e): 2.354e-02, MSE(pi1): 8.744e-02, MSE(pi2): 1.349e-02, MSE(pi3): 1.770e-02\n",
      "Epoch 73800, Train loss: 2.377e+05, Test loss: 3.521e+07, MSE(e): 2.351e-02, MSE(pi1): 8.742e-02, MSE(pi2): 1.347e-02, MSE(pi3): 1.769e-02\n",
      "Epoch 73900, Train loss: 2.374e+05, Test loss: 3.522e+07, MSE(e): 2.348e-02, MSE(pi1): 8.739e-02, MSE(pi2): 1.345e-02, MSE(pi3): 1.764e-02\n",
      "Epoch 74000, Train loss: 2.370e+05, Test loss: 3.519e+07, MSE(e): 2.343e-02, MSE(pi1): 8.683e-02, MSE(pi2): 1.343e-02, MSE(pi3): 1.770e-02\n",
      "Epoch 74100, Train loss: 2.366e+05, Test loss: 3.518e+07, MSE(e): 2.340e-02, MSE(pi1): 8.691e-02, MSE(pi2): 1.340e-02, MSE(pi3): 1.764e-02\n",
      "Epoch 74200, Train loss: 2.363e+05, Test loss: 3.519e+07, MSE(e): 2.336e-02, MSE(pi1): 8.700e-02, MSE(pi2): 1.339e-02, MSE(pi3): 1.759e-02\n",
      "Epoch 74300, Train loss: 2.359e+05, Test loss: 3.517e+07, MSE(e): 2.332e-02, MSE(pi1): 8.698e-02, MSE(pi2): 1.336e-02, MSE(pi3): 1.758e-02\n",
      "Epoch 74400, Train loss: 2.356e+05, Test loss: 3.519e+07, MSE(e): 2.330e-02, MSE(pi1): 8.710e-02, MSE(pi2): 1.335e-02, MSE(pi3): 1.754e-02\n",
      "Epoch 74500, Train loss: 2.352e+05, Test loss: 3.515e+07, MSE(e): 2.325e-02, MSE(pi1): 8.654e-02, MSE(pi2): 1.332e-02, MSE(pi3): 1.756e-02\n",
      "Epoch 74600, Train loss: 2.352e+05, Test loss: 3.519e+07, MSE(e): 2.325e-02, MSE(pi1): 8.965e-02, MSE(pi2): 1.332e-02, MSE(pi3): 1.743e-02\n",
      "Epoch 74700, Train loss: 2.344e+05, Test loss: 3.514e+07, MSE(e): 2.318e-02, MSE(pi1): 8.611e-02, MSE(pi2): 1.328e-02, MSE(pi3): 1.753e-02\n",
      "Epoch 74800, Train loss: 2.341e+05, Test loss: 3.514e+07, MSE(e): 2.314e-02, MSE(pi1): 9.071e-02, MSE(pi2): 1.326e-02, MSE(pi3): 1.772e-02\n",
      "Epoch 74900, Train loss: 2.337e+05, Test loss: 3.512e+07, MSE(e): 2.311e-02, MSE(pi1): 8.706e-02, MSE(pi2): 1.324e-02, MSE(pi3): 1.747e-02\n",
      "Epoch 75000, Train loss: 2.333e+05, Test loss: 3.512e+07, MSE(e): 2.307e-02, MSE(pi1): 8.585e-02, MSE(pi2): 1.322e-02, MSE(pi3): 1.747e-02\n",
      "Epoch 75100, Train loss: 2.330e+05, Test loss: 3.511e+07, MSE(e): 2.304e-02, MSE(pi1): 8.548e-02, MSE(pi2): 1.320e-02, MSE(pi3): 1.748e-02\n",
      "Epoch 75200, Train loss: 2.327e+05, Test loss: 3.511e+07, MSE(e): 2.300e-02, MSE(pi1): 9.241e-02, MSE(pi2): 1.318e-02, MSE(pi3): 1.770e-02\n",
      "Epoch 75300, Train loss: 2.323e+05, Test loss: 3.508e+07, MSE(e): 2.297e-02, MSE(pi1): 8.543e-02, MSE(pi2): 1.316e-02, MSE(pi3): 1.747e-02\n",
      "Epoch 75400, Train loss: 2.321e+05, Test loss: 3.514e+07, MSE(e): 2.295e-02, MSE(pi1): 8.627e-02, MSE(pi2): 1.315e-02, MSE(pi3): 1.742e-02\n",
      "Epoch 75500, Train loss: 2.316e+05, Test loss: 3.509e+07, MSE(e): 2.290e-02, MSE(pi1): 8.508e-02, MSE(pi2): 1.312e-02, MSE(pi3): 1.740e-02\n",
      "Epoch 75600, Train loss: 2.313e+05, Test loss: 3.507e+07, MSE(e): 2.286e-02, MSE(pi1): 9.423e-02, MSE(pi2): 1.310e-02, MSE(pi3): 1.722e-02\n",
      "Epoch 75700, Train loss: 2.315e+05, Test loss: 3.514e+07, MSE(e): 2.289e-02, MSE(pi1): 9.108e-02, MSE(pi2): 1.311e-02, MSE(pi3): 1.721e-02\n",
      "Epoch 75800, Train loss: 2.305e+05, Test loss: 3.506e+07, MSE(e): 2.279e-02, MSE(pi1): 8.614e-02, MSE(pi2): 1.306e-02, MSE(pi3): 1.728e-02\n",
      "Epoch 75900, Train loss: 2.302e+05, Test loss: 3.505e+07, MSE(e): 2.276e-02, MSE(pi1): 8.470e-02, MSE(pi2): 1.304e-02, MSE(pi3): 1.734e-02\n",
      "Epoch 76000, Train loss: 2.298e+05, Test loss: 3.505e+07, MSE(e): 2.272e-02, MSE(pi1): 8.443e-02, MSE(pi2): 1.302e-02, MSE(pi3): 1.732e-02\n",
      "Epoch 76100, Train loss: 2.296e+05, Test loss: 3.507e+07, MSE(e): 2.270e-02, MSE(pi1): 8.503e-02, MSE(pi2): 1.300e-02, MSE(pi3): 1.725e-02\n",
      "Epoch 76200, Train loss: 2.291e+05, Test loss: 3.505e+07, MSE(e): 2.265e-02, MSE(pi1): 8.423e-02, MSE(pi2): 1.298e-02, MSE(pi3): 1.728e-02\n",
      "Epoch 76300, Train loss: 2.289e+05, Test loss: 3.500e+07, MSE(e): 2.263e-02, MSE(pi1): 8.368e-02, MSE(pi2): 1.296e-02, MSE(pi3): 1.736e-02\n",
      "Epoch 76400, Train loss: 2.284e+05, Test loss: 3.504e+07, MSE(e): 2.259e-02, MSE(pi1): 8.392e-02, MSE(pi2): 1.294e-02, MSE(pi3): 1.726e-02\n",
      "Epoch 76500, Train loss: 2.281e+05, Test loss: 3.504e+07, MSE(e): 2.255e-02, MSE(pi1): 8.382e-02, MSE(pi2): 1.292e-02, MSE(pi3): 1.723e-02\n",
      "Epoch 76600, Train loss: 2.279e+05, Test loss: 3.503e+07, MSE(e): 2.253e-02, MSE(pi1): 8.549e-02, MSE(pi2): 1.291e-02, MSE(pi3): 1.719e-02\n",
      "Epoch 76700, Train loss: 2.274e+05, Test loss: 3.502e+07, MSE(e): 2.248e-02, MSE(pi1): 8.347e-02, MSE(pi2): 1.288e-02, MSE(pi3): 1.728e-02\n",
      "Epoch 76800, Train loss: 2.271e+05, Test loss: 3.502e+07, MSE(e): 2.245e-02, MSE(pi1): 8.340e-02, MSE(pi2): 1.286e-02, MSE(pi3): 1.719e-02\n",
      "Epoch 76900, Train loss: 2.268e+05, Test loss: 3.500e+07, MSE(e): 2.242e-02, MSE(pi1): 8.298e-02, MSE(pi2): 1.284e-02, MSE(pi3): 1.727e-02\n",
      "Epoch 77000, Train loss: 2.264e+05, Test loss: 3.501e+07, MSE(e): 2.238e-02, MSE(pi1): 8.321e-02, MSE(pi2): 1.282e-02, MSE(pi3): 1.716e-02\n",
      "Epoch 77100, Train loss: 2.261e+05, Test loss: 3.500e+07, MSE(e): 2.235e-02, MSE(pi1): 8.315e-02, MSE(pi2): 1.280e-02, MSE(pi3): 1.714e-02\n",
      "Epoch 77200, Train loss: 2.257e+05, Test loss: 3.501e+07, MSE(e): 2.232e-02, MSE(pi1): 8.462e-02, MSE(pi2): 1.278e-02, MSE(pi3): 1.705e-02\n",
      "Epoch 77300, Train loss: 2.255e+05, Test loss: 3.499e+07, MSE(e): 2.228e-02, MSE(pi1): 9.216e-02, MSE(pi2): 1.276e-02, MSE(pi3): 1.693e-02\n",
      "Epoch 77400, Train loss: 2.250e+05, Test loss: 3.500e+07, MSE(e): 2.225e-02, MSE(pi1): 8.267e-02, MSE(pi2): 1.274e-02, MSE(pi3): 1.710e-02\n",
      "Epoch 77500, Train loss: 2.247e+05, Test loss: 3.500e+07, MSE(e): 2.222e-02, MSE(pi1): 8.253e-02, MSE(pi2): 1.272e-02, MSE(pi3): 1.708e-02\n",
      "Epoch 77600, Train loss: 2.244e+05, Test loss: 3.499e+07, MSE(e): 2.218e-02, MSE(pi1): 8.265e-02, MSE(pi2): 1.270e-02, MSE(pi3): 1.705e-02\n",
      "Epoch 77700, Train loss: 2.242e+05, Test loss: 3.497e+07, MSE(e): 2.216e-02, MSE(pi1): 8.200e-02, MSE(pi2): 1.269e-02, MSE(pi3): 1.713e-02\n",
      "Epoch 77800, Train loss: 2.237e+05, Test loss: 3.499e+07, MSE(e): 2.212e-02, MSE(pi1): 8.219e-02, MSE(pi2): 1.267e-02, MSE(pi3): 1.704e-02\n",
      "Epoch 77900, Train loss: 2.234e+05, Test loss: 3.499e+07, MSE(e): 2.209e-02, MSE(pi1): 8.213e-02, MSE(pi2): 1.265e-02, MSE(pi3): 1.702e-02\n",
      "Epoch 78000, Train loss: 2.231e+05, Test loss: 3.499e+07, MSE(e): 2.205e-02, MSE(pi1): 8.191e-02, MSE(pi2): 1.263e-02, MSE(pi3): 1.700e-02\n",
      "Epoch 78100, Train loss: 2.227e+05, Test loss: 3.498e+07, MSE(e): 2.202e-02, MSE(pi1): 8.176e-02, MSE(pi2): 1.261e-02, MSE(pi3): 1.700e-02\n",
      "Epoch 78200, Train loss: 2.224e+05, Test loss: 3.498e+07, MSE(e): 2.199e-02, MSE(pi1): 8.176e-02, MSE(pi2): 1.259e-02, MSE(pi3): 1.697e-02\n",
      "Epoch 78300, Train loss: 2.221e+05, Test loss: 3.498e+07, MSE(e): 2.196e-02, MSE(pi1): 8.158e-02, MSE(pi2): 1.257e-02, MSE(pi3): 1.697e-02\n",
      "Epoch 78400, Train loss: 2.218e+05, Test loss: 3.497e+07, MSE(e): 2.192e-02, MSE(pi1): 8.143e-02, MSE(pi2): 1.255e-02, MSE(pi3): 1.695e-02\n",
      "Epoch 78500, Train loss: 2.214e+05, Test loss: 3.498e+07, MSE(e): 2.189e-02, MSE(pi1): 8.131e-02, MSE(pi2): 1.254e-02, MSE(pi3): 1.693e-02\n",
      "Epoch 78600, Train loss: 2.211e+05, Test loss: 3.497e+07, MSE(e): 2.186e-02, MSE(pi1): 8.191e-02, MSE(pi2): 1.252e-02, MSE(pi3): 1.690e-02\n",
      "Epoch 78700, Train loss: 2.210e+05, Test loss: 3.494e+07, MSE(e): 2.184e-02, MSE(pi1): 8.327e-02, MSE(pi2): 1.251e-02, MSE(pi3): 1.712e-02\n",
      "Epoch 78800, Train loss: 2.205e+05, Test loss: 3.498e+07, MSE(e): 2.180e-02, MSE(pi1): 8.112e-02, MSE(pi2): 1.248e-02, MSE(pi3): 1.686e-02\n",
      "Epoch 78900, Train loss: 2.202e+05, Test loss: 3.497e+07, MSE(e): 2.176e-02, MSE(pi1): 8.124e-02, MSE(pi2): 1.246e-02, MSE(pi3): 1.686e-02\n",
      "Epoch 79000, Train loss: 2.198e+05, Test loss: 3.498e+07, MSE(e): 2.173e-02, MSE(pi1): 8.086e-02, MSE(pi2): 1.244e-02, MSE(pi3): 1.684e-02\n",
      "Epoch 79100, Train loss: 2.208e+05, Test loss: 3.488e+07, MSE(e): 2.183e-02, MSE(pi1): 8.072e-02, MSE(pi2): 1.250e-02, MSE(pi3): 1.713e-02\n",
      "Epoch 79200, Train loss: 2.192e+05, Test loss: 3.497e+07, MSE(e): 2.167e-02, MSE(pi1): 8.166e-02, MSE(pi2): 1.241e-02, MSE(pi3): 1.677e-02\n",
      "Epoch 79300, Train loss: 2.189e+05, Test loss: 3.499e+07, MSE(e): 2.164e-02, MSE(pi1): 8.097e-02, MSE(pi2): 1.239e-02, MSE(pi3): 1.676e-02\n",
      "Epoch 79400, Train loss: 2.186e+05, Test loss: 3.497e+07, MSE(e): 2.161e-02, MSE(pi1): 8.030e-02, MSE(pi2): 1.237e-02, MSE(pi3): 1.679e-02\n",
      "Epoch 79500, Train loss: 2.183e+05, Test loss: 3.496e+07, MSE(e): 2.158e-02, MSE(pi1): 8.914e-02, MSE(pi2): 1.235e-02, MSE(pi3): 1.665e-02\n",
      "Epoch 79600, Train loss: 2.179e+05, Test loss: 3.497e+07, MSE(e): 2.155e-02, MSE(pi1): 8.012e-02, MSE(pi2): 1.234e-02, MSE(pi3): 1.676e-02\n",
      "Epoch 79700, Train loss: 2.176e+05, Test loss: 3.497e+07, MSE(e): 2.151e-02, MSE(pi1): 7.985e-02, MSE(pi2): 1.232e-02, MSE(pi3): 1.676e-02\n",
      "Epoch 79800, Train loss: 2.173e+05, Test loss: 3.497e+07, MSE(e): 2.148e-02, MSE(pi1): 8.015e-02, MSE(pi2): 1.230e-02, MSE(pi3): 1.674e-02\n",
      "Epoch 79900, Train loss: 2.175e+05, Test loss: 3.505e+07, MSE(e): 2.150e-02, MSE(pi1): 8.354e-02, MSE(pi2): 1.231e-02, MSE(pi3): 1.666e-02\n",
      "Epoch 80000, Train loss: 2.167e+05, Test loss: 3.497e+07, MSE(e): 2.142e-02, MSE(pi1): 7.989e-02, MSE(pi2): 1.226e-02, MSE(pi3): 1.669e-02\n",
      "Epoch 80100, Train loss: 2.167e+05, Test loss: 3.496e+07, MSE(e): 2.142e-02, MSE(pi1): 8.359e-02, MSE(pi2): 1.227e-02, MSE(pi3): 1.670e-02\n",
      "Epoch 80200, Train loss: 2.161e+05, Test loss: 3.498e+07, MSE(e): 2.136e-02, MSE(pi1): 7.931e-02, MSE(pi2): 1.223e-02, MSE(pi3): 1.669e-02\n",
      "Epoch 80300, Train loss: 2.158e+05, Test loss: 3.498e+07, MSE(e): 2.133e-02, MSE(pi1): 7.911e-02, MSE(pi2): 1.221e-02, MSE(pi3): 1.668e-02\n",
      "Epoch 80400, Train loss: 2.155e+05, Test loss: 3.499e+07, MSE(e): 2.130e-02, MSE(pi1): 7.940e-02, MSE(pi2): 1.219e-02, MSE(pi3): 1.665e-02\n",
      "Epoch 80500, Train loss: 2.152e+05, Test loss: 3.497e+07, MSE(e): 2.127e-02, MSE(pi1): 7.925e-02, MSE(pi2): 1.218e-02, MSE(pi3): 1.664e-02\n",
      "Epoch 80600, Train loss: 2.149e+05, Test loss: 3.498e+07, MSE(e): 2.124e-02, MSE(pi1): 7.884e-02, MSE(pi2): 1.216e-02, MSE(pi3): 1.663e-02\n",
      "Epoch 80700, Train loss: 2.152e+05, Test loss: 3.492e+07, MSE(e): 2.127e-02, MSE(pi1): 7.823e-02, MSE(pi2): 1.217e-02, MSE(pi3): 1.680e-02\n",
      "Epoch 80800, Train loss: 2.142e+05, Test loss: 3.499e+07, MSE(e): 2.118e-02, MSE(pi1): 7.865e-02, MSE(pi2): 1.212e-02, MSE(pi3): 1.660e-02\n",
      "Epoch 80900, Train loss: 2.139e+05, Test loss: 3.499e+07, MSE(e): 2.115e-02, MSE(pi1): 7.865e-02, MSE(pi2): 1.211e-02, MSE(pi3): 1.657e-02\n",
      "Epoch 81000, Train loss: 2.136e+05, Test loss: 3.499e+07, MSE(e): 2.112e-02, MSE(pi1): 7.909e-02, MSE(pi2): 1.209e-02, MSE(pi3): 1.654e-02\n",
      "Epoch 81100, Train loss: 2.133e+05, Test loss: 3.500e+07, MSE(e): 2.109e-02, MSE(pi1): 7.840e-02, MSE(pi2): 1.207e-02, MSE(pi3): 1.657e-02\n",
      "Epoch 81200, Train loss: 2.130e+05, Test loss: 3.500e+07, MSE(e): 2.106e-02, MSE(pi1): 7.812e-02, MSE(pi2): 1.205e-02, MSE(pi3): 1.655e-02\n",
      "Epoch 81300, Train loss: 2.127e+05, Test loss: 3.500e+07, MSE(e): 2.103e-02, MSE(pi1): 7.804e-02, MSE(pi2): 1.204e-02, MSE(pi3): 1.654e-02\n",
      "Epoch 81400, Train loss: 2.124e+05, Test loss: 3.500e+07, MSE(e): 2.100e-02, MSE(pi1): 7.792e-02, MSE(pi2): 1.202e-02, MSE(pi3): 1.653e-02\n",
      "Epoch 81500, Train loss: 2.122e+05, Test loss: 3.504e+07, MSE(e): 2.098e-02, MSE(pi1): 7.956e-02, MSE(pi2): 1.201e-02, MSE(pi3): 1.650e-02\n",
      "Epoch 81600, Train loss: 2.118e+05, Test loss: 3.501e+07, MSE(e): 2.094e-02, MSE(pi1): 7.823e-02, MSE(pi2): 1.198e-02, MSE(pi3): 1.659e-02\n",
      "Epoch 81700, Train loss: 2.115e+05, Test loss: 3.504e+07, MSE(e): 2.091e-02, MSE(pi1): 7.804e-02, MSE(pi2): 1.197e-02, MSE(pi3): 1.645e-02\n",
      "Epoch 81800, Train loss: 2.112e+05, Test loss: 3.501e+07, MSE(e): 2.088e-02, MSE(pi1): 7.752e-02, MSE(pi2): 1.195e-02, MSE(pi3): 1.652e-02\n",
      "Epoch 81900, Train loss: 2.109e+05, Test loss: 3.502e+07, MSE(e): 2.085e-02, MSE(pi1): 7.726e-02, MSE(pi2): 1.193e-02, MSE(pi3): 1.646e-02\n",
      "Epoch 82000, Train loss: 2.106e+05, Test loss: 3.502e+07, MSE(e): 2.082e-02, MSE(pi1): 7.713e-02, MSE(pi2): 1.191e-02, MSE(pi3): 1.646e-02\n",
      "Epoch 82100, Train loss: 2.105e+05, Test loss: 3.498e+07, MSE(e): 2.081e-02, MSE(pi1): 8.143e-02, MSE(pi2): 1.191e-02, MSE(pi3): 1.650e-02\n",
      "Epoch 82200, Train loss: 2.100e+05, Test loss: 3.504e+07, MSE(e): 2.076e-02, MSE(pi1): 7.704e-02, MSE(pi2): 1.188e-02, MSE(pi3): 1.641e-02\n",
      "Epoch 82300, Train loss: 2.097e+05, Test loss: 3.506e+07, MSE(e): 2.073e-02, MSE(pi1): 7.721e-02, MSE(pi2): 1.187e-02, MSE(pi3): 1.637e-02\n",
      "Epoch 82400, Train loss: 2.094e+05, Test loss: 3.504e+07, MSE(e): 2.070e-02, MSE(pi1): 7.678e-02, MSE(pi2): 1.185e-02, MSE(pi3): 1.638e-02\n",
      "Epoch 82500, Train loss: 2.091e+05, Test loss: 3.505e+07, MSE(e): 2.067e-02, MSE(pi1): 7.672e-02, MSE(pi2): 1.183e-02, MSE(pi3): 1.637e-02\n",
      "Epoch 82600, Train loss: 2.088e+05, Test loss: 3.505e+07, MSE(e): 2.064e-02, MSE(pi1): 7.655e-02, MSE(pi2): 1.181e-02, MSE(pi3): 1.636e-02\n",
      "Epoch 82700, Train loss: 2.085e+05, Test loss: 3.506e+07, MSE(e): 2.061e-02, MSE(pi1): 7.693e-02, MSE(pi2): 1.180e-02, MSE(pi3): 1.632e-02\n",
      "Epoch 82800, Train loss: 2.082e+05, Test loss: 3.507e+07, MSE(e): 2.058e-02, MSE(pi1): 7.695e-02, MSE(pi2): 1.178e-02, MSE(pi3): 1.629e-02\n",
      "Epoch 82900, Train loss: 2.080e+05, Test loss: 3.507e+07, MSE(e): 2.055e-02, MSE(pi1): 7.622e-02, MSE(pi2): 1.176e-02, MSE(pi3): 1.632e-02\n",
      "Epoch 83000, Train loss: 2.077e+05, Test loss: 3.510e+07, MSE(e): 2.053e-02, MSE(pi1): 7.632e-02, MSE(pi2): 1.175e-02, MSE(pi3): 1.628e-02\n",
      "Epoch 83100, Train loss: 2.074e+05, Test loss: 3.509e+07, MSE(e): 2.050e-02, MSE(pi1): 7.650e-02, MSE(pi2): 1.173e-02, MSE(pi3): 1.625e-02\n",
      "Epoch 83200, Train loss: 2.071e+05, Test loss: 3.509e+07, MSE(e): 2.047e-02, MSE(pi1): 7.595e-02, MSE(pi2): 1.171e-02, MSE(pi3): 1.627e-02\n",
      "Epoch 83300, Train loss: 2.068e+05, Test loss: 3.509e+07, MSE(e): 2.044e-02, MSE(pi1): 7.655e-02, MSE(pi2): 1.170e-02, MSE(pi3): 1.624e-02\n",
      "Epoch 83400, Train loss: 2.065e+05, Test loss: 3.510e+07, MSE(e): 2.041e-02, MSE(pi1): 7.563e-02, MSE(pi2): 1.168e-02, MSE(pi3): 1.626e-02\n",
      "Epoch 83500, Train loss: 2.062e+05, Test loss: 3.510e+07, MSE(e): 2.038e-02, MSE(pi1): 7.554e-02, MSE(pi2): 1.166e-02, MSE(pi3): 1.624e-02\n",
      "Epoch 83600, Train loss: 2.059e+05, Test loss: 3.511e+07, MSE(e): 2.035e-02, MSE(pi1): 7.554e-02, MSE(pi2): 1.165e-02, MSE(pi3): 1.622e-02\n",
      "Epoch 83700, Train loss: 2.058e+05, Test loss: 3.513e+07, MSE(e): 2.033e-02, MSE(pi1): 8.732e-02, MSE(pi2): 1.163e-02, MSE(pi3): 1.654e-02\n",
      "Epoch 83800, Train loss: 2.053e+05, Test loss: 3.512e+07, MSE(e): 2.029e-02, MSE(pi1): 7.518e-02, MSE(pi2): 1.161e-02, MSE(pi3): 1.621e-02\n",
      "Epoch 83900, Train loss: 2.050e+05, Test loss: 3.513e+07, MSE(e): 2.027e-02, MSE(pi1): 7.523e-02, MSE(pi2): 1.160e-02, MSE(pi3): 1.618e-02\n",
      "Epoch 84000, Train loss: 2.048e+05, Test loss: 3.513e+07, MSE(e): 2.024e-02, MSE(pi1): 7.491e-02, MSE(pi2): 1.158e-02, MSE(pi3): 1.618e-02\n",
      "Epoch 84100, Train loss: 2.045e+05, Test loss: 3.517e+07, MSE(e): 2.021e-02, MSE(pi1): 7.621e-02, MSE(pi2): 1.157e-02, MSE(pi3): 1.609e-02\n",
      "Epoch 84200, Train loss: 2.042e+05, Test loss: 3.515e+07, MSE(e): 2.018e-02, MSE(pi1): 7.476e-02, MSE(pi2): 1.155e-02, MSE(pi3): 1.615e-02\n",
      "Epoch 84300, Train loss: 2.039e+05, Test loss: 3.516e+07, MSE(e): 2.015e-02, MSE(pi1): 7.484e-02, MSE(pi2): 1.153e-02, MSE(pi3): 1.613e-02\n",
      "Epoch 84400, Train loss: 2.036e+05, Test loss: 3.517e+07, MSE(e): 2.012e-02, MSE(pi1): 7.458e-02, MSE(pi2): 1.151e-02, MSE(pi3): 1.612e-02\n",
      "Epoch 84500, Train loss: 2.033e+05, Test loss: 3.518e+07, MSE(e): 2.010e-02, MSE(pi1): 7.533e-02, MSE(pi2): 1.150e-02, MSE(pi3): 1.621e-02\n",
      "Epoch 84600, Train loss: 2.032e+05, Test loss: 3.517e+07, MSE(e): 2.007e-02, MSE(pi1): 8.728e-02, MSE(pi2): 1.148e-02, MSE(pi3): 1.591e-02\n",
      "Epoch 84700, Train loss: 2.027e+05, Test loss: 3.519e+07, MSE(e): 2.004e-02, MSE(pi1): 7.418e-02, MSE(pi2): 1.146e-02, MSE(pi3): 1.609e-02\n",
      "Epoch 84800, Train loss: 2.025e+05, Test loss: 3.518e+07, MSE(e): 2.001e-02, MSE(pi1): 7.412e-02, MSE(pi2): 1.145e-02, MSE(pi3): 1.608e-02\n",
      "Epoch 84900, Train loss: 2.022e+05, Test loss: 3.520e+07, MSE(e): 1.998e-02, MSE(pi1): 7.399e-02, MSE(pi2): 1.143e-02, MSE(pi3): 1.606e-02\n",
      "Epoch 85000, Train loss: 2.019e+05, Test loss: 3.520e+07, MSE(e): 1.995e-02, MSE(pi1): 7.469e-02, MSE(pi2): 1.142e-02, MSE(pi3): 1.608e-02\n",
      "Epoch 85100, Train loss: 2.016e+05, Test loss: 3.522e+07, MSE(e): 1.993e-02, MSE(pi1): 7.381e-02, MSE(pi2): 1.140e-02, MSE(pi3): 1.603e-02\n",
      "Epoch 85200, Train loss: 2.014e+05, Test loss: 3.522e+07, MSE(e): 1.990e-02, MSE(pi1): 7.366e-02, MSE(pi2): 1.139e-02, MSE(pi3): 1.609e-02\n",
      "Epoch 85300, Train loss: 2.011e+05, Test loss: 3.523e+07, MSE(e): 1.987e-02, MSE(pi1): 7.424e-02, MSE(pi2): 1.137e-02, MSE(pi3): 1.597e-02\n",
      "Epoch 85400, Train loss: 2.034e+05, Test loss: 3.510e+07, MSE(e): 2.011e-02, MSE(pi1): 7.315e-02, MSE(pi2): 1.150e-02, MSE(pi3): 1.644e-02\n",
      "Epoch 85500, Train loss: 2.005e+05, Test loss: 3.525e+07, MSE(e): 1.982e-02, MSE(pi1): 7.754e-02, MSE(pi2): 1.134e-02, MSE(pi3): 1.587e-02\n",
      "Epoch 85600, Train loss: 2.002e+05, Test loss: 3.526e+07, MSE(e): 1.979e-02, MSE(pi1): 7.314e-02, MSE(pi2): 1.132e-02, MSE(pi3): 1.598e-02\n",
      "Epoch 85700, Train loss: 1.999e+05, Test loss: 3.527e+07, MSE(e): 1.976e-02, MSE(pi1): 7.310e-02, MSE(pi2): 1.130e-02, MSE(pi3): 1.596e-02\n",
      "Epoch 85800, Train loss: 1.997e+05, Test loss: 3.526e+07, MSE(e): 1.974e-02, MSE(pi1): 7.314e-02, MSE(pi2): 1.129e-02, MSE(pi3): 1.597e-02\n",
      "Epoch 85900, Train loss: 1.994e+05, Test loss: 3.529e+07, MSE(e): 1.970e-02, MSE(pi1): 7.302e-02, MSE(pi2): 1.127e-02, MSE(pi3): 1.592e-02\n",
      "Epoch 86000, Train loss: 1.991e+05, Test loss: 3.530e+07, MSE(e): 1.968e-02, MSE(pi1): 7.281e-02, MSE(pi2): 1.126e-02, MSE(pi3): 1.591e-02\n",
      "Epoch 86100, Train loss: 1.988e+05, Test loss: 3.530e+07, MSE(e): 1.965e-02, MSE(pi1): 7.532e-02, MSE(pi2): 1.124e-02, MSE(pi3): 1.587e-02\n",
      "Epoch 86200, Train loss: 1.985e+05, Test loss: 3.531e+07, MSE(e): 1.962e-02, MSE(pi1): 7.250e-02, MSE(pi2): 1.122e-02, MSE(pi3): 1.590e-02\n",
      "Epoch 86300, Train loss: 1.983e+05, Test loss: 3.532e+07, MSE(e): 1.959e-02, MSE(pi1): 7.332e-02, MSE(pi2): 1.121e-02, MSE(pi3): 1.584e-02\n",
      "Epoch 86400, Train loss: 1.980e+05, Test loss: 3.533e+07, MSE(e): 1.957e-02, MSE(pi1): 7.238e-02, MSE(pi2): 1.119e-02, MSE(pi3): 1.586e-02\n",
      "Epoch 86500, Train loss: 1.977e+05, Test loss: 3.535e+07, MSE(e): 1.954e-02, MSE(pi1): 7.223e-02, MSE(pi2): 1.118e-02, MSE(pi3): 1.586e-02\n",
      "Epoch 86600, Train loss: 1.979e+05, Test loss: 3.528e+07, MSE(e): 1.955e-02, MSE(pi1): 7.212e-02, MSE(pi2): 1.118e-02, MSE(pi3): 1.597e-02\n",
      "Epoch 86700, Train loss: 1.972e+05, Test loss: 3.536e+07, MSE(e): 1.949e-02, MSE(pi1): 7.974e-02, MSE(pi2): 1.114e-02, MSE(pi3): 1.568e-02\n",
      "Epoch 86800, Train loss: 1.969e+05, Test loss: 3.537e+07, MSE(e): 1.946e-02, MSE(pi1): 7.196e-02, MSE(pi2): 1.113e-02, MSE(pi3): 1.581e-02\n",
      "Epoch 86900, Train loss: 1.966e+05, Test loss: 3.538e+07, MSE(e): 1.943e-02, MSE(pi1): 7.168e-02, MSE(pi2): 1.111e-02, MSE(pi3): 1.583e-02\n",
      "Epoch 87000, Train loss: 1.964e+05, Test loss: 3.539e+07, MSE(e): 1.940e-02, MSE(pi1): 7.391e-02, MSE(pi2): 1.110e-02, MSE(pi3): 1.585e-02\n",
      "Epoch 87100, Train loss: 1.961e+05, Test loss: 3.540e+07, MSE(e): 1.938e-02, MSE(pi1): 7.208e-02, MSE(pi2): 1.108e-02, MSE(pi3): 1.585e-02\n",
      "Epoch 87200, Train loss: 1.958e+05, Test loss: 3.541e+07, MSE(e): 1.935e-02, MSE(pi1): 7.142e-02, MSE(pi2): 1.107e-02, MSE(pi3): 1.577e-02\n",
      "Epoch 87300, Train loss: 1.955e+05, Test loss: 3.542e+07, MSE(e): 1.932e-02, MSE(pi1): 7.150e-02, MSE(pi2): 1.105e-02, MSE(pi3): 1.575e-02\n",
      "Epoch 87400, Train loss: 1.952e+05, Test loss: 3.544e+07, MSE(e): 1.929e-02, MSE(pi1): 7.130e-02, MSE(pi2): 1.103e-02, MSE(pi3): 1.574e-02\n",
      "Epoch 87500, Train loss: 1.950e+05, Test loss: 3.546e+07, MSE(e): 1.927e-02, MSE(pi1): 7.129e-02, MSE(pi2): 1.102e-02, MSE(pi3): 1.571e-02\n",
      "Epoch 87600, Train loss: 1.951e+05, Test loss: 3.543e+07, MSE(e): 1.928e-02, MSE(pi1): 7.312e-02, MSE(pi2): 1.102e-02, MSE(pi3): 1.590e-02\n",
      "Epoch 87700, Train loss: 1.944e+05, Test loss: 3.547e+07, MSE(e): 1.921e-02, MSE(pi1): 7.101e-02, MSE(pi2): 1.099e-02, MSE(pi3): 1.570e-02\n",
      "Epoch 87800, Train loss: 1.942e+05, Test loss: 3.545e+07, MSE(e): 1.919e-02, MSE(pi1): 7.056e-02, MSE(pi2): 1.097e-02, MSE(pi3): 1.577e-02\n",
      "Epoch 87900, Train loss: 1.939e+05, Test loss: 3.554e+07, MSE(e): 1.916e-02, MSE(pi1): 7.152e-02, MSE(pi2): 1.096e-02, MSE(pi3): 1.564e-02\n",
      "Epoch 88000, Train loss: 1.936e+05, Test loss: 3.550e+07, MSE(e): 1.913e-02, MSE(pi1): 7.065e-02, MSE(pi2): 1.094e-02, MSE(pi3): 1.566e-02\n",
      "Epoch 88100, Train loss: 1.933e+05, Test loss: 3.552e+07, MSE(e): 1.910e-02, MSE(pi1): 7.046e-02, MSE(pi2): 1.092e-02, MSE(pi3): 1.566e-02\n",
      "Epoch 88200, Train loss: 1.930e+05, Test loss: 3.553e+07, MSE(e): 1.907e-02, MSE(pi1): 7.051e-02, MSE(pi2): 1.091e-02, MSE(pi3): 1.563e-02\n",
      "Epoch 88300, Train loss: 1.941e+05, Test loss: 3.545e+07, MSE(e): 1.917e-02, MSE(pi1): 7.639e-02, MSE(pi2): 1.096e-02, MSE(pi3): 1.598e-02\n",
      "Epoch 88400, Train loss: 1.925e+05, Test loss: 3.555e+07, MSE(e): 1.902e-02, MSE(pi1): 7.074e-02, MSE(pi2): 1.088e-02, MSE(pi3): 1.561e-02\n",
      "Epoch 88500, Train loss: 1.922e+05, Test loss: 3.557e+07, MSE(e): 1.899e-02, MSE(pi1): 7.059e-02, MSE(pi2): 1.086e-02, MSE(pi3): 1.556e-02\n",
      "Epoch 88600, Train loss: 1.919e+05, Test loss: 3.557e+07, MSE(e): 1.896e-02, MSE(pi1): 6.990e-02, MSE(pi2): 1.084e-02, MSE(pi3): 1.560e-02\n",
      "Epoch 88700, Train loss: 1.916e+05, Test loss: 3.559e+07, MSE(e): 1.894e-02, MSE(pi1): 6.994e-02, MSE(pi2): 1.083e-02, MSE(pi3): 1.557e-02\n",
      "Epoch 88800, Train loss: 1.914e+05, Test loss: 3.558e+07, MSE(e): 1.891e-02, MSE(pi1): 7.073e-02, MSE(pi2): 1.081e-02, MSE(pi3): 1.559e-02\n",
      "Epoch 88900, Train loss: 1.911e+05, Test loss: 3.561e+07, MSE(e): 1.888e-02, MSE(pi1): 6.994e-02, MSE(pi2): 1.080e-02, MSE(pi3): 1.561e-02\n",
      "Epoch 89000, Train loss: 1.909e+05, Test loss: 3.563e+07, MSE(e): 1.886e-02, MSE(pi1): 7.012e-02, MSE(pi2): 1.078e-02, MSE(pi3): 1.548e-02\n",
      "Epoch 89100, Train loss: 1.906e+05, Test loss: 3.563e+07, MSE(e): 1.883e-02, MSE(pi1): 6.925e-02, MSE(pi2): 1.077e-02, MSE(pi3): 1.559e-02\n",
      "Epoch 89200, Train loss: 1.903e+05, Test loss: 3.564e+07, MSE(e): 1.880e-02, MSE(pi1): 6.934e-02, MSE(pi2): 1.075e-02, MSE(pi3): 1.553e-02\n",
      "Epoch 89300, Train loss: 1.900e+05, Test loss: 3.566e+07, MSE(e): 1.878e-02, MSE(pi1): 6.912e-02, MSE(pi2): 1.074e-02, MSE(pi3): 1.554e-02\n",
      "Epoch 89400, Train loss: 1.898e+05, Test loss: 3.564e+07, MSE(e): 1.876e-02, MSE(pi1): 6.924e-02, MSE(pi2): 1.072e-02, MSE(pi3): 1.554e-02\n",
      "Epoch 89500, Train loss: 1.895e+05, Test loss: 3.568e+07, MSE(e): 1.872e-02, MSE(pi1): 7.096e-02, MSE(pi2): 1.070e-02, MSE(pi3): 1.541e-02\n",
      "Epoch 89600, Train loss: 1.892e+05, Test loss: 3.571e+07, MSE(e): 1.870e-02, MSE(pi1): 6.942e-02, MSE(pi2): 1.069e-02, MSE(pi3): 1.543e-02\n",
      "Epoch 89700, Train loss: 1.895e+05, Test loss: 3.563e+07, MSE(e): 1.872e-02, MSE(pi1): 6.864e-02, MSE(pi2): 1.071e-02, MSE(pi3): 1.560e-02\n",
      "Epoch 89800, Train loss: 1.887e+05, Test loss: 3.572e+07, MSE(e): 1.864e-02, MSE(pi1): 6.867e-02, MSE(pi2): 1.066e-02, MSE(pi3): 1.545e-02\n",
      "Epoch 89900, Train loss: 1.884e+05, Test loss: 3.574e+07, MSE(e): 1.861e-02, MSE(pi1): 6.853e-02, MSE(pi2): 1.064e-02, MSE(pi3): 1.546e-02\n",
      "Epoch 90000, Train loss: 1.884e+05, Test loss: 3.570e+07, MSE(e): 1.861e-02, MSE(pi1): 6.806e-02, MSE(pi2): 1.064e-02, MSE(pi3): 1.553e-02\n",
      "Epoch 90100, Train loss: 1.878e+05, Test loss: 3.576e+07, MSE(e): 1.856e-02, MSE(pi1): 6.835e-02, MSE(pi2): 1.061e-02, MSE(pi3): 1.541e-02\n",
      "Epoch 90200, Train loss: 1.876e+05, Test loss: 3.576e+07, MSE(e): 1.853e-02, MSE(pi1): 6.819e-02, MSE(pi2): 1.060e-02, MSE(pi3): 1.542e-02\n",
      "Epoch 90300, Train loss: 1.873e+05, Test loss: 3.577e+07, MSE(e): 1.851e-02, MSE(pi1): 6.809e-02, MSE(pi2): 1.058e-02, MSE(pi3): 1.542e-02\n",
      "Epoch 90400, Train loss: 1.870e+05, Test loss: 3.581e+07, MSE(e): 1.848e-02, MSE(pi1): 6.794e-02, MSE(pi2): 1.056e-02, MSE(pi3): 1.540e-02\n",
      "Epoch 90500, Train loss: 1.867e+05, Test loss: 3.582e+07, MSE(e): 1.845e-02, MSE(pi1): 6.794e-02, MSE(pi2): 1.055e-02, MSE(pi3): 1.536e-02\n",
      "Epoch 90600, Train loss: 1.865e+05, Test loss: 3.583e+07, MSE(e): 1.843e-02, MSE(pi1): 6.810e-02, MSE(pi2): 1.053e-02, MSE(pi3): 1.535e-02\n",
      "Epoch 90700, Train loss: 1.862e+05, Test loss: 3.584e+07, MSE(e): 1.840e-02, MSE(pi1): 6.770e-02, MSE(pi2): 1.052e-02, MSE(pi3): 1.534e-02\n",
      "Epoch 90800, Train loss: 1.859e+05, Test loss: 3.586e+07, MSE(e): 1.837e-02, MSE(pi1): 6.774e-02, MSE(pi2): 1.050e-02, MSE(pi3): 1.531e-02\n",
      "Epoch 90900, Train loss: 1.857e+05, Test loss: 3.587e+07, MSE(e): 1.834e-02, MSE(pi1): 6.748e-02, MSE(pi2): 1.049e-02, MSE(pi3): 1.532e-02\n",
      "Epoch 91000, Train loss: 1.854e+05, Test loss: 3.588e+07, MSE(e): 1.832e-02, MSE(pi1): 6.862e-02, MSE(pi2): 1.047e-02, MSE(pi3): 1.524e-02\n",
      "Epoch 91100, Train loss: 1.853e+05, Test loss: 3.591e+07, MSE(e): 1.829e-02, MSE(pi1): 7.570e-02, MSE(pi2): 1.046e-02, MSE(pi3): 1.555e-02\n",
      "Epoch 91200, Train loss: 1.849e+05, Test loss: 3.591e+07, MSE(e): 1.826e-02, MSE(pi1): 6.721e-02, MSE(pi2): 1.044e-02, MSE(pi3): 1.527e-02\n",
      "Epoch 91300, Train loss: 1.847e+05, Test loss: 3.595e+07, MSE(e): 1.825e-02, MSE(pi1): 6.909e-02, MSE(pi2): 1.043e-02, MSE(pi3): 1.516e-02\n",
      "Epoch 91400, Train loss: 1.843e+05, Test loss: 3.594e+07, MSE(e): 1.821e-02, MSE(pi1): 6.699e-02, MSE(pi2): 1.041e-02, MSE(pi3): 1.525e-02\n",
      "Epoch 91500, Train loss: 1.841e+05, Test loss: 3.595e+07, MSE(e): 1.819e-02, MSE(pi1): 6.724e-02, MSE(pi2): 1.039e-02, MSE(pi3): 1.526e-02\n",
      "Epoch 91600, Train loss: 1.838e+05, Test loss: 3.597e+07, MSE(e): 1.816e-02, MSE(pi1): 6.703e-02, MSE(pi2): 1.038e-02, MSE(pi3): 1.521e-02\n",
      "Epoch 91700, Train loss: 1.835e+05, Test loss: 3.600e+07, MSE(e): 1.814e-02, MSE(pi1): 6.679e-02, MSE(pi2): 1.037e-02, MSE(pi3): 1.520e-02\n",
      "Epoch 91800, Train loss: 1.832e+05, Test loss: 3.600e+07, MSE(e): 1.811e-02, MSE(pi1): 6.676e-02, MSE(pi2): 1.035e-02, MSE(pi3): 1.519e-02\n",
      "Epoch 91900, Train loss: 1.830e+05, Test loss: 3.601e+07, MSE(e): 1.808e-02, MSE(pi1): 6.647e-02, MSE(pi2): 1.033e-02, MSE(pi3): 1.519e-02\n",
      "Epoch 92000, Train loss: 1.827e+05, Test loss: 3.603e+07, MSE(e): 1.805e-02, MSE(pi1): 6.650e-02, MSE(pi2): 1.032e-02, MSE(pi3): 1.516e-02\n",
      "Epoch 92100, Train loss: 1.824e+05, Test loss: 3.604e+07, MSE(e): 1.803e-02, MSE(pi1): 6.670e-02, MSE(pi2): 1.030e-02, MSE(pi3): 1.514e-02\n",
      "Epoch 92200, Train loss: 1.824e+05, Test loss: 3.601e+07, MSE(e): 1.802e-02, MSE(pi1): 6.858e-02, MSE(pi2): 1.030e-02, MSE(pi3): 1.522e-02\n",
      "Epoch 92300, Train loss: 1.819e+05, Test loss: 3.610e+07, MSE(e): 1.798e-02, MSE(pi1): 6.786e-02, MSE(pi2): 1.027e-02, MSE(pi3): 1.505e-02\n",
      "Epoch 92400, Train loss: 1.817e+05, Test loss: 3.607e+07, MSE(e): 1.795e-02, MSE(pi1): 6.602e-02, MSE(pi2): 1.026e-02, MSE(pi3): 1.514e-02\n",
      "Epoch 92500, Train loss: 1.814e+05, Test loss: 3.610e+07, MSE(e): 1.792e-02, MSE(pi1): 6.572e-02, MSE(pi2): 1.024e-02, MSE(pi3): 1.516e-02\n",
      "Epoch 92600, Train loss: 1.812e+05, Test loss: 3.615e+07, MSE(e): 1.790e-02, MSE(pi1): 6.741e-02, MSE(pi2): 1.023e-02, MSE(pi3): 1.508e-02\n",
      "Epoch 92700, Train loss: 1.809e+05, Test loss: 3.613e+07, MSE(e): 1.787e-02, MSE(pi1): 7.102e-02, MSE(pi2): 1.021e-02, MSE(pi3): 1.531e-02\n",
      "Epoch 92800, Train loss: 1.806e+05, Test loss: 3.615e+07, MSE(e): 1.784e-02, MSE(pi1): 6.545e-02, MSE(pi2): 1.019e-02, MSE(pi3): 1.509e-02\n",
      "Epoch 92900, Train loss: 1.803e+05, Test loss: 3.617e+07, MSE(e): 1.781e-02, MSE(pi1): 6.543e-02, MSE(pi2): 1.018e-02, MSE(pi3): 1.506e-02\n",
      "Epoch 93000, Train loss: 1.818e+05, Test loss: 3.603e+07, MSE(e): 1.795e-02, MSE(pi1): 7.169e-02, MSE(pi2): 1.026e-02, MSE(pi3): 1.531e-02\n",
      "Epoch 93100, Train loss: 1.798e+05, Test loss: 3.620e+07, MSE(e): 1.776e-02, MSE(pi1): 6.521e-02, MSE(pi2): 1.015e-02, MSE(pi3): 1.504e-02\n",
      "Epoch 93200, Train loss: 1.795e+05, Test loss: 3.621e+07, MSE(e): 1.773e-02, MSE(pi1): 6.668e-02, MSE(pi2): 1.013e-02, MSE(pi3): 1.502e-02\n",
      "Epoch 93300, Train loss: 1.792e+05, Test loss: 3.623e+07, MSE(e): 1.771e-02, MSE(pi1): 6.500e-02, MSE(pi2): 1.012e-02, MSE(pi3): 1.502e-02\n",
      "Epoch 93400, Train loss: 1.790e+05, Test loss: 3.624e+07, MSE(e): 1.768e-02, MSE(pi1): 6.507e-02, MSE(pi2): 1.010e-02, MSE(pi3): 1.502e-02\n",
      "Epoch 93500, Train loss: 1.787e+05, Test loss: 3.627e+07, MSE(e): 1.765e-02, MSE(pi1): 6.494e-02, MSE(pi2): 1.009e-02, MSE(pi3): 1.498e-02\n",
      "Epoch 93600, Train loss: 1.787e+05, Test loss: 3.630e+07, MSE(e): 1.766e-02, MSE(pi1): 6.576e-02, MSE(pi2): 1.009e-02, MSE(pi3): 1.488e-02\n",
      "Epoch 93700, Train loss: 1.782e+05, Test loss: 3.629e+07, MSE(e): 1.760e-02, MSE(pi1): 6.534e-02, MSE(pi2): 1.006e-02, MSE(pi3): 1.508e-02\n",
      "Epoch 93800, Train loss: 1.779e+05, Test loss: 3.630e+07, MSE(e): 1.757e-02, MSE(pi1): 6.504e-02, MSE(pi2): 1.004e-02, MSE(pi3): 1.497e-02\n",
      "Epoch 93900, Train loss: 1.776e+05, Test loss: 3.632e+07, MSE(e): 1.755e-02, MSE(pi1): 6.426e-02, MSE(pi2): 1.003e-02, MSE(pi3): 1.496e-02\n",
      "Epoch 94000, Train loss: 1.774e+05, Test loss: 3.633e+07, MSE(e): 1.752e-02, MSE(pi1): 6.426e-02, MSE(pi2): 1.001e-02, MSE(pi3): 1.494e-02\n",
      "Epoch 94100, Train loss: 1.771e+05, Test loss: 3.635e+07, MSE(e): 1.750e-02, MSE(pi1): 6.431e-02, MSE(pi2): 9.997e-03, MSE(pi3): 1.491e-02\n",
      "Epoch 94200, Train loss: 1.768e+05, Test loss: 3.638e+07, MSE(e): 1.747e-02, MSE(pi1): 6.414e-02, MSE(pi2): 9.982e-03, MSE(pi3): 1.493e-02\n",
      "Epoch 94300, Train loss: 1.766e+05, Test loss: 3.639e+07, MSE(e): 1.744e-02, MSE(pi1): 6.436e-02, MSE(pi2): 9.967e-03, MSE(pi3): 1.487e-02\n",
      "Epoch 94400, Train loss: 1.765e+05, Test loss: 3.637e+07, MSE(e): 1.743e-02, MSE(pi1): 6.505e-02, MSE(pi2): 9.960e-03, MSE(pi3): 1.491e-02\n",
      "Epoch 94500, Train loss: 1.761e+05, Test loss: 3.639e+07, MSE(e): 1.740e-02, MSE(pi1): 6.527e-02, MSE(pi2): 9.940e-03, MSE(pi3): 1.484e-02\n",
      "Epoch 94600, Train loss: 1.764e+05, Test loss: 3.652e+07, MSE(e): 1.742e-02, MSE(pi1): 6.550e-02, MSE(pi2): 9.958e-03, MSE(pi3): 1.478e-02\n",
      "Epoch 94700, Train loss: 1.757e+05, Test loss: 3.645e+07, MSE(e): 1.734e-02, MSE(pi1): 7.835e-02, MSE(pi2): 9.907e-03, MSE(pi3): 1.467e-02\n",
      "Epoch 94800, Train loss: 1.752e+05, Test loss: 3.647e+07, MSE(e): 1.731e-02, MSE(pi1): 6.339e-02, MSE(pi2): 9.891e-03, MSE(pi3): 1.484e-02\n",
      "Epoch 94900, Train loss: 1.751e+05, Test loss: 3.652e+07, MSE(e): 1.730e-02, MSE(pi1): 6.487e-02, MSE(pi2): 9.883e-03, MSE(pi3): 1.476e-02\n",
      "Epoch 95000, Train loss: 1.747e+05, Test loss: 3.650e+07, MSE(e): 1.726e-02, MSE(pi1): 6.323e-02, MSE(pi2): 9.861e-03, MSE(pi3): 1.481e-02\n",
      "Epoch 95100, Train loss: 1.745e+05, Test loss: 3.652e+07, MSE(e): 1.723e-02, MSE(pi1): 6.323e-02, MSE(pi2): 9.846e-03, MSE(pi3): 1.479e-02\n",
      "Epoch 95200, Train loss: 1.742e+05, Test loss: 3.655e+07, MSE(e): 1.721e-02, MSE(pi1): 6.407e-02, MSE(pi2): 9.833e-03, MSE(pi3): 1.476e-02\n",
      "Epoch 95300, Train loss: 1.739e+05, Test loss: 3.655e+07, MSE(e): 1.718e-02, MSE(pi1): 6.302e-02, MSE(pi2): 9.815e-03, MSE(pi3): 1.477e-02\n",
      "Epoch 95400, Train loss: 1.737e+05, Test loss: 3.657e+07, MSE(e): 1.715e-02, MSE(pi1): 6.287e-02, MSE(pi2): 9.800e-03, MSE(pi3): 1.475e-02\n",
      "Epoch 95500, Train loss: 1.734e+05, Test loss: 3.659e+07, MSE(e): 1.713e-02, MSE(pi1): 6.292e-02, MSE(pi2): 9.785e-03, MSE(pi3): 1.475e-02\n",
      "Epoch 95600, Train loss: 1.731e+05, Test loss: 3.660e+07, MSE(e): 1.710e-02, MSE(pi1): 6.300e-02, MSE(pi2): 9.770e-03, MSE(pi3): 1.471e-02\n",
      "Epoch 95700, Train loss: 1.729e+05, Test loss: 3.660e+07, MSE(e): 1.708e-02, MSE(pi1): 6.815e-02, MSE(pi2): 9.756e-03, MSE(pi3): 1.464e-02\n",
      "Epoch 95800, Train loss: 1.730e+05, Test loss: 3.658e+07, MSE(e): 1.709e-02, MSE(pi1): 6.806e-02, MSE(pi2): 9.763e-03, MSE(pi3): 1.470e-02\n",
      "Epoch 95900, Train loss: 1.727e+05, Test loss: 3.671e+07, MSE(e): 1.706e-02, MSE(pi1): 6.365e-02, MSE(pi2): 9.747e-03, MSE(pi3): 1.462e-02\n",
      "Epoch 96000, Train loss: 1.721e+05, Test loss: 3.668e+07, MSE(e): 1.700e-02, MSE(pi1): 6.321e-02, MSE(pi2): 9.710e-03, MSE(pi3): 1.462e-02\n",
      "Epoch 96100, Train loss: 1.718e+05, Test loss: 3.669e+07, MSE(e): 1.697e-02, MSE(pi1): 6.217e-02, MSE(pi2): 9.695e-03, MSE(pi3): 1.467e-02\n",
      "Epoch 96200, Train loss: 1.715e+05, Test loss: 3.670e+07, MSE(e): 1.695e-02, MSE(pi1): 6.206e-02, MSE(pi2): 9.679e-03, MSE(pi3): 1.468e-02\n",
      "Epoch 96300, Train loss: 1.713e+05, Test loss: 3.672e+07, MSE(e): 1.692e-02, MSE(pi1): 6.292e-02, MSE(pi2): 9.664e-03, MSE(pi3): 1.460e-02\n",
      "Epoch 96400, Train loss: 1.710e+05, Test loss: 3.674e+07, MSE(e): 1.689e-02, MSE(pi1): 6.173e-02, MSE(pi2): 9.649e-03, MSE(pi3): 1.465e-02\n",
      "Epoch 96500, Train loss: 1.708e+05, Test loss: 3.675e+07, MSE(e): 1.687e-02, MSE(pi1): 6.168e-02, MSE(pi2): 9.636e-03, MSE(pi3): 1.465e-02\n",
      "Epoch 96600, Train loss: 1.705e+05, Test loss: 3.678e+07, MSE(e): 1.684e-02, MSE(pi1): 6.156e-02, MSE(pi2): 9.619e-03, MSE(pi3): 1.462e-02\n",
      "Epoch 96700, Train loss: 1.703e+05, Test loss: 3.679e+07, MSE(e): 1.682e-02, MSE(pi1): 6.849e-02, MSE(pi2): 9.605e-03, MSE(pi3): 1.445e-02\n",
      "Epoch 96800, Train loss: 1.700e+05, Test loss: 3.678e+07, MSE(e): 1.679e-02, MSE(pi1): 6.562e-02, MSE(pi2): 9.590e-03, MSE(pi3): 1.457e-02\n",
      "Epoch 96900, Train loss: 1.697e+05, Test loss: 3.683e+07, MSE(e): 1.676e-02, MSE(pi1): 6.161e-02, MSE(pi2): 9.574e-03, MSE(pi3): 1.465e-02\n",
      "Epoch 97000, Train loss: 1.695e+05, Test loss: 3.686e+07, MSE(e): 1.674e-02, MSE(pi1): 6.129e-02, MSE(pi2): 9.561e-03, MSE(pi3): 1.455e-02\n",
      "Epoch 97100, Train loss: 1.692e+05, Test loss: 3.686e+07, MSE(e): 1.671e-02, MSE(pi1): 6.643e-02, MSE(pi2): 9.545e-03, MSE(pi3): 1.443e-02\n",
      "Epoch 97200, Train loss: 1.689e+05, Test loss: 3.688e+07, MSE(e): 1.669e-02, MSE(pi1): 6.108e-02, MSE(pi2): 9.530e-03, MSE(pi3): 1.455e-02\n",
      "Epoch 97300, Train loss: 1.687e+05, Test loss: 3.690e+07, MSE(e): 1.666e-02, MSE(pi1): 6.473e-02, MSE(pi2): 9.515e-03, MSE(pi3): 1.446e-02\n",
      "Epoch 97400, Train loss: 1.684e+05, Test loss: 3.692e+07, MSE(e): 1.663e-02, MSE(pi1): 6.080e-02, MSE(pi2): 9.500e-03, MSE(pi3): 1.451e-02\n",
      "Epoch 97500, Train loss: 1.683e+05, Test loss: 3.693e+07, MSE(e): 1.662e-02, MSE(pi1): 6.274e-02, MSE(pi2): 9.490e-03, MSE(pi3): 1.456e-02\n",
      "Epoch 97600, Train loss: 1.679e+05, Test loss: 3.695e+07, MSE(e): 1.658e-02, MSE(pi1): 6.061e-02, MSE(pi2): 9.470e-03, MSE(pi3): 1.449e-02\n",
      "Epoch 97700, Train loss: 1.676e+05, Test loss: 3.697e+07, MSE(e): 1.656e-02, MSE(pi1): 6.053e-02, MSE(pi2): 9.455e-03, MSE(pi3): 1.448e-02\n",
      "Epoch 97800, Train loss: 1.686e+05, Test loss: 3.691e+07, MSE(e): 1.665e-02, MSE(pi1): 6.766e-02, MSE(pi2): 9.509e-03, MSE(pi3): 1.464e-02\n",
      "Epoch 97900, Train loss: 1.671e+05, Test loss: 3.701e+07, MSE(e): 1.650e-02, MSE(pi1): 6.090e-02, MSE(pi2): 9.425e-03, MSE(pi3): 1.442e-02\n",
      "Epoch 98000, Train loss: 1.669e+05, Test loss: 3.700e+07, MSE(e): 1.648e-02, MSE(pi1): 5.992e-02, MSE(pi2): 9.414e-03, MSE(pi3): 1.450e-02\n",
      "Epoch 98100, Train loss: 1.668e+05, Test loss: 3.697e+07, MSE(e): 1.647e-02, MSE(pi1): 6.113e-02, MSE(pi2): 9.407e-03, MSE(pi3): 1.454e-02\n",
      "Epoch 98200, Train loss: 1.663e+05, Test loss: 3.706e+07, MSE(e): 1.643e-02, MSE(pi1): 5.994e-02, MSE(pi2): 9.381e-03, MSE(pi3): 1.443e-02\n",
      "Epoch 98300, Train loss: 1.661e+05, Test loss: 3.708e+07, MSE(e): 1.640e-02, MSE(pi1): 5.978e-02, MSE(pi2): 9.365e-03, MSE(pi3): 1.442e-02\n",
      "Epoch 98400, Train loss: 1.658e+05, Test loss: 3.709e+07, MSE(e): 1.638e-02, MSE(pi1): 5.983e-02, MSE(pi2): 9.351e-03, MSE(pi3): 1.447e-02\n",
      "Epoch 98500, Train loss: 1.668e+05, Test loss: 3.701e+07, MSE(e): 1.647e-02, MSE(pi1): 5.949e-02, MSE(pi2): 9.408e-03, MSE(pi3): 1.464e-02\n",
      "Epoch 98600, Train loss: 1.653e+05, Test loss: 3.713e+07, MSE(e): 1.632e-02, MSE(pi1): 5.964e-02, MSE(pi2): 9.321e-03, MSE(pi3): 1.438e-02\n",
      "Epoch 98700, Train loss: 1.650e+05, Test loss: 3.715e+07, MSE(e): 1.630e-02, MSE(pi1): 5.950e-02, MSE(pi2): 9.306e-03, MSE(pi3): 1.440e-02\n",
      "Epoch 98800, Train loss: 1.649e+05, Test loss: 3.713e+07, MSE(e): 1.628e-02, MSE(pi1): 5.894e-02, MSE(pi2): 9.297e-03, MSE(pi3): 1.445e-02\n",
      "Epoch 98900, Train loss: 1.645e+05, Test loss: 3.719e+07, MSE(e): 1.625e-02, MSE(pi1): 6.022e-02, MSE(pi2): 9.276e-03, MSE(pi3): 1.428e-02\n",
      "Epoch 99000, Train loss: 1.642e+05, Test loss: 3.720e+07, MSE(e): 1.622e-02, MSE(pi1): 5.928e-02, MSE(pi2): 9.261e-03, MSE(pi3): 1.432e-02\n",
      "Epoch 99100, Train loss: 1.640e+05, Test loss: 3.723e+07, MSE(e): 1.619e-02, MSE(pi1): 5.937e-02, MSE(pi2): 9.246e-03, MSE(pi3): 1.429e-02\n",
      "Epoch 99200, Train loss: 1.637e+05, Test loss: 3.724e+07, MSE(e): 1.617e-02, MSE(pi1): 5.893e-02, MSE(pi2): 9.231e-03, MSE(pi3): 1.434e-02\n",
      "Epoch 99300, Train loss: 1.635e+05, Test loss: 3.722e+07, MSE(e): 1.614e-02, MSE(pi1): 6.199e-02, MSE(pi2): 9.216e-03, MSE(pi3): 1.438e-02\n",
      "Epoch 99400, Train loss: 1.632e+05, Test loss: 3.728e+07, MSE(e): 1.612e-02, MSE(pi1): 5.882e-02, MSE(pi2): 9.202e-03, MSE(pi3): 1.427e-02\n",
      "Epoch 99500, Train loss: 1.637e+05, Test loss: 3.720e+07, MSE(e): 1.616e-02, MSE(pi1): 6.195e-02, MSE(pi2): 9.230e-03, MSE(pi3): 1.442e-02\n",
      "Epoch 99600, Train loss: 1.627e+05, Test loss: 3.731e+07, MSE(e): 1.607e-02, MSE(pi1): 6.074e-02, MSE(pi2): 9.172e-03, MSE(pi3): 1.441e-02\n",
      "Epoch 99700, Train loss: 1.624e+05, Test loss: 3.733e+07, MSE(e): 1.604e-02, MSE(pi1): 5.855e-02, MSE(pi2): 9.157e-03, MSE(pi3): 1.423e-02\n",
      "Epoch 99800, Train loss: 1.622e+05, Test loss: 3.734e+07, MSE(e): 1.602e-02, MSE(pi1): 5.858e-02, MSE(pi2): 9.143e-03, MSE(pi3): 1.427e-02\n",
      "Epoch 99900, Train loss: 1.619e+05, Test loss: 3.738e+07, MSE(e): 1.599e-02, MSE(pi1): 5.902e-02, MSE(pi2): 9.128e-03, MSE(pi3): 1.425e-02\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "params_to_update = filter(lambda p: p.requires_grad, pretrained_pgnniv.parameters())\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=3e-4)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "train_loop(pretrained_pgnniv, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_epoch = n_epochs-1\n",
    "# n_epochs = 20000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 5\n",
    "\n",
    "# second_lr = 3e-4\n",
    "\n",
    "# train_loop(pretrained_pgnniv, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f76f302e180>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
