{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import GPUtil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import gc\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from utils.checkpoints import load_results\n",
    "\n",
    "from architectures.pgnniv_baseline import PGNNIVBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_1000\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_1000/transfer\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear/sigmoid_nonlinear.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_1000')\n",
    "\n",
    "PRETRAINED_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/non_linear_1000_0/baseline_model_10')\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_1000/transfer')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_TRANSFERLEARNING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear/sigmoid_nonlinear.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 800\n",
      "Validation dataset length: 200\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X_train, y_train, K_train, f_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other parameters\n",
    "n_filters_explanatory = 5\n",
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_autoencoder = PretrainedAutoencoder(autoencoder_input_shape, latent_space_dim, autoencoder_output_shape).to(DEVICE)\n",
    "pretrained_pgnniv = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(pretrained_pgnniv.parameters(), lr=1e-4)\n",
    "pretrained_pgnniv, optimizer, lists = load_results(pretrained_pgnniv, optimizer, PRETRAINED_RESULTS_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa5c83febd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgnniv_pretrained_encoder = pretrained_pgnniv.encoder\n",
    "pgnniv_pretrained_decoder = pretrained_pgnniv.decoder\n",
    "pgnniv_pretrained_exp = pretrained_pgnniv.explanatory\n",
    "\n",
    "for param in pgnniv_pretrained_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in pgnniv_pretrained_decoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pgnniv_pretrained_exp.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def reinitialize_model(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            # Reinitialize Conv2d weights and biases\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            # Reinitialize Linear weights and biases\n",
    "            nn.init.kaiming_uniform_(module.weight, a=math.sqrt(5))\n",
    "            if module.bias is not None:\n",
    "                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(module.weight)\n",
    "                bound = 1 / math.sqrt(fan_in)\n",
    "                nn.init.uniform_(module.bias, -bound, bound)\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            # Reinitialize BatchNorm layers\n",
    "            nn.init.constant_(module.weight, 1)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "\n",
    "# reinitialize_model(pgnniv_pretrained_decoder)\n",
    "# reinitialize_model(pgnniv_pretrained_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 4.144e+08, Test loss: 4.307e+08, MSE(e): 4.139e+01, MSE(pi1): 2.618e+01, MSE(pi2): 1.766e+01, MSE(pi3): 2.141e+00\n",
      "Epoch 100, Train loss: 1.267e+08, Test loss: 1.373e+08, MSE(e): 1.263e+01, MSE(pi1): 2.288e+01, MSE(pi2): 5.758e+00, MSE(pi3): 1.673e+00\n",
      "Epoch 200, Train loss: 9.338e+07, Test loss: 9.920e+07, MSE(e): 9.321e+00, MSE(pi1): 7.595e+00, MSE(pi2): 4.351e+00, MSE(pi3): 8.270e-01\n",
      "Epoch 300, Train loss: 8.589e+07, Test loss: 9.179e+07, MSE(e): 8.577e+00, MSE(pi1): 5.367e+00, MSE(pi2): 3.824e+00, MSE(pi3): 6.117e-01\n",
      "Epoch 400, Train loss: 7.947e+07, Test loss: 8.551e+07, MSE(e): 7.937e+00, MSE(pi1): 4.593e+00, MSE(pi2): 3.429e+00, MSE(pi3): 5.340e-01\n",
      "Epoch 500, Train loss: 7.283e+07, Test loss: 7.898e+07, MSE(e): 7.274e+00, MSE(pi1): 3.973e+00, MSE(pi2): 3.080e+00, MSE(pi3): 4.873e-01\n",
      "Epoch 600, Train loss: 6.604e+07, Test loss: 7.221e+07, MSE(e): 6.596e+00, MSE(pi1): 3.335e+00, MSE(pi2): 2.789e+00, MSE(pi3): 4.463e-01\n",
      "Epoch 700, Train loss: 5.901e+07, Test loss: 6.523e+07, MSE(e): 5.894e+00, MSE(pi1): 2.768e+00, MSE(pi2): 2.510e+00, MSE(pi3): 4.157e-01\n",
      "Epoch 800, Train loss: 5.190e+07, Test loss: 5.805e+07, MSE(e): 5.183e+00, MSE(pi1): 2.425e+00, MSE(pi2): 2.226e+00, MSE(pi3): 3.900e-01\n",
      "Epoch 900, Train loss: 4.546e+07, Test loss: 5.130e+07, MSE(e): 4.539e+00, MSE(pi1): 2.248e+00, MSE(pi2): 1.966e+00, MSE(pi3): 3.706e-01\n",
      "Epoch 1000, Train loss: 4.033e+07, Test loss: 4.574e+07, MSE(e): 4.027e+00, MSE(pi1): 2.203e+00, MSE(pi2): 1.758e+00, MSE(pi3): 3.612e-01\n",
      "Epoch 1100, Train loss: 3.650e+07, Test loss: 4.150e+07, MSE(e): 3.644e+00, MSE(pi1): 2.215e+00, MSE(pi2): 1.602e+00, MSE(pi3): 3.582e-01\n",
      "Epoch 1200, Train loss: 3.367e+07, Test loss: 3.827e+07, MSE(e): 3.361e+00, MSE(pi1): 2.215e+00, MSE(pi2): 1.484e+00, MSE(pi3): 3.560e-01\n",
      "Epoch 1300, Train loss: 3.152e+07, Test loss: 3.571e+07, MSE(e): 3.146e+00, MSE(pi1): 2.170e+00, MSE(pi2): 1.393e+00, MSE(pi3): 3.516e-01\n",
      "Epoch 1400, Train loss: 2.984e+07, Test loss: 3.361e+07, MSE(e): 2.978e+00, MSE(pi1): 2.088e+00, MSE(pi2): 1.320e+00, MSE(pi3): 3.451e-01\n",
      "Epoch 1500, Train loss: 2.847e+07, Test loss: 3.184e+07, MSE(e): 2.841e+00, MSE(pi1): 1.991e+00, MSE(pi2): 1.260e+00, MSE(pi3): 3.374e-01\n",
      "Epoch 1600, Train loss: 2.732e+07, Test loss: 3.035e+07, MSE(e): 2.726e+00, MSE(pi1): 1.894e+00, MSE(pi2): 1.210e+00, MSE(pi3): 3.296e-01\n",
      "Epoch 1700, Train loss: 2.633e+07, Test loss: 2.909e+07, MSE(e): 2.628e+00, MSE(pi1): 1.806e+00, MSE(pi2): 1.167e+00, MSE(pi3): 3.220e-01\n",
      "Epoch 1800, Train loss: 2.546e+07, Test loss: 2.800e+07, MSE(e): 2.541e+00, MSE(pi1): 1.729e+00, MSE(pi2): 1.130e+00, MSE(pi3): 3.149e-01\n",
      "Epoch 1900, Train loss: 2.468e+07, Test loss: 2.705e+07, MSE(e): 2.464e+00, MSE(pi1): 1.661e+00, MSE(pi2): 1.097e+00, MSE(pi3): 3.084e-01\n",
      "Epoch 2000, Train loss: 2.398e+07, Test loss: 2.619e+07, MSE(e): 2.393e+00, MSE(pi1): 1.603e+00, MSE(pi2): 1.068e+00, MSE(pi3): 3.024e-01\n",
      "Epoch 2100, Train loss: 2.333e+07, Test loss: 2.541e+07, MSE(e): 2.328e+00, MSE(pi1): 1.551e+00, MSE(pi2): 1.041e+00, MSE(pi3): 2.970e-01\n",
      "Epoch 2200, Train loss: 2.273e+07, Test loss: 2.469e+07, MSE(e): 2.268e+00, MSE(pi1): 1.505e+00, MSE(pi2): 1.016e+00, MSE(pi3): 2.921e-01\n",
      "Epoch 2300, Train loss: 2.216e+07, Test loss: 2.401e+07, MSE(e): 2.212e+00, MSE(pi1): 1.463e+00, MSE(pi2): 9.922e-01, MSE(pi3): 2.875e-01\n",
      "Epoch 2400, Train loss: 2.163e+07, Test loss: 2.338e+07, MSE(e): 2.159e+00, MSE(pi1): 1.424e+00, MSE(pi2): 9.704e-01, MSE(pi3): 2.833e-01\n",
      "Epoch 2500, Train loss: 2.113e+07, Test loss: 2.278e+07, MSE(e): 2.109e+00, MSE(pi1): 1.388e+00, MSE(pi2): 9.499e-01, MSE(pi3): 2.794e-01\n",
      "Epoch 2600, Train loss: 2.066e+07, Test loss: 2.221e+07, MSE(e): 2.062e+00, MSE(pi1): 1.354e+00, MSE(pi2): 9.305e-01, MSE(pi3): 2.757e-01\n",
      "Epoch 2700, Train loss: 2.021e+07, Test loss: 2.168e+07, MSE(e): 2.017e+00, MSE(pi1): 1.322e+00, MSE(pi2): 9.122e-01, MSE(pi3): 2.721e-01\n",
      "Epoch 2800, Train loss: 1.979e+07, Test loss: 2.116e+07, MSE(e): 1.975e+00, MSE(pi1): 1.291e+00, MSE(pi2): 8.949e-01, MSE(pi3): 2.686e-01\n",
      "Epoch 2900, Train loss: 1.939e+07, Test loss: 2.067e+07, MSE(e): 1.935e+00, MSE(pi1): 1.262e+00, MSE(pi2): 8.785e-01, MSE(pi3): 2.652e-01\n",
      "Epoch 3000, Train loss: 1.901e+07, Test loss: 2.019e+07, MSE(e): 1.898e+00, MSE(pi1): 1.234e+00, MSE(pi2): 8.629e-01, MSE(pi3): 2.620e-01\n",
      "Epoch 3100, Train loss: 1.866e+07, Test loss: 1.974e+07, MSE(e): 1.862e+00, MSE(pi1): 1.209e+00, MSE(pi2): 8.482e-01, MSE(pi3): 2.591e-01\n",
      "Epoch 3200, Train loss: 1.833e+07, Test loss: 1.930e+07, MSE(e): 1.829e+00, MSE(pi1): 1.187e+00, MSE(pi2): 8.344e-01, MSE(pi3): 2.564e-01\n",
      "Epoch 3300, Train loss: 1.802e+07, Test loss: 1.889e+07, MSE(e): 1.798e+00, MSE(pi1): 1.166e+00, MSE(pi2): 8.214e-01, MSE(pi3): 2.540e-01\n",
      "Epoch 3400, Train loss: 1.773e+07, Test loss: 1.850e+07, MSE(e): 1.769e+00, MSE(pi1): 1.146e+00, MSE(pi2): 8.092e-01, MSE(pi3): 2.519e-01\n",
      "Epoch 3500, Train loss: 1.746e+07, Test loss: 1.812e+07, MSE(e): 1.742e+00, MSE(pi1): 1.129e+00, MSE(pi2): 7.977e-01, MSE(pi3): 2.499e-01\n",
      "Epoch 3600, Train loss: 1.720e+07, Test loss: 1.777e+07, MSE(e): 1.716e+00, MSE(pi1): 1.112e+00, MSE(pi2): 7.869e-01, MSE(pi3): 2.482e-01\n",
      "Epoch 3700, Train loss: 1.696e+07, Test loss: 1.743e+07, MSE(e): 1.692e+00, MSE(pi1): 1.096e+00, MSE(pi2): 7.768e-01, MSE(pi3): 2.467e-01\n",
      "Epoch 3800, Train loss: 1.673e+07, Test loss: 1.711e+07, MSE(e): 1.670e+00, MSE(pi1): 1.081e+00, MSE(pi2): 7.672e-01, MSE(pi3): 2.453e-01\n",
      "Epoch 3900, Train loss: 1.652e+07, Test loss: 1.681e+07, MSE(e): 1.648e+00, MSE(pi1): 1.066e+00, MSE(pi2): 7.580e-01, MSE(pi3): 2.440e-01\n",
      "Epoch 4000, Train loss: 1.632e+07, Test loss: 1.653e+07, MSE(e): 1.628e+00, MSE(pi1): 1.053e+00, MSE(pi2): 7.493e-01, MSE(pi3): 2.428e-01\n",
      "Epoch 4100, Train loss: 1.612e+07, Test loss: 1.626e+07, MSE(e): 1.609e+00, MSE(pi1): 1.039e+00, MSE(pi2): 7.410e-01, MSE(pi3): 2.417e-01\n",
      "Epoch 4200, Train loss: 1.594e+07, Test loss: 1.600e+07, MSE(e): 1.590e+00, MSE(pi1): 1.027e+00, MSE(pi2): 7.331e-01, MSE(pi3): 2.407e-01\n",
      "Epoch 4300, Train loss: 1.576e+07, Test loss: 1.576e+07, MSE(e): 1.572e+00, MSE(pi1): 1.015e+00, MSE(pi2): 7.254e-01, MSE(pi3): 2.396e-01\n",
      "Epoch 4400, Train loss: 1.559e+07, Test loss: 1.554e+07, MSE(e): 1.555e+00, MSE(pi1): 1.004e+00, MSE(pi2): 7.181e-01, MSE(pi3): 2.387e-01\n",
      "Epoch 4500, Train loss: 1.542e+07, Test loss: 1.532e+07, MSE(e): 1.538e+00, MSE(pi1): 9.933e-01, MSE(pi2): 7.110e-01, MSE(pi3): 2.377e-01\n",
      "Epoch 4600, Train loss: 1.526e+07, Test loss: 1.512e+07, MSE(e): 1.522e+00, MSE(pi1): 9.832e-01, MSE(pi2): 7.041e-01, MSE(pi3): 2.368e-01\n",
      "Epoch 4700, Train loss: 1.510e+07, Test loss: 1.493e+07, MSE(e): 1.507e+00, MSE(pi1): 9.736e-01, MSE(pi2): 6.975e-01, MSE(pi3): 2.359e-01\n",
      "Epoch 4800, Train loss: 1.495e+07, Test loss: 1.474e+07, MSE(e): 1.492e+00, MSE(pi1): 9.645e-01, MSE(pi2): 6.910e-01, MSE(pi3): 2.350e-01\n",
      "Epoch 4900, Train loss: 1.480e+07, Test loss: 1.457e+07, MSE(e): 1.477e+00, MSE(pi1): 9.558e-01, MSE(pi2): 6.848e-01, MSE(pi3): 2.342e-01\n",
      "Epoch 5000, Train loss: 1.466e+07, Test loss: 1.441e+07, MSE(e): 1.463e+00, MSE(pi1): 9.475e-01, MSE(pi2): 6.787e-01, MSE(pi3): 2.333e-01\n",
      "Epoch 5100, Train loss: 1.452e+07, Test loss: 1.426e+07, MSE(e): 1.449e+00, MSE(pi1): 9.396e-01, MSE(pi2): 6.728e-01, MSE(pi3): 2.325e-01\n",
      "Epoch 5200, Train loss: 1.438e+07, Test loss: 1.411e+07, MSE(e): 1.435e+00, MSE(pi1): 9.321e-01, MSE(pi2): 6.670e-01, MSE(pi3): 2.317e-01\n",
      "Epoch 5300, Train loss: 1.425e+07, Test loss: 1.398e+07, MSE(e): 1.422e+00, MSE(pi1): 9.248e-01, MSE(pi2): 6.614e-01, MSE(pi3): 2.309e-01\n",
      "Epoch 5400, Train loss: 1.412e+07, Test loss: 1.385e+07, MSE(e): 1.408e+00, MSE(pi1): 9.178e-01, MSE(pi2): 6.558e-01, MSE(pi3): 2.301e-01\n",
      "Epoch 5500, Train loss: 1.399e+07, Test loss: 1.372e+07, MSE(e): 1.396e+00, MSE(pi1): 9.111e-01, MSE(pi2): 6.504e-01, MSE(pi3): 2.293e-01\n",
      "Epoch 5600, Train loss: 1.386e+07, Test loss: 1.361e+07, MSE(e): 1.383e+00, MSE(pi1): 9.045e-01, MSE(pi2): 6.451e-01, MSE(pi3): 2.285e-01\n",
      "Epoch 5700, Train loss: 1.374e+07, Test loss: 1.350e+07, MSE(e): 1.370e+00, MSE(pi1): 8.982e-01, MSE(pi2): 6.399e-01, MSE(pi3): 2.277e-01\n",
      "Epoch 5800, Train loss: 1.361e+07, Test loss: 1.339e+07, MSE(e): 1.358e+00, MSE(pi1): 8.921e-01, MSE(pi2): 6.347e-01, MSE(pi3): 2.270e-01\n",
      "Epoch 5900, Train loss: 1.349e+07, Test loss: 1.330e+07, MSE(e): 1.346e+00, MSE(pi1): 8.862e-01, MSE(pi2): 6.297e-01, MSE(pi3): 2.263e-01\n",
      "Epoch 6000, Train loss: 1.337e+07, Test loss: 1.320e+07, MSE(e): 1.334e+00, MSE(pi1): 8.805e-01, MSE(pi2): 6.247e-01, MSE(pi3): 2.256e-01\n",
      "Epoch 6100, Train loss: 1.325e+07, Test loss: 1.311e+07, MSE(e): 1.322e+00, MSE(pi1): 8.750e-01, MSE(pi2): 6.197e-01, MSE(pi3): 2.249e-01\n",
      "Epoch 6200, Train loss: 1.314e+07, Test loss: 1.303e+07, MSE(e): 1.310e+00, MSE(pi1): 8.696e-01, MSE(pi2): 6.148e-01, MSE(pi3): 2.242e-01\n",
      "Epoch 6300, Train loss: 1.302e+07, Test loss: 1.295e+07, MSE(e): 1.299e+00, MSE(pi1): 8.644e-01, MSE(pi2): 6.100e-01, MSE(pi3): 2.235e-01\n",
      "Epoch 6400, Train loss: 1.290e+07, Test loss: 1.287e+07, MSE(e): 1.287e+00, MSE(pi1): 8.594e-01, MSE(pi2): 6.051e-01, MSE(pi3): 2.229e-01\n",
      "Epoch 6500, Train loss: 1.279e+07, Test loss: 1.280e+07, MSE(e): 1.276e+00, MSE(pi1): 8.545e-01, MSE(pi2): 6.004e-01, MSE(pi3): 2.222e-01\n",
      "Epoch 6600, Train loss: 1.268e+07, Test loss: 1.273e+07, MSE(e): 1.265e+00, MSE(pi1): 8.498e-01, MSE(pi2): 5.957e-01, MSE(pi3): 2.216e-01\n",
      "Epoch 6700, Train loss: 1.257e+07, Test loss: 1.266e+07, MSE(e): 1.253e+00, MSE(pi1): 8.452e-01, MSE(pi2): 5.910e-01, MSE(pi3): 2.210e-01\n",
      "Epoch 6800, Train loss: 1.246e+07, Test loss: 1.259e+07, MSE(e): 1.243e+00, MSE(pi1): 8.408e-01, MSE(pi2): 5.864e-01, MSE(pi3): 2.204e-01\n",
      "Epoch 6900, Train loss: 1.235e+07, Test loss: 1.252e+07, MSE(e): 1.232e+00, MSE(pi1): 8.366e-01, MSE(pi2): 5.818e-01, MSE(pi3): 2.198e-01\n",
      "Epoch 7000, Train loss: 1.224e+07, Test loss: 1.245e+07, MSE(e): 1.221e+00, MSE(pi1): 8.325e-01, MSE(pi2): 5.774e-01, MSE(pi3): 2.192e-01\n",
      "Epoch 7100, Train loss: 1.214e+07, Test loss: 1.238e+07, MSE(e): 1.211e+00, MSE(pi1): 8.285e-01, MSE(pi2): 5.729e-01, MSE(pi3): 2.186e-01\n",
      "Epoch 7200, Train loss: 1.204e+07, Test loss: 1.231e+07, MSE(e): 1.201e+00, MSE(pi1): 8.247e-01, MSE(pi2): 5.686e-01, MSE(pi3): 2.180e-01\n",
      "Epoch 7300, Train loss: 1.194e+07, Test loss: 1.224e+07, MSE(e): 1.191e+00, MSE(pi1): 8.211e-01, MSE(pi2): 5.643e-01, MSE(pi3): 2.175e-01\n",
      "Epoch 7400, Train loss: 1.184e+07, Test loss: 1.217e+07, MSE(e): 1.181e+00, MSE(pi1): 8.177e-01, MSE(pi2): 5.601e-01, MSE(pi3): 2.169e-01\n",
      "Epoch 7500, Train loss: 1.174e+07, Test loss: 1.209e+07, MSE(e): 1.171e+00, MSE(pi1): 8.145e-01, MSE(pi2): 5.560e-01, MSE(pi3): 2.164e-01\n",
      "Epoch 7600, Train loss: 1.165e+07, Test loss: 1.202e+07, MSE(e): 1.162e+00, MSE(pi1): 8.114e-01, MSE(pi2): 5.519e-01, MSE(pi3): 2.159e-01\n",
      "Epoch 7700, Train loss: 1.155e+07, Test loss: 1.194e+07, MSE(e): 1.152e+00, MSE(pi1): 8.085e-01, MSE(pi2): 5.479e-01, MSE(pi3): 2.153e-01\n",
      "Epoch 7800, Train loss: 1.146e+07, Test loss: 1.186e+07, MSE(e): 1.143e+00, MSE(pi1): 8.058e-01, MSE(pi2): 5.439e-01, MSE(pi3): 2.148e-01\n",
      "Epoch 7900, Train loss: 1.137e+07, Test loss: 1.179e+07, MSE(e): 1.134e+00, MSE(pi1): 8.033e-01, MSE(pi2): 5.400e-01, MSE(pi3): 2.143e-01\n",
      "Epoch 8000, Train loss: 1.128e+07, Test loss: 1.171e+07, MSE(e): 1.125e+00, MSE(pi1): 8.010e-01, MSE(pi2): 5.362e-01, MSE(pi3): 2.138e-01\n",
      "Epoch 8100, Train loss: 1.120e+07, Test loss: 1.163e+07, MSE(e): 1.117e+00, MSE(pi1): 7.988e-01, MSE(pi2): 5.324e-01, MSE(pi3): 2.133e-01\n",
      "Epoch 8200, Train loss: 1.111e+07, Test loss: 1.156e+07, MSE(e): 1.108e+00, MSE(pi1): 7.968e-01, MSE(pi2): 5.287e-01, MSE(pi3): 2.128e-01\n",
      "Epoch 8300, Train loss: 1.103e+07, Test loss: 1.148e+07, MSE(e): 1.100e+00, MSE(pi1): 7.949e-01, MSE(pi2): 5.250e-01, MSE(pi3): 2.123e-01\n",
      "Epoch 8400, Train loss: 1.094e+07, Test loss: 1.141e+07, MSE(e): 1.091e+00, MSE(pi1): 7.931e-01, MSE(pi2): 5.214e-01, MSE(pi3): 2.118e-01\n",
      "Epoch 8500, Train loss: 1.086e+07, Test loss: 1.133e+07, MSE(e): 1.083e+00, MSE(pi1): 7.915e-01, MSE(pi2): 5.178e-01, MSE(pi3): 2.113e-01\n",
      "Epoch 8600, Train loss: 1.078e+07, Test loss: 1.126e+07, MSE(e): 1.075e+00, MSE(pi1): 7.900e-01, MSE(pi2): 5.144e-01, MSE(pi3): 2.109e-01\n",
      "Epoch 8700, Train loss: 1.070e+07, Test loss: 1.118e+07, MSE(e): 1.067e+00, MSE(pi1): 7.887e-01, MSE(pi2): 5.109e-01, MSE(pi3): 2.104e-01\n",
      "Epoch 8800, Train loss: 1.062e+07, Test loss: 1.111e+07, MSE(e): 1.059e+00, MSE(pi1): 7.874e-01, MSE(pi2): 5.076e-01, MSE(pi3): 2.100e-01\n",
      "Epoch 8900, Train loss: 1.055e+07, Test loss: 1.104e+07, MSE(e): 1.052e+00, MSE(pi1): 7.862e-01, MSE(pi2): 5.043e-01, MSE(pi3): 2.096e-01\n",
      "Epoch 9000, Train loss: 1.047e+07, Test loss: 1.097e+07, MSE(e): 1.044e+00, MSE(pi1): 7.851e-01, MSE(pi2): 5.010e-01, MSE(pi3): 2.092e-01\n",
      "Epoch 9100, Train loss: 1.040e+07, Test loss: 1.090e+07, MSE(e): 1.037e+00, MSE(pi1): 7.841e-01, MSE(pi2): 4.978e-01, MSE(pi3): 2.088e-01\n",
      "Epoch 9200, Train loss: 1.032e+07, Test loss: 1.084e+07, MSE(e): 1.029e+00, MSE(pi1): 7.831e-01, MSE(pi2): 4.947e-01, MSE(pi3): 2.084e-01\n",
      "Epoch 9300, Train loss: 1.025e+07, Test loss: 1.077e+07, MSE(e): 1.022e+00, MSE(pi1): 7.822e-01, MSE(pi2): 4.917e-01, MSE(pi3): 2.080e-01\n",
      "Epoch 9400, Train loss: 1.018e+07, Test loss: 1.071e+07, MSE(e): 1.015e+00, MSE(pi1): 7.813e-01, MSE(pi2): 4.887e-01, MSE(pi3): 2.077e-01\n",
      "Epoch 9500, Train loss: 1.011e+07, Test loss: 1.064e+07, MSE(e): 1.008e+00, MSE(pi1): 7.805e-01, MSE(pi2): 4.857e-01, MSE(pi3): 2.073e-01\n",
      "Epoch 9600, Train loss: 1.005e+07, Test loss: 1.058e+07, MSE(e): 1.002e+00, MSE(pi1): 7.796e-01, MSE(pi2): 4.829e-01, MSE(pi3): 2.070e-01\n",
      "Epoch 9700, Train loss: 9.980e+06, Test loss: 1.052e+07, MSE(e): 9.951e-01, MSE(pi1): 7.788e-01, MSE(pi2): 4.800e-01, MSE(pi3): 2.067e-01\n",
      "Epoch 9800, Train loss: 9.915e+06, Test loss: 1.046e+07, MSE(e): 9.886e-01, MSE(pi1): 7.780e-01, MSE(pi2): 4.773e-01, MSE(pi3): 2.064e-01\n",
      "Epoch 9900, Train loss: 9.852e+06, Test loss: 1.040e+07, MSE(e): 9.823e-01, MSE(pi1): 7.772e-01, MSE(pi2): 4.746e-01, MSE(pi3): 2.061e-01\n",
      "Epoch 10000, Train loss: 9.789e+06, Test loss: 1.035e+07, MSE(e): 9.761e-01, MSE(pi1): 7.763e-01, MSE(pi2): 4.719e-01, MSE(pi3): 2.058e-01\n",
      "Epoch 10100, Train loss: 9.728e+06, Test loss: 1.029e+07, MSE(e): 9.700e-01, MSE(pi1): 7.755e-01, MSE(pi2): 4.693e-01, MSE(pi3): 2.055e-01\n",
      "Epoch 10200, Train loss: 9.668e+06, Test loss: 1.024e+07, MSE(e): 9.640e-01, MSE(pi1): 7.747e-01, MSE(pi2): 4.668e-01, MSE(pi3): 2.052e-01\n",
      "Epoch 10300, Train loss: 9.610e+06, Test loss: 1.019e+07, MSE(e): 9.581e-01, MSE(pi1): 7.738e-01, MSE(pi2): 4.643e-01, MSE(pi3): 2.049e-01\n",
      "Epoch 10400, Train loss: 9.552e+06, Test loss: 1.013e+07, MSE(e): 9.524e-01, MSE(pi1): 7.729e-01, MSE(pi2): 4.619e-01, MSE(pi3): 2.047e-01\n",
      "Epoch 10500, Train loss: 9.496e+06, Test loss: 1.008e+07, MSE(e): 9.467e-01, MSE(pi1): 7.720e-01, MSE(pi2): 4.595e-01, MSE(pi3): 2.044e-01\n",
      "Epoch 10600, Train loss: 9.440e+06, Test loss: 1.003e+07, MSE(e): 9.412e-01, MSE(pi1): 7.711e-01, MSE(pi2): 4.572e-01, MSE(pi3): 2.042e-01\n",
      "Epoch 10700, Train loss: 9.386e+06, Test loss: 9.985e+06, MSE(e): 9.358e-01, MSE(pi1): 7.701e-01, MSE(pi2): 4.549e-01, MSE(pi3): 2.039e-01\n",
      "Epoch 10800, Train loss: 9.333e+06, Test loss: 9.938e+06, MSE(e): 9.304e-01, MSE(pi1): 7.691e-01, MSE(pi2): 4.526e-01, MSE(pi3): 2.037e-01\n",
      "Epoch 10900, Train loss: 9.281e+06, Test loss: 9.891e+06, MSE(e): 9.252e-01, MSE(pi1): 7.681e-01, MSE(pi2): 4.504e-01, MSE(pi3): 2.035e-01\n",
      "Epoch 11000, Train loss: 9.229e+06, Test loss: 9.846e+06, MSE(e): 9.201e-01, MSE(pi1): 7.671e-01, MSE(pi2): 4.483e-01, MSE(pi3): 2.032e-01\n",
      "Epoch 11100, Train loss: 9.179e+06, Test loss: 9.801e+06, MSE(e): 9.151e-01, MSE(pi1): 7.660e-01, MSE(pi2): 4.462e-01, MSE(pi3): 2.030e-01\n",
      "Epoch 11200, Train loss: 9.130e+06, Test loss: 9.757e+06, MSE(e): 9.101e-01, MSE(pi1): 7.649e-01, MSE(pi2): 4.441e-01, MSE(pi3): 2.028e-01\n",
      "Epoch 11300, Train loss: 9.081e+06, Test loss: 9.715e+06, MSE(e): 9.053e-01, MSE(pi1): 7.639e-01, MSE(pi2): 4.420e-01, MSE(pi3): 2.026e-01\n",
      "Epoch 11400, Train loss: 9.033e+06, Test loss: 9.673e+06, MSE(e): 9.005e-01, MSE(pi1): 7.627e-01, MSE(pi2): 4.400e-01, MSE(pi3): 2.024e-01\n",
      "Epoch 11500, Train loss: 8.986e+06, Test loss: 9.632e+06, MSE(e): 8.958e-01, MSE(pi1): 7.616e-01, MSE(pi2): 4.380e-01, MSE(pi3): 2.022e-01\n",
      "Epoch 11600, Train loss: 8.940e+06, Test loss: 9.592e+06, MSE(e): 8.912e-01, MSE(pi1): 7.605e-01, MSE(pi2): 4.361e-01, MSE(pi3): 2.020e-01\n",
      "Epoch 11700, Train loss: 8.895e+06, Test loss: 9.554e+06, MSE(e): 8.866e-01, MSE(pi1): 7.594e-01, MSE(pi2): 4.342e-01, MSE(pi3): 2.018e-01\n",
      "Epoch 11800, Train loss: 8.850e+06, Test loss: 9.516e+06, MSE(e): 8.822e-01, MSE(pi1): 7.582e-01, MSE(pi2): 4.323e-01, MSE(pi3): 2.016e-01\n",
      "Epoch 11900, Train loss: 8.806e+06, Test loss: 9.479e+06, MSE(e): 8.778e-01, MSE(pi1): 7.571e-01, MSE(pi2): 4.304e-01, MSE(pi3): 2.014e-01\n",
      "Epoch 12000, Train loss: 8.763e+06, Test loss: 9.443e+06, MSE(e): 8.734e-01, MSE(pi1): 7.559e-01, MSE(pi2): 4.286e-01, MSE(pi3): 2.012e-01\n",
      "Epoch 12100, Train loss: 8.720e+06, Test loss: 9.408e+06, MSE(e): 8.692e-01, MSE(pi1): 7.548e-01, MSE(pi2): 4.268e-01, MSE(pi3): 2.011e-01\n",
      "Epoch 12200, Train loss: 8.678e+06, Test loss: 9.375e+06, MSE(e): 8.650e-01, MSE(pi1): 7.536e-01, MSE(pi2): 4.251e-01, MSE(pi3): 2.009e-01\n",
      "Epoch 12300, Train loss: 8.636e+06, Test loss: 9.342e+06, MSE(e): 8.608e-01, MSE(pi1): 7.525e-01, MSE(pi2): 4.233e-01, MSE(pi3): 2.007e-01\n",
      "Epoch 12400, Train loss: 8.595e+06, Test loss: 9.310e+06, MSE(e): 8.567e-01, MSE(pi1): 7.513e-01, MSE(pi2): 4.216e-01, MSE(pi3): 2.005e-01\n",
      "Epoch 12500, Train loss: 8.554e+06, Test loss: 9.279e+06, MSE(e): 8.527e-01, MSE(pi1): 7.502e-01, MSE(pi2): 4.199e-01, MSE(pi3): 2.004e-01\n",
      "Epoch 12600, Train loss: 8.514e+06, Test loss: 9.248e+06, MSE(e): 8.487e-01, MSE(pi1): 7.491e-01, MSE(pi2): 4.182e-01, MSE(pi3): 2.002e-01\n",
      "Epoch 12700, Train loss: 8.475e+06, Test loss: 9.219e+06, MSE(e): 8.447e-01, MSE(pi1): 7.479e-01, MSE(pi2): 4.165e-01, MSE(pi3): 2.000e-01\n",
      "Epoch 12800, Train loss: 8.436e+06, Test loss: 9.190e+06, MSE(e): 8.408e-01, MSE(pi1): 7.468e-01, MSE(pi2): 4.149e-01, MSE(pi3): 1.999e-01\n",
      "Epoch 12900, Train loss: 8.397e+06, Test loss: 9.162e+06, MSE(e): 8.369e-01, MSE(pi1): 7.457e-01, MSE(pi2): 4.132e-01, MSE(pi3): 1.997e-01\n",
      "Epoch 13000, Train loss: 8.359e+06, Test loss: 9.135e+06, MSE(e): 8.331e-01, MSE(pi1): 7.446e-01, MSE(pi2): 4.116e-01, MSE(pi3): 1.995e-01\n",
      "Epoch 13100, Train loss: 8.321e+06, Test loss: 9.109e+06, MSE(e): 8.293e-01, MSE(pi1): 7.436e-01, MSE(pi2): 4.100e-01, MSE(pi3): 1.994e-01\n",
      "Epoch 13200, Train loss: 8.283e+06, Test loss: 9.083e+06, MSE(e): 8.255e-01, MSE(pi1): 7.425e-01, MSE(pi2): 4.084e-01, MSE(pi3): 1.992e-01\n",
      "Epoch 13300, Train loss: 8.246e+06, Test loss: 9.058e+06, MSE(e): 8.218e-01, MSE(pi1): 7.414e-01, MSE(pi2): 4.069e-01, MSE(pi3): 1.991e-01\n",
      "Epoch 13400, Train loss: 8.209e+06, Test loss: 9.034e+06, MSE(e): 8.181e-01, MSE(pi1): 7.404e-01, MSE(pi2): 4.053e-01, MSE(pi3): 1.989e-01\n",
      "Epoch 13500, Train loss: 8.172e+06, Test loss: 9.010e+06, MSE(e): 8.145e-01, MSE(pi1): 7.394e-01, MSE(pi2): 4.038e-01, MSE(pi3): 1.988e-01\n",
      "Epoch 13600, Train loss: 8.136e+06, Test loss: 8.987e+06, MSE(e): 8.109e-01, MSE(pi1): 7.383e-01, MSE(pi2): 4.022e-01, MSE(pi3): 1.986e-01\n",
      "Epoch 13700, Train loss: 8.100e+06, Test loss: 8.964e+06, MSE(e): 8.073e-01, MSE(pi1): 7.373e-01, MSE(pi2): 4.007e-01, MSE(pi3): 1.985e-01\n",
      "Epoch 13800, Train loss: 8.065e+06, Test loss: 8.942e+06, MSE(e): 8.037e-01, MSE(pi1): 7.363e-01, MSE(pi2): 3.992e-01, MSE(pi3): 1.983e-01\n",
      "Epoch 13900, Train loss: 8.029e+06, Test loss: 8.921e+06, MSE(e): 8.002e-01, MSE(pi1): 7.353e-01, MSE(pi2): 3.977e-01, MSE(pi3): 1.982e-01\n",
      "Epoch 14000, Train loss: 7.994e+06, Test loss: 8.900e+06, MSE(e): 7.967e-01, MSE(pi1): 7.344e-01, MSE(pi2): 3.963e-01, MSE(pi3): 1.980e-01\n",
      "Epoch 14100, Train loss: 7.959e+06, Test loss: 8.880e+06, MSE(e): 7.932e-01, MSE(pi1): 7.334e-01, MSE(pi2): 3.948e-01, MSE(pi3): 1.979e-01\n",
      "Epoch 14200, Train loss: 7.925e+06, Test loss: 8.860e+06, MSE(e): 7.897e-01, MSE(pi1): 7.324e-01, MSE(pi2): 3.933e-01, MSE(pi3): 1.978e-01\n",
      "Epoch 14300, Train loss: 7.891e+06, Test loss: 8.841e+06, MSE(e): 7.863e-01, MSE(pi1): 7.315e-01, MSE(pi2): 3.919e-01, MSE(pi3): 1.976e-01\n",
      "Epoch 14400, Train loss: 7.857e+06, Test loss: 8.822e+06, MSE(e): 7.829e-01, MSE(pi1): 7.305e-01, MSE(pi2): 3.905e-01, MSE(pi3): 1.975e-01\n",
      "Epoch 14500, Train loss: 7.823e+06, Test loss: 8.804e+06, MSE(e): 7.796e-01, MSE(pi1): 7.296e-01, MSE(pi2): 3.891e-01, MSE(pi3): 1.974e-01\n",
      "Epoch 14600, Train loss: 7.790e+06, Test loss: 8.786e+06, MSE(e): 7.763e-01, MSE(pi1): 7.286e-01, MSE(pi2): 3.876e-01, MSE(pi3): 1.973e-01\n",
      "Epoch 14700, Train loss: 7.757e+06, Test loss: 8.769e+06, MSE(e): 7.730e-01, MSE(pi1): 7.277e-01, MSE(pi2): 3.863e-01, MSE(pi3): 1.971e-01\n",
      "Epoch 14800, Train loss: 7.724e+06, Test loss: 8.752e+06, MSE(e): 7.697e-01, MSE(pi1): 7.267e-01, MSE(pi2): 3.849e-01, MSE(pi3): 1.970e-01\n",
      "Epoch 14900, Train loss: 7.692e+06, Test loss: 8.735e+06, MSE(e): 7.665e-01, MSE(pi1): 7.258e-01, MSE(pi2): 3.835e-01, MSE(pi3): 1.969e-01\n",
      "Epoch 15000, Train loss: 7.660e+06, Test loss: 8.719e+06, MSE(e): 7.633e-01, MSE(pi1): 7.249e-01, MSE(pi2): 3.822e-01, MSE(pi3): 1.968e-01\n",
      "Epoch 15100, Train loss: 7.628e+06, Test loss: 8.704e+06, MSE(e): 7.601e-01, MSE(pi1): 7.240e-01, MSE(pi2): 3.808e-01, MSE(pi3): 1.967e-01\n",
      "Epoch 15200, Train loss: 7.597e+06, Test loss: 8.688e+06, MSE(e): 7.570e-01, MSE(pi1): 7.231e-01, MSE(pi2): 3.795e-01, MSE(pi3): 1.965e-01\n",
      "Epoch 15300, Train loss: 7.566e+06, Test loss: 8.673e+06, MSE(e): 7.539e-01, MSE(pi1): 7.222e-01, MSE(pi2): 3.782e-01, MSE(pi3): 1.964e-01\n",
      "Epoch 15400, Train loss: 7.535e+06, Test loss: 8.659e+06, MSE(e): 7.508e-01, MSE(pi1): 7.213e-01, MSE(pi2): 3.769e-01, MSE(pi3): 1.963e-01\n",
      "Epoch 15500, Train loss: 7.505e+06, Test loss: 8.645e+06, MSE(e): 7.477e-01, MSE(pi1): 7.204e-01, MSE(pi2): 3.756e-01, MSE(pi3): 1.962e-01\n",
      "Epoch 15600, Train loss: 7.475e+06, Test loss: 8.631e+06, MSE(e): 7.447e-01, MSE(pi1): 7.195e-01, MSE(pi2): 3.744e-01, MSE(pi3): 1.961e-01\n",
      "Epoch 15700, Train loss: 7.445e+06, Test loss: 8.617e+06, MSE(e): 7.418e-01, MSE(pi1): 7.186e-01, MSE(pi2): 3.731e-01, MSE(pi3): 1.960e-01\n",
      "Epoch 15800, Train loss: 7.415e+06, Test loss: 8.604e+06, MSE(e): 7.388e-01, MSE(pi1): 7.177e-01, MSE(pi2): 3.719e-01, MSE(pi3): 1.959e-01\n",
      "Epoch 15900, Train loss: 7.386e+06, Test loss: 8.590e+06, MSE(e): 7.359e-01, MSE(pi1): 7.168e-01, MSE(pi2): 3.706e-01, MSE(pi3): 1.958e-01\n",
      "Epoch 16000, Train loss: 7.357e+06, Test loss: 8.577e+06, MSE(e): 7.330e-01, MSE(pi1): 7.160e-01, MSE(pi2): 3.694e-01, MSE(pi3): 1.957e-01\n",
      "Epoch 16100, Train loss: 7.329e+06, Test loss: 8.565e+06, MSE(e): 7.302e-01, MSE(pi1): 7.151e-01, MSE(pi2): 3.682e-01, MSE(pi3): 1.956e-01\n",
      "Epoch 16200, Train loss: 7.301e+06, Test loss: 8.552e+06, MSE(e): 7.273e-01, MSE(pi1): 7.142e-01, MSE(pi2): 3.670e-01, MSE(pi3): 1.955e-01\n",
      "Epoch 16300, Train loss: 7.273e+06, Test loss: 8.540e+06, MSE(e): 7.246e-01, MSE(pi1): 7.134e-01, MSE(pi2): 3.658e-01, MSE(pi3): 1.954e-01\n",
      "Epoch 16400, Train loss: 7.245e+06, Test loss: 8.528e+06, MSE(e): 7.218e-01, MSE(pi1): 7.125e-01, MSE(pi2): 3.647e-01, MSE(pi3): 1.953e-01\n",
      "Epoch 16500, Train loss: 7.218e+06, Test loss: 8.515e+06, MSE(e): 7.191e-01, MSE(pi1): 7.117e-01, MSE(pi2): 3.635e-01, MSE(pi3): 1.952e-01\n",
      "Epoch 16600, Train loss: 7.191e+06, Test loss: 8.503e+06, MSE(e): 7.164e-01, MSE(pi1): 7.108e-01, MSE(pi2): 3.624e-01, MSE(pi3): 1.951e-01\n",
      "Epoch 16700, Train loss: 7.164e+06, Test loss: 8.492e+06, MSE(e): 7.137e-01, MSE(pi1): 7.100e-01, MSE(pi2): 3.613e-01, MSE(pi3): 1.950e-01\n",
      "Epoch 16800, Train loss: 7.137e+06, Test loss: 8.480e+06, MSE(e): 7.110e-01, MSE(pi1): 7.091e-01, MSE(pi2): 3.601e-01, MSE(pi3): 1.949e-01\n",
      "Epoch 16900, Train loss: 7.111e+06, Test loss: 8.468e+06, MSE(e): 7.084e-01, MSE(pi1): 7.083e-01, MSE(pi2): 3.590e-01, MSE(pi3): 1.948e-01\n",
      "Epoch 17000, Train loss: 7.085e+06, Test loss: 8.456e+06, MSE(e): 7.058e-01, MSE(pi1): 7.075e-01, MSE(pi2): 3.579e-01, MSE(pi3): 1.947e-01\n",
      "Epoch 17100, Train loss: 7.060e+06, Test loss: 8.445e+06, MSE(e): 7.033e-01, MSE(pi1): 7.067e-01, MSE(pi2): 3.569e-01, MSE(pi3): 1.946e-01\n",
      "Epoch 17200, Train loss: 7.034e+06, Test loss: 8.433e+06, MSE(e): 7.007e-01, MSE(pi1): 7.059e-01, MSE(pi2): 3.558e-01, MSE(pi3): 1.945e-01\n",
      "Epoch 17300, Train loss: 7.009e+06, Test loss: 8.422e+06, MSE(e): 6.982e-01, MSE(pi1): 7.051e-01, MSE(pi2): 3.547e-01, MSE(pi3): 1.944e-01\n",
      "Epoch 17400, Train loss: 6.984e+06, Test loss: 8.411e+06, MSE(e): 6.957e-01, MSE(pi1): 7.043e-01, MSE(pi2): 3.537e-01, MSE(pi3): 1.944e-01\n",
      "Epoch 17500, Train loss: 6.959e+06, Test loss: 8.399e+06, MSE(e): 6.933e-01, MSE(pi1): 7.035e-01, MSE(pi2): 3.526e-01, MSE(pi3): 1.943e-01\n",
      "Epoch 17600, Train loss: 6.935e+06, Test loss: 8.388e+06, MSE(e): 6.908e-01, MSE(pi1): 7.027e-01, MSE(pi2): 3.516e-01, MSE(pi3): 1.942e-01\n",
      "Epoch 17700, Train loss: 6.911e+06, Test loss: 8.376e+06, MSE(e): 6.884e-01, MSE(pi1): 7.019e-01, MSE(pi2): 3.506e-01, MSE(pi3): 1.941e-01\n",
      "Epoch 17800, Train loss: 6.887e+06, Test loss: 8.365e+06, MSE(e): 6.860e-01, MSE(pi1): 7.012e-01, MSE(pi2): 3.496e-01, MSE(pi3): 1.940e-01\n",
      "Epoch 17900, Train loss: 6.863e+06, Test loss: 8.354e+06, MSE(e): 6.837e-01, MSE(pi1): 7.004e-01, MSE(pi2): 3.486e-01, MSE(pi3): 1.939e-01\n",
      "Epoch 18000, Train loss: 6.840e+06, Test loss: 8.342e+06, MSE(e): 6.813e-01, MSE(pi1): 6.996e-01, MSE(pi2): 3.476e-01, MSE(pi3): 1.938e-01\n",
      "Epoch 18100, Train loss: 6.817e+06, Test loss: 8.331e+06, MSE(e): 6.790e-01, MSE(pi1): 6.989e-01, MSE(pi2): 3.466e-01, MSE(pi3): 1.937e-01\n",
      "Epoch 18200, Train loss: 6.794e+06, Test loss: 8.320e+06, MSE(e): 6.767e-01, MSE(pi1): 6.982e-01, MSE(pi2): 3.456e-01, MSE(pi3): 1.936e-01\n",
      "Epoch 18300, Train loss: 6.771e+06, Test loss: 8.308e+06, MSE(e): 6.744e-01, MSE(pi1): 6.974e-01, MSE(pi2): 3.447e-01, MSE(pi3): 1.936e-01\n",
      "Epoch 18400, Train loss: 6.748e+06, Test loss: 8.297e+06, MSE(e): 6.721e-01, MSE(pi1): 6.967e-01, MSE(pi2): 3.437e-01, MSE(pi3): 1.935e-01\n",
      "Epoch 18500, Train loss: 6.726e+06, Test loss: 8.285e+06, MSE(e): 6.699e-01, MSE(pi1): 6.960e-01, MSE(pi2): 3.428e-01, MSE(pi3): 1.934e-01\n",
      "Epoch 18600, Train loss: 6.704e+06, Test loss: 8.274e+06, MSE(e): 6.677e-01, MSE(pi1): 6.952e-01, MSE(pi2): 3.418e-01, MSE(pi3): 1.933e-01\n",
      "Epoch 18700, Train loss: 6.682e+06, Test loss: 8.262e+06, MSE(e): 6.655e-01, MSE(pi1): 6.945e-01, MSE(pi2): 3.409e-01, MSE(pi3): 1.932e-01\n",
      "Epoch 18800, Train loss: 6.660e+06, Test loss: 8.251e+06, MSE(e): 6.633e-01, MSE(pi1): 6.938e-01, MSE(pi2): 3.400e-01, MSE(pi3): 1.931e-01\n",
      "Epoch 18900, Train loss: 6.638e+06, Test loss: 8.239e+06, MSE(e): 6.612e-01, MSE(pi1): 6.931e-01, MSE(pi2): 3.391e-01, MSE(pi3): 1.930e-01\n",
      "Epoch 19000, Train loss: 6.617e+06, Test loss: 8.228e+06, MSE(e): 6.590e-01, MSE(pi1): 6.924e-01, MSE(pi2): 3.382e-01, MSE(pi3): 1.929e-01\n",
      "Epoch 19100, Train loss: 6.596e+06, Test loss: 8.216e+06, MSE(e): 6.569e-01, MSE(pi1): 6.917e-01, MSE(pi2): 3.373e-01, MSE(pi3): 1.928e-01\n",
      "Epoch 19200, Train loss: 6.575e+06, Test loss: 8.205e+06, MSE(e): 6.548e-01, MSE(pi1): 6.910e-01, MSE(pi2): 3.364e-01, MSE(pi3): 1.927e-01\n",
      "Epoch 19300, Train loss: 6.554e+06, Test loss: 8.193e+06, MSE(e): 6.527e-01, MSE(pi1): 6.904e-01, MSE(pi2): 3.355e-01, MSE(pi3): 1.927e-01\n",
      "Epoch 19400, Train loss: 6.533e+06, Test loss: 8.182e+06, MSE(e): 6.507e-01, MSE(pi1): 6.897e-01, MSE(pi2): 3.346e-01, MSE(pi3): 1.926e-01\n",
      "Epoch 19500, Train loss: 6.513e+06, Test loss: 8.170e+06, MSE(e): 6.487e-01, MSE(pi1): 6.890e-01, MSE(pi2): 3.338e-01, MSE(pi3): 1.925e-01\n",
      "Epoch 19600, Train loss: 6.493e+06, Test loss: 8.158e+06, MSE(e): 6.466e-01, MSE(pi1): 6.883e-01, MSE(pi2): 3.329e-01, MSE(pi3): 1.924e-01\n",
      "Epoch 19700, Train loss: 6.473e+06, Test loss: 8.147e+06, MSE(e): 6.446e-01, MSE(pi1): 6.877e-01, MSE(pi2): 3.321e-01, MSE(pi3): 1.923e-01\n",
      "Epoch 19800, Train loss: 6.453e+06, Test loss: 8.135e+06, MSE(e): 6.427e-01, MSE(pi1): 6.870e-01, MSE(pi2): 3.312e-01, MSE(pi3): 1.922e-01\n",
      "Epoch 19900, Train loss: 6.433e+06, Test loss: 8.123e+06, MSE(e): 6.407e-01, MSE(pi1): 6.864e-01, MSE(pi2): 3.304e-01, MSE(pi3): 1.921e-01\n",
      "Epoch 20000, Train loss: 6.414e+06, Test loss: 8.111e+06, MSE(e): 6.388e-01, MSE(pi1): 6.857e-01, MSE(pi2): 3.296e-01, MSE(pi3): 1.920e-01\n",
      "Epoch 20100, Train loss: 6.395e+06, Test loss: 8.099e+06, MSE(e): 6.368e-01, MSE(pi1): 6.851e-01, MSE(pi2): 3.288e-01, MSE(pi3): 1.919e-01\n",
      "Epoch 20200, Train loss: 6.376e+06, Test loss: 8.087e+06, MSE(e): 6.349e-01, MSE(pi1): 6.844e-01, MSE(pi2): 3.280e-01, MSE(pi3): 1.918e-01\n",
      "Epoch 20300, Train loss: 6.357e+06, Test loss: 8.075e+06, MSE(e): 6.331e-01, MSE(pi1): 6.838e-01, MSE(pi2): 3.272e-01, MSE(pi3): 1.917e-01\n",
      "Epoch 20400, Train loss: 6.338e+06, Test loss: 8.063e+06, MSE(e): 6.312e-01, MSE(pi1): 6.832e-01, MSE(pi2): 3.264e-01, MSE(pi3): 1.916e-01\n",
      "Epoch 20500, Train loss: 6.320e+06, Test loss: 8.052e+06, MSE(e): 6.293e-01, MSE(pi1): 6.825e-01, MSE(pi2): 3.256e-01, MSE(pi3): 1.915e-01\n",
      "Epoch 20600, Train loss: 6.301e+06, Test loss: 8.040e+06, MSE(e): 6.275e-01, MSE(pi1): 6.819e-01, MSE(pi2): 3.248e-01, MSE(pi3): 1.914e-01\n",
      "Epoch 20700, Train loss: 6.283e+06, Test loss: 8.027e+06, MSE(e): 6.257e-01, MSE(pi1): 6.813e-01, MSE(pi2): 3.240e-01, MSE(pi3): 1.913e-01\n",
      "Epoch 20800, Train loss: 6.265e+06, Test loss: 8.015e+06, MSE(e): 6.239e-01, MSE(pi1): 6.807e-01, MSE(pi2): 3.233e-01, MSE(pi3): 1.912e-01\n",
      "Epoch 20900, Train loss: 6.247e+06, Test loss: 8.003e+06, MSE(e): 6.221e-01, MSE(pi1): 6.801e-01, MSE(pi2): 3.225e-01, MSE(pi3): 1.911e-01\n",
      "Epoch 21000, Train loss: 6.230e+06, Test loss: 7.991e+06, MSE(e): 6.204e-01, MSE(pi1): 6.795e-01, MSE(pi2): 3.218e-01, MSE(pi3): 1.910e-01\n",
      "Epoch 21100, Train loss: 6.212e+06, Test loss: 7.979e+06, MSE(e): 6.186e-01, MSE(pi1): 6.789e-01, MSE(pi2): 3.210e-01, MSE(pi3): 1.909e-01\n",
      "Epoch 21200, Train loss: 6.195e+06, Test loss: 7.967e+06, MSE(e): 6.169e-01, MSE(pi1): 6.783e-01, MSE(pi2): 3.203e-01, MSE(pi3): 1.908e-01\n",
      "Epoch 21300, Train loss: 6.178e+06, Test loss: 7.955e+06, MSE(e): 6.152e-01, MSE(pi1): 6.777e-01, MSE(pi2): 3.196e-01, MSE(pi3): 1.907e-01\n",
      "Epoch 21400, Train loss: 6.161e+06, Test loss: 7.943e+06, MSE(e): 6.135e-01, MSE(pi1): 6.771e-01, MSE(pi2): 3.189e-01, MSE(pi3): 1.906e-01\n",
      "Epoch 21500, Train loss: 6.144e+06, Test loss: 7.931e+06, MSE(e): 6.118e-01, MSE(pi1): 6.765e-01, MSE(pi2): 3.181e-01, MSE(pi3): 1.905e-01\n",
      "Epoch 21600, Train loss: 6.128e+06, Test loss: 7.919e+06, MSE(e): 6.102e-01, MSE(pi1): 6.760e-01, MSE(pi2): 3.174e-01, MSE(pi3): 1.904e-01\n",
      "Epoch 21700, Train loss: 6.111e+06, Test loss: 7.906e+06, MSE(e): 6.085e-01, MSE(pi1): 6.754e-01, MSE(pi2): 3.167e-01, MSE(pi3): 1.903e-01\n",
      "Epoch 21800, Train loss: 6.095e+06, Test loss: 7.894e+06, MSE(e): 6.069e-01, MSE(pi1): 6.748e-01, MSE(pi2): 3.161e-01, MSE(pi3): 1.902e-01\n",
      "Epoch 21900, Train loss: 6.079e+06, Test loss: 7.882e+06, MSE(e): 6.053e-01, MSE(pi1): 6.743e-01, MSE(pi2): 3.154e-01, MSE(pi3): 1.901e-01\n",
      "Epoch 22000, Train loss: 6.063e+06, Test loss: 7.870e+06, MSE(e): 6.037e-01, MSE(pi1): 6.737e-01, MSE(pi2): 3.147e-01, MSE(pi3): 1.900e-01\n",
      "Epoch 22100, Train loss: 6.047e+06, Test loss: 7.858e+06, MSE(e): 6.021e-01, MSE(pi1): 6.732e-01, MSE(pi2): 3.140e-01, MSE(pi3): 1.899e-01\n",
      "Epoch 22200, Train loss: 6.032e+06, Test loss: 7.846e+06, MSE(e): 6.006e-01, MSE(pi1): 6.726e-01, MSE(pi2): 3.134e-01, MSE(pi3): 1.898e-01\n",
      "Epoch 22300, Train loss: 6.016e+06, Test loss: 7.834e+06, MSE(e): 5.990e-01, MSE(pi1): 6.721e-01, MSE(pi2): 3.127e-01, MSE(pi3): 1.897e-01\n",
      "Epoch 22400, Train loss: 6.001e+06, Test loss: 7.822e+06, MSE(e): 5.975e-01, MSE(pi1): 6.716e-01, MSE(pi2): 3.120e-01, MSE(pi3): 1.897e-01\n",
      "Epoch 22500, Train loss: 5.985e+06, Test loss: 7.810e+06, MSE(e): 5.959e-01, MSE(pi1): 6.710e-01, MSE(pi2): 3.114e-01, MSE(pi3): 1.896e-01\n",
      "Epoch 22600, Train loss: 5.970e+06, Test loss: 7.797e+06, MSE(e): 5.944e-01, MSE(pi1): 6.705e-01, MSE(pi2): 3.108e-01, MSE(pi3): 1.895e-01\n",
      "Epoch 22700, Train loss: 5.955e+06, Test loss: 7.785e+06, MSE(e): 5.930e-01, MSE(pi1): 6.700e-01, MSE(pi2): 3.101e-01, MSE(pi3): 1.894e-01\n",
      "Epoch 22800, Train loss: 5.941e+06, Test loss: 7.774e+06, MSE(e): 5.915e-01, MSE(pi1): 6.695e-01, MSE(pi2): 3.095e-01, MSE(pi3): 1.893e-01\n",
      "Epoch 22900, Train loss: 5.926e+06, Test loss: 7.762e+06, MSE(e): 5.900e-01, MSE(pi1): 6.689e-01, MSE(pi2): 3.089e-01, MSE(pi3): 1.892e-01\n",
      "Epoch 23000, Train loss: 5.911e+06, Test loss: 7.750e+06, MSE(e): 5.886e-01, MSE(pi1): 6.684e-01, MSE(pi2): 3.083e-01, MSE(pi3): 1.891e-01\n",
      "Epoch 23100, Train loss: 5.897e+06, Test loss: 7.738e+06, MSE(e): 5.871e-01, MSE(pi1): 6.679e-01, MSE(pi2): 3.077e-01, MSE(pi3): 1.890e-01\n",
      "Epoch 23200, Train loss: 5.883e+06, Test loss: 7.726e+06, MSE(e): 5.857e-01, MSE(pi1): 6.674e-01, MSE(pi2): 3.070e-01, MSE(pi3): 1.889e-01\n",
      "Epoch 23300, Train loss: 5.869e+06, Test loss: 7.714e+06, MSE(e): 5.843e-01, MSE(pi1): 6.669e-01, MSE(pi2): 3.064e-01, MSE(pi3): 1.888e-01\n",
      "Epoch 23400, Train loss: 5.855e+06, Test loss: 7.702e+06, MSE(e): 5.829e-01, MSE(pi1): 6.664e-01, MSE(pi2): 3.059e-01, MSE(pi3): 1.887e-01\n",
      "Epoch 23500, Train loss: 5.841e+06, Test loss: 7.691e+06, MSE(e): 5.815e-01, MSE(pi1): 6.659e-01, MSE(pi2): 3.053e-01, MSE(pi3): 1.886e-01\n",
      "Epoch 23600, Train loss: 5.827e+06, Test loss: 7.679e+06, MSE(e): 5.801e-01, MSE(pi1): 6.654e-01, MSE(pi2): 3.047e-01, MSE(pi3): 1.886e-01\n",
      "Epoch 23700, Train loss: 5.813e+06, Test loss: 7.667e+06, MSE(e): 5.788e-01, MSE(pi1): 6.649e-01, MSE(pi2): 3.041e-01, MSE(pi3): 1.885e-01\n",
      "Epoch 23800, Train loss: 5.800e+06, Test loss: 7.656e+06, MSE(e): 5.774e-01, MSE(pi1): 6.645e-01, MSE(pi2): 3.035e-01, MSE(pi3): 1.884e-01\n",
      "Epoch 23900, Train loss: 5.787e+06, Test loss: 7.644e+06, MSE(e): 5.761e-01, MSE(pi1): 6.640e-01, MSE(pi2): 3.030e-01, MSE(pi3): 1.883e-01\n",
      "Epoch 24000, Train loss: 5.773e+06, Test loss: 7.633e+06, MSE(e): 5.748e-01, MSE(pi1): 6.635e-01, MSE(pi2): 3.024e-01, MSE(pi3): 1.882e-01\n",
      "Epoch 24100, Train loss: 5.760e+06, Test loss: 7.621e+06, MSE(e): 5.734e-01, MSE(pi1): 6.630e-01, MSE(pi2): 3.018e-01, MSE(pi3): 1.881e-01\n",
      "Epoch 24200, Train loss: 5.747e+06, Test loss: 7.610e+06, MSE(e): 5.721e-01, MSE(pi1): 6.625e-01, MSE(pi2): 3.013e-01, MSE(pi3): 1.880e-01\n",
      "Epoch 24300, Train loss: 5.734e+06, Test loss: 7.598e+06, MSE(e): 5.708e-01, MSE(pi1): 6.620e-01, MSE(pi2): 3.007e-01, MSE(pi3): 1.879e-01\n",
      "Epoch 24400, Train loss: 5.721e+06, Test loss: 7.587e+06, MSE(e): 5.696e-01, MSE(pi1): 6.616e-01, MSE(pi2): 3.002e-01, MSE(pi3): 1.879e-01\n",
      "Epoch 24500, Train loss: 5.709e+06, Test loss: 7.576e+06, MSE(e): 5.683e-01, MSE(pi1): 6.611e-01, MSE(pi2): 2.996e-01, MSE(pi3): 1.878e-01\n",
      "Epoch 24600, Train loss: 5.696e+06, Test loss: 7.564e+06, MSE(e): 5.670e-01, MSE(pi1): 6.606e-01, MSE(pi2): 2.991e-01, MSE(pi3): 1.877e-01\n",
      "Epoch 24700, Train loss: 5.683e+06, Test loss: 7.553e+06, MSE(e): 5.658e-01, MSE(pi1): 6.601e-01, MSE(pi2): 2.986e-01, MSE(pi3): 1.876e-01\n",
      "Epoch 24800, Train loss: 5.671e+06, Test loss: 7.542e+06, MSE(e): 5.645e-01, MSE(pi1): 6.597e-01, MSE(pi2): 2.980e-01, MSE(pi3): 1.875e-01\n",
      "Epoch 24900, Train loss: 5.659e+06, Test loss: 7.531e+06, MSE(e): 5.633e-01, MSE(pi1): 6.592e-01, MSE(pi2): 2.975e-01, MSE(pi3): 1.875e-01\n",
      "Epoch 25000, Train loss: 5.647e+06, Test loss: 7.520e+06, MSE(e): 5.621e-01, MSE(pi1): 6.587e-01, MSE(pi2): 2.970e-01, MSE(pi3): 1.874e-01\n",
      "Epoch 25100, Train loss: 5.634e+06, Test loss: 7.509e+06, MSE(e): 5.609e-01, MSE(pi1): 6.582e-01, MSE(pi2): 2.965e-01, MSE(pi3): 1.873e-01\n",
      "Epoch 25200, Train loss: 5.622e+06, Test loss: 7.498e+06, MSE(e): 5.597e-01, MSE(pi1): 6.578e-01, MSE(pi2): 2.960e-01, MSE(pi3): 1.872e-01\n",
      "Epoch 25300, Train loss: 5.611e+06, Test loss: 7.487e+06, MSE(e): 5.585e-01, MSE(pi1): 6.573e-01, MSE(pi2): 2.955e-01, MSE(pi3): 1.871e-01\n",
      "Epoch 25400, Train loss: 5.599e+06, Test loss: 7.476e+06, MSE(e): 5.573e-01, MSE(pi1): 6.568e-01, MSE(pi2): 2.950e-01, MSE(pi3): 1.871e-01\n",
      "Epoch 25500, Train loss: 5.587e+06, Test loss: 7.465e+06, MSE(e): 5.561e-01, MSE(pi1): 6.563e-01, MSE(pi2): 2.945e-01, MSE(pi3): 1.870e-01\n",
      "Epoch 25600, Train loss: 5.575e+06, Test loss: 7.454e+06, MSE(e): 5.550e-01, MSE(pi1): 6.559e-01, MSE(pi2): 2.940e-01, MSE(pi3): 1.869e-01\n",
      "Epoch 25700, Train loss: 5.564e+06, Test loss: 7.443e+06, MSE(e): 5.538e-01, MSE(pi1): 6.554e-01, MSE(pi2): 2.935e-01, MSE(pi3): 1.868e-01\n",
      "Epoch 25800, Train loss: 5.552e+06, Test loss: 7.432e+06, MSE(e): 5.527e-01, MSE(pi1): 6.549e-01, MSE(pi2): 2.930e-01, MSE(pi3): 1.868e-01\n",
      "Epoch 25900, Train loss: 5.541e+06, Test loss: 7.422e+06, MSE(e): 5.516e-01, MSE(pi1): 6.545e-01, MSE(pi2): 2.925e-01, MSE(pi3): 1.867e-01\n",
      "Epoch 26000, Train loss: 5.530e+06, Test loss: 7.411e+06, MSE(e): 5.504e-01, MSE(pi1): 6.540e-01, MSE(pi2): 2.920e-01, MSE(pi3): 1.866e-01\n",
      "Epoch 26100, Train loss: 5.519e+06, Test loss: 7.400e+06, MSE(e): 5.493e-01, MSE(pi1): 6.535e-01, MSE(pi2): 2.915e-01, MSE(pi3): 1.865e-01\n",
      "Epoch 26200, Train loss: 5.507e+06, Test loss: 7.390e+06, MSE(e): 5.482e-01, MSE(pi1): 6.531e-01, MSE(pi2): 2.911e-01, MSE(pi3): 1.865e-01\n",
      "Epoch 26300, Train loss: 5.496e+06, Test loss: 7.379e+06, MSE(e): 5.471e-01, MSE(pi1): 6.526e-01, MSE(pi2): 2.906e-01, MSE(pi3): 1.864e-01\n",
      "Epoch 26400, Train loss: 5.485e+06, Test loss: 7.369e+06, MSE(e): 5.460e-01, MSE(pi1): 6.521e-01, MSE(pi2): 2.901e-01, MSE(pi3): 1.863e-01\n",
      "Epoch 26500, Train loss: 5.475e+06, Test loss: 7.358e+06, MSE(e): 5.449e-01, MSE(pi1): 6.517e-01, MSE(pi2): 2.897e-01, MSE(pi3): 1.862e-01\n",
      "Epoch 26600, Train loss: 5.464e+06, Test loss: 7.348e+06, MSE(e): 5.438e-01, MSE(pi1): 6.512e-01, MSE(pi2): 2.892e-01, MSE(pi3): 1.862e-01\n",
      "Epoch 26700, Train loss: 5.453e+06, Test loss: 7.337e+06, MSE(e): 5.428e-01, MSE(pi1): 6.507e-01, MSE(pi2): 2.887e-01, MSE(pi3): 1.861e-01\n",
      "Epoch 26800, Train loss: 5.442e+06, Test loss: 7.327e+06, MSE(e): 5.417e-01, MSE(pi1): 6.503e-01, MSE(pi2): 2.883e-01, MSE(pi3): 1.860e-01\n",
      "Epoch 26900, Train loss: 5.432e+06, Test loss: 7.316e+06, MSE(e): 5.406e-01, MSE(pi1): 6.498e-01, MSE(pi2): 2.878e-01, MSE(pi3): 1.860e-01\n",
      "Epoch 27000, Train loss: 5.421e+06, Test loss: 7.306e+06, MSE(e): 5.396e-01, MSE(pi1): 6.493e-01, MSE(pi2): 2.874e-01, MSE(pi3): 1.859e-01\n",
      "Epoch 27100, Train loss: 5.411e+06, Test loss: 7.296e+06, MSE(e): 5.385e-01, MSE(pi1): 6.489e-01, MSE(pi2): 2.869e-01, MSE(pi3): 1.858e-01\n",
      "Epoch 27200, Train loss: 5.400e+06, Test loss: 7.285e+06, MSE(e): 5.375e-01, MSE(pi1): 6.484e-01, MSE(pi2): 2.865e-01, MSE(pi3): 1.857e-01\n",
      "Epoch 27300, Train loss: 5.390e+06, Test loss: 7.275e+06, MSE(e): 5.365e-01, MSE(pi1): 6.479e-01, MSE(pi2): 2.861e-01, MSE(pi3): 1.857e-01\n",
      "Epoch 27400, Train loss: 5.380e+06, Test loss: 7.265e+06, MSE(e): 5.355e-01, MSE(pi1): 6.475e-01, MSE(pi2): 2.856e-01, MSE(pi3): 1.856e-01\n",
      "Epoch 27500, Train loss: 5.370e+06, Test loss: 7.255e+06, MSE(e): 5.344e-01, MSE(pi1): 6.470e-01, MSE(pi2): 2.852e-01, MSE(pi3): 1.855e-01\n",
      "Epoch 27600, Train loss: 5.360e+06, Test loss: 7.245e+06, MSE(e): 5.334e-01, MSE(pi1): 6.466e-01, MSE(pi2): 2.848e-01, MSE(pi3): 1.855e-01\n",
      "Epoch 27700, Train loss: 5.350e+06, Test loss: 7.235e+06, MSE(e): 5.324e-01, MSE(pi1): 6.461e-01, MSE(pi2): 2.843e-01, MSE(pi3): 1.854e-01\n",
      "Epoch 27800, Train loss: 5.340e+06, Test loss: 7.225e+06, MSE(e): 5.314e-01, MSE(pi1): 6.456e-01, MSE(pi2): 2.839e-01, MSE(pi3): 1.853e-01\n",
      "Epoch 27900, Train loss: 5.330e+06, Test loss: 7.215e+06, MSE(e): 5.305e-01, MSE(pi1): 6.452e-01, MSE(pi2): 2.835e-01, MSE(pi3): 1.853e-01\n",
      "Epoch 28000, Train loss: 5.320e+06, Test loss: 7.205e+06, MSE(e): 5.295e-01, MSE(pi1): 6.447e-01, MSE(pi2): 2.831e-01, MSE(pi3): 1.852e-01\n",
      "Epoch 28100, Train loss: 5.310e+06, Test loss: 7.195e+06, MSE(e): 5.285e-01, MSE(pi1): 6.443e-01, MSE(pi2): 2.826e-01, MSE(pi3): 1.851e-01\n",
      "Epoch 28200, Train loss: 5.300e+06, Test loss: 7.185e+06, MSE(e): 5.275e-01, MSE(pi1): 6.438e-01, MSE(pi2): 2.822e-01, MSE(pi3): 1.851e-01\n",
      "Epoch 28300, Train loss: 5.291e+06, Test loss: 7.175e+06, MSE(e): 5.266e-01, MSE(pi1): 6.434e-01, MSE(pi2): 2.818e-01, MSE(pi3): 1.850e-01\n",
      "Epoch 28400, Train loss: 5.281e+06, Test loss: 7.165e+06, MSE(e): 5.256e-01, MSE(pi1): 6.429e-01, MSE(pi2): 2.814e-01, MSE(pi3): 1.849e-01\n",
      "Epoch 28500, Train loss: 5.272e+06, Test loss: 7.155e+06, MSE(e): 5.246e-01, MSE(pi1): 6.425e-01, MSE(pi2): 2.810e-01, MSE(pi3): 1.849e-01\n",
      "Epoch 28600, Train loss: 5.262e+06, Test loss: 7.146e+06, MSE(e): 5.237e-01, MSE(pi1): 6.420e-01, MSE(pi2): 2.806e-01, MSE(pi3): 1.848e-01\n",
      "Epoch 28700, Train loss: 5.253e+06, Test loss: 7.136e+06, MSE(e): 5.228e-01, MSE(pi1): 6.415e-01, MSE(pi2): 2.802e-01, MSE(pi3): 1.847e-01\n",
      "Epoch 28800, Train loss: 5.243e+06, Test loss: 7.126e+06, MSE(e): 5.218e-01, MSE(pi1): 6.411e-01, MSE(pi2): 2.798e-01, MSE(pi3): 1.847e-01\n",
      "Epoch 28900, Train loss: 5.234e+06, Test loss: 7.117e+06, MSE(e): 5.209e-01, MSE(pi1): 6.406e-01, MSE(pi2): 2.794e-01, MSE(pi3): 1.846e-01\n",
      "Epoch 29000, Train loss: 5.225e+06, Test loss: 7.107e+06, MSE(e): 5.200e-01, MSE(pi1): 6.402e-01, MSE(pi2): 2.790e-01, MSE(pi3): 1.846e-01\n",
      "Epoch 29100, Train loss: 5.216e+06, Test loss: 7.098e+06, MSE(e): 5.190e-01, MSE(pi1): 6.397e-01, MSE(pi2): 2.786e-01, MSE(pi3): 1.845e-01\n",
      "Epoch 29200, Train loss: 5.206e+06, Test loss: 7.088e+06, MSE(e): 5.181e-01, MSE(pi1): 6.393e-01, MSE(pi2): 2.782e-01, MSE(pi3): 1.844e-01\n",
      "Epoch 29300, Train loss: 5.197e+06, Test loss: 7.079e+06, MSE(e): 5.172e-01, MSE(pi1): 6.388e-01, MSE(pi2): 2.778e-01, MSE(pi3): 1.844e-01\n",
      "Epoch 29400, Train loss: 5.188e+06, Test loss: 7.069e+06, MSE(e): 5.163e-01, MSE(pi1): 6.384e-01, MSE(pi2): 2.774e-01, MSE(pi3): 1.843e-01\n",
      "Epoch 29500, Train loss: 5.179e+06, Test loss: 7.060e+06, MSE(e): 5.154e-01, MSE(pi1): 6.379e-01, MSE(pi2): 2.770e-01, MSE(pi3): 1.842e-01\n",
      "Epoch 29600, Train loss: 5.170e+06, Test loss: 7.050e+06, MSE(e): 5.145e-01, MSE(pi1): 6.375e-01, MSE(pi2): 2.766e-01, MSE(pi3): 1.842e-01\n",
      "Epoch 29700, Train loss: 5.161e+06, Test loss: 7.041e+06, MSE(e): 5.136e-01, MSE(pi1): 6.370e-01, MSE(pi2): 2.762e-01, MSE(pi3): 1.841e-01\n",
      "Epoch 29800, Train loss: 5.152e+06, Test loss: 7.032e+06, MSE(e): 5.127e-01, MSE(pi1): 6.366e-01, MSE(pi2): 2.759e-01, MSE(pi3): 1.841e-01\n",
      "Epoch 29900, Train loss: 5.144e+06, Test loss: 7.022e+06, MSE(e): 5.119e-01, MSE(pi1): 6.361e-01, MSE(pi2): 2.755e-01, MSE(pi3): 1.840e-01\n",
      "Epoch 30000, Train loss: 5.135e+06, Test loss: 7.013e+06, MSE(e): 5.110e-01, MSE(pi1): 6.357e-01, MSE(pi2): 2.751e-01, MSE(pi3): 1.839e-01\n",
      "Epoch 30100, Train loss: 5.126e+06, Test loss: 7.004e+06, MSE(e): 5.101e-01, MSE(pi1): 6.353e-01, MSE(pi2): 2.747e-01, MSE(pi3): 1.839e-01\n",
      "Epoch 30200, Train loss: 5.117e+06, Test loss: 6.995e+06, MSE(e): 5.092e-01, MSE(pi1): 6.348e-01, MSE(pi2): 2.744e-01, MSE(pi3): 1.838e-01\n",
      "Epoch 30300, Train loss: 5.109e+06, Test loss: 6.986e+06, MSE(e): 5.084e-01, MSE(pi1): 6.344e-01, MSE(pi2): 2.740e-01, MSE(pi3): 1.837e-01\n",
      "Epoch 30400, Train loss: 5.100e+06, Test loss: 6.977e+06, MSE(e): 5.075e-01, MSE(pi1): 6.339e-01, MSE(pi2): 2.736e-01, MSE(pi3): 1.837e-01\n",
      "Epoch 30500, Train loss: 5.091e+06, Test loss: 6.967e+06, MSE(e): 5.066e-01, MSE(pi1): 6.335e-01, MSE(pi2): 2.732e-01, MSE(pi3): 1.836e-01\n",
      "Epoch 30600, Train loss: 5.083e+06, Test loss: 6.958e+06, MSE(e): 5.058e-01, MSE(pi1): 6.330e-01, MSE(pi2): 2.729e-01, MSE(pi3): 1.836e-01\n",
      "Epoch 30700, Train loss: 5.074e+06, Test loss: 6.949e+06, MSE(e): 5.049e-01, MSE(pi1): 6.326e-01, MSE(pi2): 2.725e-01, MSE(pi3): 1.835e-01\n",
      "Epoch 30800, Train loss: 5.066e+06, Test loss: 6.940e+06, MSE(e): 5.041e-01, MSE(pi1): 6.321e-01, MSE(pi2): 2.721e-01, MSE(pi3): 1.834e-01\n",
      "Epoch 30900, Train loss: 5.058e+06, Test loss: 6.931e+06, MSE(e): 5.033e-01, MSE(pi1): 6.317e-01, MSE(pi2): 2.718e-01, MSE(pi3): 1.834e-01\n",
      "Epoch 31000, Train loss: 5.049e+06, Test loss: 6.923e+06, MSE(e): 5.024e-01, MSE(pi1): 6.313e-01, MSE(pi2): 2.714e-01, MSE(pi3): 1.833e-01\n",
      "Epoch 31100, Train loss: 5.041e+06, Test loss: 6.914e+06, MSE(e): 5.016e-01, MSE(pi1): 6.308e-01, MSE(pi2): 2.711e-01, MSE(pi3): 1.833e-01\n",
      "Epoch 31200, Train loss: 5.032e+06, Test loss: 6.905e+06, MSE(e): 5.008e-01, MSE(pi1): 6.304e-01, MSE(pi2): 2.707e-01, MSE(pi3): 1.832e-01\n",
      "Epoch 31300, Train loss: 5.024e+06, Test loss: 6.896e+06, MSE(e): 4.999e-01, MSE(pi1): 6.299e-01, MSE(pi2): 2.703e-01, MSE(pi3): 1.831e-01\n",
      "Epoch 31400, Train loss: 5.016e+06, Test loss: 6.887e+06, MSE(e): 4.991e-01, MSE(pi1): 6.295e-01, MSE(pi2): 2.700e-01, MSE(pi3): 1.831e-01\n",
      "Epoch 31500, Train loss: 5.008e+06, Test loss: 6.878e+06, MSE(e): 4.983e-01, MSE(pi1): 6.290e-01, MSE(pi2): 2.696e-01, MSE(pi3): 1.830e-01\n",
      "Epoch 31600, Train loss: 5.000e+06, Test loss: 6.869e+06, MSE(e): 4.975e-01, MSE(pi1): 6.286e-01, MSE(pi2): 2.693e-01, MSE(pi3): 1.830e-01\n",
      "Epoch 31700, Train loss: 4.991e+06, Test loss: 6.861e+06, MSE(e): 4.967e-01, MSE(pi1): 6.282e-01, MSE(pi2): 2.689e-01, MSE(pi3): 1.829e-01\n",
      "Epoch 31800, Train loss: 4.983e+06, Test loss: 6.852e+06, MSE(e): 4.959e-01, MSE(pi1): 6.277e-01, MSE(pi2): 2.686e-01, MSE(pi3): 1.828e-01\n",
      "Epoch 31900, Train loss: 4.975e+06, Test loss: 6.843e+06, MSE(e): 4.950e-01, MSE(pi1): 6.273e-01, MSE(pi2): 2.682e-01, MSE(pi3): 1.828e-01\n",
      "Epoch 32000, Train loss: 4.967e+06, Test loss: 6.834e+06, MSE(e): 4.942e-01, MSE(pi1): 6.268e-01, MSE(pi2): 2.679e-01, MSE(pi3): 1.827e-01\n",
      "Epoch 32100, Train loss: 4.959e+06, Test loss: 6.826e+06, MSE(e): 4.934e-01, MSE(pi1): 6.264e-01, MSE(pi2): 2.675e-01, MSE(pi3): 1.827e-01\n",
      "Epoch 32200, Train loss: 4.951e+06, Test loss: 6.817e+06, MSE(e): 4.926e-01, MSE(pi1): 6.259e-01, MSE(pi2): 2.672e-01, MSE(pi3): 1.826e-01\n",
      "Epoch 32300, Train loss: 4.943e+06, Test loss: 6.808e+06, MSE(e): 4.918e-01, MSE(pi1): 6.255e-01, MSE(pi2): 2.668e-01, MSE(pi3): 1.825e-01\n",
      "Epoch 32400, Train loss: 4.935e+06, Test loss: 6.800e+06, MSE(e): 4.911e-01, MSE(pi1): 6.250e-01, MSE(pi2): 2.665e-01, MSE(pi3): 1.825e-01\n",
      "Epoch 32500, Train loss: 4.927e+06, Test loss: 6.791e+06, MSE(e): 4.903e-01, MSE(pi1): 6.246e-01, MSE(pi2): 2.662e-01, MSE(pi3): 1.824e-01\n",
      "Epoch 32600, Train loss: 4.919e+06, Test loss: 6.783e+06, MSE(e): 4.895e-01, MSE(pi1): 6.241e-01, MSE(pi2): 2.658e-01, MSE(pi3): 1.824e-01\n",
      "Epoch 32700, Train loss: 4.912e+06, Test loss: 6.774e+06, MSE(e): 4.887e-01, MSE(pi1): 6.237e-01, MSE(pi2): 2.655e-01, MSE(pi3): 1.823e-01\n",
      "Epoch 32800, Train loss: 4.904e+06, Test loss: 6.765e+06, MSE(e): 4.879e-01, MSE(pi1): 6.233e-01, MSE(pi2): 2.651e-01, MSE(pi3): 1.822e-01\n",
      "Epoch 32900, Train loss: 4.896e+06, Test loss: 6.757e+06, MSE(e): 4.871e-01, MSE(pi1): 6.228e-01, MSE(pi2): 2.648e-01, MSE(pi3): 1.822e-01\n",
      "Epoch 33000, Train loss: 4.888e+06, Test loss: 6.748e+06, MSE(e): 4.863e-01, MSE(pi1): 6.224e-01, MSE(pi2): 2.645e-01, MSE(pi3): 1.821e-01\n",
      "Epoch 33100, Train loss: 4.880e+06, Test loss: 6.740e+06, MSE(e): 4.856e-01, MSE(pi1): 6.219e-01, MSE(pi2): 2.641e-01, MSE(pi3): 1.820e-01\n",
      "Epoch 33200, Train loss: 4.873e+06, Test loss: 6.731e+06, MSE(e): 4.848e-01, MSE(pi1): 6.215e-01, MSE(pi2): 2.638e-01, MSE(pi3): 1.820e-01\n",
      "Epoch 33300, Train loss: 4.865e+06, Test loss: 6.723e+06, MSE(e): 4.840e-01, MSE(pi1): 6.210e-01, MSE(pi2): 2.635e-01, MSE(pi3): 1.819e-01\n",
      "Epoch 33400, Train loss: 4.857e+06, Test loss: 6.714e+06, MSE(e): 4.833e-01, MSE(pi1): 6.206e-01, MSE(pi2): 2.631e-01, MSE(pi3): 1.819e-01\n",
      "Epoch 33500, Train loss: 4.850e+06, Test loss: 6.706e+06, MSE(e): 4.825e-01, MSE(pi1): 6.201e-01, MSE(pi2): 2.628e-01, MSE(pi3): 1.818e-01\n",
      "Epoch 33600, Train loss: 4.842e+06, Test loss: 6.698e+06, MSE(e): 4.817e-01, MSE(pi1): 6.197e-01, MSE(pi2): 2.625e-01, MSE(pi3): 1.817e-01\n",
      "Epoch 33700, Train loss: 4.834e+06, Test loss: 6.689e+06, MSE(e): 4.810e-01, MSE(pi1): 6.192e-01, MSE(pi2): 2.621e-01, MSE(pi3): 1.817e-01\n",
      "Epoch 33800, Train loss: 4.827e+06, Test loss: 6.681e+06, MSE(e): 4.802e-01, MSE(pi1): 6.188e-01, MSE(pi2): 2.618e-01, MSE(pi3): 1.816e-01\n",
      "Epoch 33900, Train loss: 4.819e+06, Test loss: 6.672e+06, MSE(e): 4.794e-01, MSE(pi1): 6.183e-01, MSE(pi2): 2.615e-01, MSE(pi3): 1.816e-01\n",
      "Epoch 34000, Train loss: 4.811e+06, Test loss: 6.664e+06, MSE(e): 4.787e-01, MSE(pi1): 6.178e-01, MSE(pi2): 2.611e-01, MSE(pi3): 1.815e-01\n",
      "Epoch 34100, Train loss: 4.804e+06, Test loss: 6.655e+06, MSE(e): 4.779e-01, MSE(pi1): 6.174e-01, MSE(pi2): 2.608e-01, MSE(pi3): 1.814e-01\n",
      "Epoch 34200, Train loss: 4.796e+06, Test loss: 6.647e+06, MSE(e): 4.772e-01, MSE(pi1): 6.169e-01, MSE(pi2): 2.605e-01, MSE(pi3): 1.814e-01\n",
      "Epoch 34300, Train loss: 4.789e+06, Test loss: 6.638e+06, MSE(e): 4.764e-01, MSE(pi1): 6.165e-01, MSE(pi2): 2.601e-01, MSE(pi3): 1.813e-01\n",
      "Epoch 34400, Train loss: 4.781e+06, Test loss: 6.630e+06, MSE(e): 4.757e-01, MSE(pi1): 6.160e-01, MSE(pi2): 2.598e-01, MSE(pi3): 1.812e-01\n",
      "Epoch 34500, Train loss: 4.774e+06, Test loss: 6.621e+06, MSE(e): 4.749e-01, MSE(pi1): 6.156e-01, MSE(pi2): 2.595e-01, MSE(pi3): 1.812e-01\n",
      "Epoch 34600, Train loss: 4.766e+06, Test loss: 6.613e+06, MSE(e): 4.742e-01, MSE(pi1): 6.151e-01, MSE(pi2): 2.592e-01, MSE(pi3): 1.811e-01\n",
      "Epoch 34700, Train loss: 4.759e+06, Test loss: 6.605e+06, MSE(e): 4.734e-01, MSE(pi1): 6.146e-01, MSE(pi2): 2.588e-01, MSE(pi3): 1.811e-01\n",
      "Epoch 34800, Train loss: 4.751e+06, Test loss: 6.596e+06, MSE(e): 4.727e-01, MSE(pi1): 6.142e-01, MSE(pi2): 2.585e-01, MSE(pi3): 1.810e-01\n",
      "Epoch 34900, Train loss: 4.744e+06, Test loss: 6.588e+06, MSE(e): 4.719e-01, MSE(pi1): 6.137e-01, MSE(pi2): 2.582e-01, MSE(pi3): 1.809e-01\n",
      "Epoch 35000, Train loss: 4.736e+06, Test loss: 6.579e+06, MSE(e): 4.712e-01, MSE(pi1): 6.132e-01, MSE(pi2): 2.579e-01, MSE(pi3): 1.809e-01\n",
      "Epoch 35100, Train loss: 4.729e+06, Test loss: 6.571e+06, MSE(e): 4.705e-01, MSE(pi1): 6.128e-01, MSE(pi2): 2.575e-01, MSE(pi3): 1.808e-01\n",
      "Epoch 35200, Train loss: 4.722e+06, Test loss: 6.562e+06, MSE(e): 4.697e-01, MSE(pi1): 6.123e-01, MSE(pi2): 2.572e-01, MSE(pi3): 1.807e-01\n",
      "Epoch 35300, Train loss: 4.714e+06, Test loss: 6.554e+06, MSE(e): 4.690e-01, MSE(pi1): 6.118e-01, MSE(pi2): 2.569e-01, MSE(pi3): 1.807e-01\n",
      "Epoch 35400, Train loss: 4.707e+06, Test loss: 6.545e+06, MSE(e): 4.682e-01, MSE(pi1): 6.114e-01, MSE(pi2): 2.566e-01, MSE(pi3): 1.806e-01\n",
      "Epoch 35500, Train loss: 4.700e+06, Test loss: 6.537e+06, MSE(e): 4.675e-01, MSE(pi1): 6.109e-01, MSE(pi2): 2.563e-01, MSE(pi3): 1.805e-01\n",
      "Epoch 35600, Train loss: 4.692e+06, Test loss: 6.528e+06, MSE(e): 4.668e-01, MSE(pi1): 6.104e-01, MSE(pi2): 2.559e-01, MSE(pi3): 1.805e-01\n",
      "Epoch 35700, Train loss: 4.685e+06, Test loss: 6.520e+06, MSE(e): 4.660e-01, MSE(pi1): 6.100e-01, MSE(pi2): 2.556e-01, MSE(pi3): 1.804e-01\n",
      "Epoch 35800, Train loss: 4.678e+06, Test loss: 6.511e+06, MSE(e): 4.653e-01, MSE(pi1): 6.095e-01, MSE(pi2): 2.553e-01, MSE(pi3): 1.803e-01\n",
      "Epoch 35900, Train loss: 4.670e+06, Test loss: 6.503e+06, MSE(e): 4.646e-01, MSE(pi1): 6.090e-01, MSE(pi2): 2.550e-01, MSE(pi3): 1.803e-01\n",
      "Epoch 36000, Train loss: 4.663e+06, Test loss: 6.494e+06, MSE(e): 4.639e-01, MSE(pi1): 6.085e-01, MSE(pi2): 2.546e-01, MSE(pi3): 1.802e-01\n",
      "Epoch 36100, Train loss: 4.656e+06, Test loss: 6.485e+06, MSE(e): 4.631e-01, MSE(pi1): 6.080e-01, MSE(pi2): 2.543e-01, MSE(pi3): 1.801e-01\n",
      "Epoch 36200, Train loss: 4.648e+06, Test loss: 6.477e+06, MSE(e): 4.624e-01, MSE(pi1): 6.076e-01, MSE(pi2): 2.540e-01, MSE(pi3): 1.801e-01\n",
      "Epoch 36300, Train loss: 4.641e+06, Test loss: 6.468e+06, MSE(e): 4.617e-01, MSE(pi1): 6.071e-01, MSE(pi2): 2.537e-01, MSE(pi3): 1.800e-01\n",
      "Epoch 36400, Train loss: 4.634e+06, Test loss: 6.460e+06, MSE(e): 4.610e-01, MSE(pi1): 6.066e-01, MSE(pi2): 2.534e-01, MSE(pi3): 1.799e-01\n",
      "Epoch 36500, Train loss: 4.627e+06, Test loss: 6.451e+06, MSE(e): 4.602e-01, MSE(pi1): 6.061e-01, MSE(pi2): 2.531e-01, MSE(pi3): 1.799e-01\n",
      "Epoch 36600, Train loss: 4.619e+06, Test loss: 6.442e+06, MSE(e): 4.595e-01, MSE(pi1): 6.056e-01, MSE(pi2): 2.527e-01, MSE(pi3): 1.798e-01\n",
      "Epoch 36700, Train loss: 4.612e+06, Test loss: 6.434e+06, MSE(e): 4.588e-01, MSE(pi1): 6.051e-01, MSE(pi2): 2.524e-01, MSE(pi3): 1.797e-01\n",
      "Epoch 36800, Train loss: 4.605e+06, Test loss: 6.425e+06, MSE(e): 4.581e-01, MSE(pi1): 6.046e-01, MSE(pi2): 2.521e-01, MSE(pi3): 1.797e-01\n",
      "Epoch 36900, Train loss: 4.598e+06, Test loss: 6.416e+06, MSE(e): 4.574e-01, MSE(pi1): 6.042e-01, MSE(pi2): 2.518e-01, MSE(pi3): 1.796e-01\n",
      "Epoch 37000, Train loss: 4.591e+06, Test loss: 6.407e+06, MSE(e): 4.567e-01, MSE(pi1): 6.037e-01, MSE(pi2): 2.515e-01, MSE(pi3): 1.795e-01\n",
      "Epoch 37100, Train loss: 4.584e+06, Test loss: 6.399e+06, MSE(e): 4.559e-01, MSE(pi1): 6.032e-01, MSE(pi2): 2.512e-01, MSE(pi3): 1.794e-01\n",
      "Epoch 37200, Train loss: 4.577e+06, Test loss: 6.390e+06, MSE(e): 4.552e-01, MSE(pi1): 6.027e-01, MSE(pi2): 2.508e-01, MSE(pi3): 1.794e-01\n",
      "Epoch 37300, Train loss: 4.569e+06, Test loss: 6.381e+06, MSE(e): 4.545e-01, MSE(pi1): 6.022e-01, MSE(pi2): 2.505e-01, MSE(pi3): 1.793e-01\n",
      "Epoch 37400, Train loss: 4.562e+06, Test loss: 6.372e+06, MSE(e): 4.538e-01, MSE(pi1): 6.017e-01, MSE(pi2): 2.502e-01, MSE(pi3): 1.792e-01\n",
      "Epoch 37500, Train loss: 4.555e+06, Test loss: 6.363e+06, MSE(e): 4.531e-01, MSE(pi1): 6.012e-01, MSE(pi2): 2.499e-01, MSE(pi3): 1.792e-01\n",
      "Epoch 37600, Train loss: 4.548e+06, Test loss: 6.354e+06, MSE(e): 4.524e-01, MSE(pi1): 6.007e-01, MSE(pi2): 2.496e-01, MSE(pi3): 1.791e-01\n",
      "Epoch 37700, Train loss: 4.541e+06, Test loss: 6.345e+06, MSE(e): 4.517e-01, MSE(pi1): 6.002e-01, MSE(pi2): 2.493e-01, MSE(pi3): 1.790e-01\n",
      "Epoch 37800, Train loss: 4.534e+06, Test loss: 6.336e+06, MSE(e): 4.510e-01, MSE(pi1): 5.997e-01, MSE(pi2): 2.490e-01, MSE(pi3): 1.789e-01\n",
      "Epoch 37900, Train loss: 4.527e+06, Test loss: 6.327e+06, MSE(e): 4.503e-01, MSE(pi1): 5.992e-01, MSE(pi2): 2.487e-01, MSE(pi3): 1.789e-01\n",
      "Epoch 38000, Train loss: 4.520e+06, Test loss: 6.318e+06, MSE(e): 4.496e-01, MSE(pi1): 5.987e-01, MSE(pi2): 2.483e-01, MSE(pi3): 1.788e-01\n",
      "Epoch 38100, Train loss: 4.513e+06, Test loss: 6.309e+06, MSE(e): 4.489e-01, MSE(pi1): 5.981e-01, MSE(pi2): 2.480e-01, MSE(pi3): 1.787e-01\n",
      "Epoch 38200, Train loss: 4.506e+06, Test loss: 6.300e+06, MSE(e): 4.482e-01, MSE(pi1): 5.976e-01, MSE(pi2): 2.477e-01, MSE(pi3): 1.786e-01\n",
      "Epoch 38300, Train loss: 4.499e+06, Test loss: 6.291e+06, MSE(e): 4.475e-01, MSE(pi1): 5.971e-01, MSE(pi2): 2.474e-01, MSE(pi3): 1.785e-01\n",
      "Epoch 38400, Train loss: 4.492e+06, Test loss: 6.281e+06, MSE(e): 4.468e-01, MSE(pi1): 5.966e-01, MSE(pi2): 2.471e-01, MSE(pi3): 1.785e-01\n",
      "Epoch 38500, Train loss: 4.485e+06, Test loss: 6.272e+06, MSE(e): 4.461e-01, MSE(pi1): 5.961e-01, MSE(pi2): 2.468e-01, MSE(pi3): 1.784e-01\n",
      "Epoch 38600, Train loss: 4.478e+06, Test loss: 6.263e+06, MSE(e): 4.454e-01, MSE(pi1): 5.956e-01, MSE(pi2): 2.465e-01, MSE(pi3): 1.783e-01\n",
      "Epoch 38700, Train loss: 4.472e+06, Test loss: 6.254e+06, MSE(e): 4.448e-01, MSE(pi1): 5.950e-01, MSE(pi2): 2.462e-01, MSE(pi3): 1.782e-01\n",
      "Epoch 38800, Train loss: 4.465e+06, Test loss: 6.244e+06, MSE(e): 4.441e-01, MSE(pi1): 5.945e-01, MSE(pi2): 2.459e-01, MSE(pi3): 1.782e-01\n",
      "Epoch 38900, Train loss: 4.458e+06, Test loss: 6.235e+06, MSE(e): 4.434e-01, MSE(pi1): 5.940e-01, MSE(pi2): 2.456e-01, MSE(pi3): 1.781e-01\n",
      "Epoch 39000, Train loss: 4.451e+06, Test loss: 6.226e+06, MSE(e): 4.427e-01, MSE(pi1): 5.934e-01, MSE(pi2): 2.453e-01, MSE(pi3): 1.780e-01\n",
      "Epoch 39100, Train loss: 4.444e+06, Test loss: 6.216e+06, MSE(e): 4.420e-01, MSE(pi1): 5.929e-01, MSE(pi2): 2.450e-01, MSE(pi3): 1.779e-01\n",
      "Epoch 39200, Train loss: 4.438e+06, Test loss: 6.207e+06, MSE(e): 4.414e-01, MSE(pi1): 5.924e-01, MSE(pi2): 2.447e-01, MSE(pi3): 1.778e-01\n",
      "Epoch 39300, Train loss: 4.431e+06, Test loss: 6.197e+06, MSE(e): 4.407e-01, MSE(pi1): 5.918e-01, MSE(pi2): 2.444e-01, MSE(pi3): 1.778e-01\n",
      "Epoch 39400, Train loss: 4.424e+06, Test loss: 6.188e+06, MSE(e): 4.400e-01, MSE(pi1): 5.913e-01, MSE(pi2): 2.441e-01, MSE(pi3): 1.777e-01\n",
      "Epoch 39500, Train loss: 4.417e+06, Test loss: 6.178e+06, MSE(e): 4.394e-01, MSE(pi1): 5.908e-01, MSE(pi2): 2.438e-01, MSE(pi3): 1.776e-01\n",
      "Epoch 39600, Train loss: 4.411e+06, Test loss: 6.169e+06, MSE(e): 4.387e-01, MSE(pi1): 5.902e-01, MSE(pi2): 2.435e-01, MSE(pi3): 1.775e-01\n",
      "Epoch 39700, Train loss: 4.404e+06, Test loss: 6.159e+06, MSE(e): 4.380e-01, MSE(pi1): 5.897e-01, MSE(pi2): 2.432e-01, MSE(pi3): 1.774e-01\n",
      "Epoch 39800, Train loss: 4.397e+06, Test loss: 6.149e+06, MSE(e): 4.374e-01, MSE(pi1): 5.891e-01, MSE(pi2): 2.429e-01, MSE(pi3): 1.773e-01\n",
      "Epoch 39900, Train loss: 4.391e+06, Test loss: 6.140e+06, MSE(e): 4.367e-01, MSE(pi1): 5.886e-01, MSE(pi2): 2.426e-01, MSE(pi3): 1.772e-01\n",
      "Epoch 40000, Train loss: 4.384e+06, Test loss: 6.130e+06, MSE(e): 4.360e-01, MSE(pi1): 5.880e-01, MSE(pi2): 2.423e-01, MSE(pi3): 1.772e-01\n",
      "Epoch 40100, Train loss: 4.378e+06, Test loss: 6.120e+06, MSE(e): 4.354e-01, MSE(pi1): 5.875e-01, MSE(pi2): 2.420e-01, MSE(pi3): 1.771e-01\n",
      "Epoch 40200, Train loss: 4.371e+06, Test loss: 6.110e+06, MSE(e): 4.347e-01, MSE(pi1): 5.869e-01, MSE(pi2): 2.417e-01, MSE(pi3): 1.770e-01\n",
      "Epoch 40300, Train loss: 4.365e+06, Test loss: 6.101e+06, MSE(e): 4.341e-01, MSE(pi1): 5.863e-01, MSE(pi2): 2.414e-01, MSE(pi3): 1.769e-01\n",
      "Epoch 40400, Train loss: 4.358e+06, Test loss: 6.091e+06, MSE(e): 4.334e-01, MSE(pi1): 5.858e-01, MSE(pi2): 2.411e-01, MSE(pi3): 1.768e-01\n",
      "Epoch 40500, Train loss: 4.352e+06, Test loss: 6.081e+06, MSE(e): 4.328e-01, MSE(pi1): 5.852e-01, MSE(pi2): 2.408e-01, MSE(pi3): 1.767e-01\n",
      "Epoch 40600, Train loss: 4.345e+06, Test loss: 6.071e+06, MSE(e): 4.322e-01, MSE(pi1): 5.846e-01, MSE(pi2): 2.405e-01, MSE(pi3): 1.766e-01\n",
      "Epoch 40700, Train loss: 4.339e+06, Test loss: 6.061e+06, MSE(e): 4.315e-01, MSE(pi1): 5.841e-01, MSE(pi2): 2.403e-01, MSE(pi3): 1.766e-01\n",
      "Epoch 40800, Train loss: 4.333e+06, Test loss: 6.051e+06, MSE(e): 4.309e-01, MSE(pi1): 5.835e-01, MSE(pi2): 2.400e-01, MSE(pi3): 1.765e-01\n",
      "Epoch 40900, Train loss: 4.326e+06, Test loss: 6.041e+06, MSE(e): 4.303e-01, MSE(pi1): 5.829e-01, MSE(pi2): 2.397e-01, MSE(pi3): 1.764e-01\n",
      "Epoch 41000, Train loss: 4.320e+06, Test loss: 6.031e+06, MSE(e): 4.296e-01, MSE(pi1): 5.823e-01, MSE(pi2): 2.394e-01, MSE(pi3): 1.763e-01\n",
      "Epoch 41100, Train loss: 4.314e+06, Test loss: 6.021e+06, MSE(e): 4.290e-01, MSE(pi1): 5.818e-01, MSE(pi2): 2.391e-01, MSE(pi3): 1.762e-01\n",
      "Epoch 41200, Train loss: 4.307e+06, Test loss: 6.011e+06, MSE(e): 4.284e-01, MSE(pi1): 5.812e-01, MSE(pi2): 2.388e-01, MSE(pi3): 1.761e-01\n",
      "Epoch 41300, Train loss: 4.301e+06, Test loss: 6.001e+06, MSE(e): 4.278e-01, MSE(pi1): 5.806e-01, MSE(pi2): 2.385e-01, MSE(pi3): 1.760e-01\n",
      "Epoch 41400, Train loss: 4.295e+06, Test loss: 5.991e+06, MSE(e): 4.271e-01, MSE(pi1): 5.800e-01, MSE(pi2): 2.383e-01, MSE(pi3): 1.759e-01\n",
      "Epoch 41500, Train loss: 4.289e+06, Test loss: 5.981e+06, MSE(e): 4.265e-01, MSE(pi1): 5.794e-01, MSE(pi2): 2.380e-01, MSE(pi3): 1.758e-01\n",
      "Epoch 41600, Train loss: 4.283e+06, Test loss: 5.971e+06, MSE(e): 4.259e-01, MSE(pi1): 5.788e-01, MSE(pi2): 2.377e-01, MSE(pi3): 1.757e-01\n",
      "Epoch 41700, Train loss: 4.277e+06, Test loss: 5.961e+06, MSE(e): 4.253e-01, MSE(pi1): 5.782e-01, MSE(pi2): 2.374e-01, MSE(pi3): 1.756e-01\n",
      "Epoch 41800, Train loss: 4.271e+06, Test loss: 5.951e+06, MSE(e): 4.247e-01, MSE(pi1): 5.776e-01, MSE(pi2): 2.372e-01, MSE(pi3): 1.755e-01\n",
      "Epoch 41900, Train loss: 4.265e+06, Test loss: 5.941e+06, MSE(e): 4.241e-01, MSE(pi1): 5.770e-01, MSE(pi2): 2.369e-01, MSE(pi3): 1.754e-01\n",
      "Epoch 42000, Train loss: 4.259e+06, Test loss: 5.931e+06, MSE(e): 4.235e-01, MSE(pi1): 5.764e-01, MSE(pi2): 2.366e-01, MSE(pi3): 1.754e-01\n",
      "Epoch 42100, Train loss: 4.253e+06, Test loss: 5.921e+06, MSE(e): 4.229e-01, MSE(pi1): 5.758e-01, MSE(pi2): 2.363e-01, MSE(pi3): 1.753e-01\n",
      "Epoch 42200, Train loss: 4.247e+06, Test loss: 5.911e+06, MSE(e): 4.223e-01, MSE(pi1): 5.753e-01, MSE(pi2): 2.361e-01, MSE(pi3): 1.752e-01\n",
      "Epoch 42300, Train loss: 4.241e+06, Test loss: 5.901e+06, MSE(e): 4.217e-01, MSE(pi1): 5.747e-01, MSE(pi2): 2.358e-01, MSE(pi3): 1.751e-01\n",
      "Epoch 42400, Train loss: 4.235e+06, Test loss: 5.891e+06, MSE(e): 4.212e-01, MSE(pi1): 5.741e-01, MSE(pi2): 2.355e-01, MSE(pi3): 1.750e-01\n",
      "Epoch 42500, Train loss: 4.229e+06, Test loss: 5.880e+06, MSE(e): 4.206e-01, MSE(pi1): 5.735e-01, MSE(pi2): 2.353e-01, MSE(pi3): 1.749e-01\n",
      "Epoch 42600, Train loss: 4.223e+06, Test loss: 5.870e+06, MSE(e): 4.200e-01, MSE(pi1): 5.729e-01, MSE(pi2): 2.350e-01, MSE(pi3): 1.748e-01\n",
      "Epoch 42700, Train loss: 4.218e+06, Test loss: 5.860e+06, MSE(e): 4.194e-01, MSE(pi1): 5.722e-01, MSE(pi2): 2.347e-01, MSE(pi3): 1.747e-01\n",
      "Epoch 42800, Train loss: 4.212e+06, Test loss: 5.850e+06, MSE(e): 4.188e-01, MSE(pi1): 5.716e-01, MSE(pi2): 2.345e-01, MSE(pi3): 1.746e-01\n",
      "Epoch 42900, Train loss: 4.206e+06, Test loss: 5.840e+06, MSE(e): 4.183e-01, MSE(pi1): 5.710e-01, MSE(pi2): 2.342e-01, MSE(pi3): 1.745e-01\n",
      "Epoch 43000, Train loss: 4.201e+06, Test loss: 5.830e+06, MSE(e): 4.177e-01, MSE(pi1): 5.704e-01, MSE(pi2): 2.340e-01, MSE(pi3): 1.744e-01\n",
      "Epoch 43100, Train loss: 4.195e+06, Test loss: 5.820e+06, MSE(e): 4.172e-01, MSE(pi1): 5.698e-01, MSE(pi2): 2.337e-01, MSE(pi3): 1.743e-01\n",
      "Epoch 43200, Train loss: 4.189e+06, Test loss: 5.810e+06, MSE(e): 4.166e-01, MSE(pi1): 5.692e-01, MSE(pi2): 2.335e-01, MSE(pi3): 1.742e-01\n",
      "Epoch 43300, Train loss: 4.184e+06, Test loss: 5.800e+06, MSE(e): 4.160e-01, MSE(pi1): 5.686e-01, MSE(pi2): 2.332e-01, MSE(pi3): 1.741e-01\n",
      "Epoch 43400, Train loss: 4.178e+06, Test loss: 5.790e+06, MSE(e): 4.155e-01, MSE(pi1): 5.680e-01, MSE(pi2): 2.329e-01, MSE(pi3): 1.740e-01\n",
      "Epoch 43500, Train loss: 4.173e+06, Test loss: 5.781e+06, MSE(e): 4.149e-01, MSE(pi1): 5.674e-01, MSE(pi2): 2.327e-01, MSE(pi3): 1.739e-01\n",
      "Epoch 43600, Train loss: 4.167e+06, Test loss: 5.771e+06, MSE(e): 4.144e-01, MSE(pi1): 5.668e-01, MSE(pi2): 2.324e-01, MSE(pi3): 1.738e-01\n",
      "Epoch 43700, Train loss: 4.162e+06, Test loss: 5.761e+06, MSE(e): 4.139e-01, MSE(pi1): 5.663e-01, MSE(pi2): 2.322e-01, MSE(pi3): 1.737e-01\n",
      "Epoch 43800, Train loss: 4.156e+06, Test loss: 5.751e+06, MSE(e): 4.133e-01, MSE(pi1): 5.657e-01, MSE(pi2): 2.320e-01, MSE(pi3): 1.736e-01\n",
      "Epoch 43900, Train loss: 4.151e+06, Test loss: 5.741e+06, MSE(e): 4.128e-01, MSE(pi1): 5.651e-01, MSE(pi2): 2.317e-01, MSE(pi3): 1.735e-01\n",
      "Epoch 44000, Train loss: 4.146e+06, Test loss: 5.731e+06, MSE(e): 4.123e-01, MSE(pi1): 5.645e-01, MSE(pi2): 2.315e-01, MSE(pi3): 1.734e-01\n",
      "Epoch 44100, Train loss: 4.141e+06, Test loss: 5.722e+06, MSE(e): 4.117e-01, MSE(pi1): 5.639e-01, MSE(pi2): 2.312e-01, MSE(pi3): 1.733e-01\n",
      "Epoch 44200, Train loss: 4.135e+06, Test loss: 5.712e+06, MSE(e): 4.112e-01, MSE(pi1): 5.633e-01, MSE(pi2): 2.310e-01, MSE(pi3): 1.732e-01\n",
      "Epoch 44300, Train loss: 4.130e+06, Test loss: 5.702e+06, MSE(e): 4.107e-01, MSE(pi1): 5.627e-01, MSE(pi2): 2.307e-01, MSE(pi3): 1.731e-01\n",
      "Epoch 44400, Train loss: 4.125e+06, Test loss: 5.692e+06, MSE(e): 4.102e-01, MSE(pi1): 5.621e-01, MSE(pi2): 2.305e-01, MSE(pi3): 1.730e-01\n",
      "Epoch 44500, Train loss: 4.120e+06, Test loss: 5.683e+06, MSE(e): 4.097e-01, MSE(pi1): 5.616e-01, MSE(pi2): 2.303e-01, MSE(pi3): 1.729e-01\n",
      "Epoch 44600, Train loss: 4.115e+06, Test loss: 5.673e+06, MSE(e): 4.092e-01, MSE(pi1): 5.610e-01, MSE(pi2): 2.300e-01, MSE(pi3): 1.728e-01\n",
      "Epoch 44700, Train loss: 4.110e+06, Test loss: 5.664e+06, MSE(e): 4.087e-01, MSE(pi1): 5.604e-01, MSE(pi2): 2.298e-01, MSE(pi3): 1.727e-01\n",
      "Epoch 44800, Train loss: 4.105e+06, Test loss: 5.654e+06, MSE(e): 4.081e-01, MSE(pi1): 5.598e-01, MSE(pi2): 2.296e-01, MSE(pi3): 1.727e-01\n",
      "Epoch 44900, Train loss: 4.100e+06, Test loss: 5.645e+06, MSE(e): 4.076e-01, MSE(pi1): 5.593e-01, MSE(pi2): 2.293e-01, MSE(pi3): 1.726e-01\n",
      "Epoch 45000, Train loss: 4.095e+06, Test loss: 5.635e+06, MSE(e): 4.072e-01, MSE(pi1): 5.587e-01, MSE(pi2): 2.291e-01, MSE(pi3): 1.725e-01\n",
      "Epoch 45100, Train loss: 4.090e+06, Test loss: 5.626e+06, MSE(e): 4.067e-01, MSE(pi1): 5.582e-01, MSE(pi2): 2.289e-01, MSE(pi3): 1.724e-01\n",
      "Epoch 45200, Train loss: 4.085e+06, Test loss: 5.617e+06, MSE(e): 4.062e-01, MSE(pi1): 5.576e-01, MSE(pi2): 2.286e-01, MSE(pi3): 1.723e-01\n",
      "Epoch 45300, Train loss: 4.080e+06, Test loss: 5.607e+06, MSE(e): 4.057e-01, MSE(pi1): 5.570e-01, MSE(pi2): 2.284e-01, MSE(pi3): 1.722e-01\n",
      "Epoch 45400, Train loss: 4.075e+06, Test loss: 5.598e+06, MSE(e): 4.052e-01, MSE(pi1): 5.565e-01, MSE(pi2): 2.282e-01, MSE(pi3): 1.721e-01\n",
      "Epoch 45500, Train loss: 4.070e+06, Test loss: 5.589e+06, MSE(e): 4.047e-01, MSE(pi1): 5.559e-01, MSE(pi2): 2.280e-01, MSE(pi3): 1.720e-01\n",
      "Epoch 45600, Train loss: 4.066e+06, Test loss: 5.580e+06, MSE(e): 4.043e-01, MSE(pi1): 5.554e-01, MSE(pi2): 2.278e-01, MSE(pi3): 1.719e-01\n",
      "Epoch 45700, Train loss: 4.061e+06, Test loss: 5.571e+06, MSE(e): 4.038e-01, MSE(pi1): 5.549e-01, MSE(pi2): 2.275e-01, MSE(pi3): 1.718e-01\n",
      "Epoch 45800, Train loss: 4.056e+06, Test loss: 5.562e+06, MSE(e): 4.033e-01, MSE(pi1): 5.543e-01, MSE(pi2): 2.273e-01, MSE(pi3): 1.717e-01\n",
      "Epoch 45900, Train loss: 4.051e+06, Test loss: 5.553e+06, MSE(e): 4.028e-01, MSE(pi1): 5.538e-01, MSE(pi2): 2.271e-01, MSE(pi3): 1.716e-01\n",
      "Epoch 46000, Train loss: 4.047e+06, Test loss: 5.544e+06, MSE(e): 4.024e-01, MSE(pi1): 5.532e-01, MSE(pi2): 2.269e-01, MSE(pi3): 1.715e-01\n",
      "Epoch 46100, Train loss: 4.042e+06, Test loss: 5.535e+06, MSE(e): 4.019e-01, MSE(pi1): 5.527e-01, MSE(pi2): 2.267e-01, MSE(pi3): 1.714e-01\n",
      "Epoch 46200, Train loss: 4.038e+06, Test loss: 5.527e+06, MSE(e): 4.015e-01, MSE(pi1): 5.522e-01, MSE(pi2): 2.265e-01, MSE(pi3): 1.713e-01\n",
      "Epoch 46300, Train loss: 4.033e+06, Test loss: 5.518e+06, MSE(e): 4.010e-01, MSE(pi1): 5.517e-01, MSE(pi2): 2.262e-01, MSE(pi3): 1.712e-01\n",
      "Epoch 46400, Train loss: 4.029e+06, Test loss: 5.509e+06, MSE(e): 4.006e-01, MSE(pi1): 5.511e-01, MSE(pi2): 2.260e-01, MSE(pi3): 1.711e-01\n",
      "Epoch 46500, Train loss: 4.024e+06, Test loss: 5.501e+06, MSE(e): 4.001e-01, MSE(pi1): 5.506e-01, MSE(pi2): 2.258e-01, MSE(pi3): 1.710e-01\n",
      "Epoch 46600, Train loss: 4.020e+06, Test loss: 5.492e+06, MSE(e): 3.997e-01, MSE(pi1): 5.501e-01, MSE(pi2): 2.256e-01, MSE(pi3): 1.709e-01\n",
      "Epoch 46700, Train loss: 4.015e+06, Test loss: 5.484e+06, MSE(e): 3.992e-01, MSE(pi1): 5.496e-01, MSE(pi2): 2.254e-01, MSE(pi3): 1.708e-01\n",
      "Epoch 46800, Train loss: 4.011e+06, Test loss: 5.475e+06, MSE(e): 3.988e-01, MSE(pi1): 5.491e-01, MSE(pi2): 2.252e-01, MSE(pi3): 1.708e-01\n",
      "Epoch 46900, Train loss: 4.006e+06, Test loss: 5.467e+06, MSE(e): 3.984e-01, MSE(pi1): 5.486e-01, MSE(pi2): 2.250e-01, MSE(pi3): 1.707e-01\n",
      "Epoch 47000, Train loss: 4.002e+06, Test loss: 5.459e+06, MSE(e): 3.979e-01, MSE(pi1): 5.481e-01, MSE(pi2): 2.248e-01, MSE(pi3): 1.706e-01\n",
      "Epoch 47100, Train loss: 3.998e+06, Test loss: 5.450e+06, MSE(e): 3.975e-01, MSE(pi1): 5.476e-01, MSE(pi2): 2.246e-01, MSE(pi3): 1.705e-01\n",
      "Epoch 47200, Train loss: 3.994e+06, Test loss: 5.442e+06, MSE(e): 3.971e-01, MSE(pi1): 5.471e-01, MSE(pi2): 2.244e-01, MSE(pi3): 1.704e-01\n",
      "Epoch 47300, Train loss: 3.989e+06, Test loss: 5.434e+06, MSE(e): 3.967e-01, MSE(pi1): 5.466e-01, MSE(pi2): 2.242e-01, MSE(pi3): 1.703e-01\n",
      "Epoch 47400, Train loss: 3.985e+06, Test loss: 5.426e+06, MSE(e): 3.962e-01, MSE(pi1): 5.461e-01, MSE(pi2): 2.240e-01, MSE(pi3): 1.702e-01\n",
      "Epoch 47500, Train loss: 3.981e+06, Test loss: 5.418e+06, MSE(e): 3.958e-01, MSE(pi1): 5.456e-01, MSE(pi2): 2.238e-01, MSE(pi3): 1.701e-01\n",
      "Epoch 47600, Train loss: 3.977e+06, Test loss: 5.410e+06, MSE(e): 3.954e-01, MSE(pi1): 5.451e-01, MSE(pi2): 2.236e-01, MSE(pi3): 1.700e-01\n",
      "Epoch 47700, Train loss: 3.973e+06, Test loss: 5.402e+06, MSE(e): 3.950e-01, MSE(pi1): 5.447e-01, MSE(pi2): 2.234e-01, MSE(pi3): 1.699e-01\n",
      "Epoch 47800, Train loss: 3.968e+06, Test loss: 5.395e+06, MSE(e): 3.946e-01, MSE(pi1): 5.442e-01, MSE(pi2): 2.232e-01, MSE(pi3): 1.698e-01\n",
      "Epoch 47900, Train loss: 3.964e+06, Test loss: 5.387e+06, MSE(e): 3.942e-01, MSE(pi1): 5.437e-01, MSE(pi2): 2.230e-01, MSE(pi3): 1.698e-01\n",
      "Epoch 48000, Train loss: 3.960e+06, Test loss: 5.379e+06, MSE(e): 3.938e-01, MSE(pi1): 5.432e-01, MSE(pi2): 2.229e-01, MSE(pi3): 1.697e-01\n",
      "Epoch 48100, Train loss: 3.956e+06, Test loss: 5.372e+06, MSE(e): 3.934e-01, MSE(pi1): 5.428e-01, MSE(pi2): 2.227e-01, MSE(pi3): 1.696e-01\n",
      "Epoch 48200, Train loss: 3.952e+06, Test loss: 5.364e+06, MSE(e): 3.930e-01, MSE(pi1): 5.423e-01, MSE(pi2): 2.225e-01, MSE(pi3): 1.695e-01\n",
      "Epoch 48300, Train loss: 3.948e+06, Test loss: 5.357e+06, MSE(e): 3.926e-01, MSE(pi1): 5.418e-01, MSE(pi2): 2.223e-01, MSE(pi3): 1.694e-01\n",
      "Epoch 48400, Train loss: 3.944e+06, Test loss: 5.349e+06, MSE(e): 3.922e-01, MSE(pi1): 5.414e-01, MSE(pi2): 2.221e-01, MSE(pi3): 1.693e-01\n",
      "Epoch 48500, Train loss: 3.940e+06, Test loss: 5.342e+06, MSE(e): 3.918e-01, MSE(pi1): 5.409e-01, MSE(pi2): 2.219e-01, MSE(pi3): 1.692e-01\n",
      "Epoch 48600, Train loss: 3.937e+06, Test loss: 5.334e+06, MSE(e): 3.914e-01, MSE(pi1): 5.405e-01, MSE(pi2): 2.217e-01, MSE(pi3): 1.691e-01\n",
      "Epoch 48700, Train loss: 3.933e+06, Test loss: 5.327e+06, MSE(e): 3.910e-01, MSE(pi1): 5.400e-01, MSE(pi2): 2.216e-01, MSE(pi3): 1.691e-01\n",
      "Epoch 48800, Train loss: 3.929e+06, Test loss: 5.320e+06, MSE(e): 3.906e-01, MSE(pi1): 5.396e-01, MSE(pi2): 2.214e-01, MSE(pi3): 1.690e-01\n",
      "Epoch 48900, Train loss: 3.925e+06, Test loss: 5.313e+06, MSE(e): 3.903e-01, MSE(pi1): 5.391e-01, MSE(pi2): 2.212e-01, MSE(pi3): 1.689e-01\n",
      "Epoch 49000, Train loss: 3.921e+06, Test loss: 5.306e+06, MSE(e): 3.899e-01, MSE(pi1): 5.387e-01, MSE(pi2): 2.210e-01, MSE(pi3): 1.688e-01\n",
      "Epoch 49100, Train loss: 3.917e+06, Test loss: 5.299e+06, MSE(e): 3.895e-01, MSE(pi1): 5.383e-01, MSE(pi2): 2.208e-01, MSE(pi3): 1.687e-01\n",
      "Epoch 49200, Train loss: 3.914e+06, Test loss: 5.292e+06, MSE(e): 3.891e-01, MSE(pi1): 5.378e-01, MSE(pi2): 2.207e-01, MSE(pi3): 1.686e-01\n",
      "Epoch 49300, Train loss: 3.910e+06, Test loss: 5.285e+06, MSE(e): 3.887e-01, MSE(pi1): 5.374e-01, MSE(pi2): 2.205e-01, MSE(pi3): 1.685e-01\n",
      "Epoch 49400, Train loss: 3.906e+06, Test loss: 5.279e+06, MSE(e): 3.884e-01, MSE(pi1): 5.369e-01, MSE(pi2): 2.203e-01, MSE(pi3): 1.685e-01\n",
      "Epoch 49500, Train loss: 3.903e+06, Test loss: 5.272e+06, MSE(e): 3.880e-01, MSE(pi1): 5.365e-01, MSE(pi2): 2.201e-01, MSE(pi3): 1.684e-01\n",
      "Epoch 49600, Train loss: 3.899e+06, Test loss: 5.265e+06, MSE(e): 3.876e-01, MSE(pi1): 5.361e-01, MSE(pi2): 2.200e-01, MSE(pi3): 1.683e-01\n",
      "Epoch 49700, Train loss: 3.895e+06, Test loss: 5.259e+06, MSE(e): 3.873e-01, MSE(pi1): 5.357e-01, MSE(pi2): 2.198e-01, MSE(pi3): 1.682e-01\n",
      "Epoch 49800, Train loss: 3.892e+06, Test loss: 5.252e+06, MSE(e): 3.869e-01, MSE(pi1): 5.352e-01, MSE(pi2): 2.196e-01, MSE(pi3): 1.681e-01\n",
      "Epoch 49900, Train loss: 3.888e+06, Test loss: 5.246e+06, MSE(e): 3.866e-01, MSE(pi1): 5.348e-01, MSE(pi2): 2.194e-01, MSE(pi3): 1.680e-01\n",
      "Epoch 50000, Train loss: 3.884e+06, Test loss: 5.239e+06, MSE(e): 3.862e-01, MSE(pi1): 5.344e-01, MSE(pi2): 2.193e-01, MSE(pi3): 1.680e-01\n",
      "Epoch 50100, Train loss: 3.881e+06, Test loss: 5.233e+06, MSE(e): 3.859e-01, MSE(pi1): 5.340e-01, MSE(pi2): 2.191e-01, MSE(pi3): 1.679e-01\n",
      "Epoch 50200, Train loss: 3.877e+06, Test loss: 5.227e+06, MSE(e): 3.855e-01, MSE(pi1): 5.336e-01, MSE(pi2): 2.189e-01, MSE(pi3): 1.678e-01\n",
      "Epoch 50300, Train loss: 3.874e+06, Test loss: 5.220e+06, MSE(e): 3.852e-01, MSE(pi1): 5.332e-01, MSE(pi2): 2.188e-01, MSE(pi3): 1.677e-01\n",
      "Epoch 50400, Train loss: 3.870e+06, Test loss: 5.214e+06, MSE(e): 3.848e-01, MSE(pi1): 5.327e-01, MSE(pi2): 2.186e-01, MSE(pi3): 1.676e-01\n",
      "Epoch 50500, Train loss: 3.867e+06, Test loss: 5.208e+06, MSE(e): 3.845e-01, MSE(pi1): 5.323e-01, MSE(pi2): 2.184e-01, MSE(pi3): 1.676e-01\n",
      "Epoch 50600, Train loss: 3.863e+06, Test loss: 5.202e+06, MSE(e): 3.841e-01, MSE(pi1): 5.319e-01, MSE(pi2): 2.183e-01, MSE(pi3): 1.675e-01\n",
      "Epoch 50700, Train loss: 3.860e+06, Test loss: 5.196e+06, MSE(e): 3.838e-01, MSE(pi1): 5.315e-01, MSE(pi2): 2.181e-01, MSE(pi3): 1.674e-01\n",
      "Epoch 50800, Train loss: 3.857e+06, Test loss: 5.190e+06, MSE(e): 3.834e-01, MSE(pi1): 5.311e-01, MSE(pi2): 2.180e-01, MSE(pi3): 1.673e-01\n",
      "Epoch 50900, Train loss: 3.853e+06, Test loss: 5.184e+06, MSE(e): 3.831e-01, MSE(pi1): 5.307e-01, MSE(pi2): 2.178e-01, MSE(pi3): 1.672e-01\n",
      "Epoch 51000, Train loss: 3.850e+06, Test loss: 5.178e+06, MSE(e): 3.828e-01, MSE(pi1): 5.303e-01, MSE(pi2): 2.176e-01, MSE(pi3): 1.672e-01\n",
      "Epoch 51100, Train loss: 3.846e+06, Test loss: 5.173e+06, MSE(e): 3.824e-01, MSE(pi1): 5.299e-01, MSE(pi2): 2.175e-01, MSE(pi3): 1.671e-01\n",
      "Epoch 51200, Train loss: 3.843e+06, Test loss: 5.167e+06, MSE(e): 3.821e-01, MSE(pi1): 5.296e-01, MSE(pi2): 2.173e-01, MSE(pi3): 1.670e-01\n",
      "Epoch 51300, Train loss: 3.840e+06, Test loss: 5.161e+06, MSE(e): 3.818e-01, MSE(pi1): 5.292e-01, MSE(pi2): 2.172e-01, MSE(pi3): 1.669e-01\n",
      "Epoch 51400, Train loss: 3.836e+06, Test loss: 5.156e+06, MSE(e): 3.814e-01, MSE(pi1): 5.288e-01, MSE(pi2): 2.170e-01, MSE(pi3): 1.669e-01\n",
      "Epoch 51500, Train loss: 3.833e+06, Test loss: 5.150e+06, MSE(e): 3.811e-01, MSE(pi1): 5.284e-01, MSE(pi2): 2.168e-01, MSE(pi3): 1.668e-01\n",
      "Epoch 51600, Train loss: 3.830e+06, Test loss: 5.145e+06, MSE(e): 3.808e-01, MSE(pi1): 5.280e-01, MSE(pi2): 2.167e-01, MSE(pi3): 1.667e-01\n",
      "Epoch 51700, Train loss: 3.827e+06, Test loss: 5.139e+06, MSE(e): 3.805e-01, MSE(pi1): 5.276e-01, MSE(pi2): 2.165e-01, MSE(pi3): 1.666e-01\n",
      "Epoch 51800, Train loss: 3.823e+06, Test loss: 5.134e+06, MSE(e): 3.801e-01, MSE(pi1): 5.272e-01, MSE(pi2): 2.164e-01, MSE(pi3): 1.665e-01\n",
      "Epoch 51900, Train loss: 3.820e+06, Test loss: 5.128e+06, MSE(e): 3.798e-01, MSE(pi1): 5.269e-01, MSE(pi2): 2.162e-01, MSE(pi3): 1.665e-01\n",
      "Epoch 52000, Train loss: 3.817e+06, Test loss: 5.123e+06, MSE(e): 3.795e-01, MSE(pi1): 5.265e-01, MSE(pi2): 2.161e-01, MSE(pi3): 1.664e-01\n",
      "Epoch 52100, Train loss: 3.814e+06, Test loss: 5.118e+06, MSE(e): 3.792e-01, MSE(pi1): 5.261e-01, MSE(pi2): 2.159e-01, MSE(pi3): 1.663e-01\n",
      "Epoch 52200, Train loss: 3.811e+06, Test loss: 5.113e+06, MSE(e): 3.789e-01, MSE(pi1): 5.258e-01, MSE(pi2): 2.158e-01, MSE(pi3): 1.663e-01\n",
      "Epoch 52300, Train loss: 3.808e+06, Test loss: 5.108e+06, MSE(e): 3.785e-01, MSE(pi1): 5.254e-01, MSE(pi2): 2.156e-01, MSE(pi3): 1.662e-01\n",
      "Epoch 52400, Train loss: 3.804e+06, Test loss: 5.103e+06, MSE(e): 3.782e-01, MSE(pi1): 5.250e-01, MSE(pi2): 2.155e-01, MSE(pi3): 1.661e-01\n",
      "Epoch 52500, Train loss: 3.801e+06, Test loss: 5.098e+06, MSE(e): 3.779e-01, MSE(pi1): 5.246e-01, MSE(pi2): 2.153e-01, MSE(pi3): 1.660e-01\n",
      "Epoch 52600, Train loss: 3.798e+06, Test loss: 5.093e+06, MSE(e): 3.776e-01, MSE(pi1): 5.243e-01, MSE(pi2): 2.152e-01, MSE(pi3): 1.660e-01\n",
      "Epoch 52700, Train loss: 3.795e+06, Test loss: 5.088e+06, MSE(e): 3.773e-01, MSE(pi1): 5.239e-01, MSE(pi2): 2.150e-01, MSE(pi3): 1.659e-01\n",
      "Epoch 52800, Train loss: 3.792e+06, Test loss: 5.083e+06, MSE(e): 3.770e-01, MSE(pi1): 5.236e-01, MSE(pi2): 2.149e-01, MSE(pi3): 1.658e-01\n",
      "Epoch 52900, Train loss: 3.789e+06, Test loss: 5.078e+06, MSE(e): 3.767e-01, MSE(pi1): 5.232e-01, MSE(pi2): 2.147e-01, MSE(pi3): 1.657e-01\n",
      "Epoch 53000, Train loss: 3.786e+06, Test loss: 5.073e+06, MSE(e): 3.764e-01, MSE(pi1): 5.228e-01, MSE(pi2): 2.146e-01, MSE(pi3): 1.657e-01\n",
      "Epoch 53100, Train loss: 3.783e+06, Test loss: 5.068e+06, MSE(e): 3.761e-01, MSE(pi1): 5.225e-01, MSE(pi2): 2.144e-01, MSE(pi3): 1.656e-01\n",
      "Epoch 53200, Train loss: 3.780e+06, Test loss: 5.064e+06, MSE(e): 3.758e-01, MSE(pi1): 5.221e-01, MSE(pi2): 2.143e-01, MSE(pi3): 1.655e-01\n",
      "Epoch 53300, Train loss: 3.777e+06, Test loss: 5.059e+06, MSE(e): 3.755e-01, MSE(pi1): 5.218e-01, MSE(pi2): 2.142e-01, MSE(pi3): 1.655e-01\n",
      "Epoch 53400, Train loss: 3.774e+06, Test loss: 5.055e+06, MSE(e): 3.752e-01, MSE(pi1): 5.214e-01, MSE(pi2): 2.140e-01, MSE(pi3): 1.654e-01\n",
      "Epoch 53500, Train loss: 3.771e+06, Test loss: 5.050e+06, MSE(e): 3.749e-01, MSE(pi1): 5.211e-01, MSE(pi2): 2.139e-01, MSE(pi3): 1.653e-01\n",
      "Epoch 53600, Train loss: 3.768e+06, Test loss: 5.045e+06, MSE(e): 3.746e-01, MSE(pi1): 5.207e-01, MSE(pi2): 2.137e-01, MSE(pi3): 1.652e-01\n",
      "Epoch 53700, Train loss: 3.765e+06, Test loss: 5.041e+06, MSE(e): 3.743e-01, MSE(pi1): 5.204e-01, MSE(pi2): 2.136e-01, MSE(pi3): 1.652e-01\n",
      "Epoch 53800, Train loss: 3.762e+06, Test loss: 5.037e+06, MSE(e): 3.740e-01, MSE(pi1): 5.200e-01, MSE(pi2): 2.134e-01, MSE(pi3): 1.651e-01\n",
      "Epoch 53900, Train loss: 3.759e+06, Test loss: 5.032e+06, MSE(e): 3.737e-01, MSE(pi1): 5.197e-01, MSE(pi2): 2.133e-01, MSE(pi3): 1.650e-01\n",
      "Epoch 54000, Train loss: 3.756e+06, Test loss: 5.028e+06, MSE(e): 3.734e-01, MSE(pi1): 5.193e-01, MSE(pi2): 2.132e-01, MSE(pi3): 1.650e-01\n",
      "Epoch 54100, Train loss: 3.754e+06, Test loss: 5.024e+06, MSE(e): 3.732e-01, MSE(pi1): 5.190e-01, MSE(pi2): 2.130e-01, MSE(pi3): 1.649e-01\n",
      "Epoch 54200, Train loss: 3.751e+06, Test loss: 5.020e+06, MSE(e): 3.729e-01, MSE(pi1): 5.186e-01, MSE(pi2): 2.129e-01, MSE(pi3): 1.648e-01\n",
      "Epoch 54300, Train loss: 3.748e+06, Test loss: 5.015e+06, MSE(e): 3.726e-01, MSE(pi1): 5.183e-01, MSE(pi2): 2.128e-01, MSE(pi3): 1.648e-01\n",
      "Epoch 54400, Train loss: 3.745e+06, Test loss: 5.011e+06, MSE(e): 3.723e-01, MSE(pi1): 5.180e-01, MSE(pi2): 2.126e-01, MSE(pi3): 1.647e-01\n",
      "Epoch 54500, Train loss: 3.742e+06, Test loss: 5.007e+06, MSE(e): 3.720e-01, MSE(pi1): 5.176e-01, MSE(pi2): 2.125e-01, MSE(pi3): 1.646e-01\n",
      "Epoch 54600, Train loss: 3.739e+06, Test loss: 5.003e+06, MSE(e): 3.717e-01, MSE(pi1): 5.173e-01, MSE(pi2): 2.123e-01, MSE(pi3): 1.646e-01\n",
      "Epoch 54700, Train loss: 3.737e+06, Test loss: 4.999e+06, MSE(e): 3.715e-01, MSE(pi1): 5.170e-01, MSE(pi2): 2.122e-01, MSE(pi3): 1.645e-01\n",
      "Epoch 54800, Train loss: 3.734e+06, Test loss: 4.995e+06, MSE(e): 3.712e-01, MSE(pi1): 5.166e-01, MSE(pi2): 2.121e-01, MSE(pi3): 1.644e-01\n",
      "Epoch 54900, Train loss: 3.731e+06, Test loss: 4.991e+06, MSE(e): 3.709e-01, MSE(pi1): 5.163e-01, MSE(pi2): 2.119e-01, MSE(pi3): 1.644e-01\n",
      "Epoch 55000, Train loss: 3.728e+06, Test loss: 4.987e+06, MSE(e): 3.706e-01, MSE(pi1): 5.160e-01, MSE(pi2): 2.118e-01, MSE(pi3): 1.643e-01\n",
      "Epoch 55100, Train loss: 3.725e+06, Test loss: 4.983e+06, MSE(e): 3.704e-01, MSE(pi1): 5.156e-01, MSE(pi2): 2.117e-01, MSE(pi3): 1.642e-01\n",
      "Epoch 55200, Train loss: 3.723e+06, Test loss: 4.979e+06, MSE(e): 3.701e-01, MSE(pi1): 5.153e-01, MSE(pi2): 2.115e-01, MSE(pi3): 1.642e-01\n",
      "Epoch 55300, Train loss: 3.720e+06, Test loss: 4.976e+06, MSE(e): 3.698e-01, MSE(pi1): 5.150e-01, MSE(pi2): 2.114e-01, MSE(pi3): 1.641e-01\n",
      "Epoch 55400, Train loss: 3.717e+06, Test loss: 4.972e+06, MSE(e): 3.696e-01, MSE(pi1): 5.146e-01, MSE(pi2): 2.113e-01, MSE(pi3): 1.640e-01\n",
      "Epoch 55500, Train loss: 3.715e+06, Test loss: 4.968e+06, MSE(e): 3.693e-01, MSE(pi1): 5.143e-01, MSE(pi2): 2.112e-01, MSE(pi3): 1.640e-01\n",
      "Epoch 55600, Train loss: 3.712e+06, Test loss: 4.964e+06, MSE(e): 3.690e-01, MSE(pi1): 5.140e-01, MSE(pi2): 2.110e-01, MSE(pi3): 1.639e-01\n",
      "Epoch 55700, Train loss: 3.709e+06, Test loss: 4.961e+06, MSE(e): 3.688e-01, MSE(pi1): 5.137e-01, MSE(pi2): 2.109e-01, MSE(pi3): 1.638e-01\n",
      "Epoch 55800, Train loss: 3.707e+06, Test loss: 4.957e+06, MSE(e): 3.685e-01, MSE(pi1): 5.133e-01, MSE(pi2): 2.108e-01, MSE(pi3): 1.638e-01\n",
      "Epoch 55900, Train loss: 3.704e+06, Test loss: 4.954e+06, MSE(e): 3.682e-01, MSE(pi1): 5.130e-01, MSE(pi2): 2.106e-01, MSE(pi3): 1.637e-01\n",
      "Epoch 56000, Train loss: 3.701e+06, Test loss: 4.950e+06, MSE(e): 3.680e-01, MSE(pi1): 5.127e-01, MSE(pi2): 2.105e-01, MSE(pi3): 1.636e-01\n",
      "Epoch 56100, Train loss: 3.699e+06, Test loss: 4.947e+06, MSE(e): 3.677e-01, MSE(pi1): 5.124e-01, MSE(pi2): 2.104e-01, MSE(pi3): 1.636e-01\n",
      "Epoch 56200, Train loss: 3.696e+06, Test loss: 4.943e+06, MSE(e): 3.674e-01, MSE(pi1): 5.121e-01, MSE(pi2): 2.103e-01, MSE(pi3): 1.635e-01\n",
      "Epoch 56300, Train loss: 3.694e+06, Test loss: 4.940e+06, MSE(e): 3.672e-01, MSE(pi1): 5.117e-01, MSE(pi2): 2.101e-01, MSE(pi3): 1.634e-01\n",
      "Epoch 56400, Train loss: 3.691e+06, Test loss: 4.936e+06, MSE(e): 3.669e-01, MSE(pi1): 5.114e-01, MSE(pi2): 2.100e-01, MSE(pi3): 1.634e-01\n",
      "Epoch 56500, Train loss: 3.688e+06, Test loss: 4.933e+06, MSE(e): 3.667e-01, MSE(pi1): 5.111e-01, MSE(pi2): 2.099e-01, MSE(pi3): 1.633e-01\n",
      "Epoch 56600, Train loss: 3.686e+06, Test loss: 4.930e+06, MSE(e): 3.664e-01, MSE(pi1): 5.108e-01, MSE(pi2): 2.098e-01, MSE(pi3): 1.633e-01\n",
      "Epoch 56700, Train loss: 3.683e+06, Test loss: 4.926e+06, MSE(e): 3.662e-01, MSE(pi1): 5.105e-01, MSE(pi2): 2.096e-01, MSE(pi3): 1.632e-01\n",
      "Epoch 56800, Train loss: 3.681e+06, Test loss: 4.923e+06, MSE(e): 3.659e-01, MSE(pi1): 5.102e-01, MSE(pi2): 2.095e-01, MSE(pi3): 1.631e-01\n",
      "Epoch 56900, Train loss: 3.678e+06, Test loss: 4.920e+06, MSE(e): 3.657e-01, MSE(pi1): 5.099e-01, MSE(pi2): 2.094e-01, MSE(pi3): 1.631e-01\n",
      "Epoch 57000, Train loss: 3.676e+06, Test loss: 4.917e+06, MSE(e): 3.654e-01, MSE(pi1): 5.096e-01, MSE(pi2): 2.093e-01, MSE(pi3): 1.630e-01\n",
      "Epoch 57100, Train loss: 3.673e+06, Test loss: 4.913e+06, MSE(e): 3.652e-01, MSE(pi1): 5.092e-01, MSE(pi2): 2.091e-01, MSE(pi3): 1.629e-01\n",
      "Epoch 57200, Train loss: 3.671e+06, Test loss: 4.910e+06, MSE(e): 3.649e-01, MSE(pi1): 5.089e-01, MSE(pi2): 2.090e-01, MSE(pi3): 1.629e-01\n",
      "Epoch 57300, Train loss: 3.668e+06, Test loss: 4.907e+06, MSE(e): 3.647e-01, MSE(pi1): 5.086e-01, MSE(pi2): 2.089e-01, MSE(pi3): 1.628e-01\n",
      "Epoch 57400, Train loss: 3.666e+06, Test loss: 4.904e+06, MSE(e): 3.644e-01, MSE(pi1): 5.083e-01, MSE(pi2): 2.088e-01, MSE(pi3): 1.628e-01\n",
      "Epoch 57500, Train loss: 3.663e+06, Test loss: 4.901e+06, MSE(e): 3.642e-01, MSE(pi1): 5.080e-01, MSE(pi2): 2.087e-01, MSE(pi3): 1.627e-01\n",
      "Epoch 57600, Train loss: 3.661e+06, Test loss: 4.898e+06, MSE(e): 3.639e-01, MSE(pi1): 5.077e-01, MSE(pi2): 2.085e-01, MSE(pi3): 1.626e-01\n",
      "Epoch 57700, Train loss: 3.659e+06, Test loss: 4.895e+06, MSE(e): 3.637e-01, MSE(pi1): 5.074e-01, MSE(pi2): 2.084e-01, MSE(pi3): 1.626e-01\n",
      "Epoch 57800, Train loss: 3.656e+06, Test loss: 4.892e+06, MSE(e): 3.635e-01, MSE(pi1): 5.071e-01, MSE(pi2): 2.083e-01, MSE(pi3): 1.625e-01\n",
      "Epoch 57900, Train loss: 3.654e+06, Test loss: 4.889e+06, MSE(e): 3.632e-01, MSE(pi1): 5.068e-01, MSE(pi2): 2.082e-01, MSE(pi3): 1.625e-01\n",
      "Epoch 58000, Train loss: 3.651e+06, Test loss: 4.886e+06, MSE(e): 3.630e-01, MSE(pi1): 5.065e-01, MSE(pi2): 2.081e-01, MSE(pi3): 1.624e-01\n",
      "Epoch 58100, Train loss: 3.649e+06, Test loss: 4.883e+06, MSE(e): 3.628e-01, MSE(pi1): 5.062e-01, MSE(pi2): 2.080e-01, MSE(pi3): 1.623e-01\n",
      "Epoch 58200, Train loss: 3.647e+06, Test loss: 4.880e+06, MSE(e): 3.625e-01, MSE(pi1): 5.059e-01, MSE(pi2): 2.078e-01, MSE(pi3): 1.623e-01\n",
      "Epoch 58300, Train loss: 3.644e+06, Test loss: 4.878e+06, MSE(e): 3.623e-01, MSE(pi1): 5.056e-01, MSE(pi2): 2.077e-01, MSE(pi3): 1.622e-01\n",
      "Epoch 58400, Train loss: 3.642e+06, Test loss: 4.875e+06, MSE(e): 3.620e-01, MSE(pi1): 5.053e-01, MSE(pi2): 2.076e-01, MSE(pi3): 1.622e-01\n",
      "Epoch 58500, Train loss: 3.640e+06, Test loss: 4.872e+06, MSE(e): 3.618e-01, MSE(pi1): 5.050e-01, MSE(pi2): 2.075e-01, MSE(pi3): 1.621e-01\n",
      "Epoch 58600, Train loss: 3.637e+06, Test loss: 4.869e+06, MSE(e): 3.616e-01, MSE(pi1): 5.047e-01, MSE(pi2): 2.074e-01, MSE(pi3): 1.620e-01\n",
      "Epoch 58700, Train loss: 3.635e+06, Test loss: 4.867e+06, MSE(e): 3.614e-01, MSE(pi1): 5.044e-01, MSE(pi2): 2.073e-01, MSE(pi3): 1.620e-01\n",
      "Epoch 58800, Train loss: 3.633e+06, Test loss: 4.864e+06, MSE(e): 3.611e-01, MSE(pi1): 5.041e-01, MSE(pi2): 2.072e-01, MSE(pi3): 1.619e-01\n",
      "Epoch 58900, Train loss: 3.630e+06, Test loss: 4.861e+06, MSE(e): 3.609e-01, MSE(pi1): 5.038e-01, MSE(pi2): 2.070e-01, MSE(pi3): 1.619e-01\n",
      "Epoch 59000, Train loss: 3.628e+06, Test loss: 4.858e+06, MSE(e): 3.607e-01, MSE(pi1): 5.035e-01, MSE(pi2): 2.069e-01, MSE(pi3): 1.618e-01\n",
      "Epoch 59100, Train loss: 3.626e+06, Test loss: 4.856e+06, MSE(e): 3.604e-01, MSE(pi1): 5.032e-01, MSE(pi2): 2.068e-01, MSE(pi3): 1.617e-01\n",
      "Epoch 59200, Train loss: 3.624e+06, Test loss: 4.853e+06, MSE(e): 3.602e-01, MSE(pi1): 5.029e-01, MSE(pi2): 2.067e-01, MSE(pi3): 1.617e-01\n",
      "Epoch 59300, Train loss: 3.621e+06, Test loss: 4.851e+06, MSE(e): 3.600e-01, MSE(pi1): 5.027e-01, MSE(pi2): 2.066e-01, MSE(pi3): 1.616e-01\n",
      "Epoch 59400, Train loss: 3.619e+06, Test loss: 4.848e+06, MSE(e): 3.598e-01, MSE(pi1): 5.024e-01, MSE(pi2): 2.065e-01, MSE(pi3): 1.616e-01\n",
      "Epoch 59500, Train loss: 3.617e+06, Test loss: 4.846e+06, MSE(e): 3.595e-01, MSE(pi1): 5.021e-01, MSE(pi2): 2.064e-01, MSE(pi3): 1.615e-01\n",
      "Epoch 59600, Train loss: 3.615e+06, Test loss: 4.843e+06, MSE(e): 3.593e-01, MSE(pi1): 5.018e-01, MSE(pi2): 2.063e-01, MSE(pi3): 1.614e-01\n",
      "Epoch 59700, Train loss: 3.612e+06, Test loss: 4.841e+06, MSE(e): 3.591e-01, MSE(pi1): 5.015e-01, MSE(pi2): 2.062e-01, MSE(pi3): 1.614e-01\n",
      "Epoch 59800, Train loss: 3.610e+06, Test loss: 4.838e+06, MSE(e): 3.589e-01, MSE(pi1): 5.012e-01, MSE(pi2): 2.061e-01, MSE(pi3): 1.613e-01\n",
      "Epoch 59900, Train loss: 3.608e+06, Test loss: 4.836e+06, MSE(e): 3.587e-01, MSE(pi1): 5.009e-01, MSE(pi2): 2.059e-01, MSE(pi3): 1.613e-01\n",
      "Epoch 60000, Train loss: 3.606e+06, Test loss: 4.833e+06, MSE(e): 3.585e-01, MSE(pi1): 5.006e-01, MSE(pi2): 2.058e-01, MSE(pi3): 1.612e-01\n",
      "Epoch 60100, Train loss: 3.604e+06, Test loss: 4.831e+06, MSE(e): 3.582e-01, MSE(pi1): 5.004e-01, MSE(pi2): 2.057e-01, MSE(pi3): 1.612e-01\n",
      "Epoch 60200, Train loss: 3.602e+06, Test loss: 4.828e+06, MSE(e): 3.580e-01, MSE(pi1): 5.001e-01, MSE(pi2): 2.056e-01, MSE(pi3): 1.611e-01\n",
      "Epoch 60300, Train loss: 3.599e+06, Test loss: 4.826e+06, MSE(e): 3.578e-01, MSE(pi1): 4.998e-01, MSE(pi2): 2.055e-01, MSE(pi3): 1.610e-01\n",
      "Epoch 60400, Train loss: 3.597e+06, Test loss: 4.824e+06, MSE(e): 3.576e-01, MSE(pi1): 4.995e-01, MSE(pi2): 2.054e-01, MSE(pi3): 1.610e-01\n",
      "Epoch 60500, Train loss: 3.595e+06, Test loss: 4.821e+06, MSE(e): 3.574e-01, MSE(pi1): 4.992e-01, MSE(pi2): 2.053e-01, MSE(pi3): 1.609e-01\n",
      "Epoch 60600, Train loss: 3.593e+06, Test loss: 4.819e+06, MSE(e): 3.572e-01, MSE(pi1): 4.990e-01, MSE(pi2): 2.052e-01, MSE(pi3): 1.609e-01\n",
      "Epoch 60700, Train loss: 3.591e+06, Test loss: 4.817e+06, MSE(e): 3.570e-01, MSE(pi1): 4.987e-01, MSE(pi2): 2.051e-01, MSE(pi3): 1.608e-01\n",
      "Epoch 60800, Train loss: 3.589e+06, Test loss: 4.814e+06, MSE(e): 3.568e-01, MSE(pi1): 4.984e-01, MSE(pi2): 2.050e-01, MSE(pi3): 1.608e-01\n",
      "Epoch 60900, Train loss: 3.587e+06, Test loss: 4.812e+06, MSE(e): 3.565e-01, MSE(pi1): 4.981e-01, MSE(pi2): 2.049e-01, MSE(pi3): 1.607e-01\n",
      "Epoch 61000, Train loss: 3.585e+06, Test loss: 4.810e+06, MSE(e): 3.563e-01, MSE(pi1): 4.978e-01, MSE(pi2): 2.048e-01, MSE(pi3): 1.606e-01\n",
      "Epoch 61100, Train loss: 3.583e+06, Test loss: 4.808e+06, MSE(e): 3.561e-01, MSE(pi1): 4.975e-01, MSE(pi2): 2.047e-01, MSE(pi3): 1.606e-01\n",
      "Epoch 61200, Train loss: 3.581e+06, Test loss: 4.806e+06, MSE(e): 3.559e-01, MSE(pi1): 4.973e-01, MSE(pi2): 2.046e-01, MSE(pi3): 1.605e-01\n",
      "Epoch 61300, Train loss: 3.578e+06, Test loss: 4.803e+06, MSE(e): 3.557e-01, MSE(pi1): 4.970e-01, MSE(pi2): 2.045e-01, MSE(pi3): 1.605e-01\n",
      "Epoch 61400, Train loss: 3.576e+06, Test loss: 4.801e+06, MSE(e): 3.555e-01, MSE(pi1): 4.967e-01, MSE(pi2): 2.044e-01, MSE(pi3): 1.604e-01\n",
      "Epoch 61500, Train loss: 3.574e+06, Test loss: 4.799e+06, MSE(e): 3.553e-01, MSE(pi1): 4.965e-01, MSE(pi2): 2.043e-01, MSE(pi3): 1.604e-01\n",
      "Epoch 61600, Train loss: 3.572e+06, Test loss: 4.797e+06, MSE(e): 3.551e-01, MSE(pi1): 4.962e-01, MSE(pi2): 2.042e-01, MSE(pi3): 1.603e-01\n",
      "Epoch 61700, Train loss: 3.570e+06, Test loss: 4.795e+06, MSE(e): 3.549e-01, MSE(pi1): 4.959e-01, MSE(pi2): 2.041e-01, MSE(pi3): 1.603e-01\n",
      "Epoch 61800, Train loss: 3.568e+06, Test loss: 4.793e+06, MSE(e): 3.547e-01, MSE(pi1): 4.956e-01, MSE(pi2): 2.040e-01, MSE(pi3): 1.602e-01\n",
      "Epoch 61900, Train loss: 3.566e+06, Test loss: 4.791e+06, MSE(e): 3.545e-01, MSE(pi1): 4.954e-01, MSE(pi2): 2.039e-01, MSE(pi3): 1.601e-01\n",
      "Epoch 62000, Train loss: 3.564e+06, Test loss: 4.789e+06, MSE(e): 3.543e-01, MSE(pi1): 4.951e-01, MSE(pi2): 2.038e-01, MSE(pi3): 1.601e-01\n",
      "Epoch 62100, Train loss: 3.562e+06, Test loss: 4.787e+06, MSE(e): 3.541e-01, MSE(pi1): 4.948e-01, MSE(pi2): 2.037e-01, MSE(pi3): 1.600e-01\n",
      "Epoch 62200, Train loss: 3.560e+06, Test loss: 4.785e+06, MSE(e): 3.539e-01, MSE(pi1): 4.946e-01, MSE(pi2): 2.036e-01, MSE(pi3): 1.600e-01\n",
      "Epoch 62300, Train loss: 3.558e+06, Test loss: 4.783e+06, MSE(e): 3.537e-01, MSE(pi1): 4.943e-01, MSE(pi2): 2.035e-01, MSE(pi3): 1.599e-01\n",
      "Epoch 62400, Train loss: 3.557e+06, Test loss: 4.781e+06, MSE(e): 3.535e-01, MSE(pi1): 4.940e-01, MSE(pi2): 2.034e-01, MSE(pi3): 1.599e-01\n",
      "Epoch 62500, Train loss: 3.555e+06, Test loss: 4.779e+06, MSE(e): 3.533e-01, MSE(pi1): 4.938e-01, MSE(pi2): 2.033e-01, MSE(pi3): 1.598e-01\n",
      "Epoch 62600, Train loss: 3.553e+06, Test loss: 4.777e+06, MSE(e): 3.532e-01, MSE(pi1): 4.935e-01, MSE(pi2): 2.032e-01, MSE(pi3): 1.598e-01\n",
      "Epoch 62700, Train loss: 3.551e+06, Test loss: 4.775e+06, MSE(e): 3.530e-01, MSE(pi1): 4.932e-01, MSE(pi2): 2.031e-01, MSE(pi3): 1.597e-01\n",
      "Epoch 62800, Train loss: 3.549e+06, Test loss: 4.773e+06, MSE(e): 3.528e-01, MSE(pi1): 4.930e-01, MSE(pi2): 2.030e-01, MSE(pi3): 1.597e-01\n",
      "Epoch 62900, Train loss: 3.547e+06, Test loss: 4.771e+06, MSE(e): 3.526e-01, MSE(pi1): 4.927e-01, MSE(pi2): 2.029e-01, MSE(pi3): 1.596e-01\n",
      "Epoch 63000, Train loss: 3.545e+06, Test loss: 4.769e+06, MSE(e): 3.524e-01, MSE(pi1): 4.925e-01, MSE(pi2): 2.028e-01, MSE(pi3): 1.595e-01\n",
      "Epoch 63100, Train loss: 3.543e+06, Test loss: 4.767e+06, MSE(e): 3.522e-01, MSE(pi1): 4.922e-01, MSE(pi2): 2.027e-01, MSE(pi3): 1.595e-01\n",
      "Epoch 63200, Train loss: 3.541e+06, Test loss: 4.765e+06, MSE(e): 3.520e-01, MSE(pi1): 4.919e-01, MSE(pi2): 2.026e-01, MSE(pi3): 1.594e-01\n",
      "Epoch 63300, Train loss: 3.539e+06, Test loss: 4.763e+06, MSE(e): 3.518e-01, MSE(pi1): 4.917e-01, MSE(pi2): 2.025e-01, MSE(pi3): 1.594e-01\n",
      "Epoch 63400, Train loss: 3.537e+06, Test loss: 4.762e+06, MSE(e): 3.516e-01, MSE(pi1): 4.914e-01, MSE(pi2): 2.024e-01, MSE(pi3): 1.593e-01\n",
      "Epoch 63500, Train loss: 3.536e+06, Test loss: 4.760e+06, MSE(e): 3.515e-01, MSE(pi1): 4.912e-01, MSE(pi2): 2.024e-01, MSE(pi3): 1.593e-01\n",
      "Epoch 63600, Train loss: 3.534e+06, Test loss: 4.758e+06, MSE(e): 3.513e-01, MSE(pi1): 4.909e-01, MSE(pi2): 2.023e-01, MSE(pi3): 1.592e-01\n",
      "Epoch 63700, Train loss: 3.532e+06, Test loss: 4.756e+06, MSE(e): 3.511e-01, MSE(pi1): 4.906e-01, MSE(pi2): 2.022e-01, MSE(pi3): 1.592e-01\n",
      "Epoch 63800, Train loss: 3.530e+06, Test loss: 4.754e+06, MSE(e): 3.509e-01, MSE(pi1): 4.904e-01, MSE(pi2): 2.021e-01, MSE(pi3): 1.591e-01\n",
      "Epoch 63900, Train loss: 3.528e+06, Test loss: 4.753e+06, MSE(e): 3.507e-01, MSE(pi1): 4.901e-01, MSE(pi2): 2.020e-01, MSE(pi3): 1.591e-01\n",
      "Epoch 64000, Train loss: 3.526e+06, Test loss: 4.751e+06, MSE(e): 3.505e-01, MSE(pi1): 4.899e-01, MSE(pi2): 2.019e-01, MSE(pi3): 1.590e-01\n",
      "Epoch 64100, Train loss: 3.525e+06, Test loss: 4.749e+06, MSE(e): 3.504e-01, MSE(pi1): 4.896e-01, MSE(pi2): 2.018e-01, MSE(pi3): 1.590e-01\n",
      "Epoch 64200, Train loss: 3.523e+06, Test loss: 4.747e+06, MSE(e): 3.502e-01, MSE(pi1): 4.894e-01, MSE(pi2): 2.017e-01, MSE(pi3): 1.589e-01\n",
      "Epoch 64300, Train loss: 3.521e+06, Test loss: 4.745e+06, MSE(e): 3.500e-01, MSE(pi1): 4.891e-01, MSE(pi2): 2.016e-01, MSE(pi3): 1.588e-01\n",
      "Epoch 64400, Train loss: 3.519e+06, Test loss: 4.744e+06, MSE(e): 3.498e-01, MSE(pi1): 4.889e-01, MSE(pi2): 2.015e-01, MSE(pi3): 1.588e-01\n",
      "Epoch 64500, Train loss: 3.517e+06, Test loss: 4.742e+06, MSE(e): 3.496e-01, MSE(pi1): 4.886e-01, MSE(pi2): 2.014e-01, MSE(pi3): 1.587e-01\n",
      "Epoch 64600, Train loss: 3.516e+06, Test loss: 4.740e+06, MSE(e): 3.495e-01, MSE(pi1): 4.884e-01, MSE(pi2): 2.014e-01, MSE(pi3): 1.587e-01\n",
      "Epoch 64700, Train loss: 3.514e+06, Test loss: 4.739e+06, MSE(e): 3.493e-01, MSE(pi1): 4.881e-01, MSE(pi2): 2.013e-01, MSE(pi3): 1.586e-01\n",
      "Epoch 64800, Train loss: 3.512e+06, Test loss: 4.737e+06, MSE(e): 3.491e-01, MSE(pi1): 4.879e-01, MSE(pi2): 2.012e-01, MSE(pi3): 1.586e-01\n",
      "Epoch 64900, Train loss: 3.510e+06, Test loss: 4.735e+06, MSE(e): 3.489e-01, MSE(pi1): 4.876e-01, MSE(pi2): 2.011e-01, MSE(pi3): 1.585e-01\n",
      "Epoch 65000, Train loss: 3.508e+06, Test loss: 4.733e+06, MSE(e): 3.488e-01, MSE(pi1): 4.874e-01, MSE(pi2): 2.010e-01, MSE(pi3): 1.585e-01\n",
      "Epoch 65100, Train loss: 3.507e+06, Test loss: 4.732e+06, MSE(e): 3.486e-01, MSE(pi1): 4.871e-01, MSE(pi2): 2.009e-01, MSE(pi3): 1.584e-01\n",
      "Epoch 65200, Train loss: 3.505e+06, Test loss: 4.730e+06, MSE(e): 3.484e-01, MSE(pi1): 4.869e-01, MSE(pi2): 2.008e-01, MSE(pi3): 1.584e-01\n",
      "Epoch 65300, Train loss: 3.503e+06, Test loss: 4.729e+06, MSE(e): 3.482e-01, MSE(pi1): 4.867e-01, MSE(pi2): 2.007e-01, MSE(pi3): 1.583e-01\n",
      "Epoch 65400, Train loss: 3.501e+06, Test loss: 4.727e+06, MSE(e): 3.481e-01, MSE(pi1): 4.864e-01, MSE(pi2): 2.006e-01, MSE(pi3): 1.583e-01\n",
      "Epoch 65500, Train loss: 3.500e+06, Test loss: 4.725e+06, MSE(e): 3.479e-01, MSE(pi1): 4.862e-01, MSE(pi2): 2.006e-01, MSE(pi3): 1.582e-01\n",
      "Epoch 65600, Train loss: 3.498e+06, Test loss: 4.724e+06, MSE(e): 3.477e-01, MSE(pi1): 4.859e-01, MSE(pi2): 2.005e-01, MSE(pi3): 1.582e-01\n",
      "Epoch 65700, Train loss: 3.496e+06, Test loss: 4.722e+06, MSE(e): 3.475e-01, MSE(pi1): 4.857e-01, MSE(pi2): 2.004e-01, MSE(pi3): 1.581e-01\n",
      "Epoch 65800, Train loss: 3.495e+06, Test loss: 4.720e+06, MSE(e): 3.474e-01, MSE(pi1): 4.855e-01, MSE(pi2): 2.003e-01, MSE(pi3): 1.581e-01\n",
      "Epoch 65900, Train loss: 3.493e+06, Test loss: 4.719e+06, MSE(e): 3.472e-01, MSE(pi1): 4.852e-01, MSE(pi2): 2.002e-01, MSE(pi3): 1.580e-01\n",
      "Epoch 66000, Train loss: 3.491e+06, Test loss: 4.717e+06, MSE(e): 3.470e-01, MSE(pi1): 4.850e-01, MSE(pi2): 2.001e-01, MSE(pi3): 1.580e-01\n",
      "Epoch 66100, Train loss: 3.489e+06, Test loss: 4.716e+06, MSE(e): 3.469e-01, MSE(pi1): 4.847e-01, MSE(pi2): 2.000e-01, MSE(pi3): 1.579e-01\n",
      "Epoch 66200, Train loss: 3.488e+06, Test loss: 4.714e+06, MSE(e): 3.467e-01, MSE(pi1): 4.845e-01, MSE(pi2): 2.000e-01, MSE(pi3): 1.579e-01\n",
      "Epoch 66300, Train loss: 3.486e+06, Test loss: 4.713e+06, MSE(e): 3.465e-01, MSE(pi1): 4.843e-01, MSE(pi2): 1.999e-01, MSE(pi3): 1.578e-01\n",
      "Epoch 66400, Train loss: 3.484e+06, Test loss: 4.711e+06, MSE(e): 3.464e-01, MSE(pi1): 4.840e-01, MSE(pi2): 1.998e-01, MSE(pi3): 1.578e-01\n",
      "Epoch 66500, Train loss: 3.483e+06, Test loss: 4.710e+06, MSE(e): 3.462e-01, MSE(pi1): 4.838e-01, MSE(pi2): 1.997e-01, MSE(pi3): 1.577e-01\n",
      "Epoch 66600, Train loss: 3.481e+06, Test loss: 4.708e+06, MSE(e): 3.460e-01, MSE(pi1): 4.836e-01, MSE(pi2): 1.996e-01, MSE(pi3): 1.577e-01\n",
      "Epoch 66700, Train loss: 3.479e+06, Test loss: 4.706e+06, MSE(e): 3.459e-01, MSE(pi1): 4.833e-01, MSE(pi2): 1.995e-01, MSE(pi3): 1.576e-01\n",
      "Epoch 66800, Train loss: 3.478e+06, Test loss: 4.705e+06, MSE(e): 3.457e-01, MSE(pi1): 4.831e-01, MSE(pi2): 1.995e-01, MSE(pi3): 1.575e-01\n",
      "Epoch 66900, Train loss: 3.476e+06, Test loss: 4.703e+06, MSE(e): 3.455e-01, MSE(pi1): 4.829e-01, MSE(pi2): 1.994e-01, MSE(pi3): 1.575e-01\n",
      "Epoch 67000, Train loss: 3.474e+06, Test loss: 4.702e+06, MSE(e): 3.454e-01, MSE(pi1): 4.826e-01, MSE(pi2): 1.993e-01, MSE(pi3): 1.574e-01\n",
      "Epoch 67100, Train loss: 3.473e+06, Test loss: 4.700e+06, MSE(e): 3.452e-01, MSE(pi1): 4.824e-01, MSE(pi2): 1.992e-01, MSE(pi3): 1.574e-01\n",
      "Epoch 67200, Train loss: 3.471e+06, Test loss: 4.699e+06, MSE(e): 3.450e-01, MSE(pi1): 4.822e-01, MSE(pi2): 1.991e-01, MSE(pi3): 1.573e-01\n",
      "Epoch 67300, Train loss: 3.470e+06, Test loss: 4.697e+06, MSE(e): 3.449e-01, MSE(pi1): 4.820e-01, MSE(pi2): 1.990e-01, MSE(pi3): 1.573e-01\n",
      "Epoch 67400, Train loss: 3.468e+06, Test loss: 4.696e+06, MSE(e): 3.447e-01, MSE(pi1): 4.817e-01, MSE(pi2): 1.990e-01, MSE(pi3): 1.572e-01\n",
      "Epoch 67500, Train loss: 3.466e+06, Test loss: 4.694e+06, MSE(e): 3.446e-01, MSE(pi1): 4.815e-01, MSE(pi2): 1.989e-01, MSE(pi3): 1.572e-01\n",
      "Epoch 67600, Train loss: 3.465e+06, Test loss: 4.693e+06, MSE(e): 3.444e-01, MSE(pi1): 4.813e-01, MSE(pi2): 1.988e-01, MSE(pi3): 1.571e-01\n",
      "Epoch 67700, Train loss: 3.463e+06, Test loss: 4.691e+06, MSE(e): 3.442e-01, MSE(pi1): 4.811e-01, MSE(pi2): 1.987e-01, MSE(pi3): 1.571e-01\n",
      "Epoch 67800, Train loss: 3.461e+06, Test loss: 4.690e+06, MSE(e): 3.441e-01, MSE(pi1): 4.808e-01, MSE(pi2): 1.986e-01, MSE(pi3): 1.570e-01\n",
      "Epoch 67900, Train loss: 3.460e+06, Test loss: 4.688e+06, MSE(e): 3.439e-01, MSE(pi1): 4.806e-01, MSE(pi2): 1.986e-01, MSE(pi3): 1.570e-01\n",
      "Epoch 68000, Train loss: 3.458e+06, Test loss: 4.687e+06, MSE(e): 3.438e-01, MSE(pi1): 4.804e-01, MSE(pi2): 1.985e-01, MSE(pi3): 1.569e-01\n",
      "Epoch 68100, Train loss: 3.457e+06, Test loss: 4.685e+06, MSE(e): 3.436e-01, MSE(pi1): 4.802e-01, MSE(pi2): 1.984e-01, MSE(pi3): 1.569e-01\n",
      "Epoch 68200, Train loss: 3.455e+06, Test loss: 4.684e+06, MSE(e): 3.434e-01, MSE(pi1): 4.800e-01, MSE(pi2): 1.983e-01, MSE(pi3): 1.568e-01\n",
      "Epoch 68300, Train loss: 3.453e+06, Test loss: 4.683e+06, MSE(e): 3.433e-01, MSE(pi1): 4.797e-01, MSE(pi2): 1.982e-01, MSE(pi3): 1.568e-01\n",
      "Epoch 68400, Train loss: 3.452e+06, Test loss: 4.681e+06, MSE(e): 3.431e-01, MSE(pi1): 4.795e-01, MSE(pi2): 1.982e-01, MSE(pi3): 1.567e-01\n",
      "Epoch 68500, Train loss: 3.450e+06, Test loss: 4.680e+06, MSE(e): 3.430e-01, MSE(pi1): 4.793e-01, MSE(pi2): 1.981e-01, MSE(pi3): 1.567e-01\n",
      "Epoch 68600, Train loss: 3.449e+06, Test loss: 4.678e+06, MSE(e): 3.428e-01, MSE(pi1): 4.791e-01, MSE(pi2): 1.980e-01, MSE(pi3): 1.567e-01\n",
      "Epoch 68700, Train loss: 3.447e+06, Test loss: 4.677e+06, MSE(e): 3.426e-01, MSE(pi1): 4.789e-01, MSE(pi2): 1.979e-01, MSE(pi3): 1.566e-01\n",
      "Epoch 68800, Train loss: 3.446e+06, Test loss: 4.675e+06, MSE(e): 3.425e-01, MSE(pi1): 4.787e-01, MSE(pi2): 1.978e-01, MSE(pi3): 1.566e-01\n",
      "Epoch 68900, Train loss: 3.444e+06, Test loss: 4.674e+06, MSE(e): 3.423e-01, MSE(pi1): 4.785e-01, MSE(pi2): 1.978e-01, MSE(pi3): 1.565e-01\n",
      "Epoch 69000, Train loss: 3.442e+06, Test loss: 4.672e+06, MSE(e): 3.422e-01, MSE(pi1): 4.782e-01, MSE(pi2): 1.977e-01, MSE(pi3): 1.565e-01\n",
      "Epoch 69100, Train loss: 3.441e+06, Test loss: 4.671e+06, MSE(e): 3.420e-01, MSE(pi1): 4.780e-01, MSE(pi2): 1.976e-01, MSE(pi3): 1.564e-01\n",
      "Epoch 69200, Train loss: 3.439e+06, Test loss: 4.670e+06, MSE(e): 3.419e-01, MSE(pi1): 4.778e-01, MSE(pi2): 1.975e-01, MSE(pi3): 1.564e-01\n",
      "Epoch 69300, Train loss: 3.438e+06, Test loss: 4.668e+06, MSE(e): 3.417e-01, MSE(pi1): 4.776e-01, MSE(pi2): 1.974e-01, MSE(pi3): 1.563e-01\n",
      "Epoch 69400, Train loss: 3.436e+06, Test loss: 4.667e+06, MSE(e): 3.416e-01, MSE(pi1): 4.774e-01, MSE(pi2): 1.974e-01, MSE(pi3): 1.563e-01\n",
      "Epoch 69500, Train loss: 3.435e+06, Test loss: 4.665e+06, MSE(e): 3.414e-01, MSE(pi1): 4.772e-01, MSE(pi2): 1.973e-01, MSE(pi3): 1.562e-01\n",
      "Epoch 69600, Train loss: 3.433e+06, Test loss: 4.664e+06, MSE(e): 3.413e-01, MSE(pi1): 4.770e-01, MSE(pi2): 1.972e-01, MSE(pi3): 1.562e-01\n",
      "Epoch 69700, Train loss: 3.432e+06, Test loss: 4.662e+06, MSE(e): 3.411e-01, MSE(pi1): 4.768e-01, MSE(pi2): 1.971e-01, MSE(pi3): 1.561e-01\n",
      "Epoch 69800, Train loss: 3.430e+06, Test loss: 4.661e+06, MSE(e): 3.409e-01, MSE(pi1): 4.765e-01, MSE(pi2): 1.971e-01, MSE(pi3): 1.561e-01\n",
      "Epoch 69900, Train loss: 3.429e+06, Test loss: 4.660e+06, MSE(e): 3.408e-01, MSE(pi1): 4.763e-01, MSE(pi2): 1.970e-01, MSE(pi3): 1.560e-01\n",
      "Epoch 70000, Train loss: 3.427e+06, Test loss: 4.658e+06, MSE(e): 3.406e-01, MSE(pi1): 4.761e-01, MSE(pi2): 1.969e-01, MSE(pi3): 1.560e-01\n",
      "Epoch 70100, Train loss: 3.425e+06, Test loss: 4.657e+06, MSE(e): 3.405e-01, MSE(pi1): 4.759e-01, MSE(pi2): 1.968e-01, MSE(pi3): 1.559e-01\n",
      "Epoch 70200, Train loss: 3.424e+06, Test loss: 4.655e+06, MSE(e): 3.403e-01, MSE(pi1): 4.757e-01, MSE(pi2): 1.968e-01, MSE(pi3): 1.559e-01\n",
      "Epoch 70300, Train loss: 3.422e+06, Test loss: 4.654e+06, MSE(e): 3.402e-01, MSE(pi1): 4.755e-01, MSE(pi2): 1.967e-01, MSE(pi3): 1.558e-01\n",
      "Epoch 70400, Train loss: 3.421e+06, Test loss: 4.653e+06, MSE(e): 3.400e-01, MSE(pi1): 4.753e-01, MSE(pi2): 1.966e-01, MSE(pi3): 1.558e-01\n",
      "Epoch 70500, Train loss: 3.419e+06, Test loss: 4.651e+06, MSE(e): 3.399e-01, MSE(pi1): 4.751e-01, MSE(pi2): 1.965e-01, MSE(pi3): 1.557e-01\n",
      "Epoch 70600, Train loss: 3.418e+06, Test loss: 4.650e+06, MSE(e): 3.397e-01, MSE(pi1): 4.749e-01, MSE(pi2): 1.964e-01, MSE(pi3): 1.557e-01\n",
      "Epoch 70700, Train loss: 3.416e+06, Test loss: 4.648e+06, MSE(e): 3.396e-01, MSE(pi1): 4.747e-01, MSE(pi2): 1.964e-01, MSE(pi3): 1.556e-01\n",
      "Epoch 70800, Train loss: 3.415e+06, Test loss: 4.647e+06, MSE(e): 3.394e-01, MSE(pi1): 4.745e-01, MSE(pi2): 1.963e-01, MSE(pi3): 1.556e-01\n",
      "Epoch 70900, Train loss: 3.413e+06, Test loss: 4.645e+06, MSE(e): 3.393e-01, MSE(pi1): 4.743e-01, MSE(pi2): 1.962e-01, MSE(pi3): 1.555e-01\n",
      "Epoch 71000, Train loss: 3.412e+06, Test loss: 4.644e+06, MSE(e): 3.391e-01, MSE(pi1): 4.741e-01, MSE(pi2): 1.961e-01, MSE(pi3): 1.555e-01\n",
      "Epoch 71100, Train loss: 3.410e+06, Test loss: 4.643e+06, MSE(e): 3.390e-01, MSE(pi1): 4.739e-01, MSE(pi2): 1.961e-01, MSE(pi3): 1.554e-01\n",
      "Epoch 71200, Train loss: 3.409e+06, Test loss: 4.641e+06, MSE(e): 3.388e-01, MSE(pi1): 4.737e-01, MSE(pi2): 1.960e-01, MSE(pi3): 1.554e-01\n",
      "Epoch 71300, Train loss: 3.407e+06, Test loss: 4.640e+06, MSE(e): 3.387e-01, MSE(pi1): 4.735e-01, MSE(pi2): 1.959e-01, MSE(pi3): 1.554e-01\n",
      "Epoch 71400, Train loss: 3.406e+06, Test loss: 4.639e+06, MSE(e): 3.386e-01, MSE(pi1): 4.733e-01, MSE(pi2): 1.958e-01, MSE(pi3): 1.553e-01\n",
      "Epoch 71500, Train loss: 3.405e+06, Test loss: 4.637e+06, MSE(e): 3.384e-01, MSE(pi1): 4.731e-01, MSE(pi2): 1.958e-01, MSE(pi3): 1.553e-01\n",
      "Epoch 71600, Train loss: 3.403e+06, Test loss: 4.636e+06, MSE(e): 3.383e-01, MSE(pi1): 4.729e-01, MSE(pi2): 1.957e-01, MSE(pi3): 1.552e-01\n",
      "Epoch 71700, Train loss: 3.402e+06, Test loss: 4.634e+06, MSE(e): 3.381e-01, MSE(pi1): 4.728e-01, MSE(pi2): 1.956e-01, MSE(pi3): 1.552e-01\n",
      "Epoch 71800, Train loss: 3.400e+06, Test loss: 4.633e+06, MSE(e): 3.380e-01, MSE(pi1): 4.726e-01, MSE(pi2): 1.955e-01, MSE(pi3): 1.551e-01\n",
      "Epoch 71900, Train loss: 3.399e+06, Test loss: 4.632e+06, MSE(e): 3.378e-01, MSE(pi1): 4.724e-01, MSE(pi2): 1.955e-01, MSE(pi3): 1.551e-01\n",
      "Epoch 72000, Train loss: 3.397e+06, Test loss: 4.630e+06, MSE(e): 3.377e-01, MSE(pi1): 4.722e-01, MSE(pi2): 1.954e-01, MSE(pi3): 1.550e-01\n",
      "Epoch 72100, Train loss: 3.396e+06, Test loss: 4.629e+06, MSE(e): 3.375e-01, MSE(pi1): 4.720e-01, MSE(pi2): 1.953e-01, MSE(pi3): 1.550e-01\n",
      "Epoch 72200, Train loss: 3.394e+06, Test loss: 4.628e+06, MSE(e): 3.374e-01, MSE(pi1): 4.718e-01, MSE(pi2): 1.952e-01, MSE(pi3): 1.549e-01\n",
      "Epoch 72300, Train loss: 3.393e+06, Test loss: 4.626e+06, MSE(e): 3.372e-01, MSE(pi1): 4.716e-01, MSE(pi2): 1.952e-01, MSE(pi3): 1.549e-01\n",
      "Epoch 72400, Train loss: 3.391e+06, Test loss: 4.625e+06, MSE(e): 3.371e-01, MSE(pi1): 4.714e-01, MSE(pi2): 1.951e-01, MSE(pi3): 1.548e-01\n",
      "Epoch 72500, Train loss: 3.390e+06, Test loss: 4.623e+06, MSE(e): 3.369e-01, MSE(pi1): 4.712e-01, MSE(pi2): 1.950e-01, MSE(pi3): 1.548e-01\n",
      "Epoch 72600, Train loss: 3.388e+06, Test loss: 4.622e+06, MSE(e): 3.368e-01, MSE(pi1): 4.710e-01, MSE(pi2): 1.950e-01, MSE(pi3): 1.547e-01\n",
      "Epoch 72700, Train loss: 3.387e+06, Test loss: 4.621e+06, MSE(e): 3.367e-01, MSE(pi1): 4.709e-01, MSE(pi2): 1.949e-01, MSE(pi3): 1.547e-01\n",
      "Epoch 72800, Train loss: 3.386e+06, Test loss: 4.619e+06, MSE(e): 3.365e-01, MSE(pi1): 4.707e-01, MSE(pi2): 1.948e-01, MSE(pi3): 1.547e-01\n",
      "Epoch 72900, Train loss: 3.384e+06, Test loss: 4.618e+06, MSE(e): 3.364e-01, MSE(pi1): 4.705e-01, MSE(pi2): 1.947e-01, MSE(pi3): 1.546e-01\n",
      "Epoch 73000, Train loss: 3.383e+06, Test loss: 4.616e+06, MSE(e): 3.362e-01, MSE(pi1): 4.703e-01, MSE(pi2): 1.947e-01, MSE(pi3): 1.546e-01\n",
      "Epoch 73100, Train loss: 3.381e+06, Test loss: 4.615e+06, MSE(e): 3.361e-01, MSE(pi1): 4.701e-01, MSE(pi2): 1.946e-01, MSE(pi3): 1.545e-01\n",
      "Epoch 73200, Train loss: 3.380e+06, Test loss: 4.614e+06, MSE(e): 3.359e-01, MSE(pi1): 4.699e-01, MSE(pi2): 1.945e-01, MSE(pi3): 1.545e-01\n",
      "Epoch 73300, Train loss: 3.378e+06, Test loss: 4.612e+06, MSE(e): 3.358e-01, MSE(pi1): 4.698e-01, MSE(pi2): 1.944e-01, MSE(pi3): 1.544e-01\n",
      "Epoch 73400, Train loss: 3.377e+06, Test loss: 4.611e+06, MSE(e): 3.357e-01, MSE(pi1): 4.696e-01, MSE(pi2): 1.944e-01, MSE(pi3): 1.544e-01\n",
      "Epoch 73500, Train loss: 3.375e+06, Test loss: 4.610e+06, MSE(e): 3.355e-01, MSE(pi1): 4.694e-01, MSE(pi2): 1.943e-01, MSE(pi3): 1.543e-01\n",
      "Epoch 73600, Train loss: 3.374e+06, Test loss: 4.608e+06, MSE(e): 3.354e-01, MSE(pi1): 4.692e-01, MSE(pi2): 1.942e-01, MSE(pi3): 1.543e-01\n",
      "Epoch 73700, Train loss: 3.373e+06, Test loss: 4.607e+06, MSE(e): 3.352e-01, MSE(pi1): 4.690e-01, MSE(pi2): 1.942e-01, MSE(pi3): 1.542e-01\n",
      "Epoch 73800, Train loss: 3.371e+06, Test loss: 4.605e+06, MSE(e): 3.351e-01, MSE(pi1): 4.689e-01, MSE(pi2): 1.941e-01, MSE(pi3): 1.542e-01\n",
      "Epoch 73900, Train loss: 3.370e+06, Test loss: 4.604e+06, MSE(e): 3.350e-01, MSE(pi1): 4.687e-01, MSE(pi2): 1.940e-01, MSE(pi3): 1.542e-01\n",
      "Epoch 74000, Train loss: 3.368e+06, Test loss: 4.602e+06, MSE(e): 3.348e-01, MSE(pi1): 4.685e-01, MSE(pi2): 1.939e-01, MSE(pi3): 1.541e-01\n",
      "Epoch 74100, Train loss: 3.367e+06, Test loss: 4.601e+06, MSE(e): 3.347e-01, MSE(pi1): 4.683e-01, MSE(pi2): 1.939e-01, MSE(pi3): 1.541e-01\n",
      "Epoch 74200, Train loss: 3.366e+06, Test loss: 4.600e+06, MSE(e): 3.345e-01, MSE(pi1): 4.682e-01, MSE(pi2): 1.938e-01, MSE(pi3): 1.540e-01\n",
      "Epoch 74300, Train loss: 3.364e+06, Test loss: 4.598e+06, MSE(e): 3.344e-01, MSE(pi1): 4.680e-01, MSE(pi2): 1.937e-01, MSE(pi3): 1.540e-01\n",
      "Epoch 74400, Train loss: 3.363e+06, Test loss: 4.597e+06, MSE(e): 3.342e-01, MSE(pi1): 4.678e-01, MSE(pi2): 1.937e-01, MSE(pi3): 1.539e-01\n",
      "Epoch 74500, Train loss: 3.361e+06, Test loss: 4.596e+06, MSE(e): 3.341e-01, MSE(pi1): 4.677e-01, MSE(pi2): 1.936e-01, MSE(pi3): 1.539e-01\n",
      "Epoch 74600, Train loss: 3.360e+06, Test loss: 4.594e+06, MSE(e): 3.340e-01, MSE(pi1): 4.675e-01, MSE(pi2): 1.935e-01, MSE(pi3): 1.538e-01\n",
      "Epoch 74700, Train loss: 3.359e+06, Test loss: 4.593e+06, MSE(e): 3.338e-01, MSE(pi1): 4.673e-01, MSE(pi2): 1.934e-01, MSE(pi3): 1.538e-01\n",
      "Epoch 74800, Train loss: 3.357e+06, Test loss: 4.591e+06, MSE(e): 3.337e-01, MSE(pi1): 4.671e-01, MSE(pi2): 1.934e-01, MSE(pi3): 1.538e-01\n",
      "Epoch 74900, Train loss: 3.356e+06, Test loss: 4.590e+06, MSE(e): 3.335e-01, MSE(pi1): 4.670e-01, MSE(pi2): 1.933e-01, MSE(pi3): 1.537e-01\n",
      "Epoch 75000, Train loss: 3.354e+06, Test loss: 4.589e+06, MSE(e): 3.334e-01, MSE(pi1): 4.668e-01, MSE(pi2): 1.932e-01, MSE(pi3): 1.537e-01\n",
      "Epoch 75100, Train loss: 3.353e+06, Test loss: 4.587e+06, MSE(e): 3.333e-01, MSE(pi1): 4.666e-01, MSE(pi2): 1.932e-01, MSE(pi3): 1.536e-01\n",
      "Epoch 75200, Train loss: 3.352e+06, Test loss: 4.586e+06, MSE(e): 3.331e-01, MSE(pi1): 4.665e-01, MSE(pi2): 1.931e-01, MSE(pi3): 1.536e-01\n",
      "Epoch 75300, Train loss: 3.350e+06, Test loss: 4.584e+06, MSE(e): 3.330e-01, MSE(pi1): 4.663e-01, MSE(pi2): 1.930e-01, MSE(pi3): 1.535e-01\n",
      "Epoch 75400, Train loss: 3.349e+06, Test loss: 4.583e+06, MSE(e): 3.329e-01, MSE(pi1): 4.661e-01, MSE(pi2): 1.929e-01, MSE(pi3): 1.535e-01\n",
      "Epoch 75500, Train loss: 3.347e+06, Test loss: 4.582e+06, MSE(e): 3.327e-01, MSE(pi1): 4.660e-01, MSE(pi2): 1.929e-01, MSE(pi3): 1.535e-01\n",
      "Epoch 75600, Train loss: 3.346e+06, Test loss: 4.580e+06, MSE(e): 3.326e-01, MSE(pi1): 4.658e-01, MSE(pi2): 1.928e-01, MSE(pi3): 1.534e-01\n",
      "Epoch 75700, Train loss: 3.345e+06, Test loss: 4.579e+06, MSE(e): 3.324e-01, MSE(pi1): 4.657e-01, MSE(pi2): 1.927e-01, MSE(pi3): 1.534e-01\n",
      "Epoch 75800, Train loss: 3.343e+06, Test loss: 4.577e+06, MSE(e): 3.323e-01, MSE(pi1): 4.655e-01, MSE(pi2): 1.927e-01, MSE(pi3): 1.533e-01\n",
      "Epoch 75900, Train loss: 3.342e+06, Test loss: 4.576e+06, MSE(e): 3.322e-01, MSE(pi1): 4.653e-01, MSE(pi2): 1.926e-01, MSE(pi3): 1.533e-01\n",
      "Epoch 76000, Train loss: 3.341e+06, Test loss: 4.574e+06, MSE(e): 3.320e-01, MSE(pi1): 4.652e-01, MSE(pi2): 1.925e-01, MSE(pi3): 1.532e-01\n",
      "Epoch 76100, Train loss: 3.339e+06, Test loss: 4.573e+06, MSE(e): 3.319e-01, MSE(pi1): 4.650e-01, MSE(pi2): 1.925e-01, MSE(pi3): 1.532e-01\n",
      "Epoch 76200, Train loss: 3.338e+06, Test loss: 4.572e+06, MSE(e): 3.318e-01, MSE(pi1): 4.649e-01, MSE(pi2): 1.924e-01, MSE(pi3): 1.532e-01\n",
      "Epoch 76300, Train loss: 3.336e+06, Test loss: 4.570e+06, MSE(e): 3.316e-01, MSE(pi1): 4.647e-01, MSE(pi2): 1.923e-01, MSE(pi3): 1.531e-01\n",
      "Epoch 76400, Train loss: 3.335e+06, Test loss: 4.569e+06, MSE(e): 3.315e-01, MSE(pi1): 4.646e-01, MSE(pi2): 1.922e-01, MSE(pi3): 1.531e-01\n",
      "Epoch 76500, Train loss: 3.334e+06, Test loss: 4.567e+06, MSE(e): 3.314e-01, MSE(pi1): 4.644e-01, MSE(pi2): 1.922e-01, MSE(pi3): 1.530e-01\n",
      "Epoch 76600, Train loss: 3.332e+06, Test loss: 4.566e+06, MSE(e): 3.312e-01, MSE(pi1): 4.642e-01, MSE(pi2): 1.921e-01, MSE(pi3): 1.530e-01\n",
      "Epoch 76700, Train loss: 3.331e+06, Test loss: 4.565e+06, MSE(e): 3.311e-01, MSE(pi1): 4.641e-01, MSE(pi2): 1.920e-01, MSE(pi3): 1.529e-01\n",
      "Epoch 76800, Train loss: 3.330e+06, Test loss: 4.563e+06, MSE(e): 3.309e-01, MSE(pi1): 4.639e-01, MSE(pi2): 1.920e-01, MSE(pi3): 1.529e-01\n",
      "Epoch 76900, Train loss: 3.328e+06, Test loss: 4.562e+06, MSE(e): 3.308e-01, MSE(pi1): 4.638e-01, MSE(pi2): 1.919e-01, MSE(pi3): 1.529e-01\n",
      "Epoch 77000, Train loss: 3.327e+06, Test loss: 4.560e+06, MSE(e): 3.307e-01, MSE(pi1): 4.636e-01, MSE(pi2): 1.918e-01, MSE(pi3): 1.528e-01\n",
      "Epoch 77100, Train loss: 3.325e+06, Test loss: 4.559e+06, MSE(e): 3.305e-01, MSE(pi1): 4.635e-01, MSE(pi2): 1.918e-01, MSE(pi3): 1.528e-01\n",
      "Epoch 77200, Train loss: 3.324e+06, Test loss: 4.557e+06, MSE(e): 3.304e-01, MSE(pi1): 4.633e-01, MSE(pi2): 1.917e-01, MSE(pi3): 1.527e-01\n",
      "Epoch 77300, Train loss: 3.323e+06, Test loss: 4.556e+06, MSE(e): 3.303e-01, MSE(pi1): 4.632e-01, MSE(pi2): 1.916e-01, MSE(pi3): 1.527e-01\n",
      "Epoch 77400, Train loss: 3.321e+06, Test loss: 4.555e+06, MSE(e): 3.301e-01, MSE(pi1): 4.630e-01, MSE(pi2): 1.916e-01, MSE(pi3): 1.526e-01\n",
      "Epoch 77500, Train loss: 3.320e+06, Test loss: 4.553e+06, MSE(e): 3.300e-01, MSE(pi1): 4.629e-01, MSE(pi2): 1.915e-01, MSE(pi3): 1.526e-01\n",
      "Epoch 77600, Train loss: 3.319e+06, Test loss: 4.552e+06, MSE(e): 3.299e-01, MSE(pi1): 4.627e-01, MSE(pi2): 1.914e-01, MSE(pi3): 1.526e-01\n",
      "Epoch 77700, Train loss: 3.317e+06, Test loss: 4.550e+06, MSE(e): 3.297e-01, MSE(pi1): 4.626e-01, MSE(pi2): 1.913e-01, MSE(pi3): 1.525e-01\n",
      "Epoch 77800, Train loss: 3.316e+06, Test loss: 4.549e+06, MSE(e): 3.296e-01, MSE(pi1): 4.624e-01, MSE(pi2): 1.913e-01, MSE(pi3): 1.525e-01\n",
      "Epoch 77900, Train loss: 3.315e+06, Test loss: 4.547e+06, MSE(e): 3.295e-01, MSE(pi1): 4.623e-01, MSE(pi2): 1.912e-01, MSE(pi3): 1.524e-01\n",
      "Epoch 78000, Train loss: 3.313e+06, Test loss: 4.546e+06, MSE(e): 3.293e-01, MSE(pi1): 4.621e-01, MSE(pi2): 1.911e-01, MSE(pi3): 1.524e-01\n",
      "Epoch 78100, Train loss: 3.312e+06, Test loss: 4.545e+06, MSE(e): 3.292e-01, MSE(pi1): 4.620e-01, MSE(pi2): 1.911e-01, MSE(pi3): 1.524e-01\n",
      "Epoch 78200, Train loss: 3.311e+06, Test loss: 4.543e+06, MSE(e): 3.291e-01, MSE(pi1): 4.619e-01, MSE(pi2): 1.910e-01, MSE(pi3): 1.523e-01\n",
      "Epoch 78300, Train loss: 3.309e+06, Test loss: 4.542e+06, MSE(e): 3.289e-01, MSE(pi1): 4.617e-01, MSE(pi2): 1.909e-01, MSE(pi3): 1.523e-01\n",
      "Epoch 78400, Train loss: 3.308e+06, Test loss: 4.540e+06, MSE(e): 3.288e-01, MSE(pi1): 4.616e-01, MSE(pi2): 1.909e-01, MSE(pi3): 1.522e-01\n",
      "Epoch 78500, Train loss: 3.307e+06, Test loss: 4.539e+06, MSE(e): 3.287e-01, MSE(pi1): 4.614e-01, MSE(pi2): 1.908e-01, MSE(pi3): 1.522e-01\n",
      "Epoch 78600, Train loss: 3.305e+06, Test loss: 4.537e+06, MSE(e): 3.285e-01, MSE(pi1): 4.613e-01, MSE(pi2): 1.907e-01, MSE(pi3): 1.521e-01\n",
      "Epoch 78700, Train loss: 3.304e+06, Test loss: 4.536e+06, MSE(e): 3.284e-01, MSE(pi1): 4.612e-01, MSE(pi2): 1.907e-01, MSE(pi3): 1.521e-01\n",
      "Epoch 78800, Train loss: 3.303e+06, Test loss: 4.534e+06, MSE(e): 3.283e-01, MSE(pi1): 4.610e-01, MSE(pi2): 1.906e-01, MSE(pi3): 1.521e-01\n",
      "Epoch 78900, Train loss: 3.301e+06, Test loss: 4.533e+06, MSE(e): 3.281e-01, MSE(pi1): 4.609e-01, MSE(pi2): 1.905e-01, MSE(pi3): 1.520e-01\n",
      "Epoch 79000, Train loss: 3.300e+06, Test loss: 4.532e+06, MSE(e): 3.280e-01, MSE(pi1): 4.607e-01, MSE(pi2): 1.905e-01, MSE(pi3): 1.520e-01\n",
      "Epoch 79100, Train loss: 3.299e+06, Test loss: 4.530e+06, MSE(e): 3.279e-01, MSE(pi1): 4.606e-01, MSE(pi2): 1.904e-01, MSE(pi3): 1.519e-01\n",
      "Epoch 79200, Train loss: 3.297e+06, Test loss: 4.529e+06, MSE(e): 3.278e-01, MSE(pi1): 4.605e-01, MSE(pi2): 1.903e-01, MSE(pi3): 1.519e-01\n",
      "Epoch 79300, Train loss: 3.296e+06, Test loss: 4.527e+06, MSE(e): 3.276e-01, MSE(pi1): 4.603e-01, MSE(pi2): 1.903e-01, MSE(pi3): 1.519e-01\n",
      "Epoch 79400, Train loss: 3.295e+06, Test loss: 4.526e+06, MSE(e): 3.275e-01, MSE(pi1): 4.602e-01, MSE(pi2): 1.902e-01, MSE(pi3): 1.518e-01\n",
      "Epoch 79500, Train loss: 3.294e+06, Test loss: 4.524e+06, MSE(e): 3.274e-01, MSE(pi1): 4.601e-01, MSE(pi2): 1.901e-01, MSE(pi3): 1.518e-01\n",
      "Epoch 79600, Train loss: 3.292e+06, Test loss: 4.523e+06, MSE(e): 3.272e-01, MSE(pi1): 4.599e-01, MSE(pi2): 1.901e-01, MSE(pi3): 1.517e-01\n",
      "Epoch 79700, Train loss: 3.291e+06, Test loss: 4.522e+06, MSE(e): 3.271e-01, MSE(pi1): 4.598e-01, MSE(pi2): 1.900e-01, MSE(pi3): 1.517e-01\n",
      "Epoch 79800, Train loss: 3.290e+06, Test loss: 4.520e+06, MSE(e): 3.270e-01, MSE(pi1): 4.597e-01, MSE(pi2): 1.899e-01, MSE(pi3): 1.517e-01\n",
      "Epoch 79900, Train loss: 3.288e+06, Test loss: 4.519e+06, MSE(e): 3.268e-01, MSE(pi1): 4.595e-01, MSE(pi2): 1.899e-01, MSE(pi3): 1.516e-01\n",
      "Epoch 80000, Train loss: 3.287e+06, Test loss: 4.517e+06, MSE(e): 3.267e-01, MSE(pi1): 4.594e-01, MSE(pi2): 1.898e-01, MSE(pi3): 1.516e-01\n",
      "Epoch 80100, Train loss: 3.286e+06, Test loss: 4.516e+06, MSE(e): 3.266e-01, MSE(pi1): 4.593e-01, MSE(pi2): 1.897e-01, MSE(pi3): 1.515e-01\n",
      "Epoch 80200, Train loss: 3.284e+06, Test loss: 4.514e+06, MSE(e): 3.265e-01, MSE(pi1): 4.592e-01, MSE(pi2): 1.897e-01, MSE(pi3): 1.515e-01\n",
      "Epoch 80300, Train loss: 3.283e+06, Test loss: 4.513e+06, MSE(e): 3.263e-01, MSE(pi1): 4.590e-01, MSE(pi2): 1.896e-01, MSE(pi3): 1.515e-01\n",
      "Epoch 80400, Train loss: 3.282e+06, Test loss: 4.511e+06, MSE(e): 3.262e-01, MSE(pi1): 4.589e-01, MSE(pi2): 1.895e-01, MSE(pi3): 1.514e-01\n",
      "Epoch 80500, Train loss: 3.281e+06, Test loss: 4.510e+06, MSE(e): 3.261e-01, MSE(pi1): 4.588e-01, MSE(pi2): 1.895e-01, MSE(pi3): 1.514e-01\n",
      "Epoch 80600, Train loss: 3.279e+06, Test loss: 4.508e+06, MSE(e): 3.259e-01, MSE(pi1): 4.587e-01, MSE(pi2): 1.894e-01, MSE(pi3): 1.514e-01\n",
      "Epoch 80700, Train loss: 3.278e+06, Test loss: 4.507e+06, MSE(e): 3.258e-01, MSE(pi1): 4.585e-01, MSE(pi2): 1.893e-01, MSE(pi3): 1.513e-01\n",
      "Epoch 80800, Train loss: 3.277e+06, Test loss: 4.506e+06, MSE(e): 3.257e-01, MSE(pi1): 4.584e-01, MSE(pi2): 1.893e-01, MSE(pi3): 1.513e-01\n",
      "Epoch 80900, Train loss: 3.275e+06, Test loss: 4.504e+06, MSE(e): 3.256e-01, MSE(pi1): 4.583e-01, MSE(pi2): 1.892e-01, MSE(pi3): 1.512e-01\n",
      "Epoch 81000, Train loss: 3.274e+06, Test loss: 4.503e+06, MSE(e): 3.254e-01, MSE(pi1): 4.582e-01, MSE(pi2): 1.891e-01, MSE(pi3): 1.512e-01\n",
      "Epoch 81100, Train loss: 3.273e+06, Test loss: 4.501e+06, MSE(e): 3.253e-01, MSE(pi1): 4.580e-01, MSE(pi2): 1.891e-01, MSE(pi3): 1.512e-01\n",
      "Epoch 81200, Train loss: 3.272e+06, Test loss: 4.500e+06, MSE(e): 3.252e-01, MSE(pi1): 4.579e-01, MSE(pi2): 1.890e-01, MSE(pi3): 1.511e-01\n",
      "Epoch 81300, Train loss: 3.270e+06, Test loss: 4.499e+06, MSE(e): 3.250e-01, MSE(pi1): 4.578e-01, MSE(pi2): 1.889e-01, MSE(pi3): 1.511e-01\n",
      "Epoch 81400, Train loss: 3.269e+06, Test loss: 4.497e+06, MSE(e): 3.249e-01, MSE(pi1): 4.577e-01, MSE(pi2): 1.889e-01, MSE(pi3): 1.510e-01\n",
      "Epoch 81500, Train loss: 3.268e+06, Test loss: 4.496e+06, MSE(e): 3.248e-01, MSE(pi1): 4.576e-01, MSE(pi2): 1.888e-01, MSE(pi3): 1.510e-01\n",
      "Epoch 81600, Train loss: 3.266e+06, Test loss: 4.494e+06, MSE(e): 3.247e-01, MSE(pi1): 4.574e-01, MSE(pi2): 1.887e-01, MSE(pi3): 1.510e-01\n",
      "Epoch 81700, Train loss: 3.265e+06, Test loss: 4.493e+06, MSE(e): 3.245e-01, MSE(pi1): 4.573e-01, MSE(pi2): 1.887e-01, MSE(pi3): 1.509e-01\n",
      "Epoch 81800, Train loss: 3.264e+06, Test loss: 4.491e+06, MSE(e): 3.244e-01, MSE(pi1): 4.572e-01, MSE(pi2): 1.886e-01, MSE(pi3): 1.509e-01\n",
      "Epoch 81900, Train loss: 3.263e+06, Test loss: 4.490e+06, MSE(e): 3.243e-01, MSE(pi1): 4.571e-01, MSE(pi2): 1.886e-01, MSE(pi3): 1.509e-01\n",
      "Epoch 82000, Train loss: 3.261e+06, Test loss: 4.489e+06, MSE(e): 3.242e-01, MSE(pi1): 4.570e-01, MSE(pi2): 1.885e-01, MSE(pi3): 1.508e-01\n",
      "Epoch 82100, Train loss: 3.260e+06, Test loss: 4.487e+06, MSE(e): 3.240e-01, MSE(pi1): 4.569e-01, MSE(pi2): 1.884e-01, MSE(pi3): 1.508e-01\n",
      "Epoch 82200, Train loss: 3.259e+06, Test loss: 4.486e+06, MSE(e): 3.239e-01, MSE(pi1): 4.567e-01, MSE(pi2): 1.884e-01, MSE(pi3): 1.507e-01\n",
      "Epoch 82300, Train loss: 3.258e+06, Test loss: 4.484e+06, MSE(e): 3.238e-01, MSE(pi1): 4.566e-01, MSE(pi2): 1.883e-01, MSE(pi3): 1.507e-01\n",
      "Epoch 82400, Train loss: 3.256e+06, Test loss: 4.483e+06, MSE(e): 3.237e-01, MSE(pi1): 4.565e-01, MSE(pi2): 1.882e-01, MSE(pi3): 1.507e-01\n",
      "Epoch 82500, Train loss: 3.255e+06, Test loss: 4.481e+06, MSE(e): 3.235e-01, MSE(pi1): 4.564e-01, MSE(pi2): 1.882e-01, MSE(pi3): 1.506e-01\n",
      "Epoch 82600, Train loss: 3.254e+06, Test loss: 4.480e+06, MSE(e): 3.234e-01, MSE(pi1): 4.563e-01, MSE(pi2): 1.881e-01, MSE(pi3): 1.506e-01\n",
      "Epoch 82700, Train loss: 3.253e+06, Test loss: 4.479e+06, MSE(e): 3.233e-01, MSE(pi1): 4.562e-01, MSE(pi2): 1.880e-01, MSE(pi3): 1.506e-01\n",
      "Epoch 82800, Train loss: 3.251e+06, Test loss: 4.477e+06, MSE(e): 3.232e-01, MSE(pi1): 4.561e-01, MSE(pi2): 1.880e-01, MSE(pi3): 1.505e-01\n",
      "Epoch 82900, Train loss: 3.250e+06, Test loss: 4.476e+06, MSE(e): 3.230e-01, MSE(pi1): 4.560e-01, MSE(pi2): 1.879e-01, MSE(pi3): 1.505e-01\n",
      "Epoch 83000, Train loss: 3.249e+06, Test loss: 4.474e+06, MSE(e): 3.229e-01, MSE(pi1): 4.558e-01, MSE(pi2): 1.879e-01, MSE(pi3): 1.505e-01\n",
      "Epoch 83100, Train loss: 3.248e+06, Test loss: 4.473e+06, MSE(e): 3.228e-01, MSE(pi1): 4.557e-01, MSE(pi2): 1.878e-01, MSE(pi3): 1.504e-01\n",
      "Epoch 83200, Train loss: 3.246e+06, Test loss: 4.472e+06, MSE(e): 3.227e-01, MSE(pi1): 4.556e-01, MSE(pi2): 1.877e-01, MSE(pi3): 1.504e-01\n",
      "Epoch 83300, Train loss: 3.245e+06, Test loss: 4.470e+06, MSE(e): 3.225e-01, MSE(pi1): 4.555e-01, MSE(pi2): 1.877e-01, MSE(pi3): 1.503e-01\n",
      "Epoch 83400, Train loss: 3.244e+06, Test loss: 4.469e+06, MSE(e): 3.224e-01, MSE(pi1): 4.554e-01, MSE(pi2): 1.876e-01, MSE(pi3): 1.503e-01\n",
      "Epoch 83500, Train loss: 3.243e+06, Test loss: 4.467e+06, MSE(e): 3.223e-01, MSE(pi1): 4.553e-01, MSE(pi2): 1.875e-01, MSE(pi3): 1.503e-01\n",
      "Epoch 83600, Train loss: 3.242e+06, Test loss: 4.466e+06, MSE(e): 3.222e-01, MSE(pi1): 4.552e-01, MSE(pi2): 1.875e-01, MSE(pi3): 1.502e-01\n",
      "Epoch 83700, Train loss: 3.240e+06, Test loss: 4.465e+06, MSE(e): 3.221e-01, MSE(pi1): 4.551e-01, MSE(pi2): 1.874e-01, MSE(pi3): 1.502e-01\n",
      "Epoch 83800, Train loss: 3.239e+06, Test loss: 4.463e+06, MSE(e): 3.219e-01, MSE(pi1): 4.550e-01, MSE(pi2): 1.873e-01, MSE(pi3): 1.502e-01\n",
      "Epoch 83900, Train loss: 3.238e+06, Test loss: 4.462e+06, MSE(e): 3.218e-01, MSE(pi1): 4.549e-01, MSE(pi2): 1.873e-01, MSE(pi3): 1.501e-01\n",
      "Epoch 84000, Train loss: 3.237e+06, Test loss: 4.460e+06, MSE(e): 3.217e-01, MSE(pi1): 4.548e-01, MSE(pi2): 1.872e-01, MSE(pi3): 1.501e-01\n",
      "Epoch 84100, Train loss: 3.235e+06, Test loss: 4.459e+06, MSE(e): 3.216e-01, MSE(pi1): 4.547e-01, MSE(pi2): 1.872e-01, MSE(pi3): 1.501e-01\n",
      "Epoch 84200, Train loss: 3.234e+06, Test loss: 4.457e+06, MSE(e): 3.214e-01, MSE(pi1): 4.546e-01, MSE(pi2): 1.871e-01, MSE(pi3): 1.500e-01\n",
      "Epoch 84300, Train loss: 3.233e+06, Test loss: 4.456e+06, MSE(e): 3.213e-01, MSE(pi1): 4.545e-01, MSE(pi2): 1.870e-01, MSE(pi3): 1.500e-01\n",
      "Epoch 84400, Train loss: 3.232e+06, Test loss: 4.455e+06, MSE(e): 3.212e-01, MSE(pi1): 4.544e-01, MSE(pi2): 1.870e-01, MSE(pi3): 1.500e-01\n",
      "Epoch 84500, Train loss: 3.231e+06, Test loss: 4.453e+06, MSE(e): 3.211e-01, MSE(pi1): 4.543e-01, MSE(pi2): 1.869e-01, MSE(pi3): 1.499e-01\n",
      "Epoch 84600, Train loss: 3.229e+06, Test loss: 4.452e+06, MSE(e): 3.210e-01, MSE(pi1): 4.542e-01, MSE(pi2): 1.868e-01, MSE(pi3): 1.499e-01\n",
      "Epoch 84700, Train loss: 3.228e+06, Test loss: 4.451e+06, MSE(e): 3.208e-01, MSE(pi1): 4.541e-01, MSE(pi2): 1.868e-01, MSE(pi3): 1.499e-01\n",
      "Epoch 84800, Train loss: 3.227e+06, Test loss: 4.449e+06, MSE(e): 3.207e-01, MSE(pi1): 4.540e-01, MSE(pi2): 1.867e-01, MSE(pi3): 1.498e-01\n",
      "Epoch 84900, Train loss: 3.226e+06, Test loss: 4.448e+06, MSE(e): 3.206e-01, MSE(pi1): 4.539e-01, MSE(pi2): 1.867e-01, MSE(pi3): 1.498e-01\n",
      "Epoch 85000, Train loss: 3.225e+06, Test loss: 4.446e+06, MSE(e): 3.205e-01, MSE(pi1): 4.538e-01, MSE(pi2): 1.866e-01, MSE(pi3): 1.497e-01\n",
      "Epoch 85100, Train loss: 3.223e+06, Test loss: 4.445e+06, MSE(e): 3.204e-01, MSE(pi1): 4.537e-01, MSE(pi2): 1.865e-01, MSE(pi3): 1.497e-01\n",
      "Epoch 85200, Train loss: 3.222e+06, Test loss: 4.444e+06, MSE(e): 3.202e-01, MSE(pi1): 4.536e-01, MSE(pi2): 1.865e-01, MSE(pi3): 1.497e-01\n",
      "Epoch 85300, Train loss: 3.221e+06, Test loss: 4.442e+06, MSE(e): 3.201e-01, MSE(pi1): 4.535e-01, MSE(pi2): 1.864e-01, MSE(pi3): 1.496e-01\n",
      "Epoch 85400, Train loss: 3.220e+06, Test loss: 4.441e+06, MSE(e): 3.200e-01, MSE(pi1): 4.535e-01, MSE(pi2): 1.864e-01, MSE(pi3): 1.496e-01\n",
      "Epoch 85500, Train loss: 3.219e+06, Test loss: 4.439e+06, MSE(e): 3.199e-01, MSE(pi1): 4.534e-01, MSE(pi2): 1.863e-01, MSE(pi3): 1.496e-01\n",
      "Epoch 85600, Train loss: 3.217e+06, Test loss: 4.438e+06, MSE(e): 3.198e-01, MSE(pi1): 4.533e-01, MSE(pi2): 1.862e-01, MSE(pi3): 1.495e-01\n",
      "Epoch 85700, Train loss: 3.216e+06, Test loss: 4.437e+06, MSE(e): 3.197e-01, MSE(pi1): 4.532e-01, MSE(pi2): 1.862e-01, MSE(pi3): 1.495e-01\n",
      "Epoch 85800, Train loss: 3.215e+06, Test loss: 4.435e+06, MSE(e): 3.195e-01, MSE(pi1): 4.531e-01, MSE(pi2): 1.861e-01, MSE(pi3): 1.495e-01\n",
      "Epoch 85900, Train loss: 3.214e+06, Test loss: 4.434e+06, MSE(e): 3.194e-01, MSE(pi1): 4.530e-01, MSE(pi2): 1.861e-01, MSE(pi3): 1.494e-01\n",
      "Epoch 86000, Train loss: 3.213e+06, Test loss: 4.433e+06, MSE(e): 3.193e-01, MSE(pi1): 4.529e-01, MSE(pi2): 1.860e-01, MSE(pi3): 1.494e-01\n",
      "Epoch 86100, Train loss: 3.212e+06, Test loss: 4.431e+06, MSE(e): 3.192e-01, MSE(pi1): 4.528e-01, MSE(pi2): 1.859e-01, MSE(pi3): 1.494e-01\n",
      "Epoch 86200, Train loss: 3.210e+06, Test loss: 4.430e+06, MSE(e): 3.191e-01, MSE(pi1): 4.527e-01, MSE(pi2): 1.859e-01, MSE(pi3): 1.493e-01\n",
      "Epoch 86300, Train loss: 3.209e+06, Test loss: 4.429e+06, MSE(e): 3.190e-01, MSE(pi1): 4.526e-01, MSE(pi2): 1.858e-01, MSE(pi3): 1.493e-01\n",
      "Epoch 86400, Train loss: 3.208e+06, Test loss: 4.427e+06, MSE(e): 3.188e-01, MSE(pi1): 4.525e-01, MSE(pi2): 1.857e-01, MSE(pi3): 1.493e-01\n",
      "Epoch 86500, Train loss: 3.207e+06, Test loss: 4.426e+06, MSE(e): 3.187e-01, MSE(pi1): 4.525e-01, MSE(pi2): 1.857e-01, MSE(pi3): 1.492e-01\n",
      "Epoch 86600, Train loss: 3.206e+06, Test loss: 4.425e+06, MSE(e): 3.186e-01, MSE(pi1): 4.524e-01, MSE(pi2): 1.856e-01, MSE(pi3): 1.492e-01\n",
      "Epoch 86700, Train loss: 3.205e+06, Test loss: 4.423e+06, MSE(e): 3.185e-01, MSE(pi1): 4.523e-01, MSE(pi2): 1.856e-01, MSE(pi3): 1.492e-01\n",
      "Epoch 86800, Train loss: 3.203e+06, Test loss: 4.422e+06, MSE(e): 3.184e-01, MSE(pi1): 4.522e-01, MSE(pi2): 1.855e-01, MSE(pi3): 1.492e-01\n",
      "Epoch 86900, Train loss: 3.202e+06, Test loss: 4.421e+06, MSE(e): 3.183e-01, MSE(pi1): 4.521e-01, MSE(pi2): 1.855e-01, MSE(pi3): 1.491e-01\n",
      "Epoch 87000, Train loss: 3.201e+06, Test loss: 4.419e+06, MSE(e): 3.181e-01, MSE(pi1): 4.520e-01, MSE(pi2): 1.854e-01, MSE(pi3): 1.491e-01\n",
      "Epoch 87100, Train loss: 3.200e+06, Test loss: 4.418e+06, MSE(e): 3.180e-01, MSE(pi1): 4.520e-01, MSE(pi2): 1.853e-01, MSE(pi3): 1.491e-01\n",
      "Epoch 87200, Train loss: 3.199e+06, Test loss: 4.417e+06, MSE(e): 3.179e-01, MSE(pi1): 4.519e-01, MSE(pi2): 1.853e-01, MSE(pi3): 1.490e-01\n",
      "Epoch 87300, Train loss: 3.198e+06, Test loss: 4.415e+06, MSE(e): 3.178e-01, MSE(pi1): 4.518e-01, MSE(pi2): 1.852e-01, MSE(pi3): 1.490e-01\n",
      "Epoch 87400, Train loss: 3.196e+06, Test loss: 4.414e+06, MSE(e): 3.177e-01, MSE(pi1): 4.517e-01, MSE(pi2): 1.852e-01, MSE(pi3): 1.490e-01\n",
      "Epoch 87500, Train loss: 3.195e+06, Test loss: 4.413e+06, MSE(e): 3.176e-01, MSE(pi1): 4.516e-01, MSE(pi2): 1.851e-01, MSE(pi3): 1.489e-01\n",
      "Epoch 87600, Train loss: 3.194e+06, Test loss: 4.411e+06, MSE(e): 3.175e-01, MSE(pi1): 4.516e-01, MSE(pi2): 1.850e-01, MSE(pi3): 1.489e-01\n",
      "Epoch 87700, Train loss: 3.193e+06, Test loss: 4.410e+06, MSE(e): 3.173e-01, MSE(pi1): 4.515e-01, MSE(pi2): 1.850e-01, MSE(pi3): 1.489e-01\n",
      "Epoch 87800, Train loss: 3.192e+06, Test loss: 4.409e+06, MSE(e): 3.172e-01, MSE(pi1): 4.514e-01, MSE(pi2): 1.849e-01, MSE(pi3): 1.488e-01\n",
      "Epoch 87900, Train loss: 3.191e+06, Test loss: 4.408e+06, MSE(e): 3.171e-01, MSE(pi1): 4.513e-01, MSE(pi2): 1.849e-01, MSE(pi3): 1.488e-01\n",
      "Epoch 88000, Train loss: 3.190e+06, Test loss: 4.406e+06, MSE(e): 3.170e-01, MSE(pi1): 4.512e-01, MSE(pi2): 1.848e-01, MSE(pi3): 1.488e-01\n",
      "Epoch 88100, Train loss: 3.189e+06, Test loss: 4.405e+06, MSE(e): 3.169e-01, MSE(pi1): 4.512e-01, MSE(pi2): 1.847e-01, MSE(pi3): 1.487e-01\n",
      "Epoch 88200, Train loss: 3.187e+06, Test loss: 4.404e+06, MSE(e): 3.168e-01, MSE(pi1): 4.511e-01, MSE(pi2): 1.847e-01, MSE(pi3): 1.487e-01\n",
      "Epoch 88300, Train loss: 3.186e+06, Test loss: 4.402e+06, MSE(e): 3.167e-01, MSE(pi1): 4.510e-01, MSE(pi2): 1.846e-01, MSE(pi3): 1.487e-01\n",
      "Epoch 88400, Train loss: 3.185e+06, Test loss: 4.401e+06, MSE(e): 3.166e-01, MSE(pi1): 4.509e-01, MSE(pi2): 1.846e-01, MSE(pi3): 1.487e-01\n",
      "Epoch 88500, Train loss: 3.184e+06, Test loss: 4.400e+06, MSE(e): 3.164e-01, MSE(pi1): 4.508e-01, MSE(pi2): 1.845e-01, MSE(pi3): 1.486e-01\n",
      "Epoch 88600, Train loss: 3.183e+06, Test loss: 4.399e+06, MSE(e): 3.163e-01, MSE(pi1): 4.508e-01, MSE(pi2): 1.845e-01, MSE(pi3): 1.486e-01\n",
      "Epoch 88700, Train loss: 3.182e+06, Test loss: 4.397e+06, MSE(e): 3.162e-01, MSE(pi1): 4.507e-01, MSE(pi2): 1.844e-01, MSE(pi3): 1.486e-01\n",
      "Epoch 88800, Train loss: 3.181e+06, Test loss: 4.396e+06, MSE(e): 3.161e-01, MSE(pi1): 4.506e-01, MSE(pi2): 1.843e-01, MSE(pi3): 1.485e-01\n",
      "Epoch 88900, Train loss: 3.180e+06, Test loss: 4.395e+06, MSE(e): 3.160e-01, MSE(pi1): 4.505e-01, MSE(pi2): 1.843e-01, MSE(pi3): 1.485e-01\n",
      "Epoch 89000, Train loss: 3.178e+06, Test loss: 4.394e+06, MSE(e): 3.159e-01, MSE(pi1): 4.505e-01, MSE(pi2): 1.842e-01, MSE(pi3): 1.485e-01\n",
      "Epoch 89100, Train loss: 3.177e+06, Test loss: 4.392e+06, MSE(e): 3.158e-01, MSE(pi1): 4.504e-01, MSE(pi2): 1.842e-01, MSE(pi3): 1.484e-01\n",
      "Epoch 89200, Train loss: 3.176e+06, Test loss: 4.391e+06, MSE(e): 3.157e-01, MSE(pi1): 4.503e-01, MSE(pi2): 1.841e-01, MSE(pi3): 1.484e-01\n",
      "Epoch 89300, Train loss: 3.175e+06, Test loss: 4.390e+06, MSE(e): 3.156e-01, MSE(pi1): 4.502e-01, MSE(pi2): 1.841e-01, MSE(pi3): 1.484e-01\n",
      "Epoch 89400, Train loss: 3.174e+06, Test loss: 4.389e+06, MSE(e): 3.155e-01, MSE(pi1): 4.502e-01, MSE(pi2): 1.840e-01, MSE(pi3): 1.483e-01\n",
      "Epoch 89500, Train loss: 3.173e+06, Test loss: 4.387e+06, MSE(e): 3.153e-01, MSE(pi1): 4.501e-01, MSE(pi2): 1.839e-01, MSE(pi3): 1.483e-01\n",
      "Epoch 89600, Train loss: 3.172e+06, Test loss: 4.386e+06, MSE(e): 3.152e-01, MSE(pi1): 4.500e-01, MSE(pi2): 1.839e-01, MSE(pi3): 1.483e-01\n",
      "Epoch 89700, Train loss: 3.171e+06, Test loss: 4.385e+06, MSE(e): 3.151e-01, MSE(pi1): 4.499e-01, MSE(pi2): 1.838e-01, MSE(pi3): 1.483e-01\n",
      "Epoch 89800, Train loss: 3.170e+06, Test loss: 4.384e+06, MSE(e): 3.150e-01, MSE(pi1): 4.499e-01, MSE(pi2): 1.838e-01, MSE(pi3): 1.482e-01\n",
      "Epoch 89900, Train loss: 3.169e+06, Test loss: 4.382e+06, MSE(e): 3.149e-01, MSE(pi1): 4.498e-01, MSE(pi2): 1.837e-01, MSE(pi3): 1.482e-01\n",
      "Epoch 90000, Train loss: 3.167e+06, Test loss: 4.381e+06, MSE(e): 3.148e-01, MSE(pi1): 4.497e-01, MSE(pi2): 1.837e-01, MSE(pi3): 1.482e-01\n",
      "Epoch 90100, Train loss: 3.166e+06, Test loss: 4.380e+06, MSE(e): 3.147e-01, MSE(pi1): 4.496e-01, MSE(pi2): 1.836e-01, MSE(pi3): 1.481e-01\n",
      "Epoch 90200, Train loss: 3.165e+06, Test loss: 4.379e+06, MSE(e): 3.146e-01, MSE(pi1): 4.496e-01, MSE(pi2): 1.836e-01, MSE(pi3): 1.481e-01\n",
      "Epoch 90300, Train loss: 3.164e+06, Test loss: 4.378e+06, MSE(e): 3.145e-01, MSE(pi1): 4.495e-01, MSE(pi2): 1.835e-01, MSE(pi3): 1.481e-01\n",
      "Epoch 90400, Train loss: 3.163e+06, Test loss: 4.376e+06, MSE(e): 3.144e-01, MSE(pi1): 4.494e-01, MSE(pi2): 1.834e-01, MSE(pi3): 1.481e-01\n",
      "Epoch 90500, Train loss: 3.162e+06, Test loss: 4.375e+06, MSE(e): 3.143e-01, MSE(pi1): 4.494e-01, MSE(pi2): 1.834e-01, MSE(pi3): 1.480e-01\n",
      "Epoch 90600, Train loss: 3.161e+06, Test loss: 4.374e+06, MSE(e): 3.141e-01, MSE(pi1): 4.493e-01, MSE(pi2): 1.833e-01, MSE(pi3): 1.480e-01\n",
      "Epoch 90700, Train loss: 3.160e+06, Test loss: 4.373e+06, MSE(e): 3.140e-01, MSE(pi1): 4.492e-01, MSE(pi2): 1.833e-01, MSE(pi3): 1.480e-01\n",
      "Epoch 90800, Train loss: 3.159e+06, Test loss: 4.372e+06, MSE(e): 3.139e-01, MSE(pi1): 4.492e-01, MSE(pi2): 1.832e-01, MSE(pi3): 1.479e-01\n",
      "Epoch 90900, Train loss: 3.158e+06, Test loss: 4.371e+06, MSE(e): 3.138e-01, MSE(pi1): 4.491e-01, MSE(pi2): 1.832e-01, MSE(pi3): 1.479e-01\n",
      "Epoch 91000, Train loss: 3.157e+06, Test loss: 4.369e+06, MSE(e): 3.137e-01, MSE(pi1): 4.490e-01, MSE(pi2): 1.831e-01, MSE(pi3): 1.479e-01\n",
      "Epoch 91100, Train loss: 3.156e+06, Test loss: 4.368e+06, MSE(e): 3.136e-01, MSE(pi1): 4.489e-01, MSE(pi2): 1.831e-01, MSE(pi3): 1.479e-01\n",
      "Epoch 91200, Train loss: 3.155e+06, Test loss: 4.367e+06, MSE(e): 3.135e-01, MSE(pi1): 4.489e-01, MSE(pi2): 1.830e-01, MSE(pi3): 1.478e-01\n",
      "Epoch 91300, Train loss: 3.153e+06, Test loss: 4.366e+06, MSE(e): 3.134e-01, MSE(pi1): 4.488e-01, MSE(pi2): 1.829e-01, MSE(pi3): 1.478e-01\n",
      "Epoch 91400, Train loss: 3.152e+06, Test loss: 4.365e+06, MSE(e): 3.133e-01, MSE(pi1): 4.487e-01, MSE(pi2): 1.829e-01, MSE(pi3): 1.478e-01\n",
      "Epoch 91500, Train loss: 3.151e+06, Test loss: 4.364e+06, MSE(e): 3.132e-01, MSE(pi1): 4.487e-01, MSE(pi2): 1.828e-01, MSE(pi3): 1.477e-01\n",
      "Epoch 91600, Train loss: 3.150e+06, Test loss: 4.362e+06, MSE(e): 3.131e-01, MSE(pi1): 4.486e-01, MSE(pi2): 1.828e-01, MSE(pi3): 1.477e-01\n",
      "Epoch 91700, Train loss: 3.149e+06, Test loss: 4.361e+06, MSE(e): 3.130e-01, MSE(pi1): 4.485e-01, MSE(pi2): 1.827e-01, MSE(pi3): 1.477e-01\n",
      "Epoch 91800, Train loss: 3.148e+06, Test loss: 4.360e+06, MSE(e): 3.129e-01, MSE(pi1): 4.485e-01, MSE(pi2): 1.827e-01, MSE(pi3): 1.477e-01\n",
      "Epoch 91900, Train loss: 3.147e+06, Test loss: 4.359e+06, MSE(e): 3.128e-01, MSE(pi1): 4.484e-01, MSE(pi2): 1.826e-01, MSE(pi3): 1.476e-01\n",
      "Epoch 92000, Train loss: 3.146e+06, Test loss: 4.358e+06, MSE(e): 3.127e-01, MSE(pi1): 4.483e-01, MSE(pi2): 1.826e-01, MSE(pi3): 1.476e-01\n",
      "Epoch 92100, Train loss: 3.145e+06, Test loss: 4.357e+06, MSE(e): 3.126e-01, MSE(pi1): 4.483e-01, MSE(pi2): 1.825e-01, MSE(pi3): 1.476e-01\n",
      "Epoch 92200, Train loss: 3.144e+06, Test loss: 4.356e+06, MSE(e): 3.125e-01, MSE(pi1): 4.482e-01, MSE(pi2): 1.825e-01, MSE(pi3): 1.475e-01\n",
      "Epoch 92300, Train loss: 3.143e+06, Test loss: 4.354e+06, MSE(e): 3.124e-01, MSE(pi1): 4.481e-01, MSE(pi2): 1.824e-01, MSE(pi3): 1.475e-01\n",
      "Epoch 92400, Train loss: 3.142e+06, Test loss: 4.353e+06, MSE(e): 3.122e-01, MSE(pi1): 4.481e-01, MSE(pi2): 1.823e-01, MSE(pi3): 1.475e-01\n",
      "Epoch 92500, Train loss: 3.141e+06, Test loss: 4.352e+06, MSE(e): 3.121e-01, MSE(pi1): 4.480e-01, MSE(pi2): 1.823e-01, MSE(pi3): 1.475e-01\n",
      "Epoch 92600, Train loss: 3.140e+06, Test loss: 4.351e+06, MSE(e): 3.120e-01, MSE(pi1): 4.479e-01, MSE(pi2): 1.822e-01, MSE(pi3): 1.474e-01\n",
      "Epoch 92700, Train loss: 3.139e+06, Test loss: 4.350e+06, MSE(e): 3.119e-01, MSE(pi1): 4.479e-01, MSE(pi2): 1.822e-01, MSE(pi3): 1.474e-01\n",
      "Epoch 92800, Train loss: 3.138e+06, Test loss: 4.349e+06, MSE(e): 3.118e-01, MSE(pi1): 4.478e-01, MSE(pi2): 1.821e-01, MSE(pi3): 1.474e-01\n",
      "Epoch 92900, Train loss: 3.137e+06, Test loss: 4.348e+06, MSE(e): 3.117e-01, MSE(pi1): 4.478e-01, MSE(pi2): 1.821e-01, MSE(pi3): 1.474e-01\n",
      "Epoch 93000, Train loss: 3.136e+06, Test loss: 4.347e+06, MSE(e): 3.116e-01, MSE(pi1): 4.477e-01, MSE(pi2): 1.820e-01, MSE(pi3): 1.473e-01\n",
      "Epoch 93100, Train loss: 3.135e+06, Test loss: 4.346e+06, MSE(e): 3.115e-01, MSE(pi1): 4.476e-01, MSE(pi2): 1.820e-01, MSE(pi3): 1.473e-01\n",
      "Epoch 93200, Train loss: 3.134e+06, Test loss: 4.345e+06, MSE(e): 3.114e-01, MSE(pi1): 4.476e-01, MSE(pi2): 1.819e-01, MSE(pi3): 1.473e-01\n",
      "Epoch 93300, Train loss: 3.133e+06, Test loss: 4.343e+06, MSE(e): 3.113e-01, MSE(pi1): 4.475e-01, MSE(pi2): 1.819e-01, MSE(pi3): 1.472e-01\n",
      "Epoch 93400, Train loss: 3.132e+06, Test loss: 4.342e+06, MSE(e): 3.112e-01, MSE(pi1): 4.474e-01, MSE(pi2): 1.818e-01, MSE(pi3): 1.472e-01\n",
      "Epoch 93500, Train loss: 3.131e+06, Test loss: 4.341e+06, MSE(e): 3.111e-01, MSE(pi1): 4.474e-01, MSE(pi2): 1.818e-01, MSE(pi3): 1.472e-01\n",
      "Epoch 93600, Train loss: 3.130e+06, Test loss: 4.340e+06, MSE(e): 3.110e-01, MSE(pi1): 4.473e-01, MSE(pi2): 1.817e-01, MSE(pi3): 1.472e-01\n",
      "Epoch 93700, Train loss: 3.129e+06, Test loss: 4.339e+06, MSE(e): 3.109e-01, MSE(pi1): 4.472e-01, MSE(pi2): 1.817e-01, MSE(pi3): 1.471e-01\n",
      "Epoch 93800, Train loss: 3.127e+06, Test loss: 4.338e+06, MSE(e): 3.108e-01, MSE(pi1): 4.472e-01, MSE(pi2): 1.816e-01, MSE(pi3): 1.471e-01\n",
      "Epoch 93900, Train loss: 3.126e+06, Test loss: 4.337e+06, MSE(e): 3.107e-01, MSE(pi1): 4.471e-01, MSE(pi2): 1.816e-01, MSE(pi3): 1.471e-01\n",
      "Epoch 94000, Train loss: 3.125e+06, Test loss: 4.336e+06, MSE(e): 3.106e-01, MSE(pi1): 4.471e-01, MSE(pi2): 1.815e-01, MSE(pi3): 1.471e-01\n",
      "Epoch 94100, Train loss: 3.124e+06, Test loss: 4.335e+06, MSE(e): 3.105e-01, MSE(pi1): 4.470e-01, MSE(pi2): 1.815e-01, MSE(pi3): 1.470e-01\n",
      "Epoch 94200, Train loss: 3.123e+06, Test loss: 4.334e+06, MSE(e): 3.104e-01, MSE(pi1): 4.469e-01, MSE(pi2): 1.814e-01, MSE(pi3): 1.470e-01\n",
      "Epoch 94300, Train loss: 3.122e+06, Test loss: 4.333e+06, MSE(e): 3.103e-01, MSE(pi1): 4.469e-01, MSE(pi2): 1.813e-01, MSE(pi3): 1.470e-01\n",
      "Epoch 94400, Train loss: 3.121e+06, Test loss: 4.332e+06, MSE(e): 3.102e-01, MSE(pi1): 4.468e-01, MSE(pi2): 1.813e-01, MSE(pi3): 1.470e-01\n",
      "Epoch 94500, Train loss: 3.120e+06, Test loss: 4.331e+06, MSE(e): 3.101e-01, MSE(pi1): 4.467e-01, MSE(pi2): 1.812e-01, MSE(pi3): 1.469e-01\n",
      "Epoch 94600, Train loss: 3.119e+06, Test loss: 4.330e+06, MSE(e): 3.100e-01, MSE(pi1): 4.467e-01, MSE(pi2): 1.812e-01, MSE(pi3): 1.469e-01\n",
      "Epoch 94700, Train loss: 3.118e+06, Test loss: 4.329e+06, MSE(e): 3.099e-01, MSE(pi1): 4.466e-01, MSE(pi2): 1.811e-01, MSE(pi3): 1.469e-01\n",
      "Epoch 94800, Train loss: 3.117e+06, Test loss: 4.328e+06, MSE(e): 3.098e-01, MSE(pi1): 4.466e-01, MSE(pi2): 1.811e-01, MSE(pi3): 1.469e-01\n",
      "Epoch 94900, Train loss: 3.116e+06, Test loss: 4.327e+06, MSE(e): 3.097e-01, MSE(pi1): 4.465e-01, MSE(pi2): 1.810e-01, MSE(pi3): 1.468e-01\n",
      "Epoch 95000, Train loss: 3.115e+06, Test loss: 4.325e+06, MSE(e): 3.096e-01, MSE(pi1): 4.464e-01, MSE(pi2): 1.810e-01, MSE(pi3): 1.468e-01\n",
      "Epoch 95100, Train loss: 3.114e+06, Test loss: 4.324e+06, MSE(e): 3.095e-01, MSE(pi1): 4.464e-01, MSE(pi2): 1.809e-01, MSE(pi3): 1.468e-01\n",
      "Epoch 95200, Train loss: 3.113e+06, Test loss: 4.323e+06, MSE(e): 3.094e-01, MSE(pi1): 4.463e-01, MSE(pi2): 1.809e-01, MSE(pi3): 1.467e-01\n",
      "Epoch 95300, Train loss: 3.112e+06, Test loss: 4.322e+06, MSE(e): 3.093e-01, MSE(pi1): 4.463e-01, MSE(pi2): 1.808e-01, MSE(pi3): 1.467e-01\n",
      "Epoch 95400, Train loss: 3.111e+06, Test loss: 4.321e+06, MSE(e): 3.092e-01, MSE(pi1): 4.462e-01, MSE(pi2): 1.808e-01, MSE(pi3): 1.467e-01\n",
      "Epoch 95500, Train loss: 3.110e+06, Test loss: 4.320e+06, MSE(e): 3.091e-01, MSE(pi1): 4.461e-01, MSE(pi2): 1.807e-01, MSE(pi3): 1.467e-01\n",
      "Epoch 95600, Train loss: 3.109e+06, Test loss: 4.319e+06, MSE(e): 3.090e-01, MSE(pi1): 4.461e-01, MSE(pi2): 1.807e-01, MSE(pi3): 1.466e-01\n",
      "Epoch 95700, Train loss: 3.108e+06, Test loss: 4.318e+06, MSE(e): 3.089e-01, MSE(pi1): 4.460e-01, MSE(pi2): 1.806e-01, MSE(pi3): 1.466e-01\n",
      "Epoch 95800, Train loss: 3.108e+06, Test loss: 4.317e+06, MSE(e): 3.088e-01, MSE(pi1): 4.459e-01, MSE(pi2): 1.806e-01, MSE(pi3): 1.466e-01\n",
      "Epoch 95900, Train loss: 3.107e+06, Test loss: 4.316e+06, MSE(e): 3.087e-01, MSE(pi1): 4.459e-01, MSE(pi2): 1.805e-01, MSE(pi3): 1.466e-01\n",
      "Epoch 96000, Train loss: 3.106e+06, Test loss: 4.315e+06, MSE(e): 3.086e-01, MSE(pi1): 4.458e-01, MSE(pi2): 1.805e-01, MSE(pi3): 1.465e-01\n",
      "Epoch 96100, Train loss: 3.105e+06, Test loss: 4.314e+06, MSE(e): 3.085e-01, MSE(pi1): 4.458e-01, MSE(pi2): 1.804e-01, MSE(pi3): 1.465e-01\n",
      "Epoch 96200, Train loss: 3.104e+06, Test loss: 4.313e+06, MSE(e): 3.084e-01, MSE(pi1): 4.457e-01, MSE(pi2): 1.804e-01, MSE(pi3): 1.465e-01\n",
      "Epoch 96300, Train loss: 3.103e+06, Test loss: 4.313e+06, MSE(e): 3.083e-01, MSE(pi1): 4.457e-01, MSE(pi2): 1.803e-01, MSE(pi3): 1.465e-01\n",
      "Epoch 96400, Train loss: 3.102e+06, Test loss: 4.312e+06, MSE(e): 3.082e-01, MSE(pi1): 4.456e-01, MSE(pi2): 1.803e-01, MSE(pi3): 1.464e-01\n",
      "Epoch 96500, Train loss: 3.101e+06, Test loss: 4.311e+06, MSE(e): 3.081e-01, MSE(pi1): 4.455e-01, MSE(pi2): 1.802e-01, MSE(pi3): 1.464e-01\n",
      "Epoch 96600, Train loss: 3.100e+06, Test loss: 4.310e+06, MSE(e): 3.080e-01, MSE(pi1): 4.455e-01, MSE(pi2): 1.802e-01, MSE(pi3): 1.464e-01\n",
      "Epoch 96700, Train loss: 3.099e+06, Test loss: 4.309e+06, MSE(e): 3.079e-01, MSE(pi1): 4.454e-01, MSE(pi2): 1.801e-01, MSE(pi3): 1.464e-01\n",
      "Epoch 96800, Train loss: 3.098e+06, Test loss: 4.308e+06, MSE(e): 3.079e-01, MSE(pi1): 4.454e-01, MSE(pi2): 1.801e-01, MSE(pi3): 1.463e-01\n",
      "Epoch 96900, Train loss: 3.097e+06, Test loss: 4.307e+06, MSE(e): 3.078e-01, MSE(pi1): 4.453e-01, MSE(pi2): 1.800e-01, MSE(pi3): 1.463e-01\n",
      "Epoch 97000, Train loss: 3.096e+06, Test loss: 4.306e+06, MSE(e): 3.077e-01, MSE(pi1): 4.452e-01, MSE(pi2): 1.800e-01, MSE(pi3): 1.463e-01\n",
      "Epoch 97100, Train loss: 3.095e+06, Test loss: 4.305e+06, MSE(e): 3.076e-01, MSE(pi1): 4.452e-01, MSE(pi2): 1.799e-01, MSE(pi3): 1.463e-01\n",
      "Epoch 97200, Train loss: 3.094e+06, Test loss: 4.304e+06, MSE(e): 3.075e-01, MSE(pi1): 4.451e-01, MSE(pi2): 1.799e-01, MSE(pi3): 1.462e-01\n",
      "Epoch 97300, Train loss: 3.093e+06, Test loss: 4.303e+06, MSE(e): 3.074e-01, MSE(pi1): 4.451e-01, MSE(pi2): 1.798e-01, MSE(pi3): 1.462e-01\n",
      "Epoch 97400, Train loss: 3.092e+06, Test loss: 4.302e+06, MSE(e): 3.073e-01, MSE(pi1): 4.450e-01, MSE(pi2): 1.798e-01, MSE(pi3): 1.462e-01\n",
      "Epoch 97500, Train loss: 3.091e+06, Test loss: 4.301e+06, MSE(e): 3.072e-01, MSE(pi1): 4.449e-01, MSE(pi2): 1.797e-01, MSE(pi3): 1.462e-01\n",
      "Epoch 97600, Train loss: 3.090e+06, Test loss: 4.300e+06, MSE(e): 3.071e-01, MSE(pi1): 4.449e-01, MSE(pi2): 1.797e-01, MSE(pi3): 1.461e-01\n",
      "Epoch 97700, Train loss: 3.089e+06, Test loss: 4.299e+06, MSE(e): 3.070e-01, MSE(pi1): 4.448e-01, MSE(pi2): 1.796e-01, MSE(pi3): 1.461e-01\n",
      "Epoch 97800, Train loss: 3.088e+06, Test loss: 4.298e+06, MSE(e): 3.069e-01, MSE(pi1): 4.448e-01, MSE(pi2): 1.796e-01, MSE(pi3): 1.461e-01\n",
      "Epoch 97900, Train loss: 3.087e+06, Test loss: 4.297e+06, MSE(e): 3.068e-01, MSE(pi1): 4.447e-01, MSE(pi2): 1.795e-01, MSE(pi3): 1.461e-01\n",
      "Epoch 98000, Train loss: 3.086e+06, Test loss: 4.296e+06, MSE(e): 3.067e-01, MSE(pi1): 4.446e-01, MSE(pi2): 1.795e-01, MSE(pi3): 1.461e-01\n",
      "Epoch 98100, Train loss: 3.085e+06, Test loss: 4.296e+06, MSE(e): 3.066e-01, MSE(pi1): 4.446e-01, MSE(pi2): 1.794e-01, MSE(pi3): 1.460e-01\n",
      "Epoch 98200, Train loss: 3.084e+06, Test loss: 4.295e+06, MSE(e): 3.065e-01, MSE(pi1): 4.445e-01, MSE(pi2): 1.794e-01, MSE(pi3): 1.460e-01\n",
      "Epoch 98300, Train loss: 3.083e+06, Test loss: 4.294e+06, MSE(e): 3.064e-01, MSE(pi1): 4.445e-01, MSE(pi2): 1.793e-01, MSE(pi3): 1.460e-01\n",
      "Epoch 98400, Train loss: 3.083e+06, Test loss: 4.293e+06, MSE(e): 3.063e-01, MSE(pi1): 4.444e-01, MSE(pi2): 1.793e-01, MSE(pi3): 1.460e-01\n",
      "Epoch 98500, Train loss: 3.082e+06, Test loss: 4.292e+06, MSE(e): 3.062e-01, MSE(pi1): 4.443e-01, MSE(pi2): 1.792e-01, MSE(pi3): 1.459e-01\n",
      "Epoch 98600, Train loss: 3.081e+06, Test loss: 4.291e+06, MSE(e): 3.061e-01, MSE(pi1): 4.443e-01, MSE(pi2): 1.792e-01, MSE(pi3): 1.459e-01\n",
      "Epoch 98700, Train loss: 3.080e+06, Test loss: 4.290e+06, MSE(e): 3.060e-01, MSE(pi1): 4.442e-01, MSE(pi2): 1.792e-01, MSE(pi3): 1.459e-01\n",
      "Epoch 98800, Train loss: 3.079e+06, Test loss: 4.289e+06, MSE(e): 3.060e-01, MSE(pi1): 4.442e-01, MSE(pi2): 1.791e-01, MSE(pi3): 1.459e-01\n",
      "Epoch 98900, Train loss: 3.078e+06, Test loss: 4.289e+06, MSE(e): 3.059e-01, MSE(pi1): 4.441e-01, MSE(pi2): 1.791e-01, MSE(pi3): 1.458e-01\n",
      "Epoch 99000, Train loss: 3.077e+06, Test loss: 4.288e+06, MSE(e): 3.058e-01, MSE(pi1): 4.440e-01, MSE(pi2): 1.790e-01, MSE(pi3): 1.458e-01\n",
      "Epoch 99100, Train loss: 3.076e+06, Test loss: 4.287e+06, MSE(e): 3.057e-01, MSE(pi1): 4.440e-01, MSE(pi2): 1.790e-01, MSE(pi3): 1.458e-01\n",
      "Epoch 99200, Train loss: 3.075e+06, Test loss: 4.286e+06, MSE(e): 3.056e-01, MSE(pi1): 4.439e-01, MSE(pi2): 1.789e-01, MSE(pi3): 1.458e-01\n",
      "Epoch 99300, Train loss: 3.074e+06, Test loss: 4.285e+06, MSE(e): 3.055e-01, MSE(pi1): 4.439e-01, MSE(pi2): 1.789e-01, MSE(pi3): 1.457e-01\n",
      "Epoch 99400, Train loss: 3.073e+06, Test loss: 4.284e+06, MSE(e): 3.054e-01, MSE(pi1): 4.438e-01, MSE(pi2): 1.788e-01, MSE(pi3): 1.457e-01\n",
      "Epoch 99500, Train loss: 3.072e+06, Test loss: 4.283e+06, MSE(e): 3.053e-01, MSE(pi1): 4.438e-01, MSE(pi2): 1.788e-01, MSE(pi3): 1.457e-01\n",
      "Epoch 99600, Train loss: 3.071e+06, Test loss: 4.283e+06, MSE(e): 3.052e-01, MSE(pi1): 4.437e-01, MSE(pi2): 1.787e-01, MSE(pi3): 1.457e-01\n",
      "Epoch 99700, Train loss: 3.070e+06, Test loss: 4.282e+06, MSE(e): 3.051e-01, MSE(pi1): 4.436e-01, MSE(pi2): 1.787e-01, MSE(pi3): 1.456e-01\n",
      "Epoch 99800, Train loss: 3.069e+06, Test loss: 4.281e+06, MSE(e): 3.050e-01, MSE(pi1): 4.436e-01, MSE(pi2): 1.786e-01, MSE(pi3): 1.456e-01\n",
      "Epoch 99900, Train loss: 3.069e+06, Test loss: 4.280e+06, MSE(e): 3.049e-01, MSE(pi1): 4.435e-01, MSE(pi2): 1.786e-01, MSE(pi3): 1.456e-01\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "params_to_update = filter(lambda p: p.requires_grad, pretrained_pgnniv.parameters())\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=3e-4)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "train_loop(pretrained_pgnniv, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_epoch = n_epochs-1\n",
    "# n_epochs = 20000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 5\n",
    "\n",
    "# second_lr = 3e-4\n",
    "\n",
    "# train_loop(pretrained_pgnniv, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa57a6eac90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
