{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from utils.checkpoints import load_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/transfer_learning/results/sigmoid_no_training_decoder\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/transfer_learning/results/non_linear/baseline\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/transfer_learning/results/non_linear/baseline\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear/sigmoid_nonlinear.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/sigmoid_no_training_decoder')\n",
    "\n",
    "MODEL_RESULTS_AE_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/non_linear/baseline')\n",
    "MODEL_RESULTS_PGNNIV_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/non_linear/baseline')\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/sigmoid_no_training_decoder')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_AE_PATH)\n",
    "create_folder(MODEL_RESULTS_PGNNIV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear/sigmoid_nonlinear.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 80\n",
      "Validation dataset length: 20\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X_train, y_train, K_train, f_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import BaselineNonlinearModel as PretrainedAutoencoder\n",
    "from model.ae_nonlinear_model import AutoencoderNonlinearModel as PretrainedPGNNNIV\n",
    "from model.transfer_learnign_ae import AutoencoderTransferLearning as TransferLearningAutoencoder\n",
    "from trainers.train import train_autoencoder_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from model.ae_nonlinear_model import AutoencoderNonlinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other parameters\n",
    "n_filters_explanatory = 5\n",
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autoencoder\n",
    "autoencoder_input_shape = y_train.values[0].shape\n",
    "latent_space_dim = [20, 10, n_modes, 10, 20]\n",
    "autoencoder_output_shape = y_train.values[0].shape\n",
    "\n",
    "# pretrained_autoencoder = PretrainedAutoencoder(autoencoder_input_shape, latent_space_dim, autoencoder_output_shape).to(DEVICE)\n",
    "pretrained_autoencoder = PretrainedAutoencoder(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(pretrained_autoencoder.parameters(), lr=1e-4)\n",
    "pretrained_autoencoder, optimizer, lists = load_results(pretrained_autoencoder, optimizer, MODEL_RESULTS_AE_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained PGNNIV\n",
    "pretrained_encoder = pretrained_autoencoder.encoder\n",
    "pretrained_decoder = pretrained_autoencoder.decoder\n",
    "\n",
    "pretrained_pgnniv = AutoencoderNonlinearModel(input_shape, predictive_layers, pretrained_decoder, predictive_output, explanatory_input,\n",
    "                        explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(pretrained_pgnniv.parameters(), lr=1e-4)\n",
    "pretrained_pgnniv, optimizer, lists = load_results(pretrained_pgnniv, optimizer, MODEL_RESULTS_PGNNIV_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6285196de0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1_layer.weight: requires_grad=False\n",
      "hidden1_layer.bias: requires_grad=False\n",
      "hidden2_layer.weight: requires_grad=False\n",
      "hidden2_layer.bias: requires_grad=False\n",
      "latent_space_layer.weight: requires_grad=False\n",
      "latent_space_layer.bias: requires_grad=False\n"
     ]
    }
   ],
   "source": [
    "pgnniv_pretrained_encoder = pretrained_pgnniv.encoder\n",
    "\n",
    "for param in pgnniv_pretrained_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in pgnniv_pretrained_encoder.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 2.271e+12, Test loss: 2.350e+12, MSE(e): 1.099e+02, MSE(pi1): 1.162e+05, MSE(pi2): 4.949e+01, MSE(pi3): 1.052e+02\n",
      "Epoch 100, Train loss: 1.077e+11, Test loss: 1.249e+11, MSE(e): 1.071e+01, MSE(pi1): 4.376e+01, MSE(pi2): 4.794e+00, MSE(pi3): 1.488e+00\n",
      "Epoch 200, Train loss: 9.816e+10, Test loss: 1.078e+11, MSE(e): 9.751e+00, MSE(pi1): 5.065e+01, MSE(pi2): 4.398e+00, MSE(pi3): 1.444e+00\n",
      "Epoch 300, Train loss: 8.428e+10, Test loss: 8.408e+10, MSE(e): 8.289e+00, MSE(pi1): 1.247e+02, MSE(pi2): 3.752e+00, MSE(pi3): 1.363e+00\n",
      "Epoch 400, Train loss: 7.353e+10, Test loss: 6.847e+10, MSE(e): 7.225e+00, MSE(pi1): 1.159e+02, MSE(pi2): 3.291e+00, MSE(pi3): 1.187e+00\n",
      "Epoch 500, Train loss: 6.787e+10, Test loss: 6.420e+10, MSE(e): 6.701e+00, MSE(pi1): 7.487e+01, MSE(pi2): 3.063e+00, MSE(pi3): 1.075e+00\n",
      "Epoch 600, Train loss: 6.475e+10, Test loss: 6.372e+10, MSE(e): 6.413e+00, MSE(pi1): 5.198e+01, MSE(pi2): 2.930e+00, MSE(pi3): 1.038e+00\n",
      "Epoch 700, Train loss: 6.253e+10, Test loss: 6.371e+10, MSE(e): 6.202e+00, MSE(pi1): 4.066e+01, MSE(pi2): 2.829e+00, MSE(pi3): 1.031e+00\n",
      "Epoch 800, Train loss: 6.058e+10, Test loss: 6.434e+10, MSE(e): 6.013e+00, MSE(pi1): 3.499e+01, MSE(pi2): 2.737e+00, MSE(pi3): 1.034e+00\n",
      "Epoch 900, Train loss: 5.838e+10, Test loss: 6.621e+10, MSE(e): 5.794e+00, MSE(pi1): 3.349e+01, MSE(pi2): 2.624e+00, MSE(pi3): 1.047e+00\n",
      "Epoch 1000, Train loss: 5.577e+10, Test loss: 6.969e+10, MSE(e): 5.531e+00, MSE(pi1): 3.444e+01, MSE(pi2): 2.487e+00, MSE(pi3): 1.073e+00\n",
      "Epoch 1100, Train loss: 5.315e+10, Test loss: 7.378e+10, MSE(e): 5.270e+00, MSE(pi1): 3.384e+01, MSE(pi2): 2.356e+00, MSE(pi3): 1.108e+00\n",
      "Epoch 1200, Train loss: 5.081e+10, Test loss: 7.777e+10, MSE(e): 5.039e+00, MSE(pi1): 3.107e+01, MSE(pi2): 2.252e+00, MSE(pi3): 1.144e+00\n",
      "Epoch 1300, Train loss: 4.879e+10, Test loss: 8.100e+10, MSE(e): 4.839e+00, MSE(pi1): 2.771e+01, MSE(pi2): 2.169e+00, MSE(pi3): 1.175e+00\n",
      "Epoch 1400, Train loss: 4.625e+10, Test loss: 8.324e+10, MSE(e): 4.588e+00, MSE(pi1): 2.499e+01, MSE(pi2): 2.062e+00, MSE(pi3): 1.203e+00\n",
      "Epoch 1500, Train loss: 4.255e+10, Test loss: 8.733e+10, MSE(e): 4.219e+00, MSE(pi1): 2.363e+01, MSE(pi2): 1.907e+00, MSE(pi3): 1.228e+00\n",
      "Epoch 1600, Train loss: 3.906e+10, Test loss: 9.093e+10, MSE(e): 3.871e+00, MSE(pi1): 2.276e+01, MSE(pi2): 1.766e+00, MSE(pi3): 1.251e+00\n",
      "Epoch 1700, Train loss: 3.557e+10, Test loss: 9.328e+10, MSE(e): 3.522e+00, MSE(pi1): 2.220e+01, MSE(pi2): 1.626e+00, MSE(pi3): 1.274e+00\n",
      "Epoch 1800, Train loss: 3.215e+10, Test loss: 9.510e+10, MSE(e): 3.180e+00, MSE(pi1): 2.183e+01, MSE(pi2): 1.490e+00, MSE(pi3): 1.301e+00\n",
      "Epoch 1900, Train loss: 2.935e+10, Test loss: 9.610e+10, MSE(e): 2.901e+00, MSE(pi1): 2.124e+01, MSE(pi2): 1.379e+00, MSE(pi3): 1.330e+00\n",
      "Epoch 2000, Train loss: 2.724e+10, Test loss: 9.634e+10, MSE(e): 2.690e+00, MSE(pi1): 2.059e+01, MSE(pi2): 1.291e+00, MSE(pi3): 1.357e+00\n",
      "Epoch 2100, Train loss: 2.562e+10, Test loss: 9.655e+10, MSE(e): 2.528e+00, MSE(pi1): 2.003e+01, MSE(pi2): 1.217e+00, MSE(pi3): 1.379e+00\n",
      "Epoch 2200, Train loss: 2.417e+10, Test loss: 9.602e+10, MSE(e): 2.383e+00, MSE(pi1): 1.964e+01, MSE(pi2): 1.143e+00, MSE(pi3): 1.396e+00\n",
      "Epoch 2300, Train loss: 2.277e+10, Test loss: 9.482e+10, MSE(e): 2.244e+00, MSE(pi1): 1.936e+01, MSE(pi2): 1.068e+00, MSE(pi3): 1.409e+00\n",
      "Epoch 2400, Train loss: 2.145e+10, Test loss: 9.291e+10, MSE(e): 2.111e+00, MSE(pi1): 1.911e+01, MSE(pi2): 9.979e-01, MSE(pi3): 1.417e+00\n",
      "Epoch 2500, Train loss: 2.018e+10, Test loss: 8.919e+10, MSE(e): 1.985e+00, MSE(pi1): 1.889e+01, MSE(pi2): 9.334e-01, MSE(pi3): 1.419e+00\n",
      "Epoch 2600, Train loss: 1.888e+10, Test loss: 8.480e+10, MSE(e): 1.855e+00, MSE(pi1): 1.872e+01, MSE(pi2): 8.719e-01, MSE(pi3): 1.417e+00\n",
      "Epoch 2700, Train loss: 1.771e+10, Test loss: 8.487e+10, MSE(e): 1.738e+00, MSE(pi1): 1.862e+01, MSE(pi2): 8.197e-01, MSE(pi3): 1.411e+00\n",
      "Epoch 2800, Train loss: 1.677e+10, Test loss: 8.675e+10, MSE(e): 1.644e+00, MSE(pi1): 1.853e+01, MSE(pi2): 7.787e-01, MSE(pi3): 1.403e+00\n",
      "Epoch 2900, Train loss: 1.599e+10, Test loss: 8.878e+10, MSE(e): 1.566e+00, MSE(pi1): 1.846e+01, MSE(pi2): 7.450e-01, MSE(pi3): 1.391e+00\n",
      "Epoch 3000, Train loss: 1.530e+10, Test loss: 9.060e+10, MSE(e): 1.498e+00, MSE(pi1): 1.840e+01, MSE(pi2): 7.153e-01, MSE(pi3): 1.377e+00\n",
      "Epoch 3100, Train loss: 1.465e+10, Test loss: 9.213e+10, MSE(e): 1.433e+00, MSE(pi1): 1.835e+01, MSE(pi2): 6.868e-01, MSE(pi3): 1.360e+00\n",
      "Epoch 3200, Train loss: 1.402e+10, Test loss: 9.336e+10, MSE(e): 1.370e+00, MSE(pi1): 1.831e+01, MSE(pi2): 6.579e-01, MSE(pi3): 1.341e+00\n",
      "Epoch 3300, Train loss: 1.340e+10, Test loss: 9.429e+10, MSE(e): 1.308e+00, MSE(pi1): 1.829e+01, MSE(pi2): 6.281e-01, MSE(pi3): 1.322e+00\n",
      "Epoch 3400, Train loss: 1.280e+10, Test loss: 9.492e+10, MSE(e): 1.249e+00, MSE(pi1): 1.827e+01, MSE(pi2): 5.991e-01, MSE(pi3): 1.301e+00\n",
      "Epoch 3500, Train loss: 1.225e+10, Test loss: 9.524e+10, MSE(e): 1.194e+00, MSE(pi1): 1.828e+01, MSE(pi2): 5.725e-01, MSE(pi3): 1.282e+00\n",
      "Epoch 3600, Train loss: 1.175e+10, Test loss: 9.534e+10, MSE(e): 1.144e+00, MSE(pi1): 1.831e+01, MSE(pi2): 5.486e-01, MSE(pi3): 1.264e+00\n",
      "Epoch 3700, Train loss: 1.131e+10, Test loss: 9.578e+10, MSE(e): 1.100e+00, MSE(pi1): 1.834e+01, MSE(pi2): 5.271e-01, MSE(pi3): 1.248e+00\n",
      "Epoch 3800, Train loss: 1.089e+10, Test loss: 9.595e+10, MSE(e): 1.059e+00, MSE(pi1): 1.834e+01, MSE(pi2): 5.081e-01, MSE(pi3): 1.232e+00\n",
      "Epoch 3900, Train loss: 1.049e+10, Test loss: 9.664e+10, MSE(e): 1.019e+00, MSE(pi1): 1.834e+01, MSE(pi2): 4.900e-01, MSE(pi3): 1.217e+00\n",
      "Epoch 4000, Train loss: 1.011e+10, Test loss: 9.753e+10, MSE(e): 9.804e-01, MSE(pi1): 1.831e+01, MSE(pi2): 4.730e-01, MSE(pi3): 1.202e+00\n",
      "Epoch 4100, Train loss: 9.715e+09, Test loss: 9.858e+10, MSE(e): 9.413e-01, MSE(pi1): 1.831e+01, MSE(pi2): 4.551e-01, MSE(pi3): 1.189e+00\n",
      "Epoch 4200, Train loss: 9.310e+09, Test loss: 9.940e+10, MSE(e): 9.009e-01, MSE(pi1): 1.832e+01, MSE(pi2): 4.371e-01, MSE(pi3): 1.177e+00\n",
      "Epoch 4300, Train loss: 8.877e+09, Test loss: 9.974e+10, MSE(e): 8.578e-01, MSE(pi1): 1.830e+01, MSE(pi2): 4.183e-01, MSE(pi3): 1.166e+00\n",
      "Epoch 4400, Train loss: 8.439e+09, Test loss: 1.007e+11, MSE(e): 8.140e-01, MSE(pi1): 1.828e+01, MSE(pi2): 3.986e-01, MSE(pi3): 1.157e+00\n",
      "Epoch 4500, Train loss: 8.034e+09, Test loss: 1.021e+11, MSE(e): 7.737e-01, MSE(pi1): 1.822e+01, MSE(pi2): 3.808e-01, MSE(pi3): 1.147e+00\n",
      "Epoch 4600, Train loss: 7.667e+09, Test loss: 1.040e+11, MSE(e): 7.372e-01, MSE(pi1): 1.815e+01, MSE(pi2): 3.645e-01, MSE(pi3): 1.138e+00\n",
      "Epoch 4700, Train loss: 7.329e+09, Test loss: 1.061e+11, MSE(e): 7.035e-01, MSE(pi1): 1.805e+01, MSE(pi2): 3.495e-01, MSE(pi3): 1.128e+00\n",
      "Epoch 4800, Train loss: 7.012e+09, Test loss: 1.085e+11, MSE(e): 6.721e-01, MSE(pi1): 1.793e+01, MSE(pi2): 3.355e-01, MSE(pi3): 1.116e+00\n",
      "Epoch 4900, Train loss: 6.720e+09, Test loss: 1.113e+11, MSE(e): 6.432e-01, MSE(pi1): 1.777e+01, MSE(pi2): 3.224e-01, MSE(pi3): 1.102e+00\n",
      "Epoch 5000, Train loss: 6.451e+09, Test loss: 1.139e+11, MSE(e): 6.166e-01, MSE(pi1): 1.759e+01, MSE(pi2): 3.104e-01, MSE(pi3): 1.086e+00\n",
      "Epoch 5100, Train loss: 6.212e+09, Test loss: 1.160e+11, MSE(e): 5.931e-01, MSE(pi1): 1.742e+01, MSE(pi2): 2.997e-01, MSE(pi3): 1.069e+00\n",
      "Epoch 5200, Train loss: 5.989e+09, Test loss: 1.177e+11, MSE(e): 5.712e-01, MSE(pi1): 1.725e+01, MSE(pi2): 2.895e-01, MSE(pi3): 1.051e+00\n",
      "Epoch 5300, Train loss: 5.783e+09, Test loss: 1.191e+11, MSE(e): 5.509e-01, MSE(pi1): 1.709e+01, MSE(pi2): 2.798e-01, MSE(pi3): 1.033e+00\n",
      "Epoch 5400, Train loss: 5.590e+09, Test loss: 1.202e+11, MSE(e): 5.319e-01, MSE(pi1): 1.694e+01, MSE(pi2): 2.706e-01, MSE(pi3): 1.016e+00\n",
      "Epoch 5500, Train loss: 5.407e+09, Test loss: 1.210e+11, MSE(e): 5.139e-01, MSE(pi1): 1.679e+01, MSE(pi2): 2.618e-01, MSE(pi3): 1.000e+00\n",
      "Epoch 5600, Train loss: 5.235e+09, Test loss: 1.218e+11, MSE(e): 4.970e-01, MSE(pi1): 1.665e+01, MSE(pi2): 2.532e-01, MSE(pi3): 9.857e-01\n",
      "Epoch 5700, Train loss: 5.074e+09, Test loss: 1.227e+11, MSE(e): 4.812e-01, MSE(pi1): 1.647e+01, MSE(pi2): 2.458e-01, MSE(pi3): 9.717e-01\n",
      "Epoch 5800, Train loss: 4.912e+09, Test loss: 1.242e+11, MSE(e): 4.653e-01, MSE(pi1): 1.632e+01, MSE(pi2): 2.370e-01, MSE(pi3): 9.607e-01\n",
      "Epoch 5900, Train loss: 4.755e+09, Test loss: 1.260e+11, MSE(e): 4.499e-01, MSE(pi1): 1.615e+01, MSE(pi2): 2.291e-01, MSE(pi3): 9.497e-01\n",
      "Epoch 6000, Train loss: 4.606e+09, Test loss: 1.275e+11, MSE(e): 4.352e-01, MSE(pi1): 1.596e+01, MSE(pi2): 2.216e-01, MSE(pi3): 9.397e-01\n",
      "Epoch 6100, Train loss: 4.463e+09, Test loss: 1.286e+11, MSE(e): 4.212e-01, MSE(pi1): 1.577e+01, MSE(pi2): 2.143e-01, MSE(pi3): 9.309e-01\n",
      "Epoch 6200, Train loss: 4.322e+09, Test loss: 1.295e+11, MSE(e): 4.074e-01, MSE(pi1): 1.558e+01, MSE(pi2): 2.072e-01, MSE(pi3): 9.230e-01\n",
      "Epoch 6300, Train loss: 4.190e+09, Test loss: 1.302e+11, MSE(e): 3.944e-01, MSE(pi1): 1.539e+01, MSE(pi2): 2.006e-01, MSE(pi3): 9.161e-01\n",
      "Epoch 6400, Train loss: 4.067e+09, Test loss: 1.308e+11, MSE(e): 3.823e-01, MSE(pi1): 1.522e+01, MSE(pi2): 1.942e-01, MSE(pi3): 9.103e-01\n",
      "Epoch 6500, Train loss: 3.949e+09, Test loss: 1.315e+11, MSE(e): 3.708e-01, MSE(pi1): 1.507e+01, MSE(pi2): 1.878e-01, MSE(pi3): 9.057e-01\n",
      "Epoch 6600, Train loss: 3.843e+09, Test loss: 1.319e+11, MSE(e): 3.604e-01, MSE(pi1): 1.488e+01, MSE(pi2): 1.827e-01, MSE(pi3): 9.002e-01\n",
      "Epoch 6700, Train loss: 3.745e+09, Test loss: 1.325e+11, MSE(e): 3.508e-01, MSE(pi1): 1.472e+01, MSE(pi2): 1.775e-01, MSE(pi3): 8.955e-01\n",
      "Epoch 6800, Train loss: 3.655e+09, Test loss: 1.332e+11, MSE(e): 3.420e-01, MSE(pi1): 1.455e+01, MSE(pi2): 1.727e-01, MSE(pi3): 8.907e-01\n",
      "Epoch 6900, Train loss: 3.574e+09, Test loss: 1.339e+11, MSE(e): 3.342e-01, MSE(pi1): 1.436e+01, MSE(pi2): 1.686e-01, MSE(pi3): 8.846e-01\n",
      "Epoch 7000, Train loss: 3.511e+09, Test loss: 1.348e+11, MSE(e): 3.280e-01, MSE(pi1): 1.428e+01, MSE(pi2): 1.638e-01, MSE(pi3): 8.805e-01\n",
      "Epoch 7100, Train loss: 3.429e+09, Test loss: 1.355e+11, MSE(e): 3.203e-01, MSE(pi1): 1.389e+01, MSE(pi2): 1.611e-01, MSE(pi3): 8.678e-01\n",
      "Epoch 7200, Train loss: 3.363e+09, Test loss: 1.365e+11, MSE(e): 3.142e-01, MSE(pi1): 1.357e+01, MSE(pi2): 1.577e-01, MSE(pi3): 8.544e-01\n",
      "Epoch 7300, Train loss: 3.302e+09, Test loss: 1.374e+11, MSE(e): 3.086e-01, MSE(pi1): 1.315e+01, MSE(pi2): 1.548e-01, MSE(pi3): 8.354e-01\n",
      "Epoch 7400, Train loss: 3.241e+09, Test loss: 1.384e+11, MSE(e): 3.034e-01, MSE(pi1): 1.260e+01, MSE(pi2): 1.519e-01, MSE(pi3): 8.105e-01\n",
      "Epoch 7500, Train loss: 3.181e+09, Test loss: 1.395e+11, MSE(e): 2.984e-01, MSE(pi1): 1.194e+01, MSE(pi2): 1.490e-01, MSE(pi3): 7.807e-01\n",
      "Epoch 7600, Train loss: 3.122e+09, Test loss: 1.406e+11, MSE(e): 2.935e-01, MSE(pi1): 1.115e+01, MSE(pi2): 1.465e-01, MSE(pi3): 7.464e-01\n",
      "Epoch 7700, Train loss: 3.063e+09, Test loss: 1.416e+11, MSE(e): 2.888e-01, MSE(pi1): 1.034e+01, MSE(pi2): 1.438e-01, MSE(pi3): 7.095e-01\n",
      "Epoch 7800, Train loss: 3.004e+09, Test loss: 1.426e+11, MSE(e): 2.842e-01, MSE(pi1): 9.495e+00, MSE(pi2): 1.413e-01, MSE(pi3): 6.703e-01\n",
      "Epoch 7900, Train loss: 2.949e+09, Test loss: 1.435e+11, MSE(e): 2.800e-01, MSE(pi1): 8.646e+00, MSE(pi2): 1.395e-01, MSE(pi3): 6.258e-01\n",
      "Epoch 8000, Train loss: 2.892e+09, Test loss: 1.444e+11, MSE(e): 2.757e-01, MSE(pi1): 7.826e+00, MSE(pi2): 1.371e-01, MSE(pi3): 5.753e-01\n",
      "Epoch 8100, Train loss: 2.837e+09, Test loss: 1.453e+11, MSE(e): 2.713e-01, MSE(pi1): 7.114e+00, MSE(pi2): 1.340e-01, MSE(pi3): 5.308e-01\n",
      "Epoch 8200, Train loss: 2.801e+09, Test loss: 1.463e+11, MSE(e): 2.685e-01, MSE(pi1): 6.709e+00, MSE(pi2): 1.314e-01, MSE(pi3): 4.944e-01\n",
      "Epoch 8300, Train loss: 2.737e+09, Test loss: 1.467e+11, MSE(e): 2.636e-01, MSE(pi1): 5.728e+00, MSE(pi2): 1.298e-01, MSE(pi3): 4.337e-01\n",
      "Epoch 8400, Train loss: 2.690e+09, Test loss: 1.473e+11, MSE(e): 2.600e-01, MSE(pi1): 5.113e+00, MSE(pi2): 1.277e-01, MSE(pi3): 3.850e-01\n",
      "Epoch 8500, Train loss: 2.643e+09, Test loss: 1.478e+11, MSE(e): 2.566e-01, MSE(pi1): 4.447e+00, MSE(pi2): 1.257e-01, MSE(pi3): 3.305e-01\n",
      "Epoch 8600, Train loss: 2.594e+09, Test loss: 1.482e+11, MSE(e): 2.532e-01, MSE(pi1): 3.578e+00, MSE(pi2): 1.239e-01, MSE(pi3): 2.616e-01\n",
      "Epoch 8700, Train loss: 2.571e+09, Test loss: 1.489e+11, MSE(e): 2.515e-01, MSE(pi1): 3.401e+00, MSE(pi2): 1.218e-01, MSE(pi3): 2.179e-01\n",
      "Epoch 8800, Train loss: 2.505e+09, Test loss: 1.490e+11, MSE(e): 2.465e-01, MSE(pi1): 2.312e+00, MSE(pi2): 1.197e-01, MSE(pi3): 1.685e-01\n",
      "Epoch 8900, Train loss: 2.465e+09, Test loss: 1.493e+11, MSE(e): 2.433e-01, MSE(pi1): 1.838e+00, MSE(pi2): 1.178e-01, MSE(pi3): 1.347e-01\n",
      "Epoch 9000, Train loss: 2.428e+09, Test loss: 1.496e+11, MSE(e): 2.401e-01, MSE(pi1): 1.613e+00, MSE(pi2): 1.159e-01, MSE(pi3): 1.096e-01\n",
      "Epoch 9100, Train loss: 2.419e+09, Test loss: 1.501e+11, MSE(e): 2.388e-01, MSE(pi1): 2.001e+00, MSE(pi2): 1.147e-01, MSE(pi3): 1.045e-01\n",
      "Epoch 9200, Train loss: 2.357e+09, Test loss: 1.499e+11, MSE(e): 2.338e-01, MSE(pi1): 1.101e+00, MSE(pi2): 1.123e-01, MSE(pi3): 7.573e-02\n",
      "Epoch 9300, Train loss: 2.326e+09, Test loss: 1.501e+11, MSE(e): 2.308e-01, MSE(pi1): 1.179e+00, MSE(pi2): 1.105e-01, MSE(pi3): 6.806e-02\n",
      "Epoch 9400, Train loss: 2.295e+09, Test loss: 1.502e+11, MSE(e): 2.279e-01, MSE(pi1): 1.033e+00, MSE(pi2): 1.089e-01, MSE(pi3): 5.923e-02\n",
      "Epoch 9500, Train loss: 2.264e+09, Test loss: 1.503e+11, MSE(e): 2.249e-01, MSE(pi1): 8.767e-01, MSE(pi2): 1.073e-01, MSE(pi3): 5.460e-02\n",
      "Epoch 9600, Train loss: 2.235e+09, Test loss: 1.505e+11, MSE(e): 2.221e-01, MSE(pi1): 9.316e-01, MSE(pi2): 1.057e-01, MSE(pi3): 5.014e-02\n",
      "Epoch 9700, Train loss: 2.205e+09, Test loss: 1.508e+11, MSE(e): 2.192e-01, MSE(pi1): 7.906e-01, MSE(pi2): 1.040e-01, MSE(pi3): 4.901e-02\n",
      "Epoch 9800, Train loss: 2.177e+09, Test loss: 1.511e+11, MSE(e): 2.165e-01, MSE(pi1): 7.328e-01, MSE(pi2): 1.025e-01, MSE(pi3): 4.832e-02\n",
      "Epoch 9900, Train loss: 2.150e+09, Test loss: 1.513e+11, MSE(e): 2.138e-01, MSE(pi1): 7.051e-01, MSE(pi2): 1.011e-01, MSE(pi3): 4.620e-02\n",
      "Epoch 10000, Train loss: 2.124e+09, Test loss: 1.515e+11, MSE(e): 2.112e-01, MSE(pi1): 6.845e-01, MSE(pi2): 9.970e-02, MSE(pi3): 4.438e-02\n",
      "Epoch 10100, Train loss: 2.099e+09, Test loss: 1.516e+11, MSE(e): 2.087e-01, MSE(pi1): 8.098e-01, MSE(pi2): 9.836e-02, MSE(pi3): 4.022e-02\n",
      "Epoch 10200, Train loss: 2.077e+09, Test loss: 1.519e+11, MSE(e): 2.063e-01, MSE(pi1): 1.027e+00, MSE(pi2): 9.704e-02, MSE(pi3): 4.474e-02\n",
      "Epoch 10300, Train loss: 2.060e+09, Test loss: 1.523e+11, MSE(e): 2.046e-01, MSE(pi1): 9.057e-01, MSE(pi2): 9.613e-02, MSE(pi3): 4.717e-02\n",
      "Epoch 10400, Train loss: 2.034e+09, Test loss: 1.522e+11, MSE(e): 2.014e-01, MSE(pi1): 1.543e+00, MSE(pi2): 9.446e-02, MSE(pi3): 4.910e-02\n",
      "Epoch 10500, Train loss: 1.998e+09, Test loss: 1.520e+11, MSE(e): 1.988e-01, MSE(pi1): 5.943e-01, MSE(pi2): 9.317e-02, MSE(pi3): 3.856e-02\n",
      "Epoch 10600, Train loss: 1.977e+09, Test loss: 1.520e+11, MSE(e): 1.966e-01, MSE(pi1): 7.256e-01, MSE(pi2): 9.200e-02, MSE(pi3): 3.808e-02\n",
      "Epoch 10700, Train loss: 1.956e+09, Test loss: 1.521e+11, MSE(e): 1.940e-01, MSE(pi1): 1.140e+00, MSE(pi2): 9.067e-02, MSE(pi3): 3.849e-02\n",
      "Epoch 10800, Train loss: 1.928e+09, Test loss: 1.519e+11, MSE(e): 1.917e-01, MSE(pi1): 7.758e-01, MSE(pi2): 8.952e-02, MSE(pi3): 3.854e-02\n",
      "Epoch 10900, Train loss: 1.909e+09, Test loss: 1.523e+11, MSE(e): 1.896e-01, MSE(pi1): 8.924e-01, MSE(pi2): 8.844e-02, MSE(pi3): 4.100e-02\n",
      "Epoch 11000, Train loss: 1.876e+09, Test loss: 1.517e+11, MSE(e): 1.865e-01, MSE(pi1): 6.349e-01, MSE(pi2): 8.697e-02, MSE(pi3): 4.034e-02\n",
      "Epoch 11100, Train loss: 1.852e+09, Test loss: 1.516e+11, MSE(e): 1.839e-01, MSE(pi1): 8.354e-01, MSE(pi2): 8.561e-02, MSE(pi3): 4.408e-02\n",
      "Epoch 11200, Train loss: 1.834e+09, Test loss: 1.515e+11, MSE(e): 1.820e-01, MSE(pi1): 9.735e-01, MSE(pi2): 8.475e-02, MSE(pi3): 4.377e-02\n",
      "Epoch 11300, Train loss: 1.794e+09, Test loss: 1.506e+11, MSE(e): 1.785e-01, MSE(pi1): 5.789e-01, MSE(pi2): 8.296e-02, MSE(pi3): 3.263e-02\n",
      "Epoch 11400, Train loss: 1.768e+09, Test loss: 1.502e+11, MSE(e): 1.759e-01, MSE(pi1): 5.599e-01, MSE(pi2): 8.172e-02, MSE(pi3): 3.541e-02\n",
      "Epoch 11500, Train loss: 1.739e+09, Test loss: 1.494e+11, MSE(e): 1.729e-01, MSE(pi1): 6.104e-01, MSE(pi2): 8.027e-02, MSE(pi3): 3.741e-02\n",
      "Epoch 11600, Train loss: 1.729e+09, Test loss: 1.492e+11, MSE(e): 1.717e-01, MSE(pi1): 8.219e-01, MSE(pi2): 7.984e-02, MSE(pi3): 4.054e-02\n",
      "Epoch 11700, Train loss: 1.682e+09, Test loss: 1.474e+11, MSE(e): 1.672e-01, MSE(pi1): 6.890e-01, MSE(pi2): 7.764e-02, MSE(pi3): 2.943e-02\n",
      "Epoch 11800, Train loss: 1.645e+09, Test loss: 1.467e+11, MSE(e): 1.637e-01, MSE(pi1): 4.939e-01, MSE(pi2): 7.595e-02, MSE(pi3): 3.004e-02\n",
      "Epoch 11900, Train loss: 1.615e+09, Test loss: 1.455e+11, MSE(e): 1.607e-01, MSE(pi1): 4.838e-01, MSE(pi2): 7.459e-02, MSE(pi3): 2.979e-02\n",
      "Epoch 12000, Train loss: 1.604e+09, Test loss: 1.439e+11, MSE(e): 1.595e-01, MSE(pi1): 6.759e-01, MSE(pi2): 7.420e-02, MSE(pi3): 2.760e-02\n",
      "Epoch 12100, Train loss: 1.547e+09, Test loss: 1.436e+11, MSE(e): 1.540e-01, MSE(pi1): 4.441e-01, MSE(pi2): 7.145e-02, MSE(pi3): 2.788e-02\n",
      "Epoch 12200, Train loss: 1.524e+09, Test loss: 1.430e+11, MSE(e): 1.515e-01, MSE(pi1): 5.484e-01, MSE(pi2): 7.040e-02, MSE(pi3): 3.284e-02\n",
      "Epoch 12300, Train loss: 1.484e+09, Test loss: 1.418e+11, MSE(e): 1.475e-01, MSE(pi1): 5.674e-01, MSE(pi2): 6.854e-02, MSE(pi3): 2.648e-02\n",
      "Epoch 12400, Train loss: 1.447e+09, Test loss: 1.404e+11, MSE(e): 1.441e-01, MSE(pi1): 4.040e-01, MSE(pi2): 6.704e-02, MSE(pi3): 2.638e-02\n",
      "Epoch 12500, Train loss: 1.419e+09, Test loss: 1.392e+11, MSE(e): 1.409e-01, MSE(pi1): 7.630e-01, MSE(pi2): 6.566e-02, MSE(pi3): 2.515e-02\n",
      "Epoch 12600, Train loss: 1.382e+09, Test loss: 1.381e+11, MSE(e): 1.376e-01, MSE(pi1): 3.575e-01, MSE(pi2): 6.419e-02, MSE(pi3): 2.600e-02\n",
      "Epoch 12700, Train loss: 1.350e+09, Test loss: 1.370e+11, MSE(e): 1.344e-01, MSE(pi1): 3.438e-01, MSE(pi2): 6.279e-02, MSE(pi3): 2.626e-02\n",
      "Epoch 12800, Train loss: 1.319e+09, Test loss: 1.355e+11, MSE(e): 1.311e-01, MSE(pi1): 4.776e-01, MSE(pi2): 6.141e-02, MSE(pi3): 2.508e-02\n",
      "Epoch 12900, Train loss: 1.285e+09, Test loss: 1.343e+11, MSE(e): 1.279e-01, MSE(pi1): 3.277e-01, MSE(pi2): 6.003e-02, MSE(pi3): 2.736e-02\n",
      "Epoch 13000, Train loss: 1.265e+09, Test loss: 1.332e+11, MSE(e): 1.251e-01, MSE(pi1): 1.060e+00, MSE(pi2): 5.896e-02, MSE(pi3): 3.223e-02\n",
      "Epoch 13100, Train loss: 1.236e+09, Test loss: 1.322e+11, MSE(e): 1.227e-01, MSE(pi1): 6.805e-01, MSE(pi2): 5.788e-02, MSE(pi3): 2.564e-02\n",
      "Epoch 13200, Train loss: 1.188e+09, Test loss: 1.300e+11, MSE(e): 1.179e-01, MSE(pi1): 5.444e-01, MSE(pi2): 5.583e-02, MSE(pi3): 2.618e-02\n",
      "Epoch 13300, Train loss: 1.152e+09, Test loss: 1.285e+11, MSE(e): 1.146e-01, MSE(pi1): 3.268e-01, MSE(pi2): 5.447e-02, MSE(pi3): 2.588e-02\n",
      "Epoch 13400, Train loss: 1.120e+09, Test loss: 1.271e+11, MSE(e): 1.114e-01, MSE(pi1): 3.306e-01, MSE(pi2): 5.314e-02, MSE(pi3): 2.371e-02\n",
      "Epoch 13500, Train loss: 1.103e+09, Test loss: 1.257e+11, MSE(e): 1.088e-01, MSE(pi1): 1.091e+00, MSE(pi2): 5.228e-02, MSE(pi3): 4.807e-02\n",
      "Epoch 13600, Train loss: 1.144e+09, Test loss: 1.230e+11, MSE(e): 1.129e-01, MSE(pi1): 1.249e+00, MSE(pi2): 5.493e-02, MSE(pi3): 2.595e-02\n",
      "Epoch 13700, Train loss: 1.024e+09, Test loss: 1.233e+11, MSE(e): 1.019e-01, MSE(pi1): 2.785e-01, MSE(pi2): 4.920e-02, MSE(pi3): 2.433e-02\n",
      "Epoch 13800, Train loss: 1.005e+09, Test loss: 1.221e+11, MSE(e): 9.895e-02, MSE(pi1): 1.310e+00, MSE(pi2): 4.799e-02, MSE(pi3): 2.451e-02\n",
      "Epoch 13900, Train loss: 9.662e+08, Test loss: 1.208e+11, MSE(e): 9.595e-02, MSE(pi1): 4.352e-01, MSE(pi2): 4.677e-02, MSE(pi3): 2.277e-02\n",
      "Epoch 14000, Train loss: 9.358e+08, Test loss: 1.199e+11, MSE(e): 9.307e-02, MSE(pi1): 2.651e-01, MSE(pi2): 4.557e-02, MSE(pi3): 2.417e-02\n",
      "Epoch 14100, Train loss: 9.083e+08, Test loss: 1.187e+11, MSE(e): 9.033e-02, MSE(pi1): 2.807e-01, MSE(pi2): 4.443e-02, MSE(pi3): 2.278e-02\n",
      "Epoch 14200, Train loss: 8.852e+08, Test loss: 1.180e+11, MSE(e): 8.778e-02, MSE(pi1): 4.735e-01, MSE(pi2): 4.339e-02, MSE(pi3): 2.679e-02\n",
      "Epoch 14300, Train loss: 8.947e+08, Test loss: 1.180e+11, MSE(e): 8.876e-02, MSE(pi1): 3.482e-01, MSE(pi2): 4.421e-02, MSE(pi3): 3.585e-02\n",
      "Epoch 14400, Train loss: 8.353e+08, Test loss: 1.159e+11, MSE(e): 8.298e-02, MSE(pi1): 3.344e-01, MSE(pi2): 4.140e-02, MSE(pi3): 2.155e-02\n",
      "Epoch 14500, Train loss: 8.230e+08, Test loss: 1.159e+11, MSE(e): 8.156e-02, MSE(pi1): 4.619e-01, MSE(pi2): 4.108e-02, MSE(pi3): 2.687e-02\n",
      "Epoch 14600, Train loss: 7.960e+08, Test loss: 1.140e+11, MSE(e): 7.900e-02, MSE(pi1): 3.842e-01, MSE(pi2): 3.977e-02, MSE(pi3): 2.170e-02\n",
      "Epoch 14700, Train loss: 7.667e+08, Test loss: 1.141e+11, MSE(e): 7.605e-02, MSE(pi1): 3.950e-01, MSE(pi2): 3.847e-02, MSE(pi3): 2.260e-02\n",
      "Epoch 14800, Train loss: 7.542e+08, Test loss: 1.135e+11, MSE(e): 7.431e-02, MSE(pi1): 7.963e-01, MSE(pi2): 3.780e-02, MSE(pi3): 3.103e-02\n",
      "Epoch 14900, Train loss: 7.252e+08, Test loss: 1.125e+11, MSE(e): 7.201e-02, MSE(pi1): 3.031e-01, MSE(pi2): 3.676e-02, MSE(pi3): 2.143e-02\n",
      "Epoch 15000, Train loss: 7.521e+08, Test loss: 1.117e+11, MSE(e): 7.059e-02, MSE(pi1): 4.376e+00, MSE(pi2): 3.609e-02, MSE(pi3): 2.349e-02\n",
      "Epoch 15100, Train loss: 6.890e+08, Test loss: 1.111e+11, MSE(e): 6.846e-02, MSE(pi1): 2.254e-01, MSE(pi2): 3.526e-02, MSE(pi3): 2.177e-02\n",
      "Epoch 15200, Train loss: 6.730e+08, Test loss: 1.105e+11, MSE(e): 6.686e-02, MSE(pi1): 2.189e-01, MSE(pi2): 3.458e-02, MSE(pi3): 2.193e-02\n",
      "Epoch 15300, Train loss: 6.644e+08, Test loss: 1.098e+11, MSE(e): 6.551e-02, MSE(pi1): 7.240e-01, MSE(pi2): 3.401e-02, MSE(pi3): 2.066e-02\n",
      "Epoch 15400, Train loss: 6.436e+08, Test loss: 1.094e+11, MSE(e): 6.393e-02, MSE(pi1): 2.120e-01, MSE(pi2): 3.334e-02, MSE(pi3): 2.145e-02\n",
      "Epoch 15500, Train loss: 6.413e+08, Test loss: 1.091e+11, MSE(e): 6.307e-02, MSE(pi1): 8.181e-01, MSE(pi2): 3.304e-02, MSE(pi3): 2.337e-02\n",
      "Epoch 15600, Train loss: 6.190e+08, Test loss: 1.082e+11, MSE(e): 6.145e-02, MSE(pi1): 2.484e-01, MSE(pi2): 3.229e-02, MSE(pi3): 2.063e-02\n",
      "Epoch 15700, Train loss: 6.138e+08, Test loss: 1.077e+11, MSE(e): 6.093e-02, MSE(pi1): 2.198e-01, MSE(pi2): 3.225e-02, MSE(pi3): 2.299e-02\n",
      "Epoch 15800, Train loss: 5.980e+08, Test loss: 1.072e+11, MSE(e): 5.923e-02, MSE(pi1): 2.961e-01, MSE(pi2): 3.134e-02, MSE(pi3): 2.704e-02\n",
      "Epoch 15900, Train loss: 6.016e+08, Test loss: 1.072e+11, MSE(e): 5.899e-02, MSE(pi1): 9.092e-01, MSE(pi2): 3.135e-02, MSE(pi3): 2.573e-02\n",
      "Epoch 16000, Train loss: 5.753e+08, Test loss: 1.065e+11, MSE(e): 5.713e-02, MSE(pi1): 1.926e-01, MSE(pi2): 3.039e-02, MSE(pi3): 2.096e-02\n",
      "Epoch 16100, Train loss: 5.779e+08, Test loss: 1.056e+11, MSE(e): 5.698e-02, MSE(pi1): 5.974e-01, MSE(pi2): 3.055e-02, MSE(pi3): 2.181e-02\n",
      "Epoch 16200, Train loss: 5.640e+08, Test loss: 1.055e+11, MSE(e): 5.571e-02, MSE(pi1): 4.899e-01, MSE(pi2): 2.982e-02, MSE(pi3): 1.952e-02\n",
      "Epoch 16300, Train loss: 5.536e+08, Test loss: 1.055e+11, MSE(e): 5.461e-02, MSE(pi1): 5.259e-01, MSE(pi2): 2.929e-02, MSE(pi3): 2.249e-02\n",
      "Epoch 16400, Train loss: 5.569e+08, Test loss: 1.052e+11, MSE(e): 5.412e-02, MSE(pi1): 1.317e+00, MSE(pi2): 2.908e-02, MSE(pi3): 2.539e-02\n",
      "Epoch 16500, Train loss: 5.389e+08, Test loss: 1.047e+11, MSE(e): 5.319e-02, MSE(pi1): 4.502e-01, MSE(pi2): 2.870e-02, MSE(pi3): 2.544e-02\n",
      "Epoch 16600, Train loss: 5.327e+08, Test loss: 1.043e+11, MSE(e): 5.249e-02, MSE(pi1): 5.157e-01, MSE(pi2): 2.839e-02, MSE(pi3): 2.670e-02\n",
      "Epoch 16700, Train loss: 5.251e+08, Test loss: 1.040e+11, MSE(e): 5.193e-02, MSE(pi1): 3.373e-01, MSE(pi2): 2.804e-02, MSE(pi3): 2.363e-02\n",
      "Epoch 16800, Train loss: 5.117e+08, Test loss: 1.033e+11, MSE(e): 5.077e-02, MSE(pi1): 1.916e-01, MSE(pi2): 2.753e-02, MSE(pi3): 2.080e-02\n",
      "Epoch 16900, Train loss: 5.066e+08, Test loss: 1.030e+11, MSE(e): 5.013e-02, MSE(pi1): 3.125e-01, MSE(pi2): 2.724e-02, MSE(pi3): 2.126e-02\n",
      "Epoch 17000, Train loss: 5.047e+08, Test loss: 1.028e+11, MSE(e): 4.962e-02, MSE(pi1): 6.167e-01, MSE(pi2): 2.699e-02, MSE(pi3): 2.323e-02\n",
      "Epoch 17100, Train loss: 4.959e+08, Test loss: 1.020e+11, MSE(e): 4.906e-02, MSE(pi1): 3.077e-01, MSE(pi2): 2.675e-02, MSE(pi3): 2.215e-02\n",
      "Epoch 17200, Train loss: 4.913e+08, Test loss: 1.019e+11, MSE(e): 4.834e-02, MSE(pi1): 5.367e-01, MSE(pi2): 2.638e-02, MSE(pi3): 2.535e-02\n",
      "Epoch 17300, Train loss: 4.802e+08, Test loss: 1.017e+11, MSE(e): 4.764e-02, MSE(pi1): 1.723e-01, MSE(pi2): 2.607e-02, MSE(pi3): 2.052e-02\n",
      "Epoch 17400, Train loss: 4.751e+08, Test loss: 1.013e+11, MSE(e): 4.710e-02, MSE(pi1): 2.086e-01, MSE(pi2): 2.583e-02, MSE(pi3): 2.086e-02\n",
      "Epoch 17500, Train loss: 4.840e+08, Test loss: 1.011e+11, MSE(e): 4.692e-02, MSE(pi1): 1.217e+00, MSE(pi2): 2.576e-02, MSE(pi3): 2.642e-02\n",
      "Epoch 17600, Train loss: 4.871e+08, Test loss: 1.009e+11, MSE(e): 4.680e-02, MSE(pi1): 1.445e+00, MSE(pi2): 2.558e-02, MSE(pi3): 4.707e-02\n",
      "Epoch 17700, Train loss: 4.578e+08, Test loss: 1.005e+11, MSE(e): 4.541e-02, MSE(pi1): 1.686e-01, MSE(pi2): 2.500e-02, MSE(pi3): 2.024e-02\n",
      "Epoch 17800, Train loss: 4.516e+08, Test loss: 9.999e+10, MSE(e): 4.480e-02, MSE(pi1): 1.655e-01, MSE(pi2): 2.471e-02, MSE(pi3): 1.954e-02\n",
      "Epoch 17900, Train loss: 4.485e+08, Test loss: 9.966e+10, MSE(e): 4.439e-02, MSE(pi1): 2.412e-01, MSE(pi2): 2.452e-02, MSE(pi3): 2.185e-02\n",
      "Epoch 18000, Train loss: 4.424e+08, Test loss: 9.951e+10, MSE(e): 4.387e-02, MSE(pi1): 1.687e-01, MSE(pi2): 2.428e-02, MSE(pi3): 1.999e-02\n",
      "Epoch 18100, Train loss: 4.419e+08, Test loss: 9.918e+10, MSE(e): 4.344e-02, MSE(pi1): 4.944e-01, MSE(pi2): 2.407e-02, MSE(pi3): 2.501e-02\n",
      "Epoch 18200, Train loss: 4.319e+08, Test loss: 9.908e+10, MSE(e): 4.280e-02, MSE(pi1): 1.956e-01, MSE(pi2): 2.374e-02, MSE(pi3): 1.986e-02\n",
      "Epoch 18300, Train loss: 4.273e+08, Test loss: 9.885e+10, MSE(e): 4.230e-02, MSE(pi1): 1.862e-01, MSE(pi2): 2.349e-02, MSE(pi3): 2.408e-02\n",
      "Epoch 18400, Train loss: 4.237e+08, Test loss: 9.828e+10, MSE(e): 4.188e-02, MSE(pi1): 3.142e-01, MSE(pi2): 2.328e-02, MSE(pi3): 1.824e-02\n",
      "Epoch 18500, Train loss: 4.179e+08, Test loss: 9.845e+10, MSE(e): 4.143e-02, MSE(pi1): 1.529e-01, MSE(pi2): 2.305e-02, MSE(pi3): 2.032e-02\n",
      "Epoch 18600, Train loss: 4.257e+08, Test loss: 9.840e+10, MSE(e): 4.148e-02, MSE(pi1): 7.077e-01, MSE(pi2): 2.304e-02, MSE(pi3): 3.852e-02\n",
      "Epoch 18700, Train loss: 4.158e+08, Test loss: 9.748e+10, MSE(e): 4.118e-02, MSE(pi1): 2.137e-01, MSE(pi2): 2.305e-02, MSE(pi3): 1.808e-02\n",
      "Epoch 18800, Train loss: 4.097e+08, Test loss: 9.738e+10, MSE(e): 4.054e-02, MSE(pi1): 2.486e-01, MSE(pi2): 2.269e-02, MSE(pi3): 1.789e-02\n",
      "Epoch 18900, Train loss: 3.994e+08, Test loss: 9.775e+10, MSE(e): 3.959e-02, MSE(pi1): 1.541e-01, MSE(pi2): 2.215e-02, MSE(pi3): 1.900e-02\n",
      "Epoch 19000, Train loss: 4.005e+08, Test loss: 9.776e+10, MSE(e): 3.959e-02, MSE(pi1): 2.751e-01, MSE(pi2): 2.212e-02, MSE(pi3): 1.868e-02\n",
      "Epoch 19100, Train loss: 3.996e+08, Test loss: 9.738e+10, MSE(e): 3.901e-02, MSE(pi1): 7.875e-01, MSE(pi2): 2.188e-02, MSE(pi3): 1.699e-02\n",
      "Epoch 19200, Train loss: 3.864e+08, Test loss: 9.725e+10, MSE(e): 3.830e-02, MSE(pi1): 1.588e-01, MSE(pi2): 2.150e-02, MSE(pi3): 1.832e-02\n",
      "Epoch 19300, Train loss: 3.848e+08, Test loss: 9.719e+10, MSE(e): 3.792e-02, MSE(pi1): 3.749e-01, MSE(pi2): 2.131e-02, MSE(pi3): 1.889e-02\n",
      "Epoch 19400, Train loss: 3.830e+08, Test loss: 9.691e+10, MSE(e): 3.763e-02, MSE(pi1): 4.772e-01, MSE(pi2): 2.114e-02, MSE(pi3): 1.870e-02\n",
      "Epoch 19500, Train loss: 3.811e+08, Test loss: 9.712e+10, MSE(e): 3.725e-02, MSE(pi1): 6.208e-01, MSE(pi2): 2.097e-02, MSE(pi3): 2.416e-02\n",
      "Epoch 19600, Train loss: 3.780e+08, Test loss: 9.678e+10, MSE(e): 3.699e-02, MSE(pi1): 5.404e-01, MSE(pi2): 2.087e-02, MSE(pi3): 2.700e-02\n",
      "Epoch 19700, Train loss: 3.998e+08, Test loss: 9.734e+10, MSE(e): 3.932e-02, MSE(pi1): 3.830e-01, MSE(pi2): 2.225e-02, MSE(pi3): 2.775e-02\n",
      "Epoch 19800, Train loss: 3.636e+08, Test loss: 9.669e+10, MSE(e): 3.603e-02, MSE(pi1): 1.477e-01, MSE(pi2): 2.037e-02, MSE(pi3): 1.782e-02\n",
      "Epoch 19900, Train loss: 3.615e+08, Test loss: 9.665e+10, MSE(e): 3.577e-02, MSE(pi1): 1.875e-01, MSE(pi2): 2.024e-02, MSE(pi3): 1.990e-02\n",
      "\n",
      "Training process finished after 20000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explanatory_layers = [100]\n",
    "\n",
    "model = TransferLearningAutoencoder(input_shape, predictive_layers, pgnniv_pretrained_encoder, predictive_output, explanatory_input,\n",
    "                                   explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 20000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 18000.\n",
      "Epoch 18000, Train loss: 4.428e+08, Test loss: 9.938e+10, MSE(e): 4.391e-02, MSE(pi1): 1.818e-01, MSE(pi2): 2.431e-02, MSE(pi3): 1.887e-02\n",
      "Epoch 18100, Train loss: 4.420e+08, Test loss: 9.929e+10, MSE(e): 4.346e-02, MSE(pi1): 5.505e-01, MSE(pi2): 2.408e-02, MSE(pi3): 1.899e-02\n",
      "Epoch 18200, Train loss: 4.318e+08, Test loss: 9.889e+10, MSE(e): 4.279e-02, MSE(pi1): 2.091e-01, MSE(pi2): 2.373e-02, MSE(pi3): 1.875e-02\n",
      "Epoch 18300, Train loss: 4.316e+08, Test loss: 9.883e+10, MSE(e): 4.232e-02, MSE(pi1): 4.127e-01, MSE(pi2): 2.349e-02, MSE(pi3): 4.205e-02\n",
      "Epoch 18400, Train loss: 4.251e+08, Test loss: 9.883e+10, MSE(e): 4.203e-02, MSE(pi1): 2.666e-01, MSE(pi2): 2.339e-02, MSE(pi3): 2.130e-02\n",
      "Epoch 18500, Train loss: 4.193e+08, Test loss: 9.814e+10, MSE(e): 4.146e-02, MSE(pi1): 2.967e-01, MSE(pi2): 2.310e-02, MSE(pi3): 1.819e-02\n",
      "Epoch 18600, Train loss: 4.236e+08, Test loss: 9.840e+10, MSE(e): 4.119e-02, MSE(pi1): 9.731e-01, MSE(pi2): 2.292e-02, MSE(pi3): 1.985e-02\n",
      "Epoch 18700, Train loss: 4.448e+08, Test loss: 9.808e+10, MSE(e): 4.134e-02, MSE(pi1): 2.909e+00, MSE(pi2): 2.294e-02, MSE(pi3): 2.370e-02\n",
      "Epoch 18800, Train loss: 4.337e+08, Test loss: 9.688e+10, MSE(e): 4.275e-02, MSE(pi1): 4.386e-01, MSE(pi2): 2.392e-02, MSE(pi3): 1.812e-02\n",
      "Epoch 18900, Train loss: 4.032e+08, Test loss: 9.734e+10, MSE(e): 3.983e-02, MSE(pi1): 3.165e-01, MSE(pi2): 2.231e-02, MSE(pi3): 1.773e-02\n",
      "Epoch 19000, Train loss: 4.014e+08, Test loss: 9.791e+10, MSE(e): 3.960e-02, MSE(pi1): 3.308e-01, MSE(pi2): 2.220e-02, MSE(pi3): 2.151e-02\n",
      "Epoch 19100, Train loss: 3.980e+08, Test loss: 9.764e+10, MSE(e): 3.896e-02, MSE(pi1): 6.379e-01, MSE(pi2): 2.184e-02, MSE(pi3): 2.016e-02\n",
      "Epoch 19200, Train loss: 4.055e+08, Test loss: 9.793e+10, MSE(e): 4.006e-02, MSE(pi1): 2.430e-01, MSE(pi2): 2.251e-02, MSE(pi3): 2.454e-02\n",
      "Epoch 19300, Train loss: 3.886e+08, Test loss: 9.741e+10, MSE(e): 3.831e-02, MSE(pi1): 3.296e-01, MSE(pi2): 2.160e-02, MSE(pi3): 2.213e-02\n",
      "Epoch 19400, Train loss: 3.819e+08, Test loss: 9.707e+10, MSE(e): 3.755e-02, MSE(pi1): 4.392e-01, MSE(pi2): 2.112e-02, MSE(pi3): 1.971e-02\n",
      "Epoch 19500, Train loss: 3.764e+08, Test loss: 9.703e+10, MSE(e): 3.718e-02, MSE(pi1): 2.901e-01, MSE(pi2): 2.094e-02, MSE(pi3): 1.754e-02\n",
      "Epoch 19600, Train loss: 3.781e+08, Test loss: 9.689e+10, MSE(e): 3.683e-02, MSE(pi1): 7.221e-01, MSE(pi2): 2.077e-02, MSE(pi3): 2.638e-02\n",
      "Epoch 19700, Train loss: 3.728e+08, Test loss: 9.695e+10, MSE(e): 3.679e-02, MSE(pi1): 3.069e-01, MSE(pi2): 2.081e-02, MSE(pi3): 1.787e-02\n",
      "Epoch 19800, Train loss: 3.682e+08, Test loss: 9.636e+10, MSE(e): 3.632e-02, MSE(pi1): 3.223e-01, MSE(pi2): 2.055e-02, MSE(pi3): 1.783e-02\n",
      "Epoch 19900, Train loss: 3.683e+08, Test loss: 9.711e+10, MSE(e): 3.634e-02, MSE(pi1): 2.646e-01, MSE(pi2): 2.057e-02, MSE(pi3): 2.208e-02\n",
      "Epoch 20000, Train loss: 3.716e+08, Test loss: 9.698e+10, MSE(e): 3.582e-02, MSE(pi1): 1.052e+00, MSE(pi2): 2.030e-02, MSE(pi3): 2.905e-02\n",
      "Epoch 20100, Train loss: 3.708e+08, Test loss: 9.617e+10, MSE(e): 3.559e-02, MSE(pi1): 1.318e+00, MSE(pi2): 2.026e-02, MSE(pi3): 1.701e-02\n",
      "Epoch 20200, Train loss: 3.525e+08, Test loss: 9.648e+10, MSE(e): 3.468e-02, MSE(pi1): 3.203e-01, MSE(pi2): 1.968e-02, MSE(pi3): 2.422e-02\n",
      "Epoch 20300, Train loss: 3.464e+08, Test loss: 9.647e+10, MSE(e): 3.432e-02, MSE(pi1): 1.474e-01, MSE(pi2): 1.950e-02, MSE(pi3): 1.769e-02\n",
      "Epoch 20400, Train loss: 3.485e+08, Test loss: 9.608e+10, MSE(e): 3.425e-02, MSE(pi1): 4.272e-01, MSE(pi2): 1.951e-02, MSE(pi3): 1.651e-02\n",
      "Epoch 20500, Train loss: 3.630e+08, Test loss: 9.669e+10, MSE(e): 3.410e-02, MSE(pi1): 1.947e+00, MSE(pi2): 1.932e-02, MSE(pi3): 2.513e-02\n",
      "Epoch 20600, Train loss: 3.375e+08, Test loss: 9.645e+10, MSE(e): 3.339e-02, MSE(pi1): 1.774e-01, MSE(pi2): 1.904e-02, MSE(pi3): 1.787e-02\n",
      "Epoch 20700, Train loss: 3.498e+08, Test loss: 9.628e+10, MSE(e): 3.328e-02, MSE(pi1): 1.501e+00, MSE(pi2): 1.895e-02, MSE(pi3): 1.915e-02\n",
      "Epoch 20800, Train loss: 3.424e+08, Test loss: 9.714e+10, MSE(e): 3.386e-02, MSE(pi1): 1.760e-01, MSE(pi2): 1.932e-02, MSE(pi3): 2.003e-02\n",
      "Epoch 20900, Train loss: 3.277e+08, Test loss: 9.641e+10, MSE(e): 3.246e-02, MSE(pi1): 1.394e-01, MSE(pi2): 1.855e-02, MSE(pi3): 1.702e-02\n",
      "Epoch 21000, Train loss: 3.250e+08, Test loss: 9.642e+10, MSE(e): 3.217e-02, MSE(pi1): 1.496e-01, MSE(pi2): 1.840e-02, MSE(pi3): 1.742e-02\n",
      "Epoch 21100, Train loss: 3.279e+08, Test loss: 9.612e+10, MSE(e): 3.229e-02, MSE(pi1): 3.235e-01, MSE(pi2): 1.852e-02, MSE(pi3): 1.808e-02\n",
      "Epoch 21200, Train loss: 3.226e+08, Test loss: 9.670e+10, MSE(e): 3.173e-02, MSE(pi1): 3.254e-01, MSE(pi2): 1.817e-02, MSE(pi3): 1.994e-02\n",
      "Epoch 21300, Train loss: 3.208e+08, Test loss: 9.665e+10, MSE(e): 3.147e-02, MSE(pi1): 4.011e-01, MSE(pi2): 1.806e-02, MSE(pi3): 2.047e-02\n",
      "Epoch 21400, Train loss: 3.136e+08, Test loss: 9.659e+10, MSE(e): 3.103e-02, MSE(pi1): 1.683e-01, MSE(pi2): 1.780e-02, MSE(pi3): 1.700e-02\n",
      "Epoch 21500, Train loss: 3.118e+08, Test loss: 9.660e+10, MSE(e): 3.077e-02, MSE(pi1): 2.223e-01, MSE(pi2): 1.767e-02, MSE(pi3): 1.877e-02\n",
      "Epoch 21600, Train loss: 3.186e+08, Test loss: 9.722e+10, MSE(e): 3.136e-02, MSE(pi1): 3.127e-01, MSE(pi2): 1.809e-02, MSE(pi3): 1.915e-02\n",
      "Epoch 21700, Train loss: 3.104e+08, Test loss: 9.675e+10, MSE(e): 3.040e-02, MSE(pi1): 4.777e-01, MSE(pi2): 1.748e-02, MSE(pi3): 1.576e-02\n",
      "Epoch 21800, Train loss: 3.206e+08, Test loss: 9.615e+10, MSE(e): 3.149e-02, MSE(pi1): 4.053e-01, MSE(pi2): 1.813e-02, MSE(pi3): 1.556e-02\n",
      "Epoch 21900, Train loss: 3.126e+08, Test loss: 9.761e+10, MSE(e): 3.044e-02, MSE(pi1): 6.050e-01, MSE(pi2): 1.753e-02, MSE(pi3): 2.193e-02\n",
      "Epoch 22000, Train loss: 3.133e+08, Test loss: 9.784e+10, MSE(e): 3.066e-02, MSE(pi1): 4.462e-01, MSE(pi2): 1.761e-02, MSE(pi3): 2.203e-02\n",
      "Epoch 22100, Train loss: 3.114e+08, Test loss: 9.705e+10, MSE(e): 2.933e-02, MSE(pi1): 1.650e+00, MSE(pi2): 1.684e-02, MSE(pi3): 1.633e-02\n",
      "Epoch 22200, Train loss: 3.037e+08, Test loss: 9.695e+10, MSE(e): 2.991e-02, MSE(pi1): 3.060e-01, MSE(pi2): 1.724e-02, MSE(pi3): 1.506e-02\n",
      "Epoch 22300, Train loss: 2.976e+08, Test loss: 9.740e+10, MSE(e): 2.925e-02, MSE(pi1): 3.645e-01, MSE(pi2): 1.697e-02, MSE(pi3): 1.522e-02\n",
      "Epoch 22400, Train loss: 3.019e+08, Test loss: 9.716e+10, MSE(e): 2.912e-02, MSE(pi1): 9.086e-01, MSE(pi2): 1.692e-02, MSE(pi3): 1.532e-02\n",
      "Epoch 22500, Train loss: 2.901e+08, Test loss: 9.803e+10, MSE(e): 2.830e-02, MSE(pi1): 4.589e-01, MSE(pi2): 1.633e-02, MSE(pi3): 2.459e-02\n",
      "Epoch 22600, Train loss: 2.847e+08, Test loss: 9.780e+10, MSE(e): 2.802e-02, MSE(pi1): 2.952e-01, MSE(pi2): 1.622e-02, MSE(pi3): 1.553e-02\n",
      "Epoch 22700, Train loss: 2.820e+08, Test loss: 9.797e+10, MSE(e): 2.772e-02, MSE(pi1): 3.266e-01, MSE(pi2): 1.603e-02, MSE(pi3): 1.576e-02\n",
      "Epoch 22800, Train loss: 3.350e+08, Test loss: 9.942e+10, MSE(e): 3.132e-02, MSE(pi1): 1.662e+00, MSE(pi2): 1.840e-02, MSE(pi3): 5.188e-02\n",
      "Epoch 22900, Train loss: 2.756e+08, Test loss: 9.847e+10, MSE(e): 2.726e-02, MSE(pi1): 1.417e-01, MSE(pi2): 1.579e-02, MSE(pi3): 1.579e-02\n",
      "Epoch 23000, Train loss: 2.733e+08, Test loss: 9.853e+10, MSE(e): 2.703e-02, MSE(pi1): 1.433e-01, MSE(pi2): 1.567e-02, MSE(pi3): 1.528e-02\n",
      "Epoch 23100, Train loss: 3.011e+08, Test loss: 9.955e+10, MSE(e): 2.882e-02, MSE(pi1): 7.529e-01, MSE(pi2): 1.681e-02, MSE(pi3): 5.357e-02\n",
      "Epoch 23200, Train loss: 3.008e+08, Test loss: 9.782e+10, MSE(e): 2.937e-02, MSE(pi1): 5.565e-01, MSE(pi2): 1.698e-02, MSE(pi3): 1.495e-02\n",
      "Epoch 23300, Train loss: 2.736e+08, Test loss: 9.858e+10, MSE(e): 2.693e-02, MSE(pi1): 2.880e-01, MSE(pi2): 1.567e-02, MSE(pi3): 1.445e-02\n",
      "Epoch 23400, Train loss: 3.060e+08, Test loss: 9.799e+10, MSE(e): 3.004e-02, MSE(pi1): 4.253e-01, MSE(pi2): 1.709e-02, MSE(pi3): 1.404e-02\n",
      "Epoch 23500, Train loss: 2.662e+08, Test loss: 9.964e+10, MSE(e): 2.626e-02, MSE(pi1): 2.013e-01, MSE(pi2): 1.525e-02, MSE(pi3): 1.554e-02\n",
      "Epoch 23600, Train loss: 2.701e+08, Test loss: 9.988e+10, MSE(e): 2.620e-02, MSE(pi1): 6.140e-01, MSE(pi2): 1.522e-02, MSE(pi3): 2.030e-02\n",
      "Epoch 23700, Train loss: 2.655e+08, Test loss: 9.934e+10, MSE(e): 2.610e-02, MSE(pi1): 2.118e-01, MSE(pi2): 1.518e-02, MSE(pi3): 2.395e-02\n",
      "Epoch 23800, Train loss: 2.576e+08, Test loss: 9.987e+10, MSE(e): 2.549e-02, MSE(pi1): 1.190e-01, MSE(pi2): 1.485e-02, MSE(pi3): 1.531e-02\n",
      "Epoch 23900, Train loss: 2.616e+08, Test loss: 9.994e+10, MSE(e): 2.537e-02, MSE(pi1): 5.459e-01, MSE(pi2): 1.479e-02, MSE(pi3): 2.366e-02\n",
      "Epoch 24000, Train loss: 2.616e+08, Test loss: 1.005e+11, MSE(e): 2.556e-02, MSE(pi1): 3.731e-01, MSE(pi2): 1.496e-02, MSE(pi3): 2.257e-02\n",
      "Epoch 24100, Train loss: 2.618e+08, Test loss: 1.001e+11, MSE(e): 2.524e-02, MSE(pi1): 7.093e-01, MSE(pi2): 1.474e-02, MSE(pi3): 2.285e-02\n",
      "Epoch 24200, Train loss: 2.510e+08, Test loss: 1.005e+11, MSE(e): 2.482e-02, MSE(pi1): 1.244e-01, MSE(pi2): 1.450e-02, MSE(pi3): 1.541e-02\n",
      "Epoch 24300, Train loss: 2.618e+08, Test loss: 1.003e+11, MSE(e): 2.497e-02, MSE(pi1): 1.061e+00, MSE(pi2): 1.465e-02, MSE(pi3): 1.463e-02\n",
      "Epoch 24400, Train loss: 2.488e+08, Test loss: 1.006e+11, MSE(e): 2.456e-02, MSE(pi1): 1.378e-01, MSE(pi2): 1.438e-02, MSE(pi3): 1.824e-02\n",
      "Epoch 24500, Train loss: 2.460e+08, Test loss: 1.009e+11, MSE(e): 2.433e-02, MSE(pi1): 1.192e-01, MSE(pi2): 1.424e-02, MSE(pi3): 1.516e-02\n",
      "Epoch 24600, Train loss: 2.487e+08, Test loss: 1.010e+11, MSE(e): 2.450e-02, MSE(pi1): 2.250e-01, MSE(pi2): 1.436e-02, MSE(pi3): 1.415e-02\n",
      "Epoch 24700, Train loss: 2.442e+08, Test loss: 1.010e+11, MSE(e): 2.408e-02, MSE(pi1): 1.810e-01, MSE(pi2): 1.412e-02, MSE(pi3): 1.604e-02\n",
      "Epoch 24800, Train loss: 2.447e+08, Test loss: 1.014e+11, MSE(e): 2.408e-02, MSE(pi1): 1.748e-01, MSE(pi2): 1.413e-02, MSE(pi3): 2.179e-02\n",
      "Epoch 24900, Train loss: 2.649e+08, Test loss: 1.010e+11, MSE(e): 2.520e-02, MSE(pi1): 1.135e+00, MSE(pi2): 1.508e-02, MSE(pi3): 1.490e-02\n",
      "Epoch 25000, Train loss: 2.393e+08, Test loss: 1.014e+11, MSE(e): 2.366e-02, MSE(pi1): 1.370e-01, MSE(pi2): 1.389e-02, MSE(pi3): 1.422e-02\n",
      "Epoch 25100, Train loss: 2.394e+08, Test loss: 1.021e+11, MSE(e): 2.354e-02, MSE(pi1): 2.268e-01, MSE(pi2): 1.383e-02, MSE(pi3): 1.670e-02\n",
      "Epoch 25200, Train loss: 2.736e+08, Test loss: 1.025e+11, MSE(e): 2.378e-02, MSE(pi1): 3.365e+00, MSE(pi2): 1.394e-02, MSE(pi3): 2.107e-02\n",
      "Epoch 25300, Train loss: 2.365e+08, Test loss: 1.017e+11, MSE(e): 2.338e-02, MSE(pi1): 1.283e-01, MSE(pi2): 1.374e-02, MSE(pi3): 1.402e-02\n",
      "Epoch 25400, Train loss: 2.347e+08, Test loss: 1.024e+11, MSE(e): 2.321e-02, MSE(pi1): 1.105e-01, MSE(pi2): 1.365e-02, MSE(pi3): 1.518e-02\n",
      "Epoch 25500, Train loss: 2.364e+08, Test loss: 1.023e+11, MSE(e): 2.297e-02, MSE(pi1): 5.380e-01, MSE(pi2): 1.355e-02, MSE(pi3): 1.382e-02\n",
      "Epoch 25600, Train loss: 2.306e+08, Test loss: 1.024e+11, MSE(e): 2.276e-02, MSE(pi1): 1.668e-01, MSE(pi2): 1.342e-02, MSE(pi3): 1.388e-02\n",
      "Epoch 25700, Train loss: 2.338e+08, Test loss: 1.032e+11, MSE(e): 2.288e-02, MSE(pi1): 3.086e-01, MSE(pi2): 1.347e-02, MSE(pi3): 1.897e-02\n",
      "Epoch 25800, Train loss: 2.512e+08, Test loss: 1.018e+11, MSE(e): 2.466e-02, MSE(pi1): 3.164e-01, MSE(pi2): 1.444e-02, MSE(pi3): 1.363e-02\n",
      "Epoch 25900, Train loss: 2.276e+08, Test loss: 1.028e+11, MSE(e): 2.239e-02, MSE(pi1): 2.302e-01, MSE(pi2): 1.324e-02, MSE(pi3): 1.367e-02\n",
      "Epoch 26000, Train loss: 2.384e+08, Test loss: 1.025e+11, MSE(e): 2.277e-02, MSE(pi1): 9.396e-01, MSE(pi2): 1.345e-02, MSE(pi3): 1.243e-02\n",
      "Epoch 26100, Train loss: 2.281e+08, Test loss: 1.030e+11, MSE(e): 2.236e-02, MSE(pi1): 3.109e-01, MSE(pi2): 1.320e-02, MSE(pi3): 1.341e-02\n",
      "Epoch 26200, Train loss: 2.574e+08, Test loss: 1.026e+11, MSE(e): 2.525e-02, MSE(pi1): 3.414e-01, MSE(pi2): 1.452e-02, MSE(pi3): 1.429e-02\n",
      "Epoch 26300, Train loss: 2.212e+08, Test loss: 1.039e+11, MSE(e): 2.187e-02, MSE(pi1): 1.065e-01, MSE(pi2): 1.293e-02, MSE(pi3): 1.469e-02\n",
      "Epoch 26400, Train loss: 2.219e+08, Test loss: 1.041e+11, MSE(e): 2.181e-02, MSE(pi1): 2.254e-01, MSE(pi2): 1.290e-02, MSE(pi3): 1.522e-02\n",
      "Epoch 26500, Train loss: 2.241e+08, Test loss: 1.038e+11, MSE(e): 2.211e-02, MSE(pi1): 1.448e-01, MSE(pi2): 1.308e-02, MSE(pi3): 1.477e-02\n",
      "Epoch 26600, Train loss: 2.256e+08, Test loss: 1.045e+11, MSE(e): 2.184e-02, MSE(pi1): 5.639e-01, MSE(pi2): 1.288e-02, MSE(pi3): 1.528e-02\n",
      "Epoch 26700, Train loss: 2.172e+08, Test loss: 1.042e+11, MSE(e): 2.136e-02, MSE(pi1): 2.179e-01, MSE(pi2): 1.266e-02, MSE(pi3): 1.487e-02\n",
      "Epoch 26800, Train loss: 2.166e+08, Test loss: 1.042e+11, MSE(e): 2.125e-02, MSE(pi1): 2.798e-01, MSE(pi2): 1.261e-02, MSE(pi3): 1.282e-02\n",
      "Epoch 26900, Train loss: 2.394e+08, Test loss: 1.046e+11, MSE(e): 2.150e-02, MSE(pi1): 1.912e+00, MSE(pi2): 1.270e-02, MSE(pi3): 5.299e-02\n",
      "Epoch 27000, Train loss: 2.121e+08, Test loss: 1.048e+11, MSE(e): 2.097e-02, MSE(pi1): 1.021e-01, MSE(pi2): 1.245e-02, MSE(pi3): 1.394e-02\n",
      "Epoch 27100, Train loss: 2.109e+08, Test loss: 1.047e+11, MSE(e): 2.084e-02, MSE(pi1): 1.118e-01, MSE(pi2): 1.238e-02, MSE(pi3): 1.351e-02\n",
      "Epoch 27200, Train loss: 2.106e+08, Test loss: 1.050e+11, MSE(e): 2.076e-02, MSE(pi1): 1.367e-01, MSE(pi2): 1.234e-02, MSE(pi3): 1.668e-02\n",
      "Epoch 27300, Train loss: 2.264e+08, Test loss: 1.050e+11, MSE(e): 2.081e-02, MSE(pi1): 1.677e+00, MSE(pi2): 1.230e-02, MSE(pi3): 1.539e-02\n",
      "Epoch 27400, Train loss: 2.082e+08, Test loss: 1.052e+11, MSE(e): 2.052e-02, MSE(pi1): 1.381e-01, MSE(pi2): 1.221e-02, MSE(pi3): 1.586e-02\n",
      "Epoch 27500, Train loss: 2.073e+08, Test loss: 1.050e+11, MSE(e): 2.047e-02, MSE(pi1): 1.292e-01, MSE(pi2): 1.219e-02, MSE(pi3): 1.337e-02\n",
      "Epoch 27600, Train loss: 2.270e+08, Test loss: 1.056e+11, MSE(e): 2.117e-02, MSE(pi1): 6.478e-01, MSE(pi2): 1.256e-02, MSE(pi3): 8.868e-02\n",
      "Epoch 27700, Train loss: 2.041e+08, Test loss: 1.055e+11, MSE(e): 2.018e-02, MSE(pi1): 9.935e-02, MSE(pi2): 1.202e-02, MSE(pi3): 1.352e-02\n",
      "Epoch 27800, Train loss: 2.033e+08, Test loss: 1.056e+11, MSE(e): 2.008e-02, MSE(pi1): 1.165e-01, MSE(pi2): 1.197e-02, MSE(pi3): 1.331e-02\n",
      "Epoch 27900, Train loss: 2.036e+08, Test loss: 1.055e+11, MSE(e): 2.005e-02, MSE(pi1): 1.773e-01, MSE(pi2): 1.195e-02, MSE(pi3): 1.289e-02\n",
      "Epoch 28000, Train loss: 2.044e+08, Test loss: 1.056e+11, MSE(e): 2.004e-02, MSE(pi1): 2.170e-01, MSE(pi2): 1.195e-02, MSE(pi3): 1.815e-02\n",
      "Epoch 28100, Train loss: 2.012e+08, Test loss: 1.059e+11, MSE(e): 1.979e-02, MSE(pi1): 2.046e-01, MSE(pi2): 1.181e-02, MSE(pi3): 1.284e-02\n",
      "Epoch 28200, Train loss: 2.149e+08, Test loss: 1.063e+11, MSE(e): 2.113e-02, MSE(pi1): 1.893e-01, MSE(pi2): 1.247e-02, MSE(pi3): 1.649e-02\n",
      "Epoch 28300, Train loss: 2.046e+08, Test loss: 1.067e+11, MSE(e): 2.020e-02, MSE(pi1): 1.083e-01, MSE(pi2): 1.196e-02, MSE(pi3): 1.535e-02\n",
      "Epoch 28400, Train loss: 2.003e+08, Test loss: 1.062e+11, MSE(e): 1.960e-02, MSE(pi1): 2.837e-01, MSE(pi2): 1.171e-02, MSE(pi3): 1.539e-02\n",
      "Epoch 28500, Train loss: 1.988e+08, Test loss: 1.061e+11, MSE(e): 1.964e-02, MSE(pi1): 1.027e-01, MSE(pi2): 1.172e-02, MSE(pi3): 1.367e-02\n",
      "Epoch 28600, Train loss: 2.026e+08, Test loss: 1.064e+11, MSE(e): 1.939e-02, MSE(pi1): 6.807e-01, MSE(pi2): 1.158e-02, MSE(pi3): 1.891e-02\n",
      "Epoch 28700, Train loss: 1.965e+08, Test loss: 1.061e+11, MSE(e): 1.929e-02, MSE(pi1): 2.267e-01, MSE(pi2): 1.156e-02, MSE(pi3): 1.284e-02\n",
      "Epoch 28800, Train loss: 2.052e+08, Test loss: 1.068e+11, MSE(e): 1.927e-02, MSE(pi1): 1.074e+00, MSE(pi2): 1.149e-02, MSE(pi3): 1.823e-02\n",
      "Epoch 28900, Train loss: 1.989e+08, Test loss: 1.072e+11, MSE(e): 1.960e-02, MSE(pi1): 1.463e-01, MSE(pi2): 1.166e-02, MSE(pi3): 1.456e-02\n",
      "Epoch 29000, Train loss: 1.951e+08, Test loss: 1.069e+11, MSE(e): 1.899e-02, MSE(pi1): 3.886e-01, MSE(pi2): 1.136e-02, MSE(pi3): 1.259e-02\n",
      "Epoch 29100, Train loss: 1.967e+08, Test loss: 1.062e+11, MSE(e): 1.936e-02, MSE(pi1): 1.845e-01, MSE(pi2): 1.158e-02, MSE(pi3): 1.290e-02\n",
      "Epoch 29200, Train loss: 2.237e+08, Test loss: 1.066e+11, MSE(e): 1.946e-02, MSE(pi1): 2.621e+00, MSE(pi2): 1.164e-02, MSE(pi3): 2.851e-02\n",
      "Epoch 29300, Train loss: 1.928e+08, Test loss: 1.074e+11, MSE(e): 1.902e-02, MSE(pi1): 1.140e-01, MSE(pi2): 1.136e-02, MSE(pi3): 1.425e-02\n",
      "Epoch 29400, Train loss: 1.892e+08, Test loss: 1.068e+11, MSE(e): 1.860e-02, MSE(pi1): 1.872e-01, MSE(pi2): 1.116e-02, MSE(pi3): 1.261e-02\n",
      "Epoch 29500, Train loss: 1.999e+08, Test loss: 1.071e+11, MSE(e): 1.896e-02, MSE(pi1): 9.020e-01, MSE(pi2): 1.136e-02, MSE(pi3): 1.320e-02\n",
      "Epoch 29600, Train loss: 1.926e+08, Test loss: 1.070e+11, MSE(e): 1.862e-02, MSE(pi1): 4.731e-01, MSE(pi2): 1.114e-02, MSE(pi3): 1.718e-02\n",
      "Epoch 29700, Train loss: 1.895e+08, Test loss: 1.074e+11, MSE(e): 1.847e-02, MSE(pi1): 2.319e-01, MSE(pi2): 1.104e-02, MSE(pi3): 2.500e-02\n",
      "Epoch 29800, Train loss: 1.876e+08, Test loss: 1.074e+11, MSE(e): 1.836e-02, MSE(pi1): 2.743e-01, MSE(pi2): 1.100e-02, MSE(pi3): 1.223e-02\n",
      "Epoch 29900, Train loss: 2.011e+08, Test loss: 1.069e+11, MSE(e): 1.897e-02, MSE(pi1): 9.751e-01, MSE(pi2): 1.125e-02, MSE(pi3): 1.621e-02\n",
      "Epoch 30000, Train loss: 2.071e+08, Test loss: 1.064e+11, MSE(e): 2.044e-02, MSE(pi1): 1.394e-01, MSE(pi2): 1.202e-02, MSE(pi3): 1.281e-02\n",
      "Epoch 30100, Train loss: 1.868e+08, Test loss: 1.071e+11, MSE(e): 1.807e-02, MSE(pi1): 4.910e-01, MSE(pi2): 1.086e-02, MSE(pi3): 1.206e-02\n",
      "Epoch 30200, Train loss: 1.855e+08, Test loss: 1.074e+11, MSE(e): 1.806e-02, MSE(pi1): 3.672e-01, MSE(pi2): 1.084e-02, MSE(pi3): 1.217e-02\n",
      "Epoch 30300, Train loss: 1.895e+08, Test loss: 1.073e+11, MSE(e): 1.796e-02, MSE(pi1): 8.192e-01, MSE(pi2): 1.081e-02, MSE(pi3): 1.681e-02\n",
      "Epoch 30400, Train loss: 1.827e+08, Test loss: 1.070e+11, MSE(e): 1.799e-02, MSE(pi1): 1.569e-01, MSE(pi2): 1.081e-02, MSE(pi3): 1.201e-02\n",
      "Epoch 30500, Train loss: 1.921e+08, Test loss: 1.070e+11, MSE(e): 1.857e-02, MSE(pi1): 5.000e-01, MSE(pi2): 1.106e-02, MSE(pi3): 1.431e-02\n",
      "Epoch 30600, Train loss: 2.047e+08, Test loss: 1.072e+11, MSE(e): 1.832e-02, MSE(pi1): 2.027e+00, MSE(pi2): 1.109e-02, MSE(pi3): 1.243e-02\n",
      "Epoch 30700, Train loss: 1.883e+08, Test loss: 1.071e+11, MSE(e): 1.813e-02, MSE(pi1): 5.796e-01, MSE(pi2): 1.086e-02, MSE(pi3): 1.226e-02\n",
      "Epoch 30800, Train loss: 1.811e+08, Test loss: 1.075e+11, MSE(e): 1.762e-02, MSE(pi1): 3.737e-01, MSE(pi2): 1.063e-02, MSE(pi3): 1.141e-02\n",
      "Epoch 30900, Train loss: 1.769e+08, Test loss: 1.079e+11, MSE(e): 1.741e-02, MSE(pi1): 1.302e-01, MSE(pi2): 1.048e-02, MSE(pi3): 1.466e-02\n",
      "Epoch 31000, Train loss: 1.810e+08, Test loss: 1.083e+11, MSE(e): 1.747e-02, MSE(pi1): 4.918e-01, MSE(pi2): 1.049e-02, MSE(pi3): 1.375e-02\n",
      "Epoch 31100, Train loss: 2.127e+08, Test loss: 1.092e+11, MSE(e): 2.034e-02, MSE(pi1): 7.442e-01, MSE(pi2): 1.179e-02, MSE(pi3): 1.923e-02\n",
      "Epoch 31200, Train loss: 1.782e+08, Test loss: 1.076e+11, MSE(e): 1.744e-02, MSE(pi1): 2.423e-01, MSE(pi2): 1.047e-02, MSE(pi3): 1.409e-02\n",
      "Epoch 31300, Train loss: 1.885e+08, Test loss: 1.080e+11, MSE(e): 1.729e-02, MSE(pi1): 1.111e+00, MSE(pi2): 1.038e-02, MSE(pi3): 4.498e-02\n",
      "Epoch 31400, Train loss: 1.727e+08, Test loss: 1.080e+11, MSE(e): 1.704e-02, MSE(pi1): 9.960e-02, MSE(pi2): 1.027e-02, MSE(pi3): 1.285e-02\n",
      "Epoch 31500, Train loss: 1.733e+08, Test loss: 1.081e+11, MSE(e): 1.699e-02, MSE(pi1): 1.866e-01, MSE(pi2): 1.024e-02, MSE(pi3): 1.483e-02\n",
      "Epoch 31600, Train loss: 1.768e+08, Test loss: 1.082e+11, MSE(e): 1.694e-02, MSE(pi1): 6.198e-01, MSE(pi2): 1.020e-02, MSE(pi3): 1.244e-02\n",
      "Epoch 31700, Train loss: 1.709e+08, Test loss: 1.082e+11, MSE(e): 1.683e-02, MSE(pi1): 1.343e-01, MSE(pi2): 1.015e-02, MSE(pi3): 1.245e-02\n",
      "Epoch 31800, Train loss: 1.860e+08, Test loss: 1.075e+11, MSE(e): 1.815e-02, MSE(pi1): 3.377e-01, MSE(pi2): 1.082e-02, MSE(pi3): 1.146e-02\n",
      "Epoch 31900, Train loss: 1.724e+08, Test loss: 1.080e+11, MSE(e): 1.692e-02, MSE(pi1): 1.481e-01, MSE(pi2): 1.022e-02, MSE(pi3): 1.670e-02\n",
      "Epoch 32000, Train loss: 1.742e+08, Test loss: 1.086e+11, MSE(e): 1.683e-02, MSE(pi1): 4.010e-01, MSE(pi2): 1.010e-02, MSE(pi3): 1.919e-02\n",
      "Epoch 32100, Train loss: 1.863e+08, Test loss: 1.092e+11, MSE(e): 1.771e-02, MSE(pi1): 7.387e-01, MSE(pi2): 1.056e-02, MSE(pi3): 1.766e-02\n",
      "Epoch 32200, Train loss: 2.039e+08, Test loss: 1.071e+11, MSE(e): 2.011e-02, MSE(pi1): 1.527e-01, MSE(pi2): 1.168e-02, MSE(pi3): 1.244e-02\n",
      "Epoch 32300, Train loss: 1.693e+08, Test loss: 1.086e+11, MSE(e): 1.647e-02, MSE(pi1): 3.248e-01, MSE(pi2): 9.945e-03, MSE(pi3): 1.333e-02\n",
      "Epoch 32400, Train loss: 1.684e+08, Test loss: 1.085e+11, MSE(e): 1.643e-02, MSE(pi1): 2.977e-01, MSE(pi2): 9.922e-03, MSE(pi3): 1.125e-02\n",
      "Epoch 32500, Train loss: 1.671e+08, Test loss: 1.089e+11, MSE(e): 1.644e-02, MSE(pi1): 1.288e-01, MSE(pi2): 9.921e-03, MSE(pi3): 1.326e-02\n",
      "Epoch 32600, Train loss: 1.669e+08, Test loss: 1.090e+11, MSE(e): 1.636e-02, MSE(pi1): 1.969e-01, MSE(pi2): 9.869e-03, MSE(pi3): 1.247e-02\n",
      "Epoch 32700, Train loss: 1.660e+08, Test loss: 1.088e+11, MSE(e): 1.625e-02, MSE(pi1): 2.164e-01, MSE(pi2): 9.823e-03, MSE(pi3): 1.331e-02\n",
      "Epoch 32800, Train loss: 1.740e+08, Test loss: 1.094e+11, MSE(e): 1.656e-02, MSE(pi1): 6.680e-01, MSE(pi2): 9.948e-03, MSE(pi3): 1.677e-02\n",
      "Epoch 32900, Train loss: 1.700e+08, Test loss: 1.086e+11, MSE(e): 1.620e-02, MSE(pi1): 6.754e-01, MSE(pi2): 9.806e-03, MSE(pi3): 1.226e-02\n",
      "Epoch 33000, Train loss: 1.828e+08, Test loss: 1.080e+11, MSE(e): 1.763e-02, MSE(pi1): 5.363e-01, MSE(pi2): 1.053e-02, MSE(pi3): 1.173e-02\n",
      "Epoch 33100, Train loss: 1.633e+08, Test loss: 1.092e+11, MSE(e): 1.604e-02, MSE(pi1): 1.692e-01, MSE(pi2): 9.688e-03, MSE(pi3): 1.242e-02\n",
      "Epoch 33200, Train loss: 1.696e+08, Test loss: 1.086e+11, MSE(e): 1.635e-02, MSE(pi1): 4.923e-01, MSE(pi2): 9.822e-03, MSE(pi3): 1.185e-02\n",
      "Epoch 33300, Train loss: 1.621e+08, Test loss: 1.089e+11, MSE(e): 1.590e-02, MSE(pi1): 1.956e-01, MSE(pi2): 9.618e-03, MSE(pi3): 1.150e-02\n",
      "Epoch 33400, Train loss: 1.651e+08, Test loss: 1.088e+11, MSE(e): 1.597e-02, MSE(pi1): 4.228e-01, MSE(pi2): 9.700e-03, MSE(pi3): 1.097e-02\n",
      "Epoch 33500, Train loss: 1.663e+08, Test loss: 1.091e+11, MSE(e): 1.595e-02, MSE(pi1): 5.479e-01, MSE(pi2): 9.628e-03, MSE(pi3): 1.334e-02\n",
      "Epoch 33600, Train loss: 1.619e+08, Test loss: 1.091e+11, MSE(e): 1.572e-02, MSE(pi1): 3.205e-01, MSE(pi2): 9.511e-03, MSE(pi3): 1.531e-02\n",
      "Epoch 33700, Train loss: 1.623e+08, Test loss: 1.089e+11, MSE(e): 1.601e-02, MSE(pi1): 9.610e-02, MSE(pi2): 9.644e-03, MSE(pi3): 1.303e-02\n",
      "Epoch 33800, Train loss: 1.612e+08, Test loss: 1.095e+11, MSE(e): 1.573e-02, MSE(pi1): 2.627e-01, MSE(pi2): 9.541e-03, MSE(pi3): 1.360e-02\n",
      "Epoch 33900, Train loss: 1.624e+08, Test loss: 1.096e+11, MSE(e): 1.570e-02, MSE(pi1): 3.888e-01, MSE(pi2): 9.481e-03, MSE(pi3): 1.510e-02\n",
      "Epoch 34000, Train loss: 1.683e+08, Test loss: 1.099e+11, MSE(e): 1.654e-02, MSE(pi1): 1.454e-01, MSE(pi2): 9.859e-03, MSE(pi3): 1.484e-02\n",
      "Epoch 34100, Train loss: 1.748e+08, Test loss: 1.085e+11, MSE(e): 1.718e-02, MSE(pi1): 1.881e-01, MSE(pi2): 1.023e-02, MSE(pi3): 1.134e-02\n",
      "Epoch 34200, Train loss: 1.873e+08, Test loss: 1.105e+11, MSE(e): 1.690e-02, MSE(pi1): 1.606e+00, MSE(pi2): 1.033e-02, MSE(pi3): 2.173e-02\n",
      "Epoch 34300, Train loss: 1.633e+08, Test loss: 1.092e+11, MSE(e): 1.576e-02, MSE(pi1): 4.528e-01, MSE(pi2): 9.507e-03, MSE(pi3): 1.193e-02\n",
      "Epoch 34400, Train loss: 1.769e+08, Test loss: 1.088e+11, MSE(e): 1.700e-02, MSE(pi1): 5.788e-01, MSE(pi2): 1.019e-02, MSE(pi3): 1.066e-02\n",
      "Epoch 34500, Train loss: 1.584e+08, Test loss: 1.099e+11, MSE(e): 1.532e-02, MSE(pi1): 4.107e-01, MSE(pi2): 9.265e-03, MSE(pi3): 1.074e-02\n",
      "Epoch 34600, Train loss: 1.541e+08, Test loss: 1.097e+11, MSE(e): 1.518e-02, MSE(pi1): 1.035e-01, MSE(pi2): 9.194e-03, MSE(pi3): 1.242e-02\n",
      "Epoch 34700, Train loss: 1.640e+08, Test loss: 1.099e+11, MSE(e): 1.540e-02, MSE(pi1): 8.810e-01, MSE(pi2): 9.275e-03, MSE(pi3): 1.093e-02\n",
      "Epoch 34800, Train loss: 1.532e+08, Test loss: 1.097e+11, MSE(e): 1.510e-02, MSE(pi1): 1.113e-01, MSE(pi2): 9.151e-03, MSE(pi3): 1.110e-02\n",
      "Epoch 34900, Train loss: 1.614e+08, Test loss: 1.103e+11, MSE(e): 1.528e-02, MSE(pi1): 7.278e-01, MSE(pi2): 9.196e-03, MSE(pi3): 1.259e-02\n",
      "Epoch 35000, Train loss: 1.586e+08, Test loss: 1.106e+11, MSE(e): 1.552e-02, MSE(pi1): 2.376e-01, MSE(pi2): 9.322e-03, MSE(pi3): 1.098e-02\n",
      "Epoch 35100, Train loss: 1.545e+08, Test loss: 1.106e+11, MSE(e): 1.515e-02, MSE(pi1): 1.681e-01, MSE(pi2): 9.157e-03, MSE(pi3): 1.307e-02\n",
      "Epoch 35200, Train loss: 1.526e+08, Test loss: 1.102e+11, MSE(e): 1.486e-02, MSE(pi1): 2.852e-01, MSE(pi2): 9.001e-03, MSE(pi3): 1.174e-02\n",
      "Epoch 35300, Train loss: 1.501e+08, Test loss: 1.103e+11, MSE(e): 1.481e-02, MSE(pi1): 7.378e-02, MSE(pi2): 8.978e-03, MSE(pi3): 1.229e-02\n",
      "Epoch 35400, Train loss: 1.516e+08, Test loss: 1.105e+11, MSE(e): 1.476e-02, MSE(pi1): 2.401e-01, MSE(pi2): 8.947e-03, MSE(pi3): 1.644e-02\n",
      "Epoch 35500, Train loss: 1.528e+08, Test loss: 1.103e+11, MSE(e): 1.477e-02, MSE(pi1): 4.038e-01, MSE(pi2): 8.966e-03, MSE(pi3): 1.075e-02\n",
      "Epoch 35600, Train loss: 1.534e+08, Test loss: 1.104e+11, MSE(e): 1.470e-02, MSE(pi1): 4.964e-01, MSE(pi2): 8.907e-03, MSE(pi3): 1.375e-02\n",
      "Epoch 35700, Train loss: 1.598e+08, Test loss: 1.100e+11, MSE(e): 1.519e-02, MSE(pi1): 6.044e-01, MSE(pi2): 9.206e-03, MSE(pi3): 1.890e-02\n",
      "Epoch 35800, Train loss: 1.511e+08, Test loss: 1.111e+11, MSE(e): 1.491e-02, MSE(pi1): 7.277e-02, MSE(pi2): 8.984e-03, MSE(pi3): 1.293e-02\n",
      "Epoch 35900, Train loss: 1.580e+08, Test loss: 1.106e+11, MSE(e): 1.460e-02, MSE(pi1): 1.074e+00, MSE(pi2): 8.827e-03, MSE(pi3): 1.263e-02\n",
      "Epoch 36000, Train loss: 1.503e+08, Test loss: 1.102e+11, MSE(e): 1.480e-02, MSE(pi1): 1.165e-01, MSE(pi2): 8.958e-03, MSE(pi3): 1.088e-02\n",
      "Epoch 36100, Train loss: 1.626e+08, Test loss: 1.107e+11, MSE(e): 1.550e-02, MSE(pi1): 4.448e-01, MSE(pi2): 9.390e-03, MSE(pi3): 3.219e-02\n",
      "Epoch 36200, Train loss: 1.514e+08, Test loss: 1.110e+11, MSE(e): 1.465e-02, MSE(pi1): 3.495e-01, MSE(pi2): 8.814e-03, MSE(pi3): 1.492e-02\n",
      "Epoch 36300, Train loss: 1.452e+08, Test loss: 1.109e+11, MSE(e): 1.432e-02, MSE(pi1): 8.357e-02, MSE(pi2): 8.690e-03, MSE(pi3): 1.184e-02\n",
      "Epoch 36400, Train loss: 1.594e+08, Test loss: 1.110e+11, MSE(e): 1.442e-02, MSE(pi1): 1.329e+00, MSE(pi2): 8.711e-03, MSE(pi3): 1.921e-02\n",
      "Epoch 36500, Train loss: 1.477e+08, Test loss: 1.113e+11, MSE(e): 1.437e-02, MSE(pi1): 2.728e-01, MSE(pi2): 8.692e-03, MSE(pi3): 1.300e-02\n",
      "Epoch 36600, Train loss: 1.467e+08, Test loss: 1.111e+11, MSE(e): 1.423e-02, MSE(pi1): 2.155e-01, MSE(pi2): 8.637e-03, MSE(pi3): 2.238e-02\n",
      "Epoch 36700, Train loss: 1.497e+08, Test loss: 1.117e+11, MSE(e): 1.440e-02, MSE(pi1): 4.632e-01, MSE(pi2): 8.690e-03, MSE(pi3): 1.050e-02\n",
      "Epoch 36800, Train loss: 1.634e+08, Test loss: 1.113e+11, MSE(e): 1.429e-02, MSE(pi1): 1.817e+00, MSE(pi2): 8.611e-03, MSE(pi3): 2.304e-02\n",
      "Epoch 36900, Train loss: 1.431e+08, Test loss: 1.111e+11, MSE(e): 1.406e-02, MSE(pi1): 1.155e-01, MSE(pi2): 8.533e-03, MSE(pi3): 1.329e-02\n",
      "Epoch 37000, Train loss: 1.528e+08, Test loss: 1.120e+11, MSE(e): 1.508e-02, MSE(pi1): 7.915e-02, MSE(pi2): 8.988e-03, MSE(pi3): 1.215e-02\n",
      "Epoch 37100, Train loss: 1.605e+08, Test loss: 1.118e+11, MSE(e): 1.452e-02, MSE(pi1): 1.332e+00, MSE(pi2): 8.847e-03, MSE(pi3): 2.058e-02\n",
      "Epoch 37200, Train loss: 1.454e+08, Test loss: 1.117e+11, MSE(e): 1.430e-02, MSE(pi1): 1.279e-01, MSE(pi2): 8.621e-03, MSE(pi3): 1.163e-02\n",
      "Epoch 37300, Train loss: 1.494e+08, Test loss: 1.116e+11, MSE(e): 1.400e-02, MSE(pi1): 7.784e-01, MSE(pi2): 8.484e-03, MSE(pi3): 1.589e-02\n",
      "Epoch 37400, Train loss: 1.518e+08, Test loss: 1.115e+11, MSE(e): 1.395e-02, MSE(pi1): 1.111e+00, MSE(pi2): 8.439e-03, MSE(pi3): 1.181e-02\n",
      "Epoch 37500, Train loss: 1.406e+08, Test loss: 1.115e+11, MSE(e): 1.386e-02, MSE(pi1): 9.040e-02, MSE(pi2): 8.403e-03, MSE(pi3): 1.112e-02\n",
      "Epoch 37600, Train loss: 1.422e+08, Test loss: 1.116e+11, MSE(e): 1.380e-02, MSE(pi1): 3.069e-01, MSE(pi2): 8.374e-03, MSE(pi3): 1.105e-02\n",
      "Epoch 37700, Train loss: 1.427e+08, Test loss: 1.120e+11, MSE(e): 1.388e-02, MSE(pi1): 2.590e-01, MSE(pi2): 8.434e-03, MSE(pi3): 1.303e-02\n",
      "Epoch 37800, Train loss: 1.689e+08, Test loss: 1.128e+11, MSE(e): 1.663e-02, MSE(pi1): 1.524e-01, MSE(pi2): 9.662e-03, MSE(pi3): 1.073e-02\n",
      "Epoch 37900, Train loss: 1.495e+08, Test loss: 1.117e+11, MSE(e): 1.381e-02, MSE(pi1): 9.796e-01, MSE(pi2): 8.385e-03, MSE(pi3): 1.586e-02\n",
      "Epoch 38000, Train loss: 1.445e+08, Test loss: 1.113e+11, MSE(e): 1.415e-02, MSE(pi1): 1.930e-01, MSE(pi2): 8.561e-03, MSE(pi3): 1.060e-02\n",
      "Epoch 38100, Train loss: 1.428e+08, Test loss: 1.115e+11, MSE(e): 1.393e-02, MSE(pi1): 2.053e-01, MSE(pi2): 8.409e-03, MSE(pi3): 1.510e-02\n",
      "Epoch 38200, Train loss: 1.422e+08, Test loss: 1.116e+11, MSE(e): 1.395e-02, MSE(pi1): 1.580e-01, MSE(pi2): 8.420e-03, MSE(pi3): 1.130e-02\n",
      "Epoch 38300, Train loss: 1.606e+08, Test loss: 1.126e+11, MSE(e): 1.571e-02, MSE(pi1): 2.132e-01, MSE(pi2): 9.129e-03, MSE(pi3): 1.395e-02\n",
      "Epoch 38400, Train loss: 1.425e+08, Test loss: 1.120e+11, MSE(e): 1.359e-02, MSE(pi1): 5.437e-01, MSE(pi2): 8.276e-03, MSE(pi3): 1.148e-02\n",
      "Epoch 38500, Train loss: 1.359e+08, Test loss: 1.122e+11, MSE(e): 1.338e-02, MSE(pi1): 8.644e-02, MSE(pi2): 8.124e-03, MSE(pi3): 1.211e-02\n",
      "Epoch 38600, Train loss: 1.403e+08, Test loss: 1.121e+11, MSE(e): 1.348e-02, MSE(pi1): 3.219e-01, MSE(pi2): 8.169e-03, MSE(pi3): 2.221e-02\n",
      "Epoch 38700, Train loss: 1.652e+08, Test loss: 1.128e+11, MSE(e): 1.624e-02, MSE(pi1): 1.326e-01, MSE(pi2): 9.359e-03, MSE(pi3): 1.396e-02\n",
      "Epoch 38800, Train loss: 1.355e+08, Test loss: 1.124e+11, MSE(e): 1.328e-02, MSE(pi1): 1.630e-01, MSE(pi2): 8.062e-03, MSE(pi3): 1.061e-02\n",
      "Epoch 38900, Train loss: 1.543e+08, Test loss: 1.131e+11, MSE(e): 1.404e-02, MSE(pi1): 1.175e+00, MSE(pi2): 8.384e-03, MSE(pi3): 2.090e-02\n",
      "Epoch 39000, Train loss: 1.461e+08, Test loss: 1.119e+11, MSE(e): 1.439e-02, MSE(pi1): 1.147e-01, MSE(pi2): 8.588e-03, MSE(pi3): 1.058e-02\n",
      "Epoch 39100, Train loss: 1.584e+08, Test loss: 1.133e+11, MSE(e): 1.385e-02, MSE(pi1): 1.873e+00, MSE(pi2): 8.271e-03, MSE(pi3): 1.199e-02\n",
      "Epoch 39200, Train loss: 1.334e+08, Test loss: 1.126e+11, MSE(e): 1.315e-02, MSE(pi1): 7.142e-02, MSE(pi2): 7.981e-03, MSE(pi3): 1.121e-02\n",
      "Epoch 39300, Train loss: 1.364e+08, Test loss: 1.129e+11, MSE(e): 1.324e-02, MSE(pi1): 2.983e-01, MSE(pi2): 8.015e-03, MSE(pi3): 1.053e-02\n",
      "Epoch 39400, Train loss: 1.356e+08, Test loss: 1.126e+11, MSE(e): 1.311e-02, MSE(pi1): 3.430e-01, MSE(pi2): 7.956e-03, MSE(pi3): 1.071e-02\n",
      "Epoch 39500, Train loss: 1.333e+08, Test loss: 1.133e+11, MSE(e): 1.314e-02, MSE(pi1): 7.977e-02, MSE(pi2): 7.948e-03, MSE(pi3): 1.091e-02\n",
      "Epoch 39600, Train loss: 1.568e+08, Test loss: 1.119e+11, MSE(e): 1.510e-02, MSE(pi1): 4.756e-01, MSE(pi2): 8.843e-03, MSE(pi3): 1.025e-02\n",
      "Epoch 39700, Train loss: 1.369e+08, Test loss: 1.129e+11, MSE(e): 1.316e-02, MSE(pi1): 3.920e-01, MSE(pi2): 7.970e-03, MSE(pi3): 1.356e-02\n",
      "Epoch 39800, Train loss: 1.345e+08, Test loss: 1.130e+11, MSE(e): 1.291e-02, MSE(pi1): 4.148e-01, MSE(pi2): 7.824e-03, MSE(pi3): 1.235e-02\n",
      "Epoch 39900, Train loss: 1.312e+08, Test loss: 1.131e+11, MSE(e): 1.286e-02, MSE(pi1): 1.492e-01, MSE(pi2): 7.805e-03, MSE(pi3): 1.059e-02\n",
      "Epoch 40000, Train loss: 1.305e+08, Test loss: 1.134e+11, MSE(e): 1.285e-02, MSE(pi1): 7.820e-02, MSE(pi2): 7.786e-03, MSE(pi3): 1.190e-02\n",
      "Epoch 40100, Train loss: 1.323e+08, Test loss: 1.137e+11, MSE(e): 1.301e-02, MSE(pi1): 9.454e-02, MSE(pi2): 7.865e-03, MSE(pi3): 1.187e-02\n",
      "Epoch 40200, Train loss: 1.422e+08, Test loss: 1.133e+11, MSE(e): 1.285e-02, MSE(pi1): 1.260e+00, MSE(pi2): 7.754e-03, MSE(pi3): 1.099e-02\n",
      "Epoch 40300, Train loss: 1.292e+08, Test loss: 1.135e+11, MSE(e): 1.273e-02, MSE(pi1): 6.940e-02, MSE(pi2): 7.718e-03, MSE(pi3): 1.121e-02\n",
      "Epoch 40400, Train loss: 1.353e+08, Test loss: 1.131e+11, MSE(e): 1.286e-02, MSE(pi1): 5.121e-01, MSE(pi2): 7.814e-03, MSE(pi3): 1.565e-02\n",
      "Epoch 40500, Train loss: 1.303e+08, Test loss: 1.137e+11, MSE(e): 1.275e-02, MSE(pi1): 1.531e-01, MSE(pi2): 7.726e-03, MSE(pi3): 1.243e-02\n",
      "Epoch 40600, Train loss: 1.285e+08, Test loss: 1.134e+11, MSE(e): 1.261e-02, MSE(pi1): 1.344e-01, MSE(pi2): 7.653e-03, MSE(pi3): 1.042e-02\n",
      "Epoch 40700, Train loss: 1.295e+08, Test loss: 1.134e+11, MSE(e): 1.259e-02, MSE(pi1): 2.572e-01, MSE(pi2): 7.627e-03, MSE(pi3): 1.063e-02\n",
      "Epoch 40800, Train loss: 1.346e+08, Test loss: 1.143e+11, MSE(e): 1.318e-02, MSE(pi1): 1.719e-01, MSE(pi2): 7.920e-03, MSE(pi3): 1.046e-02\n",
      "Epoch 40900, Train loss: 1.472e+08, Test loss: 1.126e+11, MSE(e): 1.437e-02, MSE(pi1): 2.367e-01, MSE(pi2): 8.632e-03, MSE(pi3): 1.111e-02\n",
      "Epoch 41000, Train loss: 1.310e+08, Test loss: 1.135e+11, MSE(e): 1.270e-02, MSE(pi1): 2.328e-01, MSE(pi2): 7.682e-03, MSE(pi3): 1.721e-02\n",
      "Epoch 41100, Train loss: 1.271e+08, Test loss: 1.137e+11, MSE(e): 1.246e-02, MSE(pi1): 1.285e-01, MSE(pi2): 7.563e-03, MSE(pi3): 1.158e-02\n",
      "Epoch 41200, Train loss: 1.329e+08, Test loss: 1.142e+11, MSE(e): 1.259e-02, MSE(pi1): 4.537e-01, MSE(pi2): 7.546e-03, MSE(pi3): 2.428e-02\n",
      "Epoch 41300, Train loss: 1.277e+08, Test loss: 1.137e+11, MSE(e): 1.256e-02, MSE(pi1): 1.127e-01, MSE(pi2): 7.581e-03, MSE(pi3): 1.054e-02\n",
      "Epoch 41400, Train loss: 1.285e+08, Test loss: 1.141e+11, MSE(e): 1.233e-02, MSE(pi1): 3.854e-01, MSE(pi2): 7.465e-03, MSE(pi3): 1.310e-02\n",
      "Epoch 41500, Train loss: 1.253e+08, Test loss: 1.140e+11, MSE(e): 1.230e-02, MSE(pi1): 1.142e-01, MSE(pi2): 7.464e-03, MSE(pi3): 1.179e-02\n",
      "Epoch 41600, Train loss: 1.284e+08, Test loss: 1.140e+11, MSE(e): 1.241e-02, MSE(pi1): 3.283e-01, MSE(pi2): 7.495e-03, MSE(pi3): 1.085e-02\n",
      "Epoch 41700, Train loss: 1.241e+08, Test loss: 1.143e+11, MSE(e): 1.222e-02, MSE(pi1): 7.093e-02, MSE(pi2): 7.399e-03, MSE(pi3): 1.238e-02\n",
      "Epoch 41800, Train loss: 1.242e+08, Test loss: 1.144e+11, MSE(e): 1.220e-02, MSE(pi1): 1.041e-01, MSE(pi2): 7.391e-03, MSE(pi3): 1.110e-02\n",
      "Epoch 41900, Train loss: 1.311e+08, Test loss: 1.143e+11, MSE(e): 1.235e-02, MSE(pi1): 5.416e-01, MSE(pi2): 7.495e-03, MSE(pi3): 2.186e-02\n",
      "Epoch 42000, Train loss: 1.289e+08, Test loss: 1.143e+11, MSE(e): 1.217e-02, MSE(pi1): 6.212e-01, MSE(pi2): 7.370e-03, MSE(pi3): 9.867e-03\n",
      "Epoch 42100, Train loss: 1.292e+08, Test loss: 1.142e+11, MSE(e): 1.249e-02, MSE(pi1): 3.085e-01, MSE(pi2): 7.531e-03, MSE(pi3): 1.258e-02\n",
      "Epoch 42200, Train loss: 1.220e+08, Test loss: 1.146e+11, MSE(e): 1.203e-02, MSE(pi1): 6.354e-02, MSE(pi2): 7.288e-03, MSE(pi3): 1.083e-02\n",
      "Epoch 42300, Train loss: 1.327e+08, Test loss: 1.144e+11, MSE(e): 1.251e-02, MSE(pi1): 6.163e-01, MSE(pi2): 7.543e-03, MSE(pi3): 1.456e-02\n",
      "Epoch 42400, Train loss: 1.296e+08, Test loss: 1.146e+11, MSE(e): 1.202e-02, MSE(pi1): 8.273e-01, MSE(pi2): 7.262e-03, MSE(pi3): 1.105e-02\n",
      "Epoch 42500, Train loss: 1.883e+08, Test loss: 1.132e+11, MSE(e): 1.860e-02, MSE(pi1): 1.244e-01, MSE(pi2): 1.040e-02, MSE(pi3): 1.035e-02\n",
      "Epoch 42600, Train loss: 1.281e+08, Test loss: 1.145e+11, MSE(e): 1.210e-02, MSE(pi1): 6.221e-01, MSE(pi2): 7.343e-03, MSE(pi3): 9.352e-03\n",
      "Epoch 42700, Train loss: 1.211e+08, Test loss: 1.147e+11, MSE(e): 1.191e-02, MSE(pi1): 1.036e-01, MSE(pi2): 7.219e-03, MSE(pi3): 9.921e-03\n",
      "Epoch 42800, Train loss: 1.233e+08, Test loss: 1.148e+11, MSE(e): 1.185e-02, MSE(pi1): 3.536e-01, MSE(pi2): 7.176e-03, MSE(pi3): 1.178e-02\n",
      "Epoch 42900, Train loss: 1.219e+08, Test loss: 1.146e+11, MSE(e): 1.188e-02, MSE(pi1): 1.856e-01, MSE(pi2): 7.189e-03, MSE(pi3): 1.206e-02\n",
      "Epoch 43000, Train loss: 1.225e+08, Test loss: 1.149e+11, MSE(e): 1.191e-02, MSE(pi1): 2.278e-01, MSE(pi2): 7.199e-03, MSE(pi3): 1.074e-02\n",
      "Epoch 43100, Train loss: 1.228e+08, Test loss: 1.152e+11, MSE(e): 1.203e-02, MSE(pi1): 7.743e-02, MSE(pi2): 7.311e-03, MSE(pi3): 1.772e-02\n",
      "Epoch 43200, Train loss: 1.198e+08, Test loss: 1.151e+11, MSE(e): 1.172e-02, MSE(pi1): 1.510e-01, MSE(pi2): 7.097e-03, MSE(pi3): 1.056e-02\n",
      "Epoch 43300, Train loss: 1.197e+08, Test loss: 1.154e+11, MSE(e): 1.178e-02, MSE(pi1): 7.349e-02, MSE(pi2): 7.124e-03, MSE(pi3): 1.103e-02\n",
      "Epoch 43400, Train loss: 1.244e+08, Test loss: 1.154e+11, MSE(e): 1.198e-02, MSE(pi1): 3.553e-01, MSE(pi2): 7.201e-03, MSE(pi3): 1.052e-02\n",
      "Epoch 43500, Train loss: 1.201e+08, Test loss: 1.148e+11, MSE(e): 1.178e-02, MSE(pi1): 1.310e-01, MSE(pi2): 7.123e-03, MSE(pi3): 1.002e-02\n",
      "Epoch 43600, Train loss: 1.250e+08, Test loss: 1.147e+11, MSE(e): 1.205e-02, MSE(pi1): 3.471e-01, MSE(pi2): 7.275e-03, MSE(pi3): 1.029e-02\n",
      "Epoch 43700, Train loss: 1.330e+08, Test loss: 1.145e+11, MSE(e): 1.306e-02, MSE(pi1): 1.427e-01, MSE(pi2): 7.676e-03, MSE(pi3): 9.849e-03\n",
      "Epoch 43800, Train loss: 1.185e+08, Test loss: 1.153e+11, MSE(e): 1.152e-02, MSE(pi1): 1.903e-01, MSE(pi2): 6.972e-03, MSE(pi3): 1.378e-02\n",
      "Epoch 43900, Train loss: 1.182e+08, Test loss: 1.154e+11, MSE(e): 1.152e-02, MSE(pi1): 1.809e-01, MSE(pi2): 6.962e-03, MSE(pi3): 1.204e-02\n",
      "Epoch 44000, Train loss: 1.200e+08, Test loss: 1.153e+11, MSE(e): 1.153e-02, MSE(pi1): 3.731e-01, MSE(pi2): 6.990e-03, MSE(pi3): 9.938e-03\n",
      "Epoch 44100, Train loss: 1.172e+08, Test loss: 1.156e+11, MSE(e): 1.150e-02, MSE(pi1): 9.672e-02, MSE(pi2): 6.944e-03, MSE(pi3): 1.262e-02\n",
      "Epoch 44200, Train loss: 1.227e+08, Test loss: 1.160e+11, MSE(e): 1.180e-02, MSE(pi1): 3.283e-01, MSE(pi2): 7.125e-03, MSE(pi3): 1.395e-02\n",
      "Epoch 44300, Train loss: 1.182e+08, Test loss: 1.154e+11, MSE(e): 1.152e-02, MSE(pi1): 2.024e-01, MSE(pi2): 6.952e-03, MSE(pi3): 1.007e-02\n",
      "Epoch 44400, Train loss: 1.208e+08, Test loss: 1.154e+11, MSE(e): 1.169e-02, MSE(pi1): 2.917e-01, MSE(pi2): 7.134e-03, MSE(pi3): 9.901e-03\n",
      "Epoch 44500, Train loss: 1.228e+08, Test loss: 1.155e+11, MSE(e): 1.153e-02, MSE(pi1): 6.541e-01, MSE(pi2): 7.012e-03, MSE(pi3): 9.610e-03\n",
      "Epoch 44600, Train loss: 1.176e+08, Test loss: 1.154e+11, MSE(e): 1.147e-02, MSE(pi1): 1.818e-01, MSE(pi2): 6.924e-03, MSE(pi3): 1.041e-02\n",
      "Epoch 44700, Train loss: 1.250e+08, Test loss: 1.157e+11, MSE(e): 1.165e-02, MSE(pi1): 5.980e-01, MSE(pi2): 7.071e-03, MSE(pi3): 2.514e-02\n",
      "Epoch 44800, Train loss: 1.705e+08, Test loss: 1.172e+11, MSE(e): 1.662e-02, MSE(pi1): 2.019e-01, MSE(pi2): 9.443e-03, MSE(pi3): 2.239e-02\n",
      "Epoch 44900, Train loss: 1.148e+08, Test loss: 1.158e+11, MSE(e): 1.117e-02, MSE(pi1): 2.115e-01, MSE(pi2): 6.752e-03, MSE(pi3): 1.003e-02\n",
      "Epoch 45000, Train loss: 1.354e+08, Test loss: 1.166e+11, MSE(e): 1.213e-02, MSE(pi1): 1.067e+00, MSE(pi2): 7.122e-03, MSE(pi3): 3.418e-02\n",
      "Epoch 45100, Train loss: 1.226e+08, Test loss: 1.152e+11, MSE(e): 1.205e-02, MSE(pi1): 1.147e-01, MSE(pi2): 7.263e-03, MSE(pi3): 9.790e-03\n",
      "Epoch 45200, Train loss: 1.166e+08, Test loss: 1.156e+11, MSE(e): 1.144e-02, MSE(pi1): 1.195e-01, MSE(pi2): 6.867e-03, MSE(pi3): 1.038e-02\n",
      "Epoch 45300, Train loss: 1.267e+08, Test loss: 1.168e+11, MSE(e): 1.221e-02, MSE(pi1): 3.533e-01, MSE(pi2): 7.200e-03, MSE(pi3): 1.069e-02\n",
      "Epoch 45400, Train loss: 1.217e+08, Test loss: 1.168e+11, MSE(e): 1.179e-02, MSE(pi1): 2.511e-01, MSE(pi2): 7.059e-03, MSE(pi3): 1.315e-02\n",
      "Epoch 45500, Train loss: 1.196e+08, Test loss: 1.159e+11, MSE(e): 1.131e-02, MSE(pi1): 4.617e-01, MSE(pi2): 6.848e-03, MSE(pi3): 1.950e-02\n",
      "Epoch 45600, Train loss: 1.124e+08, Test loss: 1.163e+11, MSE(e): 1.105e-02, MSE(pi1): 8.346e-02, MSE(pi2): 6.655e-03, MSE(pi3): 1.095e-02\n",
      "Epoch 45700, Train loss: 1.174e+08, Test loss: 1.163e+11, MSE(e): 1.120e-02, MSE(pi1): 3.479e-01, MSE(pi2): 6.713e-03, MSE(pi3): 1.843e-02\n",
      "Epoch 45800, Train loss: 1.234e+08, Test loss: 1.156e+11, MSE(e): 1.186e-02, MSE(pi1): 2.356e-01, MSE(pi2): 7.268e-03, MSE(pi3): 2.368e-02\n",
      "Epoch 45900, Train loss: 1.129e+08, Test loss: 1.162e+11, MSE(e): 1.105e-02, MSE(pi1): 1.437e-01, MSE(pi2): 6.707e-03, MSE(pi3): 9.853e-03\n",
      "Epoch 46000, Train loss: 1.152e+08, Test loss: 1.163e+11, MSE(e): 1.088e-02, MSE(pi1): 5.231e-01, MSE(pi2): 6.568e-03, MSE(pi3): 1.155e-02\n",
      "Epoch 46100, Train loss: 1.238e+08, Test loss: 1.169e+11, MSE(e): 1.138e-02, MSE(pi1): 7.641e-01, MSE(pi2): 6.761e-03, MSE(pi3): 2.373e-02\n",
      "Epoch 46200, Train loss: 1.174e+08, Test loss: 1.160e+11, MSE(e): 1.147e-02, MSE(pi1): 1.651e-01, MSE(pi2): 6.850e-03, MSE(pi3): 1.043e-02\n",
      "Epoch 46300, Train loss: 1.226e+08, Test loss: 1.173e+11, MSE(e): 1.188e-02, MSE(pi1): 2.057e-01, MSE(pi2): 7.188e-03, MSE(pi3): 1.702e-02\n",
      "Epoch 46400, Train loss: 1.218e+08, Test loss: 1.174e+11, MSE(e): 1.161e-02, MSE(pi1): 3.983e-01, MSE(pi2): 6.870e-03, MSE(pi3): 1.688e-02\n",
      "Epoch 46500, Train loss: 1.242e+08, Test loss: 1.162e+11, MSE(e): 1.158e-02, MSE(pi1): 6.304e-01, MSE(pi2): 7.069e-03, MSE(pi3): 2.109e-02\n",
      "Epoch 46600, Train loss: 1.095e+08, Test loss: 1.170e+11, MSE(e): 1.076e-02, MSE(pi1): 7.021e-02, MSE(pi2): 6.478e-03, MSE(pi3): 1.181e-02\n",
      "Epoch 46700, Train loss: 1.133e+08, Test loss: 1.161e+11, MSE(e): 1.106e-02, MSE(pi1): 1.858e-01, MSE(pi2): 6.667e-03, MSE(pi3): 8.941e-03\n",
      "Epoch 46800, Train loss: 1.174e+08, Test loss: 1.164e+11, MSE(e): 1.085e-02, MSE(pi1): 6.096e-01, MSE(pi2): 6.558e-03, MSE(pi3): 2.860e-02\n",
      "Epoch 46900, Train loss: 1.315e+08, Test loss: 1.162e+11, MSE(e): 1.296e-02, MSE(pi1): 9.079e-02, MSE(pi2): 7.519e-03, MSE(pi3): 9.737e-03\n",
      "Epoch 47000, Train loss: 1.084e+08, Test loss: 1.169e+11, MSE(e): 1.059e-02, MSE(pi1): 1.455e-01, MSE(pi2): 6.395e-03, MSE(pi3): 1.059e-02\n",
      "Epoch 47100, Train loss: 1.199e+08, Test loss: 1.167e+11, MSE(e): 1.073e-02, MSE(pi1): 8.668e-01, MSE(pi2): 6.446e-03, MSE(pi3): 3.901e-02\n",
      "Epoch 47200, Train loss: 1.098e+08, Test loss: 1.165e+11, MSE(e): 1.079e-02, MSE(pi1): 9.761e-02, MSE(pi2): 6.498e-03, MSE(pi3): 9.025e-03\n",
      "Epoch 47300, Train loss: 1.088e+08, Test loss: 1.169e+11, MSE(e): 1.056e-02, MSE(pi1): 2.007e-01, MSE(pi2): 6.355e-03, MSE(pi3): 1.130e-02\n",
      "Epoch 47400, Train loss: 1.134e+08, Test loss: 1.165e+11, MSE(e): 1.097e-02, MSE(pi1): 2.559e-01, MSE(pi2): 6.539e-03, MSE(pi3): 1.183e-02\n",
      "Epoch 47500, Train loss: 1.084e+08, Test loss: 1.169e+11, MSE(e): 1.043e-02, MSE(pi1): 3.152e-01, MSE(pi2): 6.284e-03, MSE(pi3): 1.001e-02\n",
      "Epoch 47600, Train loss: 1.057e+08, Test loss: 1.170e+11, MSE(e): 1.039e-02, MSE(pi1): 7.648e-02, MSE(pi2): 6.272e-03, MSE(pi3): 1.046e-02\n",
      "Epoch 47700, Train loss: 1.160e+08, Test loss: 1.168e+11, MSE(e): 1.069e-02, MSE(pi1): 8.243e-01, MSE(pi2): 6.408e-03, MSE(pi3): 8.488e-03\n",
      "Epoch 47800, Train loss: 1.060e+08, Test loss: 1.170e+11, MSE(e): 1.042e-02, MSE(pi1): 8.983e-02, MSE(pi2): 6.309e-03, MSE(pi3): 9.115e-03\n",
      "Epoch 47900, Train loss: 1.350e+08, Test loss: 1.160e+11, MSE(e): 1.267e-02, MSE(pi1): 7.363e-01, MSE(pi2): 7.373e-03, MSE(pi3): 9.172e-03\n",
      "Epoch 48000, Train loss: 1.153e+08, Test loss: 1.174e+11, MSE(e): 1.110e-02, MSE(pi1): 3.456e-01, MSE(pi2): 6.658e-03, MSE(pi3): 8.785e-03\n",
      "Epoch 48100, Train loss: 1.046e+08, Test loss: 1.172e+11, MSE(e): 1.027e-02, MSE(pi1): 9.531e-02, MSE(pi2): 6.201e-03, MSE(pi3): 9.275e-03\n",
      "Epoch 48200, Train loss: 1.357e+08, Test loss: 1.185e+11, MSE(e): 1.306e-02, MSE(pi1): 3.708e-01, MSE(pi2): 7.576e-03, MSE(pi3): 1.438e-02\n",
      "Epoch 48300, Train loss: 1.233e+08, Test loss: 1.170e+11, MSE(e): 1.065e-02, MSE(pi1): 1.572e+00, MSE(pi2): 6.358e-03, MSE(pi3): 1.042e-02\n",
      "Epoch 48400, Train loss: 1.091e+08, Test loss: 1.168e+11, MSE(e): 1.057e-02, MSE(pi1): 2.320e-01, MSE(pi2): 6.390e-03, MSE(pi3): 1.024e-02\n",
      "Epoch 48500, Train loss: 1.099e+08, Test loss: 1.173e+11, MSE(e): 1.045e-02, MSE(pi1): 3.529e-01, MSE(pi2): 6.306e-03, MSE(pi3): 1.938e-02\n",
      "Epoch 48600, Train loss: 1.030e+08, Test loss: 1.175e+11, MSE(e): 1.013e-02, MSE(pi1): 6.762e-02, MSE(pi2): 6.108e-03, MSE(pi3): 1.047e-02\n",
      "Epoch 48700, Train loss: 1.171e+08, Test loss: 1.178e+11, MSE(e): 1.062e-02, MSE(pi1): 8.970e-01, MSE(pi2): 6.459e-03, MSE(pi3): 1.939e-02\n",
      "Epoch 48800, Train loss: 1.109e+08, Test loss: 1.172e+11, MSE(e): 1.049e-02, MSE(pi1): 4.426e-01, MSE(pi2): 6.337e-03, MSE(pi3): 1.529e-02\n",
      "Epoch 48900, Train loss: 1.290e+08, Test loss: 1.188e+11, MSE(e): 1.257e-02, MSE(pi1): 1.667e-01, MSE(pi2): 7.299e-03, MSE(pi3): 1.538e-02\n",
      "Epoch 49000, Train loss: 1.108e+08, Test loss: 1.170e+11, MSE(e): 1.074e-02, MSE(pi1): 2.417e-01, MSE(pi2): 6.461e-03, MSE(pi3): 1.041e-02\n",
      "Epoch 49100, Train loss: 1.072e+08, Test loss: 1.176e+11, MSE(e): 1.032e-02, MSE(pi1): 3.111e-01, MSE(pi2): 6.240e-03, MSE(pi3): 8.431e-03\n",
      "Epoch 49200, Train loss: 1.271e+08, Test loss: 1.167e+11, MSE(e): 1.144e-02, MSE(pi1): 8.993e-01, MSE(pi2): 6.803e-03, MSE(pi3): 3.749e-02\n",
      "Epoch 49300, Train loss: 1.032e+08, Test loss: 1.181e+11, MSE(e): 1.015e-02, MSE(pi1): 5.723e-02, MSE(pi2): 6.085e-03, MSE(pi3): 1.052e-02\n",
      "Epoch 49400, Train loss: 1.011e+08, Test loss: 1.177e+11, MSE(e): 9.903e-03, MSE(pi1): 1.108e-01, MSE(pi2): 5.966e-03, MSE(pi3): 1.002e-02\n",
      "Epoch 49500, Train loss: 1.178e+08, Test loss: 1.184e+11, MSE(e): 1.124e-02, MSE(pi1): 4.137e-01, MSE(pi2): 6.683e-03, MSE(pi3): 1.299e-02\n",
      "Epoch 49600, Train loss: 1.033e+08, Test loss: 1.180e+11, MSE(e): 9.990e-03, MSE(pi1): 2.065e-01, MSE(pi2): 6.030e-03, MSE(pi3): 1.365e-02\n",
      "Epoch 49700, Train loss: 1.006e+08, Test loss: 1.180e+11, MSE(e): 9.898e-03, MSE(pi1): 6.696e-02, MSE(pi2): 5.948e-03, MSE(pi3): 9.653e-03\n",
      "Epoch 49800, Train loss: 1.360e+08, Test loss: 1.192e+11, MSE(e): 1.318e-02, MSE(pi1): 2.079e-01, MSE(pi2): 7.847e-03, MSE(pi3): 2.086e-02\n",
      "Epoch 49900, Train loss: 1.042e+08, Test loss: 1.184e+11, MSE(e): 1.011e-02, MSE(pi1): 2.028e-01, MSE(pi2): 6.033e-03, MSE(pi3): 1.123e-02\n",
      "Epoch 50000, Train loss: 1.085e+08, Test loss: 1.176e+11, MSE(e): 1.060e-02, MSE(pi1): 1.386e-01, MSE(pi2): 6.489e-03, MSE(pi3): 1.094e-02\n",
      "Epoch 50100, Train loss: 1.085e+08, Test loss: 1.178e+11, MSE(e): 9.831e-03, MSE(pi1): 9.245e-01, MSE(pi2): 5.893e-03, MSE(pi3): 9.761e-03\n",
      "Epoch 50200, Train loss: 9.976e+07, Test loss: 1.180e+11, MSE(e): 9.745e-03, MSE(pi1): 1.352e-01, MSE(pi2): 5.867e-03, MSE(pi3): 9.618e-03\n",
      "Epoch 50300, Train loss: 1.051e+08, Test loss: 1.185e+11, MSE(e): 1.009e-02, MSE(pi1): 2.940e-01, MSE(pi2): 6.074e-03, MSE(pi3): 1.338e-02\n",
      "Epoch 50400, Train loss: 1.007e+08, Test loss: 1.180e+11, MSE(e): 9.672e-03, MSE(pi1): 2.713e-01, MSE(pi2): 5.813e-03, MSE(pi3): 1.294e-02\n",
      "Epoch 50500, Train loss: 9.988e+07, Test loss: 1.181e+11, MSE(e): 9.654e-03, MSE(pi1): 1.799e-01, MSE(pi2): 5.813e-03, MSE(pi3): 1.546e-02\n",
      "Epoch 50600, Train loss: 1.074e+08, Test loss: 1.187e+11, MSE(e): 1.045e-02, MSE(pi1): 1.501e-01, MSE(pi2): 6.223e-03, MSE(pi3): 1.402e-02\n",
      "Epoch 50700, Train loss: 1.045e+08, Test loss: 1.182e+11, MSE(e): 9.799e-03, MSE(pi1): 5.631e-01, MSE(pi2): 5.871e-03, MSE(pi3): 8.582e-03\n",
      "Epoch 50800, Train loss: 9.987e+07, Test loss: 1.178e+11, MSE(e): 9.794e-03, MSE(pi1): 1.003e-01, MSE(pi2): 5.930e-03, MSE(pi3): 9.283e-03\n",
      "Epoch 50900, Train loss: 9.830e+07, Test loss: 1.182e+11, MSE(e): 9.536e-03, MSE(pi1): 2.031e-01, MSE(pi2): 5.736e-03, MSE(pi3): 9.163e-03\n",
      "Epoch 51000, Train loss: 1.039e+08, Test loss: 1.180e+11, MSE(e): 9.647e-03, MSE(pi1): 6.532e-01, MSE(pi2): 5.783e-03, MSE(pi3): 8.868e-03\n",
      "Epoch 51100, Train loss: 9.990e+07, Test loss: 1.185e+11, MSE(e): 9.606e-03, MSE(pi1): 1.594e-01, MSE(pi2): 5.743e-03, MSE(pi3): 2.250e-02\n",
      "Epoch 51200, Train loss: 1.058e+08, Test loss: 1.177e+11, MSE(e): 1.017e-02, MSE(pi1): 3.152e-01, MSE(pi2): 6.129e-03, MSE(pi3): 9.356e-03\n",
      "Epoch 51300, Train loss: 1.090e+08, Test loss: 1.176e+11, MSE(e): 1.046e-02, MSE(pi1): 3.445e-01, MSE(pi2): 6.349e-03, MSE(pi3): 9.240e-03\n",
      "Epoch 51400, Train loss: 1.012e+08, Test loss: 1.178e+11, MSE(e): 9.941e-03, MSE(pi1): 7.144e-02, MSE(pi2): 6.020e-03, MSE(pi3): 1.027e-02\n",
      "Epoch 51500, Train loss: 1.024e+08, Test loss: 1.187e+11, MSE(e): 9.748e-03, MSE(pi1): 3.842e-01, MSE(pi2): 5.900e-03, MSE(pi3): 1.102e-02\n",
      "Epoch 51600, Train loss: 9.704e+07, Test loss: 1.186e+11, MSE(e): 9.477e-03, MSE(pi1): 1.262e-01, MSE(pi2): 5.674e-03, MSE(pi3): 1.008e-02\n",
      "Epoch 51700, Train loss: 1.504e+08, Test loss: 1.173e+11, MSE(e): 1.240e-02, MSE(pi1): 2.508e+00, MSE(pi2): 7.704e-03, MSE(pi3): 1.295e-02\n",
      "Epoch 51800, Train loss: 9.735e+07, Test loss: 1.183e+11, MSE(e): 9.566e-03, MSE(pi1): 7.782e-02, MSE(pi2): 5.780e-03, MSE(pi3): 9.134e-03\n",
      "Epoch 51900, Train loss: 9.600e+07, Test loss: 1.184e+11, MSE(e): 9.395e-03, MSE(pi1): 1.095e-01, MSE(pi2): 5.660e-03, MSE(pi3): 9.542e-03\n",
      "Epoch 52000, Train loss: 9.795e+07, Test loss: 1.188e+11, MSE(e): 9.467e-03, MSE(pi1): 2.157e-01, MSE(pi2): 5.665e-03, MSE(pi3): 1.127e-02\n",
      "Epoch 52100, Train loss: 9.591e+07, Test loss: 1.186e+11, MSE(e): 9.310e-03, MSE(pi1): 1.855e-01, MSE(pi2): 5.603e-03, MSE(pi3): 9.566e-03\n",
      "Epoch 52200, Train loss: 1.087e+08, Test loss: 1.190e+11, MSE(e): 9.549e-03, MSE(pi1): 1.200e+00, MSE(pi2): 5.684e-03, MSE(pi3): 1.186e-02\n",
      "Epoch 52300, Train loss: 9.465e+07, Test loss: 1.185e+11, MSE(e): 9.233e-03, MSE(pi1): 1.415e-01, MSE(pi2): 5.559e-03, MSE(pi3): 9.097e-03\n",
      "Epoch 52400, Train loss: 1.151e+08, Test loss: 1.177e+11, MSE(e): 1.088e-02, MSE(pi1): 5.391e-01, MSE(pi2): 6.369e-03, MSE(pi3): 8.519e-03\n",
      "Epoch 52500, Train loss: 1.216e+08, Test loss: 1.199e+11, MSE(e): 1.162e-02, MSE(pi1): 3.906e-01, MSE(pi2): 6.869e-03, MSE(pi3): 1.512e-02\n",
      "Epoch 52600, Train loss: 1.041e+08, Test loss: 1.188e+11, MSE(e): 9.339e-03, MSE(pi1): 9.399e-01, MSE(pi2): 5.576e-03, MSE(pi3): 1.297e-02\n",
      "Epoch 52700, Train loss: 9.329e+07, Test loss: 1.189e+11, MSE(e): 9.134e-03, MSE(pi1): 8.988e-02, MSE(pi2): 5.493e-03, MSE(pi3): 1.049e-02\n",
      "Epoch 52800, Train loss: 1.172e+08, Test loss: 1.178e+11, MSE(e): 1.150e-02, MSE(pi1): 1.158e-01, MSE(pi2): 7.063e-03, MSE(pi3): 1.035e-02\n",
      "Epoch 52900, Train loss: 1.005e+08, Test loss: 1.190e+11, MSE(e): 9.703e-03, MSE(pi1): 2.341e-01, MSE(pi2): 5.880e-03, MSE(pi3): 1.109e-02\n",
      "Epoch 53000, Train loss: 1.023e+08, Test loss: 1.196e+11, MSE(e): 9.864e-03, MSE(pi1): 2.295e-01, MSE(pi2): 5.798e-03, MSE(pi3): 1.363e-02\n",
      "Epoch 53100, Train loss: 9.507e+07, Test loss: 1.186e+11, MSE(e): 9.136e-03, MSE(pi1): 2.819e-01, MSE(pi2): 5.479e-03, MSE(pi3): 8.877e-03\n",
      "Epoch 53200, Train loss: 1.142e+08, Test loss: 1.178e+11, MSE(e): 1.065e-02, MSE(pi1): 6.748e-01, MSE(pi2): 6.384e-03, MSE(pi3): 9.301e-03\n",
      "Epoch 53300, Train loss: 1.035e+08, Test loss: 1.187e+11, MSE(e): 9.722e-03, MSE(pi1): 5.370e-01, MSE(pi2): 5.951e-03, MSE(pi3): 9.301e-03\n",
      "Epoch 53400, Train loss: 1.111e+08, Test loss: 1.192e+11, MSE(e): 9.316e-03, MSE(pi1): 1.700e+00, MSE(pi2): 5.538e-03, MSE(pi3): 9.041e-03\n",
      "Epoch 53500, Train loss: 9.585e+07, Test loss: 1.184e+11, MSE(e): 9.410e-03, MSE(pi1): 8.796e-02, MSE(pi2): 5.706e-03, MSE(pi3): 8.695e-03\n",
      "Epoch 53600, Train loss: 1.064e+08, Test loss: 1.184e+11, MSE(e): 9.991e-03, MSE(pi1): 5.530e-01, MSE(pi2): 6.038e-03, MSE(pi3): 9.320e-03\n",
      "Epoch 53700, Train loss: 1.179e+08, Test loss: 1.184e+11, MSE(e): 1.085e-02, MSE(pi1): 8.570e-01, MSE(pi2): 6.309e-03, MSE(pi3): 8.935e-03\n",
      "Epoch 53800, Train loss: 9.030e+07, Test loss: 1.190e+11, MSE(e): 8.866e-03, MSE(pi1): 7.285e-02, MSE(pi2): 5.326e-03, MSE(pi3): 9.104e-03\n",
      "Epoch 53900, Train loss: 9.522e+07, Test loss: 1.189e+11, MSE(e): 9.170e-03, MSE(pi1): 2.262e-01, MSE(pi2): 5.468e-03, MSE(pi3): 1.265e-02\n",
      "Epoch 54000, Train loss: 1.046e+08, Test loss: 1.194e+11, MSE(e): 9.072e-03, MSE(pi1): 1.272e+00, MSE(pi2): 5.420e-03, MSE(pi3): 1.193e-02\n",
      "Epoch 54100, Train loss: 9.570e+07, Test loss: 1.189e+11, MSE(e): 9.084e-03, MSE(pi1): 3.940e-01, MSE(pi2): 5.478e-03, MSE(pi3): 9.130e-03\n",
      "Epoch 54200, Train loss: 9.685e+07, Test loss: 1.194e+11, MSE(e): 8.938e-03, MSE(pi1): 6.519e-01, MSE(pi2): 5.332e-03, MSE(pi3): 9.493e-03\n",
      "Epoch 54300, Train loss: 9.411e+07, Test loss: 1.190e+11, MSE(e): 9.128e-03, MSE(pi1): 1.976e-01, MSE(pi2): 5.527e-03, MSE(pi3): 8.565e-03\n",
      "Epoch 54400, Train loss: 9.009e+07, Test loss: 1.194e+11, MSE(e): 8.784e-03, MSE(pi1): 1.313e-01, MSE(pi2): 5.258e-03, MSE(pi3): 9.355e-03\n",
      "Epoch 54500, Train loss: 9.598e+07, Test loss: 1.193e+11, MSE(e): 9.296e-03, MSE(pi1): 1.753e-01, MSE(pi2): 5.610e-03, MSE(pi3): 1.268e-02\n",
      "Epoch 54600, Train loss: 9.131e+07, Test loss: 1.192e+11, MSE(e): 8.874e-03, MSE(pi1): 1.426e-01, MSE(pi2): 5.325e-03, MSE(pi3): 1.148e-02\n",
      "Epoch 54700, Train loss: 1.018e+08, Test loss: 1.193e+11, MSE(e): 8.808e-03, MSE(pi1): 1.142e+00, MSE(pi2): 5.232e-03, MSE(pi3): 2.340e-02\n",
      "Epoch 54800, Train loss: 9.005e+07, Test loss: 1.191e+11, MSE(e): 8.807e-03, MSE(pi1): 1.097e-01, MSE(pi2): 5.270e-03, MSE(pi3): 8.891e-03\n",
      "Epoch 54900, Train loss: 8.902e+07, Test loss: 1.194e+11, MSE(e): 8.689e-03, MSE(pi1): 1.203e-01, MSE(pi2): 5.216e-03, MSE(pi3): 9.249e-03\n",
      "Epoch 55000, Train loss: 9.340e+07, Test loss: 1.195e+11, MSE(e): 8.759e-03, MSE(pi1): 4.953e-01, MSE(pi2): 5.237e-03, MSE(pi3): 8.610e-03\n",
      "Epoch 55100, Train loss: 9.044e+07, Test loss: 1.194e+11, MSE(e): 8.670e-03, MSE(pi1): 2.741e-01, MSE(pi2): 5.189e-03, MSE(pi3): 9.982e-03\n",
      "Epoch 55200, Train loss: 1.152e+08, Test loss: 1.197e+11, MSE(e): 9.402e-03, MSE(pi1): 1.975e+00, MSE(pi2): 5.684e-03, MSE(pi3): 1.465e-02\n",
      "Epoch 55300, Train loss: 9.135e+07, Test loss: 1.194e+11, MSE(e): 8.696e-03, MSE(pi1): 3.372e-01, MSE(pi2): 5.194e-03, MSE(pi3): 1.027e-02\n",
      "Epoch 55400, Train loss: 9.438e+07, Test loss: 1.196e+11, MSE(e): 8.591e-03, MSE(pi1): 7.453e-01, MSE(pi2): 5.132e-03, MSE(pi3): 1.018e-02\n",
      "Epoch 55500, Train loss: 9.455e+07, Test loss: 1.199e+11, MSE(e): 9.089e-03, MSE(pi1): 2.400e-01, MSE(pi2): 5.507e-03, MSE(pi3): 1.257e-02\n",
      "Epoch 55600, Train loss: 8.785e+07, Test loss: 1.197e+11, MSE(e): 8.546e-03, MSE(pi1): 1.406e-01, MSE(pi2): 5.110e-03, MSE(pi3): 9.895e-03\n",
      "Epoch 55700, Train loss: 8.821e+07, Test loss: 1.195e+11, MSE(e): 8.500e-03, MSE(pi1): 2.304e-01, MSE(pi2): 5.087e-03, MSE(pi3): 9.108e-03\n",
      "Epoch 55800, Train loss: 9.147e+07, Test loss: 1.195e+11, MSE(e): 8.674e-03, MSE(pi1): 3.817e-01, MSE(pi2): 5.190e-03, MSE(pi3): 9.091e-03\n",
      "Epoch 55900, Train loss: 9.452e+07, Test loss: 1.198e+11, MSE(e): 8.548e-03, MSE(pi1): 8.139e-01, MSE(pi2): 5.083e-03, MSE(pi3): 9.014e-03\n",
      "Epoch 56000, Train loss: 1.047e+08, Test loss: 1.192e+11, MSE(e): 9.837e-03, MSE(pi1): 5.350e-01, MSE(pi2): 5.935e-03, MSE(pi3): 9.465e-03\n",
      "Epoch 56100, Train loss: 9.976e+07, Test loss: 1.197e+11, MSE(e): 9.119e-03, MSE(pi1): 6.541e-01, MSE(pi2): 5.431e-03, MSE(pi3): 2.028e-02\n",
      "Epoch 56200, Train loss: 8.990e+07, Test loss: 1.195e+11, MSE(e): 8.547e-03, MSE(pi1): 3.603e-01, MSE(pi2): 5.125e-03, MSE(pi3): 8.228e-03\n",
      "Epoch 56300, Train loss: 1.438e+08, Test loss: 1.216e+11, MSE(e): 1.372e-02, MSE(pi1): 4.782e-01, MSE(pi2): 7.893e-03, MSE(pi3): 1.825e-02\n",
      "Epoch 56400, Train loss: 9.013e+07, Test loss: 1.199e+11, MSE(e): 8.732e-03, MSE(pi1): 1.775e-01, MSE(pi2): 5.266e-03, MSE(pi3): 1.041e-02\n",
      "Epoch 56500, Train loss: 9.022e+07, Test loss: 1.199e+11, MSE(e): 8.413e-03, MSE(pi1): 3.968e-01, MSE(pi2): 5.041e-03, MSE(pi3): 2.125e-02\n",
      "Epoch 56600, Train loss: 8.552e+07, Test loss: 1.200e+11, MSE(e): 8.341e-03, MSE(pi1): 1.214e-01, MSE(pi2): 4.997e-03, MSE(pi3): 8.963e-03\n",
      "Epoch 56700, Train loss: 8.821e+07, Test loss: 1.197e+11, MSE(e): 8.587e-03, MSE(pi1): 1.434e-01, MSE(pi2): 5.201e-03, MSE(pi3): 9.035e-03\n",
      "Epoch 56800, Train loss: 9.250e+07, Test loss: 1.195e+11, MSE(e): 8.710e-03, MSE(pi1): 4.224e-01, MSE(pi2): 5.223e-03, MSE(pi3): 1.171e-02\n",
      "Epoch 56900, Train loss: 8.420e+07, Test loss: 1.200e+11, MSE(e): 8.243e-03, MSE(pi1): 8.599e-02, MSE(pi2): 4.936e-03, MSE(pi3): 9.018e-03\n",
      "Epoch 57000, Train loss: 8.969e+07, Test loss: 1.199e+11, MSE(e): 8.328e-03, MSE(pi1): 5.284e-01, MSE(pi2): 4.976e-03, MSE(pi3): 1.126e-02\n",
      "Epoch 57100, Train loss: 8.818e+07, Test loss: 1.205e+11, MSE(e): 8.567e-03, MSE(pi1): 8.838e-02, MSE(pi2): 5.105e-03, MSE(pi3): 1.624e-02\n",
      "Epoch 57200, Train loss: 9.041e+07, Test loss: 1.202e+11, MSE(e): 8.415e-03, MSE(pi1): 4.351e-01, MSE(pi2): 4.999e-03, MSE(pi3): 1.908e-02\n",
      "Epoch 57300, Train loss: 8.425e+07, Test loss: 1.200e+11, MSE(e): 8.175e-03, MSE(pi1): 1.502e-01, MSE(pi2): 4.893e-03, MSE(pi3): 9.965e-03\n",
      "Epoch 57400, Train loss: 8.515e+07, Test loss: 1.200e+11, MSE(e): 8.269e-03, MSE(pi1): 1.193e-01, MSE(pi2): 4.969e-03, MSE(pi3): 1.264e-02\n",
      "Epoch 57500, Train loss: 9.354e+07, Test loss: 1.204e+11, MSE(e): 8.493e-03, MSE(pi1): 5.934e-01, MSE(pi2): 4.985e-03, MSE(pi3): 2.681e-02\n",
      "Epoch 57600, Train loss: 9.152e+07, Test loss: 1.205e+11, MSE(e): 8.819e-03, MSE(pi1): 2.055e-01, MSE(pi2): 5.316e-03, MSE(pi3): 1.278e-02\n",
      "Epoch 57700, Train loss: 1.006e+08, Test loss: 1.205e+11, MSE(e): 8.980e-03, MSE(pi1): 9.744e-01, MSE(pi2): 5.205e-03, MSE(pi3): 1.020e-02\n",
      "Epoch 57800, Train loss: 8.264e+07, Test loss: 1.201e+11, MSE(e): 8.114e-03, MSE(pi1): 5.053e-02, MSE(pi2): 4.857e-03, MSE(pi3): 9.929e-03\n",
      "Epoch 57900, Train loss: 9.411e+07, Test loss: 1.209e+11, MSE(e): 9.050e-03, MSE(pi1): 2.423e-01, MSE(pi2): 5.328e-03, MSE(pi3): 1.186e-02\n",
      "Epoch 58000, Train loss: 8.415e+07, Test loss: 1.202e+11, MSE(e): 8.050e-03, MSE(pi1): 2.809e-01, MSE(pi2): 4.818e-03, MSE(pi3): 8.407e-03\n",
      "Epoch 58100, Train loss: 8.849e+07, Test loss: 1.196e+11, MSE(e): 8.621e-03, MSE(pi1): 1.394e-01, MSE(pi2): 5.162e-03, MSE(pi3): 8.794e-03\n",
      "Epoch 58200, Train loss: 8.554e+07, Test loss: 1.203e+11, MSE(e): 8.222e-03, MSE(pi1): 1.451e-01, MSE(pi2): 4.922e-03, MSE(pi3): 1.869e-02\n",
      "Epoch 58300, Train loss: 8.187e+07, Test loss: 1.202e+11, MSE(e): 8.024e-03, MSE(pi1): 7.046e-02, MSE(pi2): 4.802e-03, MSE(pi3): 9.293e-03\n",
      "Epoch 58400, Train loss: 8.841e+07, Test loss: 1.206e+11, MSE(e): 8.246e-03, MSE(pi1): 4.882e-01, MSE(pi2): 4.891e-03, MSE(pi3): 1.077e-02\n",
      "Epoch 58500, Train loss: 9.663e+07, Test loss: 1.207e+11, MSE(e): 8.641e-03, MSE(pi1): 9.244e-01, MSE(pi2): 5.014e-03, MSE(pi3): 9.743e-03\n",
      "Epoch 58600, Train loss: 9.446e+07, Test loss: 1.212e+11, MSE(e): 9.197e-03, MSE(pi1): 1.299e-01, MSE(pi2): 5.439e-03, MSE(pi3): 1.196e-02\n",
      "Epoch 58700, Train loss: 8.108e+07, Test loss: 1.206e+11, MSE(e): 7.963e-03, MSE(pi1): 4.719e-02, MSE(pi2): 4.761e-03, MSE(pi3): 9.720e-03\n",
      "Epoch 58800, Train loss: 8.126e+07, Test loss: 1.206e+11, MSE(e): 7.934e-03, MSE(pi1): 7.927e-02, MSE(pi2): 4.739e-03, MSE(pi3): 1.124e-02\n",
      "Epoch 58900, Train loss: 8.549e+07, Test loss: 1.201e+11, MSE(e): 8.201e-03, MSE(pi1): 2.582e-01, MSE(pi2): 4.854e-03, MSE(pi3): 8.947e-03\n",
      "Epoch 59000, Train loss: 8.283e+07, Test loss: 1.206e+11, MSE(e): 8.023e-03, MSE(pi1): 1.505e-01, MSE(pi2): 4.819e-03, MSE(pi3): 1.091e-02\n",
      "Epoch 59100, Train loss: 9.643e+07, Test loss: 1.213e+11, MSE(e): 9.318e-03, MSE(pi1): 1.658e-01, MSE(pi2): 5.448e-03, MSE(pi3): 1.591e-02\n",
      "Epoch 59200, Train loss: 8.132e+07, Test loss: 1.205e+11, MSE(e): 7.842e-03, MSE(pi1): 1.916e-01, MSE(pi2): 4.688e-03, MSE(pi3): 9.829e-03\n",
      "Epoch 59300, Train loss: 8.306e+07, Test loss: 1.204e+11, MSE(e): 7.886e-03, MSE(pi1): 2.996e-01, MSE(pi2): 4.711e-03, MSE(pi3): 1.201e-02\n",
      "Epoch 59400, Train loss: 8.389e+07, Test loss: 1.202e+11, MSE(e): 8.137e-03, MSE(pi1): 1.734e-01, MSE(pi2): 4.840e-03, MSE(pi3): 7.927e-03\n",
      "Epoch 59500, Train loss: 8.990e+07, Test loss: 1.202e+11, MSE(e): 8.716e-03, MSE(pi1): 1.922e-01, MSE(pi2): 5.098e-03, MSE(pi3): 8.201e-03\n",
      "Epoch 59600, Train loss: 1.007e+08, Test loss: 1.202e+11, MSE(e): 8.901e-03, MSE(pi1): 1.069e+00, MSE(pi2): 5.512e-03, MSE(pi3): 1.039e-02\n",
      "Epoch 59700, Train loss: 8.519e+07, Test loss: 1.202e+11, MSE(e): 8.104e-03, MSE(pi1): 2.794e-01, MSE(pi2): 4.874e-03, MSE(pi3): 1.357e-02\n",
      "Epoch 59800, Train loss: 8.197e+07, Test loss: 1.211e+11, MSE(e): 8.032e-03, MSE(pi1): 5.220e-02, MSE(pi2): 4.792e-03, MSE(pi3): 1.128e-02\n",
      "Epoch 59900, Train loss: 8.046e+07, Test loss: 1.208e+11, MSE(e): 7.764e-03, MSE(pi1): 1.960e-01, MSE(pi2): 4.635e-03, MSE(pi3): 8.526e-03\n",
      "Epoch 60000, Train loss: 8.361e+07, Test loss: 1.207e+11, MSE(e): 7.804e-03, MSE(pi1): 4.735e-01, MSE(pi2): 4.654e-03, MSE(pi3): 8.316e-03\n",
      "Epoch 60100, Train loss: 7.991e+07, Test loss: 1.209e+11, MSE(e): 7.709e-03, MSE(pi1): 1.867e-01, MSE(pi2): 4.602e-03, MSE(pi3): 9.532e-03\n",
      "Epoch 60200, Train loss: 8.009e+07, Test loss: 1.205e+11, MSE(e): 7.704e-03, MSE(pi1): 1.874e-01, MSE(pi2): 4.605e-03, MSE(pi3): 1.174e-02\n",
      "Epoch 60300, Train loss: 1.165e+08, Test loss: 1.195e+11, MSE(e): 1.139e-02, MSE(pi1): 1.457e-01, MSE(pi2): 7.043e-03, MSE(pi3): 1.122e-02\n",
      "Epoch 60400, Train loss: 8.025e+07, Test loss: 1.208e+11, MSE(e): 7.645e-03, MSE(pi1): 2.764e-01, MSE(pi2): 4.562e-03, MSE(pi3): 1.039e-02\n",
      "Epoch 60500, Train loss: 7.797e+07, Test loss: 1.209e+11, MSE(e): 7.614e-03, MSE(pi1): 8.909e-02, MSE(pi2): 4.552e-03, MSE(pi3): 9.377e-03\n",
      "Epoch 60600, Train loss: 7.956e+07, Test loss: 1.210e+11, MSE(e): 7.615e-03, MSE(pi1): 2.483e-01, MSE(pi2): 4.541e-03, MSE(pi3): 9.238e-03\n",
      "Epoch 60700, Train loss: 8.475e+07, Test loss: 1.214e+11, MSE(e): 7.988e-03, MSE(pi1): 3.632e-01, MSE(pi2): 4.737e-03, MSE(pi3): 1.239e-02\n",
      "Epoch 60800, Train loss: 7.984e+07, Test loss: 1.209e+11, MSE(e): 7.630e-03, MSE(pi1): 2.619e-01, MSE(pi2): 4.530e-03, MSE(pi3): 9.214e-03\n",
      "Epoch 60900, Train loss: 8.045e+07, Test loss: 1.212e+11, MSE(e): 7.765e-03, MSE(pi1): 1.011e-01, MSE(pi2): 4.634e-03, MSE(pi3): 1.788e-02\n",
      "Epoch 61000, Train loss: 8.186e+07, Test loss: 1.206e+11, MSE(e): 7.808e-03, MSE(pi1): 2.925e-01, MSE(pi2): 4.676e-03, MSE(pi3): 8.549e-03\n",
      "Epoch 61100, Train loss: 1.159e+08, Test loss: 1.224e+11, MSE(e): 1.091e-02, MSE(pi1): 5.274e-01, MSE(pi2): 6.407e-03, MSE(pi3): 1.474e-02\n",
      "Epoch 61200, Train loss: 7.963e+07, Test loss: 1.215e+11, MSE(e): 7.774e-03, MSE(pi1): 9.431e-02, MSE(pi2): 4.616e-03, MSE(pi3): 9.427e-03\n",
      "Epoch 61300, Train loss: 7.815e+07, Test loss: 1.213e+11, MSE(e): 7.603e-03, MSE(pi1): 1.020e-01, MSE(pi2): 4.553e-03, MSE(pi3): 1.101e-02\n",
      "Epoch 61400, Train loss: 7.795e+07, Test loss: 1.211e+11, MSE(e): 7.456e-03, MSE(pi1): 2.575e-01, MSE(pi2): 4.451e-03, MSE(pi3): 8.158e-03\n",
      "Epoch 61500, Train loss: 7.940e+07, Test loss: 1.210e+11, MSE(e): 7.475e-03, MSE(pi1): 3.797e-01, MSE(pi2): 4.453e-03, MSE(pi3): 8.515e-03\n",
      "Epoch 61600, Train loss: 1.017e+08, Test loss: 1.204e+11, MSE(e): 8.431e-03, MSE(pi1): 1.580e+00, MSE(pi2): 5.055e-03, MSE(pi3): 1.627e-02\n",
      "Epoch 61700, Train loss: 7.866e+07, Test loss: 1.206e+11, MSE(e): 7.708e-03, MSE(pi1): 6.924e-02, MSE(pi2): 4.560e-03, MSE(pi3): 8.905e-03\n",
      "Epoch 61800, Train loss: 7.848e+07, Test loss: 1.213e+11, MSE(e): 7.518e-03, MSE(pi1): 2.409e-01, MSE(pi2): 4.471e-03, MSE(pi3): 8.852e-03\n",
      "Epoch 61900, Train loss: 7.677e+07, Test loss: 1.215e+11, MSE(e): 7.420e-03, MSE(pi1): 1.680e-01, MSE(pi2): 4.421e-03, MSE(pi3): 8.837e-03\n",
      "Epoch 62000, Train loss: 8.980e+07, Test loss: 1.212e+11, MSE(e): 7.750e-03, MSE(pi1): 1.128e+00, MSE(pi2): 4.642e-03, MSE(pi3): 1.031e-02\n",
      "Epoch 62100, Train loss: 7.579e+07, Test loss: 1.212e+11, MSE(e): 7.342e-03, MSE(pi1): 1.569e-01, MSE(pi2): 4.383e-03, MSE(pi3): 8.098e-03\n",
      "Epoch 62200, Train loss: 7.694e+07, Test loss: 1.211e+11, MSE(e): 7.405e-03, MSE(pi1): 2.058e-01, MSE(pi2): 4.431e-03, MSE(pi3): 8.344e-03\n",
      "Epoch 62300, Train loss: 8.901e+07, Test loss: 1.203e+11, MSE(e): 8.596e-03, MSE(pi1): 2.185e-01, MSE(pi2): 5.111e-03, MSE(pi3): 8.642e-03\n",
      "Epoch 62400, Train loss: 7.592e+07, Test loss: 1.213e+11, MSE(e): 7.310e-03, MSE(pi1): 1.877e-01, MSE(pi2): 4.364e-03, MSE(pi3): 9.360e-03\n",
      "Epoch 62500, Train loss: 8.243e+07, Test loss: 1.208e+11, MSE(e): 7.989e-03, MSE(pi1): 1.716e-01, MSE(pi2): 4.674e-03, MSE(pi3): 8.242e-03\n",
      "Epoch 62600, Train loss: 7.560e+07, Test loss: 1.214e+11, MSE(e): 7.396e-03, MSE(pi1): 6.471e-02, MSE(pi2): 4.431e-03, MSE(pi3): 9.941e-03\n",
      "Epoch 62700, Train loss: 9.527e+07, Test loss: 1.222e+11, MSE(e): 8.956e-03, MSE(pi1): 3.494e-01, MSE(pi2): 5.139e-03, MSE(pi3): 2.214e-02\n",
      "Epoch 62800, Train loss: 7.774e+07, Test loss: 1.210e+11, MSE(e): 7.405e-03, MSE(pi1): 2.798e-01, MSE(pi2): 4.427e-03, MSE(pi3): 8.967e-03\n",
      "Epoch 62900, Train loss: 7.827e+07, Test loss: 1.218e+11, MSE(e): 7.431e-03, MSE(pi1): 2.990e-01, MSE(pi2): 4.400e-03, MSE(pi3): 9.664e-03\n",
      "Epoch 63000, Train loss: 8.082e+07, Test loss: 1.216e+11, MSE(e): 7.380e-03, MSE(pi1): 5.699e-01, MSE(pi2): 4.415e-03, MSE(pi3): 1.327e-02\n",
      "Epoch 63100, Train loss: 7.770e+07, Test loss: 1.218e+11, MSE(e): 7.469e-03, MSE(pi1): 1.905e-01, MSE(pi2): 4.415e-03, MSE(pi3): 1.104e-02\n",
      "Epoch 63200, Train loss: 1.118e+08, Test loss: 1.201e+11, MSE(e): 1.065e-02, MSE(pi1): 4.344e-01, MSE(pi2): 6.338e-03, MSE(pi3): 9.611e-03\n",
      "Epoch 63300, Train loss: 8.494e+07, Test loss: 1.214e+11, MSE(e): 7.890e-03, MSE(pi1): 4.897e-01, MSE(pi2): 4.712e-03, MSE(pi3): 1.146e-02\n",
      "Epoch 63400, Train loss: 8.052e+07, Test loss: 1.215e+11, MSE(e): 7.206e-03, MSE(pi1): 7.262e-01, MSE(pi2): 4.289e-03, MSE(pi3): 1.198e-02\n",
      "Epoch 63500, Train loss: 7.883e+07, Test loss: 1.215e+11, MSE(e): 7.181e-03, MSE(pi1): 6.032e-01, MSE(pi2): 4.262e-03, MSE(pi3): 9.794e-03\n",
      "Epoch 63600, Train loss: 8.518e+07, Test loss: 1.210e+11, MSE(e): 8.260e-03, MSE(pi1): 1.107e-01, MSE(pi2): 5.033e-03, MSE(pi3): 1.471e-02\n",
      "Epoch 63700, Train loss: 7.368e+07, Test loss: 1.215e+11, MSE(e): 7.112e-03, MSE(pi1): 1.702e-01, MSE(pi2): 4.244e-03, MSE(pi3): 8.633e-03\n",
      "Epoch 63800, Train loss: 7.405e+07, Test loss: 1.216e+11, MSE(e): 7.203e-03, MSE(pi1): 1.013e-01, MSE(pi2): 4.301e-03, MSE(pi3): 9.988e-03\n",
      "Epoch 63900, Train loss: 8.085e+07, Test loss: 1.220e+11, MSE(e): 7.642e-03, MSE(pi1): 3.170e-01, MSE(pi2): 4.455e-03, MSE(pi3): 1.250e-02\n",
      "Epoch 64000, Train loss: 7.318e+07, Test loss: 1.218e+11, MSE(e): 7.075e-03, MSE(pi1): 1.592e-01, MSE(pi2): 4.213e-03, MSE(pi3): 8.411e-03\n",
      "Epoch 64100, Train loss: 7.570e+07, Test loss: 1.216e+11, MSE(e): 7.242e-03, MSE(pi1): 2.488e-01, MSE(pi2): 4.325e-03, MSE(pi3): 7.985e-03\n",
      "Epoch 64200, Train loss: 7.236e+07, Test loss: 1.217e+11, MSE(e): 7.035e-03, MSE(pi1): 1.126e-01, MSE(pi2): 4.190e-03, MSE(pi3): 8.847e-03\n",
      "Epoch 64300, Train loss: 8.542e+07, Test loss: 1.223e+11, MSE(e): 7.461e-03, MSE(pi1): 8.611e-01, MSE(pi2): 4.370e-03, MSE(pi3): 2.206e-02\n",
      "Epoch 64400, Train loss: 8.720e+07, Test loss: 1.210e+11, MSE(e): 8.521e-03, MSE(pi1): 1.101e-01, MSE(pi2): 5.212e-03, MSE(pi3): 8.850e-03\n",
      "Epoch 64500, Train loss: 7.315e+07, Test loss: 1.217e+11, MSE(e): 7.018e-03, MSE(pi1): 2.095e-01, MSE(pi2): 4.178e-03, MSE(pi3): 8.762e-03\n",
      "Epoch 64600, Train loss: 7.167e+07, Test loss: 1.219e+11, MSE(e): 7.010e-03, MSE(pi1): 6.100e-02, MSE(pi2): 4.188e-03, MSE(pi3): 9.535e-03\n",
      "Epoch 64700, Train loss: 7.102e+07, Test loss: 1.219e+11, MSE(e): 6.963e-03, MSE(pi1): 4.904e-02, MSE(pi2): 4.147e-03, MSE(pi3): 9.039e-03\n",
      "Epoch 64800, Train loss: 7.961e+07, Test loss: 1.218e+11, MSE(e): 7.033e-03, MSE(pi1): 8.093e-01, MSE(pi2): 4.180e-03, MSE(pi3): 1.189e-02\n",
      "Epoch 64900, Train loss: 7.670e+07, Test loss: 1.221e+11, MSE(e): 7.108e-03, MSE(pi1): 4.402e-01, MSE(pi2): 4.216e-03, MSE(pi3): 1.224e-02\n",
      "Epoch 65000, Train loss: 7.301e+07, Test loss: 1.217e+11, MSE(e): 7.053e-03, MSE(pi1): 1.629e-01, MSE(pi2): 4.233e-03, MSE(pi3): 8.520e-03\n",
      "Epoch 65100, Train loss: 8.261e+07, Test loss: 1.216e+11, MSE(e): 7.198e-03, MSE(pi1): 9.405e-01, MSE(pi2): 4.280e-03, MSE(pi3): 1.221e-02\n",
      "Epoch 65200, Train loss: 7.217e+07, Test loss: 1.217e+11, MSE(e): 6.952e-03, MSE(pi1): 1.731e-01, MSE(pi2): 4.135e-03, MSE(pi3): 9.227e-03\n",
      "Epoch 65300, Train loss: 7.397e+07, Test loss: 1.216e+11, MSE(e): 7.171e-03, MSE(pi1): 1.425e-01, MSE(pi2): 4.321e-03, MSE(pi3): 8.432e-03\n",
      "Epoch 65400, Train loss: 8.600e+07, Test loss: 1.225e+11, MSE(e): 8.152e-03, MSE(pi1): 2.393e-01, MSE(pi2): 4.634e-03, MSE(pi3): 2.096e-02\n",
      "Epoch 65500, Train loss: 8.181e+07, Test loss: 1.213e+11, MSE(e): 7.968e-03, MSE(pi1): 9.885e-02, MSE(pi2): 4.761e-03, MSE(pi3): 1.135e-02\n",
      "Epoch 65600, Train loss: 7.145e+07, Test loss: 1.221e+11, MSE(e): 6.937e-03, MSE(pi1): 1.018e-01, MSE(pi2): 4.130e-03, MSE(pi3): 1.058e-02\n",
      "Epoch 65700, Train loss: 7.622e+07, Test loss: 1.224e+11, MSE(e): 7.239e-03, MSE(pi1): 2.809e-01, MSE(pi2): 4.241e-03, MSE(pi3): 1.018e-02\n",
      "Epoch 65800, Train loss: 7.652e+07, Test loss: 1.217e+11, MSE(e): 6.972e-03, MSE(pi1): 5.996e-01, MSE(pi2): 4.178e-03, MSE(pi3): 8.002e-03\n",
      "Epoch 65900, Train loss: 7.062e+07, Test loss: 1.222e+11, MSE(e): 6.888e-03, MSE(pi1): 7.718e-02, MSE(pi2): 4.114e-03, MSE(pi3): 9.715e-03\n",
      "Epoch 66000, Train loss: 7.762e+07, Test loss: 1.227e+11, MSE(e): 7.318e-03, MSE(pi1): 3.054e-01, MSE(pi2): 4.286e-03, MSE(pi3): 1.386e-02\n",
      "Epoch 66100, Train loss: 7.848e+07, Test loss: 1.225e+11, MSE(e): 7.418e-03, MSE(pi1): 3.166e-01, MSE(pi2): 4.504e-03, MSE(pi3): 1.131e-02\n",
      "Epoch 66200, Train loss: 7.708e+07, Test loss: 1.218e+11, MSE(e): 6.955e-03, MSE(pi1): 6.701e-01, MSE(pi2): 4.126e-03, MSE(pi3): 8.330e-03\n",
      "Epoch 66300, Train loss: 7.064e+07, Test loss: 1.219e+11, MSE(e): 6.810e-03, MSE(pi1): 1.696e-01, MSE(pi2): 4.067e-03, MSE(pi3): 8.364e-03\n",
      "Epoch 66400, Train loss: 8.098e+07, Test loss: 1.220e+11, MSE(e): 6.862e-03, MSE(pi1): 1.120e+00, MSE(pi2): 4.025e-03, MSE(pi3): 1.152e-02\n",
      "Epoch 66500, Train loss: 6.828e+07, Test loss: 1.222e+11, MSE(e): 6.693e-03, MSE(pi1): 4.601e-02, MSE(pi2): 3.987e-03, MSE(pi3): 8.875e-03\n",
      "Epoch 66600, Train loss: 7.312e+07, Test loss: 1.221e+11, MSE(e): 6.875e-03, MSE(pi1): 3.433e-01, MSE(pi2): 4.116e-03, MSE(pi3): 9.380e-03\n",
      "Epoch 66700, Train loss: 7.492e+07, Test loss: 1.218e+11, MSE(e): 7.020e-03, MSE(pi1): 3.848e-01, MSE(pi2): 4.228e-03, MSE(pi3): 8.765e-03\n",
      "Epoch 66800, Train loss: 7.657e+07, Test loss: 1.226e+11, MSE(e): 7.427e-03, MSE(pi1): 1.343e-01, MSE(pi2): 4.304e-03, MSE(pi3): 9.563e-03\n",
      "Epoch 66900, Train loss: 7.469e+07, Test loss: 1.225e+11, MSE(e): 6.803e-03, MSE(pi1): 5.588e-01, MSE(pi2): 4.048e-03, MSE(pi3): 1.075e-02\n",
      "Epoch 67000, Train loss: 7.153e+07, Test loss: 1.218e+11, MSE(e): 7.000e-03, MSE(pi1): 5.546e-02, MSE(pi2): 4.124e-03, MSE(pi3): 9.758e-03\n",
      "Epoch 67100, Train loss: 7.925e+07, Test loss: 1.225e+11, MSE(e): 7.355e-03, MSE(pi1): 3.257e-01, MSE(pi2): 4.459e-03, MSE(pi3): 2.437e-02\n",
      "Epoch 67200, Train loss: 7.325e+07, Test loss: 1.226e+11, MSE(e): 7.115e-03, MSE(pi1): 9.424e-02, MSE(pi2): 4.250e-03, MSE(pi3): 1.157e-02\n",
      "Epoch 67300, Train loss: 7.410e+07, Test loss: 1.221e+11, MSE(e): 6.680e-03, MSE(pi1): 6.307e-01, MSE(pi2): 3.962e-03, MSE(pi3): 9.891e-03\n",
      "Epoch 67400, Train loss: 7.186e+07, Test loss: 1.225e+11, MSE(e): 6.737e-03, MSE(pi1): 2.584e-01, MSE(pi2): 3.953e-03, MSE(pi3): 1.902e-02\n",
      "Epoch 67500, Train loss: 6.757e+07, Test loss: 1.224e+11, MSE(e): 6.602e-03, MSE(pi1): 6.379e-02, MSE(pi2): 3.923e-03, MSE(pi3): 9.150e-03\n",
      "Epoch 67600, Train loss: 6.767e+07, Test loss: 1.222e+11, MSE(e): 6.559e-03, MSE(pi1): 1.035e-01, MSE(pi2): 3.912e-03, MSE(pi3): 1.054e-02\n",
      "Epoch 67700, Train loss: 8.287e+07, Test loss: 1.230e+11, MSE(e): 7.956e-03, MSE(pi1): 1.297e-01, MSE(pi2): 4.718e-03, MSE(pi3): 2.014e-02\n",
      "Epoch 67800, Train loss: 6.677e+07, Test loss: 1.224e+11, MSE(e): 6.536e-03, MSE(pi1): 4.135e-02, MSE(pi2): 3.892e-03, MSE(pi3): 9.904e-03\n",
      "Epoch 67900, Train loss: 8.390e+07, Test loss: 1.215e+11, MSE(e): 8.138e-03, MSE(pi1): 9.590e-02, MSE(pi2): 5.011e-03, MSE(pi3): 1.561e-02\n",
      "Epoch 68000, Train loss: 6.751e+07, Test loss: 1.221e+11, MSE(e): 6.598e-03, MSE(pi1): 6.609e-02, MSE(pi2): 3.937e-03, MSE(pi3): 8.703e-03\n",
      "Epoch 68100, Train loss: 6.800e+07, Test loss: 1.224e+11, MSE(e): 6.583e-03, MSE(pi1): 1.208e-01, MSE(pi2): 3.928e-03, MSE(pi3): 9.644e-03\n",
      "Epoch 68200, Train loss: 7.360e+07, Test loss: 1.227e+11, MSE(e): 6.761e-03, MSE(pi1): 4.786e-01, MSE(pi2): 4.042e-03, MSE(pi3): 1.203e-02\n",
      "Epoch 68300, Train loss: 6.776e+07, Test loss: 1.223e+11, MSE(e): 6.577e-03, MSE(pi1): 1.137e-01, MSE(pi2): 3.922e-03, MSE(pi3): 8.519e-03\n",
      "Epoch 68400, Train loss: 7.117e+07, Test loss: 1.223e+11, MSE(e): 6.550e-03, MSE(pi1): 4.559e-01, MSE(pi2): 3.906e-03, MSE(pi3): 1.109e-02\n",
      "Epoch 68500, Train loss: 6.846e+07, Test loss: 1.228e+11, MSE(e): 6.613e-03, MSE(pi1): 1.346e-01, MSE(pi2): 3.916e-03, MSE(pi3): 9.811e-03\n",
      "Epoch 68600, Train loss: 8.737e+07, Test loss: 1.229e+11, MSE(e): 7.291e-03, MSE(pi1): 1.272e+00, MSE(pi2): 4.384e-03, MSE(pi3): 1.737e-02\n",
      "Epoch 68700, Train loss: 6.691e+07, Test loss: 1.225e+11, MSE(e): 6.481e-03, MSE(pi1): 1.285e-01, MSE(pi2): 3.860e-03, MSE(pi3): 8.160e-03\n",
      "Epoch 68800, Train loss: 7.141e+07, Test loss: 1.224e+11, MSE(e): 6.460e-03, MSE(pi1): 5.905e-01, MSE(pi2): 3.831e-03, MSE(pi3): 9.092e-03\n",
      "Epoch 68900, Train loss: 6.660e+07, Test loss: 1.226e+11, MSE(e): 6.417e-03, MSE(pi1): 1.347e-01, MSE(pi2): 3.816e-03, MSE(pi3): 1.087e-02\n",
      "Epoch 69000, Train loss: 6.530e+07, Test loss: 1.224e+11, MSE(e): 6.379e-03, MSE(pi1): 3.895e-02, MSE(pi2): 3.800e-03, MSE(pi3): 1.122e-02\n",
      "Epoch 69100, Train loss: 6.814e+07, Test loss: 1.225e+11, MSE(e): 6.435e-03, MSE(pi1): 2.882e-01, MSE(pi2): 3.835e-03, MSE(pi3): 9.121e-03\n",
      "Epoch 69200, Train loss: 6.612e+07, Test loss: 1.226e+11, MSE(e): 6.358e-03, MSE(pi1): 1.384e-01, MSE(pi2): 3.784e-03, MSE(pi3): 1.153e-02\n",
      "Epoch 69300, Train loss: 6.614e+07, Test loss: 1.226e+11, MSE(e): 6.417e-03, MSE(pi1): 6.524e-02, MSE(pi2): 3.823e-03, MSE(pi3): 1.323e-02\n",
      "Epoch 69400, Train loss: 7.292e+07, Test loss: 1.221e+11, MSE(e): 6.877e-03, MSE(pi1): 3.271e-01, MSE(pi2): 4.159e-03, MSE(pi3): 8.847e-03\n",
      "Epoch 69500, Train loss: 6.667e+07, Test loss: 1.226e+11, MSE(e): 6.319e-03, MSE(pi1): 2.544e-01, MSE(pi2): 3.754e-03, MSE(pi3): 9.281e-03\n",
      "Epoch 69600, Train loss: 8.227e+07, Test loss: 1.230e+11, MSE(e): 7.505e-03, MSE(pi1): 6.349e-01, MSE(pi2): 4.401e-03, MSE(pi3): 8.704e-03\n",
      "Epoch 69700, Train loss: 7.519e+07, Test loss: 1.233e+11, MSE(e): 7.053e-03, MSE(pi1): 3.403e-01, MSE(pi2): 4.232e-03, MSE(pi3): 1.254e-02\n",
      "Epoch 69800, Train loss: 7.383e+07, Test loss: 1.226e+11, MSE(e): 6.363e-03, MSE(pi1): 9.251e-01, MSE(pi2): 3.752e-03, MSE(pi3): 9.475e-03\n",
      "Epoch 69900, Train loss: 6.500e+07, Test loss: 1.225e+11, MSE(e): 6.291e-03, MSE(pi1): 7.187e-02, MSE(pi2): 3.750e-03, MSE(pi3): 1.367e-02\n",
      "Epoch 70000, Train loss: 6.635e+07, Test loss: 1.225e+11, MSE(e): 6.306e-03, MSE(pi1): 2.471e-01, MSE(pi2): 3.739e-03, MSE(pi3): 8.137e-03\n",
      "Epoch 70100, Train loss: 7.179e+07, Test loss: 1.224e+11, MSE(e): 6.499e-03, MSE(pi1): 5.758e-01, MSE(pi2): 3.915e-03, MSE(pi3): 1.041e-02\n",
      "Epoch 70200, Train loss: 6.481e+07, Test loss: 1.225e+11, MSE(e): 6.326e-03, MSE(pi1): 6.030e-02, MSE(pi2): 3.759e-03, MSE(pi3): 9.429e-03\n",
      "Epoch 70300, Train loss: 6.419e+07, Test loss: 1.228e+11, MSE(e): 6.245e-03, MSE(pi1): 8.448e-02, MSE(pi2): 3.704e-03, MSE(pi3): 8.971e-03\n",
      "Epoch 70400, Train loss: 6.330e+07, Test loss: 1.227e+11, MSE(e): 6.193e-03, MSE(pi1): 3.748e-02, MSE(pi2): 3.683e-03, MSE(pi3): 1.002e-02\n",
      "Epoch 70500, Train loss: 7.464e+07, Test loss: 1.229e+11, MSE(e): 6.334e-03, MSE(pi1): 9.843e-01, MSE(pi2): 3.720e-03, MSE(pi3): 1.459e-02\n",
      "Epoch 70600, Train loss: 7.133e+07, Test loss: 1.226e+11, MSE(e): 6.346e-03, MSE(pi1): 6.193e-01, MSE(pi2): 3.749e-03, MSE(pi3): 1.674e-02\n",
      "Epoch 70700, Train loss: 6.348e+07, Test loss: 1.228e+11, MSE(e): 6.165e-03, MSE(pi1): 1.009e-01, MSE(pi2): 3.662e-03, MSE(pi3): 8.295e-03\n",
      "Epoch 70800, Train loss: 6.705e+07, Test loss: 1.230e+11, MSE(e): 6.445e-03, MSE(pi1): 1.008e-01, MSE(pi2): 3.850e-03, MSE(pi3): 1.597e-02\n",
      "Epoch 70900, Train loss: 6.294e+07, Test loss: 1.227e+11, MSE(e): 6.137e-03, MSE(pi1): 6.828e-02, MSE(pi2): 3.648e-03, MSE(pi3): 8.892e-03\n",
      "Epoch 71000, Train loss: 7.236e+07, Test loss: 1.234e+11, MSE(e): 6.874e-03, MSE(pi1): 2.686e-01, MSE(pi2): 4.008e-03, MSE(pi3): 9.327e-03\n",
      "Epoch 71100, Train loss: 6.763e+07, Test loss: 1.230e+11, MSE(e): 6.282e-03, MSE(pi1): 3.882e-01, MSE(pi2): 3.705e-03, MSE(pi3): 9.357e-03\n",
      "Epoch 71200, Train loss: 7.205e+07, Test loss: 1.223e+11, MSE(e): 6.472e-03, MSE(pi1): 6.213e-01, MSE(pi2): 3.844e-03, MSE(pi3): 1.121e-02\n",
      "Epoch 71300, Train loss: 6.390e+07, Test loss: 1.226e+11, MSE(e): 6.240e-03, MSE(pi1): 6.871e-02, MSE(pi2): 3.719e-03, MSE(pi3): 8.141e-03\n",
      "Epoch 71400, Train loss: 7.170e+07, Test loss: 1.229e+11, MSE(e): 6.316e-03, MSE(pi1): 7.669e-01, MSE(pi2): 3.723e-03, MSE(pi3): 8.695e-03\n",
      "Epoch 71500, Train loss: 6.888e+07, Test loss: 1.226e+11, MSE(e): 6.448e-03, MSE(pi1): 3.513e-01, MSE(pi2): 3.862e-03, MSE(pi3): 8.878e-03\n",
      "Epoch 71600, Train loss: 7.080e+07, Test loss: 1.223e+11, MSE(e): 6.666e-03, MSE(pi1): 3.212e-01, MSE(pi2): 3.993e-03, MSE(pi3): 9.241e-03\n",
      "Epoch 71700, Train loss: 6.509e+07, Test loss: 1.227e+11, MSE(e): 6.114e-03, MSE(pi1): 3.181e-01, MSE(pi2): 3.640e-03, MSE(pi3): 7.712e-03\n",
      "Epoch 71800, Train loss: 6.906e+07, Test loss: 1.229e+11, MSE(e): 6.353e-03, MSE(pi1): 4.490e-01, MSE(pi2): 3.802e-03, MSE(pi3): 1.043e-02\n",
      "Epoch 71900, Train loss: 6.552e+07, Test loss: 1.229e+11, MSE(e): 6.109e-03, MSE(pi1): 3.635e-01, MSE(pi2): 3.612e-03, MSE(pi3): 7.952e-03\n",
      "Epoch 72000, Train loss: 6.226e+07, Test loss: 1.229e+11, MSE(e): 6.065e-03, MSE(pi1): 6.732e-02, MSE(pi2): 3.594e-03, MSE(pi3): 9.435e-03\n",
      "Epoch 72100, Train loss: 6.431e+07, Test loss: 1.227e+11, MSE(e): 6.065e-03, MSE(pi1): 2.684e-01, MSE(pi2): 3.592e-03, MSE(pi3): 9.689e-03\n",
      "Epoch 72200, Train loss: 6.509e+07, Test loss: 1.228e+11, MSE(e): 6.043e-03, MSE(pi1): 3.634e-01, MSE(pi2): 3.593e-03, MSE(pi3): 1.021e-02\n",
      "Epoch 72300, Train loss: 6.142e+07, Test loss: 1.229e+11, MSE(e): 5.980e-03, MSE(pi1): 8.653e-02, MSE(pi2): 3.551e-03, MSE(pi3): 7.515e-03\n",
      "Epoch 72400, Train loss: 6.134e+07, Test loss: 1.228e+11, MSE(e): 5.981e-03, MSE(pi1): 6.940e-02, MSE(pi2): 3.552e-03, MSE(pi3): 8.350e-03\n",
      "Epoch 72500, Train loss: 6.271e+07, Test loss: 1.231e+11, MSE(e): 6.012e-03, MSE(pi1): 1.754e-01, MSE(pi2): 3.565e-03, MSE(pi3): 8.351e-03\n",
      "Epoch 72600, Train loss: 6.366e+07, Test loss: 1.230e+11, MSE(e): 5.970e-03, MSE(pi1): 2.882e-01, MSE(pi2): 3.536e-03, MSE(pi3): 1.072e-02\n",
      "Epoch 72700, Train loss: 8.961e+07, Test loss: 1.224e+11, MSE(e): 7.536e-03, MSE(pi1): 1.332e+00, MSE(pi2): 4.612e-03, MSE(pi3): 9.342e-03\n",
      "Epoch 72800, Train loss: 6.720e+07, Test loss: 1.225e+11, MSE(e): 6.260e-03, MSE(pi1): 3.831e-01, MSE(pi2): 3.688e-03, MSE(pi3): 7.676e-03\n",
      "Epoch 72900, Train loss: 6.759e+07, Test loss: 1.227e+11, MSE(e): 6.086e-03, MSE(pi1): 5.948e-01, MSE(pi2): 3.597e-03, MSE(pi3): 7.813e-03\n",
      "Epoch 73000, Train loss: 7.041e+07, Test loss: 1.230e+11, MSE(e): 6.052e-03, MSE(pi1): 8.961e-01, MSE(pi2): 3.568e-03, MSE(pi3): 9.260e-03\n",
      "Epoch 73100, Train loss: 6.374e+07, Test loss: 1.232e+11, MSE(e): 6.141e-03, MSE(pi1): 1.278e-01, MSE(pi2): 3.613e-03, MSE(pi3): 1.060e-02\n",
      "Epoch 73200, Train loss: 8.132e+07, Test loss: 1.229e+11, MSE(e): 6.158e-03, MSE(pi1): 1.845e+00, MSE(pi2): 3.564e-03, MSE(pi3): 1.298e-02\n",
      "Epoch 73300, Train loss: 6.575e+07, Test loss: 1.234e+11, MSE(e): 6.207e-03, MSE(pi1): 2.612e-01, MSE(pi2): 3.701e-03, MSE(pi3): 1.061e-02\n",
      "Epoch 73400, Train loss: 7.907e+07, Test loss: 1.234e+11, MSE(e): 7.215e-03, MSE(pi1): 5.499e-01, MSE(pi2): 4.152e-03, MSE(pi3): 1.425e-02\n",
      "Epoch 73500, Train loss: 7.825e+07, Test loss: 1.221e+11, MSE(e): 7.628e-03, MSE(pi1): 1.122e-01, MSE(pi2): 4.506e-03, MSE(pi3): 8.454e-03\n",
      "Epoch 73600, Train loss: 8.049e+07, Test loss: 1.223e+11, MSE(e): 7.517e-03, MSE(pi1): 4.610e-01, MSE(pi2): 4.631e-03, MSE(pi3): 7.124e-03\n",
      "Epoch 73700, Train loss: 6.053e+07, Test loss: 1.231e+11, MSE(e): 5.864e-03, MSE(pi1): 9.865e-02, MSE(pi2): 3.472e-03, MSE(pi3): 9.035e-03\n",
      "Epoch 73800, Train loss: 6.183e+07, Test loss: 1.233e+11, MSE(e): 5.868e-03, MSE(pi1): 1.749e-01, MSE(pi2): 3.477e-03, MSE(pi3): 1.399e-02\n",
      "Epoch 73900, Train loss: 6.553e+07, Test loss: 1.235e+11, MSE(e): 6.322e-03, MSE(pi1): 9.169e-02, MSE(pi2): 3.727e-03, MSE(pi3): 1.394e-02\n",
      "Epoch 74000, Train loss: 9.806e+07, Test loss: 1.222e+11, MSE(e): 8.110e-03, MSE(pi1): 1.588e+00, MSE(pi2): 5.085e-03, MSE(pi3): 1.079e-02\n",
      "Epoch 74100, Train loss: 6.416e+07, Test loss: 1.234e+11, MSE(e): 6.216e-03, MSE(pi1): 1.067e-01, MSE(pi2): 3.712e-03, MSE(pi3): 9.318e-03\n",
      "Epoch 74200, Train loss: 6.159e+07, Test loss: 1.232e+11, MSE(e): 5.856e-03, MSE(pi1): 2.262e-01, MSE(pi2): 3.464e-03, MSE(pi3): 7.664e-03\n",
      "Epoch 74300, Train loss: 6.442e+07, Test loss: 1.234e+11, MSE(e): 6.257e-03, MSE(pi1): 1.021e-01, MSE(pi2): 3.624e-03, MSE(pi3): 8.367e-03\n",
      "Epoch 74400, Train loss: 6.242e+07, Test loss: 1.231e+11, MSE(e): 5.840e-03, MSE(pi1): 2.927e-01, MSE(pi2): 3.466e-03, MSE(pi3): 1.092e-02\n",
      "Epoch 74500, Train loss: 6.312e+07, Test loss: 1.231e+11, MSE(e): 5.921e-03, MSE(pi1): 2.902e-01, MSE(pi2): 3.530e-03, MSE(pi3): 1.016e-02\n",
      "Epoch 74600, Train loss: 9.259e+07, Test loss: 1.224e+11, MSE(e): 7.274e-03, MSE(pi1): 1.878e+00, MSE(pi2): 4.447e-03, MSE(pi3): 1.077e-02\n",
      "Epoch 74700, Train loss: 6.133e+07, Test loss: 1.227e+11, MSE(e): 5.920e-03, MSE(pi1): 1.329e-01, MSE(pi2): 3.511e-03, MSE(pi3): 8.070e-03\n",
      "Epoch 74800, Train loss: 6.434e+07, Test loss: 1.234e+11, MSE(e): 6.203e-03, MSE(pi1): 9.784e-02, MSE(pi2): 3.739e-03, MSE(pi3): 1.331e-02\n",
      "Epoch 74900, Train loss: 6.201e+07, Test loss: 1.232e+11, MSE(e): 5.912e-03, MSE(pi1): 1.744e-01, MSE(pi2): 3.533e-03, MSE(pi3): 1.140e-02\n",
      "Epoch 75000, Train loss: 6.786e+07, Test loss: 1.233e+11, MSE(e): 6.108e-03, MSE(pi1): 3.515e-01, MSE(pi2): 3.521e-03, MSE(pi3): 3.271e-02\n",
      "Epoch 75100, Train loss: 7.448e+07, Test loss: 1.240e+11, MSE(e): 7.188e-03, MSE(pi1): 1.397e-01, MSE(pi2): 4.327e-03, MSE(pi3): 1.208e-02\n",
      "Epoch 75200, Train loss: 6.169e+07, Test loss: 1.233e+11, MSE(e): 5.889e-03, MSE(pi1): 1.951e-01, MSE(pi2): 3.466e-03, MSE(pi3): 8.512e-03\n",
      "Epoch 75300, Train loss: 5.955e+07, Test loss: 1.230e+11, MSE(e): 5.671e-03, MSE(pi1): 1.983e-01, MSE(pi2): 3.366e-03, MSE(pi3): 8.500e-03\n",
      "Epoch 75400, Train loss: 6.489e+07, Test loss: 1.233e+11, MSE(e): 5.711e-03, MSE(pi1): 6.798e-01, MSE(pi2): 3.360e-03, MSE(pi3): 9.776e-03\n",
      "Epoch 75500, Train loss: 5.975e+07, Test loss: 1.232e+11, MSE(e): 5.719e-03, MSE(pi1): 1.675e-01, MSE(pi2): 3.389e-03, MSE(pi3): 8.852e-03\n",
      "Epoch 75600, Train loss: 6.203e+07, Test loss: 1.233e+11, MSE(e): 5.720e-03, MSE(pi1): 4.061e-01, MSE(pi2): 3.358e-03, MSE(pi3): 7.708e-03\n",
      "Epoch 75700, Train loss: 5.904e+07, Test loss: 1.233e+11, MSE(e): 5.686e-03, MSE(pi1): 1.203e-01, MSE(pi2): 3.371e-03, MSE(pi3): 9.753e-03\n",
      "Epoch 75800, Train loss: 6.754e+07, Test loss: 1.230e+11, MSE(e): 5.779e-03, MSE(pi1): 8.930e-01, MSE(pi2): 3.395e-03, MSE(pi3): 8.159e-03\n",
      "Epoch 75900, Train loss: 6.000e+07, Test loss: 1.230e+11, MSE(e): 5.864e-03, MSE(pi1): 5.460e-02, MSE(pi2): 3.517e-03, MSE(pi3): 8.200e-03\n",
      "Epoch 76000, Train loss: 5.844e+07, Test loss: 1.231e+11, MSE(e): 5.618e-03, MSE(pi1): 1.342e-01, MSE(pi2): 3.333e-03, MSE(pi3): 9.210e-03\n",
      "Epoch 76100, Train loss: 5.881e+07, Test loss: 1.231e+11, MSE(e): 5.610e-03, MSE(pi1): 1.940e-01, MSE(pi2): 3.325e-03, MSE(pi3): 7.671e-03\n",
      "Epoch 76200, Train loss: 5.783e+07, Test loss: 1.231e+11, MSE(e): 5.586e-03, MSE(pi1): 1.118e-01, MSE(pi2): 3.319e-03, MSE(pi3): 8.439e-03\n",
      "Epoch 76300, Train loss: 1.077e+08, Test loss: 1.241e+11, MSE(e): 7.412e-03, MSE(pi1): 3.153e+00, MSE(pi2): 4.360e-03, MSE(pi3): 2.053e-02\n",
      "Epoch 76400, Train loss: 7.444e+07, Test loss: 1.223e+11, MSE(e): 7.053e-03, MSE(pi1): 3.187e-01, MSE(pi2): 4.200e-03, MSE(pi3): 7.310e-03\n",
      "Epoch 76500, Train loss: 6.083e+07, Test loss: 1.229e+11, MSE(e): 5.836e-03, MSE(pi1): 1.694e-01, MSE(pi2): 3.418e-03, MSE(pi3): 7.739e-03\n",
      "Epoch 76600, Train loss: 5.737e+07, Test loss: 1.232e+11, MSE(e): 5.543e-03, MSE(pi1): 1.139e-01, MSE(pi2): 3.291e-03, MSE(pi3): 7.967e-03\n",
      "Epoch 76700, Train loss: 5.677e+07, Test loss: 1.233e+11, MSE(e): 5.539e-03, MSE(pi1): 5.182e-02, MSE(pi2): 3.287e-03, MSE(pi3): 8.594e-03\n",
      "Epoch 76800, Train loss: 5.860e+07, Test loss: 1.234e+11, MSE(e): 5.553e-03, MSE(pi1): 2.116e-01, MSE(pi2): 3.279e-03, MSE(pi3): 9.563e-03\n",
      "Epoch 76900, Train loss: 5.729e+07, Test loss: 1.232e+11, MSE(e): 5.513e-03, MSE(pi1): 1.035e-01, MSE(pi2): 3.270e-03, MSE(pi3): 1.134e-02\n",
      "Epoch 77000, Train loss: 5.666e+07, Test loss: 1.232e+11, MSE(e): 5.518e-03, MSE(pi1): 6.824e-02, MSE(pi2): 3.277e-03, MSE(pi3): 7.940e-03\n",
      "Epoch 77100, Train loss: 5.855e+07, Test loss: 1.231e+11, MSE(e): 5.504e-03, MSE(pi1): 2.605e-01, MSE(pi2): 3.258e-03, MSE(pi3): 9.016e-03\n",
      "Epoch 77200, Train loss: 5.817e+07, Test loss: 1.234e+11, MSE(e): 5.512e-03, MSE(pi1): 2.207e-01, MSE(pi2): 3.253e-03, MSE(pi3): 8.392e-03\n",
      "Epoch 77300, Train loss: 5.682e+07, Test loss: 1.232e+11, MSE(e): 5.480e-03, MSE(pi1): 5.991e-02, MSE(pi2): 3.247e-03, MSE(pi3): 1.421e-02\n",
      "Epoch 77400, Train loss: 6.111e+07, Test loss: 1.234e+11, MSE(e): 5.525e-03, MSE(pi1): 4.937e-01, MSE(pi2): 3.250e-03, MSE(pi3): 9.264e-03\n",
      "Epoch 77500, Train loss: 6.046e+07, Test loss: 1.231e+11, MSE(e): 5.794e-03, MSE(pi1): 1.774e-01, MSE(pi2): 3.496e-03, MSE(pi3): 7.493e-03\n",
      "Epoch 77600, Train loss: 5.817e+07, Test loss: 1.231e+11, MSE(e): 5.512e-03, MSE(pi1): 2.285e-01, MSE(pi2): 3.281e-03, MSE(pi3): 7.684e-03\n",
      "Epoch 77700, Train loss: 5.635e+07, Test loss: 1.234e+11, MSE(e): 5.499e-03, MSE(pi1): 5.094e-02, MSE(pi2): 3.264e-03, MSE(pi3): 8.581e-03\n",
      "Epoch 77800, Train loss: 6.149e+07, Test loss: 1.235e+11, MSE(e): 5.581e-03, MSE(pi1): 4.623e-01, MSE(pi2): 3.284e-03, MSE(pi3): 1.058e-02\n",
      "Epoch 77900, Train loss: 6.396e+07, Test loss: 1.227e+11, MSE(e): 6.032e-03, MSE(pi1): 2.883e-01, MSE(pi2): 3.568e-03, MSE(pi3): 7.558e-03\n",
      "Epoch 78000, Train loss: 5.865e+07, Test loss: 1.233e+11, MSE(e): 5.402e-03, MSE(pi1): 3.763e-01, MSE(pi2): 3.192e-03, MSE(pi3): 8.590e-03\n",
      "Epoch 78100, Train loss: 6.435e+07, Test loss: 1.233e+11, MSE(e): 5.448e-03, MSE(pi1): 8.874e-01, MSE(pi2): 3.195e-03, MSE(pi3): 9.922e-03\n",
      "Epoch 78200, Train loss: 5.795e+07, Test loss: 1.234e+11, MSE(e): 5.415e-03, MSE(pi1): 2.693e-01, MSE(pi2): 3.184e-03, MSE(pi3): 1.112e-02\n",
      "Epoch 78300, Train loss: 5.762e+07, Test loss: 1.236e+11, MSE(e): 5.596e-03, MSE(pi1): 7.033e-02, MSE(pi2): 3.277e-03, MSE(pi3): 9.584e-03\n",
      "Epoch 78400, Train loss: 5.566e+07, Test loss: 1.231e+11, MSE(e): 5.354e-03, MSE(pi1): 1.399e-01, MSE(pi2): 3.174e-03, MSE(pi3): 7.157e-03\n",
      "Epoch 78500, Train loss: 5.928e+07, Test loss: 1.236e+11, MSE(e): 5.550e-03, MSE(pi1): 2.749e-01, MSE(pi2): 3.273e-03, MSE(pi3): 1.033e-02\n",
      "Epoch 78600, Train loss: 6.706e+07, Test loss: 1.241e+11, MSE(e): 6.158e-03, MSE(pi1): 1.921e-01, MSE(pi2): 3.470e-03, MSE(pi3): 3.561e-02\n",
      "Epoch 78700, Train loss: 5.909e+07, Test loss: 1.231e+11, MSE(e): 5.559e-03, MSE(pi1): 2.655e-01, MSE(pi2): 3.331e-03, MSE(pi3): 8.465e-03\n",
      "Epoch 78800, Train loss: 6.129e+07, Test loss: 1.229e+11, MSE(e): 5.918e-03, MSE(pi1): 1.095e-01, MSE(pi2): 3.601e-03, MSE(pi3): 1.017e-02\n",
      "Epoch 78900, Train loss: 7.836e+07, Test loss: 1.226e+11, MSE(e): 7.381e-03, MSE(pi1): 3.689e-01, MSE(pi2): 4.630e-03, MSE(pi3): 8.622e-03\n",
      "Epoch 79000, Train loss: 5.579e+07, Test loss: 1.234e+11, MSE(e): 5.393e-03, MSE(pi1): 9.050e-02, MSE(pi2): 3.202e-03, MSE(pi3): 9.569e-03\n",
      "Epoch 79100, Train loss: 5.477e+07, Test loss: 1.232e+11, MSE(e): 5.284e-03, MSE(pi1): 1.205e-01, MSE(pi2): 3.131e-03, MSE(pi3): 7.230e-03\n",
      "Epoch 79200, Train loss: 5.761e+07, Test loss: 1.229e+11, MSE(e): 5.556e-03, MSE(pi1): 1.237e-01, MSE(pi2): 3.301e-03, MSE(pi3): 8.065e-03\n",
      "Epoch 79300, Train loss: 5.559e+07, Test loss: 1.231e+11, MSE(e): 5.302e-03, MSE(pi1): 8.509e-02, MSE(pi2): 3.139e-03, MSE(pi3): 1.719e-02\n",
      "Epoch 79400, Train loss: 6.113e+07, Test loss: 1.235e+11, MSE(e): 5.590e-03, MSE(pi1): 4.055e-01, MSE(pi2): 3.299e-03, MSE(pi3): 1.175e-02\n",
      "Epoch 79500, Train loss: 5.736e+07, Test loss: 1.232e+11, MSE(e): 5.527e-03, MSE(pi1): 1.230e-01, MSE(pi2): 3.276e-03, MSE(pi3): 8.615e-03\n",
      "Epoch 79600, Train loss: 6.190e+07, Test loss: 1.234e+11, MSE(e): 5.324e-03, MSE(pi1): 7.536e-01, MSE(pi2): 3.121e-03, MSE(pi3): 1.121e-02\n",
      "Epoch 79700, Train loss: 5.496e+07, Test loss: 1.234e+11, MSE(e): 5.242e-03, MSE(pi1): 1.147e-01, MSE(pi2): 3.089e-03, MSE(pi3): 1.395e-02\n",
      "Epoch 79800, Train loss: 5.322e+07, Test loss: 1.233e+11, MSE(e): 5.200e-03, MSE(pi1): 4.192e-02, MSE(pi2): 3.080e-03, MSE(pi3): 8.005e-03\n",
      "Epoch 79900, Train loss: 6.136e+07, Test loss: 1.240e+11, MSE(e): 5.956e-03, MSE(pi1): 9.237e-02, MSE(pi2): 3.563e-03, MSE(pi3): 8.763e-03\n",
      "Epoch 80000, Train loss: 6.960e+07, Test loss: 1.241e+11, MSE(e): 6.336e-03, MSE(pi1): 4.965e-01, MSE(pi2): 3.797e-03, MSE(pi3): 1.276e-02\n",
      "Epoch 80100, Train loss: 6.965e+07, Test loss: 1.242e+11, MSE(e): 6.763e-03, MSE(pi1): 1.101e-01, MSE(pi2): 3.798e-03, MSE(pi3): 9.139e-03\n",
      "Epoch 80200, Train loss: 5.441e+07, Test loss: 1.232e+11, MSE(e): 5.288e-03, MSE(pi1): 7.802e-02, MSE(pi2): 3.133e-03, MSE(pi3): 7.510e-03\n",
      "Epoch 80300, Train loss: 7.673e+07, Test loss: 1.243e+11, MSE(e): 7.415e-03, MSE(pi1): 8.182e-02, MSE(pi2): 4.364e-03, MSE(pi3): 1.762e-02\n",
      "Epoch 80400, Train loss: 5.571e+07, Test loss: 1.233e+11, MSE(e): 5.203e-03, MSE(pi1): 2.585e-01, MSE(pi2): 3.058e-03, MSE(pi3): 1.097e-02\n",
      "Epoch 80500, Train loss: 6.125e+07, Test loss: 1.235e+11, MSE(e): 5.607e-03, MSE(pi1): 3.748e-01, MSE(pi2): 3.372e-03, MSE(pi3): 1.432e-02\n",
      "Epoch 80600, Train loss: 9.218e+07, Test loss: 1.238e+11, MSE(e): 6.532e-03, MSE(pi1): 2.465e+00, MSE(pi2): 3.948e-03, MSE(pi3): 2.213e-02\n",
      "Epoch 80700, Train loss: 5.653e+07, Test loss: 1.231e+11, MSE(e): 5.262e-03, MSE(pi1): 3.117e-01, MSE(pi2): 3.123e-03, MSE(pi3): 7.984e-03\n",
      "Epoch 80800, Train loss: 5.381e+07, Test loss: 1.233e+11, MSE(e): 5.127e-03, MSE(pi1): 1.816e-01, MSE(pi2): 3.031e-03, MSE(pi3): 7.206e-03\n",
      "Epoch 80900, Train loss: 6.486e+07, Test loss: 1.236e+11, MSE(e): 5.408e-03, MSE(pi1): 1.012e+00, MSE(pi2): 3.119e-03, MSE(pi3): 6.625e-03\n",
      "Epoch 81000, Train loss: 5.418e+07, Test loss: 1.234e+11, MSE(e): 5.160e-03, MSE(pi1): 1.764e-01, MSE(pi2): 3.047e-03, MSE(pi3): 8.126e-03\n",
      "Epoch 81100, Train loss: 5.256e+07, Test loss: 1.233e+11, MSE(e): 5.129e-03, MSE(pi1): 3.774e-02, MSE(pi2): 3.044e-03, MSE(pi3): 8.930e-03\n",
      "Epoch 81200, Train loss: 5.400e+07, Test loss: 1.232e+11, MSE(e): 5.151e-03, MSE(pi1): 1.710e-01, MSE(pi2): 3.051e-03, MSE(pi3): 7.708e-03\n",
      "Epoch 81300, Train loss: 7.057e+07, Test loss: 1.229e+11, MSE(e): 5.698e-03, MSE(pi1): 1.280e+00, MSE(pi2): 3.281e-03, MSE(pi3): 7.865e-03\n",
      "Epoch 81400, Train loss: 5.354e+07, Test loss: 1.234e+11, MSE(e): 5.130e-03, MSE(pi1): 1.032e-01, MSE(pi2): 3.036e-03, MSE(pi3): 1.211e-02\n",
      "Epoch 81500, Train loss: 5.262e+07, Test loss: 1.233e+11, MSE(e): 5.050e-03, MSE(pi1): 8.401e-02, MSE(pi2): 2.983e-03, MSE(pi3): 1.282e-02\n",
      "Epoch 81600, Train loss: 6.655e+07, Test loss: 1.229e+11, MSE(e): 5.759e-03, MSE(pi1): 8.089e-01, MSE(pi2): 3.440e-03, MSE(pi3): 8.690e-03\n",
      "Epoch 81700, Train loss: 5.379e+07, Test loss: 1.233e+11, MSE(e): 5.090e-03, MSE(pi1): 2.134e-01, MSE(pi2): 3.016e-03, MSE(pi3): 7.584e-03\n",
      "Epoch 81800, Train loss: 5.378e+07, Test loss: 1.233e+11, MSE(e): 5.039e-03, MSE(pi1): 2.664e-01, MSE(pi2): 2.973e-03, MSE(pi3): 7.217e-03\n",
      "Epoch 81900, Train loss: 5.890e+07, Test loss: 1.229e+11, MSE(e): 5.625e-03, MSE(pi1): 1.822e-01, MSE(pi2): 3.309e-03, MSE(pi3): 8.284e-03\n",
      "Epoch 82000, Train loss: 5.629e+07, Test loss: 1.237e+11, MSE(e): 5.272e-03, MSE(pi1): 2.307e-01, MSE(pi2): 3.039e-03, MSE(pi3): 1.260e-02\n",
      "Epoch 82100, Train loss: 7.885e+07, Test loss: 1.225e+11, MSE(e): 7.543e-03, MSE(pi1): 2.493e-01, MSE(pi2): 4.775e-03, MSE(pi3): 9.266e-03\n",
      "Epoch 82200, Train loss: 5.520e+07, Test loss: 1.233e+11, MSE(e): 5.288e-03, MSE(pi1): 1.578e-01, MSE(pi2): 3.176e-03, MSE(pi3): 7.503e-03\n",
      "Epoch 82300, Train loss: 5.567e+07, Test loss: 1.235e+11, MSE(e): 5.057e-03, MSE(pi1): 3.543e-01, MSE(pi2): 2.979e-03, MSE(pi3): 1.559e-02\n",
      "Epoch 82400, Train loss: 5.236e+07, Test loss: 1.235e+11, MSE(e): 5.007e-03, MSE(pi1): 5.473e-02, MSE(pi2): 2.945e-03, MSE(pi3): 1.745e-02\n",
      "Epoch 82500, Train loss: 6.191e+07, Test loss: 1.240e+11, MSE(e): 5.871e-03, MSE(pi1): 1.785e-01, MSE(pi2): 3.507e-03, MSE(pi3): 1.412e-02\n",
      "Epoch 82600, Train loss: 5.227e+07, Test loss: 1.233e+11, MSE(e): 5.008e-03, MSE(pi1): 1.318e-01, MSE(pi2): 2.966e-03, MSE(pi3): 8.795e-03\n",
      "Epoch 82700, Train loss: 5.180e+07, Test loss: 1.233e+11, MSE(e): 4.969e-03, MSE(pi1): 1.175e-01, MSE(pi2): 2.944e-03, MSE(pi3): 9.293e-03\n",
      "Epoch 82800, Train loss: 5.378e+07, Test loss: 1.232e+11, MSE(e): 5.036e-03, MSE(pi1): 2.692e-01, MSE(pi2): 2.987e-03, MSE(pi3): 7.309e-03\n",
      "Epoch 82900, Train loss: 5.527e+07, Test loss: 1.235e+11, MSE(e): 5.154e-03, MSE(pi1): 2.617e-01, MSE(pi2): 3.037e-03, MSE(pi3): 1.115e-02\n",
      "Epoch 83000, Train loss: 5.886e+07, Test loss: 1.237e+11, MSE(e): 5.468e-03, MSE(pi1): 2.760e-01, MSE(pi2): 3.272e-03, MSE(pi3): 1.422e-02\n",
      "Epoch 83100, Train loss: 5.225e+07, Test loss: 1.237e+11, MSE(e): 5.062e-03, MSE(pi1): 7.508e-02, MSE(pi2): 2.967e-03, MSE(pi3): 8.844e-03\n",
      "Epoch 83200, Train loss: 5.491e+07, Test loss: 1.237e+11, MSE(e): 5.219e-03, MSE(pi1): 1.813e-01, MSE(pi2): 3.112e-03, MSE(pi3): 9.028e-03\n",
      "Epoch 83300, Train loss: 5.857e+07, Test loss: 1.238e+11, MSE(e): 5.394e-03, MSE(pi1): 3.539e-01, MSE(pi2): 3.238e-03, MSE(pi3): 1.088e-02\n",
      "Epoch 83400, Train loss: 5.300e+07, Test loss: 1.234e+11, MSE(e): 4.917e-03, MSE(pi1): 3.134e-01, MSE(pi2): 2.894e-03, MSE(pi3): 6.974e-03\n",
      "Epoch 83500, Train loss: 5.573e+07, Test loss: 1.235e+11, MSE(e): 4.918e-03, MSE(pi1): 5.250e-01, MSE(pi2): 2.881e-03, MSE(pi3): 1.300e-02\n",
      "Epoch 83600, Train loss: 9.028e+07, Test loss: 1.243e+11, MSE(e): 7.585e-03, MSE(pi1): 1.008e+00, MSE(pi2): 4.395e-03, MSE(pi3): 4.346e-02\n",
      "Epoch 83700, Train loss: 5.145e+07, Test loss: 1.236e+11, MSE(e): 4.948e-03, MSE(pi1): 1.084e-01, MSE(pi2): 2.921e-03, MSE(pi3): 8.937e-03\n",
      "Epoch 83800, Train loss: 5.052e+07, Test loss: 1.234e+11, MSE(e): 4.850e-03, MSE(pi1): 1.126e-01, MSE(pi2): 2.861e-03, MSE(pi3): 8.999e-03\n",
      "Epoch 83900, Train loss: 5.860e+07, Test loss: 1.236e+11, MSE(e): 4.980e-03, MSE(pi1): 7.089e-01, MSE(pi2): 2.899e-03, MSE(pi3): 1.705e-02\n",
      "Epoch 84000, Train loss: 4.987e+07, Test loss: 1.233e+11, MSE(e): 4.862e-03, MSE(pi1): 4.080e-02, MSE(pi2): 2.866e-03, MSE(pi3): 8.452e-03\n",
      "Epoch 84100, Train loss: 6.475e+07, Test loss: 1.236e+11, MSE(e): 5.139e-03, MSE(pi1): 1.248e+00, MSE(pi2): 2.964e-03, MSE(pi3): 8.745e-03\n",
      "Epoch 84200, Train loss: 8.000e+07, Test loss: 1.225e+11, MSE(e): 7.478e-03, MSE(pi1): 4.382e-01, MSE(pi2): 4.629e-03, MSE(pi3): 8.452e-03\n",
      "Epoch 84300, Train loss: 9.228e+07, Test loss: 1.241e+11, MSE(e): 7.923e-03, MSE(pi1): 1.094e+00, MSE(pi2): 5.028e-03, MSE(pi3): 2.104e-02\n",
      "Epoch 84400, Train loss: 5.468e+07, Test loss: 1.233e+11, MSE(e): 4.912e-03, MSE(pi1): 3.856e-01, MSE(pi2): 2.905e-03, MSE(pi3): 1.701e-02\n",
      "Epoch 84500, Train loss: 4.889e+07, Test loss: 1.234e+11, MSE(e): 4.774e-03, MSE(pi1): 3.547e-02, MSE(pi2): 2.819e-03, MSE(pi3): 7.963e-03\n",
      "Epoch 84600, Train loss: 7.644e+07, Test loss: 1.234e+11, MSE(e): 5.128e-03, MSE(pi1): 2.417e+00, MSE(pi2): 2.952e-03, MSE(pi3): 9.881e-03\n",
      "Epoch 84700, Train loss: 5.395e+07, Test loss: 1.239e+11, MSE(e): 5.208e-03, MSE(pi1): 8.970e-02, MSE(pi2): 3.093e-03, MSE(pi3): 9.637e-03\n",
      "Epoch 84800, Train loss: 5.035e+07, Test loss: 1.238e+11, MSE(e): 4.870e-03, MSE(pi1): 7.020e-02, MSE(pi2): 2.876e-03, MSE(pi3): 9.436e-03\n",
      "Epoch 84900, Train loss: 5.306e+07, Test loss: 1.236e+11, MSE(e): 4.994e-03, MSE(pi1): 2.367e-01, MSE(pi2): 2.950e-03, MSE(pi3): 7.506e-03\n",
      "Epoch 85000, Train loss: 4.912e+07, Test loss: 1.234e+11, MSE(e): 4.753e-03, MSE(pi1): 8.314e-02, MSE(pi2): 2.805e-03, MSE(pi3): 7.552e-03\n",
      "Epoch 85100, Train loss: 5.154e+07, Test loss: 1.235e+11, MSE(e): 4.761e-03, MSE(pi1): 3.196e-01, MSE(pi2): 2.803e-03, MSE(pi3): 7.338e-03\n",
      "Epoch 85200, Train loss: 6.021e+07, Test loss: 1.237e+11, MSE(e): 5.169e-03, MSE(pi1): 6.226e-01, MSE(pi2): 3.093e-03, MSE(pi3): 2.299e-02\n",
      "Epoch 85300, Train loss: 4.918e+07, Test loss: 1.235e+11, MSE(e): 4.714e-03, MSE(pi1): 1.242e-01, MSE(pi2): 2.779e-03, MSE(pi3): 8.029e-03\n",
      "Epoch 85400, Train loss: 4.936e+07, Test loss: 1.234e+11, MSE(e): 4.742e-03, MSE(pi1): 1.037e-01, MSE(pi2): 2.801e-03, MSE(pi3): 8.999e-03\n",
      "Epoch 85500, Train loss: 4.964e+07, Test loss: 1.237e+11, MSE(e): 4.794e-03, MSE(pi1): 8.797e-02, MSE(pi2): 2.817e-03, MSE(pi3): 8.193e-03\n",
      "Epoch 85600, Train loss: 5.367e+07, Test loss: 1.236e+11, MSE(e): 4.813e-03, MSE(pi1): 4.713e-01, MSE(pi2): 2.803e-03, MSE(pi3): 8.308e-03\n",
      "Epoch 85700, Train loss: 5.543e+07, Test loss: 1.239e+11, MSE(e): 5.052e-03, MSE(pi1): 3.935e-01, MSE(pi2): 2.925e-03, MSE(pi3): 9.720e-03\n",
      "Epoch 85800, Train loss: 5.085e+07, Test loss: 1.235e+11, MSE(e): 4.841e-03, MSE(pi1): 1.600e-01, MSE(pi2): 2.847e-03, MSE(pi3): 8.322e-03\n",
      "Epoch 85900, Train loss: 4.820e+07, Test loss: 1.235e+11, MSE(e): 4.662e-03, MSE(pi1): 6.141e-02, MSE(pi2): 2.749e-03, MSE(pi3): 9.737e-03\n",
      "Epoch 86000, Train loss: 5.787e+07, Test loss: 1.233e+11, MSE(e): 4.757e-03, MSE(pi1): 9.668e-01, MSE(pi2): 2.773e-03, MSE(pi3): 6.349e-03\n",
      "Epoch 86100, Train loss: 5.144e+07, Test loss: 1.238e+11, MSE(e): 4.883e-03, MSE(pi1): 1.795e-01, MSE(pi2): 2.831e-03, MSE(pi3): 8.172e-03\n",
      "Epoch 86200, Train loss: 5.011e+07, Test loss: 1.233e+11, MSE(e): 4.742e-03, MSE(pi1): 1.654e-01, MSE(pi2): 2.794e-03, MSE(pi3): 1.041e-02\n",
      "Epoch 86300, Train loss: 6.328e+07, Test loss: 1.229e+11, MSE(e): 5.758e-03, MSE(pi1): 4.678e-01, MSE(pi2): 3.403e-03, MSE(pi3): 1.025e-02\n",
      "Epoch 86400, Train loss: 4.828e+07, Test loss: 1.234e+11, MSE(e): 4.651e-03, MSE(pi1): 1.002e-01, MSE(pi2): 2.745e-03, MSE(pi3): 7.708e-03\n",
      "Epoch 86500, Train loss: 5.620e+07, Test loss: 1.234e+11, MSE(e): 4.698e-03, MSE(pi1): 8.553e-01, MSE(pi2): 2.765e-03, MSE(pi3): 6.649e-03\n",
      "Epoch 86600, Train loss: 4.896e+07, Test loss: 1.234e+11, MSE(e): 4.701e-03, MSE(pi1): 1.222e-01, MSE(pi2): 2.780e-03, MSE(pi3): 7.279e-03\n",
      "Epoch 86700, Train loss: 6.187e+07, Test loss: 1.237e+11, MSE(e): 4.733e-03, MSE(pi1): 1.383e+00, MSE(pi2): 2.727e-03, MSE(pi3): 7.129e-03\n",
      "Epoch 86800, Train loss: 4.710e+07, Test loss: 1.234e+11, MSE(e): 4.583e-03, MSE(pi1): 4.762e-02, MSE(pi2): 2.702e-03, MSE(pi3): 7.895e-03\n",
      "Epoch 86900, Train loss: 5.038e+07, Test loss: 1.236e+11, MSE(e): 4.738e-03, MSE(pi1): 2.251e-01, MSE(pi2): 2.772e-03, MSE(pi3): 7.526e-03\n",
      "Epoch 87000, Train loss: 5.008e+07, Test loss: 1.234e+11, MSE(e): 4.648e-03, MSE(pi1): 2.803e-01, MSE(pi2): 2.744e-03, MSE(pi3): 8.027e-03\n",
      "Epoch 87100, Train loss: 5.664e+07, Test loss: 1.232e+11, MSE(e): 4.911e-03, MSE(pi1): 6.803e-01, MSE(pi2): 2.902e-03, MSE(pi3): 7.296e-03\n",
      "Epoch 87200, Train loss: 5.144e+07, Test loss: 1.236e+11, MSE(e): 4.969e-03, MSE(pi1): 1.000e-01, MSE(pi2): 2.940e-03, MSE(pi3): 7.553e-03\n",
      "Epoch 87300, Train loss: 6.493e+07, Test loss: 1.242e+11, MSE(e): 5.764e-03, MSE(pi1): 5.933e-01, MSE(pi2): 3.404e-03, MSE(pi3): 1.357e-02\n",
      "Epoch 87400, Train loss: 5.500e+07, Test loss: 1.231e+11, MSE(e): 4.928e-03, MSE(pi1): 4.976e-01, MSE(pi2): 2.929e-03, MSE(pi3): 7.440e-03\n",
      "Epoch 87500, Train loss: 7.183e+07, Test loss: 1.229e+11, MSE(e): 6.778e-03, MSE(pi1): 3.267e-01, MSE(pi2): 4.215e-03, MSE(pi3): 7.850e-03\n",
      "Epoch 87600, Train loss: 4.732e+07, Test loss: 1.236e+11, MSE(e): 4.573e-03, MSE(pi1): 3.637e-02, MSE(pi2): 2.690e-03, MSE(pi3): 1.233e-02\n",
      "Epoch 87700, Train loss: 5.209e+07, Test loss: 1.235e+11, MSE(e): 4.774e-03, MSE(pi1): 3.220e-01, MSE(pi2): 2.811e-03, MSE(pi3): 1.128e-02\n",
      "Epoch 87800, Train loss: 4.813e+07, Test loss: 1.238e+11, MSE(e): 4.576e-03, MSE(pi1): 1.557e-01, MSE(pi2): 2.686e-03, MSE(pi3): 8.149e-03\n",
      "Epoch 87900, Train loss: 5.293e+07, Test loss: 1.235e+11, MSE(e): 4.565e-03, MSE(pi1): 6.423e-01, MSE(pi2): 2.660e-03, MSE(pi3): 8.577e-03\n",
      "Epoch 88000, Train loss: 4.717e+07, Test loss: 1.236e+11, MSE(e): 4.584e-03, MSE(pi1): 5.330e-02, MSE(pi2): 2.708e-03, MSE(pi3): 7.954e-03\n",
      "Epoch 88100, Train loss: 5.140e+07, Test loss: 1.232e+11, MSE(e): 4.815e-03, MSE(pi1): 2.461e-01, MSE(pi2): 2.825e-03, MSE(pi3): 7.868e-03\n",
      "Epoch 88200, Train loss: 6.164e+07, Test loss: 1.241e+11, MSE(e): 5.399e-03, MSE(pi1): 6.301e-01, MSE(pi2): 3.257e-03, MSE(pi3): 1.351e-02\n",
      "Epoch 88300, Train loss: 4.942e+07, Test loss: 1.234e+11, MSE(e): 4.517e-03, MSE(pi1): 3.454e-01, MSE(pi2): 2.650e-03, MSE(pi3): 7.962e-03\n",
      "Epoch 88400, Train loss: 4.845e+07, Test loss: 1.235e+11, MSE(e): 4.648e-03, MSE(pi1): 6.254e-02, MSE(pi2): 2.734e-03, MSE(pi3): 1.345e-02\n",
      "Epoch 88500, Train loss: 6.328e+07, Test loss: 1.237e+11, MSE(e): 4.905e-03, MSE(pi1): 1.187e+00, MSE(pi2): 2.764e-03, MSE(pi3): 2.363e-02\n",
      "Epoch 88600, Train loss: 4.643e+07, Test loss: 1.237e+11, MSE(e): 4.512e-03, MSE(pi1): 4.997e-02, MSE(pi2): 2.652e-03, MSE(pi3): 8.123e-03\n",
      "Epoch 88700, Train loss: 4.823e+07, Test loss: 1.237e+11, MSE(e): 4.595e-03, MSE(pi1): 1.547e-01, MSE(pi2): 2.681e-03, MSE(pi3): 7.372e-03\n",
      "Epoch 88800, Train loss: 5.431e+07, Test loss: 1.238e+11, MSE(e): 4.783e-03, MSE(pi1): 5.435e-01, MSE(pi2): 2.766e-03, MSE(pi3): 1.043e-02\n",
      "Epoch 88900, Train loss: 4.986e+07, Test loss: 1.241e+11, MSE(e): 4.826e-03, MSE(pi1): 6.868e-02, MSE(pi2): 2.840e-03, MSE(pi3): 9.140e-03\n",
      "Epoch 89000, Train loss: 4.967e+07, Test loss: 1.235e+11, MSE(e): 4.466e-03, MSE(pi1): 4.222e-01, MSE(pi2): 2.615e-03, MSE(pi3): 7.920e-03\n",
      "Epoch 89100, Train loss: 4.812e+07, Test loss: 1.238e+11, MSE(e): 4.466e-03, MSE(pi1): 2.626e-01, MSE(pi2): 2.622e-03, MSE(pi3): 8.303e-03\n",
      "Epoch 89200, Train loss: 4.567e+07, Test loss: 1.235e+11, MSE(e): 4.425e-03, MSE(pi1): 5.991e-02, MSE(pi2): 2.611e-03, MSE(pi3): 8.242e-03\n",
      "Epoch 89300, Train loss: 5.080e+07, Test loss: 1.235e+11, MSE(e): 4.447e-03, MSE(pi1): 5.561e-01, MSE(pi2): 2.596e-03, MSE(pi3): 7.731e-03\n",
      "Epoch 89400, Train loss: 5.527e+07, Test loss: 1.241e+11, MSE(e): 5.227e-03, MSE(pi1): 1.950e-01, MSE(pi2): 2.936e-03, MSE(pi3): 1.046e-02\n",
      "Epoch 89500, Train loss: 6.260e+07, Test loss: 1.231e+11, MSE(e): 5.416e-03, MSE(pi1): 7.591e-01, MSE(pi2): 3.351e-03, MSE(pi3): 8.547e-03\n",
      "Epoch 89600, Train loss: 4.618e+07, Test loss: 1.235e+11, MSE(e): 4.415e-03, MSE(pi1): 1.265e-01, MSE(pi2): 2.589e-03, MSE(pi3): 7.649e-03\n",
      "Epoch 89700, Train loss: 7.237e+07, Test loss: 1.246e+11, MSE(e): 6.817e-03, MSE(pi1): 1.482e-01, MSE(pi2): 3.984e-03, MSE(pi3): 2.711e-02\n",
      "Epoch 89800, Train loss: 4.657e+07, Test loss: 1.235e+11, MSE(e): 4.449e-03, MSE(pi1): 1.321e-01, MSE(pi2): 2.626e-03, MSE(pi3): 7.646e-03\n",
      "Epoch 89900, Train loss: 4.653e+07, Test loss: 1.234e+11, MSE(e): 4.485e-03, MSE(pi1): 9.850e-02, MSE(pi2): 2.647e-03, MSE(pi3): 6.949e-03\n",
      "Epoch 90000, Train loss: 6.438e+07, Test loss: 1.241e+11, MSE(e): 5.260e-03, MSE(pi1): 9.969e-01, MSE(pi2): 3.070e-03, MSE(pi3): 1.807e-02\n",
      "Epoch 90100, Train loss: 4.568e+07, Test loss: 1.238e+11, MSE(e): 4.347e-03, MSE(pi1): 1.311e-01, MSE(pi2): 2.557e-03, MSE(pi3): 9.024e-03\n",
      "Epoch 90200, Train loss: 4.729e+07, Test loss: 1.235e+11, MSE(e): 4.419e-03, MSE(pi1): 2.324e-01, MSE(pi2): 2.584e-03, MSE(pi3): 7.774e-03\n",
      "Epoch 90300, Train loss: 4.594e+07, Test loss: 1.235e+11, MSE(e): 4.358e-03, MSE(pi1): 1.654e-01, MSE(pi2): 2.558e-03, MSE(pi3): 7.045e-03\n",
      "Epoch 90400, Train loss: 4.553e+07, Test loss: 1.235e+11, MSE(e): 4.365e-03, MSE(pi1): 5.334e-02, MSE(pi2): 2.566e-03, MSE(pi3): 1.348e-02\n",
      "Epoch 90500, Train loss: 4.521e+07, Test loss: 1.236e+11, MSE(e): 4.314e-03, MSE(pi1): 1.101e-01, MSE(pi2): 2.541e-03, MSE(pi3): 9.663e-03\n",
      "Epoch 90600, Train loss: 4.618e+07, Test loss: 1.235e+11, MSE(e): 4.475e-03, MSE(pi1): 5.994e-02, MSE(pi2): 2.609e-03, MSE(pi3): 8.267e-03\n",
      "Epoch 90700, Train loss: 4.505e+07, Test loss: 1.237e+11, MSE(e): 4.295e-03, MSE(pi1): 1.242e-01, MSE(pi2): 2.522e-03, MSE(pi3): 8.576e-03\n",
      "Epoch 90800, Train loss: 4.858e+07, Test loss: 1.240e+11, MSE(e): 4.564e-03, MSE(pi1): 2.003e-01, MSE(pi2): 2.669e-03, MSE(pi3): 9.447e-03\n",
      "Epoch 90900, Train loss: 6.531e+07, Test loss: 1.230e+11, MSE(e): 6.149e-03, MSE(pi1): 3.055e-01, MSE(pi2): 3.542e-03, MSE(pi3): 7.667e-03\n",
      "Epoch 91000, Train loss: 4.824e+07, Test loss: 1.234e+11, MSE(e): 4.680e-03, MSE(pi1): 6.452e-02, MSE(pi2): 2.756e-03, MSE(pi3): 8.031e-03\n",
      "Epoch 91100, Train loss: 4.837e+07, Test loss: 1.238e+11, MSE(e): 4.301e-03, MSE(pi1): 4.548e-01, MSE(pi2): 2.514e-03, MSE(pi3): 8.106e-03\n",
      "Epoch 91200, Train loss: 4.431e+07, Test loss: 1.238e+11, MSE(e): 4.265e-03, MSE(pi1): 8.153e-02, MSE(pi2): 2.496e-03, MSE(pi3): 8.447e-03\n",
      "Epoch 91300, Train loss: 4.506e+07, Test loss: 1.238e+11, MSE(e): 4.279e-03, MSE(pi1): 1.458e-01, MSE(pi2): 2.508e-03, MSE(pi3): 8.108e-03\n",
      "Epoch 91400, Train loss: 4.680e+07, Test loss: 1.240e+11, MSE(e): 4.425e-03, MSE(pi1): 1.638e-01, MSE(pi2): 2.564e-03, MSE(pi3): 9.089e-03\n",
      "Epoch 91500, Train loss: 4.402e+07, Test loss: 1.238e+11, MSE(e): 4.231e-03, MSE(pi1): 8.635e-02, MSE(pi2): 2.487e-03, MSE(pi3): 8.470e-03\n",
      "Epoch 91600, Train loss: 5.186e+07, Test loss: 1.236e+11, MSE(e): 4.355e-03, MSE(pi1): 7.644e-01, MSE(pi2): 2.548e-03, MSE(pi3): 6.599e-03\n",
      "Epoch 91700, Train loss: 5.322e+07, Test loss: 1.237e+11, MSE(e): 4.334e-03, MSE(pi1): 9.147e-01, MSE(pi2): 2.498e-03, MSE(pi3): 7.306e-03\n",
      "Epoch 91800, Train loss: 4.546e+07, Test loss: 1.237e+11, MSE(e): 4.245e-03, MSE(pi1): 2.196e-01, MSE(pi2): 2.500e-03, MSE(pi3): 8.215e-03\n",
      "Epoch 91900, Train loss: 4.301e+07, Test loss: 1.238e+11, MSE(e): 4.178e-03, MSE(pi1): 4.429e-02, MSE(pi2): 2.454e-03, MSE(pi3): 7.915e-03\n",
      "Epoch 92000, Train loss: 4.574e+07, Test loss: 1.239e+11, MSE(e): 4.286e-03, MSE(pi1): 2.152e-01, MSE(pi2): 2.499e-03, MSE(pi3): 7.307e-03\n",
      "Epoch 92100, Train loss: 4.299e+07, Test loss: 1.238e+11, MSE(e): 4.162e-03, MSE(pi1): 5.718e-02, MSE(pi2): 2.446e-03, MSE(pi3): 7.933e-03\n",
      "Epoch 92200, Train loss: 4.960e+07, Test loss: 1.242e+11, MSE(e): 4.590e-03, MSE(pi1): 2.747e-01, MSE(pi2): 2.732e-03, MSE(pi3): 9.547e-03\n",
      "Epoch 92300, Train loss: 4.703e+07, Test loss: 1.238e+11, MSE(e): 4.469e-03, MSE(pi1): 1.403e-01, MSE(pi2): 2.665e-03, MSE(pi3): 9.421e-03\n",
      "Epoch 92400, Train loss: 4.665e+07, Test loss: 1.237e+11, MSE(e): 4.364e-03, MSE(pi1): 2.126e-01, MSE(pi2): 2.547e-03, MSE(pi3): 8.834e-03\n",
      "Epoch 92500, Train loss: 5.343e+07, Test loss: 1.233e+11, MSE(e): 5.176e-03, MSE(pi1): 8.441e-02, MSE(pi2): 3.138e-03, MSE(pi3): 8.227e-03\n",
      "Epoch 92600, Train loss: 4.484e+07, Test loss: 1.239e+11, MSE(e): 4.335e-03, MSE(pi1): 3.326e-02, MSE(pi2): 2.564e-03, MSE(pi3): 1.155e-02\n",
      "Epoch 92700, Train loss: 4.439e+07, Test loss: 1.238e+11, MSE(e): 4.141e-03, MSE(pi1): 2.151e-01, MSE(pi2): 2.425e-03, MSE(pi3): 8.297e-03\n",
      "Epoch 92800, Train loss: 4.578e+07, Test loss: 1.238e+11, MSE(e): 4.185e-03, MSE(pi1): 3.016e-01, MSE(pi2): 2.449e-03, MSE(pi3): 9.104e-03\n",
      "Epoch 92900, Train loss: 4.249e+07, Test loss: 1.238e+11, MSE(e): 4.125e-03, MSE(pi1): 4.942e-02, MSE(pi2): 2.427e-03, MSE(pi3): 7.413e-03\n",
      "Epoch 93000, Train loss: 4.852e+07, Test loss: 1.236e+11, MSE(e): 4.304e-03, MSE(pi1): 4.822e-01, MSE(pi2): 2.550e-03, MSE(pi3): 6.573e-03\n",
      "Epoch 93100, Train loss: 4.842e+07, Test loss: 1.235e+11, MSE(e): 4.679e-03, MSE(pi1): 8.625e-02, MSE(pi2): 2.745e-03, MSE(pi3): 7.723e-03\n",
      "Epoch 93200, Train loss: 4.422e+07, Test loss: 1.237e+11, MSE(e): 4.293e-03, MSE(pi1): 3.195e-02, MSE(pi2): 2.504e-03, MSE(pi3): 9.731e-03\n",
      "Epoch 93300, Train loss: 4.547e+07, Test loss: 1.238e+11, MSE(e): 4.171e-03, MSE(pi1): 2.840e-01, MSE(pi2): 2.447e-03, MSE(pi3): 9.245e-03\n",
      "Epoch 93400, Train loss: 4.807e+07, Test loss: 1.238e+11, MSE(e): 4.148e-03, MSE(pi1): 4.920e-01, MSE(pi2): 2.414e-03, MSE(pi3): 1.664e-02\n",
      "Epoch 93500, Train loss: 4.220e+07, Test loss: 1.240e+11, MSE(e): 4.077e-03, MSE(pi1): 5.736e-02, MSE(pi2): 2.394e-03, MSE(pi3): 8.576e-03\n",
      "Epoch 93600, Train loss: 4.389e+07, Test loss: 1.240e+11, MSE(e): 4.132e-03, MSE(pi1): 1.778e-01, MSE(pi2): 2.415e-03, MSE(pi3): 7.866e-03\n",
      "Epoch 93700, Train loss: 4.266e+07, Test loss: 1.239e+11, MSE(e): 4.120e-03, MSE(pi1): 6.444e-02, MSE(pi2): 2.408e-03, MSE(pi3): 8.229e-03\n",
      "Epoch 93800, Train loss: 4.634e+07, Test loss: 1.243e+11, MSE(e): 4.285e-03, MSE(pi1): 2.729e-01, MSE(pi2): 2.492e-03, MSE(pi3): 7.588e-03\n",
      "Epoch 93900, Train loss: 5.078e+07, Test loss: 1.241e+11, MSE(e): 4.135e-03, MSE(pi1): 8.612e-01, MSE(pi2): 2.402e-03, MSE(pi3): 8.184e-03\n",
      "Epoch 94000, Train loss: 4.428e+07, Test loss: 1.240e+11, MSE(e): 4.088e-03, MSE(pi1): 2.562e-01, MSE(pi2): 2.401e-03, MSE(pi3): 8.432e-03\n",
      "Epoch 94100, Train loss: 4.404e+07, Test loss: 1.237e+11, MSE(e): 4.162e-03, MSE(pi1): 1.697e-01, MSE(pi2): 2.434e-03, MSE(pi3): 7.186e-03\n",
      "Epoch 94200, Train loss: 5.006e+07, Test loss: 1.237e+11, MSE(e): 4.362e-03, MSE(pi1): 5.782e-01, MSE(pi2): 2.573e-03, MSE(pi3): 6.598e-03\n",
      "Epoch 94300, Train loss: 4.628e+07, Test loss: 1.236e+11, MSE(e): 4.444e-03, MSE(pi1): 1.132e-01, MSE(pi2): 2.651e-03, MSE(pi3): 7.008e-03\n",
      "Epoch 94400, Train loss: 4.962e+07, Test loss: 1.243e+11, MSE(e): 4.816e-03, MSE(pi1): 5.156e-02, MSE(pi2): 2.904e-03, MSE(pi3): 9.378e-03\n",
      "Epoch 94500, Train loss: 8.208e+07, Test loss: 1.253e+11, MSE(e): 7.972e-03, MSE(pi1): 9.896e-02, MSE(pi2): 4.702e-03, MSE(pi3): 1.371e-02\n",
      "Epoch 94600, Train loss: 4.623e+07, Test loss: 1.244e+11, MSE(e): 4.254e-03, MSE(pi1): 2.836e-01, MSE(pi2): 2.442e-03, MSE(pi3): 8.603e-03\n",
      "Epoch 94700, Train loss: 4.292e+07, Test loss: 1.242e+11, MSE(e): 4.085e-03, MSE(pi1): 1.031e-01, MSE(pi2): 2.395e-03, MSE(pi3): 1.039e-02\n",
      "Epoch 94800, Train loss: 4.468e+07, Test loss: 1.239e+11, MSE(e): 4.027e-03, MSE(pi1): 3.700e-01, MSE(pi2): 2.364e-03, MSE(pi3): 7.091e-03\n",
      "Epoch 94900, Train loss: 1.156e+08, Test loss: 1.255e+11, MSE(e): 1.075e-02, MSE(pi1): 5.986e-01, MSE(pi2): 6.348e-03, MSE(pi3): 2.105e-02\n",
      "Epoch 95000, Train loss: 4.379e+07, Test loss: 1.239e+11, MSE(e): 4.047e-03, MSE(pi1): 2.623e-01, MSE(pi2): 2.369e-03, MSE(pi3): 6.953e-03\n",
      "Epoch 95100, Train loss: 4.384e+07, Test loss: 1.244e+11, MSE(e): 4.148e-03, MSE(pi1): 1.412e-01, MSE(pi2): 2.396e-03, MSE(pi3): 9.475e-03\n",
      "Epoch 95200, Train loss: 4.976e+07, Test loss: 1.246e+11, MSE(e): 4.654e-03, MSE(pi1): 2.219e-01, MSE(pi2): 2.680e-03, MSE(pi3): 1.001e-02\n",
      "Epoch 95300, Train loss: 9.796e+07, Test loss: 1.226e+11, MSE(e): 8.453e-03, MSE(pi1): 1.219e+00, MSE(pi2): 5.187e-03, MSE(pi3): 1.246e-02\n",
      "Epoch 95400, Train loss: 4.056e+07, Test loss: 1.241e+11, MSE(e): 3.921e-03, MSE(pi1): 5.433e-02, MSE(pi2): 2.299e-03, MSE(pi3): 8.051e-03\n",
      "Epoch 95500, Train loss: 5.088e+07, Test loss: 1.243e+11, MSE(e): 4.828e-03, MSE(pi1): 1.706e-01, MSE(pi2): 2.915e-03, MSE(pi3): 8.901e-03\n",
      "Epoch 95600, Train loss: 6.028e+07, Test loss: 1.251e+11, MSE(e): 5.683e-03, MSE(pi1): 2.333e-01, MSE(pi2): 3.292e-03, MSE(pi3): 1.116e-02\n",
      "Epoch 95700, Train loss: 4.100e+07, Test loss: 1.240e+11, MSE(e): 3.938e-03, MSE(pi1): 8.922e-02, MSE(pi2): 2.315e-03, MSE(pi3): 7.185e-03\n",
      "Epoch 95800, Train loss: 5.026e+07, Test loss: 1.240e+11, MSE(e): 4.417e-03, MSE(pi1): 4.804e-01, MSE(pi2): 2.564e-03, MSE(pi3): 1.285e-02\n",
      "Epoch 95900, Train loss: 4.748e+07, Test loss: 1.237e+11, MSE(e): 4.454e-03, MSE(pi1): 2.250e-01, MSE(pi2): 2.634e-03, MSE(pi3): 6.847e-03\n",
      "Epoch 96000, Train loss: 4.662e+07, Test loss: 1.242e+11, MSE(e): 3.955e-03, MSE(pi1): 5.915e-01, MSE(pi2): 2.294e-03, MSE(pi3): 1.154e-02\n",
      "Epoch 96100, Train loss: 4.233e+07, Test loss: 1.243e+11, MSE(e): 3.936e-03, MSE(pi1): 2.240e-01, MSE(pi2): 2.294e-03, MSE(pi3): 7.340e-03\n",
      "Epoch 96200, Train loss: 4.206e+07, Test loss: 1.243e+11, MSE(e): 3.891e-03, MSE(pi1): 2.309e-01, MSE(pi2): 2.275e-03, MSE(pi3): 8.375e-03\n",
      "Epoch 96300, Train loss: 4.630e+07, Test loss: 1.239e+11, MSE(e): 4.349e-03, MSE(pi1): 2.134e-01, MSE(pi2): 2.603e-03, MSE(pi3): 6.681e-03\n",
      "Epoch 96400, Train loss: 4.614e+07, Test loss: 1.245e+11, MSE(e): 4.242e-03, MSE(pi1): 2.263e-01, MSE(pi2): 2.512e-03, MSE(pi3): 1.460e-02\n",
      "Epoch 96500, Train loss: 4.689e+07, Test loss: 1.247e+11, MSE(e): 4.536e-03, MSE(pi1): 3.694e-02, MSE(pi2): 2.590e-03, MSE(pi3): 1.163e-02\n",
      "Epoch 96600, Train loss: 4.968e+07, Test loss: 1.238e+11, MSE(e): 4.651e-03, MSE(pi1): 2.410e-01, MSE(pi2): 2.790e-03, MSE(pi3): 7.562e-03\n",
      "Epoch 96700, Train loss: 4.195e+07, Test loss: 1.242e+11, MSE(e): 3.919e-03, MSE(pi1): 2.063e-01, MSE(pi2): 2.297e-03, MSE(pi3): 6.958e-03\n",
      "Epoch 96800, Train loss: 5.836e+07, Test loss: 1.235e+11, MSE(e): 5.135e-03, MSE(pi1): 6.264e-01, MSE(pi2): 3.080e-03, MSE(pi3): 7.404e-03\n",
      "Epoch 96900, Train loss: 4.465e+07, Test loss: 1.244e+11, MSE(e): 3.917e-03, MSE(pi1): 4.507e-01, MSE(pi2): 2.271e-03, MSE(pi3): 9.698e-03\n",
      "Epoch 97000, Train loss: 4.311e+07, Test loss: 1.240e+11, MSE(e): 4.039e-03, MSE(pi1): 2.039e-01, MSE(pi2): 2.376e-03, MSE(pi3): 6.833e-03\n",
      "Epoch 97100, Train loss: 4.272e+07, Test loss: 1.244e+11, MSE(e): 3.880e-03, MSE(pi1): 2.463e-01, MSE(pi2): 2.270e-03, MSE(pi3): 1.458e-02\n",
      "Epoch 97200, Train loss: 4.051e+07, Test loss: 1.244e+11, MSE(e): 3.802e-03, MSE(pi1): 1.789e-01, MSE(pi2): 2.221e-03, MSE(pi3): 7.044e-03\n",
      "Epoch 97300, Train loss: 4.212e+07, Test loss: 1.242e+11, MSE(e): 3.822e-03, MSE(pi1): 3.293e-01, MSE(pi2): 2.232e-03, MSE(pi3): 6.132e-03\n",
      "Epoch 97400, Train loss: 4.602e+07, Test loss: 1.241e+11, MSE(e): 4.081e-03, MSE(pi1): 4.396e-01, MSE(pi2): 2.373e-03, MSE(pi3): 8.101e-03\n",
      "Epoch 97500, Train loss: 5.779e+07, Test loss: 1.241e+11, MSE(e): 5.273e-03, MSE(pi1): 3.741e-01, MSE(pi2): 3.122e-03, MSE(pi3): 1.317e-02\n",
      "Epoch 97600, Train loss: 4.294e+07, Test loss: 1.243e+11, MSE(e): 4.070e-03, MSE(pi1): 1.576e-01, MSE(pi2): 2.400e-03, MSE(pi3): 6.725e-03\n",
      "Epoch 97700, Train loss: 4.421e+07, Test loss: 1.240e+11, MSE(e): 4.228e-03, MSE(pi1): 8.975e-02, MSE(pi2): 2.488e-03, MSE(pi3): 1.025e-02\n",
      "Epoch 97800, Train loss: 4.791e+07, Test loss: 1.242e+11, MSE(e): 3.913e-03, MSE(pi1): 8.034e-01, MSE(pi2): 2.256e-03, MSE(pi3): 7.504e-03\n",
      "Epoch 97900, Train loss: 4.163e+07, Test loss: 1.247e+11, MSE(e): 4.015e-03, MSE(pi1): 6.603e-02, MSE(pi2): 2.343e-03, MSE(pi3): 8.162e-03\n",
      "Epoch 98000, Train loss: 4.577e+07, Test loss: 1.243e+11, MSE(e): 3.836e-03, MSE(pi1): 6.618e-01, MSE(pi2): 2.227e-03, MSE(pi3): 7.969e-03\n",
      "Epoch 98100, Train loss: 4.177e+07, Test loss: 1.247e+11, MSE(e): 3.988e-03, MSE(pi1): 7.914e-02, MSE(pi2): 2.362e-03, MSE(pi3): 1.094e-02\n",
      "Epoch 98200, Train loss: 4.565e+07, Test loss: 1.242e+11, MSE(e): 4.191e-03, MSE(pi1): 2.963e-01, MSE(pi2): 2.506e-03, MSE(pi3): 7.732e-03\n",
      "Epoch 98300, Train loss: 3.827e+07, Test loss: 1.245e+11, MSE(e): 3.715e-03, MSE(pi1): 3.795e-02, MSE(pi2): 2.174e-03, MSE(pi3): 7.394e-03\n",
      "Epoch 98400, Train loss: 6.752e+07, Test loss: 1.239e+11, MSE(e): 6.262e-03, MSE(pi1): 2.534e-01, MSE(pi2): 3.915e-03, MSE(pi3): 2.361e-02\n",
      "Epoch 98500, Train loss: 3.877e+07, Test loss: 1.248e+11, MSE(e): 3.761e-03, MSE(pi1): 4.041e-02, MSE(pi2): 2.193e-03, MSE(pi3): 7.609e-03\n",
      "Epoch 98600, Train loss: 4.153e+07, Test loss: 1.244e+11, MSE(e): 3.777e-03, MSE(pi1): 3.030e-01, MSE(pi2): 2.199e-03, MSE(pi3): 7.323e-03\n",
      "Epoch 98700, Train loss: 4.289e+07, Test loss: 1.246e+11, MSE(e): 4.036e-03, MSE(pi1): 1.858e-01, MSE(pi2): 2.380e-03, MSE(pi3): 6.725e-03\n",
      "Epoch 98800, Train loss: 3.935e+07, Test loss: 1.247e+11, MSE(e): 3.714e-03, MSE(pi1): 1.544e-01, MSE(pi2): 2.169e-03, MSE(pi3): 6.696e-03\n",
      "Epoch 98900, Train loss: 4.076e+07, Test loss: 1.249e+11, MSE(e): 3.933e-03, MSE(pi1): 5.482e-02, MSE(pi2): 2.307e-03, MSE(pi3): 8.767e-03\n",
      "Epoch 99000, Train loss: 4.214e+07, Test loss: 1.247e+11, MSE(e): 3.706e-03, MSE(pi1): 4.051e-01, MSE(pi2): 2.153e-03, MSE(pi3): 1.029e-02\n",
      "Epoch 99100, Train loss: 4.658e+07, Test loss: 1.241e+11, MSE(e): 4.464e-03, MSE(pi1): 1.244e-01, MSE(pi2): 2.599e-03, MSE(pi3): 6.921e-03\n",
      "Epoch 99200, Train loss: 4.646e+07, Test loss: 1.247e+11, MSE(e): 3.752e-03, MSE(pi1): 7.847e-01, MSE(pi2): 2.167e-03, MSE(pi3): 1.095e-02\n",
      "Epoch 99300, Train loss: 3.829e+07, Test loss: 1.247e+11, MSE(e): 3.678e-03, MSE(pi1): 4.475e-02, MSE(pi2): 2.153e-03, MSE(pi3): 1.060e-02\n",
      "Epoch 99400, Train loss: 5.554e+07, Test loss: 1.246e+11, MSE(e): 4.184e-03, MSE(pi1): 9.426e-01, MSE(pi2): 2.408e-03, MSE(pi3): 4.273e-02\n",
      "Epoch 99500, Train loss: 3.827e+07, Test loss: 1.245e+11, MSE(e): 3.714e-03, MSE(pi1): 3.850e-02, MSE(pi2): 2.164e-03, MSE(pi3): 7.432e-03\n",
      "Epoch 99600, Train loss: 4.122e+07, Test loss: 1.246e+11, MSE(e): 3.681e-03, MSE(pi1): 3.493e-01, MSE(pi2): 2.144e-03, MSE(pi3): 9.120e-03\n",
      "Epoch 99700, Train loss: 5.656e+07, Test loss: 1.239e+11, MSE(e): 5.012e-03, MSE(pi1): 5.735e-01, MSE(pi2): 2.863e-03, MSE(pi3): 7.054e-03\n",
      "Epoch 99800, Train loss: 6.360e+07, Test loss: 1.240e+11, MSE(e): 5.283e-03, MSE(pi1): 1.004e+00, MSE(pi2): 3.215e-03, MSE(pi3): 7.307e-03\n",
      "Epoch 99900, Train loss: 6.235e+07, Test loss: 1.255e+11, MSE(e): 6.043e-03, MSE(pi1): 8.179e-02, MSE(pi2): 3.552e-03, MSE(pi3): 1.098e-02\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 18000\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64 \n",
    "n_checkpoints = 10\n",
    "\n",
    "second_lr = 3e-4\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f62851baed0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(model(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            model(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parametros de entrenamiento\n",
    "# start_epoch = 9000\n",
    "# n_epochs = 100000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 100\n",
    "\n",
    "# second_lr = 1e-4\n",
    "\n",
    "# train_loop(model, optimizer, X_train_NN, y_train_NN, f_train_NN, X_test_NN, y_test_NN, f_test_NN,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
