{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from utils.checkpoints import load_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder successfully created at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/transfer_learning/results/sigmoid_training_decoder\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear_1000_0/model_autoencoder_AE_10\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear_1000_0/model_autoencoder_NN_10\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear/sigmoid_nonlinear.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/sigmoid_training_decoder')\n",
    "\n",
    "MODEL_RESULTS_AE_PATH = os.path.join(ROOT_PATH, r'results/non_linear_1000_0/model_autoencoder_AE_10')\n",
    "MODEL_RESULTS_PGNNIV_PATH = os.path.join(ROOT_PATH, r'results/non_linear_1000_0/model_autoencoder_NN_10')\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/sigmoid_training_decoder')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_AE_PATH)\n",
    "create_folder(MODEL_RESULTS_PGNNIV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear/sigmoid_nonlinear.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 80\n",
      "Validation dataset length: 20\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X_train, y_train, K_train, f_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Autoencoder as PretrainedAutoencoder\n",
    "from model.ae_nonlinear_model import AutoencoderNonlinearModel as PretrainedPGNNNIV\n",
    "from model.transfer_learnign_ae import AutoencoderTransferLearning as TransferLearningAutoencoder\n",
    "from trainers.train import train_autoencoder_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from model.ae_nonlinear_model import AutoencoderNonlinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other parameters\n",
    "n_filters_explanatory = 5\n",
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autoencoder\n",
    "autoencoder_input_shape = y_train.values[0].shape\n",
    "latent_space_dim = [20, 10, n_modes, 10, 20]\n",
    "autoencoder_output_shape = y_train.values[0].shape\n",
    "\n",
    "pretrained_autoencoder = PretrainedAutoencoder(autoencoder_input_shape, latent_space_dim, autoencoder_output_shape).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(pretrained_autoencoder.parameters(), lr=1e-4)\n",
    "pretrained_autoencoder, optimizer, lists = load_results(pretrained_autoencoder, optimizer, MODEL_RESULTS_AE_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained PGNNIV\n",
    "pretrained_encoder = pretrained_autoencoder.encoder\n",
    "pretrained_decoder = pretrained_autoencoder.decoder\n",
    "\n",
    "pretrained_pgnniv = AutoencoderNonlinearModel(input_shape, predictive_layers, pretrained_decoder, predictive_output, explanatory_input,\n",
    "                        explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(pretrained_pgnniv.parameters(), lr=1e-4)\n",
    "pretrained_pgnniv, optimizer, lists = load_results(pretrained_pgnniv, optimizer, MODEL_RESULTS_PGNNIV_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa57012e0f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7sUlEQVR4nO3deXxU9b3/8fckIQkICbKFgCxxQzAKEmTTWNewiaK24OUKrlSsyIXUJRGrQKlBq4iKoFbQekXECnq1UEr8iYAsVTCACIoKGIQEDJQJYckyOb8/YlJjJsmcmXNmfT0fjzzuzcn3c+aTcWzefs/3fI/DMAxDAAAAISIq0A0AAACYQXgBAAAhhfACAABCCuEFAACEFMILAAAIKYQXAAAQUggvAAAgpBBeAABASIkJdANWq6ys1IEDB9SiRQs5HI5AtwMAADxgGIaOHTumDh06KCqq4bmVsAsvBw4cUKdOnQLdBgAA8MK+fft0xhlnNDgm7MJLixYtJFX98gkJCQHuBgAAeKK4uFidOnWq+TvekLALL9WXihISEggvAACEGE+WfLBgFwAAhBTCCwAACCmEFwAAEFIILwAAIKQQXgAAQEghvAAAgJBCeAEAACHF1vCyZs0aDR8+XB06dJDD4dB7773XaM3q1auVlpam+Ph4nXnmmXrxxRftbBEAAIQYW8PL8ePH1bNnT82ZM8ej8Xv27NHQoUOVnp6uvLw8Pfzww5o4caKWLFliZ5sAAMATlS5pz1rpi3eq/m+lKyBt2LrD7pAhQzRkyBCPx7/44ovq3LmzZs+eLUnq3r27Nm3apKeeeko33XSTTV0CAIBG7XhfWvGQVHzgP8cSOkiDn5B6XOfXVoLq8QAbNmxQRkZGrWODBg3S/PnzVV5eriZNmtSpKS0tVWlpac33xcXFtvcJAEBIqXRJ36+XjhVIx3+UTmsrtUiWugyUoqIbr9/xvvT2WElG7ePFBVXHR77u1wATVOGlsLBQSUlJtY4lJSWpoqJCRUVFSk5OrlOTk5OjadOm+atFAAACozqAlByUmieZCx6/nDGp5snMSaWrqv6XwUX66ZhDWpElnTfMs34sEFThRar7QCbDMNwer5adna3MzMya76ufSgkAQMirDiw7/y5tfVMq/dnVBU+CR30zJtWKDzQ+c/L9evfBp4YhFe+vGpeS3thvZImgCi/t27dXYWFhrWOHDh1STEyMWrdu7bYmLi5OcXFx/mgPAAD/aWjGRGo8eDQ4Y/JzRsMzJyUHPevX03EWCKp9XgYMGKDc3Nxax1auXKk+ffq4Xe8CAEDIMHOnTvWMSYMzHlJN8HB3rkZnTH6meubEneZJ7o97O84Cts68lJSU6Ntvv635fs+ePdqyZYtatWqlzp07Kzs7W/v379frr78uSRo/frzmzJmjzMxMjRs3Ths2bND8+fO1aNEiO9sEAMB6lS5p7ydVQeXHr6TdH0tlx/7z8/ou+3g8Y/KT+i7ZmJ0JqW98l4FVvRYX1NOTo+rnXQaaez0f2BpeNm3apCuuuKLm++q1Kbfeeqtee+01FRQUKD8/v+bnKSkpWr58uSZPnqwXXnhBHTp00HPPPcdt0gCA0FHpktY8Ja1/Vio7Xv+4+i77mJkxqeYueJidCalvfFR0Vch6e6wkh2oHmJ/Wow6e6bfFupLkMKpXxIaJ4uJiJSYmyul0KiEhIdDtAADClbu7f75aJn0wUTr5b8/Pk9BRmvTFf/74f/GOtOROc73c+ve6My+VLml2agMzJg304I7bfV46VgUXC26TNvP3O6gW7AIAEBLc/SFverq50FLtl5d9zM6YNGvj/pJNrRmThjg8mznpcV3Vol5vbte2GOEFAICGVJRJn/1FOvxd1SZv5aek3R/VHedNcKn288s+ja4x+YWhT9cfIHpcV3VZqt59XkzOnERF++126IYQXgAA+KXqS0LrnpW+zW18vK9+Ptvi8YyJpIETpdQRDY/5+YyJtzvsBhnCCwAA1Spd0sdPSOufkypO+uc13V32aWzGpFkbadjT0vkjPHuNIJkxsQrhBQAASdq+VFo6Tqqs8O/r1nfZJwxnTKxCeAEARLZKl/TqEGnfv/z/2o1d9gmzGROrEF4AAJGj0iV9u0raOEc6dbTqDqH8jVL5Cf/2YfayD2ohvAAAwl+lS1o1U1r7lKRKm17kpw3cmraSTh75z+HYFtKZl0ud+1UtzOWyj88ILwCA8PbFO9KScbIvtPwkoUPVbcdBshdKOCO8AADCU0WZNLunVGJyq32zzh0kDbivdkhhnYqtCC8AgPBS6ZL+doe08z17X8cRLQ24V8r4o72vgzoILwCA8FDpklY9/tO6FhslpUq9RksXj5NiYu19LbhFeAEAhL7tS6V37pRt61raXyj1vJnAEiQILwCA0LZwpPTNP+05d5dLpTHvEliCDOEFABCaKl3SrB5SSaG15409TepxvXTts4SWIEV4AQCElkqX9PFMac2f5dFTlz3RqZ/U97fc2hwiCC8AgNBQHVrWPiUZFq1tSUqV7vxQim1qzfngF4QXAEDw2/Z21UMTrdKkufTQHi4LhSjCCwAguM3uJR3dY935zhkk/ffb1p0Pfkd4AQAEp4oy6alzqh6gaIWEM6QJm7hEFAYILwCA4LPiYWnjC9acyxEt3fSKlHqjNedDwBFeAADB5aXLpYI8388THS+N/F/pnKu4eyjMEF4AAMHjf2+yJricM1j678W+nwdBifACAAgO8y6VDn7h2zkSO0v3fsq6ljBHeAEABN7jnaSyYt/OMeA+adAMa/pBUCO8AAACp6JMeuIsqdyH4BLdVMrOZ8+WCEJ4AQAExj+ypH/N8+0czdpKD35rTT8IGYQXAID/PdtL+rePG8/1vUcaOtOSdhBaCC8AAP9aONK34NI8WZq0jctEEYzwAgDwn21vS9/80/v6ll2qggsiGuEFAOAfvu6a27KrNGmrZe0gdBFeAAD2e3OUtGuF9/U3/kW6cKR1/SCkEV4AAPZ6c6S0y8tLRfFtpAd3sb0/aokKdAMAgDC2cJT3waX9hVLWdwQX1EF4AQDYY0W29I2Xl4qSekrj11rbD8IG4QUAYL0v3pE2zvWuNqGzdM8aa/tBWGHNCwDAWiv/IK1/zrtaboWGB5h5AQBY58v3vA8u7S8kuMAjhBcAgDUqXdLfbvWutj1rXOA5wgsAwBrTW3lXl3KFNJ41LvAc4QUA4Lupid7VNWsr3fqepa0g/BFeAAC+eXW4d3VN20gPfmttL4gIhBcAgPdWZEnfe3HJp00P6aHvrO8HEYHwAgDwzso/SBvnma+LaSpN2GB9P4gYhBcAgHkVZd7dEh0dLz1SaH0/iCiEFwCAeX86w3xNwtnSHw5a3wsijl/Cy9y5c5WSkqL4+HilpaVp7dqG7+VfuHChevbsqWbNmik5OVm33367Dh8+7I9WAQCNmdZGMkrN12Vutr4XRCTbw8vixYs1adIkTZkyRXl5eUpPT9eQIUOUn5/vdvwnn3yisWPH6s4779SXX36pv/3tb/rss89011132d0qAKAx01tLRrn5ukePWN8LIpbt4WXWrFm68847ddddd6l79+6aPXu2OnXqpHnz3C/y2rhxo7p27aqJEycqJSVFl156qe6++25t2rTJ7lYBAA2Ze6lUWWG+buT/SlHR1veDiGVreCkrK9PmzZuVkZFR63hGRobWr1/vtmbgwIH64YcftHz5chmGoYMHD+qdd97RsGHD3I4vLS1VcXFxrS8AgMW2vSMd+sJ83Q0vST2us74fRDRbw0tRUZFcLpeSkpJqHU9KSlJhofvV5gMHDtTChQs1atQoxcbGqn379mrZsqWef/55t+NzcnKUmJhY89WpUyfLfw8AiGiVLmnpnebrEjtLPW+2vh9EPL8s2HU4HLW+NwyjzrFqO3bs0MSJE/Xoo49q8+bNWrFihfbs2aPx48e7HZ+dnS2n01nztW/fPsv7B4CI9lR38zVRsdJkL2ZqAA/E2HnyNm3aKDo6us4sy6FDh+rMxlTLycnRJZdcogceeECSdOGFF+q0005Tenq6ZsyYoeTk5Frj4+LiFBcXZ88vAACR7s1R0gmTtzfHni49vNeWdgDJ5pmX2NhYpaWlKTc3t9bx3NxcDRw40G3NiRMnFBVVu63o6KqFXoZh2NMoAKCuspPSrhXm6wgusJntl40yMzP1yiuvaMGCBdq5c6cmT56s/Pz8mstA2dnZGjt2bM344cOHa+nSpZo3b552796tdevWaeLEierbt686dOhgd7sAgGpPnmm+JpMHLcJ+tl42kqRRo0bp8OHDmj59ugoKCpSamqrly5erS5cukqSCgoJae77cdtttOnbsmObMmaPf//73atmypa688ko98cQTdrcKAKj2jyyp4oS5mtgEKaGtPf0AP+MwwuxaTHFxsRITE+V0OpWQkBDodgAg9FSUSTNMhpCoWOnRH+3pBxHBzN9vnm0EAKgtx+Rzi+JOJ7jArwgvAID/WPZ7yWXyuUW/32lPL0A9CC8AgCpfvid99oq5mjbnSbFNbWkHqA/hBQBQtYvu3241Xzd+rfW9AI0gvAAApOltzNcMuFeKibW+F6ARhBcAiHQvXCKp0lxN21Rp0OO2tAM0hvACAJHsVIn043ZzNVEx0r3r7OkH8ADhBQAi2cyO5mseLrC+D8AEwgsARKoX083X9P8d61wQcIQXAIhEp0qkwm3matpeIA3OsacfwATCCwBEItOXixzSvZ/Y0gpgFuEFACLN3x8wX/Pg99b3AXiJ8AIAkaSiTNr0srma05KkZon29AN4gfACAJHk2Z7ma3h2EYIM4QUAIsW2d6RjB8zVjHhJioq2px/AS4QXAIgElS5p6Z3mauISpV4329MP4APCCwBEgmd7m695aI/1fQAWILwAQLg7VSI595qr+fWrXC5C0CK8AEC4m9PP3PhmbaXUG+3pBbAA4QUAwllFmVTyg7maiVtsaQWwCuEFAMLZjHbmxjdLkuKb29MLYBHCCwCEq9dvkmSYq8ncbksrgJUILwAQjspOSrs/NFeTdjtPjEZIILwAQDh6pofJAoc0fLYdnQCWI7wAQLg5VSKdPGKuJsvkol4ggAgvABBuZp1nbnzbVBbpIqQQXgAgnHzxjlR2zFzNvevs6QWwCeEFAMJFpUtaYvL5RY/8aE8vgI0ILwAQLp7qbm58y67cXYSQRHgBgHBwwimdOGiuZjyXixCaCC8AEA5euNjc+CbNWaSLkEV4AYBQV1EmHTc56/L7r+3pBfADwgsAhLo/dTA3Pu50Zl0Q0ggvABDKFv5GMsrN1fx+pz29AH5CeAGAUFV2UvpmpbmacwdLsU3t6QfwE8ILAISqRTebG9+kuTR6sT29AH5EeAGAUFTpkvZ8bK7mgW9taQXwN8ILAISiZ3ubG9+sDZeLEDYILwAQak6VSM695mombrWlFSAQCC8AEGqeSDE3Propt0YjrBBeACCUnHBKRpm5GjakQ5ghvABAKHnyTHPjYxOlZon29AIECOEFAELFCaekCnM1D3KHEcIP4QUAQsWfzzI3vkNfKSbWnl6AACK8AEAoOOE0/xiAO5bZ0wsQYH4JL3PnzlVKSori4+OVlpamtWvXNji+tLRUU6ZMUZcuXRQXF6ezzjpLCxYs8EerABCcnuxsbnyfO5l1QdiKsfsFFi9erEmTJmnu3Lm65JJL9NJLL2nIkCHasWOHOnd2/y/jyJEjdfDgQc2fP19nn322Dh06pIoKk9d5ASBc/P1+8zXXzrK+DyBIOAzDMOx8gX79+ql3796aN29ezbHu3btrxIgRysnJqTN+xYoVuvnmm7V79261atXK9OsVFxcrMTFRTqdTCQkJPvUOAAFXUSbNaGuu5v49UnPz//sJBJKZv9+2XjYqKyvT5s2blZGRUet4RkaG1q9f77bm/fffV58+ffTkk0+qY8eOOvfcc3X//ffr5MmTbseXlpaquLi41hcAhI1PXzJZEE1wQdiz9bJRUVGRXC6XkpKSah1PSkpSYWGh25rdu3frk08+UXx8vN59910VFRXpd7/7nY4cOeJ23UtOTo6mTZtmS/8AEHArHzE3Pivfnj6AIOKXBbsOh6PW94Zh1DlWrbKyUg6HQwsXLlTfvn01dOhQzZo1S6+99prb2Zfs7Gw5nc6ar3379tnyOwCA330wydz4Zu15DAAigq0zL23atFF0dHSdWZZDhw7VmY2plpycrI4dOyox8T87Qnbv3l2GYeiHH37QOeecU2t8XFyc4uLirG8eAAKpokza/Kq5mswv7OkFCDK2zrzExsYqLS1Nubm5tY7n5uZq4MCBbmsuueQSHThwQCUlJTXHdu3apaioKJ1xxhl2tgsAweOv15sb3+Q0bo1GxLD9slFmZqZeeeUVLViwQDt37tTkyZOVn5+v8ePHS6q67DN27Nia8aNHj1br1q11++23a8eOHVqzZo0eeOAB3XHHHWratKnd7QJA4FWUSfvc39RQr/u22tMLEIRs3+dl1KhROnz4sKZPn66CggKlpqZq+fLl6tKliySpoKBA+fn/WWDWvHlz5ebm6r777lOfPn3UunVrjRw5UjNmzLC7VQAIDkt+a258dFMpweTt1EAIs32fF39jnxcAIa3SJU03eavzo0ekqGh7+gH8JGj2eQEAmLRwtLnx6Q8QXBBxCC8AECwqyqTvVpiruSLbnl6AIEZ4AYBgsWCYufGd05l1QUQivABAMKgokw58aq7mlr/Z0wsQ5AgvABAMZqWaG3/6WVIs20cgMhFeACDQTpVIJw6aq7l3oz29ACGA8AIAgTazo7nxzTuymy4iGuEFAAKp+EfzNRNMro0BwgzhBQACada55sYnduHJ0Yh4hBcACJSyk5IqzdX8T54trQChhPACAIHy0q/MjR84iX1dABFeACAwKsqkw1+bq7n6UXt6AUIM4QUAAmHW+ebG97uXWRfgJ4QXAPC3UyXSiUPmagb90Z5egBBEeAEAf5vZxdz4655n1gX4GcILAPhTyRFJFeZqeo+1pRUgVBFeAMCfnkoxN/7XC+3pAwhhhBcA8JejheZregyxvg8gxBFeAMBfZnczN37g/7DWBXCD8AIA/uDNrMvVj1nfBxAGCC8A4A9mZ11SRzLrAtSD8AIAdjvhNF8z4gXr+wDCBOEFAOz2ZGdz4y8eJ8XE2tMLEAYILwBgp8JvzdcMe8r6PoAwQngBADu9mGZu/MhF9vQBhBHCCwDYpeSI+ZrzBlnfBxBmCC8AYJenzjY3/qKx3GEEeIDwAgB2OOGU5DJXM3y2HZ0AYYfwAgB2eLKrufHXvcCsC+AhwgsAWG3LW5IqzdX0vsWWVoBwRHgBACtVuqT37jZXc/8ee3oBwhThBQCslDvVfE3zVpa3AYQzwgsAWKXSJW14zlwNsy6AaYQXALDKNx+aGx8Vx6wL4AXCCwBYZdFIc+OzvrenDyDMEV4AwAqfvWayoIkU29SOToCwR3gBAF9VuqRl/2OuJnOnPb0AEYDwAgC+Wp5tviahrfV9ABGC8AIAvqh0SZteMleT+a09vQARgvACAL6Y3ctkQRSzLoCPCC8A4K1TJVJxvrmarH329AJEEMILAHjr1cEmC2Kk+Oa2tAJEEsILAHij0iUd/MJczYO77ekFiDCEFwDwxqye5sY74qVmifb0AkQYwgsAmHWqRCoxuXYle68trQCRyC/hZe7cuUpJSVF8fLzS0tK0du1aj+rWrVunmJgY9erVy94GAcCMZy4wNz4qjt10AQvZHl4WL16sSZMmacqUKcrLy1N6erqGDBmi/PyGV+g7nU6NHTtWV111ld0tAoDnyk5KpUfM1Uz60p5egAhle3iZNWuW7rzzTt11113q3r27Zs+erU6dOmnevHkN1t19990aPXq0BgwYYHeLAOC5J1LM17CvC2ApW8NLWVmZNm/erIyMjFrHMzIytH79+nrrXn31VX333Xd67LHHGn2N0tJSFRcX1/oCAFuccEquk+ZqHjS5DwyARtkaXoqKiuRyuZSUlFTreFJSkgoLC93WfPPNN8rKytLChQsVExPT6Gvk5OQoMTGx5qtTp06W9A4AdTzdzdx47jACbOGXBbsOh6PW94Zh1DkmSS6XS6NHj9a0adN07rnnenTu7OxsOZ3Omq99+9i9EoANTpWYn3XhDiPAFo1PbfigTZs2io6OrjPLcujQoTqzMZJ07Ngxbdq0SXl5eZowYYIkqbKyUoZhKCYmRitXrtSVV15ZqyYuLk5xcXH2/RIAIEkzO5ob37wjdxgBNrF15iU2NlZpaWnKzc2tdTw3N1cDBw6sMz4hIUFffPGFtmzZUvM1fvx4devWTVu2bFG/fv3sbBcA3Duy33zNxM3W9wFAks0zL5KUmZmpMWPGqE+fPhowYIBefvll5efna/z48ZKqLvvs379fr7/+uqKiopSamlqrvl27doqPj69zHAD85rke5saffjazLoCNbA8vo0aN0uHDhzV9+nQVFBQoNTVVy5cvV5cuXSRJBQUFje75AgAB482sy70brO8DQA2HYRhGoJuwUnFxsRITE+V0OpWQkBDodgCEuqkm7xbqeLE07kN7egHCmJm/3zzbCADq89kr5mtuX259HwBqIbwAgDuVLmnZ783VnD1Yiom1px8ANQgvAODOMz3N14x+0/o+ANRBeAGAXzpVIh0zueHldS9IUdH29AOgFsILAPzSzDPM1/S+xfo+ALhFeAGAnztaKMnkTZgTd9jSCgD3CC8A8HOzTT58UZJamXx0AACfEF4AoNpR90+7b1Dmt9b3AaBBhBcAqObNrEtCW+v7ANAgwgsASNK7d5uveZBHmwCBQHgBgIoyaetb5mriWkvNTD46AIAlCC8AMLOL+ZqHvrG+DwAeIbwAiGwlR6SKE+Zq0n7LhnRAABFeAES2p1LM1wybaX0fADxGeAEQuYq8WHB7/TxmXYAAI7wAiFxzLjBZECNdNNqWVgB4jvACIDJ5c2v0wz9Y3wcA0wgvACKPN7dGN0uSYpva0w8AUwgvACLPjGTzNZO2Wt8HAK8QXgBElpIjkirM1XS9nFkXIIgQXgBEFm9ujb7t/6zvA4DXCC8AIsf7k8zX8NRoIOgQXgBEhooy6fNXzdfx1Ggg6BBeAESGGV6EEJ4aDQQlwguA8Hdkv/mapm15ajQQpAgvAMLfcz3M1zzwtfV9ALAE4QVAeJvaynzNtc/y/CIgiBFeAISvI/sluczX9bnN6k4AWCgm0A0Annpr7XfKWvaVx+Mdklbff4U6t2lmX1MIbt5cLnrkR+v7AGApwguCSuai1Vq6tcSScxmSLntqldufvXVHf/U/t7Ulr4MgNbWl+ZoLR0sxsZa3AsBahBcEzN//tU8T3t0WkNe+ecHGWt//c+Jl6tahRUB6gQ2K8lUVX026cZ7lrQCwHuEFfnXPghX6xy4v1iDYbNBza2r+//fGX6JeXVsGrhn4bs4F5msmcXcRECoIL7Ddva+t1LKvygPdhsdGvLhOkjTnhgt1bb9OAe4Gps08x4uiKKlle8tbAWAPwgtsseCjrzR95XeBbsMnE97dVnNZi8tKIeKEUzp1yHzdo0XW9wLANoQXWGr6e59qwcbwu1uj+rLSZw9frbYJcQHuBvV6srP5muvnsacLEGIIL7BE1t/W6a3NRwPdhu0ufvxDSdIabsEOPs/396IoSrpotOWtALAX4QU+eWP1N3rkH7sC3YbfVd+CvfXRDCU2axLgbqBTJdLhnebrHjlofS8AbEd4gVdWfLZf45dsCXQbAddz+kqdJunLmcMC3Upkm9nRfE2fO9nTBQhRPB4ApnxbWKKuWcsILj9zXFLXrGXasvdooFuJTFO9fPLztbOs7QOA3zDzAo+4Kg2d9fDyQLdRIyVB+iBzkJrH1/4Iv/3Jbj34dy8uH1ig+hbr7x4fqugoR0B6iDivj/Cu7uFCS9sA4F8OwzC82IYyeBUXFysxMVFOp1MJCQmBbicsvPDx1/rzim8D8tpWLYzd8UOxhs5Za0FHnskafKbGX97db68XkcpOSo97sTdL50ukO4IniAOoYubvN+EFDeqatcxvr3V5J+m1e/2zduTjbQd125ubbH+dvayFsY+3l4umOq3tA4AlCC+EF5/9WFxac1uwndY9eKU6tmpq++s0xO5ZGW6rtsEfkyXXCfN1jx5hTxcgSJn5+82aF9TR45FlOlFhz7mjJX32yDVq1Tx47vLocUZCzQzJO+v26P4Pdlh6/urbqpmFscgbv/EuuIx4ieAChAlmXlCLXZeJ5t7YU0P7nmHLue3w4ecFuuvtzy0/LwHGR96uc4k7Xcrea3k7AKzDZSPCi1fsCC7BcFnIF3bsZ7N8Qrp6nMFn0yuscwHClpm/337Z52Xu3LlKSUlRfHy80tLStHZt/esLli5dqmuuuUZt27ZVQkKCBgwYoH/+85/+aDOiWRlcLm1fdbvw3pnDQjq4SNLgiztq78xhWvLbgZadc+ictX5dCB02vA0uE629DAgg8GwPL4sXL9akSZM0ZcoU5eXlKT09XUOGDFF+fr7b8WvWrNE111yj5cuXa/Pmzbriiis0fPhw5eXl2d1qRCqrqLT0D+nemcP0xqRhYbfPSdqZp2vvzGG68WIv/4C6QYAxwdv9XBQltfJi910AQc32y0b9+vVT7969NW/evJpj3bt314gRI5STk+PROc4//3yNGjVKjz76aKNjuWzkuRkf7NAr6/ZYcq6NWVepfct4S84V7KzesI91MI3wdp2LxOUiIIQEzWWjsrIybd68WRkZGbWOZ2RkaP369R6do7KyUseOHVOrVq3c/ry0tFTFxcW1vtC4a59bY0lwWT4hXXtnDouY4CJJ0VEO7Z05TGvuv8KS8zED0wiCC4BfsDW8FBUVyeVyKSkpqdbxpKQkFRZ6tj33008/rePHj2vkyJFuf56Tk6PExMSar06dOvncd7hLn/n/tP3AMZ/O0SquasYgkheedm7TzLJZk65Zy1RWUWnJucKKt+tcHvnR2j4ABBW/LNh1OGqvfzAMo84xdxYtWqSpU6dq8eLFateundsx2dnZcjqdNV/79u2zpOdwNey5Ndp39JRP59j6aIY+n8aljmp7Zw7TtT2TGh/YiHMf+YemLN1qQUdhwtvg0v93PC0aCHO2hpc2bdooOjq6zizLoUOH6szG/NLixYt155136u2339bVV19d77i4uDglJCTU+oJ7ty/YqC99nHHZO3OYEps1saij8DHnv/po14whPp9n4ac/6OxsLiN5HVzi2kmDPVtLByB02RpeYmNjlZaWptzc3FrHc3NzNXBg/beeLlq0SLfddpvefPNNDRvGf+Fb4a6/fqZVuw77dA4WljYsNibKkveowojwdTBTT/e+Nvsb6/oAELRsv2yUmZmpV155RQsWLNDOnTs1efJk5efna/z48ZKqLvuMHTu2ZvyiRYs0duxYPf300+rfv78KCwtVWFgop5PFd976YOsBfbjzkNf13ZOsW9sRCfbOHKZ1D17p83kiMsBsfl2Sl2t/WKALRAy/7LA7d+5cPfnkkyooKFBqaqqeeeYZXXbZZZKk2267TXv37tXHH38sSbr88su1evXqOue49dZb9dprrzX6WtwqXZuvt/VunzpIzeN5BJa3rAggERMcK13SdPd3FTYqa78U39zafgD4FY8HILzU8OWPZ8T80bSZrwHGIWlPJPyz8HadS9KF0j32PRUcgH8EzT4vCCyCS3Dw9b00FAGXkLwNLoomuAARiPASplIfXeFVXZQILnaw4j0N2wDjdXCRNPWIdX0ACBmElzCUvXSLSspcXtXuJrjYZu/MYfpw0q98Ose5U6x7LEFQ8Cm4sEAXiFSElzBz118/1aJP93tVy4yL/c5u39yn97nMZSj73S3WNRRIBBcAXiK8hJE/LftSH+70blt0got/+fJ+L/rXfi3fdsDCbgLAl+DyKJeKgEhHeAkTZRWV+svavV7VElwCw5f3/Xdv5slVGaI3CvoSXG54SYqKtq4XACGJ8BIm0qZ5t0CX4BJYvrz/vuzfEzC+BJf41lLPm63rBUDIIryEgbTpK3Ws3Px/hRNcgoMv/xxC6g4kX4KLJGXttqYPACGP8BLi0v64UodPlJuu++7xoTZ0A2+FfYDxNbiwQBfAzxBeQtjtC/6lw8fNB5cXb+mt6CiHDR3BF2EZYIp/JLgAsBzhJUS9//kPWrWryHTdnJt7aXBqsg0dwQphFWBmJEuzzvbtHAQXAG4QXkLQiu0Fmvj2VtN1d1zSVdf26mhDR7BSWASYqYlSxQkfz0FwAeAe4SXEuCoNZS3ZZroutUMLPTr8fBs6gh12Th/sde2WvUeta8Qbvl4mkgguABpEeAkxcz76VkdPVpiqad00Wn+feJlNHcEOTWOjdelZ3oWAES+us7gbD5WdJLgA8AvCSwip2ojuO9N1n/5hkA3dwG5vjLvU61q/Xz76yxDp8fa+n4fgAsADhJcQsWJ7gfrnfKiSUnMPXOTOotAWEutfpiZK+9dbcB6CCwDPEF5CwIrtBbrnjc91xORt0XNHX8SdRWHAlwDTLdvGAGPVZSJFE1wAmEJ4CXKuSkPTPtghs/vnzh3dW0Mv7GBLT/A/bwNMqSE99n/bLe5G0kvXWHOZKOlCaSoPWgRgDuEliLkqDb22bo8KnKc8rnE4qmZchl7IjEu48TbA/HXD9yqrqLSmiZIjVbMtBZ/6fq6s/dI9a30/D4CIQ3gJUiu2F+jSJz7SH5ftNFX3wn8x4xLOds0Y4lXduY/8w/cXn9peeirF9/NIVZeJ4ptbcy4AEYfwEoSWbyvQ+Dc+NzXj0vq0WL14S29mXMJcbEyUbul3hle1Xi/gPbTnp7UtJ72r/yXWtwDwEeElyPx9y37d++bnpmpandZEG7KvYnFuhJhxQ0/FRntXe8nMD80VTE2U5vby7sXcno/gAsB3hJcgkrN8hya8tcXjxbmOn74ev+ECxcbwjzKS7PqTd+tf9h8tldOTp5BvfMOiO4l+0rEfwQWAZfiLFwRclYae+udXemnNHlN17RPjNe+W3sy4RChvF/D2nL6y/h/uWF0VWlbc62VXbjxcKI1r4DUBwCSHYRhm78INasXFxUpMTJTT6VRCQkKg22nUiu0Fynx7i06Umbsb5A/Duuu2S1LYgC7CnSxzqfujK0zXtY6TNk/7WfjJ/0Ja4P2OvvVitgWAh8z8/Y7xU09wY8X2qoW5ZiUnxhNcIKnqGUgDuyZo/d5iU3WHSyXniXIlVhyVZp1tT3MEFwA24bJRgLgqDa83D3tseA+CC2q8OT7ddE0P7VDznDb2BJffbSG4ALAV4SVAPt1zRAePlZmqcahq51zWuOCXPF3/MlBr9F2T0VoWN0PRXt6x1KCpTqmdRXvBAEA9uGwUIIeOeb6HS7Xnb+7FPi6o196Zw9zu5RKjCk2Pfk6jojcpylG1C7PlJn0ttbTgcQEA4AHCS4C0axFvavzdl6Xo2l4dbeoG4WLdg1fqkic/kiT113otbDJHUVE2BZZqXCIC4GeElwDpm9JKSS1iPbp09OyoXrr+IoILGtcxpkTrmtyuZEepHHbNslRjtgVAgBBeLOSqNPTpniM6dOyU2rWIV9+UVvUurI2Ocmja9amN3m00Lj2F4IKGlZ2UXr1BKtggSepox1qWn7vpHemCa2x+EQCoH+HFIiu2F2jaBztqPY8oOTFejw3vUe8C28GpyXrxlt7KfHurTpS5av3M4ZB+m56i7KE9bO0bIepUiTTvGsm5w7+vyyUiAEGATeo81NCsyortBbrnjc/rbOtfPefS2C64rkpD678p0pK8H3SizKWLu7bSrQO7suU/atu9WXr9ysC89m8/lTp0C8xrA4gIbFJnsYZmVa7p0V7TPtjh9nlEhqoCzLQPduiaHu0bvISU3q2t0ru1taV/hKgj+6Xnekry4FlEdiG0AAhChJdG1DerUug8pXve+FyTrj6nVqj5JUNSgfOUPt1zRAPOam1rrwhxxT9Ks7orkGHFMKTKSunImPVqe+75AesDABpCeGmAq9JodFbl1XV7PTqXN/u6IMx99ra0bFygu5D0n9ByVfnj2quu0oK92juT8AIgOBFeGvDpniONzqocPenZfyWb3dcFYWbTO9Lf7wx0F3VUh5b08qd0QB1q/az/jH9q4yODAtQZANSP8NIAT2dLWjZtIufJcrczNA5J7ROrFvgiAnz1ifSWZ1v1B4phVH39YEjXlr+oYrlfGFdYUlH18MZmTfzcIQA0jPDSAE9nS26/JEWzP9wlh1QrwFQvz+VBimGk0iV9kC3lvRToTkwzVNX+qPJMbVIfj2p6Tl/p8XOTAMBfCC8N6JvSSsmJ8Sp0nmpwVmXClWerW/vmde5Iat/IPi8IQnnvS/83JtBd2KCFHPdvU/c/bZC5x4FKD/wtT3/+zUW2dAUA3mCfl0ZU320kuZ9V+fkeLmZ22IWf7N0ivfarQHcRONf/r3TRdTXfnixzqfujK0yfZteMIew7BMBWZv5+E1484M3uufDRCaf00tWSc1egOwk9g56XBoyt98d3LPiXPtpVZPq0XD4CYCfCi5932A0bRfnSnJ6SKgPdCcy67q9S7xEeDz8ne5nKTf6b/8SNqRrVt4u5IgDwEOHFhvBiSqVL+n69VHJQatam6kFFJQel4z9KTU+X9m/+6R5VQzp5VCraKRmVUkWpdOKoVF4iGRWB6R2h47bVUtdeXpW6Kg2d9fBy03XfPT40/EI7gKAQdI8HmDt3rv785z+roKBA559/vmbPnq309PR6x69evVqZmZn68ssv1aFDBz344IMaP368P1r13Y73pRUPScUHAt0Jws0Ni6SeQy05VXSUQ3++6QI9sOQLU3UjXvhEH9xX/7+7AOAPtq/AW7x4sSZNmqQpU6YoLy9P6enpGjJkiPLz892O37Nnj4YOHar09HTl5eXp4Ycf1sSJE7VkyRK7W/Xdjvelt8cSXGCN4a9WPcW5+sui4FLtNxd3Vmy0uZov9hfr5C+egA4A/mb7ZaN+/fqpd+/emjdvXs2x7t27a8SIEcrJyakz/qGHHtL777+vnTt31hwbP368tm7dqg0bNjT6egG7bFTpkmanElzgJYc08UupVUe/vqo3l49iHNK3OSzeBWCtoLlsVFZWps2bNysrK6vW8YyMDK1fv95tzYYNG5SRkVHr2KBBgzR//nyVl5erSZPau32WlpaqtLS05vvi4mKLujfp+/UEF3im/++kjBlSlMlpDxtERzn0pxE9NOW9HR7XVBjSj8WlapsQZ2NnAFA/W8NLUVGRXC6XkpKSah1PSkpSYWGh25rCwkK34ysqKlRUVKTk5Nq3Jufk5GjatGnWNu6NkoOB7gDB5uoZ0sDfBUVIach/908xFV4k6eLHP+TWaQAB45cFuw5H7bsTDMOoc6yx8e6OS1J2drYyMzNrvi8uLlanTp18adc7zZMaH4PwM3qFdO6AQHfhs53TB5vevK7XY8u1ZZq163AAwBO2hpc2bdooOjq6zizLoUOH6syuVGvfvr3b8TExMWrdunWd8XFxcYqLC4Lp6y4DpYQOUnGB5PZhAgg5Xa+QRi+SYpsGuhPbNY2NVtfW8dp72LOHkUrS0VJDR0rK1Kp5rI2dAUBdtoaX2NhYpaWlKTc3VzfccEPN8dzcXF1//fVuawYMGKAPPvig1rGVK1eqT58+dda7BJWoaGnwE1V3G9V5RCOCQuLZ0t0fSc0SA91JUFo5+Qqd+8g/TNX0npHL5SMAfmf7ZaPMzEyNGTNGffr00YABA/Tyyy8rPz+/Zt+W7Oxs7d+/X6+//rqkqjuL5syZo8zMTI0bN04bNmzQ/PnztWjRIrtb9V2P66SRr7PPix3Gb5banx3oLsJabEyU7rikqxas22uqjtkXAP5me3gZNWqUDh8+rOnTp6ugoECpqalavny5unSp2ma8oKCg1p4vKSkpWr58uSZPnqwXXnhBHTp00HPPPaebbrrJ7lat0eM66bxhIb7DbpQ0/jPCQgR6dPj5em3dXlMPiOgzI1e7mX0B4Ec8HgBALc4T5eo5faWpmlk3XaAbL+5sU0cAIoGZv9884x5ALYnNmqi5yeVlmUu+kKsyrP47CEAQI7wAqOPzx4aYruk11dyt1gDgLcILgDpiY6J0+8CupmqOlVXqSEmZPQ0BwM8QXgC49dh15yu6/r0k3eo9I9eeZgDgZwgvAOq19bFBpmuWfrbPhk4A4D8ILwDq1Tw+Rkkm93DJXLKNxbsAbEV4AdCgtVlXma6Z8OZmGzoBgCqEFwANio2J0tgB5vZw+cf2gyqrMLPVHQB4jvACoFHTr79AMSYX7/aZYW6jOwDwFOEFgEe+mDbY1PjiUy45T5Tb1A2ASEZ4AeCRprHROqftaaZqrnr6I5u6ARDJCC8APLbsfy4zNb7oeAVrXwBYjvACwGOxMVEacn6SqZpLn2DjOgDWIrwAMGXOf6eZGn/oWIVKTlXY1A2ASER4AWBKdJRDs266wFTNkNmrbeoGQCQivAAw7caLO5u6dXrf0VOsfQFgGcILAK/Mv+1iU+MfWrLVpk4ARBrCCwCvXHpOW0WZmH15N+8AzzwCYAnCCwCvREc59MyoXqZqnv7nTnuaARBRCC8AvHZ9r45q38Lzp07PXb2H2RcAPiO8APDJmofMPXX61/PW2dQJgEhBeAHgk9iYKHVp1dTj8Xn7nPrTsi9t7AhAuCO8APDZsonmHhvwl7V7uXUagNcILwB81jw+RskJcaZqXlnznU3dAAh3hBcAllj94JWmxr+ybo9NnQAId4QXAJaIjYnSsAvaezz+yPFy7jwC4BXCCwDLPPdfvWVi3zr9hjuPAHiB8ALAMtFRDs36TU+Px3++z6kPth6wsSMA4YjwAsBSN6SdoaZNPP+flgff2cblIwCmEF4AWC7zmm4ejz1Z7tLG3Ydt7AZAuCG8ALDcrQO7mhr/xsbv7WkEQFgivACwXGxMlO66JMXj8f/YXqgV2wts7AhAOCG8ALDFI8N76Mw2zTwe//u3t7L2BYBHCC8AbJObebmaRHt28/TxMpee/3/f2NwRgHBAeAFgm+goh57/r4s8Hv/Cx98y+wKgUYQXALYanJqsvl1P92hsucvQ+m+LbO4IQKgjvACw3cVdW3k89vmPuHQEoGGEFwC2G3h2G4/Hbv3ByaUjAA0ivACwXf8zWysuxrOFu6UVlfp0zxGbOwIQyggvAGwXHeXQ07/u5fH4Q8dO2dcMgJBHeAHgF9f26qC0Li09Gru36Li9zQAIaYQXAH7z9t0DdVpsdKPjnvnwG3bcBVAvwgsAv4mOcujpkT3lyeqXrKVfsHAXgFuEFwB+NTg1WZOuPrfRcUdPlGvOR9/6oSMAoYbwAsDvunr4zKNX1+1h9gVAHbaGl3//+98aM2aMEhMTlZiYqDFjxujo0aP1ji8vL9dDDz2kCy64QKeddpo6dOigsWPH6sCBA3a2CcDP2rWI92jc0ZPlmsOmdQB+wdbwMnr0aG3ZskUrVqzQihUrtGXLFo0ZM6be8SdOnNDnn3+uP/zhD/r888+1dOlS7dq1S9ddd52dbQLws74prdSyaROPxrJ4F8AvOQzDsGVOdufOnerRo4c2btyofv36SZI2btyoAQMG6KuvvlK3bt08Os9nn32mvn376vvvv1fnzp0bHV9cXKzExEQ5nU4lJCT49DsAsM+zH+7SMx96NquSnBivTx66UtFRnm10ByD0mPn7bdvMy4YNG5SYmFgTXCSpf//+SkxM1Pr16z0+j9PplMPhUMuWLd3+vLS0VMXFxbW+AAS/CVeeo5bNPJt9KXCeYtddADVsCy+FhYVq165dnePt2rVTYWGhR+c4deqUsrKyNHr06HpTWE5OTs2amsTERHXq1MmnvgH4R3SUQzNvvMDj8ey6C6Ca6fAydepUORyOBr82bdokSXI46k7xGobh9vgvlZeX6+abb1ZlZaXmzp1b77js7Gw5nc6ar3379pn9lQAEyODUZE324LZpyfNFvgDCX4zZggkTJujmm29ucEzXrl21bds2HTx4sM7PfvzxRyUlJTVYX15erpEjR2rPnj366KOPGrz2FRcXp7i4OM+aBxB0Jlx5thZ9+r0Ki0vd/twhqX1ivPqmtPJvYwCClunw0qZNG7Vp0/jj7QcMGCCn06lPP/1Uffv2lST961//ktPp1MCBA+utqw4u33zzjVatWqXWrVubbRFACImOcmjqdefrnjc+lyT9/A6C6jnax4b3YLEugBq2rXnp3r27Bg8erHHjxmnjxo3auHGjxo0bp2uvvbbWnUbnnXee3n33XUlSRUWFfv3rX2vTpk1auHChXC6XCgsLVVhYqLKyMrtaBRBgg1OTNe+W3mqfWPvSUPvEeM27pbcGpyYHqDMAwcj0zIsZCxcu1MSJE5WRkSFJuu666zRnzpxaY77++ms5nU5J0g8//KD3339fktSrV69a41atWqXLL7/cznYBBNDg1GRd06O9Pt1zRIeOnVK7FlWXiphxAfBLtu3zEijs8wIAQOgJin1eAAAA7EB4AQAAIYXwAgAAQgrhBQAAhBTCCwAACCmEFwAAEFIILwAAIKQQXgAAQEghvAAAgJBi6+MBAqF6w+Di4uIAdwIAADxV/Xfbk43/wy68HDt2TJLUqVOnAHcCAADMOnbsmBITExscE3bPNqqsrNSBAwfUokULORyBeaBbcXGxOnXqpH379vF8JZvwHtuL99d+vMf24z22n5XvsWEYOnbsmDp06KCoqIZXtYTdzEtUVJTOOOOMQLchSUpISOBfGJvxHtuL99d+vMf24z22n1XvcWMzLtVYsAsAAEIK4QUAAIQUwosN4uLi9NhjjykuLi7QrYQt3mN78f7aj/fYfrzH9gvUexx2C3YBAEB4Y+YFAACEFMILAAAIKYQXAAAQUggvAAAgpBBevDR37lylpKQoPj5eaWlpWrt2bYPjV69erbS0NMXHx+vMM8/Uiy++6KdOQ5OZ9/fjjz+Ww+Go8/XVV1/5sePQsmbNGg0fPlwdOnSQw+HQe++912gNn2FzzL7HfI7NycnJ0cUXX6wWLVqoXbt2GjFihL7++utG6/gce86b99hfn2PCixcWL16sSZMmacqUKcrLy1N6erqGDBmi/Px8t+P37NmjoUOHKj09XXl5eXr44Yc1ceJELVmyxM+dhwaz72+1r7/+WgUFBTVf55xzjp86Dj3Hjx9Xz549NWfOHI/G8xk2z+x7XI3PsWdWr16te++9Vxs3blRubq4qKiqUkZGh48eP11vD59gcb97jarZ/jg2Y1rdvX2P8+PG1jp133nlGVlaW2/EPPvigcd5559U6dvfddxv9+/e3rcdQZvb9XbVqlSHJ+Pe//+2H7sKPJOPdd99tcAyfYd948h7zOfbNoUOHDEnG6tWr6x3D59g3nrzH/vocM/NiUllZmTZv3qyMjIxaxzMyMrR+/Xq3NRs2bKgzftCgQdq0aZPKy8tt6zUUefP+VrvooouUnJysq666SqtWrbKzzYjDZ9h/+Bx7x+l0SpJatWpV7xg+x77x5D2uZvfnmPBiUlFRkVwul5KSkmodT0pKUmFhoduawsJCt+MrKipUVFRkW6+hyJv3Nzk5WS+//LKWLFmipUuXqlu3brrqqqu0Zs0af7QcEfgM24/PsfcMw1BmZqYuvfRSpaam1juOz7H3PH2P/fU5DrunSvuLw+Go9b1hGHWONTbe3XFUMfP+duvWTd26dav5fsCAAdq3b5+eeuopXXbZZbb2GUn4DNuLz7H3JkyYoG3btumTTz5pdCyfY+94+h7763PMzItJbdq0UXR0dJ1ZgEOHDtVJ9NXat2/vdnxMTIxat25tW6+hyJv3153+/fvrm2++sbq9iMVnODD4HDfuvvvu0/vvv69Vq1bpjDPOaHAsn2PvmHmP3bHjc0x4MSk2NlZpaWnKzc2tdTw3N1cDBw50WzNgwIA641euXKk+ffqoSZMmtvUairx5f93Jy8tTcnKy1e1FLD7DgcHnuH6GYWjChAlaunSpPvroI6WkpDRaw+fYHG/eY3ds+Rzbuhw4TL311ltGkyZNjPnz5xs7duwwJk2aZJx22mnG3r17DcMwjKysLGPMmDE143fv3m00a9bMmDx5srFjxw5j/vz5RpMmTYx33nknUL9CUDP7/j7zzDPGu+++a+zatcvYvn27kZWVZUgylixZEqhfIegdO3bMyMvLM/Ly8gxJxqxZs4y8vDzj+++/NwyDz7AVzL7HfI7Nueeee4zExETj448/NgoKCmq+Tpw4UTOGz7FvvHmP/fU5Jrx46YUXXjC6dOlixMbGGr17965169itt95q/OpXv6o1/uOPPzYuuugiIzY21ujatasxb948P3ccWsy8v0888YRx1llnGfHx8cbpp59uXHrppcayZcsC0HXoqL6d8Zdft956q2EYfIatYPY95nNsjrv3VpLx6quv1ozhc+wbb95jf32OHT81CAAAEBJY8wIAAEIK4QUAAIQUwgsAAAgphBcAABBSCC8AACCkEF4AAEBIIbwAAICQQngBAAAhhfACAABCCuEFAACEFMILAAAIKYQXAAAQUv4/vxlP75nfc0EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1_layer.weight: requires_grad=True\n",
      "hidden1_layer.bias: requires_grad=True\n",
      "hidden2_layer.weight: requires_grad=True\n",
      "hidden2_layer.bias: requires_grad=True\n",
      "latent_space_layer.weight: requires_grad=True\n",
      "latent_space_layer.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "pgnniv_pretrained_encoder = pretrained_pgnniv.encoder\n",
    "\n",
    "# for param in pgnniv_pretrained_encoder.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "for name, param in pgnniv_pretrained_encoder.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 2.621e+12, Test loss: 2.895e+12, MSE(e): 1.183e+02, MSE(pi1): 1.418e+05, MSE(pi2): 4.850e+01, MSE(pi3): 1.945e+02\n",
      "Epoch 100, Train loss: 4.937e+11, Test loss: 7.277e+11, MSE(e): 4.585e+01, MSE(pi1): 3.152e+03, MSE(pi2): 1.450e+01, MSE(pi3): 3.615e+01\n",
      "Epoch 200, Train loss: 1.534e+11, Test loss: 2.284e+11, MSE(e): 1.466e+01, MSE(pi1): 5.206e+02, MSE(pi2): 5.850e+00, MSE(pi3): 1.516e+01\n",
      "Epoch 300, Train loss: 1.152e+11, Test loss: 1.433e+11, MSE(e): 1.141e+01, MSE(pi1): 3.533e+01, MSE(pi2): 5.069e+00, MSE(pi3): 6.965e+00\n",
      "Epoch 400, Train loss: 1.136e+11, Test loss: 1.358e+11, MSE(e): 1.129e+01, MSE(pi1): 1.489e+01, MSE(pi2): 5.021e+00, MSE(pi3): 5.848e+00\n",
      "Epoch 500, Train loss: 1.123e+11, Test loss: 1.334e+11, MSE(e): 1.115e+01, MSE(pi1): 2.307e+01, MSE(pi2): 4.971e+00, MSE(pi3): 5.666e+00\n",
      "Epoch 600, Train loss: 9.331e+10, Test loss: 1.046e+11, MSE(e): 8.862e+00, MSE(pi1): 4.083e+02, MSE(pi2): 4.088e+00, MSE(pi3): 6.042e+00\n",
      "Epoch 700, Train loss: 5.586e+10, Test loss: 5.588e+10, MSE(e): 5.168e+00, MSE(pi1): 3.566e+02, MSE(pi2): 2.581e+00, MSE(pi3): 6.127e+00\n",
      "Epoch 800, Train loss: 3.936e+10, Test loss: 3.631e+10, MSE(e): 3.664e+00, MSE(pi1): 2.132e+02, MSE(pi2): 1.955e+00, MSE(pi3): 5.915e+00\n",
      "Epoch 900, Train loss: 3.202e+10, Test loss: 3.057e+10, MSE(e): 3.011e+00, MSE(pi1): 1.340e+02, MSE(pi2): 1.682e+00, MSE(pi3): 5.666e+00\n",
      "Epoch 1000, Train loss: 2.710e+10, Test loss: 2.679e+10, MSE(e): 2.560e+00, MSE(pi1): 9.498e+01, MSE(pi2): 1.499e+00, MSE(pi3): 5.483e+00\n",
      "Epoch 1100, Train loss: 2.432e+10, Test loss: 2.517e+10, MSE(e): 2.307e+00, MSE(pi1): 7.131e+01, MSE(pi2): 1.392e+00, MSE(pi3): 5.298e+00\n",
      "Epoch 1200, Train loss: 2.232e+10, Test loss: 2.499e+10, MSE(e): 2.124e+00, MSE(pi1): 5.706e+01, MSE(pi2): 1.314e+00, MSE(pi3): 5.132e+00\n",
      "Epoch 1300, Train loss: 2.089e+10, Test loss: 2.430e+10, MSE(e): 1.991e+00, MSE(pi1): 4.818e+01, MSE(pi2): 1.257e+00, MSE(pi3): 4.982e+00\n",
      "Epoch 1400, Train loss: 1.984e+10, Test loss: 2.328e+10, MSE(e): 1.893e+00, MSE(pi1): 4.201e+01, MSE(pi2): 1.215e+00, MSE(pi3): 4.843e+00\n",
      "Epoch 1500, Train loss: 1.904e+10, Test loss: 2.244e+10, MSE(e): 1.819e+00, MSE(pi1): 3.745e+01, MSE(pi2): 1.182e+00, MSE(pi3): 4.714e+00\n",
      "Epoch 1600, Train loss: 1.840e+10, Test loss: 2.195e+10, MSE(e): 1.761e+00, MSE(pi1): 3.392e+01, MSE(pi2): 1.156e+00, MSE(pi3): 4.592e+00\n",
      "Epoch 1700, Train loss: 1.791e+10, Test loss: 2.157e+10, MSE(e): 1.715e+00, MSE(pi1): 3.111e+01, MSE(pi2): 1.136e+00, MSE(pi3): 4.477e+00\n",
      "Epoch 1800, Train loss: 1.751e+10, Test loss: 2.131e+10, MSE(e): 1.679e+00, MSE(pi1): 2.885e+01, MSE(pi2): 1.119e+00, MSE(pi3): 4.368e+00\n",
      "Epoch 1900, Train loss: 1.719e+10, Test loss: 2.121e+10, MSE(e): 1.649e+00, MSE(pi1): 2.700e+01, MSE(pi2): 1.106e+00, MSE(pi3): 4.261e+00\n",
      "Epoch 2000, Train loss: 1.692e+10, Test loss: 2.123e+10, MSE(e): 1.625e+00, MSE(pi1): 2.553e+01, MSE(pi2): 1.094e+00, MSE(pi3): 4.158e+00\n",
      "Epoch 2100, Train loss: 1.669e+10, Test loss: 2.135e+10, MSE(e): 1.604e+00, MSE(pi1): 2.441e+01, MSE(pi2): 1.084e+00, MSE(pi3): 4.059e+00\n",
      "Epoch 2200, Train loss: 1.648e+10, Test loss: 2.144e+10, MSE(e): 1.585e+00, MSE(pi1): 2.366e+01, MSE(pi2): 1.074e+00, MSE(pi3): 3.960e+00\n",
      "Epoch 2300, Train loss: 1.628e+10, Test loss: 2.149e+10, MSE(e): 1.566e+00, MSE(pi1): 2.335e+01, MSE(pi2): 1.063e+00, MSE(pi3): 3.862e+00\n",
      "Epoch 2400, Train loss: 1.606e+10, Test loss: 2.149e+10, MSE(e): 1.545e+00, MSE(pi1): 2.355e+01, MSE(pi2): 1.050e+00, MSE(pi3): 3.764e+00\n",
      "Epoch 2500, Train loss: 1.580e+10, Test loss: 2.139e+10, MSE(e): 1.519e+00, MSE(pi1): 2.446e+01, MSE(pi2): 1.032e+00, MSE(pi3): 3.662e+00\n",
      "Epoch 2600, Train loss: 1.544e+10, Test loss: 2.090e+10, MSE(e): 1.483e+00, MSE(pi1): 2.623e+01, MSE(pi2): 1.007e+00, MSE(pi3): 3.554e+00\n",
      "Epoch 2700, Train loss: 1.492e+10, Test loss: 1.936e+10, MSE(e): 1.428e+00, MSE(pi1): 2.910e+01, MSE(pi2): 9.683e-01, MSE(pi3): 3.438e+00\n",
      "Epoch 2800, Train loss: 1.413e+10, Test loss: 1.741e+10, MSE(e): 1.347e+00, MSE(pi1): 3.255e+01, MSE(pi2): 9.089e-01, MSE(pi3): 3.308e+00\n",
      "Epoch 2900, Train loss: 1.308e+10, Test loss: 1.579e+10, MSE(e): 1.242e+00, MSE(pi1): 3.401e+01, MSE(pi2): 8.320e-01, MSE(pi3): 3.158e+00\n",
      "Epoch 3000, Train loss: 1.196e+10, Test loss: 1.436e+10, MSE(e): 1.133e+00, MSE(pi1): 3.257e+01, MSE(pi2): 7.535e-01, MSE(pi3): 2.998e+00\n",
      "Epoch 3100, Train loss: 1.091e+10, Test loss: 1.336e+10, MSE(e): 1.033e+00, MSE(pi1): 2.997e+01, MSE(pi2): 6.834e-01, MSE(pi3): 2.835e+00\n",
      "Epoch 3200, Train loss: 1.006e+10, Test loss: 1.297e+10, MSE(e): 9.519e-01, MSE(pi1): 2.732e+01, MSE(pi2): 6.276e-01, MSE(pi3): 2.677e+00\n",
      "Epoch 3300, Train loss: 9.410e+09, Test loss: 1.289e+10, MSE(e): 8.911e-01, MSE(pi1): 2.466e+01, MSE(pi2): 5.865e-01, MSE(pi3): 2.522e+00\n",
      "Epoch 3400, Train loss: 8.893e+09, Test loss: 1.278e+10, MSE(e): 8.431e-01, MSE(pi1): 2.252e+01, MSE(pi2): 5.547e-01, MSE(pi3): 2.375e+00\n",
      "Epoch 3500, Train loss: 8.432e+09, Test loss: 1.271e+10, MSE(e): 7.998e-01, MSE(pi1): 2.094e+01, MSE(pi2): 5.265e-01, MSE(pi3): 2.239e+00\n",
      "Epoch 3600, Train loss: 7.935e+09, Test loss: 1.244e+10, MSE(e): 7.525e-01, MSE(pi1): 1.985e+01, MSE(pi2): 4.953e-01, MSE(pi3): 2.116e+00\n",
      "Epoch 3700, Train loss: 7.293e+09, Test loss: 1.173e+10, MSE(e): 6.902e-01, MSE(pi1): 1.913e+01, MSE(pi2): 4.530e-01, MSE(pi3): 2.001e+00\n",
      "Epoch 3800, Train loss: 6.368e+09, Test loss: 1.020e+10, MSE(e): 5.993e-01, MSE(pi1): 1.864e+01, MSE(pi2): 3.917e-01, MSE(pi3): 1.892e+00\n",
      "Epoch 3900, Train loss: 5.232e+09, Test loss: 8.653e+09, MSE(e): 4.872e-01, MSE(pi1): 1.813e+01, MSE(pi2): 3.131e-01, MSE(pi3): 1.786e+00\n",
      "Epoch 4000, Train loss: 4.210e+09, Test loss: 7.342e+09, MSE(e): 3.864e-01, MSE(pi1): 1.769e+01, MSE(pi2): 2.408e-01, MSE(pi3): 1.692e+00\n",
      "Epoch 4100, Train loss: 3.399e+09, Test loss: 6.417e+09, MSE(e): 3.062e-01, MSE(pi1): 1.756e+01, MSE(pi2): 1.840e-01, MSE(pi3): 1.622e+00\n",
      "Epoch 4200, Train loss: 2.847e+09, Test loss: 5.804e+09, MSE(e): 2.515e-01, MSE(pi1): 1.754e+01, MSE(pi2): 1.473e-01, MSE(pi3): 1.571e+00\n",
      "Epoch 4300, Train loss: 2.412e+09, Test loss: 5.285e+09, MSE(e): 2.084e-01, MSE(pi1): 1.751e+01, MSE(pi2): 1.219e-01, MSE(pi3): 1.527e+00\n",
      "Epoch 4400, Train loss: 2.084e+09, Test loss: 4.853e+09, MSE(e): 1.761e-01, MSE(pi1): 1.745e+01, MSE(pi2): 1.027e-01, MSE(pi3): 1.487e+00\n",
      "Epoch 4500, Train loss: 1.809e+09, Test loss: 4.463e+09, MSE(e): 1.491e-01, MSE(pi1): 1.738e+01, MSE(pi2): 8.693e-02, MSE(pi3): 1.446e+00\n",
      "Epoch 4600, Train loss: 1.572e+09, Test loss: 4.137e+09, MSE(e): 1.258e-01, MSE(pi1): 1.728e+01, MSE(pi2): 7.322e-02, MSE(pi3): 1.404e+00\n",
      "Epoch 4700, Train loss: 1.370e+09, Test loss: 3.865e+09, MSE(e): 1.062e-01, MSE(pi1): 1.716e+01, MSE(pi2): 6.152e-02, MSE(pi3): 1.360e+00\n",
      "Epoch 4800, Train loss: 1.197e+09, Test loss: 3.682e+09, MSE(e): 8.955e-02, MSE(pi1): 1.701e+01, MSE(pi2): 5.166e-02, MSE(pi3): 1.315e+00\n",
      "Epoch 4900, Train loss: 1.059e+09, Test loss: 3.593e+09, MSE(e): 7.633e-02, MSE(pi1): 1.684e+01, MSE(pi2): 4.394e-02, MSE(pi3): 1.269e+00\n",
      "Epoch 5000, Train loss: 9.117e+08, Test loss: 3.668e+09, MSE(e): 6.233e-02, MSE(pi1): 1.663e+01, MSE(pi2): 3.570e-02, MSE(pi3): 1.222e+00\n",
      "Epoch 5100, Train loss: 8.270e+08, Test loss: 3.651e+09, MSE(e): 5.454e-02, MSE(pi1): 1.641e+01, MSE(pi2): 3.132e-02, MSE(pi3): 1.175e+00\n",
      "Epoch 5200, Train loss: 7.599e+08, Test loss: 3.683e+09, MSE(e): 4.853e-02, MSE(pi1): 1.617e+01, MSE(pi2): 2.807e-02, MSE(pi3): 1.130e+00\n",
      "Epoch 5300, Train loss: 7.049e+08, Test loss: 3.751e+09, MSE(e): 4.372e-02, MSE(pi1): 1.592e+01, MSE(pi2): 2.548e-02, MSE(pi3): 1.086e+00\n",
      "Epoch 5400, Train loss: 6.606e+08, Test loss: 3.823e+09, MSE(e): 3.995e-02, MSE(pi1): 1.567e+01, MSE(pi2): 2.356e-02, MSE(pi3): 1.045e+00\n",
      "Epoch 5500, Train loss: 6.234e+08, Test loss: 3.892e+09, MSE(e): 3.686e-02, MSE(pi1): 1.542e+01, MSE(pi2): 2.183e-02, MSE(pi3): 1.006e+00\n",
      "Epoch 5600, Train loss: 5.956e+08, Test loss: 3.937e+09, MSE(e): 3.468e-02, MSE(pi1): 1.518e+01, MSE(pi2): 2.112e-02, MSE(pi3): 9.703e-01\n",
      "Epoch 5700, Train loss: 5.639e+08, Test loss: 3.995e+09, MSE(e): 3.206e-02, MSE(pi1): 1.495e+01, MSE(pi2): 1.925e-02, MSE(pi3): 9.383e-01\n",
      "Epoch 5800, Train loss: 5.448e+08, Test loss: 4.053e+09, MSE(e): 3.066e-02, MSE(pi1): 1.473e+01, MSE(pi2): 1.773e-02, MSE(pi3): 9.095e-01\n",
      "Epoch 5900, Train loss: 5.159e+08, Test loss: 4.042e+09, MSE(e): 2.826e-02, MSE(pi1): 1.450e+01, MSE(pi2): 1.720e-02, MSE(pi3): 8.825e-01\n",
      "Epoch 6000, Train loss: 5.062e+08, Test loss: 4.113e+09, MSE(e): 2.772e-02, MSE(pi1): 1.431e+01, MSE(pi2): 1.573e-02, MSE(pi3): 8.592e-01\n",
      "Epoch 6100, Train loss: 4.791e+08, Test loss: 4.025e+09, MSE(e): 2.545e-02, MSE(pi1): 1.410e+01, MSE(pi2): 1.585e-02, MSE(pi3): 8.365e-01\n",
      "Epoch 6200, Train loss: 4.601e+08, Test loss: 4.038e+09, MSE(e): 2.393e-02, MSE(pi1): 1.391e+01, MSE(pi2): 1.434e-02, MSE(pi3): 8.168e-01\n",
      "Epoch 6300, Train loss: 4.434e+08, Test loss: 3.986e+09, MSE(e): 2.265e-02, MSE(pi1): 1.372e+01, MSE(pi2): 1.372e-02, MSE(pi3): 7.979e-01\n",
      "Epoch 6400, Train loss: 4.308e+08, Test loss: 3.921e+09, MSE(e): 2.176e-02, MSE(pi1): 1.352e+01, MSE(pi2): 1.371e-02, MSE(pi3): 7.797e-01\n",
      "Epoch 6500, Train loss: 4.382e+08, Test loss: 3.826e+09, MSE(e): 2.289e-02, MSE(pi1): 1.331e+01, MSE(pi2): 1.494e-02, MSE(pi3): 7.621e-01\n",
      "Epoch 6600, Train loss: 3.990e+08, Test loss: 3.842e+09, MSE(e): 1.933e-02, MSE(pi1): 1.312e+01, MSE(pi2): 1.182e-02, MSE(pi3): 7.457e-01\n",
      "Epoch 6700, Train loss: 3.855e+08, Test loss: 3.802e+09, MSE(e): 1.837e-02, MSE(pi1): 1.290e+01, MSE(pi2): 1.096e-02, MSE(pi3): 7.288e-01\n",
      "Epoch 6800, Train loss: 3.705e+08, Test loss: 3.721e+09, MSE(e): 1.728e-02, MSE(pi1): 1.266e+01, MSE(pi2): 1.055e-02, MSE(pi3): 7.111e-01\n",
      "Epoch 6900, Train loss: 3.561e+08, Test loss: 3.663e+09, MSE(e): 1.628e-02, MSE(pi1): 1.241e+01, MSE(pi2): 1.006e-02, MSE(pi3): 6.927e-01\n",
      "Epoch 7000, Train loss: 3.412e+08, Test loss: 3.597e+09, MSE(e): 1.525e-02, MSE(pi1): 1.214e+01, MSE(pi2): 9.285e-03, MSE(pi3): 6.731e-01\n",
      "Epoch 7100, Train loss: 3.263e+08, Test loss: 3.523e+09, MSE(e): 1.427e-02, MSE(pi1): 1.184e+01, MSE(pi2): 8.754e-03, MSE(pi3): 6.519e-01\n",
      "Epoch 7200, Train loss: 3.117e+08, Test loss: 3.465e+09, MSE(e): 1.336e-02, MSE(pi1): 1.152e+01, MSE(pi2): 8.113e-03, MSE(pi3): 6.290e-01\n",
      "Epoch 7300, Train loss: 2.971e+08, Test loss: 3.401e+09, MSE(e): 1.252e-02, MSE(pi1): 1.116e+01, MSE(pi2): 7.580e-03, MSE(pi3): 6.041e-01\n",
      "Epoch 7400, Train loss: 2.830e+08, Test loss: 3.316e+09, MSE(e): 1.178e-02, MSE(pi1): 1.076e+01, MSE(pi2): 7.278e-03, MSE(pi3): 5.768e-01\n",
      "Epoch 7500, Train loss: 2.682e+08, Test loss: 3.279e+09, MSE(e): 1.104e-02, MSE(pi1): 1.031e+01, MSE(pi2): 6.675e-03, MSE(pi3): 5.473e-01\n",
      "Epoch 7600, Train loss: 2.534e+08, Test loss: 3.223e+09, MSE(e): 1.038e-02, MSE(pi1): 9.810e+00, MSE(pi2): 6.268e-03, MSE(pi3): 5.154e-01\n",
      "Epoch 7700, Train loss: 2.384e+08, Test loss: 3.163e+09, MSE(e): 9.772e-03, MSE(pi1): 9.252e+00, MSE(pi2): 5.968e-03, MSE(pi3): 4.814e-01\n",
      "Epoch 7800, Train loss: 2.228e+08, Test loss: 3.120e+09, MSE(e): 9.195e-03, MSE(pi1): 8.631e+00, MSE(pi2): 5.553e-03, MSE(pi3): 4.456e-01\n",
      "Epoch 7900, Train loss: 2.070e+08, Test loss: 3.068e+09, MSE(e): 8.666e-03, MSE(pi1): 7.948e+00, MSE(pi2): 5.176e-03, MSE(pi3): 4.085e-01\n",
      "Epoch 8000, Train loss: 1.907e+08, Test loss: 3.024e+09, MSE(e): 8.166e-03, MSE(pi1): 7.202e+00, MSE(pi2): 4.934e-03, MSE(pi3): 3.704e-01\n",
      "Epoch 8100, Train loss: 1.823e+08, Test loss: 2.890e+09, MSE(e): 8.503e-03, MSE(pi1): 6.414e+00, MSE(pi2): 5.597e-03, MSE(pi3): 3.316e-01\n",
      "Epoch 8200, Train loss: 1.581e+08, Test loss: 2.934e+09, MSE(e): 7.258e-03, MSE(pi1): 5.600e+00, MSE(pi2): 4.385e-03, MSE(pi3): 2.954e-01\n",
      "Epoch 8300, Train loss: 1.423e+08, Test loss: 2.891e+09, MSE(e): 6.838e-03, MSE(pi1): 4.795e+00, MSE(pi2): 4.129e-03, MSE(pi3): 2.599e-01\n",
      "Epoch 8400, Train loss: 1.278e+08, Test loss: 2.852e+09, MSE(e): 6.486e-03, MSE(pi1): 4.032e+00, MSE(pi2): 4.027e-03, MSE(pi3): 2.265e-01\n",
      "Epoch 8500, Train loss: 1.138e+08, Test loss: 2.809e+09, MSE(e): 6.069e-03, MSE(pi1): 3.341e+00, MSE(pi2): 3.660e-03, MSE(pi3): 1.964e-01\n",
      "Epoch 8600, Train loss: 1.015e+08, Test loss: 2.771e+09, MSE(e): 5.716e-03, MSE(pi1): 2.746e+00, MSE(pi2): 3.443e-03, MSE(pi3): 1.692e-01\n",
      "Epoch 8700, Train loss: 9.097e+07, Test loss: 2.737e+09, MSE(e): 5.392e-03, MSE(pi1): 2.254e+00, MSE(pi2): 3.266e-03, MSE(pi3): 1.451e-01\n",
      "Epoch 8800, Train loss: 8.195e+07, Test loss: 2.699e+09, MSE(e): 5.087e-03, MSE(pi1): 1.865e+00, MSE(pi2): 3.054e-03, MSE(pi3): 1.243e-01\n",
      "Epoch 8900, Train loss: 7.434e+07, Test loss: 2.669e+09, MSE(e): 4.804e-03, MSE(pi1): 1.565e+00, MSE(pi2): 2.866e-03, MSE(pi3): 1.065e-01\n",
      "Epoch 9000, Train loss: 6.805e+07, Test loss: 2.635e+09, MSE(e): 4.551e-03, MSE(pi1): 1.341e+00, MSE(pi2): 2.725e-03, MSE(pi3): 9.129e-02\n",
      "Epoch 9100, Train loss: 6.275e+07, Test loss: 2.603e+09, MSE(e): 4.318e-03, MSE(pi1): 1.172e+00, MSE(pi2): 2.581e-03, MSE(pi3): 7.854e-02\n",
      "Epoch 9200, Train loss: 7.579e+07, Test loss: 2.453e+09, MSE(e): 5.835e-03, MSE(pi1): 1.086e+00, MSE(pi2): 3.556e-03, MSE(pi3): 6.581e-02\n",
      "Epoch 9300, Train loss: 5.442e+07, Test loss: 2.544e+09, MSE(e): 3.906e-03, MSE(pi1): 9.448e-01, MSE(pi2): 2.334e-03, MSE(pi3): 5.912e-02\n",
      "Epoch 9400, Train loss: 5.148e+07, Test loss: 2.515e+09, MSE(e): 3.722e-03, MSE(pi1): 8.868e-01, MSE(pi2): 2.219e-03, MSE(pi3): 5.392e-02\n",
      "Epoch 9500, Train loss: 4.811e+07, Test loss: 2.492e+09, MSE(e): 3.556e-03, MSE(pi1): 7.935e-01, MSE(pi2): 2.112e-03, MSE(pi3): 4.622e-02\n",
      "Epoch 9600, Train loss: 4.543e+07, Test loss: 2.456e+09, MSE(e): 3.407e-03, MSE(pi1): 7.356e-01, MSE(pi2): 2.043e-03, MSE(pi3): 4.003e-02\n",
      "Epoch 9700, Train loss: 4.292e+07, Test loss: 2.440e+09, MSE(e): 3.260e-03, MSE(pi1): 6.659e-01, MSE(pi2): 1.931e-03, MSE(pi3): 3.657e-02\n",
      "Epoch 9800, Train loss: 4.068e+07, Test loss: 2.405e+09, MSE(e): 3.132e-03, MSE(pi1): 6.077e-01, MSE(pi2): 1.880e-03, MSE(pi3): 3.280e-02\n",
      "Epoch 9900, Train loss: 5.550e+07, Test loss: 2.302e+09, MSE(e): 4.685e-03, MSE(pi1): 5.956e-01, MSE(pi2): 2.745e-03, MSE(pi3): 2.694e-02\n",
      "Epoch 10000, Train loss: 3.885e+07, Test loss: 2.357e+09, MSE(e): 2.915e-03, MSE(pi1): 7.168e-01, MSE(pi2): 1.744e-03, MSE(pi3): 2.532e-02\n",
      "Epoch 10100, Train loss: 3.480e+07, Test loss: 2.332e+09, MSE(e): 2.777e-03, MSE(pi1): 4.543e-01, MSE(pi2): 1.655e-03, MSE(pi3): 2.483e-02\n",
      "Epoch 10200, Train loss: 3.356e+07, Test loss: 2.297e+09, MSE(e): 2.720e-03, MSE(pi1): 4.194e-01, MSE(pi2): 1.645e-03, MSE(pi3): 2.172e-02\n",
      "Epoch 10300, Train loss: 3.181e+07, Test loss: 2.286e+09, MSE(e): 2.585e-03, MSE(pi1): 3.984e-01, MSE(pi2): 1.548e-03, MSE(pi3): 1.971e-02\n",
      "Epoch 10400, Train loss: 3.027e+07, Test loss: 2.258e+09, MSE(e): 2.499e-03, MSE(pi1): 3.416e-01, MSE(pi2): 1.501e-03, MSE(pi3): 1.865e-02\n",
      "Epoch 10500, Train loss: 2.944e+07, Test loss: 2.230e+09, MSE(e): 2.454e-03, MSE(pi1): 3.296e-01, MSE(pi2): 1.485e-03, MSE(pi3): 1.609e-02\n",
      "Epoch 10600, Train loss: 3.026e+07, Test loss: 2.264e+09, MSE(e): 2.569e-03, MSE(pi1): 2.838e-01, MSE(pi2): 1.450e-03, MSE(pi3): 1.730e-02\n",
      "Epoch 10700, Train loss: 2.663e+07, Test loss: 2.208e+09, MSE(e): 2.254e-03, MSE(pi1): 2.605e-01, MSE(pi2): 1.347e-03, MSE(pi3): 1.488e-02\n",
      "Epoch 10800, Train loss: 2.583e+07, Test loss: 2.186e+09, MSE(e): 2.188e-03, MSE(pi1): 2.602e-01, MSE(pi2): 1.311e-03, MSE(pi3): 1.347e-02\n",
      "Epoch 10900, Train loss: 2.537e+07, Test loss: 2.149e+09, MSE(e): 2.185e-03, MSE(pi1): 2.364e-01, MSE(pi2): 1.322e-03, MSE(pi3): 1.155e-02\n",
      "Epoch 11000, Train loss: 2.464e+07, Test loss: 2.145e+09, MSE(e): 2.084e-03, MSE(pi1): 2.689e-01, MSE(pi2): 1.254e-03, MSE(pi3): 1.113e-02\n",
      "Epoch 11100, Train loss: 2.310e+07, Test loss: 2.144e+09, MSE(e): 2.006e-03, MSE(pi1): 1.970e-01, MSE(pi2): 1.201e-03, MSE(pi3): 1.067e-02\n",
      "Epoch 11200, Train loss: 2.230e+07, Test loss: 2.120e+09, MSE(e): 1.952e-03, MSE(pi1): 1.751e-01, MSE(pi2): 1.175e-03, MSE(pi3): 1.035e-02\n",
      "Epoch 11300, Train loss: 2.218e+07, Test loss: 2.125e+09, MSE(e): 1.953e-03, MSE(pi1): 1.607e-01, MSE(pi2): 1.153e-03, MSE(pi3): 1.047e-02\n",
      "Epoch 11400, Train loss: 2.130e+07, Test loss: 2.085e+09, MSE(e): 1.879e-03, MSE(pi1): 1.571e-01, MSE(pi2): 1.134e-03, MSE(pi3): 9.351e-03\n",
      "Epoch 11500, Train loss: 2.085e+07, Test loss: 2.099e+09, MSE(e): 1.837e-03, MSE(pi1): 1.513e-01, MSE(pi2): 1.094e-03, MSE(pi3): 9.720e-03\n",
      "Epoch 11600, Train loss: 2.026e+07, Test loss: 2.063e+09, MSE(e): 1.795e-03, MSE(pi1): 1.458e-01, MSE(pi2): 1.085e-03, MSE(pi3): 8.551e-03\n",
      "Epoch 11700, Train loss: 2.046e+07, Test loss: 2.035e+09, MSE(e): 1.785e-03, MSE(pi1): 1.865e-01, MSE(pi2): 1.081e-03, MSE(pi3): 7.462e-03\n",
      "Epoch 11800, Train loss: 1.929e+07, Test loss: 2.059e+09, MSE(e): 1.693e-03, MSE(pi1): 1.481e-01, MSE(pi2): 1.017e-03, MSE(pi3): 8.776e-03\n",
      "Epoch 11900, Train loss: 1.846e+07, Test loss: 2.039e+09, MSE(e): 1.645e-03, MSE(pi1): 1.211e-01, MSE(pi2): 9.951e-04, MSE(pi3): 8.037e-03\n",
      "Epoch 12000, Train loss: 1.817e+07, Test loss: 2.031e+09, MSE(e): 1.611e-03, MSE(pi1): 1.267e-01, MSE(pi2): 9.748e-04, MSE(pi3): 7.981e-03\n",
      "Epoch 12100, Train loss: 1.910e+07, Test loss: 2.039e+09, MSE(e): 1.703e-03, MSE(pi1): 1.219e-01, MSE(pi2): 1.005e-03, MSE(pi3): 8.509e-03\n",
      "Epoch 12200, Train loss: 2.411e+07, Test loss: 2.051e+09, MSE(e): 2.172e-03, MSE(pi1): 1.401e-01, MSE(pi2): 1.206e-03, MSE(pi3): 9.884e-03\n",
      "Epoch 12300, Train loss: 1.773e+07, Test loss: 2.001e+09, MSE(e): 1.520e-03, MSE(pi1): 1.788e-01, MSE(pi2): 9.219e-04, MSE(pi3): 7.354e-03\n",
      "Epoch 12400, Train loss: 1.667e+07, Test loss: 1.987e+09, MSE(e): 1.490e-03, MSE(pi1): 1.049e-01, MSE(pi2): 9.071e-04, MSE(pi3): 7.203e-03\n",
      "Epoch 12500, Train loss: 1.652e+07, Test loss: 1.984e+09, MSE(e): 1.468e-03, MSE(pi1): 1.143e-01, MSE(pi2): 8.949e-04, MSE(pi3): 6.947e-03\n",
      "Epoch 12600, Train loss: 1.919e+07, Test loss: 1.936e+09, MSE(e): 1.705e-03, MSE(pi1): 1.524e-01, MSE(pi2): 1.013e-03, MSE(pi3): 6.115e-03\n",
      "Epoch 12700, Train loss: 1.677e+07, Test loss: 1.970e+09, MSE(e): 1.415e-03, MSE(pi1): 1.790e-01, MSE(pi2): 8.574e-04, MSE(pi3): 8.240e-03\n",
      "Epoch 12800, Train loss: 1.742e+07, Test loss: 1.963e+09, MSE(e): 1.397e-03, MSE(pi1): 2.587e-01, MSE(pi2): 8.449e-04, MSE(pi3): 8.582e-03\n",
      "Epoch 12900, Train loss: 1.535e+07, Test loss: 1.960e+09, MSE(e): 1.377e-03, MSE(pi1): 8.523e-02, MSE(pi2): 8.357e-04, MSE(pi3): 7.283e-03\n",
      "Epoch 13000, Train loss: 1.648e+07, Test loss: 1.943e+09, MSE(e): 1.456e-03, MSE(pi1): 1.264e-01, MSE(pi2): 8.825e-04, MSE(pi3): 6.567e-03\n",
      "Epoch 13100, Train loss: 1.489e+07, Test loss: 1.931e+09, MSE(e): 1.320e-03, MSE(pi1): 1.027e-01, MSE(pi2): 8.085e-04, MSE(pi3): 6.664e-03\n",
      "Epoch 13200, Train loss: 1.452e+07, Test loss: 1.934e+09, MSE(e): 1.298e-03, MSE(pi1): 8.070e-02, MSE(pi2): 7.932e-04, MSE(pi3): 7.290e-03\n",
      "Epoch 13300, Train loss: 1.459e+07, Test loss: 1.918e+09, MSE(e): 1.279e-03, MSE(pi1): 1.141e-01, MSE(pi2): 7.845e-04, MSE(pi3): 6.593e-03\n",
      "Epoch 13400, Train loss: 2.231e+07, Test loss: 1.875e+09, MSE(e): 2.009e-03, MSE(pi1): 1.626e-01, MSE(pi2): 1.138e-03, MSE(pi3): 5.973e-03\n",
      "Epoch 13500, Train loss: 1.820e+07, Test loss: 1.958e+09, MSE(e): 1.607e-03, MSE(pi1): 1.288e-01, MSE(pi2): 9.156e-04, MSE(pi3): 8.387e-03\n",
      "Epoch 13600, Train loss: 1.394e+07, Test loss: 1.911e+09, MSE(e): 1.243e-03, MSE(pi1): 8.154e-02, MSE(pi2): 7.553e-04, MSE(pi3): 7.017e-03\n",
      "Epoch 13700, Train loss: 1.343e+07, Test loss: 1.896e+09, MSE(e): 1.205e-03, MSE(pi1): 6.987e-02, MSE(pi2): 7.415e-04, MSE(pi3): 6.820e-03\n",
      "Epoch 13800, Train loss: 1.588e+07, Test loss: 1.854e+09, MSE(e): 1.441e-03, MSE(pi1): 8.285e-02, MSE(pi2): 8.447e-04, MSE(pi3): 6.418e-03\n",
      "Epoch 13900, Train loss: 1.324e+07, Test loss: 1.887e+09, MSE(e): 1.186e-03, MSE(pi1): 6.629e-02, MSE(pi2): 7.253e-04, MSE(pi3): 7.131e-03\n",
      "Epoch 14000, Train loss: 1.563e+07, Test loss: 1.846e+09, MSE(e): 1.395e-03, MSE(pi1): 9.832e-02, MSE(pi2): 8.171e-04, MSE(pi3): 6.908e-03\n",
      "Epoch 14100, Train loss: 1.291e+07, Test loss: 1.880e+09, MSE(e): 1.151e-03, MSE(pi1): 6.917e-02, MSE(pi2): 7.058e-04, MSE(pi3): 7.119e-03\n",
      "Epoch 14200, Train loss: 1.280e+07, Test loss: 1.862e+09, MSE(e): 1.122e-03, MSE(pi1): 7.911e-02, MSE(pi2): 6.910e-04, MSE(pi3): 7.865e-03\n",
      "Epoch 14300, Train loss: 1.251e+07, Test loss: 1.848e+09, MSE(e): 1.120e-03, MSE(pi1): 6.239e-02, MSE(pi2): 6.896e-04, MSE(pi3): 6.841e-03\n",
      "Epoch 14400, Train loss: 1.457e+07, Test loss: 1.882e+09, MSE(e): 1.307e-03, MSE(pi1): 7.846e-02, MSE(pi2): 7.585e-04, MSE(pi3): 7.111e-03\n",
      "Epoch 14500, Train loss: 1.385e+07, Test loss: 1.838e+09, MSE(e): 1.109e-03, MSE(pi1): 2.144e-01, MSE(pi2): 6.822e-04, MSE(pi3): 6.230e-03\n",
      "Epoch 14600, Train loss: 1.186e+07, Test loss: 1.840e+09, MSE(e): 1.062e-03, MSE(pi1): 5.697e-02, MSE(pi2): 6.570e-04, MSE(pi3): 6.713e-03\n",
      "Epoch 14700, Train loss: 1.176e+07, Test loss: 1.833e+09, MSE(e): 1.050e-03, MSE(pi1): 5.842e-02, MSE(pi2): 6.499e-04, MSE(pi3): 6.711e-03\n",
      "Epoch 14800, Train loss: 1.205e+07, Test loss: 1.843e+09, MSE(e): 1.082e-03, MSE(pi1): 5.429e-02, MSE(pi2): 6.600e-04, MSE(pi3): 6.838e-03\n",
      "Epoch 14900, Train loss: 1.210e+07, Test loss: 1.808e+09, MSE(e): 1.072e-03, MSE(pi1): 7.347e-02, MSE(pi2): 6.600e-04, MSE(pi3): 6.466e-03\n",
      "Epoch 15000, Train loss: 1.132e+07, Test loss: 1.819e+09, MSE(e): 1.012e-03, MSE(pi1): 5.321e-02, MSE(pi2): 6.274e-04, MSE(pi3): 6.678e-03\n",
      "Epoch 15100, Train loss: 1.119e+07, Test loss: 1.814e+09, MSE(e): 9.996e-04, MSE(pi1): 5.206e-02, MSE(pi2): 6.200e-04, MSE(pi3): 6.758e-03\n",
      "Epoch 15200, Train loss: 1.383e+07, Test loss: 1.814e+09, MSE(e): 1.011e-03, MSE(pi1): 3.021e-01, MSE(pi2): 6.170e-04, MSE(pi3): 6.938e-03\n",
      "Epoch 15300, Train loss: 1.135e+07, Test loss: 1.791e+09, MSE(e): 1.016e-03, MSE(pi1): 5.454e-02, MSE(pi2): 6.262e-04, MSE(pi3): 6.479e-03\n",
      "Epoch 15400, Train loss: 1.130e+07, Test loss: 1.785e+09, MSE(e): 1.008e-03, MSE(pi1): 5.650e-02, MSE(pi2): 6.189e-04, MSE(pi3): 6.561e-03\n",
      "Epoch 15500, Train loss: 1.123e+07, Test loss: 1.783e+09, MSE(e): 9.801e-04, MSE(pi1): 7.897e-02, MSE(pi2): 6.064e-04, MSE(pi3): 6.426e-03\n",
      "Epoch 15600, Train loss: 1.061e+07, Test loss: 1.788e+09, MSE(e): 9.450e-04, MSE(pi1): 4.979e-02, MSE(pi2): 5.875e-04, MSE(pi3): 6.625e-03\n",
      "Epoch 15700, Train loss: 1.097e+07, Test loss: 1.791e+09, MSE(e): 9.822e-04, MSE(pi1): 4.574e-02, MSE(pi2): 6.000e-04, MSE(pi3): 6.920e-03\n",
      "Epoch 15800, Train loss: 1.101e+07, Test loss: 1.774e+09, MSE(e): 9.404e-04, MSE(pi1): 9.250e-02, MSE(pi2): 5.805e-04, MSE(pi3): 6.786e-03\n",
      "Epoch 15900, Train loss: 1.077e+07, Test loss: 1.779e+09, MSE(e): 9.191e-04, MSE(pi1): 9.249e-02, MSE(pi2): 5.697e-04, MSE(pi3): 6.509e-03\n",
      "Epoch 16000, Train loss: 1.051e+07, Test loss: 1.773e+09, MSE(e): 9.074e-04, MSE(pi1): 7.612e-02, MSE(pi2): 5.633e-04, MSE(pi3): 6.755e-03\n",
      "Epoch 16100, Train loss: 1.276e+07, Test loss: 1.733e+09, MSE(e): 1.123e-03, MSE(pi1): 8.623e-02, MSE(pi2): 6.538e-04, MSE(pi3): 6.695e-03\n",
      "Epoch 16200, Train loss: 1.161e+07, Test loss: 1.762e+09, MSE(e): 9.301e-04, MSE(pi1): 1.615e-01, MSE(pi2): 5.698e-04, MSE(pi3): 6.974e-03\n",
      "Epoch 16300, Train loss: 1.056e+07, Test loss: 1.761e+09, MSE(e): 8.915e-04, MSE(pi1): 1.031e-01, MSE(pi2): 5.545e-04, MSE(pi3): 6.094e-03\n",
      "Epoch 16400, Train loss: 2.166e+07, Test loss: 1.694e+09, MSE(e): 2.004e-03, MSE(pi1): 1.049e-01, MSE(pi2): 1.068e-03, MSE(pi3): 5.686e-03\n",
      "Epoch 16500, Train loss: 1.074e+07, Test loss: 1.752e+09, MSE(e): 8.681e-04, MSE(pi1): 1.382e-01, MSE(pi2): 5.370e-04, MSE(pi3): 6.776e-03\n",
      "Epoch 16600, Train loss: 9.862e+06, Test loss: 1.747e+09, MSE(e): 8.523e-04, MSE(pi1): 7.035e-02, MSE(pi2): 5.306e-04, MSE(pi3): 6.352e-03\n",
      "Epoch 16700, Train loss: 1.215e+07, Test loss: 1.721e+09, MSE(e): 9.960e-04, MSE(pi1): 1.590e-01, MSE(pi2): 6.042e-04, MSE(pi3): 5.974e-03\n",
      "Epoch 16800, Train loss: 1.109e+07, Test loss: 1.764e+09, MSE(e): 9.939e-04, MSE(pi1): 4.310e-02, MSE(pi2): 5.860e-04, MSE(pi3): 7.180e-03\n",
      "Epoch 16900, Train loss: 9.768e+06, Test loss: 1.723e+09, MSE(e): 8.574e-04, MSE(pi1): 5.689e-02, MSE(pi2): 5.315e-04, MSE(pi3): 6.250e-03\n",
      "Epoch 17000, Train loss: 9.381e+06, Test loss: 1.731e+09, MSE(e): 8.208e-04, MSE(pi1): 4.924e-02, MSE(pi2): 5.115e-04, MSE(pi3): 6.805e-03\n",
      "Epoch 17100, Train loss: 1.060e+07, Test loss: 1.724e+09, MSE(e): 8.255e-04, MSE(pi1): 1.710e-01, MSE(pi2): 5.101e-04, MSE(pi3): 6.393e-03\n",
      "Epoch 17200, Train loss: 9.247e+06, Test loss: 1.719e+09, MSE(e): 8.049e-04, MSE(pi1): 5.757e-02, MSE(pi2): 5.028e-04, MSE(pi3): 6.222e-03\n",
      "Epoch 17300, Train loss: 9.127e+06, Test loss: 1.719e+09, MSE(e): 7.967e-04, MSE(pi1): 4.694e-02, MSE(pi2): 4.969e-04, MSE(pi3): 6.911e-03\n",
      "Epoch 17400, Train loss: 9.814e+06, Test loss: 1.692e+09, MSE(e): 8.712e-04, MSE(pi1): 4.672e-02, MSE(pi2): 5.336e-04, MSE(pi3): 6.347e-03\n",
      "Epoch 17500, Train loss: 9.992e+06, Test loss: 1.702e+09, MSE(e): 8.063e-04, MSE(pi1): 1.299e-01, MSE(pi2): 5.009e-04, MSE(pi3): 6.300e-03\n",
      "Epoch 17600, Train loss: 9.205e+06, Test loss: 1.703e+09, MSE(e): 7.823e-04, MSE(pi1): 7.173e-02, MSE(pi2): 4.887e-04, MSE(pi3): 6.647e-03\n",
      "Epoch 17700, Train loss: 8.708e+06, Test loss: 1.705e+09, MSE(e): 7.669e-04, MSE(pi1): 3.799e-02, MSE(pi2): 4.793e-04, MSE(pi3): 6.592e-03\n",
      "Epoch 17800, Train loss: 8.830e+06, Test loss: 1.697e+09, MSE(e): 7.705e-04, MSE(pi1): 4.777e-02, MSE(pi2): 4.806e-04, MSE(pi3): 6.476e-03\n",
      "Epoch 17900, Train loss: 9.252e+06, Test loss: 1.682e+09, MSE(e): 7.797e-04, MSE(pi1): 7.991e-02, MSE(pi2): 4.863e-04, MSE(pi3): 6.555e-03\n",
      "Epoch 18000, Train loss: 9.290e+06, Test loss: 1.678e+09, MSE(e): 8.034e-04, MSE(pi1): 6.125e-02, MSE(pi2): 4.950e-04, MSE(pi3): 6.440e-03\n",
      "Epoch 18100, Train loss: 1.184e+07, Test loss: 1.726e+09, MSE(e): 9.889e-04, MSE(pi1): 1.192e-01, MSE(pi2): 5.783e-04, MSE(pi3): 7.554e-03\n",
      "Epoch 18200, Train loss: 1.194e+07, Test loss: 1.722e+09, MSE(e): 1.085e-03, MSE(pi1): 3.381e-02, MSE(pi2): 6.058e-04, MSE(pi3): 7.505e-03\n",
      "Epoch 18300, Train loss: 8.307e+06, Test loss: 1.660e+09, MSE(e): 7.278e-04, MSE(pi1): 3.606e-02, MSE(pi2): 4.558e-04, MSE(pi3): 6.680e-03\n",
      "Epoch 18400, Train loss: 8.329e+06, Test loss: 1.681e+09, MSE(e): 7.227e-04, MSE(pi1): 4.579e-02, MSE(pi2): 4.520e-04, MSE(pi3): 6.439e-03\n",
      "Epoch 18500, Train loss: 9.133e+06, Test loss: 1.680e+09, MSE(e): 7.240e-04, MSE(pi1): 1.173e-01, MSE(pi2): 4.495e-04, MSE(pi3): 7.212e-03\n",
      "Epoch 18600, Train loss: 8.363e+06, Test loss: 1.696e+09, MSE(e): 7.215e-04, MSE(pi1): 4.884e-02, MSE(pi2): 4.484e-04, MSE(pi3): 6.593e-03\n",
      "Epoch 18700, Train loss: 9.085e+06, Test loss: 1.676e+09, MSE(e): 7.180e-04, MSE(pi1): 1.121e-01, MSE(pi2): 4.433e-04, MSE(pi3): 7.850e-03\n",
      "Epoch 18800, Train loss: 8.013e+06, Test loss: 1.665e+09, MSE(e): 7.007e-04, MSE(pi1): 3.619e-02, MSE(pi2): 4.393e-04, MSE(pi3): 6.445e-03\n",
      "Epoch 18900, Train loss: 9.180e+06, Test loss: 1.687e+09, MSE(e): 8.109e-04, MSE(pi1): 3.715e-02, MSE(pi2): 4.860e-04, MSE(pi3): 6.994e-03\n",
      "Epoch 19000, Train loss: 8.537e+06, Test loss: 1.662e+09, MSE(e): 6.933e-04, MSE(pi1): 9.831e-02, MSE(pi2): 4.331e-04, MSE(pi3): 6.207e-03\n",
      "Epoch 19100, Train loss: 8.821e+06, Test loss: 1.681e+09, MSE(e): 7.576e-04, MSE(pi1): 5.277e-02, MSE(pi2): 4.616e-04, MSE(pi3): 7.166e-03\n",
      "Epoch 19200, Train loss: 1.056e+07, Test loss: 1.660e+09, MSE(e): 7.019e-04, MSE(pi1): 2.845e-01, MSE(pi2): 4.309e-04, MSE(pi3): 6.960e-03\n",
      "Epoch 19300, Train loss: 7.901e+06, Test loss: 1.660e+09, MSE(e): 6.913e-04, MSE(pi1): 3.264e-02, MSE(pi2): 4.295e-04, MSE(pi3): 6.620e-03\n",
      "Epoch 19400, Train loss: 1.423e+07, Test loss: 1.607e+09, MSE(e): 1.312e-03, MSE(pi1): 5.217e-02, MSE(pi2): 7.123e-04, MSE(pi3): 5.792e-03\n",
      "Epoch 19500, Train loss: 7.825e+06, Test loss: 1.645e+09, MSE(e): 6.675e-04, MSE(pi1): 5.235e-02, MSE(pi2): 4.190e-04, MSE(pi3): 6.263e-03\n",
      "Epoch 19600, Train loss: 7.561e+06, Test loss: 1.647e+09, MSE(e): 6.575e-04, MSE(pi1): 3.274e-02, MSE(pi2): 4.128e-04, MSE(pi3): 6.584e-03\n",
      "Epoch 19700, Train loss: 7.507e+06, Test loss: 1.642e+09, MSE(e): 6.528e-04, MSE(pi1): 3.219e-02, MSE(pi2): 4.102e-04, MSE(pi3): 6.563e-03\n",
      "Epoch 19800, Train loss: 7.993e+06, Test loss: 1.655e+09, MSE(e): 6.776e-04, MSE(pi1): 5.730e-02, MSE(pi2): 4.173e-04, MSE(pi3): 6.447e-03\n",
      "Epoch 19900, Train loss: 7.948e+06, Test loss: 1.650e+09, MSE(e): 6.878e-04, MSE(pi1): 4.055e-02, MSE(pi2): 4.217e-04, MSE(pi3): 6.645e-03\n",
      "Epoch 20000, Train loss: 8.237e+06, Test loss: 1.627e+09, MSE(e): 6.765e-04, MSE(pi1): 8.030e-02, MSE(pi2): 4.188e-04, MSE(pi3): 6.693e-03\n",
      "Epoch 20100, Train loss: 7.455e+06, Test loss: 1.639e+09, MSE(e): 6.432e-04, MSE(pi1): 3.650e-02, MSE(pi2): 4.017e-04, MSE(pi3): 6.582e-03\n",
      "Epoch 20200, Train loss: 7.346e+06, Test loss: 1.636e+09, MSE(e): 6.358e-04, MSE(pi1): 3.252e-02, MSE(pi2): 3.984e-04, MSE(pi3): 6.628e-03\n",
      "Epoch 20300, Train loss: 7.500e+06, Test loss: 1.637e+09, MSE(e): 6.422e-04, MSE(pi1): 4.184e-02, MSE(pi2): 4.008e-04, MSE(pi3): 6.597e-03\n",
      "Epoch 20400, Train loss: 7.458e+06, Test loss: 1.635e+09, MSE(e): 6.359e-04, MSE(pi1): 4.376e-02, MSE(pi2): 3.952e-04, MSE(pi3): 6.609e-03\n",
      "Epoch 20500, Train loss: 1.083e+07, Test loss: 1.601e+09, MSE(e): 9.372e-04, MSE(pi1): 8.597e-02, MSE(pi2): 5.348e-04, MSE(pi3): 5.944e-03\n",
      "Epoch 20600, Train loss: 7.087e+06, Test loss: 1.622e+09, MSE(e): 6.132e-04, MSE(pi1): 3.067e-02, MSE(pi2): 3.860e-04, MSE(pi3): 6.476e-03\n",
      "Epoch 20700, Train loss: 1.050e+07, Test loss: 1.593e+09, MSE(e): 9.228e-04, MSE(pi1): 6.916e-02, MSE(pi2): 5.334e-04, MSE(pi3): 5.780e-03\n",
      "Epoch 20800, Train loss: 8.807e+06, Test loss: 1.615e+09, MSE(e): 7.689e-04, MSE(pi1): 5.036e-02, MSE(pi2): 4.622e-04, MSE(pi3): 6.147e-03\n",
      "Epoch 20900, Train loss: 8.452e+06, Test loss: 1.617e+09, MSE(e): 6.166e-04, MSE(pi1): 1.572e-01, MSE(pi2): 3.820e-04, MSE(pi3): 7.154e-03\n",
      "Epoch 21000, Train loss: 8.304e+06, Test loss: 1.624e+09, MSE(e): 6.335e-04, MSE(pi1): 1.373e-01, MSE(pi2): 3.841e-04, MSE(pi3): 5.963e-03\n",
      "Epoch 21100, Train loss: 7.069e+06, Test loss: 1.603e+09, MSE(e): 6.117e-04, MSE(pi1): 3.152e-02, MSE(pi2): 3.833e-04, MSE(pi3): 6.362e-03\n",
      "Epoch 21200, Train loss: 6.981e+06, Test loss: 1.610e+09, MSE(e): 5.937e-04, MSE(pi1): 3.984e-02, MSE(pi2): 3.731e-04, MSE(pi3): 6.455e-03\n",
      "Epoch 21300, Train loss: 8.133e+06, Test loss: 1.639e+09, MSE(e): 7.090e-04, MSE(pi1): 3.693e-02, MSE(pi2): 4.208e-04, MSE(pi3): 6.732e-03\n",
      "Epoch 21400, Train loss: 7.322e+06, Test loss: 1.619e+09, MSE(e): 6.251e-04, MSE(pi1): 3.838e-02, MSE(pi2): 3.861e-04, MSE(pi3): 6.866e-03\n",
      "Epoch 21500, Train loss: 6.749e+06, Test loss: 1.601e+09, MSE(e): 5.797e-04, MSE(pi1): 2.917e-02, MSE(pi2): 3.656e-04, MSE(pi3): 6.604e-03\n",
      "Epoch 21600, Train loss: 6.696e+06, Test loss: 1.599e+09, MSE(e): 5.761e-04, MSE(pi1): 2.896e-02, MSE(pi2): 3.635e-04, MSE(pi3): 6.454e-03\n",
      "Epoch 21700, Train loss: 7.332e+06, Test loss: 1.594e+09, MSE(e): 5.898e-04, MSE(pi1): 7.258e-02, MSE(pi2): 3.664e-04, MSE(pi3): 7.079e-03\n",
      "Epoch 21800, Train loss: 7.146e+06, Test loss: 1.594e+09, MSE(e): 5.780e-04, MSE(pi1): 7.247e-02, MSE(pi2): 3.632e-04, MSE(pi3): 6.415e-03\n",
      "Epoch 21900, Train loss: 6.872e+06, Test loss: 1.584e+09, MSE(e): 5.878e-04, MSE(pi1): 3.528e-02, MSE(pi2): 3.667e-04, MSE(pi3): 6.408e-03\n",
      "Epoch 22000, Train loss: 9.124e+06, Test loss: 1.568e+09, MSE(e): 7.803e-04, MSE(pi1): 6.732e-02, MSE(pi2): 4.467e-04, MSE(pi3): 6.481e-03\n",
      "Epoch 22100, Train loss: 6.762e+06, Test loss: 1.582e+09, MSE(e): 5.700e-04, MSE(pi1): 4.225e-02, MSE(pi2): 3.575e-04, MSE(pi3): 6.395e-03\n",
      "Epoch 22200, Train loss: 6.621e+06, Test loss: 1.594e+09, MSE(e): 5.648e-04, MSE(pi1): 3.087e-02, MSE(pi2): 3.549e-04, MSE(pi3): 6.640e-03\n",
      "Epoch 22300, Train loss: 6.710e+06, Test loss: 1.582e+09, MSE(e): 5.566e-04, MSE(pi1): 5.175e-02, MSE(pi2): 3.516e-04, MSE(pi3): 6.264e-03\n",
      "Epoch 22400, Train loss: 6.984e+06, Test loss: 1.597e+09, MSE(e): 5.988e-04, MSE(pi1): 3.472e-02, MSE(pi2): 3.663e-04, MSE(pi3): 6.487e-03\n",
      "Epoch 22500, Train loss: 1.771e+07, Test loss: 1.532e+09, MSE(e): 1.441e-03, MSE(pi1): 2.761e-01, MSE(pi2): 7.776e-04, MSE(pi3): 5.459e-03\n",
      "Epoch 22600, Train loss: 6.377e+06, Test loss: 1.584e+09, MSE(e): 5.458e-04, MSE(pi1): 2.689e-02, MSE(pi2): 3.443e-04, MSE(pi3): 6.499e-03\n",
      "Epoch 22700, Train loss: 7.077e+06, Test loss: 1.585e+09, MSE(e): 5.551e-04, MSE(pi1): 8.578e-02, MSE(pi2): 3.463e-04, MSE(pi3): 6.680e-03\n",
      "Epoch 22800, Train loss: 7.875e+06, Test loss: 1.557e+09, MSE(e): 6.871e-04, MSE(pi1): 3.950e-02, MSE(pi2): 4.082e-04, MSE(pi3): 6.091e-03\n",
      "Epoch 22900, Train loss: 6.839e+06, Test loss: 1.580e+09, MSE(e): 5.450e-04, MSE(pi1): 6.816e-02, MSE(pi2): 3.420e-04, MSE(pi3): 7.070e-03\n",
      "Epoch 23000, Train loss: 6.254e+06, Test loss: 1.575e+09, MSE(e): 5.328e-04, MSE(pi1): 2.742e-02, MSE(pi2): 3.367e-04, MSE(pi3): 6.522e-03\n",
      "Epoch 23100, Train loss: 6.267e+06, Test loss: 1.570e+09, MSE(e): 5.296e-04, MSE(pi1): 3.281e-02, MSE(pi2): 3.349e-04, MSE(pi3): 6.423e-03\n",
      "Epoch 23200, Train loss: 6.696e+06, Test loss: 1.595e+09, MSE(e): 5.606e-04, MSE(pi1): 4.430e-02, MSE(pi2): 3.446e-04, MSE(pi3): 6.472e-03\n",
      "Epoch 23300, Train loss: 7.839e+06, Test loss: 1.568e+09, MSE(e): 5.396e-04, MSE(pi1): 1.803e-01, MSE(pi2): 3.356e-04, MSE(pi3): 6.393e-03\n",
      "Epoch 23400, Train loss: 6.242e+06, Test loss: 1.568e+09, MSE(e): 5.221e-04, MSE(pi1): 3.692e-02, MSE(pi2): 3.302e-04, MSE(pi3): 6.515e-03\n",
      "Epoch 23500, Train loss: 7.696e+06, Test loss: 1.547e+09, MSE(e): 5.807e-04, MSE(pi1): 1.285e-01, MSE(pi2): 3.613e-04, MSE(pi3): 6.038e-03\n",
      "Epoch 23600, Train loss: 7.312e+06, Test loss: 1.539e+09, MSE(e): 6.303e-04, MSE(pi1): 3.736e-02, MSE(pi2): 3.770e-04, MSE(pi3): 6.355e-03\n",
      "Epoch 23700, Train loss: 6.224e+06, Test loss: 1.558e+09, MSE(e): 5.154e-04, MSE(pi1): 3.321e-02, MSE(pi2): 3.258e-04, MSE(pi3): 7.376e-03\n",
      "Epoch 23800, Train loss: 6.006e+06, Test loss: 1.557e+09, MSE(e): 5.102e-04, MSE(pi1): 2.671e-02, MSE(pi2): 3.234e-04, MSE(pi3): 6.374e-03\n",
      "Epoch 23900, Train loss: 1.266e+07, Test loss: 1.517e+09, MSE(e): 1.048e-03, MSE(pi1): 1.531e-01, MSE(pi2): 5.462e-04, MSE(pi3): 6.549e-03\n",
      "Epoch 24000, Train loss: 5.949e+06, Test loss: 1.554e+09, MSE(e): 5.049e-04, MSE(pi1): 2.556e-02, MSE(pi2): 3.201e-04, MSE(pi3): 6.443e-03\n",
      "Epoch 24100, Train loss: 6.583e+06, Test loss: 1.546e+09, MSE(e): 5.125e-04, MSE(pi1): 8.060e-02, MSE(pi2): 3.230e-04, MSE(pi3): 6.526e-03\n",
      "Epoch 24200, Train loss: 6.949e+06, Test loss: 1.564e+09, MSE(e): 5.425e-04, MSE(pi1): 8.462e-02, MSE(pi2): 3.329e-04, MSE(pi3): 6.778e-03\n",
      "Epoch 24300, Train loss: 5.879e+06, Test loss: 1.548e+09, MSE(e): 4.974e-04, MSE(pi1): 2.657e-02, MSE(pi2): 3.154e-04, MSE(pi3): 6.389e-03\n",
      "Epoch 24400, Train loss: 5.863e+06, Test loss: 1.551e+09, MSE(e): 4.969e-04, MSE(pi1): 2.485e-02, MSE(pi2): 3.145e-04, MSE(pi3): 6.457e-03\n",
      "Epoch 24500, Train loss: 8.758e+06, Test loss: 1.522e+09, MSE(e): 7.116e-04, MSE(pi1): 1.026e-01, MSE(pi2): 4.153e-04, MSE(pi3): 6.159e-03\n",
      "Epoch 24600, Train loss: 5.974e+06, Test loss: 1.537e+09, MSE(e): 4.967e-04, MSE(pi1): 3.470e-02, MSE(pi2): 3.135e-04, MSE(pi3): 6.595e-03\n",
      "Epoch 24700, Train loss: 9.055e+06, Test loss: 1.532e+09, MSE(e): 6.473e-04, MSE(pi1): 1.964e-01, MSE(pi2): 3.898e-04, MSE(pi3): 6.187e-03\n",
      "Epoch 24800, Train loss: 6.113e+06, Test loss: 1.527e+09, MSE(e): 5.136e-04, MSE(pi1): 3.651e-02, MSE(pi2): 3.227e-04, MSE(pi3): 6.125e-03\n",
      "Epoch 24900, Train loss: 5.913e+06, Test loss: 1.540e+09, MSE(e): 4.848e-04, MSE(pi1): 4.125e-02, MSE(pi2): 3.071e-04, MSE(pi3): 6.521e-03\n",
      "Epoch 25000, Train loss: 6.383e+06, Test loss: 1.532e+09, MSE(e): 4.910e-04, MSE(pi1): 8.784e-02, MSE(pi2): 3.105e-04, MSE(pi3): 5.955e-03\n",
      "Epoch 25100, Train loss: 5.793e+06, Test loss: 1.540e+09, MSE(e): 4.864e-04, MSE(pi1): 2.909e-02, MSE(pi2): 3.062e-04, MSE(pi3): 6.385e-03\n",
      "Epoch 25200, Train loss: 5.759e+06, Test loss: 1.539e+09, MSE(e): 4.829e-04, MSE(pi1): 2.701e-02, MSE(pi2): 3.051e-04, MSE(pi3): 6.599e-03\n",
      "Epoch 25300, Train loss: 5.744e+06, Test loss: 1.531e+09, MSE(e): 4.751e-04, MSE(pi1): 3.746e-02, MSE(pi2): 3.016e-04, MSE(pi3): 6.192e-03\n",
      "Epoch 25400, Train loss: 6.660e+06, Test loss: 1.529e+09, MSE(e): 4.857e-04, MSE(pi1): 1.124e-01, MSE(pi2): 3.056e-04, MSE(pi3): 6.800e-03\n",
      "Epoch 25500, Train loss: 6.127e+06, Test loss: 1.521e+09, MSE(e): 4.798e-04, MSE(pi1): 7.172e-02, MSE(pi2): 3.041e-04, MSE(pi3): 6.112e-03\n",
      "Epoch 25600, Train loss: 9.796e+06, Test loss: 1.576e+09, MSE(e): 8.400e-04, MSE(pi1): 6.544e-02, MSE(pi2): 4.576e-04, MSE(pi3): 7.416e-03\n",
      "Epoch 25700, Train loss: 7.386e+06, Test loss: 1.510e+09, MSE(e): 5.266e-04, MSE(pi1): 1.532e-01, MSE(pi2): 3.302e-04, MSE(pi3): 5.878e-03\n",
      "Epoch 25800, Train loss: 6.450e+06, Test loss: 1.529e+09, MSE(e): 4.841e-04, MSE(pi1): 9.472e-02, MSE(pi2): 3.029e-04, MSE(pi3): 6.624e-03\n",
      "Epoch 25900, Train loss: 5.491e+06, Test loss: 1.520e+09, MSE(e): 4.609e-04, MSE(pi1): 2.458e-02, MSE(pi2): 2.931e-04, MSE(pi3): 6.362e-03\n",
      "Epoch 26000, Train loss: 7.941e+06, Test loss: 1.490e+09, MSE(e): 6.213e-04, MSE(pi1): 1.131e-01, MSE(pi2): 3.702e-04, MSE(pi3): 5.970e-03\n",
      "Epoch 26100, Train loss: 9.234e+06, Test loss: 1.481e+09, MSE(e): 7.978e-04, MSE(pi1): 6.840e-02, MSE(pi2): 4.538e-04, MSE(pi3): 5.728e-03\n",
      "Epoch 26200, Train loss: 7.666e+06, Test loss: 1.543e+09, MSE(e): 6.368e-04, MSE(pi1): 6.425e-02, MSE(pi2): 3.582e-04, MSE(pi3): 6.549e-03\n",
      "Epoch 26300, Train loss: 5.955e+06, Test loss: 1.524e+09, MSE(e): 4.673e-04, MSE(pi1): 5.749e-02, MSE(pi2): 2.939e-04, MSE(pi3): 7.070e-03\n",
      "Epoch 26400, Train loss: 5.550e+06, Test loss: 1.506e+09, MSE(e): 4.650e-04, MSE(pi1): 2.639e-02, MSE(pi2): 2.934e-04, MSE(pi3): 6.364e-03\n",
      "Epoch 26500, Train loss: 6.197e+06, Test loss: 1.524e+09, MSE(e): 4.971e-04, MSE(pi1): 5.190e-02, MSE(pi2): 3.074e-04, MSE(pi3): 7.071e-03\n",
      "Epoch 26600, Train loss: 5.982e+06, Test loss: 1.502e+09, MSE(e): 4.647e-04, MSE(pi1): 7.331e-02, MSE(pi2): 2.950e-04, MSE(pi3): 6.024e-03\n",
      "Epoch 26700, Train loss: 6.145e+06, Test loss: 1.519e+09, MSE(e): 4.712e-04, MSE(pi1): 7.266e-02, MSE(pi2): 2.944e-04, MSE(pi3): 7.062e-03\n",
      "Epoch 26800, Train loss: 5.758e+06, Test loss: 1.507e+09, MSE(e): 4.522e-04, MSE(pi1): 5.962e-02, MSE(pi2): 2.871e-04, MSE(pi3): 6.402e-03\n",
      "Epoch 26900, Train loss: 9.223e+06, Test loss: 1.527e+09, MSE(e): 7.510e-04, MSE(pi1): 1.055e-01, MSE(pi2): 3.964e-04, MSE(pi3): 6.577e-03\n",
      "Epoch 27000, Train loss: 5.543e+06, Test loss: 1.495e+09, MSE(e): 4.484e-04, MSE(pi1): 4.377e-02, MSE(pi2): 2.848e-04, MSE(pi3): 6.222e-03\n",
      "Epoch 27100, Train loss: 5.526e+06, Test loss: 1.495e+09, MSE(e): 4.451e-04, MSE(pi1): 4.003e-02, MSE(pi2): 2.812e-04, MSE(pi3): 6.746e-03\n",
      "Epoch 27200, Train loss: 5.282e+06, Test loss: 1.493e+09, MSE(e): 4.374e-04, MSE(pi1): 2.548e-02, MSE(pi2): 2.782e-04, MSE(pi3): 6.535e-03\n",
      "Epoch 27300, Train loss: 1.890e+07, Test loss: 1.427e+09, MSE(e): 1.552e-03, MSE(pi1): 2.830e-01, MSE(pi2): 8.191e-04, MSE(pi3): 5.503e-03\n",
      "Epoch 27400, Train loss: 5.519e+06, Test loss: 1.493e+09, MSE(e): 4.352e-04, MSE(pi1): 5.499e-02, MSE(pi2): 2.769e-04, MSE(pi3): 6.175e-03\n",
      "Epoch 27500, Train loss: 1.170e+07, Test loss: 1.536e+09, MSE(e): 1.075e-03, MSE(pi1): 2.395e-02, MSE(pi2): 5.448e-04, MSE(pi3): 7.083e-03\n",
      "Epoch 27600, Train loss: 1.175e+07, Test loss: 1.440e+09, MSE(e): 9.997e-04, MSE(pi1): 1.188e-01, MSE(pi2): 5.461e-04, MSE(pi3): 5.607e-03\n",
      "Epoch 27700, Train loss: 1.453e+07, Test loss: 1.552e+09, MSE(e): 1.033e-03, MSE(pi1): 3.143e-01, MSE(pi2): 5.524e-04, MSE(pi3): 1.052e-02\n",
      "Epoch 27800, Train loss: 5.288e+06, Test loss: 1.465e+09, MSE(e): 4.344e-04, MSE(pi1): 2.926e-02, MSE(pi2): 2.747e-04, MSE(pi3): 6.522e-03\n",
      "Epoch 27900, Train loss: 5.081e+06, Test loss: 1.485e+09, MSE(e): 4.220e-04, MSE(pi1): 2.255e-02, MSE(pi2): 2.692e-04, MSE(pi3): 6.351e-03\n",
      "Epoch 28000, Train loss: 5.084e+06, Test loss: 1.484e+09, MSE(e): 4.212e-04, MSE(pi1): 2.380e-02, MSE(pi2): 2.683e-04, MSE(pi3): 6.335e-03\n",
      "Epoch 28100, Train loss: 1.103e+07, Test loss: 1.541e+09, MSE(e): 7.743e-04, MSE(pi1): 2.392e-01, MSE(pi2): 4.336e-04, MSE(pi3): 8.925e-03\n",
      "Epoch 28200, Train loss: 5.061e+06, Test loss: 1.482e+09, MSE(e): 4.177e-04, MSE(pi1): 2.374e-02, MSE(pi2): 2.661e-04, MSE(pi3): 6.467e-03\n",
      "Epoch 28300, Train loss: 5.385e+06, Test loss: 1.471e+09, MSE(e): 4.269e-04, MSE(pi1): 5.010e-02, MSE(pi2): 2.710e-04, MSE(pi3): 6.153e-03\n",
      "Epoch 28400, Train loss: 7.972e+06, Test loss: 1.450e+09, MSE(e): 6.857e-04, MSE(pi1): 5.108e-02, MSE(pi2): 3.920e-04, MSE(pi3): 6.045e-03\n",
      "Epoch 28500, Train loss: 5.330e+06, Test loss: 1.489e+09, MSE(e): 4.392e-04, MSE(pi1): 2.716e-02, MSE(pi2): 2.743e-04, MSE(pi3): 6.669e-03\n",
      "Epoch 28600, Train loss: 5.270e+06, Test loss: 1.487e+09, MSE(e): 4.379e-04, MSE(pi1): 2.275e-02, MSE(pi2): 2.734e-04, MSE(pi3): 6.638e-03\n",
      "Epoch 28700, Train loss: 5.341e+06, Test loss: 1.485e+09, MSE(e): 4.126e-04, MSE(pi1): 6.112e-02, MSE(pi2): 2.610e-04, MSE(pi3): 6.046e-03\n",
      "Epoch 28800, Train loss: 3.288e+07, Test loss: 1.393e+09, MSE(e): 3.097e-03, MSE(pi1): 1.387e-01, MSE(pi2): 1.501e-03, MSE(pi3): 5.276e-03\n",
      "Epoch 28900, Train loss: 4.900e+06, Test loss: 1.468e+09, MSE(e): 4.046e-04, MSE(pi1): 2.184e-02, MSE(pi2): 2.583e-04, MSE(pi3): 6.356e-03\n",
      "Epoch 29000, Train loss: 6.843e+06, Test loss: 1.505e+09, MSE(e): 5.883e-04, MSE(pi1): 3.066e-02, MSE(pi2): 3.326e-04, MSE(pi3): 6.535e-03\n",
      "Epoch 29100, Train loss: 6.665e+06, Test loss: 1.446e+09, MSE(e): 5.082e-04, MSE(pi1): 9.789e-02, MSE(pi2): 3.073e-04, MSE(pi3): 6.038e-03\n",
      "Epoch 29200, Train loss: 9.140e+06, Test loss: 1.427e+09, MSE(e): 8.182e-04, MSE(pi1): 3.794e-02, MSE(pi2): 4.475e-04, MSE(pi3): 5.788e-03\n",
      "Epoch 29300, Train loss: 5.570e+06, Test loss: 1.481e+09, MSE(e): 4.536e-04, MSE(pi1): 3.604e-02, MSE(pi2): 2.780e-04, MSE(pi3): 6.736e-03\n",
      "Epoch 29400, Train loss: 7.128e+06, Test loss: 1.431e+09, MSE(e): 6.001e-04, MSE(pi1): 5.072e-02, MSE(pi2): 3.464e-04, MSE(pi3): 6.190e-03\n",
      "Epoch 29500, Train loss: 5.768e+06, Test loss: 1.453e+09, MSE(e): 4.157e-04, MSE(pi1): 1.021e-01, MSE(pi2): 2.638e-04, MSE(pi3): 5.903e-03\n",
      "Epoch 29600, Train loss: 5.693e+06, Test loss: 1.451e+09, MSE(e): 4.059e-04, MSE(pi1): 1.035e-01, MSE(pi2): 2.576e-04, MSE(pi3): 5.995e-03\n",
      "Epoch 29700, Train loss: 4.932e+06, Test loss: 1.449e+09, MSE(e): 3.981e-04, MSE(pi1): 3.134e-02, MSE(pi2): 2.535e-04, MSE(pi3): 6.381e-03\n",
      "Epoch 29800, Train loss: 5.446e+06, Test loss: 1.434e+09, MSE(e): 4.538e-04, MSE(pi1): 3.064e-02, MSE(pi2): 2.803e-04, MSE(pi3): 6.023e-03\n",
      "Epoch 29900, Train loss: 4.980e+06, Test loss: 1.453e+09, MSE(e): 3.913e-04, MSE(pi1): 4.378e-02, MSE(pi2): 2.494e-04, MSE(pi3): 6.300e-03\n",
      "Epoch 30000, Train loss: 4.811e+06, Test loss: 1.449e+09, MSE(e): 3.879e-04, MSE(pi1): 2.724e-02, MSE(pi2): 2.475e-04, MSE(pi3): 6.595e-03\n",
      "Epoch 30100, Train loss: 5.202e+06, Test loss: 1.452e+09, MSE(e): 3.918e-04, MSE(pi1): 6.568e-02, MSE(pi2): 2.486e-04, MSE(pi3): 6.278e-03\n",
      "Epoch 30200, Train loss: 4.720e+06, Test loss: 1.445e+09, MSE(e): 3.853e-04, MSE(pi1): 2.304e-02, MSE(pi2): 2.461e-04, MSE(pi3): 6.360e-03\n",
      "Epoch 30300, Train loss: 6.984e+06, Test loss: 1.484e+09, MSE(e): 6.002e-04, MSE(pi1): 2.795e-02, MSE(pi2): 3.381e-04, MSE(pi3): 7.019e-03\n",
      "Epoch 30400, Train loss: 7.177e+06, Test loss: 1.482e+09, MSE(e): 6.110e-04, MSE(pi1): 3.519e-02, MSE(pi2): 3.465e-04, MSE(pi3): 7.152e-03\n",
      "Epoch 30500, Train loss: 5.195e+06, Test loss: 1.441e+09, MSE(e): 3.868e-04, MSE(pi1): 7.136e-02, MSE(pi2): 2.461e-04, MSE(pi3): 6.137e-03\n",
      "Epoch 30600, Train loss: 5.576e+06, Test loss: 1.434e+09, MSE(e): 3.888e-04, MSE(pi1): 1.049e-01, MSE(pi2): 2.463e-04, MSE(pi3): 6.391e-03\n",
      "Epoch 30700, Train loss: 5.193e+06, Test loss: 1.451e+09, MSE(e): 4.120e-04, MSE(pi1): 1.828e-02, MSE(pi2): 2.531e-04, MSE(pi3): 8.900e-03\n",
      "Epoch 30800, Train loss: 5.187e+06, Test loss: 1.420e+09, MSE(e): 4.249e-04, MSE(pi1): 3.251e-02, MSE(pi2): 2.631e-04, MSE(pi3): 6.131e-03\n",
      "Epoch 30900, Train loss: 9.821e+06, Test loss: 1.388e+09, MSE(e): 8.034e-04, MSE(pi1): 1.202e-01, MSE(pi2): 4.492e-04, MSE(pi3): 5.852e-03\n",
      "Epoch 31000, Train loss: 4.992e+06, Test loss: 1.424e+09, MSE(e): 3.932e-04, MSE(pi1): 4.494e-02, MSE(pi2): 2.504e-04, MSE(pi3): 6.102e-03\n",
      "Epoch 31100, Train loss: 4.557e+06, Test loss: 1.430e+09, MSE(e): 3.704e-04, MSE(pi1): 2.196e-02, MSE(pi2): 2.371e-04, MSE(pi3): 6.330e-03\n",
      "Epoch 31200, Train loss: 4.561e+06, Test loss: 1.425e+09, MSE(e): 3.714e-04, MSE(pi1): 1.948e-02, MSE(pi2): 2.379e-04, MSE(pi3): 6.518e-03\n",
      "Epoch 31300, Train loss: 4.734e+06, Test loss: 1.425e+09, MSE(e): 3.746e-04, MSE(pi1): 3.848e-02, MSE(pi2): 2.394e-04, MSE(pi3): 6.028e-03\n",
      "Epoch 31400, Train loss: 7.949e+06, Test loss: 1.477e+09, MSE(e): 6.667e-04, MSE(pi1): 5.607e-02, MSE(pi2): 3.699e-04, MSE(pi3): 7.214e-03\n",
      "Epoch 31500, Train loss: 4.923e+06, Test loss: 1.423e+09, MSE(e): 3.689e-04, MSE(pi1): 5.608e-02, MSE(pi2): 2.342e-04, MSE(pi3): 6.735e-03\n",
      "Epoch 31600, Train loss: 4.742e+06, Test loss: 1.420e+09, MSE(e): 3.672e-04, MSE(pi1): 4.486e-02, MSE(pi2): 2.343e-04, MSE(pi3): 6.212e-03\n",
      "Epoch 31700, Train loss: 4.690e+06, Test loss: 1.430e+09, MSE(e): 3.717e-04, MSE(pi1): 3.315e-02, MSE(pi2): 2.353e-04, MSE(pi3): 6.415e-03\n",
      "Epoch 31800, Train loss: 4.486e+06, Test loss: 1.426e+09, MSE(e): 3.643e-04, MSE(pi1): 2.201e-02, MSE(pi2): 2.331e-04, MSE(pi3): 6.222e-03\n",
      "Epoch 31900, Train loss: 5.576e+06, Test loss: 1.424e+09, MSE(e): 3.702e-04, MSE(pi1): 1.120e-01, MSE(pi2): 2.323e-04, MSE(pi3): 7.545e-03\n",
      "Epoch 32000, Train loss: 6.224e+06, Test loss: 1.403e+09, MSE(e): 4.171e-04, MSE(pi1): 1.413e-01, MSE(pi2): 2.562e-04, MSE(pi3): 6.402e-03\n",
      "Epoch 32100, Train loss: 5.387e+06, Test loss: 1.400e+09, MSE(e): 3.934e-04, MSE(pi1): 8.230e-02, MSE(pi2): 2.460e-04, MSE(pi3): 6.299e-03\n",
      "Epoch 32200, Train loss: 6.031e+06, Test loss: 1.425e+09, MSE(e): 3.789e-04, MSE(pi1): 1.532e-01, MSE(pi2): 2.360e-04, MSE(pi3): 7.102e-03\n",
      "Epoch 32300, Train loss: 6.030e+06, Test loss: 1.443e+09, MSE(e): 5.039e-04, MSE(pi1): 3.444e-02, MSE(pi2): 2.833e-04, MSE(pi3): 6.465e-03\n",
      "Epoch 32400, Train loss: 7.012e+06, Test loss: 1.452e+09, MSE(e): 6.117e-04, MSE(pi1): 2.019e-02, MSE(pi2): 3.381e-04, MSE(pi3): 6.933e-03\n",
      "Epoch 32500, Train loss: 8.580e+06, Test loss: 1.362e+09, MSE(e): 7.451e-04, MSE(pi1): 5.626e-02, MSE(pi2): 4.102e-04, MSE(pi3): 5.665e-03\n",
      "Epoch 32600, Train loss: 5.012e+06, Test loss: 1.395e+09, MSE(e): 3.734e-04, MSE(pi1): 6.206e-02, MSE(pi2): 2.319e-04, MSE(pi3): 6.574e-03\n",
      "Epoch 32700, Train loss: 5.161e+06, Test loss: 1.406e+09, MSE(e): 3.546e-04, MSE(pi1): 1.006e-01, MSE(pi2): 2.235e-04, MSE(pi3): 6.083e-03\n",
      "Epoch 32800, Train loss: 4.440e+06, Test loss: 1.403e+09, MSE(e): 3.477e-04, MSE(pi1): 3.092e-02, MSE(pi2): 2.225e-04, MSE(pi3): 6.538e-03\n",
      "Epoch 32900, Train loss: 4.489e+06, Test loss: 1.396e+09, MSE(e): 3.521e-04, MSE(pi1): 3.440e-02, MSE(pi2): 2.245e-04, MSE(pi3): 6.236e-03\n",
      "Epoch 33000, Train loss: 8.241e+06, Test loss: 1.356e+09, MSE(e): 7.327e-04, MSE(pi1): 3.213e-02, MSE(pi2): 4.019e-04, MSE(pi3): 5.920e-03\n",
      "Epoch 33100, Train loss: 7.475e+06, Test loss: 1.362e+09, MSE(e): 6.498e-04, MSE(pi1): 3.699e-02, MSE(pi2): 3.542e-04, MSE(pi3): 6.068e-03\n",
      "Epoch 33200, Train loss: 7.025e+06, Test loss: 1.388e+09, MSE(e): 3.844e-04, MSE(pi1): 2.560e-01, MSE(pi2): 2.384e-04, MSE(pi3): 6.207e-03\n",
      "Epoch 33300, Train loss: 6.016e+06, Test loss: 1.376e+09, MSE(e): 5.123e-04, MSE(pi1): 3.032e-02, MSE(pi2): 2.987e-04, MSE(pi3): 5.896e-03\n",
      "Epoch 33400, Train loss: 5.344e+06, Test loss: 1.414e+09, MSE(e): 4.334e-04, MSE(pi1): 3.458e-02, MSE(pi2): 2.563e-04, MSE(pi3): 6.638e-03\n",
      "Epoch 33500, Train loss: 1.101e+07, Test loss: 1.456e+09, MSE(e): 9.674e-04, MSE(pi1): 5.676e-02, MSE(pi2): 4.945e-04, MSE(pi3): 7.716e-03\n",
      "Epoch 33600, Train loss: 1.214e+07, Test loss: 1.438e+09, MSE(e): 1.106e-03, MSE(pi1): 3.356e-02, MSE(pi2): 5.526e-04, MSE(pi3): 7.515e-03\n",
      "Epoch 33700, Train loss: 4.512e+06, Test loss: 1.395e+09, MSE(e): 3.438e-04, MSE(pi1): 3.708e-02, MSE(pi2): 2.175e-04, MSE(pi3): 7.029e-03\n",
      "Epoch 33800, Train loss: 4.409e+06, Test loss: 1.376e+09, MSE(e): 3.489e-04, MSE(pi1): 3.149e-02, MSE(pi2): 2.220e-04, MSE(pi3): 6.044e-03\n",
      "Epoch 33900, Train loss: 4.826e+06, Test loss: 1.408e+09, MSE(e): 3.649e-04, MSE(pi1): 5.475e-02, MSE(pi2): 2.227e-04, MSE(pi3): 6.297e-03\n",
      "Epoch 34000, Train loss: 4.488e+06, Test loss: 1.379e+09, MSE(e): 3.353e-04, MSE(pi1): 4.693e-02, MSE(pi2): 2.136e-04, MSE(pi3): 6.659e-03\n",
      "Epoch 34100, Train loss: 4.476e+06, Test loss: 1.377e+09, MSE(e): 3.365e-04, MSE(pi1): 5.112e-02, MSE(pi2): 2.153e-04, MSE(pi3): 5.997e-03\n",
      "Epoch 34200, Train loss: 5.245e+06, Test loss: 1.364e+09, MSE(e): 4.218e-04, MSE(pi1): 3.609e-02, MSE(pi2): 2.515e-04, MSE(pi3): 6.663e-03\n",
      "Epoch 34300, Train loss: 4.307e+06, Test loss: 1.385e+09, MSE(e): 3.380e-04, MSE(pi1): 2.689e-02, MSE(pi2): 2.143e-04, MSE(pi3): 6.578e-03\n",
      "Epoch 34400, Train loss: 4.249e+06, Test loss: 1.377e+09, MSE(e): 3.271e-04, MSE(pi1): 2.883e-02, MSE(pi2): 2.092e-04, MSE(pi3): 6.900e-03\n",
      "Epoch 34500, Train loss: 4.109e+06, Test loss: 1.380e+09, MSE(e): 3.269e-04, MSE(pi1): 2.111e-02, MSE(pi2): 2.085e-04, MSE(pi3): 6.290e-03\n",
      "Epoch 34600, Train loss: 4.872e+06, Test loss: 1.368e+09, MSE(e): 3.375e-04, MSE(pi1): 8.734e-02, MSE(pi2): 2.134e-04, MSE(pi3): 6.238e-03\n",
      "Epoch 34700, Train loss: 4.071e+06, Test loss: 1.373e+09, MSE(e): 3.222e-04, MSE(pi1): 2.183e-02, MSE(pi2): 2.063e-04, MSE(pi3): 6.307e-03\n",
      "Epoch 34800, Train loss: 4.067e+06, Test loss: 1.368e+09, MSE(e): 3.211e-04, MSE(pi1): 2.343e-02, MSE(pi2): 2.055e-04, MSE(pi3): 6.220e-03\n",
      "Epoch 34900, Train loss: 5.142e+06, Test loss: 1.375e+09, MSE(e): 3.615e-04, MSE(pi1): 8.041e-02, MSE(pi2): 2.241e-04, MSE(pi3): 7.224e-03\n",
      "Epoch 35000, Train loss: 4.407e+06, Test loss: 1.368e+09, MSE(e): 3.211e-04, MSE(pi1): 5.199e-02, MSE(pi2): 2.043e-04, MSE(pi3): 6.768e-03\n",
      "Epoch 35100, Train loss: 4.067e+06, Test loss: 1.361e+09, MSE(e): 3.190e-04, MSE(pi1): 2.371e-02, MSE(pi2): 2.040e-04, MSE(pi3): 6.399e-03\n",
      "Epoch 35200, Train loss: 4.151e+06, Test loss: 1.372e+09, MSE(e): 3.299e-04, MSE(pi1): 2.202e-02, MSE(pi2): 2.072e-04, MSE(pi3): 6.321e-03\n",
      "Epoch 35300, Train loss: 4.093e+06, Test loss: 1.371e+09, MSE(e): 3.251e-04, MSE(pi1): 2.267e-02, MSE(pi2): 2.075e-04, MSE(pi3): 6.154e-03\n",
      "Epoch 35400, Train loss: 5.733e+06, Test loss: 1.333e+09, MSE(e): 4.602e-04, MSE(pi1): 5.305e-02, MSE(pi2): 2.707e-04, MSE(pi3): 6.002e-03\n",
      "Epoch 35500, Train loss: 6.983e+06, Test loss: 1.368e+09, MSE(e): 4.519e-04, MSE(pi1): 1.681e-01, MSE(pi2): 2.650e-04, MSE(pi3): 7.830e-03\n",
      "Epoch 35600, Train loss: 3.971e+06, Test loss: 1.357e+09, MSE(e): 3.106e-04, MSE(pi1): 2.342e-02, MSE(pi2): 1.992e-04, MSE(pi3): 6.313e-03\n",
      "Epoch 35700, Train loss: 4.046e+06, Test loss: 1.357e+09, MSE(e): 3.129e-04, MSE(pi1): 2.941e-02, MSE(pi2): 1.991e-04, MSE(pi3): 6.226e-03\n",
      "Epoch 35800, Train loss: 4.302e+06, Test loss: 1.355e+09, MSE(e): 3.235e-04, MSE(pi1): 4.587e-02, MSE(pi2): 2.015e-04, MSE(pi3): 6.083e-03\n",
      "Epoch 35900, Train loss: 5.024e+06, Test loss: 1.323e+09, MSE(e): 3.540e-04, MSE(pi1): 8.320e-02, MSE(pi2): 2.197e-04, MSE(pi3): 6.524e-03\n",
      "Epoch 36000, Train loss: 8.178e+06, Test loss: 1.302e+09, MSE(e): 7.224e-04, MSE(pi1): 3.595e-02, MSE(pi2): 3.805e-04, MSE(pi3): 5.947e-03\n",
      "Epoch 36100, Train loss: 5.330e+06, Test loss: 1.349e+09, MSE(e): 3.199e-04, MSE(pi1): 1.493e-01, MSE(pi2): 2.009e-04, MSE(pi3): 6.383e-03\n",
      "Epoch 36200, Train loss: 3.890e+06, Test loss: 1.349e+09, MSE(e): 3.058e-04, MSE(pi1): 1.882e-02, MSE(pi2): 1.957e-04, MSE(pi3): 6.436e-03\n",
      "Epoch 36300, Train loss: 2.023e+07, Test loss: 1.272e+09, MSE(e): 1.892e-03, MSE(pi1): 7.253e-02, MSE(pi2): 9.197e-04, MSE(pi3): 5.820e-03\n",
      "Epoch 36400, Train loss: 3.827e+06, Test loss: 1.341e+09, MSE(e): 3.013e-04, MSE(pi1): 1.899e-02, MSE(pi2): 1.937e-04, MSE(pi3): 6.235e-03\n",
      "Epoch 36500, Train loss: 4.269e+06, Test loss: 1.344e+09, MSE(e): 3.041e-04, MSE(pi1): 5.753e-02, MSE(pi2): 1.937e-04, MSE(pi3): 6.534e-03\n",
      "Epoch 36600, Train loss: 4.065e+06, Test loss: 1.357e+09, MSE(e): 3.050e-04, MSE(pi1): 3.842e-02, MSE(pi2): 1.935e-04, MSE(pi3): 6.307e-03\n",
      "Epoch 36700, Train loss: 4.073e+06, Test loss: 1.335e+09, MSE(e): 3.209e-04, MSE(pi1): 2.457e-02, MSE(pi2): 2.028e-04, MSE(pi3): 6.179e-03\n",
      "Epoch 36800, Train loss: 3.830e+06, Test loss: 1.334e+09, MSE(e): 2.978e-04, MSE(pi1): 2.368e-02, MSE(pi2): 1.914e-04, MSE(pi3): 6.156e-03\n",
      "Epoch 36900, Train loss: 4.178e+06, Test loss: 1.336e+09, MSE(e): 2.985e-04, MSE(pi1): 5.148e-02, MSE(pi2): 1.900e-04, MSE(pi3): 6.787e-03\n",
      "Epoch 37000, Train loss: 4.721e+06, Test loss: 1.317e+09, MSE(e): 3.493e-04, MSE(pi1): 5.895e-02, MSE(pi2): 2.118e-04, MSE(pi3): 6.379e-03\n",
      "Epoch 37100, Train loss: 3.903e+06, Test loss: 1.336e+09, MSE(e): 2.957e-04, MSE(pi1): 2.887e-02, MSE(pi2): 1.891e-04, MSE(pi3): 6.568e-03\n",
      "Epoch 37200, Train loss: 1.385e+07, Test loss: 1.274e+09, MSE(e): 1.255e-03, MSE(pi1): 7.528e-02, MSE(pi2): 6.357e-04, MSE(pi3): 5.441e-03\n",
      "Epoch 37300, Train loss: 6.121e+06, Test loss: 1.367e+09, MSE(e): 4.953e-04, MSE(pi1): 4.636e-02, MSE(pi2): 2.773e-04, MSE(pi3): 7.048e-03\n",
      "Epoch 37400, Train loss: 6.776e+06, Test loss: 1.356e+09, MSE(e): 5.652e-04, MSE(pi1): 4.017e-02, MSE(pi2): 3.065e-04, MSE(pi3): 7.222e-03\n",
      "Epoch 37500, Train loss: 3.754e+06, Test loss: 1.323e+09, MSE(e): 2.894e-04, MSE(pi1): 2.470e-02, MSE(pi2): 1.860e-04, MSE(pi3): 6.133e-03\n",
      "Epoch 37600, Train loss: 3.677e+06, Test loss: 1.323e+09, MSE(e): 2.871e-04, MSE(pi1): 1.755e-02, MSE(pi2): 1.846e-04, MSE(pi3): 6.302e-03\n",
      "Epoch 37700, Train loss: 6.305e+06, Test loss: 1.300e+09, MSE(e): 3.865e-04, MSE(pi1): 1.838e-01, MSE(pi2): 2.383e-04, MSE(pi3): 6.015e-03\n",
      "Epoch 37800, Train loss: 5.698e+06, Test loss: 1.282e+09, MSE(e): 4.850e-04, MSE(pi1): 2.580e-02, MSE(pi2): 2.750e-04, MSE(pi3): 5.906e-03\n",
      "Epoch 37900, Train loss: 3.968e+06, Test loss: 1.334e+09, MSE(e): 3.148e-04, MSE(pi1): 1.751e-02, MSE(pi2): 1.953e-04, MSE(pi3): 6.446e-03\n",
      "Epoch 38000, Train loss: 4.048e+06, Test loss: 1.321e+09, MSE(e): 2.878e-04, MSE(pi1): 5.311e-02, MSE(pi2): 1.830e-04, MSE(pi3): 6.386e-03\n",
      "Epoch 38100, Train loss: 4.625e+06, Test loss: 1.304e+09, MSE(e): 3.232e-04, MSE(pi1): 7.957e-02, MSE(pi2): 2.030e-04, MSE(pi3): 5.973e-03\n",
      "Epoch 38200, Train loss: 4.448e+06, Test loss: 1.314e+09, MSE(e): 2.895e-04, MSE(pi1): 8.900e-02, MSE(pi2): 1.835e-04, MSE(pi3): 6.634e-03\n",
      "Epoch 38300, Train loss: 4.884e+06, Test loss: 1.315e+09, MSE(e): 2.928e-04, MSE(pi1): 1.319e-01, MSE(pi2): 1.825e-04, MSE(pi3): 6.376e-03\n",
      "Epoch 38400, Train loss: 5.330e+06, Test loss: 1.299e+09, MSE(e): 3.880e-04, MSE(pi1): 8.724e-02, MSE(pi2): 2.352e-04, MSE(pi3): 5.775e-03\n",
      "Epoch 38500, Train loss: 4.717e+06, Test loss: 1.317e+09, MSE(e): 2.945e-04, MSE(pi1): 1.134e-01, MSE(pi2): 1.819e-04, MSE(pi3): 6.378e-03\n",
      "Epoch 38600, Train loss: 4.262e+06, Test loss: 1.310e+09, MSE(e): 2.834e-04, MSE(pi1): 7.834e-02, MSE(pi2): 1.802e-04, MSE(pi3): 6.443e-03\n",
      "Epoch 38700, Train loss: 3.789e+06, Test loss: 1.301e+09, MSE(e): 2.901e-04, MSE(pi1): 2.818e-02, MSE(pi2): 1.852e-04, MSE(pi3): 6.063e-03\n",
      "Epoch 38800, Train loss: 5.891e+06, Test loss: 1.340e+09, MSE(e): 4.671e-04, MSE(pi1): 5.917e-02, MSE(pi2): 2.505e-04, MSE(pi3): 6.289e-03\n",
      "Epoch 38900, Train loss: 4.623e+06, Test loss: 1.311e+09, MSE(e): 2.851e-04, MSE(pi1): 1.058e-01, MSE(pi2): 1.792e-04, MSE(pi3): 7.136e-03\n",
      "Epoch 39000, Train loss: 3.581e+06, Test loss: 1.299e+09, MSE(e): 2.727e-04, MSE(pi1): 2.367e-02, MSE(pi2): 1.754e-04, MSE(pi3): 6.166e-03\n",
      "Epoch 39100, Train loss: 4.173e+06, Test loss: 1.312e+09, MSE(e): 3.303e-04, MSE(pi1): 2.004e-02, MSE(pi2): 1.996e-04, MSE(pi3): 6.693e-03\n",
      "Epoch 39200, Train loss: 3.499e+06, Test loss: 1.299e+09, MSE(e): 2.699e-04, MSE(pi1): 1.719e-02, MSE(pi2): 1.737e-04, MSE(pi3): 6.275e-03\n",
      "Epoch 39300, Train loss: 3.929e+06, Test loss: 1.296e+09, MSE(e): 2.753e-04, MSE(pi1): 5.129e-02, MSE(pi2): 1.744e-04, MSE(pi3): 6.634e-03\n",
      "Epoch 39400, Train loss: 4.103e+06, Test loss: 1.290e+09, MSE(e): 2.791e-04, MSE(pi1): 7.207e-02, MSE(pi2): 1.782e-04, MSE(pi3): 5.912e-03\n",
      "Epoch 39500, Train loss: 3.731e+06, Test loss: 1.295e+09, MSE(e): 2.695e-04, MSE(pi1): 4.323e-02, MSE(pi2): 1.722e-04, MSE(pi3): 6.035e-03\n",
      "Epoch 39600, Train loss: 4.846e+06, Test loss: 1.291e+09, MSE(e): 2.787e-04, MSE(pi1): 1.447e-01, MSE(pi2): 1.752e-04, MSE(pi3): 6.117e-03\n",
      "Epoch 39700, Train loss: 4.660e+06, Test loss: 1.275e+09, MSE(e): 3.525e-04, MSE(pi1): 5.377e-02, MSE(pi2): 2.126e-04, MSE(pi3): 5.972e-03\n",
      "Epoch 39800, Train loss: 3.676e+06, Test loss: 1.297e+09, MSE(e): 2.781e-04, MSE(pi1): 2.479e-02, MSE(pi2): 1.752e-04, MSE(pi3): 6.468e-03\n",
      "Epoch 39900, Train loss: 1.284e+07, Test loss: 1.322e+09, MSE(e): 1.084e-03, MSE(pi1): 1.129e-01, MSE(pi2): 5.384e-04, MSE(pi3): 8.687e-03\n",
      "Epoch 40000, Train loss: 3.813e+06, Test loss: 1.288e+09, MSE(e): 2.653e-04, MSE(pi1): 5.051e-02, MSE(pi2): 1.692e-04, MSE(pi3): 6.552e-03\n",
      "Epoch 40100, Train loss: 3.923e+06, Test loss: 1.291e+09, MSE(e): 2.705e-04, MSE(pi1): 6.096e-02, MSE(pi2): 1.694e-04, MSE(pi3): 6.083e-03\n",
      "Epoch 40200, Train loss: 4.742e+06, Test loss: 1.302e+09, MSE(e): 3.179e-04, MSE(pi1): 8.830e-02, MSE(pi2): 1.885e-04, MSE(pi3): 6.796e-03\n",
      "Epoch 40300, Train loss: 6.863e+06, Test loss: 1.319e+09, MSE(e): 6.004e-04, MSE(pi1): 1.743e-02, MSE(pi2): 3.125e-04, MSE(pi3): 6.847e-03\n",
      "Epoch 40400, Train loss: 3.920e+06, Test loss: 1.288e+09, MSE(e): 2.767e-04, MSE(pi1): 5.028e-02, MSE(pi2): 1.726e-04, MSE(pi3): 6.500e-03\n",
      "Epoch 40500, Train loss: 3.509e+06, Test loss: 1.286e+09, MSE(e): 2.661e-04, MSE(pi1): 2.029e-02, MSE(pi2): 1.691e-04, MSE(pi3): 6.454e-03\n",
      "Epoch 40600, Train loss: 3.707e+06, Test loss: 1.279e+09, MSE(e): 2.773e-04, MSE(pi1): 2.782e-02, MSE(pi2): 1.735e-04, MSE(pi3): 6.561e-03\n",
      "Epoch 40700, Train loss: 3.495e+06, Test loss: 1.276e+09, MSE(e): 2.562e-04, MSE(pi1): 3.226e-02, MSE(pi2): 1.645e-04, MSE(pi3): 6.102e-03\n",
      "Epoch 40800, Train loss: 3.648e+06, Test loss: 1.272e+09, MSE(e): 2.599e-04, MSE(pi1): 4.568e-02, MSE(pi2): 1.668e-04, MSE(pi3): 5.918e-03\n",
      "Epoch 40900, Train loss: 3.768e+06, Test loss: 1.300e+09, MSE(e): 2.852e-04, MSE(pi1): 2.413e-02, MSE(pi2): 1.764e-04, MSE(pi3): 6.747e-03\n",
      "Epoch 41000, Train loss: 3.708e+06, Test loss: 1.270e+09, MSE(e): 2.561e-04, MSE(pi1): 5.007e-02, MSE(pi2): 1.637e-04, MSE(pi3): 6.470e-03\n",
      "Epoch 41100, Train loss: 3.326e+06, Test loss: 1.267e+09, MSE(e): 2.530e-04, MSE(pi1): 1.781e-02, MSE(pi2): 1.628e-04, MSE(pi3): 6.179e-03\n",
      "Epoch 41200, Train loss: 4.045e+06, Test loss: 1.273e+09, MSE(e): 2.574e-04, MSE(pi1): 8.094e-02, MSE(pi2): 1.632e-04, MSE(pi3): 6.610e-03\n",
      "Epoch 41300, Train loss: 3.743e+06, Test loss: 1.269e+09, MSE(e): 2.692e-04, MSE(pi1): 3.862e-02, MSE(pi2): 1.696e-04, MSE(pi3): 6.651e-03\n",
      "Epoch 41400, Train loss: 4.567e+06, Test loss: 1.291e+09, MSE(e): 3.366e-04, MSE(pi1): 5.201e-02, MSE(pi2): 1.968e-04, MSE(pi3): 6.809e-03\n",
      "Epoch 41500, Train loss: 5.197e+06, Test loss: 1.273e+09, MSE(e): 2.668e-04, MSE(pi1): 1.840e-01, MSE(pi2): 1.655e-04, MSE(pi3): 6.889e-03\n",
      "Epoch 41600, Train loss: 3.431e+06, Test loss: 1.264e+09, MSE(e): 2.478e-04, MSE(pi1): 3.118e-02, MSE(pi2): 1.589e-04, MSE(pi3): 6.415e-03\n",
      "Epoch 41700, Train loss: 3.345e+06, Test loss: 1.253e+09, MSE(e): 2.535e-04, MSE(pi1): 1.993e-02, MSE(pi2): 1.625e-04, MSE(pi3): 6.104e-03\n",
      "Epoch 41800, Train loss: 3.995e+06, Test loss: 1.231e+09, MSE(e): 3.035e-04, MSE(pi1): 3.580e-02, MSE(pi2): 1.855e-04, MSE(pi3): 6.015e-03\n",
      "Epoch 41900, Train loss: 8.897e+06, Test loss: 1.215e+09, MSE(e): 7.453e-04, MSE(pi1): 8.945e-02, MSE(pi2): 3.975e-04, MSE(pi3): 5.498e-03\n",
      "Epoch 42000, Train loss: 3.342e+06, Test loss: 1.264e+09, MSE(e): 2.456e-04, MSE(pi1): 2.714e-02, MSE(pi2): 1.568e-04, MSE(pi3): 6.143e-03\n",
      "Epoch 42100, Train loss: 4.040e+06, Test loss: 1.234e+09, MSE(e): 3.162e-04, MSE(pi1): 2.841e-02, MSE(pi2): 1.913e-04, MSE(pi3): 5.939e-03\n",
      "Epoch 42200, Train loss: 6.171e+06, Test loss: 1.289e+09, MSE(e): 4.111e-04, MSE(pi1): 1.312e-01, MSE(pi2): 2.324e-04, MSE(pi3): 7.485e-03\n",
      "Epoch 42300, Train loss: 3.882e+06, Test loss: 1.261e+09, MSE(e): 2.543e-04, MSE(pi1): 6.434e-02, MSE(pi2): 1.602e-04, MSE(pi3): 6.961e-03\n",
      "Epoch 42400, Train loss: 5.396e+06, Test loss: 1.248e+09, MSE(e): 2.646e-04, MSE(pi1): 2.032e-01, MSE(pi2): 1.648e-04, MSE(pi3): 7.188e-03\n",
      "Epoch 42500, Train loss: 3.281e+06, Test loss: 1.242e+09, MSE(e): 2.488e-04, MSE(pi1): 1.752e-02, MSE(pi2): 1.589e-04, MSE(pi3): 6.176e-03\n",
      "Epoch 42600, Train loss: 9.690e+06, Test loss: 1.194e+09, MSE(e): 8.420e-04, MSE(pi1): 7.128e-02, MSE(pi2): 4.375e-04, MSE(pi3): 5.571e-03\n",
      "Epoch 42700, Train loss: 3.254e+06, Test loss: 1.249e+09, MSE(e): 2.378e-04, MSE(pi1): 2.564e-02, MSE(pi2): 1.523e-04, MSE(pi3): 6.198e-03\n",
      "Epoch 42800, Train loss: 3.717e+06, Test loss: 1.235e+09, MSE(e): 2.675e-04, MSE(pi1): 3.961e-02, MSE(pi2): 1.642e-04, MSE(pi3): 6.458e-03\n",
      "Epoch 42900, Train loss: 3.661e+06, Test loss: 1.249e+09, MSE(e): 2.479e-04, MSE(pi1): 5.008e-02, MSE(pi2): 1.566e-04, MSE(pi3): 6.810e-03\n",
      "Epoch 43000, Train loss: 4.754e+06, Test loss: 1.223e+09, MSE(e): 3.616e-04, MSE(pi1): 5.279e-02, MSE(pi2): 2.075e-04, MSE(pi3): 6.100e-03\n",
      "Epoch 43100, Train loss: 3.180e+06, Test loss: 1.248e+09, MSE(e): 2.385e-04, MSE(pi1): 1.668e-02, MSE(pi2): 1.518e-04, MSE(pi3): 6.284e-03\n",
      "Epoch 43200, Train loss: 3.114e+06, Test loss: 1.240e+09, MSE(e): 2.317e-04, MSE(pi1): 1.679e-02, MSE(pi2): 1.492e-04, MSE(pi3): 6.286e-03\n",
      "Epoch 43300, Train loss: 3.467e+06, Test loss: 1.247e+09, MSE(e): 2.459e-04, MSE(pi1): 3.346e-02, MSE(pi2): 1.549e-04, MSE(pi3): 6.731e-03\n",
      "Epoch 43400, Train loss: 3.220e+06, Test loss: 1.232e+09, MSE(e): 2.377e-04, MSE(pi1): 2.278e-02, MSE(pi2): 1.522e-04, MSE(pi3): 6.148e-03\n",
      "Epoch 43500, Train loss: 3.877e+06, Test loss: 1.228e+09, MSE(e): 2.502e-04, MSE(pi1): 7.631e-02, MSE(pi2): 1.582e-04, MSE(pi3): 6.122e-03\n",
      "Epoch 43600, Train loss: 6.421e+06, Test loss: 1.270e+09, MSE(e): 4.982e-04, MSE(pi1): 7.977e-02, MSE(pi2): 2.539e-04, MSE(pi3): 6.409e-03\n",
      "Epoch 43700, Train loss: 3.679e+06, Test loss: 1.229e+09, MSE(e): 2.415e-04, MSE(pi1): 6.109e-02, MSE(pi2): 1.504e-04, MSE(pi3): 6.535e-03\n",
      "Epoch 43800, Train loss: 3.399e+06, Test loss: 1.230e+09, MSE(e): 2.335e-04, MSE(pi1): 4.184e-02, MSE(pi2): 1.481e-04, MSE(pi3): 6.459e-03\n",
      "Epoch 43900, Train loss: 3.481e+06, Test loss: 1.228e+09, MSE(e): 2.351e-04, MSE(pi1): 5.400e-02, MSE(pi2): 1.504e-04, MSE(pi3): 5.896e-03\n",
      "Epoch 44000, Train loss: 3.491e+06, Test loss: 1.239e+09, MSE(e): 2.432e-04, MSE(pi1): 4.303e-02, MSE(pi2): 1.506e-04, MSE(pi3): 6.288e-03\n",
      "Epoch 44100, Train loss: 3.538e+06, Test loss: 1.225e+09, MSE(e): 2.291e-04, MSE(pi1): 5.827e-02, MSE(pi2): 1.449e-04, MSE(pi3): 6.642e-03\n",
      "Epoch 44200, Train loss: 3.658e+06, Test loss: 1.228e+09, MSE(e): 2.289e-04, MSE(pi1): 7.411e-02, MSE(pi2): 1.450e-04, MSE(pi3): 6.283e-03\n",
      "Epoch 44300, Train loss: 3.218e+06, Test loss: 1.222e+09, MSE(e): 2.361e-04, MSE(pi1): 2.528e-02, MSE(pi2): 1.510e-04, MSE(pi3): 6.043e-03\n",
      "Epoch 44400, Train loss: 3.328e+06, Test loss: 1.213e+09, MSE(e): 2.414e-04, MSE(pi1): 2.851e-02, MSE(pi2): 1.507e-04, MSE(pi3): 6.294e-03\n",
      "Epoch 44500, Train loss: 2.993e+06, Test loss: 1.221e+09, MSE(e): 2.206e-04, MSE(pi1): 1.673e-02, MSE(pi2): 1.422e-04, MSE(pi3): 6.197e-03\n",
      "Epoch 44600, Train loss: 6.394e+06, Test loss: 1.254e+09, MSE(e): 5.129e-04, MSE(pi1): 6.297e-02, MSE(pi2): 2.582e-04, MSE(pi3): 6.347e-03\n",
      "Epoch 44700, Train loss: 4.511e+06, Test loss: 1.224e+09, MSE(e): 2.322e-04, MSE(pi1): 1.476e-01, MSE(pi2): 1.440e-04, MSE(pi3): 7.127e-03\n",
      "Epoch 44800, Train loss: 3.547e+06, Test loss: 1.219e+09, MSE(e): 2.243e-04, MSE(pi1): 6.402e-02, MSE(pi2): 1.422e-04, MSE(pi3): 6.641e-03\n",
      "Epoch 44900, Train loss: 3.870e+06, Test loss: 1.205e+09, MSE(e): 3.003e-04, MSE(pi1): 2.551e-02, MSE(pi2): 1.764e-04, MSE(pi3): 6.125e-03\n",
      "Epoch 45000, Train loss: 3.616e+06, Test loss: 1.204e+09, MSE(e): 2.482e-04, MSE(pi1): 5.107e-02, MSE(pi2): 1.523e-04, MSE(pi3): 6.236e-03\n",
      "Epoch 45100, Train loss: 3.574e+06, Test loss: 1.216e+09, MSE(e): 2.215e-04, MSE(pi1): 6.855e-02, MSE(pi2): 1.408e-04, MSE(pi3): 6.732e-03\n",
      "Epoch 45200, Train loss: 3.733e+06, Test loss: 1.215e+09, MSE(e): 2.213e-04, MSE(pi1): 8.826e-02, MSE(pi2): 1.401e-04, MSE(pi3): 6.368e-03\n",
      "Epoch 45300, Train loss: 4.593e+06, Test loss: 1.187e+09, MSE(e): 3.294e-04, MSE(pi1): 7.181e-02, MSE(pi2): 1.975e-04, MSE(pi3): 5.808e-03\n",
      "Epoch 45400, Train loss: 3.595e+06, Test loss: 1.208e+09, MSE(e): 2.245e-04, MSE(pi1): 6.457e-02, MSE(pi2): 1.398e-04, MSE(pi3): 7.047e-03\n",
      "Epoch 45500, Train loss: 4.100e+06, Test loss: 1.202e+09, MSE(e): 2.368e-04, MSE(pi1): 1.104e-01, MSE(pi2): 1.484e-04, MSE(pi3): 6.291e-03\n",
      "Epoch 45600, Train loss: 3.055e+06, Test loss: 1.207e+09, MSE(e): 2.125e-04, MSE(pi1): 3.236e-02, MSE(pi2): 1.365e-04, MSE(pi3): 6.063e-03\n",
      "Epoch 45700, Train loss: 3.667e+06, Test loss: 1.213e+09, MSE(e): 2.233e-04, MSE(pi1): 7.956e-02, MSE(pi2): 1.390e-04, MSE(pi3): 6.392e-03\n",
      "Epoch 45800, Train loss: 3.781e+06, Test loss: 1.203e+09, MSE(e): 2.199e-04, MSE(pi1): 9.464e-02, MSE(pi2): 1.393e-04, MSE(pi3): 6.358e-03\n",
      "Epoch 45900, Train loss: 2.905e+06, Test loss: 1.205e+09, MSE(e): 2.094e-04, MSE(pi1): 1.765e-02, MSE(pi2): 1.347e-04, MSE(pi3): 6.347e-03\n",
      "Epoch 46000, Train loss: 3.267e+06, Test loss: 1.202e+09, MSE(e): 2.116e-04, MSE(pi1): 5.266e-02, MSE(pi2): 1.351e-04, MSE(pi3): 6.250e-03\n",
      "Epoch 46100, Train loss: 1.713e+07, Test loss: 1.155e+09, MSE(e): 1.394e-03, MSE(pi1): 2.653e-01, MSE(pi2): 7.014e-04, MSE(pi3): 5.304e-03\n",
      "Epoch 46200, Train loss: 4.959e+06, Test loss: 1.203e+09, MSE(e): 2.252e-04, MSE(pi1): 2.016e-01, MSE(pi2): 1.380e-04, MSE(pi3): 6.903e-03\n",
      "Epoch 46300, Train loss: 3.250e+06, Test loss: 1.185e+09, MSE(e): 2.105e-04, MSE(pi1): 4.978e-02, MSE(pi2): 1.355e-04, MSE(pi3): 6.467e-03\n",
      "Epoch 46400, Train loss: 1.950e+07, Test loss: 1.133e+09, MSE(e): 1.832e-03, MSE(pi1): 6.471e-02, MSE(pi2): 8.700e-04, MSE(pi3): 5.334e-03\n",
      "Epoch 46500, Train loss: 3.044e+06, Test loss: 1.188e+09, MSE(e): 2.147e-04, MSE(pi1): 2.992e-02, MSE(pi2): 1.375e-04, MSE(pi3): 5.975e-03\n",
      "Epoch 46600, Train loss: 3.448e+06, Test loss: 1.206e+09, MSE(e): 2.271e-04, MSE(pi1): 4.908e-02, MSE(pi2): 1.400e-04, MSE(pi3): 6.862e-03\n",
      "Epoch 46700, Train loss: 2.818e+06, Test loss: 1.192e+09, MSE(e): 2.030e-04, MSE(pi1): 1.686e-02, MSE(pi2): 1.311e-04, MSE(pi3): 6.190e-03\n",
      "Epoch 46800, Train loss: 2.800e+06, Test loss: 1.191e+09, MSE(e): 2.022e-04, MSE(pi1): 1.585e-02, MSE(pi2): 1.304e-04, MSE(pi3): 6.200e-03\n",
      "Epoch 46900, Train loss: 2.810e+06, Test loss: 1.194e+09, MSE(e): 2.026e-04, MSE(pi1): 1.581e-02, MSE(pi2): 1.300e-04, MSE(pi3): 6.258e-03\n",
      "Epoch 47000, Train loss: 2.785e+06, Test loss: 1.191e+09, MSE(e): 2.002e-04, MSE(pi1): 1.550e-02, MSE(pi2): 1.289e-04, MSE(pi3): 6.280e-03\n",
      "Epoch 47100, Train loss: 3.854e+06, Test loss: 1.215e+09, MSE(e): 2.256e-04, MSE(pi1): 9.161e-02, MSE(pi2): 1.391e-04, MSE(pi3): 6.818e-03\n",
      "Epoch 47200, Train loss: 2.865e+06, Test loss: 1.195e+09, MSE(e): 2.086e-04, MSE(pi1): 1.489e-02, MSE(pi2): 1.318e-04, MSE(pi3): 6.308e-03\n",
      "Epoch 47300, Train loss: 2.996e+06, Test loss: 1.187e+09, MSE(e): 2.001e-04, MSE(pi1): 3.444e-02, MSE(pi2): 1.280e-04, MSE(pi3): 6.507e-03\n",
      "Epoch 47400, Train loss: 3.445e+06, Test loss: 1.205e+09, MSE(e): 2.483e-04, MSE(pi1): 3.317e-02, MSE(pi2): 1.466e-04, MSE(pi3): 6.308e-03\n",
      "Epoch 47500, Train loss: 3.796e+06, Test loss: 1.162e+09, MSE(e): 2.902e-04, MSE(pi1): 2.905e-02, MSE(pi2): 1.698e-04, MSE(pi3): 6.037e-03\n",
      "Epoch 47600, Train loss: 1.278e+07, Test loss: 1.258e+09, MSE(e): 1.176e-03, MSE(pi1): 2.961e-02, MSE(pi2): 5.494e-04, MSE(pi3): 7.297e-03\n",
      "Epoch 47700, Train loss: 3.214e+06, Test loss: 1.173e+09, MSE(e): 2.255e-04, MSE(pi1): 2.894e-02, MSE(pi2): 1.385e-04, MSE(pi3): 6.701e-03\n",
      "Epoch 47800, Train loss: 3.052e+06, Test loss: 1.185e+09, MSE(e): 1.990e-04, MSE(pi1): 4.414e-02, MSE(pi2): 1.266e-04, MSE(pi3): 6.203e-03\n",
      "Epoch 47900, Train loss: 2.718e+06, Test loss: 1.181e+09, MSE(e): 1.941e-04, MSE(pi1): 1.538e-02, MSE(pi2): 1.248e-04, MSE(pi3): 6.238e-03\n",
      "Epoch 48000, Train loss: 9.217e+06, Test loss: 1.244e+09, MSE(e): 6.873e-04, MSE(pi1): 1.491e-01, MSE(pi2): 3.530e-04, MSE(pi3): 8.530e-03\n",
      "Epoch 48100, Train loss: 2.717e+06, Test loss: 1.176e+09, MSE(e): 1.918e-04, MSE(pi1): 1.729e-02, MSE(pi2): 1.236e-04, MSE(pi3): 6.252e-03\n",
      "Epoch 48200, Train loss: 5.162e+06, Test loss: 1.182e+09, MSE(e): 4.312e-04, MSE(pi1): 1.698e-02, MSE(pi2): 2.236e-04, MSE(pi3): 6.796e-03\n",
      "Epoch 48300, Train loss: 3.033e+06, Test loss: 1.174e+09, MSE(e): 1.933e-04, MSE(pi1): 4.684e-02, MSE(pi2): 1.234e-04, MSE(pi3): 6.323e-03\n",
      "Epoch 48400, Train loss: 9.300e+06, Test loss: 1.245e+09, MSE(e): 7.576e-04, MSE(pi1): 9.192e-02, MSE(pi2): 3.812e-04, MSE(pi3): 8.041e-03\n",
      "Epoch 48500, Train loss: 4.441e+06, Test loss: 1.172e+09, MSE(e): 2.051e-04, MSE(pi1): 1.764e-01, MSE(pi2): 1.254e-04, MSE(pi3): 6.261e-03\n",
      "Epoch 48600, Train loss: 3.203e+06, Test loss: 1.160e+09, MSE(e): 2.409e-04, MSE(pi1): 1.903e-02, MSE(pi2): 1.453e-04, MSE(pi3): 6.037e-03\n",
      "Epoch 48700, Train loss: 3.354e+06, Test loss: 1.161e+09, MSE(e): 2.136e-04, MSE(pi1): 5.495e-02, MSE(pi2): 1.290e-04, MSE(pi3): 6.689e-03\n",
      "Epoch 48800, Train loss: 2.706e+06, Test loss: 1.172e+09, MSE(e): 1.918e-04, MSE(pi1): 1.622e-02, MSE(pi2): 1.221e-04, MSE(pi3): 6.257e-03\n",
      "Epoch 48900, Train loss: 3.277e+06, Test loss: 1.180e+09, MSE(e): 2.081e-04, MSE(pi1): 5.213e-02, MSE(pi2): 1.298e-04, MSE(pi3): 6.749e-03\n",
      "Epoch 49000, Train loss: 3.488e+06, Test loss: 1.153e+09, MSE(e): 2.222e-04, MSE(pi1): 6.068e-02, MSE(pi2): 1.334e-04, MSE(pi3): 6.593e-03\n",
      "Epoch 49100, Train loss: 4.625e+06, Test loss: 1.172e+09, MSE(e): 2.086e-04, MSE(pi1): 1.891e-01, MSE(pi2): 1.240e-04, MSE(pi3): 6.479e-03\n",
      "Epoch 49200, Train loss: 2.711e+06, Test loss: 1.168e+09, MSE(e): 1.889e-04, MSE(pi1): 1.799e-02, MSE(pi2): 1.205e-04, MSE(pi3): 6.413e-03\n",
      "Epoch 49300, Train loss: 2.711e+06, Test loss: 1.171e+09, MSE(e): 1.892e-04, MSE(pi1): 1.628e-02, MSE(pi2): 1.201e-04, MSE(pi3): 6.558e-03\n",
      "Epoch 49400, Train loss: 5.886e+06, Test loss: 1.125e+09, MSE(e): 4.830e-04, MSE(pi1): 4.524e-02, MSE(pi2): 2.493e-04, MSE(pi3): 6.040e-03\n",
      "Epoch 49500, Train loss: 6.700e+06, Test loss: 1.168e+09, MSE(e): 2.210e-04, MSE(pi1): 3.740e-01, MSE(pi2): 1.274e-04, MSE(pi3): 7.500e-03\n",
      "Epoch 49600, Train loss: 2.607e+06, Test loss: 1.162e+09, MSE(e): 1.826e-04, MSE(pi1): 1.495e-02, MSE(pi2): 1.172e-04, MSE(pi3): 6.316e-03\n",
      "Epoch 49700, Train loss: 3.642e+06, Test loss: 1.154e+09, MSE(e): 2.565e-04, MSE(pi1): 3.181e-02, MSE(pi2): 1.491e-04, MSE(pi3): 7.589e-03\n",
      "Epoch 49800, Train loss: 2.627e+06, Test loss: 1.155e+09, MSE(e): 1.799e-04, MSE(pi1): 1.937e-02, MSE(pi2): 1.157e-04, MSE(pi3): 6.337e-03\n",
      "Epoch 49900, Train loss: 2.869e+06, Test loss: 1.141e+09, MSE(e): 2.087e-04, MSE(pi1): 1.786e-02, MSE(pi2): 1.298e-04, MSE(pi3): 6.035e-03\n",
      "\n",
      "Training process finished after 50000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explanatory_layers = [100]\n",
    "# n_filters_explanatory = 20\n",
    "\n",
    "model = TransferLearningAutoencoder(input_shape, predictive_layers, pgnniv_pretrained_encoder, predictive_output, explanatory_input,\n",
    "                                   explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 50000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "new_lr = 1e-3\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE, new_lr=new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa5743b88f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(model(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            model(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parametros de entrenamiento\n",
    "# start_epoch = 9000\n",
    "# n_epochs = 100000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 100\n",
    "\n",
    "# second_lr = 1e-4\n",
    "\n",
    "# train_loop(model, optimizer, X_train_NN, y_train_NN, f_train_NN, X_test_NN, y_test_NN, f_test_NN,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
