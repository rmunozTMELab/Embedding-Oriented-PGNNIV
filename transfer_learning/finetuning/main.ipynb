{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import GPUtil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from utils.checkpoints import load_results\n",
    "\n",
    "from architectures.pgnniv_baseline import PGNNIVBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_100\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_100/finetuning\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear/sigmoid_nonlinear.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_100')\n",
    "\n",
    "PRETRAINED_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/non_linear_1000_0/baseline_model_10')\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_100/finetuning')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_TRANSFERLEARNING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear/sigmoid_nonlinear.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 80\n",
      "Validation dataset length: 20\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X_train, y_train, K_train, f_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other parameters\n",
    "n_filters_explanatory = 5\n",
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_autoencoder = PretrainedAutoencoder(autoencoder_input_shape, latent_space_dim, autoencoder_output_shape).to(DEVICE)\n",
    "pretrained_pgnniv = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(pretrained_pgnniv.parameters(), lr=1e-4)\n",
    "pretrained_pgnniv, optimizer, lists = load_results(pretrained_pgnniv, optimizer, PRETRAINED_RESULTS_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7eff258071a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgnniv_pretrained_encoder = pretrained_pgnniv.encoder\n",
    "pgnniv_pretrained_decoder = pretrained_pgnniv.decoder\n",
    "pgnniv_pretrained_exp = pretrained_pgnniv.explanatory\n",
    "\n",
    "for param in pgnniv_pretrained_encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pgnniv_pretrained_decoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pgnniv_pretrained_exp.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def reinitialize_model(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            # Reinitialize Conv2d weights and biases\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            # Reinitialize Linear weights and biases\n",
    "            nn.init.kaiming_uniform_(module.weight, a=math.sqrt(5))\n",
    "            if module.bias is not None:\n",
    "                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(module.weight)\n",
    "                bound = 1 / math.sqrt(fan_in)\n",
    "                nn.init.uniform_(module.bias, -bound, bound)\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            # Reinitialize BatchNorm layers\n",
    "            nn.init.constant_(module.weight, 1)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "\n",
    "# reinitialize_model(pgnniv_pretrained_decoder)\n",
    "# reinitialize_model(pgnniv_pretrained_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 2.900e+08, Test loss: 4.942e+08, MSE(e): 2.896e+01, MSE(pi1): 2.193e+01, MSE(pi2): 1.262e+01, MSE(pi3): 1.571e+00\n",
      "Epoch 100, Train loss: 1.612e+08, Test loss: 2.364e+08, MSE(e): 1.606e+01, MSE(pi1): 3.739e+01, MSE(pi2): 7.478e+00, MSE(pi3): 2.164e+00\n",
      "Epoch 200, Train loss: 9.399e+07, Test loss: 1.321e+08, MSE(e): 9.326e+00, MSE(pi1): 4.703e+01, MSE(pi2): 4.668e+00, MSE(pi3): 2.588e+00\n",
      "Epoch 300, Train loss: 6.392e+07, Test loss: 8.970e+07, MSE(e): 6.322e+00, MSE(pi1): 4.299e+01, MSE(pi2): 3.343e+00, MSE(pi3): 2.623e+00\n",
      "Epoch 400, Train loss: 4.764e+07, Test loss: 6.890e+07, MSE(e): 4.701e+00, MSE(pi1): 3.686e+01, MSE(pi2): 2.729e+00, MSE(pi3): 2.653e+00\n",
      "Epoch 500, Train loss: 3.804e+07, Test loss: 5.669e+07, MSE(e): 3.743e+00, MSE(pi1): 3.392e+01, MSE(pi2): 2.362e+00, MSE(pi3): 2.667e+00\n",
      "Epoch 600, Train loss: 3.153e+07, Test loss: 4.562e+07, MSE(e): 3.096e+00, MSE(pi1): 3.096e+01, MSE(pi2): 2.052e+00, MSE(pi3): 2.603e+00\n",
      "Epoch 700, Train loss: 2.624e+07, Test loss: 3.535e+07, MSE(e): 2.571e+00, MSE(pi1): 2.833e+01, MSE(pi2): 1.755e+00, MSE(pi3): 2.510e+00\n",
      "Epoch 800, Train loss: 2.139e+07, Test loss: 2.732e+07, MSE(e): 2.089e+00, MSE(pi1): 2.629e+01, MSE(pi2): 1.464e+00, MSE(pi3): 2.417e+00\n",
      "Epoch 900, Train loss: 1.783e+07, Test loss: 2.315e+07, MSE(e): 1.735e+00, MSE(pi1): 2.469e+01, MSE(pi2): 1.238e+00, MSE(pi3): 2.315e+00\n",
      "Epoch 1000, Train loss: 1.510e+07, Test loss: 2.065e+07, MSE(e): 1.465e+00, MSE(pi1): 2.348e+01, MSE(pi2): 1.065e+00, MSE(pi3): 2.214e+00\n",
      "Epoch 1100, Train loss: 1.312e+07, Test loss: 1.886e+07, MSE(e): 1.268e+00, MSE(pi1): 2.259e+01, MSE(pi2): 9.353e-01, MSE(pi3): 2.117e+00\n",
      "Epoch 1200, Train loss: 1.168e+07, Test loss: 1.742e+07, MSE(e): 1.125e+00, MSE(pi1): 2.196e+01, MSE(pi2): 8.331e-01, MSE(pi3): 2.023e+00\n",
      "Epoch 1300, Train loss: 1.055e+07, Test loss: 1.621e+07, MSE(e): 1.014e+00, MSE(pi1): 2.152e+01, MSE(pi2): 7.476e-01, MSE(pi3): 1.930e+00\n",
      "Epoch 1400, Train loss: 9.605e+06, Test loss: 1.513e+07, MSE(e): 9.209e-01, MSE(pi1): 2.119e+01, MSE(pi2): 6.739e-01, MSE(pi3): 1.834e+00\n",
      "Epoch 1500, Train loss: 8.770e+06, Test loss: 1.401e+07, MSE(e): 8.387e-01, MSE(pi1): 2.089e+01, MSE(pi2): 6.076e-01, MSE(pi3): 1.730e+00\n",
      "Epoch 1600, Train loss: 7.990e+06, Test loss: 1.281e+07, MSE(e): 7.622e-01, MSE(pi1): 2.052e+01, MSE(pi2): 5.456e-01, MSE(pi3): 1.617e+00\n",
      "Epoch 1700, Train loss: 7.259e+06, Test loss: 1.172e+07, MSE(e): 6.909e-01, MSE(pi1): 2.003e+01, MSE(pi2): 4.873e-01, MSE(pi3): 1.494e+00\n",
      "Epoch 1800, Train loss: 6.604e+06, Test loss: 1.089e+07, MSE(e): 6.272e-01, MSE(pi1): 1.940e+01, MSE(pi2): 4.348e-01, MSE(pi3): 1.368e+00\n",
      "Epoch 1900, Train loss: 6.022e+06, Test loss: 1.021e+07, MSE(e): 5.709e-01, MSE(pi1): 1.871e+01, MSE(pi2): 3.883e-01, MSE(pi3): 1.249e+00\n",
      "Epoch 2000, Train loss: 5.497e+06, Test loss: 9.591e+06, MSE(e): 5.202e-01, MSE(pi1): 1.805e+01, MSE(pi2): 3.474e-01, MSE(pi3): 1.142e+00\n",
      "Epoch 2100, Train loss: 5.016e+06, Test loss: 8.999e+06, MSE(e): 4.737e-01, MSE(pi1): 1.745e+01, MSE(pi2): 3.110e-01, MSE(pi3): 1.049e+00\n",
      "Epoch 2200, Train loss: 4.568e+06, Test loss: 8.410e+06, MSE(e): 4.302e-01, MSE(pi1): 1.688e+01, MSE(pi2): 2.784e-01, MSE(pi3): 9.651e-01\n",
      "Epoch 2300, Train loss: 4.144e+06, Test loss: 7.811e+06, MSE(e): 3.894e-01, MSE(pi1): 1.621e+01, MSE(pi2): 2.487e-01, MSE(pi3): 8.812e-01\n",
      "Epoch 2400, Train loss: 3.735e+06, Test loss: 7.190e+06, MSE(e): 3.511e-01, MSE(pi1): 1.468e+01, MSE(pi2): 2.218e-01, MSE(pi3): 7.669e-01\n",
      "Epoch 2500, Train loss: 3.306e+06, Test loss: 6.513e+06, MSE(e): 3.155e-01, MSE(pi1): 8.888e+00, MSE(pi2): 1.975e-01, MSE(pi3): 6.156e-01\n",
      "Epoch 2600, Train loss: 2.946e+06, Test loss: 5.872e+06, MSE(e): 2.829e-01, MSE(pi1): 5.955e+00, MSE(pi2): 1.757e-01, MSE(pi3): 5.717e-01\n",
      "Epoch 2700, Train loss: 2.638e+06, Test loss: 5.293e+06, MSE(e): 2.541e-01, MSE(pi1): 4.939e+00, MSE(pi2): 1.568e-01, MSE(pi3): 4.740e-01\n",
      "Epoch 2800, Train loss: 2.369e+06, Test loss: 4.778e+06, MSE(e): 2.288e-01, MSE(pi1): 4.131e+00, MSE(pi2): 1.405e-01, MSE(pi3): 3.987e-01\n",
      "Epoch 2900, Train loss: 2.139e+06, Test loss: 4.336e+06, MSE(e): 2.070e-01, MSE(pi1): 3.489e+00, MSE(pi2): 1.265e-01, MSE(pi3): 3.391e-01\n",
      "Epoch 3000, Train loss: 1.940e+06, Test loss: 3.947e+06, MSE(e): 1.881e-01, MSE(pi1): 2.979e+00, MSE(pi2): 1.144e-01, MSE(pi3): 2.908e-01\n",
      "Epoch 3100, Train loss: 1.767e+06, Test loss: 3.585e+06, MSE(e): 1.716e-01, MSE(pi1): 2.569e+00, MSE(pi2): 1.036e-01, MSE(pi3): 2.511e-01\n",
      "Epoch 3200, Train loss: 1.627e+06, Test loss: 3.249e+06, MSE(e): 1.583e-01, MSE(pi1): 2.238e+00, MSE(pi2): 9.494e-02, MSE(pi3): 2.184e-01\n",
      "Epoch 3300, Train loss: 1.509e+06, Test loss: 2.977e+06, MSE(e): 1.470e-01, MSE(pi1): 1.969e+00, MSE(pi2): 8.766e-02, MSE(pi3): 1.914e-01\n",
      "Epoch 3400, Train loss: 1.404e+06, Test loss: 2.750e+06, MSE(e): 1.369e-01, MSE(pi1): 1.749e+00, MSE(pi2): 8.122e-02, MSE(pi3): 1.688e-01\n",
      "Epoch 3500, Train loss: 1.302e+06, Test loss: 2.560e+06, MSE(e): 1.271e-01, MSE(pi1): 1.564e+00, MSE(pi2): 7.509e-02, MSE(pi3): 1.498e-01\n",
      "Epoch 3600, Train loss: 1.195e+06, Test loss: 2.425e+06, MSE(e): 1.168e-01, MSE(pi1): 1.406e+00, MSE(pi2): 6.876e-02, MSE(pi3): 1.337e-01\n",
      "Epoch 3700, Train loss: 1.094e+06, Test loss: 2.286e+06, MSE(e): 1.070e-01, MSE(pi1): 1.266e+00, MSE(pi2): 6.269e-02, MSE(pi3): 1.196e-01\n",
      "Epoch 3800, Train loss: 1.006e+06, Test loss: 2.139e+06, MSE(e): 9.842e-02, MSE(pi1): 1.138e+00, MSE(pi2): 5.732e-02, MSE(pi3): 1.070e-01\n",
      "Epoch 3900, Train loss: 9.301e+05, Test loss: 1.993e+06, MSE(e): 9.102e-02, MSE(pi1): 1.021e+00, MSE(pi2): 5.266e-02, MSE(pi3): 9.578e-02\n",
      "Epoch 4000, Train loss: 8.615e+05, Test loss: 1.861e+06, MSE(e): 8.437e-02, MSE(pi1): 9.145e-01, MSE(pi2): 4.851e-02, MSE(pi3): 8.587e-02\n",
      "Epoch 4100, Train loss: 7.978e+05, Test loss: 1.747e+06, MSE(e): 7.819e-02, MSE(pi1): 8.181e-01, MSE(pi2): 4.469e-02, MSE(pi3): 7.706e-02\n",
      "Epoch 4200, Train loss: 7.375e+05, Test loss: 1.652e+06, MSE(e): 7.232e-02, MSE(pi1): 7.316e-01, MSE(pi2): 4.111e-02, MSE(pi3): 6.915e-02\n",
      "Epoch 4300, Train loss: 6.794e+05, Test loss: 1.578e+06, MSE(e): 6.666e-02, MSE(pi1): 6.545e-01, MSE(pi2): 3.770e-02, MSE(pi3): 6.193e-02\n",
      "Epoch 4400, Train loss: 6.233e+05, Test loss: 1.526e+06, MSE(e): 6.119e-02, MSE(pi1): 5.854e-01, MSE(pi2): 3.443e-02, MSE(pi3): 5.530e-02\n",
      "Epoch 4500, Train loss: 5.701e+05, Test loss: 1.491e+06, MSE(e): 5.600e-02, MSE(pi1): 5.224e-01, MSE(pi2): 3.136e-02, MSE(pi3): 4.923e-02\n",
      "Epoch 4600, Train loss: 5.217e+05, Test loss: 1.469e+06, MSE(e): 5.126e-02, MSE(pi1): 4.649e-01, MSE(pi2): 2.860e-02, MSE(pi3): 4.380e-02\n",
      "Epoch 4700, Train loss: 4.789e+05, Test loss: 1.453e+06, MSE(e): 4.709e-02, MSE(pi1): 4.136e-01, MSE(pi2): 2.619e-02, MSE(pi3): 3.907e-02\n",
      "Epoch 4800, Train loss: 4.416e+05, Test loss: 1.437e+06, MSE(e): 4.344e-02, MSE(pi1): 3.689e-01, MSE(pi2): 2.411e-02, MSE(pi3): 3.504e-02\n",
      "Epoch 4900, Train loss: 4.088e+05, Test loss: 1.417e+06, MSE(e): 4.023e-02, MSE(pi1): 3.304e-01, MSE(pi2): 2.228e-02, MSE(pi3): 3.163e-02\n",
      "Epoch 5000, Train loss: 3.793e+05, Test loss: 1.392e+06, MSE(e): 3.735e-02, MSE(pi1): 2.972e-01, MSE(pi2): 2.065e-02, MSE(pi3): 2.873e-02\n",
      "Epoch 5100, Train loss: 3.525e+05, Test loss: 1.363e+06, MSE(e): 3.471e-02, MSE(pi1): 2.682e-01, MSE(pi2): 1.916e-02, MSE(pi3): 2.622e-02\n",
      "Epoch 5200, Train loss: 3.276e+05, Test loss: 1.332e+06, MSE(e): 3.228e-02, MSE(pi1): 2.427e-01, MSE(pi2): 1.779e-02, MSE(pi3): 2.403e-02\n",
      "Epoch 5300, Train loss: 3.045e+05, Test loss: 1.302e+06, MSE(e): 3.001e-02, MSE(pi1): 2.200e-01, MSE(pi2): 1.651e-02, MSE(pi3): 2.207e-02\n",
      "Epoch 5400, Train loss: 2.829e+05, Test loss: 1.273e+06, MSE(e): 2.788e-02, MSE(pi1): 1.997e-01, MSE(pi2): 1.531e-02, MSE(pi3): 2.033e-02\n",
      "Epoch 5500, Train loss: 2.626e+05, Test loss: 1.245e+06, MSE(e): 2.589e-02, MSE(pi1): 1.815e-01, MSE(pi2): 1.420e-02, MSE(pi3): 1.875e-02\n",
      "Epoch 5600, Train loss: 2.437e+05, Test loss: 1.220e+06, MSE(e): 2.403e-02, MSE(pi1): 1.650e-01, MSE(pi2): 1.316e-02, MSE(pi3): 1.732e-02\n",
      "Epoch 5700, Train loss: 2.260e+05, Test loss: 1.197e+06, MSE(e): 2.229e-02, MSE(pi1): 1.501e-01, MSE(pi2): 1.219e-02, MSE(pi3): 1.604e-02\n",
      "Epoch 5800, Train loss: 2.095e+05, Test loss: 1.175e+06, MSE(e): 2.066e-02, MSE(pi1): 1.366e-01, MSE(pi2): 1.128e-02, MSE(pi3): 1.488e-02\n",
      "Epoch 5900, Train loss: 1.941e+05, Test loss: 1.156e+06, MSE(e): 1.914e-02, MSE(pi1): 1.245e-01, MSE(pi2): 1.045e-02, MSE(pi3): 1.383e-02\n",
      "Epoch 6000, Train loss: 1.798e+05, Test loss: 1.139e+06, MSE(e): 1.773e-02, MSE(pi1): 1.137e-01, MSE(pi2): 9.670e-03, MSE(pi3): 1.290e-02\n",
      "Epoch 6100, Train loss: 1.666e+05, Test loss: 1.125e+06, MSE(e): 1.643e-02, MSE(pi1): 1.044e-01, MSE(pi2): 8.955e-03, MSE(pi3): 1.203e-02\n",
      "Epoch 6200, Train loss: 1.543e+05, Test loss: 1.111e+06, MSE(e): 1.522e-02, MSE(pi1): 9.556e-02, MSE(pi2): 8.295e-03, MSE(pi3): 1.136e-02\n",
      "Epoch 6300, Train loss: 1.430e+05, Test loss: 1.099e+06, MSE(e): 1.410e-02, MSE(pi1): 8.802e-02, MSE(pi2): 7.687e-03, MSE(pi3): 1.074e-02\n",
      "Epoch 6400, Train loss: 1.325e+05, Test loss: 1.088e+06, MSE(e): 1.307e-02, MSE(pi1): 8.142e-02, MSE(pi2): 7.129e-03, MSE(pi3): 1.020e-02\n",
      "Epoch 6500, Train loss: 1.228e+05, Test loss: 1.077e+06, MSE(e): 1.211e-02, MSE(pi1): 7.560e-02, MSE(pi2): 6.616e-03, MSE(pi3): 9.750e-03\n",
      "Epoch 6600, Train loss: 1.139e+05, Test loss: 1.067e+06, MSE(e): 1.123e-02, MSE(pi1): 7.052e-02, MSE(pi2): 6.147e-03, MSE(pi3): 9.366e-03\n",
      "Epoch 6700, Train loss: 1.057e+05, Test loss: 1.058e+06, MSE(e): 1.041e-02, MSE(pi1): 6.601e-02, MSE(pi2): 5.715e-03, MSE(pi3): 9.048e-03\n",
      "Epoch 6800, Train loss: 9.812e+04, Test loss: 1.048e+06, MSE(e): 9.662e-03, MSE(pi1): 6.207e-02, MSE(pi2): 5.317e-03, MSE(pi3): 8.775e-03\n",
      "Epoch 6900, Train loss: 9.110e+04, Test loss: 1.038e+06, MSE(e): 8.966e-03, MSE(pi1): 5.846e-02, MSE(pi2): 4.951e-03, MSE(pi3): 8.558e-03\n",
      "Epoch 7000, Train loss: 8.462e+04, Test loss: 1.028e+06, MSE(e): 8.323e-03, MSE(pi1): 5.521e-02, MSE(pi2): 4.614e-03, MSE(pi3): 8.377e-03\n",
      "Epoch 7100, Train loss: 7.862e+04, Test loss: 1.018e+06, MSE(e): 7.728e-03, MSE(pi1): 5.235e-02, MSE(pi2): 4.303e-03, MSE(pi3): 8.211e-03\n",
      "Epoch 7200, Train loss: 7.305e+04, Test loss: 1.008e+06, MSE(e): 7.174e-03, MSE(pi1): 4.972e-02, MSE(pi2): 4.014e-03, MSE(pi3): 8.070e-03\n",
      "Epoch 7300, Train loss: 6.789e+04, Test loss: 9.968e+05, MSE(e): 6.662e-03, MSE(pi1): 4.726e-02, MSE(pi2): 3.746e-03, MSE(pi3): 7.954e-03\n",
      "Epoch 7400, Train loss: 6.311e+04, Test loss: 9.855e+05, MSE(e): 6.188e-03, MSE(pi1): 4.500e-02, MSE(pi2): 3.500e-03, MSE(pi3): 7.852e-03\n",
      "Epoch 7500, Train loss: 5.867e+04, Test loss: 9.742e+05, MSE(e): 5.746e-03, MSE(pi1): 4.299e-02, MSE(pi2): 3.269e-03, MSE(pi3): 7.751e-03\n",
      "Epoch 7600, Train loss: 5.458e+04, Test loss: 9.623e+05, MSE(e): 5.340e-03, MSE(pi1): 4.107e-02, MSE(pi2): 3.058e-03, MSE(pi3): 7.668e-03\n",
      "Epoch 7700, Train loss: 5.077e+04, Test loss: 9.502e+05, MSE(e): 4.962e-03, MSE(pi1): 3.931e-02, MSE(pi2): 2.860e-03, MSE(pi3): 7.590e-03\n",
      "Epoch 7800, Train loss: 4.730e+04, Test loss: 9.382e+05, MSE(e): 4.617e-03, MSE(pi1): 3.770e-02, MSE(pi2): 2.680e-03, MSE(pi3): 7.517e-03\n",
      "Epoch 7900, Train loss: 4.408e+04, Test loss: 9.259e+05, MSE(e): 4.298e-03, MSE(pi1): 3.619e-02, MSE(pi2): 2.512e-03, MSE(pi3): 7.450e-03\n",
      "Epoch 8000, Train loss: 4.171e+04, Test loss: 9.150e+05, MSE(e): 4.062e-03, MSE(pi1): 3.580e-02, MSE(pi2): 2.377e-03, MSE(pi3): 7.275e-03\n",
      "Epoch 8100, Train loss: 3.837e+04, Test loss: 9.009e+05, MSE(e): 3.730e-03, MSE(pi1): 3.349e-02, MSE(pi2): 2.213e-03, MSE(pi3): 7.329e-03\n",
      "Epoch 8200, Train loss: 3.621e+04, Test loss: 8.871e+05, MSE(e): 3.515e-03, MSE(pi1): 3.159e-02, MSE(pi2): 2.096e-03, MSE(pi3): 7.360e-03\n",
      "Epoch 8300, Train loss: 3.357e+04, Test loss: 8.761e+05, MSE(e): 3.254e-03, MSE(pi1): 3.116e-02, MSE(pi2): 1.959e-03, MSE(pi3): 7.221e-03\n",
      "Epoch 8400, Train loss: 3.315e+04, Test loss: 8.658e+05, MSE(e): 3.213e-03, MSE(pi1): 3.186e-02, MSE(pi2): 1.909e-03, MSE(pi3): 6.990e-03\n",
      "Epoch 8500, Train loss: 2.963e+04, Test loss: 8.534e+05, MSE(e): 2.863e-03, MSE(pi1): 2.913e-02, MSE(pi2): 1.746e-03, MSE(pi3): 7.124e-03\n",
      "Epoch 8600, Train loss: 2.794e+04, Test loss: 8.429e+05, MSE(e): 2.695e-03, MSE(pi1): 2.819e-02, MSE(pi2): 1.653e-03, MSE(pi3): 7.082e-03\n",
      "Epoch 8700, Train loss: 2.640e+04, Test loss: 8.329e+05, MSE(e): 2.542e-03, MSE(pi1): 2.710e-02, MSE(pi2): 1.568e-03, MSE(pi3): 7.065e-03\n",
      "Epoch 8800, Train loss: 2.497e+04, Test loss: 8.242e+05, MSE(e): 2.400e-03, MSE(pi1): 2.649e-02, MSE(pi2): 1.488e-03, MSE(pi3): 7.001e-03\n",
      "Epoch 8900, Train loss: 2.368e+04, Test loss: 8.159e+05, MSE(e): 2.273e-03, MSE(pi1): 2.571e-02, MSE(pi2): 1.415e-03, MSE(pi3): 6.962e-03\n",
      "Epoch 9000, Train loss: 2.252e+04, Test loss: 8.088e+05, MSE(e): 2.158e-03, MSE(pi1): 2.496e-02, MSE(pi2): 1.349e-03, MSE(pi3): 6.929e-03\n",
      "Epoch 9100, Train loss: 2.146e+04, Test loss: 8.021e+05, MSE(e): 2.052e-03, MSE(pi1): 2.428e-02, MSE(pi2): 1.287e-03, MSE(pi3): 6.894e-03\n",
      "Epoch 9200, Train loss: 2.047e+04, Test loss: 7.960e+05, MSE(e): 1.955e-03, MSE(pi1): 2.360e-02, MSE(pi2): 1.230e-03, MSE(pi3): 6.863e-03\n",
      "Epoch 9300, Train loss: 1.958e+04, Test loss: 7.908e+05, MSE(e): 1.867e-03, MSE(pi1): 2.300e-02, MSE(pi2): 1.177e-03, MSE(pi3): 6.832e-03\n",
      "Epoch 9400, Train loss: 1.877e+04, Test loss: 7.853e+05, MSE(e): 1.786e-03, MSE(pi1): 2.262e-02, MSE(pi2): 1.128e-03, MSE(pi3): 6.780e-03\n",
      "Epoch 9500, Train loss: 1.798e+04, Test loss: 7.811e+05, MSE(e): 1.708e-03, MSE(pi1): 2.188e-02, MSE(pi2): 1.081e-03, MSE(pi3): 6.773e-03\n",
      "Epoch 9600, Train loss: 1.735e+04, Test loss: 7.758e+05, MSE(e): 1.646e-03, MSE(pi1): 2.176e-02, MSE(pi2): 1.041e-03, MSE(pi3): 6.702e-03\n",
      "Epoch 9700, Train loss: 1.658e+04, Test loss: 7.724e+05, MSE(e): 1.570e-03, MSE(pi1): 2.084e-02, MSE(pi2): 9.970e-04, MSE(pi3): 6.723e-03\n",
      "Epoch 9800, Train loss: 1.596e+04, Test loss: 7.685e+05, MSE(e): 1.508e-03, MSE(pi1): 2.025e-02, MSE(pi2): 9.585e-04, MSE(pi3): 6.711e-03\n",
      "Epoch 9900, Train loss: 1.537e+04, Test loss: 7.644e+05, MSE(e): 1.450e-03, MSE(pi1): 1.990e-02, MSE(pi2): 9.225e-04, MSE(pi3): 6.676e-03\n",
      "Epoch 10000, Train loss: 1.481e+04, Test loss: 7.603e+05, MSE(e): 1.395e-03, MSE(pi1): 1.949e-02, MSE(pi2): 8.883e-04, MSE(pi3): 6.653e-03\n",
      "Epoch 10100, Train loss: 1.429e+04, Test loss: 7.561e+05, MSE(e): 1.344e-03, MSE(pi1): 1.916e-02, MSE(pi2): 8.560e-04, MSE(pi3): 6.622e-03\n",
      "Epoch 10200, Train loss: 1.379e+04, Test loss: 7.522e+05, MSE(e): 1.294e-03, MSE(pi1): 1.870e-02, MSE(pi2): 8.252e-04, MSE(pi3): 6.610e-03\n",
      "Epoch 10300, Train loss: 1.333e+04, Test loss: 7.482e+05, MSE(e): 1.248e-03, MSE(pi1): 1.829e-02, MSE(pi2): 7.961e-04, MSE(pi3): 6.595e-03\n",
      "Epoch 10400, Train loss: 1.289e+04, Test loss: 7.441e+05, MSE(e): 1.205e-03, MSE(pi1): 1.798e-02, MSE(pi2): 7.686e-04, MSE(pi3): 6.571e-03\n",
      "Epoch 10500, Train loss: 1.262e+04, Test loss: 7.391e+05, MSE(e): 1.178e-03, MSE(pi1): 1.815e-02, MSE(pi2): 7.484e-04, MSE(pi3): 6.503e-03\n",
      "Epoch 10600, Train loss: 1.207e+04, Test loss: 7.356e+05, MSE(e): 1.124e-03, MSE(pi1): 1.733e-02, MSE(pi2): 7.172e-04, MSE(pi3): 6.535e-03\n",
      "Epoch 10700, Train loss: 1.400e+04, Test loss: 7.296e+05, MSE(e): 1.317e-03, MSE(pi1): 1.921e-02, MSE(pi2): 7.871e-04, MSE(pi3): 6.320e-03\n",
      "Epoch 10800, Train loss: 1.133e+04, Test loss: 7.271e+05, MSE(e): 1.051e-03, MSE(pi1): 1.674e-02, MSE(pi2): 6.707e-04, MSE(pi3): 6.501e-03\n",
      "Epoch 10900, Train loss: 1.098e+04, Test loss: 7.228e+05, MSE(e): 1.017e-03, MSE(pi1): 1.645e-02, MSE(pi2): 6.489e-04, MSE(pi3): 6.486e-03\n",
      "Epoch 11000, Train loss: 1.064e+04, Test loss: 7.183e+05, MSE(e): 9.834e-04, MSE(pi1): 1.620e-02, MSE(pi2): 6.277e-04, MSE(pi3): 6.469e-03\n",
      "Epoch 11100, Train loss: 1.059e+04, Test loss: 7.155e+05, MSE(e): 9.788e-04, MSE(pi1): 1.527e-02, MSE(pi2): 6.180e-04, MSE(pi3): 6.536e-03\n",
      "Epoch 11200, Train loss: 1.002e+04, Test loss: 7.097e+05, MSE(e): 9.217e-04, MSE(pi1): 1.566e-02, MSE(pi2): 5.883e-04, MSE(pi3): 6.444e-03\n",
      "Epoch 11300, Train loss: 9.725e+03, Test loss: 7.053e+05, MSE(e): 8.926e-04, MSE(pi1): 1.548e-02, MSE(pi2): 5.696e-04, MSE(pi3): 6.442e-03\n",
      "Epoch 11400, Train loss: 9.443e+03, Test loss: 7.011e+05, MSE(e): 8.649e-04, MSE(pi1): 1.524e-02, MSE(pi2): 5.518e-04, MSE(pi3): 6.413e-03\n",
      "Epoch 11500, Train loss: 9.169e+03, Test loss: 6.969e+05, MSE(e): 8.378e-04, MSE(pi1): 1.496e-02, MSE(pi2): 5.345e-04, MSE(pi3): 6.411e-03\n",
      "Epoch 11600, Train loss: 8.912e+03, Test loss: 6.930e+05, MSE(e): 8.124e-04, MSE(pi1): 1.475e-02, MSE(pi2): 5.181e-04, MSE(pi3): 6.395e-03\n",
      "Epoch 11700, Train loss: 8.665e+03, Test loss: 6.890e+05, MSE(e): 7.877e-04, MSE(pi1): 1.492e-02, MSE(pi2): 5.023e-04, MSE(pi3): 6.386e-03\n",
      "Epoch 11800, Train loss: 8.469e+03, Test loss: 6.850e+05, MSE(e): 7.688e-04, MSE(pi1): 1.469e-02, MSE(pi2): 4.892e-04, MSE(pi3): 6.336e-03\n",
      "Epoch 11900, Train loss: 8.188e+03, Test loss: 6.812e+05, MSE(e): 7.406e-04, MSE(pi1): 1.430e-02, MSE(pi2): 4.720e-04, MSE(pi3): 6.381e-03\n",
      "Epoch 12000, Train loss: 7.959e+03, Test loss: 6.776e+05, MSE(e): 7.184e-04, MSE(pi1): 1.401e-02, MSE(pi2): 4.577e-04, MSE(pi3): 6.351e-03\n",
      "Epoch 12100, Train loss: 7.743e+03, Test loss: 6.740e+05, MSE(e): 6.970e-04, MSE(pi1): 1.386e-02, MSE(pi2): 4.440e-04, MSE(pi3): 6.338e-03\n",
      "Epoch 12200, Train loss: 7.701e+03, Test loss: 6.707e+05, MSE(e): 6.925e-04, MSE(pi1): 1.359e-02, MSE(pi2): 4.367e-04, MSE(pi3): 6.393e-03\n",
      "Epoch 12300, Train loss: 7.339e+03, Test loss: 6.675e+05, MSE(e): 6.568e-04, MSE(pi1): 1.365e-02, MSE(pi2): 4.181e-04, MSE(pi3): 6.345e-03\n",
      "Epoch 12400, Train loss: 7.140e+03, Test loss: 6.642e+05, MSE(e): 6.375e-04, MSE(pi1): 1.340e-02, MSE(pi2): 4.057e-04, MSE(pi3): 6.310e-03\n",
      "Epoch 12500, Train loss: 6.956e+03, Test loss: 6.613e+05, MSE(e): 6.193e-04, MSE(pi1): 1.330e-02, MSE(pi2): 3.940e-04, MSE(pi3): 6.297e-03\n",
      "Epoch 12600, Train loss: 6.774e+03, Test loss: 6.584e+05, MSE(e): 6.013e-04, MSE(pi1): 1.306e-02, MSE(pi2): 3.824e-04, MSE(pi3): 6.305e-03\n",
      "Epoch 12700, Train loss: 6.601e+03, Test loss: 6.557e+05, MSE(e): 5.842e-04, MSE(pi1): 1.301e-02, MSE(pi2): 3.714e-04, MSE(pi3): 6.284e-03\n",
      "Epoch 12800, Train loss: 6.434e+03, Test loss: 6.531e+05, MSE(e): 5.675e-04, MSE(pi1): 1.304e-02, MSE(pi2): 3.607e-04, MSE(pi3): 6.284e-03\n",
      "Epoch 12900, Train loss: 6.280e+03, Test loss: 6.507e+05, MSE(e): 5.525e-04, MSE(pi1): 1.286e-02, MSE(pi2): 3.509e-04, MSE(pi3): 6.258e-03\n",
      "Epoch 13000, Train loss: 6.115e+03, Test loss: 6.482e+05, MSE(e): 5.360e-04, MSE(pi1): 1.276e-02, MSE(pi2): 3.404e-04, MSE(pi3): 6.267e-03\n",
      "Epoch 13100, Train loss: 5.964e+03, Test loss: 6.461e+05, MSE(e): 5.213e-04, MSE(pi1): 1.247e-02, MSE(pi2): 3.310e-04, MSE(pi3): 6.263e-03\n",
      "Epoch 13200, Train loss: 5.835e+03, Test loss: 6.441e+05, MSE(e): 5.072e-04, MSE(pi1): 1.321e-02, MSE(pi2): 3.219e-04, MSE(pi3): 6.305e-03\n",
      "Epoch 13300, Train loss: 5.681e+03, Test loss: 6.420e+05, MSE(e): 4.933e-04, MSE(pi1): 1.228e-02, MSE(pi2): 3.130e-04, MSE(pi3): 6.249e-03\n",
      "Epoch 13400, Train loss: 5.584e+03, Test loss: 6.422e+05, MSE(e): 4.836e-04, MSE(pi1): 1.264e-02, MSE(pi2): 3.062e-04, MSE(pi3): 6.213e-03\n",
      "Epoch 13500, Train loss: 5.423e+03, Test loss: 6.385e+05, MSE(e): 4.678e-04, MSE(pi1): 1.210e-02, MSE(pi2): 2.966e-04, MSE(pi3): 6.237e-03\n",
      "Epoch 13600, Train loss: 5.303e+03, Test loss: 6.369e+05, MSE(e): 4.558e-04, MSE(pi1): 1.199e-02, MSE(pi2): 2.889e-04, MSE(pi3): 6.252e-03\n",
      "Epoch 13700, Train loss: 7.142e+03, Test loss: 6.391e+05, MSE(e): 6.395e-04, MSE(pi1): 1.459e-02, MSE(pi2): 3.640e-04, MSE(pi3): 6.009e-03\n",
      "Epoch 13800, Train loss: 5.070e+03, Test loss: 6.340e+05, MSE(e): 4.329e-04, MSE(pi1): 1.183e-02, MSE(pi2): 2.742e-04, MSE(pi3): 6.224e-03\n",
      "Epoch 13900, Train loss: 4.961e+03, Test loss: 6.325e+05, MSE(e): 4.221e-04, MSE(pi1): 1.176e-02, MSE(pi2): 2.673e-04, MSE(pi3): 6.219e-03\n",
      "Epoch 14000, Train loss: 4.857e+03, Test loss: 6.313e+05, MSE(e): 4.118e-04, MSE(pi1): 1.172e-02, MSE(pi2): 2.607e-04, MSE(pi3): 6.210e-03\n",
      "Epoch 14100, Train loss: 4.754e+03, Test loss: 6.301e+05, MSE(e): 4.016e-04, MSE(pi1): 1.163e-02, MSE(pi2): 2.541e-04, MSE(pi3): 6.208e-03\n",
      "Epoch 14200, Train loss: 4.659e+03, Test loss: 6.289e+05, MSE(e): 3.923e-04, MSE(pi1): 1.151e-02, MSE(pi2): 2.480e-04, MSE(pi3): 6.211e-03\n",
      "Epoch 14300, Train loss: 4.567e+03, Test loss: 6.279e+05, MSE(e): 3.831e-04, MSE(pi1): 1.150e-02, MSE(pi2): 2.422e-04, MSE(pi3): 6.202e-03\n",
      "Epoch 14400, Train loss: 4.517e+03, Test loss: 6.267e+05, MSE(e): 3.782e-04, MSE(pi1): 1.112e-02, MSE(pi2): 2.377e-04, MSE(pi3): 6.237e-03\n",
      "Epoch 14500, Train loss: 4.392e+03, Test loss: 6.260e+05, MSE(e): 3.658e-04, MSE(pi1): 1.130e-02, MSE(pi2): 2.311e-04, MSE(pi3): 6.206e-03\n",
      "Epoch 14600, Train loss: 4.341e+03, Test loss: 6.254e+05, MSE(e): 3.609e-04, MSE(pi1): 1.152e-02, MSE(pi2): 2.274e-04, MSE(pi3): 6.167e-03\n",
      "Epoch 14700, Train loss: 4.230e+03, Test loss: 6.242e+05, MSE(e): 3.498e-04, MSE(pi1): 1.124e-02, MSE(pi2): 2.207e-04, MSE(pi3): 6.191e-03\n",
      "Epoch 14800, Train loss: 4.158e+03, Test loss: 6.230e+05, MSE(e): 3.427e-04, MSE(pi1): 1.107e-02, MSE(pi2): 2.160e-04, MSE(pi3): 6.202e-03\n",
      "Epoch 14900, Train loss: 4.083e+03, Test loss: 6.228e+05, MSE(e): 3.353e-04, MSE(pi1): 1.114e-02, MSE(pi2): 2.114e-04, MSE(pi3): 6.185e-03\n",
      "Epoch 15000, Train loss: 4.014e+03, Test loss: 6.218e+05, MSE(e): 3.285e-04, MSE(pi1): 1.100e-02, MSE(pi2): 2.069e-04, MSE(pi3): 6.193e-03\n",
      "Epoch 15100, Train loss: 3.946e+03, Test loss: 6.214e+05, MSE(e): 3.217e-04, MSE(pi1): 1.106e-02, MSE(pi2): 2.027e-04, MSE(pi3): 6.178e-03\n",
      "Epoch 15200, Train loss: 4.083e+03, Test loss: 6.213e+05, MSE(e): 3.356e-04, MSE(pi1): 1.169e-02, MSE(pi2): 2.076e-04, MSE(pi3): 6.103e-03\n",
      "Epoch 15300, Train loss: 3.818e+03, Test loss: 6.201e+05, MSE(e): 3.091e-04, MSE(pi1): 1.091e-02, MSE(pi2): 1.945e-04, MSE(pi3): 6.181e-03\n",
      "Epoch 15400, Train loss: 3.814e+03, Test loss: 6.192e+05, MSE(e): 3.087e-04, MSE(pi1): 1.057e-02, MSE(pi2): 1.925e-04, MSE(pi3): 6.215e-03\n",
      "Epoch 15500, Train loss: 3.700e+03, Test loss: 6.189e+05, MSE(e): 2.974e-04, MSE(pi1): 1.086e-02, MSE(pi2): 1.870e-04, MSE(pi3): 6.173e-03\n",
      "Epoch 15600, Train loss: 3.670e+03, Test loss: 6.192e+05, MSE(e): 2.944e-04, MSE(pi1): 1.100e-02, MSE(pi2): 1.847e-04, MSE(pi3): 6.153e-03\n",
      "Epoch 15700, Train loss: 3.591e+03, Test loss: 6.178e+05, MSE(e): 2.866e-04, MSE(pi1): 1.077e-02, MSE(pi2): 1.800e-04, MSE(pi3): 6.170e-03\n",
      "Epoch 15800, Train loss: 3.542e+03, Test loss: 6.172e+05, MSE(e): 2.817e-04, MSE(pi1): 1.073e-02, MSE(pi2): 1.767e-04, MSE(pi3): 6.175e-03\n",
      "Epoch 15900, Train loss: 3.489e+03, Test loss: 6.169e+05, MSE(e): 2.765e-04, MSE(pi1): 1.073e-02, MSE(pi2): 1.735e-04, MSE(pi3): 6.163e-03\n",
      "Epoch 16000, Train loss: 3.442e+03, Test loss: 6.164e+05, MSE(e): 2.719e-04, MSE(pi1): 1.062e-02, MSE(pi2): 1.704e-04, MSE(pi3): 6.172e-03\n",
      "Epoch 16100, Train loss: 3.395e+03, Test loss: 6.160e+05, MSE(e): 2.672e-04, MSE(pi1): 1.065e-02, MSE(pi2): 1.674e-04, MSE(pi3): 6.163e-03\n",
      "Epoch 16200, Train loss: 3.356e+03, Test loss: 6.155e+05, MSE(e): 2.633e-04, MSE(pi1): 1.050e-02, MSE(pi2): 1.647e-04, MSE(pi3): 6.177e-03\n",
      "Epoch 16300, Train loss: 3.308e+03, Test loss: 6.153e+05, MSE(e): 2.586e-04, MSE(pi1): 1.060e-02, MSE(pi2): 1.619e-04, MSE(pi3): 6.159e-03\n",
      "Epoch 16400, Train loss: 3.274e+03, Test loss: 6.158e+05, MSE(e): 2.553e-04, MSE(pi1): 1.077e-02, MSE(pi2): 1.596e-04, MSE(pi3): 6.136e-03\n",
      "Epoch 16500, Train loss: 3.521e+03, Test loss: 6.185e+05, MSE(e): 2.800e-04, MSE(pi1): 1.122e-02, MSE(pi2): 1.695e-04, MSE(pi3): 6.088e-03\n",
      "Epoch 16600, Train loss: 3.185e+03, Test loss: 6.143e+05, MSE(e): 2.464e-04, MSE(pi1): 1.050e-02, MSE(pi2): 1.540e-04, MSE(pi3): 6.156e-03\n",
      "Epoch 16700, Train loss: 3.220e+03, Test loss: 6.157e+05, MSE(e): 2.500e-04, MSE(pi1): 1.079e-02, MSE(pi2): 1.550e-04, MSE(pi3): 6.123e-03\n",
      "Epoch 16800, Train loss: 3.118e+03, Test loss: 6.138e+05, MSE(e): 2.390e-04, MSE(pi1): 1.073e-02, MSE(pi2): 1.491e-04, MSE(pi3): 6.206e-03\n",
      "Epoch 16900, Train loss: 3.074e+03, Test loss: 6.136e+05, MSE(e): 2.354e-04, MSE(pi1): 1.047e-02, MSE(pi2): 1.469e-04, MSE(pi3): 6.149e-03\n",
      "Epoch 17000, Train loss: 3.227e+03, Test loss: 6.180e+05, MSE(e): 2.505e-04, MSE(pi1): 1.136e-02, MSE(pi2): 1.529e-04, MSE(pi3): 6.081e-03\n",
      "Epoch 17100, Train loss: 3.005e+03, Test loss: 6.132e+05, MSE(e): 2.286e-04, MSE(pi1): 1.042e-02, MSE(pi2): 1.425e-04, MSE(pi3): 6.147e-03\n",
      "Epoch 17200, Train loss: 3.043e+03, Test loss: 6.148e+05, MSE(e): 2.325e-04, MSE(pi1): 1.076e-02, MSE(pi2): 1.437e-04, MSE(pi3): 6.105e-03\n",
      "Epoch 17300, Train loss: 2.941e+03, Test loss: 6.128e+05, MSE(e): 2.222e-04, MSE(pi1): 1.039e-02, MSE(pi2): 1.384e-04, MSE(pi3): 6.144e-03\n",
      "Epoch 17400, Train loss: 2.928e+03, Test loss: 6.116e+05, MSE(e): 2.209e-04, MSE(pi1): 1.023e-02, MSE(pi2): 1.369e-04, MSE(pi3): 6.163e-03\n",
      "Epoch 17500, Train loss: 2.880e+03, Test loss: 6.125e+05, MSE(e): 2.162e-04, MSE(pi1): 1.030e-02, MSE(pi2): 1.345e-04, MSE(pi3): 6.147e-03\n",
      "Epoch 17600, Train loss: 2.851e+03, Test loss: 6.124e+05, MSE(e): 2.133e-04, MSE(pi1): 1.042e-02, MSE(pi2): 1.326e-04, MSE(pi3): 6.133e-03\n",
      "Epoch 17700, Train loss: 2.824e+03, Test loss: 6.126e+05, MSE(e): 2.107e-04, MSE(pi1): 1.034e-02, MSE(pi2): 1.309e-04, MSE(pi3): 6.137e-03\n",
      "Epoch 17800, Train loss: 2.977e+03, Test loss: 6.155e+05, MSE(e): 2.260e-04, MSE(pi1): 1.103e-02, MSE(pi2): 1.372e-04, MSE(pi3): 6.062e-03\n",
      "Epoch 17900, Train loss: 2.766e+03, Test loss: 6.122e+05, MSE(e): 2.050e-04, MSE(pi1): 1.029e-02, MSE(pi2): 1.273e-04, MSE(pi3): 6.137e-03\n",
      "Epoch 18000, Train loss: 2.743e+03, Test loss: 6.128e+05, MSE(e): 2.024e-04, MSE(pi1): 1.010e-02, MSE(pi2): 1.255e-04, MSE(pi3): 6.178e-03\n",
      "Epoch 18100, Train loss: 2.720e+03, Test loss: 6.121e+05, MSE(e): 1.998e-04, MSE(pi1): 1.093e-02, MSE(pi2): 1.240e-04, MSE(pi3): 6.124e-03\n",
      "Epoch 18200, Train loss: 2.696e+03, Test loss: 6.122e+05, MSE(e): 1.980e-04, MSE(pi1): 1.053e-02, MSE(pi2): 1.228e-04, MSE(pi3): 6.106e-03\n",
      "Epoch 18300, Train loss: 2.664e+03, Test loss: 6.121e+05, MSE(e): 1.948e-04, MSE(pi1): 1.021e-02, MSE(pi2): 1.207e-04, MSE(pi3): 6.136e-03\n",
      "Epoch 18400, Train loss: 2.663e+03, Test loss: 6.121e+05, MSE(e): 1.947e-04, MSE(pi1): 9.926e-03, MSE(pi2): 1.199e-04, MSE(pi3): 6.169e-03\n",
      "Epoch 18500, Train loss: 2.618e+03, Test loss: 6.121e+05, MSE(e): 1.902e-04, MSE(pi1): 1.019e-02, MSE(pi2): 1.178e-04, MSE(pi3): 6.135e-03\n",
      "Epoch 18600, Train loss: 2.595e+03, Test loss: 6.121e+05, MSE(e): 1.879e-04, MSE(pi1): 1.023e-02, MSE(pi2): 1.164e-04, MSE(pi3): 6.129e-03\n",
      "Epoch 18700, Train loss: 2.581e+03, Test loss: 6.115e+05, MSE(e): 1.865e-04, MSE(pi1): 1.025e-02, MSE(pi2): 1.151e-04, MSE(pi3): 6.134e-03\n",
      "Epoch 18800, Train loss: 2.550e+03, Test loss: 6.122e+05, MSE(e): 1.835e-04, MSE(pi1): 1.015e-02, MSE(pi2): 1.135e-04, MSE(pi3): 6.133e-03\n",
      "Epoch 18900, Train loss: 2.529e+03, Test loss: 6.120e+05, MSE(e): 1.814e-04, MSE(pi1): 1.018e-02, MSE(pi2): 1.122e-04, MSE(pi3): 6.129e-03\n",
      "Epoch 19000, Train loss: 3.325e+03, Test loss: 6.070e+05, MSE(e): 2.606e-04, MSE(pi1): 8.950e-03, MSE(pi2): 1.430e-04, MSE(pi3): 6.296e-03\n",
      "Epoch 19100, Train loss: 2.487e+03, Test loss: 6.124e+05, MSE(e): 1.773e-04, MSE(pi1): 1.011e-02, MSE(pi2): 1.095e-04, MSE(pi3): 6.132e-03\n",
      "Epoch 19200, Train loss: 2.560e+03, Test loss: 6.085e+05, MSE(e): 1.839e-04, MSE(pi1): 1.097e-02, MSE(pi2): 1.113e-04, MSE(pi3): 6.119e-03\n",
      "Epoch 19300, Train loss: 2.448e+03, Test loss: 6.127e+05, MSE(e): 1.734e-04, MSE(pi1): 1.011e-02, MSE(pi2): 1.071e-04, MSE(pi3): 6.128e-03\n",
      "Epoch 19400, Train loss: 2.429e+03, Test loss: 6.127e+05, MSE(e): 1.715e-04, MSE(pi1): 1.014e-02, MSE(pi2): 1.058e-04, MSE(pi3): 6.126e-03\n",
      "Epoch 19500, Train loss: 2.412e+03, Test loss: 6.128e+05, MSE(e): 1.698e-04, MSE(pi1): 9.990e-03, MSE(pi2): 1.047e-04, MSE(pi3): 6.138e-03\n",
      "Epoch 19600, Train loss: 2.392e+03, Test loss: 6.130e+05, MSE(e): 1.678e-04, MSE(pi1): 1.008e-02, MSE(pi2): 1.035e-04, MSE(pi3): 6.126e-03\n",
      "Epoch 19700, Train loss: 2.374e+03, Test loss: 6.145e+05, MSE(e): 1.660e-04, MSE(pi1): 1.007e-02, MSE(pi2): 1.024e-04, MSE(pi3): 6.125e-03\n",
      "Epoch 19800, Train loss: 2.356e+03, Test loss: 6.134e+05, MSE(e): 1.643e-04, MSE(pi1): 1.006e-02, MSE(pi2): 1.013e-04, MSE(pi3): 6.125e-03\n",
      "Epoch 19900, Train loss: 2.339e+03, Test loss: 6.135e+05, MSE(e): 1.626e-04, MSE(pi1): 1.002e-02, MSE(pi2): 1.002e-04, MSE(pi3): 6.130e-03\n",
      "Epoch 20000, Train loss: 2.322e+03, Test loss: 6.135e+05, MSE(e): 1.609e-04, MSE(pi1): 1.006e-02, MSE(pi2): 9.914e-05, MSE(pi3): 6.123e-03\n",
      "Epoch 20100, Train loss: 2.306e+03, Test loss: 6.138e+05, MSE(e): 1.593e-04, MSE(pi1): 1.025e-02, MSE(pi2): 9.813e-05, MSE(pi3): 6.106e-03\n",
      "Epoch 20200, Train loss: 2.290e+03, Test loss: 6.143e+05, MSE(e): 1.577e-04, MSE(pi1): 1.010e-02, MSE(pi2): 9.714e-05, MSE(pi3): 6.115e-03\n",
      "Epoch 20300, Train loss: 2.704e+03, Test loss: 6.190e+05, MSE(e): 1.991e-04, MSE(pi1): 1.113e-02, MSE(pi2): 1.147e-04, MSE(pi3): 6.020e-03\n",
      "Epoch 20400, Train loss: 2.258e+03, Test loss: 6.143e+05, MSE(e): 1.545e-04, MSE(pi1): 1.033e-02, MSE(pi2): 9.509e-05, MSE(pi3): 6.101e-03\n",
      "Epoch 20500, Train loss: 2.246e+03, Test loss: 6.146e+05, MSE(e): 1.534e-04, MSE(pi1): 1.015e-02, MSE(pi2): 9.439e-05, MSE(pi3): 6.104e-03\n",
      "Epoch 20600, Train loss: 2.226e+03, Test loss: 6.147e+05, MSE(e): 1.514e-04, MSE(pi1): 1.000e-02, MSE(pi2): 9.314e-05, MSE(pi3): 6.120e-03\n",
      "Epoch 20700, Train loss: 2.213e+03, Test loss: 6.147e+05, MSE(e): 1.501e-04, MSE(pi1): 9.965e-03, MSE(pi2): 9.223e-05, MSE(pi3): 6.124e-03\n",
      "Epoch 20800, Train loss: 2.197e+03, Test loss: 6.149e+05, MSE(e): 1.485e-04, MSE(pi1): 9.959e-03, MSE(pi2): 9.129e-05, MSE(pi3): 6.123e-03\n",
      "Epoch 20900, Train loss: 2.182e+03, Test loss: 6.154e+05, MSE(e): 1.471e-04, MSE(pi1): 9.934e-03, MSE(pi2): 9.041e-05, MSE(pi3): 6.124e-03\n",
      "Epoch 21000, Train loss: 2.176e+03, Test loss: 6.152e+05, MSE(e): 1.460e-04, MSE(pi1): 1.021e-02, MSE(pi2): 8.958e-05, MSE(pi3): 6.142e-03\n",
      "Epoch 21100, Train loss: 2.154e+03, Test loss: 6.159e+05, MSE(e): 1.443e-04, MSE(pi1): 9.974e-03, MSE(pi2): 8.868e-05, MSE(pi3): 6.117e-03\n",
      "Epoch 21200, Train loss: 2.177e+03, Test loss: 6.154e+05, MSE(e): 1.464e-04, MSE(pi1): 9.621e-03, MSE(pi2): 8.899e-05, MSE(pi3): 6.168e-03\n",
      "Epoch 21300, Train loss: 2.134e+03, Test loss: 6.163e+05, MSE(e): 1.416e-04, MSE(pi1): 1.047e-02, MSE(pi2): 8.698e-05, MSE(pi3): 6.129e-03\n",
      "Epoch 21400, Train loss: 2.115e+03, Test loss: 6.164e+05, MSE(e): 1.404e-04, MSE(pi1): 1.001e-02, MSE(pi2): 8.619e-05, MSE(pi3): 6.112e-03\n",
      "Epoch 21500, Train loss: 2.259e+03, Test loss: 6.159e+05, MSE(e): 1.544e-04, MSE(pi1): 1.182e-02, MSE(pi2): 9.260e-05, MSE(pi3): 5.970e-03\n",
      "Epoch 21600, Train loss: 2.089e+03, Test loss: 6.170e+05, MSE(e): 1.378e-04, MSE(pi1): 9.940e-03, MSE(pi2): 8.461e-05, MSE(pi3): 6.115e-03\n",
      "Epoch 21700, Train loss: 2.325e+03, Test loss: 6.138e+05, MSE(e): 1.612e-04, MSE(pi1): 9.347e-03, MSE(pi2): 9.332e-05, MSE(pi3): 6.193e-03\n",
      "Epoch 21800, Train loss: 2.064e+03, Test loss: 6.175e+05, MSE(e): 1.353e-04, MSE(pi1): 9.945e-03, MSE(pi2): 8.308e-05, MSE(pi3): 6.113e-03\n",
      "Epoch 21900, Train loss: 2.055e+03, Test loss: 6.181e+05, MSE(e): 1.344e-04, MSE(pi1): 1.001e-02, MSE(pi2): 8.251e-05, MSE(pi3): 6.104e-03\n",
      "Epoch 22000, Train loss: 2.231e+03, Test loss: 6.214e+05, MSE(e): 1.519e-04, MSE(pi1): 1.084e-02, MSE(pi2): 9.003e-05, MSE(pi3): 6.033e-03\n",
      "Epoch 22100, Train loss: 2.029e+03, Test loss: 6.182e+05, MSE(e): 1.318e-04, MSE(pi1): 9.928e-03, MSE(pi2): 8.088e-05, MSE(pi3): 6.112e-03\n",
      "Epoch 22200, Train loss: 2.018e+03, Test loss: 6.185e+05, MSE(e): 1.307e-04, MSE(pi1): 9.883e-03, MSE(pi2): 8.015e-05, MSE(pi3): 6.116e-03\n",
      "Epoch 22300, Train loss: 2.007e+03, Test loss: 6.185e+05, MSE(e): 1.297e-04, MSE(pi1): 1.015e-02, MSE(pi2): 7.957e-05, MSE(pi3): 6.089e-03\n",
      "Epoch 22400, Train loss: 1.995e+03, Test loss: 6.191e+05, MSE(e): 1.285e-04, MSE(pi1): 9.899e-03, MSE(pi2): 7.881e-05, MSE(pi3): 6.112e-03\n",
      "Epoch 22500, Train loss: 1.984e+03, Test loss: 6.192e+05, MSE(e): 1.274e-04, MSE(pi1): 9.893e-03, MSE(pi2): 7.813e-05, MSE(pi3): 6.112e-03\n",
      "Epoch 22600, Train loss: 1.986e+03, Test loss: 6.190e+05, MSE(e): 1.275e-04, MSE(pi1): 9.654e-03, MSE(pi2): 7.779e-05, MSE(pi3): 6.141e-03\n",
      "Epoch 22700, Train loss: 1.963e+03, Test loss: 6.196e+05, MSE(e): 1.253e-04, MSE(pi1): 9.889e-03, MSE(pi2): 7.683e-05, MSE(pi3): 6.111e-03\n",
      "Epoch 22800, Train loss: 2.004e+03, Test loss: 6.213e+05, MSE(e): 1.294e-04, MSE(pi1): 1.041e-02, MSE(pi2): 7.862e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 22900, Train loss: 1.943e+03, Test loss: 6.202e+05, MSE(e): 1.233e-04, MSE(pi1): 9.879e-03, MSE(pi2): 7.560e-05, MSE(pi3): 6.110e-03\n",
      "Epoch 23000, Train loss: 1.934e+03, Test loss: 6.202e+05, MSE(e): 1.224e-04, MSE(pi1): 9.841e-03, MSE(pi2): 7.497e-05, MSE(pi3): 6.114e-03\n",
      "Epoch 23100, Train loss: 1.925e+03, Test loss: 6.209e+05, MSE(e): 1.215e-04, MSE(pi1): 1.000e-02, MSE(pi2): 7.451e-05, MSE(pi3): 6.096e-03\n",
      "Epoch 23200, Train loss: 4.617e+03, Test loss: 6.322e+05, MSE(e): 3.903e-04, MSE(pi1): 1.259e-02, MSE(pi2): 1.871e-04, MSE(pi3): 5.877e-03\n",
      "Epoch 23300, Train loss: 1.904e+03, Test loss: 6.213e+05, MSE(e): 1.195e-04, MSE(pi1): 9.878e-03, MSE(pi2): 7.322e-05, MSE(pi3): 6.107e-03\n",
      "Epoch 23400, Train loss: 1.905e+03, Test loss: 6.216e+05, MSE(e): 1.191e-04, MSE(pi1): 9.428e-03, MSE(pi2): 7.293e-05, MSE(pi3): 6.193e-03\n",
      "Epoch 23500, Train loss: 1.886e+03, Test loss: 6.213e+05, MSE(e): 1.177e-04, MSE(pi1): 9.891e-03, MSE(pi2): 7.212e-05, MSE(pi3): 6.104e-03\n",
      "Epoch 23600, Train loss: 1.877e+03, Test loss: 6.219e+05, MSE(e): 1.167e-04, MSE(pi1): 9.864e-03, MSE(pi2): 7.150e-05, MSE(pi3): 6.107e-03\n",
      "Epoch 23700, Train loss: 1.869e+03, Test loss: 6.221e+05, MSE(e): 1.160e-04, MSE(pi1): 9.736e-03, MSE(pi2): 7.096e-05, MSE(pi3): 6.121e-03\n",
      "Epoch 23800, Train loss: 1.868e+03, Test loss: 6.225e+05, MSE(e): 1.150e-04, MSE(pi1): 1.061e-02, MSE(pi2): 7.043e-05, MSE(pi3): 6.115e-03\n",
      "Epoch 23900, Train loss: 1.850e+03, Test loss: 6.228e+05, MSE(e): 1.141e-04, MSE(pi1): 9.862e-03, MSE(pi2): 6.989e-05, MSE(pi3): 6.105e-03\n",
      "Epoch 24000, Train loss: 1.850e+03, Test loss: 6.222e+05, MSE(e): 1.141e-04, MSE(pi1): 9.860e-03, MSE(pi2): 6.958e-05, MSE(pi3): 6.110e-03\n",
      "Epoch 24100, Train loss: 1.833e+03, Test loss: 6.232e+05, MSE(e): 1.124e-04, MSE(pi1): 9.828e-03, MSE(pi2): 6.883e-05, MSE(pi3): 6.108e-03\n",
      "Epoch 24200, Train loss: 1.825e+03, Test loss: 6.233e+05, MSE(e): 1.116e-04, MSE(pi1): 9.831e-03, MSE(pi2): 6.832e-05, MSE(pi3): 6.107e-03\n",
      "Epoch 24300, Train loss: 1.817e+03, Test loss: 6.236e+05, MSE(e): 1.108e-04, MSE(pi1): 9.805e-03, MSE(pi2): 6.783e-05, MSE(pi3): 6.109e-03\n",
      "Epoch 24400, Train loss: 1.809e+03, Test loss: 6.239e+05, MSE(e): 1.100e-04, MSE(pi1): 9.824e-03, MSE(pi2): 6.734e-05, MSE(pi3): 6.106e-03\n",
      "Epoch 24500, Train loss: 1.801e+03, Test loss: 6.246e+05, MSE(e): 1.092e-04, MSE(pi1): 9.951e-03, MSE(pi2): 6.690e-05, MSE(pi3): 6.092e-03\n",
      "Epoch 24600, Train loss: 1.793e+03, Test loss: 6.244e+05, MSE(e): 1.084e-04, MSE(pi1): 9.823e-03, MSE(pi2): 6.638e-05, MSE(pi3): 6.105e-03\n",
      "Epoch 24700, Train loss: 1.798e+03, Test loss: 6.240e+05, MSE(e): 1.089e-04, MSE(pi1): 9.722e-03, MSE(pi2): 6.627e-05, MSE(pi3): 6.118e-03\n",
      "Epoch 24800, Train loss: 1.787e+03, Test loss: 6.248e+05, MSE(e): 1.077e-04, MSE(pi1): 1.078e-02, MSE(pi2): 6.620e-05, MSE(pi3): 6.020e-03\n",
      "Epoch 24900, Train loss: 1.770e+03, Test loss: 6.253e+05, MSE(e): 1.061e-04, MSE(pi1): 9.817e-03, MSE(pi2): 6.499e-05, MSE(pi3): 6.103e-03\n",
      "Epoch 25000, Train loss: 1.810e+03, Test loss: 6.243e+05, MSE(e): 1.099e-04, MSE(pi1): 9.619e-03, MSE(pi2): 6.608e-05, MSE(pi3): 6.145e-03\n",
      "Epoch 25100, Train loss: 1.759e+03, Test loss: 6.255e+05, MSE(e): 1.047e-04, MSE(pi1): 1.053e-02, MSE(pi2): 6.415e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 25200, Train loss: 1.748e+03, Test loss: 6.259e+05, MSE(e): 1.039e-04, MSE(pi1): 9.848e-03, MSE(pi2): 6.362e-05, MSE(pi3): 6.100e-03\n",
      "Epoch 25300, Train loss: 1.750e+03, Test loss: 6.254e+05, MSE(e): 1.041e-04, MSE(pi1): 9.849e-03, MSE(pi2): 6.344e-05, MSE(pi3): 6.104e-03\n",
      "Epoch 25400, Train loss: 1.733e+03, Test loss: 6.265e+05, MSE(e): 1.025e-04, MSE(pi1): 9.835e-03, MSE(pi2): 6.277e-05, MSE(pi3): 6.099e-03\n",
      "Epoch 25500, Train loss: 1.734e+03, Test loss: 6.267e+05, MSE(e): 1.019e-04, MSE(pi1): 1.055e-02, MSE(pi2): 6.237e-05, MSE(pi3): 6.095e-03\n",
      "Epoch 25600, Train loss: 1.720e+03, Test loss: 6.268e+05, MSE(e): 1.012e-04, MSE(pi1): 9.744e-03, MSE(pi2): 6.191e-05, MSE(pi3): 6.108e-03\n",
      "Epoch 25700, Train loss: 1.713e+03, Test loss: 6.271e+05, MSE(e): 1.005e-04, MSE(pi1): 9.802e-03, MSE(pi2): 6.152e-05, MSE(pi3): 6.101e-03\n",
      "Epoch 25800, Train loss: 1.706e+03, Test loss: 6.275e+05, MSE(e): 9.979e-05, MSE(pi1): 9.778e-03, MSE(pi2): 6.110e-05, MSE(pi3): 6.105e-03\n",
      "Epoch 25900, Train loss: 1.699e+03, Test loss: 6.276e+05, MSE(e): 9.913e-05, MSE(pi1): 9.793e-03, MSE(pi2): 6.071e-05, MSE(pi3): 6.101e-03\n",
      "Epoch 26000, Train loss: 1.730e+03, Test loss: 6.286e+05, MSE(e): 1.021e-04, MSE(pi1): 1.043e-02, MSE(pi2): 6.214e-05, MSE(pi3): 6.043e-03\n",
      "Epoch 26100, Train loss: 1.687e+03, Test loss: 6.281e+05, MSE(e): 9.786e-05, MSE(pi1): 9.788e-03, MSE(pi2): 5.994e-05, MSE(pi3): 6.100e-03\n",
      "Epoch 26200, Train loss: 1.730e+03, Test loss: 6.296e+05, MSE(e): 1.010e-04, MSE(pi1): 1.151e-02, MSE(pi2): 6.138e-05, MSE(pi3): 6.048e-03\n",
      "Epoch 26300, Train loss: 1.674e+03, Test loss: 6.287e+05, MSE(e): 9.664e-05, MSE(pi1): 9.781e-03, MSE(pi2): 5.920e-05, MSE(pi3): 6.100e-03\n",
      "Epoch 26400, Train loss: 1.668e+03, Test loss: 6.287e+05, MSE(e): 9.601e-05, MSE(pi1): 9.774e-03, MSE(pi2): 5.880e-05, MSE(pi3): 6.101e-03\n",
      "Epoch 26500, Train loss: 1.933e+03, Test loss: 6.299e+05, MSE(e): 1.226e-04, MSE(pi1): 1.064e-02, MSE(pi2): 7.033e-05, MSE(pi3): 6.007e-03\n",
      "Epoch 26600, Train loss: 1.656e+03, Test loss: 6.292e+05, MSE(e): 9.480e-05, MSE(pi1): 9.778e-03, MSE(pi2): 5.807e-05, MSE(pi3): 6.099e-03\n",
      "Epoch 26700, Train loss: 1.650e+03, Test loss: 6.295e+05, MSE(e): 9.421e-05, MSE(pi1): 9.656e-03, MSE(pi2): 5.771e-05, MSE(pi3): 6.115e-03\n",
      "Epoch 26800, Train loss: 1.647e+03, Test loss: 6.294e+05, MSE(e): 9.387e-05, MSE(pi1): 9.703e-03, MSE(pi2): 5.739e-05, MSE(pi3): 6.107e-03\n",
      "Epoch 26900, Train loss: 1.642e+03, Test loss: 6.301e+05, MSE(e): 9.320e-05, MSE(pi1): 9.559e-03, MSE(pi2): 5.708e-05, MSE(pi3): 6.147e-03\n",
      "Epoch 27000, Train loss: 1.633e+03, Test loss: 6.303e+05, MSE(e): 9.258e-05, MSE(pi1): 9.802e-03, MSE(pi2): 5.675e-05, MSE(pi3): 6.094e-03\n",
      "Epoch 27100, Train loss: 1.682e+03, Test loss: 6.286e+05, MSE(e): 9.724e-05, MSE(pi1): 9.491e-03, MSE(pi2): 5.820e-05, MSE(pi3): 6.151e-03\n",
      "Epoch 27200, Train loss: 1.621e+03, Test loss: 6.306e+05, MSE(e): 9.136e-05, MSE(pi1): 9.787e-03, MSE(pi2): 5.600e-05, MSE(pi3): 6.098e-03\n",
      "Epoch 27300, Train loss: 1.616e+03, Test loss: 6.309e+05, MSE(e): 9.081e-05, MSE(pi1): 9.780e-03, MSE(pi2): 5.567e-05, MSE(pi3): 6.096e-03\n",
      "Epoch 27400, Train loss: 1.675e+03, Test loss: 6.290e+05, MSE(e): 9.669e-05, MSE(pi1): 9.697e-03, MSE(pi2): 5.770e-05, MSE(pi3): 6.111e-03\n",
      "Epoch 27500, Train loss: 1.604e+03, Test loss: 6.311e+05, MSE(e): 8.969e-05, MSE(pi1): 9.739e-03, MSE(pi2): 5.496e-05, MSE(pi3): 6.100e-03\n",
      "Epoch 27600, Train loss: 2.516e+03, Test loss: 6.263e+05, MSE(e): 1.803e-04, MSE(pi1): 8.606e-03, MSE(pi2): 9.090e-05, MSE(pi3): 6.267e-03\n",
      "Epoch 27700, Train loss: 1.594e+03, Test loss: 6.316e+05, MSE(e): 8.862e-05, MSE(pi1): 9.735e-03, MSE(pi2): 5.432e-05, MSE(pi3): 6.099e-03\n",
      "Epoch 27800, Train loss: 1.604e+03, Test loss: 6.309e+05, MSE(e): 8.966e-05, MSE(pi1): 9.677e-03, MSE(pi2): 5.450e-05, MSE(pi3): 6.108e-03\n",
      "Epoch 27900, Train loss: 1.583e+03, Test loss: 6.319e+05, MSE(e): 8.759e-05, MSE(pi1): 9.751e-03, MSE(pi2): 5.369e-05, MSE(pi3): 6.097e-03\n",
      "Epoch 28000, Train loss: 2.237e+03, Test loss: 6.280e+05, MSE(e): 1.523e-04, MSE(pi1): 8.578e-03, MSE(pi2): 7.929e-05, MSE(pi3): 6.282e-03\n",
      "Epoch 28100, Train loss: 1.573e+03, Test loss: 6.324e+05, MSE(e): 8.657e-05, MSE(pi1): 9.759e-03, MSE(pi2): 5.310e-05, MSE(pi3): 6.095e-03\n",
      "Epoch 28200, Train loss: 1.626e+03, Test loss: 6.311e+05, MSE(e): 9.178e-05, MSE(pi1): 9.339e-03, MSE(pi2): 5.482e-05, MSE(pi3): 6.151e-03\n",
      "Epoch 28300, Train loss: 1.563e+03, Test loss: 6.328e+05, MSE(e): 8.557e-05, MSE(pi1): 9.744e-03, MSE(pi2): 5.249e-05, MSE(pi3): 6.096e-03\n",
      "Epoch 28400, Train loss: 1.558e+03, Test loss: 6.327e+05, MSE(e): 8.507e-05, MSE(pi1): 9.726e-03, MSE(pi2): 5.219e-05, MSE(pi3): 6.097e-03\n",
      "Epoch 28500, Train loss: 1.787e+03, Test loss: 6.314e+05, MSE(e): 1.078e-04, MSE(pi1): 9.158e-03, MSE(pi2): 6.078e-05, MSE(pi3): 6.174e-03\n",
      "Epoch 28600, Train loss: 1.552e+03, Test loss: 6.336e+05, MSE(e): 8.435e-05, MSE(pi1): 9.349e-03, MSE(pi2): 5.173e-05, MSE(pi3): 6.149e-03\n",
      "Epoch 28700, Train loss: 1.544e+03, Test loss: 6.334e+05, MSE(e): 8.366e-05, MSE(pi1): 9.750e-03, MSE(pi2): 5.131e-05, MSE(pi3): 6.095e-03\n",
      "Epoch 28800, Train loss: 1.553e+03, Test loss: 6.342e+05, MSE(e): 8.363e-05, MSE(pi1): 9.713e-03, MSE(pi2): 5.129e-05, MSE(pi3): 6.191e-03\n",
      "Epoch 28900, Train loss: 1.536e+03, Test loss: 6.339e+05, MSE(e): 8.290e-05, MSE(pi1): 9.656e-03, MSE(pi2): 5.078e-05, MSE(pi3): 6.105e-03\n",
      "Epoch 29000, Train loss: 1.529e+03, Test loss: 6.342e+05, MSE(e): 8.225e-05, MSE(pi1): 9.727e-03, MSE(pi2): 5.050e-05, MSE(pi3): 6.095e-03\n",
      "Epoch 29100, Train loss: 1.534e+03, Test loss: 6.363e+05, MSE(e): 8.232e-05, MSE(pi1): 9.326e-03, MSE(pi2): 5.047e-05, MSE(pi3): 6.171e-03\n",
      "Epoch 29200, Train loss: 1.520e+03, Test loss: 6.345e+05, MSE(e): 8.135e-05, MSE(pi1): 9.736e-03, MSE(pi2): 4.997e-05, MSE(pi3): 6.093e-03\n",
      "Epoch 29300, Train loss: 1.539e+03, Test loss: 6.340e+05, MSE(e): 8.315e-05, MSE(pi1): 9.491e-03, MSE(pi2): 5.040e-05, MSE(pi3): 6.123e-03\n",
      "Epoch 29400, Train loss: 1.511e+03, Test loss: 6.349e+05, MSE(e): 8.046e-05, MSE(pi1): 9.705e-03, MSE(pi2): 4.943e-05, MSE(pi3): 6.096e-03\n",
      "Epoch 29500, Train loss: 1.507e+03, Test loss: 6.350e+05, MSE(e): 8.008e-05, MSE(pi1): 9.773e-03, MSE(pi2): 4.922e-05, MSE(pi3): 6.088e-03\n",
      "Epoch 29600, Train loss: 1.688e+03, Test loss: 6.331e+05, MSE(e): 9.797e-05, MSE(pi1): 9.263e-03, MSE(pi2): 5.585e-05, MSE(pi3): 6.158e-03\n",
      "Epoch 29700, Train loss: 1.498e+03, Test loss: 6.354e+05, MSE(e): 7.916e-05, MSE(pi1): 9.712e-03, MSE(pi2): 4.864e-05, MSE(pi3): 6.094e-03\n",
      "Epoch 29800, Train loss: 1.495e+03, Test loss: 6.356e+05, MSE(e): 7.882e-05, MSE(pi1): 9.607e-03, MSE(pi2): 4.837e-05, MSE(pi3): 6.106e-03\n",
      "Epoch 29900, Train loss: 2.038e+03, Test loss: 6.411e+05, MSE(e): 1.332e-04, MSE(pi1): 1.082e-02, MSE(pi2): 7.181e-05, MSE(pi3): 5.975e-03\n",
      "Epoch 30000, Train loss: 1.486e+03, Test loss: 6.360e+05, MSE(e): 7.791e-05, MSE(pi1): 9.722e-03, MSE(pi2): 4.791e-05, MSE(pi3): 6.092e-03\n",
      "Epoch 30100, Train loss: 1.483e+03, Test loss: 6.354e+05, MSE(e): 7.760e-05, MSE(pi1): 9.543e-03, MSE(pi2): 4.763e-05, MSE(pi3): 6.119e-03\n",
      "Epoch 30200, Train loss: 1.477e+03, Test loss: 6.362e+05, MSE(e): 7.708e-05, MSE(pi1): 9.724e-03, MSE(pi2): 4.740e-05, MSE(pi3): 6.091e-03\n",
      "Epoch 30300, Train loss: 1.474e+03, Test loss: 6.367e+05, MSE(e): 7.679e-05, MSE(pi1): 9.664e-03, MSE(pi2): 4.724e-05, MSE(pi3): 6.097e-03\n",
      "Epoch 30400, Train loss: 1.470e+03, Test loss: 6.368e+05, MSE(e): 7.642e-05, MSE(pi1): 9.745e-03, MSE(pi2): 4.703e-05, MSE(pi3): 6.088e-03\n",
      "Epoch 30500, Train loss: 1.465e+03, Test loss: 6.368e+05, MSE(e): 7.590e-05, MSE(pi1): 9.675e-03, MSE(pi2): 4.669e-05, MSE(pi3): 6.095e-03\n",
      "Epoch 30600, Train loss: 1.461e+03, Test loss: 6.368e+05, MSE(e): 7.551e-05, MSE(pi1): 9.672e-03, MSE(pi2): 4.645e-05, MSE(pi3): 6.096e-03\n",
      "Epoch 30700, Train loss: 1.458e+03, Test loss: 6.370e+05, MSE(e): 7.517e-05, MSE(pi1): 9.693e-03, MSE(pi2): 4.623e-05, MSE(pi3): 6.094e-03\n",
      "Epoch 30800, Train loss: 1.454e+03, Test loss: 6.372e+05, MSE(e): 7.474e-05, MSE(pi1): 9.699e-03, MSE(pi2): 4.601e-05, MSE(pi3): 6.092e-03\n",
      "Epoch 30900, Train loss: 1.459e+03, Test loss: 6.371e+05, MSE(e): 7.525e-05, MSE(pi1): 9.569e-03, MSE(pi2): 4.602e-05, MSE(pi3): 6.107e-03\n",
      "Epoch 31000, Train loss: 1.446e+03, Test loss: 6.375e+05, MSE(e): 7.399e-05, MSE(pi1): 9.696e-03, MSE(pi2): 4.556e-05, MSE(pi3): 6.092e-03\n",
      "Epoch 31100, Train loss: 1.491e+03, Test loss: 6.388e+05, MSE(e): 7.852e-05, MSE(pi1): 1.001e-02, MSE(pi2): 4.767e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 31200, Train loss: 1.439e+03, Test loss: 6.378e+05, MSE(e): 7.326e-05, MSE(pi1): 9.696e-03, MSE(pi2): 4.513e-05, MSE(pi3): 6.091e-03\n",
      "Epoch 31300, Train loss: 1.444e+03, Test loss: 6.369e+05, MSE(e): 7.359e-05, MSE(pi1): 1.003e-02, MSE(pi2): 4.514e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 31400, Train loss: 1.431e+03, Test loss: 6.382e+05, MSE(e): 7.254e-05, MSE(pi1): 9.695e-03, MSE(pi2): 4.470e-05, MSE(pi3): 6.091e-03\n",
      "Epoch 31500, Train loss: 1.429e+03, Test loss: 6.382e+05, MSE(e): 7.224e-05, MSE(pi1): 9.762e-03, MSE(pi2): 4.455e-05, MSE(pi3): 6.084e-03\n",
      "Epoch 31600, Train loss: 1.425e+03, Test loss: 6.386e+05, MSE(e): 7.187e-05, MSE(pi1): 9.718e-03, MSE(pi2): 4.432e-05, MSE(pi3): 6.087e-03\n",
      "Epoch 31700, Train loss: 1.421e+03, Test loss: 6.386e+05, MSE(e): 7.149e-05, MSE(pi1): 9.686e-03, MSE(pi2): 4.408e-05, MSE(pi3): 6.091e-03\n",
      "Epoch 31800, Train loss: 1.464e+03, Test loss: 6.401e+05, MSE(e): 7.555e-05, MSE(pi1): 1.006e-02, MSE(pi2): 4.599e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 31900, Train loss: 1.414e+03, Test loss: 6.388e+05, MSE(e): 7.081e-05, MSE(pi1): 9.657e-03, MSE(pi2): 4.365e-05, MSE(pi3): 6.093e-03\n",
      "Epoch 32000, Train loss: 1.485e+03, Test loss: 6.383e+05, MSE(e): 7.778e-05, MSE(pi1): 9.245e-03, MSE(pi2): 4.611e-05, MSE(pi3): 6.147e-03\n",
      "Epoch 32100, Train loss: 1.407e+03, Test loss: 6.392e+05, MSE(e): 7.012e-05, MSE(pi1): 9.680e-03, MSE(pi2): 4.327e-05, MSE(pi3): 6.090e-03\n",
      "Epoch 32200, Train loss: 2.038e+03, Test loss: 6.354e+05, MSE(e): 1.328e-04, MSE(pi1): 9.271e-03, MSE(pi2): 6.803e-05, MSE(pi3): 6.172e-03\n",
      "Epoch 32300, Train loss: 1.400e+03, Test loss: 6.394e+05, MSE(e): 6.945e-05, MSE(pi1): 9.667e-03, MSE(pi2): 4.286e-05, MSE(pi3): 6.091e-03\n",
      "Epoch 32400, Train loss: 1.407e+03, Test loss: 6.389e+05, MSE(e): 7.007e-05, MSE(pi1): 9.986e-03, MSE(pi2): 4.304e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 32500, Train loss: 1.394e+03, Test loss: 6.397e+05, MSE(e): 6.879e-05, MSE(pi1): 9.682e-03, MSE(pi2): 4.248e-05, MSE(pi3): 6.089e-03\n",
      "Epoch 32600, Train loss: 1.391e+03, Test loss: 6.399e+05, MSE(e): 6.852e-05, MSE(pi1): 9.713e-03, MSE(pi2): 4.234e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 32700, Train loss: 1.387e+03, Test loss: 6.399e+05, MSE(e): 6.815e-05, MSE(pi1): 9.674e-03, MSE(pi2): 4.209e-05, MSE(pi3): 6.089e-03\n",
      "Epoch 32800, Train loss: 1.412e+03, Test loss: 6.395e+05, MSE(e): 7.056e-05, MSE(pi1): 9.421e-03, MSE(pi2): 4.280e-05, MSE(pi3): 6.120e-03\n",
      "Epoch 32900, Train loss: 1.381e+03, Test loss: 6.402e+05, MSE(e): 6.753e-05, MSE(pi1): 9.675e-03, MSE(pi2): 4.173e-05, MSE(pi3): 6.089e-03\n",
      "Epoch 33000, Train loss: 1.381e+03, Test loss: 6.406e+05, MSE(e): 6.749e-05, MSE(pi1): 9.398e-03, MSE(pi2): 4.169e-05, MSE(pi3): 6.120e-03\n",
      "Epoch 33100, Train loss: 1.375e+03, Test loss: 6.405e+05, MSE(e): 6.694e-05, MSE(pi1): 9.715e-03, MSE(pi2): 4.140e-05, MSE(pi3): 6.084e-03\n",
      "Epoch 33200, Train loss: 1.393e+03, Test loss: 6.398e+05, MSE(e): 6.851e-05, MSE(pi1): 9.678e-03, MSE(pi2): 4.180e-05, MSE(pi3): 6.115e-03\n",
      "Epoch 33300, Train loss: 1.368e+03, Test loss: 6.407e+05, MSE(e): 6.629e-05, MSE(pi1): 9.668e-03, MSE(pi2): 4.100e-05, MSE(pi3): 6.088e-03\n",
      "Epoch 33400, Train loss: 1.477e+03, Test loss: 6.398e+05, MSE(e): 7.698e-05, MSE(pi1): 9.367e-03, MSE(pi2): 4.486e-05, MSE(pi3): 6.133e-03\n",
      "Epoch 33500, Train loss: 1.362e+03, Test loss: 6.410e+05, MSE(e): 6.570e-05, MSE(pi1): 9.665e-03, MSE(pi2): 4.064e-05, MSE(pi3): 6.088e-03\n",
      "Epoch 33600, Train loss: 1.360e+03, Test loss: 6.410e+05, MSE(e): 6.540e-05, MSE(pi1): 9.550e-03, MSE(pi2): 4.046e-05, MSE(pi3): 6.104e-03\n",
      "Epoch 33700, Train loss: 1.360e+03, Test loss: 6.409e+05, MSE(e): 6.543e-05, MSE(pi1): 9.731e-03, MSE(pi2): 4.038e-05, MSE(pi3): 6.082e-03\n",
      "Epoch 33800, Train loss: 1.354e+03, Test loss: 6.413e+05, MSE(e): 6.482e-05, MSE(pi1): 9.661e-03, MSE(pi2): 4.013e-05, MSE(pi3): 6.088e-03\n",
      "Epoch 33900, Train loss: 1.354e+03, Test loss: 6.413e+05, MSE(e): 6.487e-05, MSE(pi1): 9.645e-03, MSE(pi2): 4.002e-05, MSE(pi3): 6.091e-03\n",
      "Epoch 34000, Train loss: 1.360e+03, Test loss: 6.409e+05, MSE(e): 6.539e-05, MSE(pi1): 9.532e-03, MSE(pi2): 4.011e-05, MSE(pi3): 6.103e-03\n",
      "Epoch 34100, Train loss: 1.345e+03, Test loss: 6.417e+05, MSE(e): 6.395e-05, MSE(pi1): 9.660e-03, MSE(pi2): 3.962e-05, MSE(pi3): 6.087e-03\n",
      "Epoch 34200, Train loss: 1.347e+03, Test loss: 6.437e+05, MSE(e): 6.420e-05, MSE(pi1): 1.000e-02, MSE(pi2): 3.981e-05, MSE(pi3): 6.050e-03\n",
      "Epoch 34300, Train loss: 1.339e+03, Test loss: 6.419e+05, MSE(e): 6.340e-05, MSE(pi1): 9.661e-03, MSE(pi2): 3.930e-05, MSE(pi3): 6.086e-03\n",
      "Epoch 34400, Train loss: 1.375e+03, Test loss: 6.432e+05, MSE(e): 6.663e-05, MSE(pi1): 1.000e-02, MSE(pi2): 4.078e-05, MSE(pi3): 6.087e-03\n",
      "Epoch 34500, Train loss: 1.334e+03, Test loss: 6.421e+05, MSE(e): 6.285e-05, MSE(pi1): 9.634e-03, MSE(pi2): 3.895e-05, MSE(pi3): 6.089e-03\n",
      "Epoch 34600, Train loss: 1.331e+03, Test loss: 6.422e+05, MSE(e): 6.257e-05, MSE(pi1): 9.668e-03, MSE(pi2): 3.881e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 34700, Train loss: 1.329e+03, Test loss: 6.425e+05, MSE(e): 6.237e-05, MSE(pi1): 9.678e-03, MSE(pi2): 3.871e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 34800, Train loss: 1.331e+03, Test loss: 6.424e+05, MSE(e): 6.207e-05, MSE(pi1): 1.006e-02, MSE(pi2): 3.849e-05, MSE(pi3): 6.095e-03\n",
      "Epoch 34900, Train loss: 1.324e+03, Test loss: 6.425e+05, MSE(e): 6.185e-05, MSE(pi1): 9.699e-03, MSE(pi2): 3.840e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 35000, Train loss: 1.997e+03, Test loss: 6.389e+05, MSE(e): 1.288e-04, MSE(pi1): 9.030e-03, MSE(pi2): 6.483e-05, MSE(pi3): 6.187e-03\n",
      "Epoch 35100, Train loss: 1.317e+03, Test loss: 6.427e+05, MSE(e): 6.124e-05, MSE(pi1): 9.625e-03, MSE(pi2): 3.802e-05, MSE(pi3): 6.088e-03\n",
      "Epoch 35200, Train loss: 1.810e+03, Test loss: 6.399e+05, MSE(e): 1.102e-04, MSE(pi1): 9.036e-03, MSE(pi2): 5.722e-05, MSE(pi3): 6.177e-03\n",
      "Epoch 35300, Train loss: 1.312e+03, Test loss: 6.429e+05, MSE(e): 6.072e-05, MSE(pi1): 9.644e-03, MSE(pi2): 3.771e-05, MSE(pi3): 6.086e-03\n",
      "Epoch 35400, Train loss: 1.456e+03, Test loss: 6.418e+05, MSE(e): 7.468e-05, MSE(pi1): 9.505e-03, MSE(pi2): 4.292e-05, MSE(pi3): 6.138e-03\n",
      "Epoch 35500, Train loss: 1.307e+03, Test loss: 6.431e+05, MSE(e): 6.021e-05, MSE(pi1): 9.652e-03, MSE(pi2): 3.742e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 35600, Train loss: 1.391e+03, Test loss: 6.449e+05, MSE(e): 6.866e-05, MSE(pi1): 1.007e-02, MSE(pi2): 4.127e-05, MSE(pi3): 6.037e-03\n",
      "Epoch 35700, Train loss: 1.302e+03, Test loss: 6.433e+05, MSE(e): 5.971e-05, MSE(pi1): 9.644e-03, MSE(pi2): 3.712e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 35800, Train loss: 1.372e+03, Test loss: 6.456e+05, MSE(e): 6.673e-05, MSE(pi1): 9.890e-03, MSE(pi2): 4.031e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 35900, Train loss: 1.297e+03, Test loss: 6.435e+05, MSE(e): 5.921e-05, MSE(pi1): 9.617e-03, MSE(pi2): 3.683e-05, MSE(pi3): 6.089e-03\n",
      "Epoch 36000, Train loss: 2.363e+03, Test loss: 6.396e+05, MSE(e): 1.650e-04, MSE(pi1): 8.920e-03, MSE(pi2): 7.916e-05, MSE(pi3): 6.234e-03\n",
      "Epoch 36100, Train loss: 1.292e+03, Test loss: 6.437e+05, MSE(e): 5.873e-05, MSE(pi1): 9.637e-03, MSE(pi2): 3.655e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 36200, Train loss: 1.684e+03, Test loss: 6.455e+05, MSE(e): 9.783e-05, MSE(pi1): 1.016e-02, MSE(pi2): 5.350e-05, MSE(pi3): 6.038e-03\n",
      "Epoch 36300, Train loss: 1.287e+03, Test loss: 6.439e+05, MSE(e): 5.825e-05, MSE(pi1): 9.655e-03, MSE(pi2): 3.627e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 36400, Train loss: 1.292e+03, Test loss: 6.441e+05, MSE(e): 5.864e-05, MSE(pi1): 9.506e-03, MSE(pi2): 3.627e-05, MSE(pi3): 6.101e-03\n",
      "Epoch 36500, Train loss: 1.283e+03, Test loss: 6.440e+05, MSE(e): 5.778e-05, MSE(pi1): 9.733e-03, MSE(pi2): 3.598e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 36600, Train loss: 1.281e+03, Test loss: 6.443e+05, MSE(e): 5.764e-05, MSE(pi1): 9.643e-03, MSE(pi2): 3.592e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 36700, Train loss: 1.278e+03, Test loss: 6.445e+05, MSE(e): 5.732e-05, MSE(pi1): 9.506e-03, MSE(pi2): 3.568e-05, MSE(pi3): 6.099e-03\n",
      "Epoch 36800, Train loss: 1.281e+03, Test loss: 6.449e+05, MSE(e): 5.735e-05, MSE(pi1): 9.624e-03, MSE(pi2): 3.572e-05, MSE(pi3): 6.117e-03\n",
      "Epoch 36900, Train loss: 1.273e+03, Test loss: 6.444e+05, MSE(e): 5.685e-05, MSE(pi1): 9.607e-03, MSE(pi2): 3.543e-05, MSE(pi3): 6.087e-03\n",
      "Epoch 37000, Train loss: 1.271e+03, Test loss: 6.445e+05, MSE(e): 5.663e-05, MSE(pi1): 9.633e-03, MSE(pi2): 3.531e-05, MSE(pi3): 6.084e-03\n",
      "Epoch 37100, Train loss: 1.467e+03, Test loss: 6.429e+05, MSE(e): 7.570e-05, MSE(pi1): 9.213e-03, MSE(pi2): 4.256e-05, MSE(pi3): 6.178e-03\n",
      "Epoch 37200, Train loss: 1.267e+03, Test loss: 6.447e+05, MSE(e): 5.619e-05, MSE(pi1): 9.632e-03, MSE(pi2): 3.505e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 37300, Train loss: 1.543e+03, Test loss: 6.422e+05, MSE(e): 8.353e-05, MSE(pi1): 9.449e-03, MSE(pi2): 4.562e-05, MSE(pi3): 6.129e-03\n",
      "Epoch 37400, Train loss: 1.262e+03, Test loss: 6.448e+05, MSE(e): 5.574e-05, MSE(pi1): 9.618e-03, MSE(pi2): 3.478e-05, MSE(pi3): 6.084e-03\n",
      "Epoch 37500, Train loss: 1.265e+03, Test loss: 6.451e+05, MSE(e): 5.601e-05, MSE(pi1): 9.510e-03, MSE(pi2): 3.476e-05, MSE(pi3): 6.098e-03\n",
      "Epoch 37600, Train loss: 1.264e+03, Test loss: 6.446e+05, MSE(e): 5.555e-05, MSE(pi1): 1.066e-02, MSE(pi2): 3.476e-05, MSE(pi3): 6.024e-03\n",
      "Epoch 37700, Train loss: 1.263e+03, Test loss: 6.454e+05, MSE(e): 5.582e-05, MSE(pi1): 9.708e-03, MSE(pi2): 3.482e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 37800, Train loss: 1.255e+03, Test loss: 6.449e+05, MSE(e): 5.506e-05, MSE(pi1): 9.559e-03, MSE(pi2): 3.429e-05, MSE(pi3): 6.091e-03\n",
      "Epoch 37900, Train loss: 1.255e+03, Test loss: 6.455e+05, MSE(e): 5.476e-05, MSE(pi1): 9.433e-03, MSE(pi2): 3.417e-05, MSE(pi3): 6.131e-03\n",
      "Epoch 38000, Train loss: 1.252e+03, Test loss: 6.451e+05, MSE(e): 5.473e-05, MSE(pi1): 9.561e-03, MSE(pi2): 3.407e-05, MSE(pi3): 6.090e-03\n",
      "Epoch 38100, Train loss: 1.284e+03, Test loss: 6.466e+05, MSE(e): 5.802e-05, MSE(pi1): 9.785e-03, MSE(pi2): 3.571e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 38200, Train loss: 1.249e+03, Test loss: 6.458e+05, MSE(e): 5.434e-05, MSE(pi1): 9.202e-03, MSE(pi2): 3.394e-05, MSE(pi3): 6.134e-03\n",
      "Epoch 38300, Train loss: 1.243e+03, Test loss: 6.458e+05, MSE(e): 5.386e-05, MSE(pi1): 9.646e-03, MSE(pi2): 3.370e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 38400, Train loss: 1.296e+03, Test loss: 6.468e+05, MSE(e): 5.637e-05, MSE(pi1): 1.045e-02, MSE(pi2): 3.531e-05, MSE(pi3): 6.280e-03\n",
      "Epoch 38500, Train loss: 1.239e+03, Test loss: 6.457e+05, MSE(e): 5.343e-05, MSE(pi1): 9.592e-03, MSE(pi2): 3.341e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 38600, Train loss: 1.373e+03, Test loss: 6.478e+05, MSE(e): 6.696e-05, MSE(pi1): 1.009e-02, MSE(pi2): 3.948e-05, MSE(pi3): 6.028e-03\n",
      "Epoch 38700, Train loss: 1.235e+03, Test loss: 6.458e+05, MSE(e): 5.302e-05, MSE(pi1): 9.608e-03, MSE(pi2): 3.318e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 38800, Train loss: 1.235e+03, Test loss: 6.461e+05, MSE(e): 5.309e-05, MSE(pi1): 9.774e-03, MSE(pi2): 3.327e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 38900, Train loss: 1.231e+03, Test loss: 6.461e+05, MSE(e): 5.265e-05, MSE(pi1): 9.565e-03, MSE(pi2): 3.298e-05, MSE(pi3): 6.087e-03\n",
      "Epoch 39000, Train loss: 1.268e+03, Test loss: 6.454e+05, MSE(e): 5.511e-05, MSE(pi1): 1.234e-02, MSE(pi2): 3.481e-05, MSE(pi3): 5.937e-03\n",
      "Epoch 39100, Train loss: 1.227e+03, Test loss: 6.461e+05, MSE(e): 5.225e-05, MSE(pi1): 9.596e-03, MSE(pi2): 3.272e-05, MSE(pi3): 6.084e-03\n",
      "Epoch 39200, Train loss: 1.228e+03, Test loss: 6.458e+05, MSE(e): 5.231e-05, MSE(pi1): 9.593e-03, MSE(pi2): 3.266e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 39300, Train loss: 1.223e+03, Test loss: 6.463e+05, MSE(e): 5.185e-05, MSE(pi1): 9.612e-03, MSE(pi2): 3.251e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 39400, Train loss: 1.226e+03, Test loss: 6.467e+05, MSE(e): 5.216e-05, MSE(pi1): 9.896e-03, MSE(pi2): 3.272e-05, MSE(pi3): 6.055e-03\n",
      "Epoch 39500, Train loss: 1.219e+03, Test loss: 6.464e+05, MSE(e): 5.147e-05, MSE(pi1): 9.614e-03, MSE(pi2): 3.229e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 39600, Train loss: 1.259e+03, Test loss: 6.471e+05, MSE(e): 5.550e-05, MSE(pi1): 9.793e-03, MSE(pi2): 3.418e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 39700, Train loss: 1.215e+03, Test loss: 6.466e+05, MSE(e): 5.111e-05, MSE(pi1): 9.620e-03, MSE(pi2): 3.208e-05, MSE(pi3): 6.080e-03\n",
      "Epoch 39800, Train loss: 1.752e+03, Test loss: 6.453e+05, MSE(e): 1.027e-04, MSE(pi1): 9.350e-03, MSE(pi2): 5.259e-05, MSE(pi3): 6.318e-03\n",
      "Epoch 39900, Train loss: 1.212e+03, Test loss: 6.467e+05, MSE(e): 5.074e-05, MSE(pi1): 9.624e-03, MSE(pi2): 3.187e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 40000, Train loss: 1.970e+03, Test loss: 6.444e+05, MSE(e): 1.262e-04, MSE(pi1): 8.694e-03, MSE(pi2): 6.172e-05, MSE(pi3): 6.214e-03\n",
      "Epoch 40100, Train loss: 1.208e+03, Test loss: 6.468e+05, MSE(e): 5.038e-05, MSE(pi1): 9.608e-03, MSE(pi2): 3.165e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 40200, Train loss: 1.223e+03, Test loss: 6.475e+05, MSE(e): 5.187e-05, MSE(pi1): 9.768e-03, MSE(pi2): 3.241e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 40300, Train loss: 1.205e+03, Test loss: 6.471e+05, MSE(e): 5.004e-05, MSE(pi1): 9.616e-03, MSE(pi2): 3.146e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 40400, Train loss: 1.203e+03, Test loss: 6.470e+05, MSE(e): 4.985e-05, MSE(pi1): 9.605e-03, MSE(pi2): 3.133e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 40500, Train loss: 1.203e+03, Test loss: 6.469e+05, MSE(e): 4.989e-05, MSE(pi1): 9.610e-03, MSE(pi2): 3.126e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 40600, Train loss: 1.200e+03, Test loss: 6.469e+05, MSE(e): 4.957e-05, MSE(pi1): 9.927e-03, MSE(pi2): 3.122e-05, MSE(pi3): 6.052e-03\n",
      "Epoch 40700, Train loss: 1.197e+03, Test loss: 6.473e+05, MSE(e): 4.935e-05, MSE(pi1): 9.592e-03, MSE(pi2): 3.105e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 40800, Train loss: 1.196e+03, Test loss: 6.472e+05, MSE(e): 4.915e-05, MSE(pi1): 9.598e-03, MSE(pi2): 3.093e-05, MSE(pi3): 6.080e-03\n",
      "Epoch 40900, Train loss: 1.195e+03, Test loss: 6.475e+05, MSE(e): 4.907e-05, MSE(pi1): 9.643e-03, MSE(pi2): 3.091e-05, MSE(pi3): 6.074e-03\n",
      "Epoch 41000, Train loss: 1.193e+03, Test loss: 6.473e+05, MSE(e): 4.883e-05, MSE(pi1): 9.771e-03, MSE(pi2): 3.076e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 41100, Train loss: 1.191e+03, Test loss: 6.475e+05, MSE(e): 4.873e-05, MSE(pi1): 9.655e-03, MSE(pi2): 3.071e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 41200, Train loss: 1.189e+03, Test loss: 6.477e+05, MSE(e): 4.854e-05, MSE(pi1): 9.547e-03, MSE(pi2): 3.058e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 41300, Train loss: 1.198e+03, Test loss: 6.473e+05, MSE(e): 4.929e-05, MSE(pi1): 9.652e-03, MSE(pi2): 3.071e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 41400, Train loss: 1.923e+03, Test loss: 6.525e+05, MSE(e): 1.219e-04, MSE(pi1): 1.059e-02, MSE(pi2): 6.196e-05, MSE(pi3): 5.972e-03\n",
      "Epoch 41500, Train loss: 1.184e+03, Test loss: 6.477e+05, MSE(e): 4.798e-05, MSE(pi1): 9.591e-03, MSE(pi2): 3.023e-05, MSE(pi3): 6.080e-03\n",
      "Epoch 41600, Train loss: 1.188e+03, Test loss: 6.473e+05, MSE(e): 4.842e-05, MSE(pi1): 9.517e-03, MSE(pi2): 3.029e-05, MSE(pi3): 6.089e-03\n",
      "Epoch 41700, Train loss: 1.181e+03, Test loss: 6.478e+05, MSE(e): 4.768e-05, MSE(pi1): 9.587e-03, MSE(pi2): 3.005e-05, MSE(pi3): 6.080e-03\n",
      "Epoch 41800, Train loss: 1.184e+03, Test loss: 6.479e+05, MSE(e): 4.765e-05, MSE(pi1): 1.031e-02, MSE(pi2): 3.011e-05, MSE(pi3): 6.046e-03\n",
      "Epoch 41900, Train loss: 2.073e+03, Test loss: 6.498e+05, MSE(e): 1.370e-04, MSE(pi1): 1.085e-02, MSE(pi2): 6.819e-05, MSE(pi3): 5.945e-03\n",
      "Epoch 42000, Train loss: 1.176e+03, Test loss: 6.480e+05, MSE(e): 4.718e-05, MSE(pi1): 9.595e-03, MSE(pi2): 2.977e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 42100, Train loss: 1.180e+03, Test loss: 6.476e+05, MSE(e): 4.761e-05, MSE(pi1): 9.554e-03, MSE(pi2): 2.983e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 42200, Train loss: 1.172e+03, Test loss: 6.481e+05, MSE(e): 4.686e-05, MSE(pi1): 9.582e-03, MSE(pi2): 2.959e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 42300, Train loss: 2.209e+03, Test loss: 6.465e+05, MSE(e): 1.489e-04, MSE(pi1): 8.335e-03, MSE(pi2): 7.050e-05, MSE(pi3): 6.360e-03\n",
      "Epoch 42400, Train loss: 1.169e+03, Test loss: 6.482e+05, MSE(e): 4.656e-05, MSE(pi1): 9.595e-03, MSE(pi2): 2.941e-05, MSE(pi3): 6.078e-03\n",
      "Epoch 42500, Train loss: 1.939e+03, Test loss: 6.538e+05, MSE(e): 1.234e-04, MSE(pi1): 1.040e-02, MSE(pi2): 6.232e-05, MSE(pi3): 6.006e-03\n",
      "Epoch 42600, Train loss: 1.166e+03, Test loss: 6.483e+05, MSE(e): 4.625e-05, MSE(pi1): 9.612e-03, MSE(pi2): 2.924e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 42700, Train loss: 1.165e+03, Test loss: 6.483e+05, MSE(e): 4.611e-05, MSE(pi1): 9.667e-03, MSE(pi2): 2.917e-05, MSE(pi3): 6.070e-03\n",
      "Epoch 42800, Train loss: 1.164e+03, Test loss: 6.484e+05, MSE(e): 4.598e-05, MSE(pi1): 9.534e-03, MSE(pi2): 2.904e-05, MSE(pi3): 6.084e-03\n",
      "Epoch 42900, Train loss: 1.162e+03, Test loss: 6.484e+05, MSE(e): 4.580e-05, MSE(pi1): 9.580e-03, MSE(pi2): 2.896e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 43000, Train loss: 1.160e+03, Test loss: 6.485e+05, MSE(e): 4.566e-05, MSE(pi1): 9.597e-03, MSE(pi2): 2.889e-05, MSE(pi3): 6.077e-03\n",
      "Epoch 43100, Train loss: 1.161e+03, Test loss: 6.487e+05, MSE(e): 4.552e-05, MSE(pi1): 9.750e-03, MSE(pi2): 2.879e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 43200, Train loss: 1.171e+03, Test loss: 6.500e+05, MSE(e): 4.643e-05, MSE(pi1): 9.503e-03, MSE(pi2): 2.927e-05, MSE(pi3): 6.116e-03\n",
      "Epoch 43300, Train loss: 1.156e+03, Test loss: 6.487e+05, MSE(e): 4.521e-05, MSE(pi1): 9.587e-03, MSE(pi2): 2.863e-05, MSE(pi3): 6.077e-03\n",
      "Epoch 43400, Train loss: 1.693e+03, Test loss: 6.475e+05, MSE(e): 9.806e-05, MSE(pi1): 8.418e-03, MSE(pi2): 4.955e-05, MSE(pi3): 6.279e-03\n",
      "Epoch 43500, Train loss: 1.168e+03, Test loss: 6.482e+05, MSE(e): 4.641e-05, MSE(pi1): 9.421e-03, MSE(pi2): 2.890e-05, MSE(pi3): 6.098e-03\n",
      "Epoch 43600, Train loss: 1.151e+03, Test loss: 6.489e+05, MSE(e): 4.479e-05, MSE(pi1): 9.604e-03, MSE(pi2): 2.839e-05, MSE(pi3): 6.075e-03\n",
      "Epoch 43700, Train loss: 1.152e+03, Test loss: 6.494e+05, MSE(e): 4.480e-05, MSE(pi1): 9.861e-03, MSE(pi2): 2.844e-05, MSE(pi3): 6.051e-03\n",
      "Epoch 43800, Train loss: 1.149e+03, Test loss: 6.489e+05, MSE(e): 4.450e-05, MSE(pi1): 9.578e-03, MSE(pi2): 2.821e-05, MSE(pi3): 6.078e-03\n",
      "Epoch 43900, Train loss: 1.172e+03, Test loss: 6.486e+05, MSE(e): 4.663e-05, MSE(pi1): 9.826e-03, MSE(pi2): 2.894e-05, MSE(pi3): 6.077e-03\n",
      "Epoch 44000, Train loss: 1.146e+03, Test loss: 6.490e+05, MSE(e): 4.422e-05, MSE(pi1): 9.589e-03, MSE(pi2): 2.805e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 44100, Train loss: 1.147e+03, Test loss: 6.494e+05, MSE(e): 4.423e-05, MSE(pi1): 9.362e-03, MSE(pi2): 2.796e-05, MSE(pi3): 6.106e-03\n",
      "Epoch 44200, Train loss: 1.143e+03, Test loss: 6.491e+05, MSE(e): 4.394e-05, MSE(pi1): 9.586e-03, MSE(pi2): 2.789e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 44300, Train loss: 1.190e+03, Test loss: 6.503e+05, MSE(e): 4.865e-05, MSE(pi1): 1.009e-02, MSE(pi2): 3.014e-05, MSE(pi3): 6.027e-03\n",
      "Epoch 44400, Train loss: 1.140e+03, Test loss: 6.493e+05, MSE(e): 4.367e-05, MSE(pi1): 9.582e-03, MSE(pi2): 2.773e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 44500, Train loss: 1.158e+03, Test loss: 6.492e+05, MSE(e): 4.478e-05, MSE(pi1): 9.591e-03, MSE(pi2): 2.802e-05, MSE(pi3): 6.146e-03\n",
      "Epoch 44600, Train loss: 1.149e+03, Test loss: 6.488e+05, MSE(e): 4.454e-05, MSE(pi1): 9.492e-03, MSE(pi2): 2.790e-05, MSE(pi3): 6.088e-03\n",
      "Epoch 44700, Train loss: 1.136e+03, Test loss: 6.494e+05, MSE(e): 4.328e-05, MSE(pi1): 9.552e-03, MSE(pi2): 2.751e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 44800, Train loss: 1.136e+03, Test loss: 6.495e+05, MSE(e): 4.324e-05, MSE(pi1): 9.578e-03, MSE(pi2): 2.750e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 44900, Train loss: 1.163e+03, Test loss: 6.489e+05, MSE(e): 4.547e-05, MSE(pi1): 9.693e-03, MSE(pi2): 2.812e-05, MSE(pi3): 6.108e-03\n",
      "Epoch 45000, Train loss: 1.132e+03, Test loss: 6.496e+05, MSE(e): 4.288e-05, MSE(pi1): 9.591e-03, MSE(pi2): 2.728e-05, MSE(pi3): 6.075e-03\n",
      "Epoch 45100, Train loss: 1.167e+03, Test loss: 6.485e+05, MSE(e): 4.484e-05, MSE(pi1): 1.264e-02, MSE(pi2): 2.892e-05, MSE(pi3): 5.923e-03\n",
      "Epoch 45200, Train loss: 1.130e+03, Test loss: 6.496e+05, MSE(e): 4.262e-05, MSE(pi1): 9.574e-03, MSE(pi2): 2.709e-05, MSE(pi3): 6.077e-03\n",
      "Epoch 45300, Train loss: 1.129e+03, Test loss: 6.497e+05, MSE(e): 4.261e-05, MSE(pi1): 9.627e-03, MSE(pi2): 2.713e-05, MSE(pi3): 6.070e-03\n",
      "Epoch 45400, Train loss: 1.127e+03, Test loss: 6.498e+05, MSE(e): 4.240e-05, MSE(pi1): 9.610e-03, MSE(pi2): 2.700e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 45500, Train loss: 1.131e+03, Test loss: 6.493e+05, MSE(e): 4.245e-05, MSE(pi1): 1.036e-02, MSE(pi2): 2.709e-05, MSE(pi3): 6.024e-03\n",
      "Epoch 45600, Train loss: 1.127e+03, Test loss: 6.497e+05, MSE(e): 4.232e-05, MSE(pi1): 9.536e-03, MSE(pi2): 2.683e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 45700, Train loss: 1.161e+03, Test loss: 6.503e+05, MSE(e): 4.573e-05, MSE(pi1): 9.679e-03, MSE(pi2): 2.853e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 45800, Train loss: 1.130e+03, Test loss: 6.497e+05, MSE(e): 4.267e-05, MSE(pi1): 1.004e-02, MSE(pi2): 2.720e-05, MSE(pi3): 6.030e-03\n",
      "Epoch 45900, Train loss: 1.123e+03, Test loss: 6.497e+05, MSE(e): 4.198e-05, MSE(pi1): 9.509e-03, MSE(pi2): 2.662e-05, MSE(pi3): 6.084e-03\n",
      "Epoch 46000, Train loss: 1.119e+03, Test loss: 6.499e+05, MSE(e): 4.160e-05, MSE(pi1): 9.568e-03, MSE(pi2): 2.650e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 46100, Train loss: 1.118e+03, Test loss: 6.502e+05, MSE(e): 4.150e-05, MSE(pi1): 9.476e-03, MSE(pi2): 2.646e-05, MSE(pi3): 6.086e-03\n",
      "Epoch 46200, Train loss: 1.413e+03, Test loss: 6.499e+05, MSE(e): 7.075e-05, MSE(pi1): 8.938e-03, MSE(pi2): 3.771e-05, MSE(pi3): 6.159e-03\n",
      "Epoch 46300, Train loss: 1.116e+03, Test loss: 6.501e+05, MSE(e): 4.123e-05, MSE(pi1): 9.578e-03, MSE(pi2): 2.629e-05, MSE(pi3): 6.075e-03\n",
      "Epoch 46400, Train loss: 1.116e+03, Test loss: 6.503e+05, MSE(e): 4.117e-05, MSE(pi1): 9.337e-03, MSE(pi2): 2.623e-05, MSE(pi3): 6.112e-03\n",
      "Epoch 46500, Train loss: 1.114e+03, Test loss: 6.501e+05, MSE(e): 4.107e-05, MSE(pi1): 9.525e-03, MSE(pi2): 2.615e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 46600, Train loss: 1.112e+03, Test loss: 6.501e+05, MSE(e): 4.087e-05, MSE(pi1): 9.578e-03, MSE(pi2): 2.609e-05, MSE(pi3): 6.074e-03\n",
      "Epoch 46700, Train loss: 1.112e+03, Test loss: 6.501e+05, MSE(e): 4.091e-05, MSE(pi1): 9.583e-03, MSE(pi2): 2.604e-05, MSE(pi3): 6.075e-03\n",
      "Epoch 46800, Train loss: 1.110e+03, Test loss: 6.503e+05, MSE(e): 4.063e-05, MSE(pi1): 9.576e-03, MSE(pi2): 2.595e-05, MSE(pi3): 6.074e-03\n",
      "Epoch 46900, Train loss: 1.131e+03, Test loss: 6.509e+05, MSE(e): 4.280e-05, MSE(pi1): 9.827e-03, MSE(pi2): 2.704e-05, MSE(pi3): 6.046e-03\n",
      "Epoch 47000, Train loss: 1.127e+03, Test loss: 6.500e+05, MSE(e): 4.235e-05, MSE(pi1): 9.431e-03, MSE(pi2): 2.643e-05, MSE(pi3): 6.093e-03\n",
      "Epoch 47100, Train loss: 1.378e+03, Test loss: 6.512e+05, MSE(e): 6.714e-05, MSE(pi1): 1.127e-02, MSE(pi2): 3.780e-05, MSE(pi3): 5.935e-03\n",
      "Epoch 47200, Train loss: 1.105e+03, Test loss: 6.504e+05, MSE(e): 4.017e-05, MSE(pi1): 9.572e-03, MSE(pi2): 2.568e-05, MSE(pi3): 6.074e-03\n",
      "Epoch 47300, Train loss: 1.105e+03, Test loss: 6.504e+05, MSE(e): 4.018e-05, MSE(pi1): 9.432e-03, MSE(pi2): 2.560e-05, MSE(pi3): 6.091e-03\n",
      "Epoch 47400, Train loss: 1.109e+03, Test loss: 6.501e+05, MSE(e): 4.056e-05, MSE(pi1): 9.630e-03, MSE(pi2): 2.572e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 47500, Train loss: 1.101e+03, Test loss: 6.505e+05, MSE(e): 3.983e-05, MSE(pi1): 9.571e-03, MSE(pi2): 2.547e-05, MSE(pi3): 6.074e-03\n",
      "Epoch 47600, Train loss: 1.109e+03, Test loss: 6.502e+05, MSE(e): 4.055e-05, MSE(pi1): 9.491e-03, MSE(pi2): 2.564e-05, MSE(pi3): 6.084e-03\n",
      "Epoch 47700, Train loss: 1.099e+03, Test loss: 6.506e+05, MSE(e): 3.960e-05, MSE(pi1): 9.472e-03, MSE(pi2): 2.533e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 47800, Train loss: 1.100e+03, Test loss: 6.508e+05, MSE(e): 3.966e-05, MSE(pi1): 9.639e-03, MSE(pi2): 2.541e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 47900, Train loss: 1.103e+03, Test loss: 6.510e+05, MSE(e): 3.946e-05, MSE(pi1): 9.784e-03, MSE(pi2): 2.522e-05, MSE(pi3): 6.109e-03\n",
      "Epoch 48000, Train loss: 1.096e+03, Test loss: 6.508e+05, MSE(e): 3.931e-05, MSE(pi1): 9.506e-03, MSE(pi2): 2.513e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 48100, Train loss: 1.095e+03, Test loss: 6.507e+05, MSE(e): 3.915e-05, MSE(pi1): 9.561e-03, MSE(pi2): 2.508e-05, MSE(pi3): 6.074e-03\n",
      "Epoch 48200, Train loss: 1.095e+03, Test loss: 6.507e+05, MSE(e): 3.921e-05, MSE(pi1): 9.509e-03, MSE(pi2): 2.503e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 48300, Train loss: 1.099e+03, Test loss: 6.503e+05, MSE(e): 3.921e-05, MSE(pi1): 1.055e-02, MSE(pi2): 2.522e-05, MSE(pi3): 6.013e-03\n",
      "Epoch 48400, Train loss: 1.092e+03, Test loss: 6.509e+05, MSE(e): 3.885e-05, MSE(pi1): 9.527e-03, MSE(pi2): 2.488e-05, MSE(pi3): 6.078e-03\n",
      "Epoch 48500, Train loss: 1.092e+03, Test loss: 6.511e+05, MSE(e): 3.893e-05, MSE(pi1): 9.536e-03, MSE(pi2): 2.486e-05, MSE(pi3): 6.078e-03\n",
      "Epoch 48600, Train loss: 1.117e+03, Test loss: 6.505e+05, MSE(e): 4.079e-05, MSE(pi1): 1.151e-02, MSE(pi2): 2.645e-05, MSE(pi3): 5.940e-03\n",
      "Epoch 48700, Train loss: 1.223e+03, Test loss: 6.498e+05, MSE(e): 5.188e-05, MSE(pi1): 9.135e-03, MSE(pi2): 2.973e-05, MSE(pi3): 6.130e-03\n",
      "Epoch 48800, Train loss: 1.337e+03, Test loss: 6.494e+05, MSE(e): 6.322e-05, MSE(pi1): 9.044e-03, MSE(pi2): 3.422e-05, MSE(pi3): 6.144e-03\n",
      "Epoch 48900, Train loss: 1.087e+03, Test loss: 6.507e+05, MSE(e): 3.838e-05, MSE(pi1): 9.792e-03, MSE(pi2): 2.467e-05, MSE(pi3): 6.052e-03\n",
      "Epoch 49000, Train loss: 1.086e+03, Test loss: 6.512e+05, MSE(e): 3.827e-05, MSE(pi1): 9.554e-03, MSE(pi2): 2.459e-05, MSE(pi3): 6.074e-03\n",
      "Epoch 49100, Train loss: 1.185e+03, Test loss: 6.498e+05, MSE(e): 4.785e-05, MSE(pi1): 1.002e-02, MSE(pi2): 2.817e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 49200, Train loss: 1.621e+03, Test loss: 6.545e+05, MSE(e): 9.194e-05, MSE(pi1): 1.049e-02, MSE(pi2): 4.770e-05, MSE(pi3): 5.971e-03\n",
      "Epoch 49300, Train loss: 1.082e+03, Test loss: 6.512e+05, MSE(e): 3.788e-05, MSE(pi1): 9.571e-03, MSE(pi2): 2.435e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 49400, Train loss: 1.090e+03, Test loss: 6.510e+05, MSE(e): 3.867e-05, MSE(pi1): 9.451e-03, MSE(pi2): 2.452e-05, MSE(pi3): 6.087e-03\n",
      "Epoch 49500, Train loss: 1.082e+03, Test loss: 6.516e+05, MSE(e): 3.782e-05, MSE(pi1): 9.271e-03, MSE(pi2): 2.427e-05, MSE(pi3): 6.107e-03\n",
      "Epoch 49600, Train loss: 1.152e+03, Test loss: 6.517e+05, MSE(e): 4.485e-05, MSE(pi1): 9.204e-03, MSE(pi2): 2.675e-05, MSE(pi3): 6.119e-03\n",
      "Epoch 49700, Train loss: 1.078e+03, Test loss: 6.514e+05, MSE(e): 3.747e-05, MSE(pi1): 9.548e-03, MSE(pi2): 2.410e-05, MSE(pi3): 6.074e-03\n",
      "Epoch 49800, Train loss: 1.077e+03, Test loss: 6.514e+05, MSE(e): 3.742e-05, MSE(pi1): 9.631e-03, MSE(pi2): 2.410e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 49900, Train loss: 1.076e+03, Test loss: 6.514e+05, MSE(e): 3.728e-05, MSE(pi1): 9.567e-03, MSE(pi2): 2.398e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 50000, Train loss: 1.083e+03, Test loss: 6.521e+05, MSE(e): 3.763e-05, MSE(pi1): 9.283e-03, MSE(pi2): 2.419e-05, MSE(pi3): 6.137e-03\n",
      "Epoch 50100, Train loss: 1.074e+03, Test loss: 6.515e+05, MSE(e): 3.708e-05, MSE(pi1): 9.563e-03, MSE(pi2): 2.388e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 50200, Train loss: 1.121e+03, Test loss: 6.522e+05, MSE(e): 4.178e-05, MSE(pi1): 1.002e-02, MSE(pi2): 2.613e-05, MSE(pi3): 6.026e-03\n",
      "Epoch 50300, Train loss: 1.111e+03, Test loss: 6.500e+05, MSE(e): 4.029e-05, MSE(pi1): 1.146e-02, MSE(pi2): 2.624e-05, MSE(pi3): 5.933e-03\n",
      "Epoch 50400, Train loss: 1.083e+03, Test loss: 6.511e+05, MSE(e): 3.802e-05, MSE(pi1): 9.458e-03, MSE(pi2): 2.406e-05, MSE(pi3): 6.086e-03\n",
      "Epoch 50500, Train loss: 1.070e+03, Test loss: 6.516e+05, MSE(e): 3.673e-05, MSE(pi1): 9.585e-03, MSE(pi2): 2.369e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 50600, Train loss: 1.071e+03, Test loss: 6.515e+05, MSE(e): 3.683e-05, MSE(pi1): 9.490e-03, MSE(pi2): 2.361e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 50700, Train loss: 1.218e+03, Test loss: 6.502e+05, MSE(e): 5.137e-05, MSE(pi1): 9.379e-03, MSE(pi2): 2.918e-05, MSE(pi3): 6.106e-03\n",
      "Epoch 50800, Train loss: 1.067e+03, Test loss: 6.516e+05, MSE(e): 3.640e-05, MSE(pi1): 9.534e-03, MSE(pi2): 2.345e-05, MSE(pi3): 6.075e-03\n",
      "Epoch 50900, Train loss: 1.066e+03, Test loss: 6.518e+05, MSE(e): 3.633e-05, MSE(pi1): 9.601e-03, MSE(pi2): 2.345e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 51000, Train loss: 1.071e+03, Test loss: 6.522e+05, MSE(e): 3.673e-05, MSE(pi1): 9.448e-03, MSE(pi2): 2.365e-05, MSE(pi3): 6.089e-03\n",
      "Epoch 51100, Train loss: 1.064e+03, Test loss: 6.517e+05, MSE(e): 3.612e-05, MSE(pi1): 9.541e-03, MSE(pi2): 2.329e-05, MSE(pi3): 6.074e-03\n",
      "Epoch 51200, Train loss: 1.065e+03, Test loss: 6.516e+05, MSE(e): 3.624e-05, MSE(pi1): 9.539e-03, MSE(pi2): 2.328e-05, MSE(pi3): 6.075e-03\n",
      "Epoch 51300, Train loss: 1.064e+03, Test loss: 6.516e+05, MSE(e): 3.616e-05, MSE(pi1): 9.886e-03, MSE(pi2): 2.342e-05, MSE(pi3): 6.037e-03\n",
      "Epoch 51400, Train loss: 1.068e+03, Test loss: 6.516e+05, MSE(e): 3.647e-05, MSE(pi1): 9.380e-03, MSE(pi2): 2.328e-05, MSE(pi3): 6.093e-03\n",
      "Epoch 51500, Train loss: 1.060e+03, Test loss: 6.520e+05, MSE(e): 3.576e-05, MSE(pi1): 9.566e-03, MSE(pi2): 2.311e-05, MSE(pi3): 6.070e-03\n",
      "Epoch 51600, Train loss: 1.219e+03, Test loss: 6.538e+05, MSE(e): 5.173e-05, MSE(pi1): 9.938e-03, MSE(pi2): 3.022e-05, MSE(pi3): 6.027e-03\n",
      "Epoch 51700, Train loss: 1.058e+03, Test loss: 6.520e+05, MSE(e): 3.557e-05, MSE(pi1): 9.569e-03, MSE(pi2): 2.300e-05, MSE(pi3): 6.070e-03\n",
      "Epoch 51800, Train loss: 1.057e+03, Test loss: 6.519e+05, MSE(e): 3.547e-05, MSE(pi1): 9.556e-03, MSE(pi2): 2.292e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 51900, Train loss: 1.058e+03, Test loss: 6.519e+05, MSE(e): 3.548e-05, MSE(pi1): 9.715e-03, MSE(pi2): 2.292e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 52000, Train loss: 1.056e+03, Test loss: 6.520e+05, MSE(e): 3.529e-05, MSE(pi1): 9.554e-03, MSE(pi2): 2.282e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 52100, Train loss: 1.055e+03, Test loss: 6.522e+05, MSE(e): 3.526e-05, MSE(pi1): 9.688e-03, MSE(pi2): 2.284e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 52200, Train loss: 1.054e+03, Test loss: 6.521e+05, MSE(e): 3.511e-05, MSE(pi1): 9.554e-03, MSE(pi2): 2.272e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 52300, Train loss: 1.053e+03, Test loss: 6.521e+05, MSE(e): 3.505e-05, MSE(pi1): 9.567e-03, MSE(pi2): 2.269e-05, MSE(pi3): 6.070e-03\n",
      "Epoch 52400, Train loss: 1.053e+03, Test loss: 6.523e+05, MSE(e): 3.502e-05, MSE(pi1): 9.592e-03, MSE(pi2): 2.268e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 52500, Train loss: 1.054e+03, Test loss: 6.519e+05, MSE(e): 3.510e-05, MSE(pi1): 1.008e-02, MSE(pi2): 2.280e-05, MSE(pi3): 6.026e-03\n",
      "Epoch 52600, Train loss: 2.168e+03, Test loss: 6.506e+05, MSE(e): 1.458e-04, MSE(pi1): 9.413e-03, MSE(pi2): 6.713e-05, MSE(pi3): 6.160e-03\n",
      "Epoch 52700, Train loss: 1.050e+03, Test loss: 6.523e+05, MSE(e): 3.469e-05, MSE(pi1): 9.575e-03, MSE(pi2): 2.247e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 52800, Train loss: 1.049e+03, Test loss: 6.522e+05, MSE(e): 3.460e-05, MSE(pi1): 9.544e-03, MSE(pi2): 2.241e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 52900, Train loss: 1.049e+03, Test loss: 6.526e+05, MSE(e): 3.456e-05, MSE(pi1): 9.349e-03, MSE(pi2): 2.237e-05, MSE(pi3): 6.093e-03\n",
      "Epoch 53000, Train loss: 1.047e+03, Test loss: 6.523e+05, MSE(e): 3.443e-05, MSE(pi1): 9.547e-03, MSE(pi2): 2.231e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 53100, Train loss: 1.054e+03, Test loss: 6.522e+05, MSE(e): 3.507e-05, MSE(pi1): 9.507e-03, MSE(pi2): 2.246e-05, MSE(pi3): 6.077e-03\n",
      "Epoch 53200, Train loss: 1.046e+03, Test loss: 6.523e+05, MSE(e): 3.427e-05, MSE(pi1): 9.680e-03, MSE(pi2): 2.222e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 53300, Train loss: 1.073e+03, Test loss: 6.524e+05, MSE(e): 3.686e-05, MSE(pi1): 9.242e-03, MSE(pi2): 2.303e-05, MSE(pi3): 6.121e-03\n",
      "Epoch 53400, Train loss: 1.044e+03, Test loss: 6.524e+05, MSE(e): 3.410e-05, MSE(pi1): 9.551e-03, MSE(pi2): 2.212e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 53500, Train loss: 3.439e+03, Test loss: 6.586e+05, MSE(e): 2.734e-04, MSE(pi1): 1.183e-02, MSE(pi2): 1.233e-04, MSE(pi3): 5.866e-03\n",
      "Epoch 53600, Train loss: 1.042e+03, Test loss: 6.525e+05, MSE(e): 3.393e-05, MSE(pi1): 9.547e-03, MSE(pi2): 2.202e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 53700, Train loss: 1.041e+03, Test loss: 6.525e+05, MSE(e): 3.385e-05, MSE(pi1): 9.499e-03, MSE(pi2): 2.197e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 53800, Train loss: 1.041e+03, Test loss: 6.526e+05, MSE(e): 3.390e-05, MSE(pi1): 9.622e-03, MSE(pi2): 2.203e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 53900, Train loss: 1.047e+03, Test loss: 6.527e+05, MSE(e): 3.437e-05, MSE(pi1): 9.500e-03, MSE(pi2): 2.205e-05, MSE(pi3): 6.078e-03\n",
      "Epoch 54000, Train loss: 1.039e+03, Test loss: 6.526e+05, MSE(e): 3.361e-05, MSE(pi1): 9.547e-03, MSE(pi2): 2.184e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 54100, Train loss: 1.051e+03, Test loss: 6.521e+05, MSE(e): 3.473e-05, MSE(pi1): 9.708e-03, MSE(pi2): 2.216e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 54200, Train loss: 1.037e+03, Test loss: 6.526e+05, MSE(e): 3.345e-05, MSE(pi1): 9.571e-03, MSE(pi2): 2.174e-05, MSE(pi3): 6.068e-03\n",
      "Epoch 54300, Train loss: 1.038e+03, Test loss: 6.528e+05, MSE(e): 3.356e-05, MSE(pi1): 9.555e-03, MSE(pi2): 2.182e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 54400, Train loss: 1.212e+03, Test loss: 6.521e+05, MSE(e): 5.085e-05, MSE(pi1): 9.185e-03, MSE(pi2): 2.834e-05, MSE(pi3): 6.121e-03\n",
      "Epoch 54500, Train loss: 1.035e+03, Test loss: 6.527e+05, MSE(e): 3.321e-05, MSE(pi1): 9.553e-03, MSE(pi2): 2.159e-05, MSE(pi3): 6.070e-03\n",
      "Epoch 54600, Train loss: 1.252e+03, Test loss: 6.519e+05, MSE(e): 5.481e-05, MSE(pi1): 9.530e-03, MSE(pi2): 3.011e-05, MSE(pi3): 6.089e-03\n",
      "Epoch 54700, Train loss: 1.033e+03, Test loss: 6.528e+05, MSE(e): 3.306e-05, MSE(pi1): 9.559e-03, MSE(pi2): 2.151e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 54800, Train loss: 1.082e+03, Test loss: 6.530e+05, MSE(e): 3.793e-05, MSE(pi1): 9.526e-03, MSE(pi2): 2.380e-05, MSE(pi3): 6.077e-03\n",
      "Epoch 54900, Train loss: 1.032e+03, Test loss: 6.528e+05, MSE(e): 3.291e-05, MSE(pi1): 9.556e-03, MSE(pi2): 2.143e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 55000, Train loss: 1.031e+03, Test loss: 6.529e+05, MSE(e): 3.285e-05, MSE(pi1): 9.571e-03, MSE(pi2): 2.140e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 55100, Train loss: 1.054e+03, Test loss: 6.534e+05, MSE(e): 3.520e-05, MSE(pi1): 9.671e-03, MSE(pi2): 2.254e-05, MSE(pi3): 6.054e-03\n",
      "Epoch 55200, Train loss: 1.029e+03, Test loss: 6.529e+05, MSE(e): 3.267e-05, MSE(pi1): 9.523e-03, MSE(pi2): 2.127e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 55300, Train loss: 1.123e+03, Test loss: 6.536e+05, MSE(e): 4.177e-05, MSE(pi1): 1.069e-02, MSE(pi2): 2.557e-05, MSE(pi3): 5.983e-03\n",
      "Epoch 55400, Train loss: 1.030e+03, Test loss: 6.528e+05, MSE(e): 3.256e-05, MSE(pi1): 9.839e-03, MSE(pi2): 2.122e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 55500, Train loss: 1.028e+03, Test loss: 6.529e+05, MSE(e): 3.252e-05, MSE(pi1): 9.697e-03, MSE(pi2): 2.122e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 55600, Train loss: 1.335e+03, Test loss: 6.522e+05, MSE(e): 6.302e-05, MSE(pi1): 9.055e-03, MSE(pi2): 3.300e-05, MSE(pi3): 6.139e-03\n",
      "Epoch 55700, Train loss: 1.026e+03, Test loss: 6.530e+05, MSE(e): 3.230e-05, MSE(pi1): 9.532e-03, MSE(pi2): 2.104e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 55800, Train loss: 1.027e+03, Test loss: 6.529e+05, MSE(e): 3.240e-05, MSE(pi1): 9.574e-03, MSE(pi2): 2.104e-05, MSE(pi3): 6.068e-03\n",
      "Epoch 55900, Train loss: 1.058e+03, Test loss: 6.551e+05, MSE(e): 3.535e-05, MSE(pi1): 9.885e-03, MSE(pi2): 2.250e-05, MSE(pi3): 6.052e-03\n",
      "Epoch 56000, Train loss: 1.023e+03, Test loss: 6.531e+05, MSE(e): 3.207e-05, MSE(pi1): 9.543e-03, MSE(pi2): 2.092e-05, MSE(pi3): 6.070e-03\n",
      "Epoch 56100, Train loss: 1.022e+03, Test loss: 6.531e+05, MSE(e): 3.200e-05, MSE(pi1): 9.540e-03, MSE(pi2): 2.088e-05, MSE(pi3): 6.070e-03\n",
      "Epoch 56200, Train loss: 1.043e+03, Test loss: 6.539e+05, MSE(e): 3.406e-05, MSE(pi1): 9.598e-03, MSE(pi2): 2.191e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 56300, Train loss: 1.021e+03, Test loss: 6.532e+05, MSE(e): 3.186e-05, MSE(pi1): 9.550e-03, MSE(pi2): 2.080e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 56400, Train loss: 1.379e+03, Test loss: 6.517e+05, MSE(e): 6.740e-05, MSE(pi1): 8.838e-03, MSE(pi2): 3.468e-05, MSE(pi3): 6.166e-03\n",
      "Epoch 56500, Train loss: 1.020e+03, Test loss: 6.532e+05, MSE(e): 3.171e-05, MSE(pi1): 9.529e-03, MSE(pi2): 2.071e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 56600, Train loss: 1.045e+03, Test loss: 6.538e+05, MSE(e): 3.374e-05, MSE(pi1): 8.850e-03, MSE(pi2): 2.171e-05, MSE(pi3): 6.194e-03\n",
      "Epoch 56700, Train loss: 1.020e+03, Test loss: 6.530e+05, MSE(e): 3.178e-05, MSE(pi1): 9.505e-03, MSE(pi2): 2.065e-05, MSE(pi3): 6.074e-03\n",
      "Epoch 56800, Train loss: 1.017e+03, Test loss: 6.532e+05, MSE(e): 3.150e-05, MSE(pi1): 9.543e-03, MSE(pi2): 2.059e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 56900, Train loss: 1.054e+03, Test loss: 6.530e+05, MSE(e): 3.491e-05, MSE(pi1): 9.401e-03, MSE(pi2): 2.173e-05, MSE(pi3): 6.109e-03\n",
      "Epoch 57000, Train loss: 1.016e+03, Test loss: 6.533e+05, MSE(e): 3.136e-05, MSE(pi1): 9.540e-03, MSE(pi2): 2.051e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 57100, Train loss: 1.045e+03, Test loss: 6.527e+05, MSE(e): 3.412e-05, MSE(pi1): 9.839e-03, MSE(pi2): 2.144e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 57200, Train loss: 1.016e+03, Test loss: 6.532e+05, MSE(e): 3.132e-05, MSE(pi1): 9.514e-03, MSE(pi2): 2.042e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 57300, Train loss: 1.014e+03, Test loss: 6.533e+05, MSE(e): 3.116e-05, MSE(pi1): 9.546e-03, MSE(pi2): 2.039e-05, MSE(pi3): 6.068e-03\n",
      "Epoch 57400, Train loss: 1.025e+03, Test loss: 6.536e+05, MSE(e): 3.217e-05, MSE(pi1): 9.964e-03, MSE(pi2): 2.097e-05, MSE(pi3): 6.032e-03\n",
      "Epoch 57500, Train loss: 1.015e+03, Test loss: 6.536e+05, MSE(e): 3.130e-05, MSE(pi1): 9.584e-03, MSE(pi2): 2.049e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 57600, Train loss: 1.012e+03, Test loss: 6.534e+05, MSE(e): 3.094e-05, MSE(pi1): 9.548e-03, MSE(pi2): 2.027e-05, MSE(pi3): 6.068e-03\n",
      "Epoch 57700, Train loss: 1.361e+03, Test loss: 6.561e+05, MSE(e): 6.594e-05, MSE(pi1): 1.013e-02, MSE(pi2): 3.552e-05, MSE(pi3): 6.001e-03\n",
      "Epoch 57800, Train loss: 1.010e+03, Test loss: 6.535e+05, MSE(e): 3.082e-05, MSE(pi1): 9.534e-03, MSE(pi2): 2.017e-05, MSE(pi3): 6.070e-03\n",
      "Epoch 57900, Train loss: 1.010e+03, Test loss: 6.534e+05, MSE(e): 3.075e-05, MSE(pi1): 9.560e-03, MSE(pi2): 2.014e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 58000, Train loss: 1.012e+03, Test loss: 6.537e+05, MSE(e): 3.098e-05, MSE(pi1): 9.625e-03, MSE(pi2): 2.030e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 58100, Train loss: 1.016e+03, Test loss: 6.542e+05, MSE(e): 3.095e-05, MSE(pi1): 9.262e-03, MSE(pi2): 2.025e-05, MSE(pi3): 6.142e-03\n",
      "Epoch 58200, Train loss: 1.025e+03, Test loss: 6.531e+05, MSE(e): 3.224e-05, MSE(pi1): 9.431e-03, MSE(pi2): 2.055e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 58300, Train loss: 1.114e+03, Test loss: 6.526e+05, MSE(e): 4.104e-05, MSE(pi1): 9.254e-03, MSE(pi2): 2.391e-05, MSE(pi3): 6.108e-03\n",
      "Epoch 58400, Train loss: 1.016e+03, Test loss: 6.532e+05, MSE(e): 3.113e-05, MSE(pi1): 1.055e-02, MSE(pi2): 2.051e-05, MSE(pi3): 5.996e-03\n",
      "Epoch 58500, Train loss: 1.006e+03, Test loss: 6.537e+05, MSE(e): 3.038e-05, MSE(pi1): 9.558e-03, MSE(pi2): 1.994e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 58600, Train loss: 1.019e+03, Test loss: 6.540e+05, MSE(e): 3.162e-05, MSE(pi1): 9.940e-03, MSE(pi2): 2.061e-05, MSE(pi3): 6.031e-03\n",
      "Epoch 58700, Train loss: 1.004e+03, Test loss: 6.536e+05, MSE(e): 3.022e-05, MSE(pi1): 9.607e-03, MSE(pi2): 1.984e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 58800, Train loss: 1.005e+03, Test loss: 6.537e+05, MSE(e): 3.027e-05, MSE(pi1): 9.543e-03, MSE(pi2): 1.988e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 58900, Train loss: 1.003e+03, Test loss: 6.537e+05, MSE(e): 3.008e-05, MSE(pi1): 9.539e-03, MSE(pi2): 1.975e-05, MSE(pi3): 6.068e-03\n",
      "Epoch 59000, Train loss: 1.008e+03, Test loss: 6.538e+05, MSE(e): 3.060e-05, MSE(pi1): 9.736e-03, MSE(pi2): 2.007e-05, MSE(pi3): 6.048e-03\n",
      "Epoch 59100, Train loss: 1.002e+03, Test loss: 6.537e+05, MSE(e): 2.995e-05, MSE(pi1): 9.545e-03, MSE(pi2): 1.967e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 59200, Train loss: 1.028e+03, Test loss: 6.539e+05, MSE(e): 3.264e-05, MSE(pi1): 9.775e-03, MSE(pi2): 2.100e-05, MSE(pi3): 6.043e-03\n",
      "Epoch 59300, Train loss: 1.054e+03, Test loss: 6.546e+05, MSE(e): 3.526e-05, MSE(pi1): 9.756e-03, MSE(pi2): 2.216e-05, MSE(pi3): 6.041e-03\n",
      "Epoch 59400, Train loss: 9.999e+02, Test loss: 6.538e+05, MSE(e): 2.978e-05, MSE(pi1): 9.548e-03, MSE(pi2): 1.958e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 59500, Train loss: 1.028e+03, Test loss: 6.531e+05, MSE(e): 3.215e-05, MSE(pi1): 9.305e-03, MSE(pi2): 2.032e-05, MSE(pi3): 6.134e-03\n",
      "Epoch 59600, Train loss: 9.985e+02, Test loss: 6.538e+05, MSE(e): 2.964e-05, MSE(pi1): 9.545e-03, MSE(pi2): 1.948e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 59700, Train loss: 1.037e+03, Test loss: 6.550e+05, MSE(e): 3.316e-05, MSE(pi1): 9.012e-03, MSE(pi2): 2.067e-05, MSE(pi3): 6.154e-03\n",
      "Epoch 59800, Train loss: 9.973e+02, Test loss: 6.539e+05, MSE(e): 2.952e-05, MSE(pi1): 9.535e-03, MSE(pi2): 1.941e-05, MSE(pi3): 6.068e-03\n",
      "Epoch 59900, Train loss: 9.967e+02, Test loss: 6.538e+05, MSE(e): 2.945e-05, MSE(pi1): 9.536e-03, MSE(pi2): 1.937e-05, MSE(pi3): 6.068e-03\n",
      "Epoch 60000, Train loss: 9.962e+02, Test loss: 6.539e+05, MSE(e): 2.940e-05, MSE(pi1): 9.545e-03, MSE(pi2): 1.933e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 60100, Train loss: 1.601e+03, Test loss: 6.525e+05, MSE(e): 8.951e-05, MSE(pi1): 8.593e-03, MSE(pi2): 4.312e-05, MSE(pi3): 6.200e-03\n",
      "Epoch 60200, Train loss: 9.948e+02, Test loss: 6.539e+05, MSE(e): 2.927e-05, MSE(pi1): 9.566e-03, MSE(pi2): 1.927e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 60300, Train loss: 1.387e+03, Test loss: 6.555e+05, MSE(e): 6.809e-05, MSE(pi1): 1.184e-02, MSE(pi2): 3.664e-05, MSE(pi3): 5.878e-03\n",
      "Epoch 60400, Train loss: 9.937e+02, Test loss: 6.540e+05, MSE(e): 2.916e-05, MSE(pi1): 9.535e-03, MSE(pi2): 1.919e-05, MSE(pi3): 6.068e-03\n",
      "Epoch 60500, Train loss: 9.930e+02, Test loss: 6.540e+05, MSE(e): 2.909e-05, MSE(pi1): 9.537e-03, MSE(pi2): 1.916e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 60600, Train loss: 1.000e+03, Test loss: 6.539e+05, MSE(e): 2.973e-05, MSE(pi1): 9.334e-03, MSE(pi2): 1.929e-05, MSE(pi3): 6.093e-03\n",
      "Epoch 60700, Train loss: 9.920e+02, Test loss: 6.540e+05, MSE(e): 2.897e-05, MSE(pi1): 9.569e-03, MSE(pi2): 1.909e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 60800, Train loss: 9.987e+02, Test loss: 6.535e+05, MSE(e): 2.960e-05, MSE(pi1): 9.628e-03, MSE(pi2): 1.924e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 60900, Train loss: 9.910e+02, Test loss: 6.541e+05, MSE(e): 2.890e-05, MSE(pi1): 9.552e-03, MSE(pi2): 1.906e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 61000, Train loss: 9.901e+02, Test loss: 6.541e+05, MSE(e): 2.881e-05, MSE(pi1): 9.545e-03, MSE(pi2): 1.900e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 61100, Train loss: 1.499e+03, Test loss: 6.527e+05, MSE(e): 7.916e-05, MSE(pi1): 9.574e-03, MSE(pi2): 3.899e-05, MSE(pi3): 6.113e-03\n",
      "Epoch 61200, Train loss: 9.899e+02, Test loss: 6.542e+05, MSE(e): 2.879e-05, MSE(pi1): 9.572e-03, MSE(pi2): 1.900e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 61300, Train loss: 9.885e+02, Test loss: 6.541e+05, MSE(e): 2.864e-05, MSE(pi1): 9.495e-03, MSE(pi2): 1.886e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 61400, Train loss: 1.223e+03, Test loss: 6.529e+05, MSE(e): 5.082e-05, MSE(pi1): 1.139e-02, MSE(pi2): 2.792e-05, MSE(pi3): 6.013e-03\n",
      "Epoch 61500, Train loss: 9.871e+02, Test loss: 6.541e+05, MSE(e): 2.850e-05, MSE(pi1): 9.541e-03, MSE(pi2): 1.881e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 61600, Train loss: 1.171e+03, Test loss: 6.539e+05, MSE(e): 4.677e-05, MSE(pi1): 9.181e-03, MSE(pi2): 2.578e-05, MSE(pi3): 6.117e-03\n",
      "Epoch 61700, Train loss: 9.859e+02, Test loss: 6.542e+05, MSE(e): 2.839e-05, MSE(pi1): 9.538e-03, MSE(pi2): 1.874e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 61800, Train loss: 9.859e+02, Test loss: 6.542e+05, MSE(e): 2.834e-05, MSE(pi1): 9.626e-03, MSE(pi2): 1.872e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 61900, Train loss: 1.016e+03, Test loss: 6.547e+05, MSE(e): 3.143e-05, MSE(pi1): 9.758e-03, MSE(pi2): 2.022e-05, MSE(pi3): 6.040e-03\n",
      "Epoch 62000, Train loss: 9.883e+02, Test loss: 6.541e+05, MSE(e): 2.830e-05, MSE(pi1): 1.027e-02, MSE(pi2): 1.873e-05, MSE(pi3): 6.026e-03\n",
      "Epoch 62100, Train loss: 1.123e+03, Test loss: 6.540e+05, MSE(e): 4.084e-05, MSE(pi1): 9.465e-03, MSE(pi2): 2.338e-05, MSE(pi3): 6.195e-03\n",
      "Epoch 62200, Train loss: 9.832e+02, Test loss: 6.542e+05, MSE(e): 2.811e-05, MSE(pi1): 9.532e-03, MSE(pi2): 1.857e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 62300, Train loss: 1.573e+03, Test loss: 6.529e+05, MSE(e): 8.669e-05, MSE(pi1): 8.940e-03, MSE(pi2): 4.179e-05, MSE(pi3): 6.166e-03\n",
      "Epoch 62400, Train loss: 9.820e+02, Test loss: 6.543e+05, MSE(e): 2.800e-05, MSE(pi1): 9.533e-03, MSE(pi2): 1.851e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 62500, Train loss: 1.428e+03, Test loss: 6.530e+05, MSE(e): 7.187e-05, MSE(pi1): 9.747e-03, MSE(pi2): 3.579e-05, MSE(pi3): 6.115e-03\n",
      "Epoch 62600, Train loss: 9.809e+02, Test loss: 6.543e+05, MSE(e): 2.789e-05, MSE(pi1): 9.536e-03, MSE(pi2): 1.844e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 62700, Train loss: 1.049e+03, Test loss: 6.544e+05, MSE(e): 3.462e-05, MSE(pi1): 1.072e-02, MSE(pi2): 2.182e-05, MSE(pi3): 5.958e-03\n",
      "Epoch 62800, Train loss: 1.045e+03, Test loss: 6.540e+05, MSE(e): 3.421e-05, MSE(pi1): 9.319e-03, MSE(pi2): 2.070e-05, MSE(pi3): 6.095e-03\n",
      "Epoch 62900, Train loss: 2.134e+03, Test loss: 6.525e+05, MSE(e): 1.427e-04, MSE(pi1): 8.608e-03, MSE(pi2): 6.467e-05, MSE(pi3): 6.209e-03\n",
      "Epoch 63000, Train loss: 9.787e+02, Test loss: 6.544e+05, MSE(e): 2.767e-05, MSE(pi1): 9.545e-03, MSE(pi2): 1.831e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 63100, Train loss: 1.005e+03, Test loss: 6.544e+05, MSE(e): 2.997e-05, MSE(pi1): 9.222e-03, MSE(pi2): 1.904e-05, MSE(pi3): 6.136e-03\n",
      "Epoch 63200, Train loss: 9.776e+02, Test loss: 6.544e+05, MSE(e): 2.756e-05, MSE(pi1): 9.530e-03, MSE(pi2): 1.825e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 63300, Train loss: 9.828e+02, Test loss: 6.544e+05, MSE(e): 2.809e-05, MSE(pi1): 9.616e-03, MSE(pi2): 1.856e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 63400, Train loss: 9.765e+02, Test loss: 6.544e+05, MSE(e): 2.745e-05, MSE(pi1): 9.535e-03, MSE(pi2): 1.818e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 63500, Train loss: 9.954e+02, Test loss: 6.546e+05, MSE(e): 2.937e-05, MSE(pi1): 9.675e-03, MSE(pi2): 1.916e-05, MSE(pi3): 6.049e-03\n",
      "Epoch 63600, Train loss: 9.776e+02, Test loss: 6.542e+05, MSE(e): 2.742e-05, MSE(pi1): 1.002e-02, MSE(pi2): 1.821e-05, MSE(pi3): 6.032e-03\n",
      "Epoch 63700, Train loss: 9.764e+02, Test loss: 6.546e+05, MSE(e): 2.746e-05, MSE(pi1): 9.615e-03, MSE(pi2): 1.822e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 63800, Train loss: 2.507e+03, Test loss: 6.592e+05, MSE(e): 1.803e-04, MSE(pi1): 1.108e-02, MSE(pi2): 8.303e-05, MSE(pi3): 5.934e-03\n",
      "Epoch 63900, Train loss: 9.738e+02, Test loss: 6.545e+05, MSE(e): 2.719e-05, MSE(pi1): 9.526e-03, MSE(pi2): 1.802e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 64000, Train loss: 1.135e+03, Test loss: 6.531e+05, MSE(e): 4.303e-05, MSE(pi1): 1.121e-02, MSE(pi2): 2.548e-05, MSE(pi3): 5.923e-03\n",
      "Epoch 64100, Train loss: 9.728e+02, Test loss: 6.545e+05, MSE(e): 2.708e-05, MSE(pi1): 9.536e-03, MSE(pi2): 1.797e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 64200, Train loss: 1.003e+03, Test loss: 6.546e+05, MSE(e): 2.999e-05, MSE(pi1): 9.461e-03, MSE(pi2): 1.892e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 64300, Train loss: 9.717e+02, Test loss: 6.546e+05, MSE(e): 2.698e-05, MSE(pi1): 9.526e-03, MSE(pi2): 1.790e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 64400, Train loss: 1.445e+03, Test loss: 6.557e+05, MSE(e): 7.382e-05, MSE(pi1): 1.069e-02, MSE(pi2): 3.804e-05, MSE(pi3): 5.996e-03\n",
      "Epoch 64500, Train loss: 9.707e+02, Test loss: 6.546e+05, MSE(e): 2.688e-05, MSE(pi1): 9.533e-03, MSE(pi2): 1.785e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 64600, Train loss: 9.917e+02, Test loss: 6.542e+05, MSE(e): 2.893e-05, MSE(pi1): 9.317e-03, MSE(pi2): 1.846e-05, MSE(pi3): 6.092e-03\n",
      "Epoch 64700, Train loss: 9.755e+02, Test loss: 6.548e+05, MSE(e): 2.738e-05, MSE(pi1): 9.630e-03, MSE(pi2): 1.814e-05, MSE(pi3): 6.054e-03\n",
      "Epoch 64800, Train loss: 9.696e+02, Test loss: 6.546e+05, MSE(e): 2.677e-05, MSE(pi1): 9.506e-03, MSE(pi2): 1.774e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 64900, Train loss: 9.721e+02, Test loss: 6.546e+05, MSE(e): 2.699e-05, MSE(pi1): 9.348e-03, MSE(pi2): 1.776e-05, MSE(pi3): 6.087e-03\n",
      "Epoch 65000, Train loss: 1.215e+03, Test loss: 6.541e+05, MSE(e): 5.119e-05, MSE(pi1): 9.143e-03, MSE(pi2): 2.721e-05, MSE(pi3): 6.121e-03\n",
      "Epoch 65100, Train loss: 9.676e+02, Test loss: 6.547e+05, MSE(e): 2.657e-05, MSE(pi1): 9.531e-03, MSE(pi2): 1.766e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 65200, Train loss: 1.258e+03, Test loss: 6.551e+05, MSE(e): 5.263e-05, MSE(pi1): 9.671e-03, MSE(pi2): 2.841e-05, MSE(pi3): 6.346e-03\n",
      "Epoch 65300, Train loss: 9.667e+02, Test loss: 6.548e+05, MSE(e): 2.648e-05, MSE(pi1): 9.533e-03, MSE(pi2): 1.761e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 65400, Train loss: 9.662e+02, Test loss: 6.547e+05, MSE(e): 2.643e-05, MSE(pi1): 9.528e-03, MSE(pi2): 1.757e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 65500, Train loss: 9.657e+02, Test loss: 6.547e+05, MSE(e): 2.638e-05, MSE(pi1): 9.527e-03, MSE(pi2): 1.754e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 65600, Train loss: 9.653e+02, Test loss: 6.547e+05, MSE(e): 2.634e-05, MSE(pi1): 9.529e-03, MSE(pi2): 1.751e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 65700, Train loss: 9.647e+02, Test loss: 6.547e+05, MSE(e): 2.628e-05, MSE(pi1): 9.530e-03, MSE(pi2): 1.748e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 65800, Train loss: 9.643e+02, Test loss: 6.548e+05, MSE(e): 2.624e-05, MSE(pi1): 9.545e-03, MSE(pi2): 1.745e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 65900, Train loss: 9.637e+02, Test loss: 6.547e+05, MSE(e): 2.619e-05, MSE(pi1): 9.558e-03, MSE(pi2): 1.744e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 66000, Train loss: 9.823e+02, Test loss: 6.550e+05, MSE(e): 2.805e-05, MSE(pi1): 1.003e-02, MSE(pi2): 1.845e-05, MSE(pi3): 6.015e-03\n",
      "Epoch 66100, Train loss: 9.627e+02, Test loss: 6.548e+05, MSE(e): 2.609e-05, MSE(pi1): 9.535e-03, MSE(pi2): 1.737e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 66200, Train loss: 9.804e+02, Test loss: 6.546e+05, MSE(e): 2.781e-05, MSE(pi1): 9.370e-03, MSE(pi2): 1.789e-05, MSE(pi3): 6.086e-03\n",
      "Epoch 66300, Train loss: 9.618e+02, Test loss: 6.548e+05, MSE(e): 2.600e-05, MSE(pi1): 9.536e-03, MSE(pi2): 1.732e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 66400, Train loss: 9.982e+02, Test loss: 6.557e+05, MSE(e): 2.957e-05, MSE(pi1): 9.767e-03, MSE(pi2): 1.903e-05, MSE(pi3): 6.048e-03\n",
      "Epoch 66500, Train loss: 9.608e+02, Test loss: 6.548e+05, MSE(e): 2.590e-05, MSE(pi1): 9.522e-03, MSE(pi2): 1.725e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 66600, Train loss: 1.021e+03, Test loss: 6.549e+05, MSE(e): 3.199e-05, MSE(pi1): 1.003e-02, MSE(pi2): 2.015e-05, MSE(pi3): 6.010e-03\n",
      "Epoch 66700, Train loss: 9.599e+02, Test loss: 6.549e+05, MSE(e): 2.581e-05, MSE(pi1): 9.537e-03, MSE(pi2): 1.721e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 66800, Train loss: 1.090e+03, Test loss: 6.545e+05, MSE(e): 3.871e-05, MSE(pi1): 9.195e-03, MSE(pi2): 2.205e-05, MSE(pi3): 6.111e-03\n",
      "Epoch 66900, Train loss: 9.633e+02, Test loss: 6.549e+05, MSE(e): 2.574e-05, MSE(pi1): 9.883e-03, MSE(pi2): 1.715e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 67000, Train loss: 9.670e+02, Test loss: 6.551e+05, MSE(e): 2.654e-05, MSE(pi1): 9.599e-03, MSE(pi2): 1.760e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 67100, Train loss: 9.583e+02, Test loss: 6.550e+05, MSE(e): 2.565e-05, MSE(pi1): 9.539e-03, MSE(pi2): 1.712e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 67200, Train loss: 9.603e+02, Test loss: 6.548e+05, MSE(e): 2.570e-05, MSE(pi1): 9.740e-03, MSE(pi2): 1.708e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 67300, Train loss: 9.572e+02, Test loss: 6.550e+05, MSE(e): 2.554e-05, MSE(pi1): 9.462e-03, MSE(pi2): 1.702e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 67400, Train loss: 1.153e+03, Test loss: 6.566e+05, MSE(e): 4.483e-05, MSE(pi1): 1.002e-02, MSE(pi2): 2.559e-05, MSE(pi3): 6.041e-03\n",
      "Epoch 67500, Train loss: 9.562e+02, Test loss: 6.549e+05, MSE(e): 2.544e-05, MSE(pi1): 9.552e-03, MSE(pi2): 1.698e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 67600, Train loss: 9.619e+02, Test loss: 6.551e+05, MSE(e): 2.604e-05, MSE(pi1): 9.652e-03, MSE(pi2): 1.733e-05, MSE(pi3): 6.050e-03\n",
      "Epoch 67700, Train loss: 9.554e+02, Test loss: 6.550e+05, MSE(e): 2.537e-05, MSE(pi1): 9.548e-03, MSE(pi2): 1.695e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 67800, Train loss: 9.568e+02, Test loss: 6.551e+05, MSE(e): 2.551e-05, MSE(pi1): 9.573e-03, MSE(pi2): 1.704e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 67900, Train loss: 1.016e+03, Test loss: 6.554e+05, MSE(e): 3.143e-05, MSE(pi1): 9.632e-03, MSE(pi2): 1.976e-05, MSE(pi3): 6.053e-03\n",
      "Epoch 68000, Train loss: 9.539e+02, Test loss: 6.550e+05, MSE(e): 2.521e-05, MSE(pi1): 9.533e-03, MSE(pi2): 1.684e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 68100, Train loss: 9.749e+02, Test loss: 6.546e+05, MSE(e): 2.675e-05, MSE(pi1): 1.031e-02, MSE(pi2): 1.765e-05, MSE(pi3): 6.042e-03\n",
      "Epoch 68200, Train loss: 9.530e+02, Test loss: 6.550e+05, MSE(e): 2.512e-05, MSE(pi1): 9.528e-03, MSE(pi2): 1.679e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 68300, Train loss: 9.530e+02, Test loss: 6.550e+05, MSE(e): 2.513e-05, MSE(pi1): 9.544e-03, MSE(pi2): 1.682e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 68400, Train loss: 9.523e+02, Test loss: 6.551e+05, MSE(e): 2.505e-05, MSE(pi1): 9.508e-03, MSE(pi2): 1.673e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 68500, Train loss: 9.517e+02, Test loss: 6.550e+05, MSE(e): 2.499e-05, MSE(pi1): 9.526e-03, MSE(pi2): 1.671e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 68600, Train loss: 1.732e+03, Test loss: 6.569e+05, MSE(e): 1.027e-04, MSE(pi1): 1.051e-02, MSE(pi2): 4.996e-05, MSE(pi3): 5.999e-03\n",
      "Epoch 68700, Train loss: 9.512e+02, Test loss: 6.550e+05, MSE(e): 2.491e-05, MSE(pi1): 9.588e-03, MSE(pi2): 1.666e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 68800, Train loss: 1.149e+03, Test loss: 6.554e+05, MSE(e): 4.443e-05, MSE(pi1): 1.104e-02, MSE(pi2): 2.552e-05, MSE(pi3): 5.938e-03\n",
      "Epoch 68900, Train loss: 1.301e+03, Test loss: 6.542e+05, MSE(e): 5.971e-05, MSE(pi1): 8.970e-03, MSE(pi2): 3.029e-05, MSE(pi3): 6.142e-03\n",
      "Epoch 69000, Train loss: 9.628e+02, Test loss: 6.558e+05, MSE(e): 2.537e-05, MSE(pi1): 9.294e-03, MSE(pi2): 1.691e-05, MSE(pi3): 6.162e-03\n",
      "Epoch 69100, Train loss: 9.493e+02, Test loss: 6.551e+05, MSE(e): 2.475e-05, MSE(pi1): 9.527e-03, MSE(pi2): 1.654e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 69200, Train loss: 9.949e+02, Test loss: 6.558e+05, MSE(e): 2.846e-05, MSE(pi1): 8.768e-03, MSE(pi2): 1.827e-05, MSE(pi3): 6.227e-03\n",
      "Epoch 69300, Train loss: 9.482e+02, Test loss: 6.551e+05, MSE(e): 2.465e-05, MSE(pi1): 9.507e-03, MSE(pi2): 1.649e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 69400, Train loss: 9.618e+02, Test loss: 6.554e+05, MSE(e): 2.604e-05, MSE(pi1): 9.627e-03, MSE(pi2): 1.723e-05, MSE(pi3): 6.051e-03\n",
      "Epoch 69500, Train loss: 9.473e+02, Test loss: 6.551e+05, MSE(e): 2.456e-05, MSE(pi1): 9.522e-03, MSE(pi2): 1.645e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 69600, Train loss: 9.476e+02, Test loss: 6.550e+05, MSE(e): 2.459e-05, MSE(pi1): 9.757e-03, MSE(pi2): 1.652e-05, MSE(pi3): 6.041e-03\n",
      "Epoch 69700, Train loss: 9.613e+02, Test loss: 6.547e+05, MSE(e): 2.594e-05, MSE(pi1): 9.772e-03, MSE(pi2): 1.698e-05, MSE(pi3): 6.042e-03\n",
      "Epoch 69800, Train loss: 9.460e+02, Test loss: 6.551e+05, MSE(e): 2.444e-05, MSE(pi1): 9.528e-03, MSE(pi2): 1.638e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 69900, Train loss: 9.770e+02, Test loss: 6.555e+05, MSE(e): 2.758e-05, MSE(pi1): 9.906e-03, MSE(pi2): 1.794e-05, MSE(pi3): 6.021e-03\n",
      "Epoch 70000, Train loss: 9.452e+02, Test loss: 6.551e+05, MSE(e): 2.436e-05, MSE(pi1): 9.530e-03, MSE(pi2): 1.634e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 70100, Train loss: 9.451e+02, Test loss: 6.552e+05, MSE(e): 2.435e-05, MSE(pi1): 9.557e-03, MSE(pi2): 1.631e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 70200, Train loss: 9.444e+02, Test loss: 6.551e+05, MSE(e): 2.427e-05, MSE(pi1): 9.561e-03, MSE(pi2): 1.628e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 70300, Train loss: 9.451e+02, Test loss: 6.551e+05, MSE(e): 2.434e-05, MSE(pi1): 9.527e-03, MSE(pi2): 1.625e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 70400, Train loss: 1.041e+03, Test loss: 6.550e+05, MSE(e): 3.382e-05, MSE(pi1): 9.296e-03, MSE(pi2): 1.980e-05, MSE(pi3): 6.097e-03\n",
      "Epoch 70500, Train loss: 9.431e+02, Test loss: 6.552e+05, MSE(e): 2.415e-05, MSE(pi1): 9.534e-03, MSE(pi2): 1.621e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 70600, Train loss: 1.060e+03, Test loss: 6.560e+05, MSE(e): 3.579e-05, MSE(pi1): 9.811e-03, MSE(pi2): 2.142e-05, MSE(pi3): 6.041e-03\n",
      "Epoch 70700, Train loss: 9.423e+02, Test loss: 6.552e+05, MSE(e): 2.407e-05, MSE(pi1): 9.530e-03, MSE(pi2): 1.615e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 70800, Train loss: 9.464e+02, Test loss: 6.548e+05, MSE(e): 2.446e-05, MSE(pi1): 9.459e-03, MSE(pi2): 1.621e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 70900, Train loss: 9.415e+02, Test loss: 6.552e+05, MSE(e): 2.398e-05, MSE(pi1): 9.524e-03, MSE(pi2): 1.610e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 71000, Train loss: 9.449e+02, Test loss: 6.550e+05, MSE(e): 2.431e-05, MSE(pi1): 9.549e-03, MSE(pi2): 1.616e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 71100, Train loss: 1.058e+03, Test loss: 6.564e+05, MSE(e): 3.574e-05, MSE(pi1): 9.854e-03, MSE(pi2): 2.141e-05, MSE(pi3): 6.024e-03\n",
      "Epoch 71200, Train loss: 9.404e+02, Test loss: 6.553e+05, MSE(e): 2.386e-05, MSE(pi1): 9.445e-03, MSE(pi2): 1.602e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 71300, Train loss: 9.400e+02, Test loss: 6.552e+05, MSE(e): 2.383e-05, MSE(pi1): 9.579e-03, MSE(pi2): 1.601e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 71400, Train loss: 1.214e+03, Test loss: 6.544e+05, MSE(e): 5.069e-05, MSE(pi1): 9.309e-03, MSE(pi2): 2.639e-05, MSE(pi3): 6.140e-03\n",
      "Epoch 71500, Train loss: 9.392e+02, Test loss: 6.552e+05, MSE(e): 2.375e-05, MSE(pi1): 9.508e-03, MSE(pi2): 1.594e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 71600, Train loss: 9.530e+02, Test loss: 6.551e+05, MSE(e): 2.505e-05, MSE(pi1): 9.209e-03, MSE(pi2): 1.631e-05, MSE(pi3): 6.103e-03\n",
      "Epoch 71700, Train loss: 9.384e+02, Test loss: 6.552e+05, MSE(e): 2.368e-05, MSE(pi1): 9.509e-03, MSE(pi2): 1.590e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 71800, Train loss: 9.401e+02, Test loss: 6.556e+05, MSE(e): 2.378e-05, MSE(pi1): 9.310e-03, MSE(pi2): 1.597e-05, MSE(pi3): 6.093e-03\n",
      "Epoch 71900, Train loss: 9.875e+02, Test loss: 6.567e+05, MSE(e): 2.662e-05, MSE(pi1): 9.602e-03, MSE(pi2): 1.784e-05, MSE(pi3): 6.253e-03\n",
      "Epoch 72000, Train loss: 9.372e+02, Test loss: 6.553e+05, MSE(e): 2.356e-05, MSE(pi1): 9.537e-03, MSE(pi2): 1.586e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 72100, Train loss: 9.366e+02, Test loss: 6.552e+05, MSE(e): 2.351e-05, MSE(pi1): 9.523e-03, MSE(pi2): 1.581e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 72200, Train loss: 9.497e+02, Test loss: 6.560e+05, MSE(e): 2.375e-05, MSE(pi1): 1.138e-02, MSE(pi2): 1.605e-05, MSE(pi3): 5.983e-03\n",
      "Epoch 72300, Train loss: 9.359e+02, Test loss: 6.554e+05, MSE(e): 2.344e-05, MSE(pi1): 9.521e-03, MSE(pi2): 1.577e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 72400, Train loss: 9.355e+02, Test loss: 6.553e+05, MSE(e): 2.340e-05, MSE(pi1): 9.524e-03, MSE(pi2): 1.575e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 72500, Train loss: 9.351e+02, Test loss: 6.552e+05, MSE(e): 2.336e-05, MSE(pi1): 9.523e-03, MSE(pi2): 1.572e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 72600, Train loss: 9.387e+02, Test loss: 6.555e+05, MSE(e): 2.370e-05, MSE(pi1): 9.586e-03, MSE(pi2): 1.593e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 72700, Train loss: 9.344e+02, Test loss: 6.553e+05, MSE(e): 2.329e-05, MSE(pi1): 9.525e-03, MSE(pi2): 1.568e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 72800, Train loss: 9.340e+02, Test loss: 6.553e+05, MSE(e): 2.325e-05, MSE(pi1): 9.526e-03, MSE(pi2): 1.566e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 72900, Train loss: 9.432e+02, Test loss: 6.560e+05, MSE(e): 2.401e-05, MSE(pi1): 9.857e-03, MSE(pi2): 1.610e-05, MSE(pi3): 6.045e-03\n",
      "Epoch 73000, Train loss: 9.333e+02, Test loss: 6.553e+05, MSE(e): 2.318e-05, MSE(pi1): 9.518e-03, MSE(pi2): 1.561e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 73100, Train loss: 9.329e+02, Test loss: 6.553e+05, MSE(e): 2.314e-05, MSE(pi1): 9.526e-03, MSE(pi2): 1.559e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 73200, Train loss: 9.415e+02, Test loss: 6.552e+05, MSE(e): 2.394e-05, MSE(pi1): 9.428e-03, MSE(pi2): 1.579e-05, MSE(pi3): 6.078e-03\n",
      "Epoch 73300, Train loss: 9.322e+02, Test loss: 6.553e+05, MSE(e): 2.306e-05, MSE(pi1): 9.533e-03, MSE(pi2): 1.555e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 73400, Train loss: 9.394e+02, Test loss: 6.553e+05, MSE(e): 2.376e-05, MSE(pi1): 9.442e-03, MSE(pi2): 1.572e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 73500, Train loss: 9.317e+02, Test loss: 6.553e+05, MSE(e): 2.300e-05, MSE(pi1): 9.639e-03, MSE(pi2): 1.552e-05, MSE(pi3): 6.052e-03\n",
      "Epoch 73600, Train loss: 2.860e+03, Test loss: 6.592e+05, MSE(e): 2.158e-04, MSE(pi1): 1.116e-02, MSE(pi2): 9.725e-05, MSE(pi3): 5.904e-03\n",
      "Epoch 73700, Train loss: 9.307e+02, Test loss: 6.553e+05, MSE(e): 2.292e-05, MSE(pi1): 9.527e-03, MSE(pi2): 1.545e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 73800, Train loss: 1.071e+03, Test loss: 6.555e+05, MSE(e): 3.612e-05, MSE(pi1): 8.220e-03, MSE(pi2): 2.086e-05, MSE(pi3): 6.272e-03\n",
      "Epoch 73900, Train loss: 9.300e+02, Test loss: 6.553e+05, MSE(e): 2.284e-05, MSE(pi1): 9.503e-03, MSE(pi2): 1.540e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 74000, Train loss: 9.745e+02, Test loss: 6.550e+05, MSE(e): 2.724e-05, MSE(pi1): 9.333e-03, MSE(pi2): 1.694e-05, MSE(pi3): 6.088e-03\n",
      "Epoch 74100, Train loss: 9.381e+02, Test loss: 6.554e+05, MSE(e): 2.282e-05, MSE(pi1): 1.024e-02, MSE(pi2): 1.537e-05, MSE(pi3): 6.075e-03\n",
      "Epoch 74200, Train loss: 9.470e+02, Test loss: 6.554e+05, MSE(e): 2.363e-05, MSE(pi1): 1.111e-02, MSE(pi2): 1.573e-05, MSE(pi3): 5.997e-03\n",
      "Epoch 74300, Train loss: 9.285e+02, Test loss: 6.553e+05, MSE(e): 2.270e-05, MSE(pi1): 9.516e-03, MSE(pi2): 1.532e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 74400, Train loss: 9.432e+02, Test loss: 6.548e+05, MSE(e): 2.391e-05, MSE(pi1): 1.055e-02, MSE(pi2): 1.612e-05, MSE(pi3): 5.986e-03\n",
      "Epoch 74500, Train loss: 9.278e+02, Test loss: 6.553e+05, MSE(e): 2.263e-05, MSE(pi1): 9.524e-03, MSE(pi2): 1.528e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 74600, Train loss: 9.276e+02, Test loss: 6.555e+05, MSE(e): 2.260e-05, MSE(pi1): 9.480e-03, MSE(pi2): 1.524e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 74700, Train loss: 9.278e+02, Test loss: 6.552e+05, MSE(e): 2.262e-05, MSE(pi1): 9.769e-03, MSE(pi2): 1.532e-05, MSE(pi3): 6.039e-03\n",
      "Epoch 74800, Train loss: 9.279e+02, Test loss: 6.553e+05, MSE(e): 2.263e-05, MSE(pi1): 9.501e-03, MSE(pi2): 1.522e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 74900, Train loss: 9.286e+02, Test loss: 6.554e+05, MSE(e): 2.273e-05, MSE(pi1): 9.570e-03, MSE(pi2): 1.536e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 75000, Train loss: 1.377e+03, Test loss: 6.571e+05, MSE(e): 6.755e-05, MSE(pi1): 1.040e-02, MSE(pi2): 3.487e-05, MSE(pi3): 5.978e-03\n",
      "Epoch 75100, Train loss: 9.256e+02, Test loss: 6.553e+05, MSE(e): 2.241e-05, MSE(pi1): 9.518e-03, MSE(pi2): 1.515e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 75200, Train loss: 9.310e+02, Test loss: 6.553e+05, MSE(e): 2.294e-05, MSE(pi1): 9.493e-03, MSE(pi2): 1.526e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 75300, Train loss: 9.450e+02, Test loss: 6.546e+05, MSE(e): 2.326e-05, MSE(pi1): 1.171e-02, MSE(pi2): 1.592e-05, MSE(pi3): 5.953e-03\n",
      "Epoch 75400, Train loss: 9.255e+02, Test loss: 6.554e+05, MSE(e): 2.241e-05, MSE(pi1): 9.532e-03, MSE(pi2): 1.517e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 75500, Train loss: 9.292e+02, Test loss: 6.554e+05, MSE(e): 2.279e-05, MSE(pi1): 9.587e-03, MSE(pi2): 1.537e-05, MSE(pi3): 6.054e-03\n",
      "Epoch 75600, Train loss: 9.278e+02, Test loss: 6.556e+05, MSE(e): 2.238e-05, MSE(pi1): 9.246e-03, MSE(pi2): 1.510e-05, MSE(pi3): 6.115e-03\n",
      "Epoch 75700, Train loss: 9.264e+02, Test loss: 6.554e+05, MSE(e): 2.248e-05, MSE(pi1): 9.441e-03, MSE(pi2): 1.506e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 75800, Train loss: 9.231e+02, Test loss: 6.553e+05, MSE(e): 2.217e-05, MSE(pi1): 9.525e-03, MSE(pi2): 1.500e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 75900, Train loss: 9.236e+02, Test loss: 6.558e+05, MSE(e): 2.219e-05, MSE(pi1): 9.458e-03, MSE(pi2): 1.502e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 76000, Train loss: 9.225e+02, Test loss: 6.553e+05, MSE(e): 2.210e-05, MSE(pi1): 9.522e-03, MSE(pi2): 1.496e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 76100, Train loss: 1.352e+03, Test loss: 6.548e+05, MSE(e): 6.478e-05, MSE(pi1): 8.942e-03, MSE(pi2): 3.180e-05, MSE(pi3): 6.145e-03\n",
      "Epoch 76200, Train loss: 9.218e+02, Test loss: 6.554e+05, MSE(e): 2.204e-05, MSE(pi1): 9.523e-03, MSE(pi2): 1.492e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 76300, Train loss: 9.215e+02, Test loss: 6.553e+05, MSE(e): 2.201e-05, MSE(pi1): 9.572e-03, MSE(pi2): 1.491e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 76400, Train loss: 1.077e+03, Test loss: 6.548e+05, MSE(e): 3.741e-05, MSE(pi1): 9.220e-03, MSE(pi2): 2.081e-05, MSE(pi3): 6.105e-03\n",
      "Epoch 76500, Train loss: 9.208e+02, Test loss: 6.554e+05, MSE(e): 2.194e-05, MSE(pi1): 9.531e-03, MSE(pi2): 1.486e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 76600, Train loss: 9.308e+02, Test loss: 6.553e+05, MSE(e): 2.276e-05, MSE(pi1): 8.847e-03, MSE(pi2): 1.533e-05, MSE(pi3): 6.148e-03\n",
      "Epoch 76700, Train loss: 9.201e+02, Test loss: 6.553e+05, MSE(e): 2.187e-05, MSE(pi1): 9.518e-03, MSE(pi2): 1.481e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 76800, Train loss: 9.302e+02, Test loss: 6.561e+05, MSE(e): 2.289e-05, MSE(pi1): 9.553e-03, MSE(pi2): 1.536e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 76900, Train loss: 9.195e+02, Test loss: 6.553e+05, MSE(e): 2.180e-05, MSE(pi1): 9.517e-03, MSE(pi2): 1.477e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 77000, Train loss: 1.620e+03, Test loss: 6.581e+05, MSE(e): 9.183e-05, MSE(pi1): 1.029e-02, MSE(pi2): 4.518e-05, MSE(pi3): 5.989e-03\n",
      "Epoch 77100, Train loss: 9.188e+02, Test loss: 6.554e+05, MSE(e): 2.174e-05, MSE(pi1): 9.521e-03, MSE(pi2): 1.474e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 77200, Train loss: 2.686e+03, Test loss: 6.548e+05, MSE(e): 1.977e-04, MSE(pi1): 8.419e-03, MSE(pi2): 8.592e-05, MSE(pi3): 6.243e-03\n",
      "Epoch 77300, Train loss: 9.182e+02, Test loss: 6.554e+05, MSE(e): 2.168e-05, MSE(pi1): 9.528e-03, MSE(pi2): 1.471e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 77400, Train loss: 9.217e+02, Test loss: 6.557e+05, MSE(e): 2.195e-05, MSE(pi1): 9.354e-03, MSE(pi2): 1.485e-05, MSE(pi3): 6.086e-03\n",
      "Epoch 77500, Train loss: 9.179e+02, Test loss: 6.553e+05, MSE(e): 2.165e-05, MSE(pi1): 9.481e-03, MSE(pi2): 1.464e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 77600, Train loss: 1.171e+03, Test loss: 6.559e+05, MSE(e): 4.658e-05, MSE(pi1): 8.800e-03, MSE(pi2): 2.415e-05, MSE(pi3): 6.176e-03\n",
      "Epoch 77700, Train loss: 9.168e+02, Test loss: 6.553e+05, MSE(e): 2.154e-05, MSE(pi1): 9.516e-03, MSE(pi2): 1.461e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 77800, Train loss: 1.133e+03, Test loss: 6.562e+05, MSE(e): 4.325e-05, MSE(pi1): 9.878e-03, MSE(pi2): 2.421e-05, MSE(pi3): 6.020e-03\n",
      "Epoch 77900, Train loss: 9.162e+02, Test loss: 6.554e+05, MSE(e): 2.148e-05, MSE(pi1): 9.518e-03, MSE(pi2): 1.458e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 78000, Train loss: 2.464e+03, Test loss: 6.586e+05, MSE(e): 1.762e-04, MSE(pi1): 1.087e-02, MSE(pi2): 8.045e-05, MSE(pi3): 5.928e-03\n",
      "Epoch 78100, Train loss: 9.156e+02, Test loss: 6.553e+05, MSE(e): 2.142e-05, MSE(pi1): 9.511e-03, MSE(pi2): 1.453e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 78200, Train loss: 9.338e+02, Test loss: 6.551e+05, MSE(e): 2.316e-05, MSE(pi1): 9.395e-03, MSE(pi2): 1.541e-05, MSE(pi3): 6.082e-03\n",
      "Epoch 78300, Train loss: 9.149e+02, Test loss: 6.553e+05, MSE(e): 2.135e-05, MSE(pi1): 9.518e-03, MSE(pi2): 1.450e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 78400, Train loss: 9.511e+02, Test loss: 6.558e+05, MSE(e): 2.462e-05, MSE(pi1): 8.998e-03, MSE(pi2): 1.561e-05, MSE(pi3): 6.150e-03\n",
      "Epoch 78500, Train loss: 9.142e+02, Test loss: 6.553e+05, MSE(e): 2.129e-05, MSE(pi1): 9.518e-03, MSE(pi2): 1.446e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 78600, Train loss: 9.150e+02, Test loss: 6.555e+05, MSE(e): 2.132e-05, MSE(pi1): 9.686e-03, MSE(pi2): 1.451e-05, MSE(pi3): 6.049e-03\n",
      "Epoch 78700, Train loss: 9.136e+02, Test loss: 6.553e+05, MSE(e): 2.122e-05, MSE(pi1): 9.516e-03, MSE(pi2): 1.442e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 78800, Train loss: 9.150e+02, Test loss: 6.552e+05, MSE(e): 2.131e-05, MSE(pi1): 9.693e-03, MSE(pi2): 1.444e-05, MSE(pi3): 6.049e-03\n",
      "Epoch 78900, Train loss: 9.130e+02, Test loss: 6.553e+05, MSE(e): 2.116e-05, MSE(pi1): 9.517e-03, MSE(pi2): 1.439e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 79000, Train loss: 9.224e+02, Test loss: 6.551e+05, MSE(e): 2.208e-05, MSE(pi1): 9.646e-03, MSE(pi2): 1.470e-05, MSE(pi3): 6.051e-03\n",
      "Epoch 79100, Train loss: 9.123e+02, Test loss: 6.553e+05, MSE(e): 2.110e-05, MSE(pi1): 9.514e-03, MSE(pi2): 1.435e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 79200, Train loss: 9.297e+02, Test loss: 6.552e+05, MSE(e): 2.283e-05, MSE(pi1): 9.833e-03, MSE(pi2): 1.527e-05, MSE(pi3): 6.030e-03\n",
      "Epoch 79300, Train loss: 9.117e+02, Test loss: 6.553e+05, MSE(e): 2.104e-05, MSE(pi1): 9.515e-03, MSE(pi2): 1.431e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 79400, Train loss: 9.118e+02, Test loss: 6.553e+05, MSE(e): 2.103e-05, MSE(pi1): 9.415e-03, MSE(pi2): 1.427e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 79500, Train loss: 9.115e+02, Test loss: 6.554e+05, MSE(e): 2.102e-05, MSE(pi1): 9.510e-03, MSE(pi2): 1.431e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 79600, Train loss: 9.823e+02, Test loss: 6.561e+05, MSE(e): 2.812e-05, MSE(pi1): 9.631e-03, MSE(pi2): 1.758e-05, MSE(pi3): 6.047e-03\n",
      "Epoch 79700, Train loss: 9.105e+02, Test loss: 6.553e+05, MSE(e): 2.092e-05, MSE(pi1): 9.516e-03, MSE(pi2): 1.425e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 79800, Train loss: 9.434e+02, Test loss: 6.555e+05, MSE(e): 2.420e-05, MSE(pi1): 9.857e-03, MSE(pi2): 1.584e-05, MSE(pi3): 6.029e-03\n",
      "Epoch 79900, Train loss: 9.182e+02, Test loss: 6.551e+05, MSE(e): 2.167e-05, MSE(pi1): 9.446e-03, MSE(pi2): 1.442e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 80000, Train loss: 9.100e+02, Test loss: 6.553e+05, MSE(e): 2.088e-05, MSE(pi1): 9.532e-03, MSE(pi2): 1.423e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 80100, Train loss: 9.128e+02, Test loss: 6.552e+05, MSE(e): 2.117e-05, MSE(pi1): 9.737e-03, MSE(pi2): 1.443e-05, MSE(pi3): 6.037e-03\n",
      "Epoch 80200, Train loss: 9.216e+02, Test loss: 6.555e+05, MSE(e): 2.206e-05, MSE(pi1): 9.625e-03, MSE(pi2): 1.483e-05, MSE(pi3): 6.048e-03\n",
      "Epoch 80300, Train loss: 9.087e+02, Test loss: 6.553e+05, MSE(e): 2.074e-05, MSE(pi1): 9.517e-03, MSE(pi2): 1.413e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 80400, Train loss: 9.200e+02, Test loss: 6.554e+05, MSE(e): 2.136e-05, MSE(pi1): 9.972e-03, MSE(pi2): 1.445e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 80500, Train loss: 9.082e+02, Test loss: 6.553e+05, MSE(e): 2.070e-05, MSE(pi1): 9.527e-03, MSE(pi2): 1.411e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 80600, Train loss: 9.100e+02, Test loss: 6.551e+05, MSE(e): 2.073e-05, MSE(pi1): 9.995e-03, MSE(pi2): 1.416e-05, MSE(pi3): 6.027e-03\n",
      "Epoch 80700, Train loss: 9.198e+02, Test loss: 6.555e+05, MSE(e): 2.187e-05, MSE(pi1): 9.668e-03, MSE(pi2): 1.472e-05, MSE(pi3): 6.044e-03\n",
      "Epoch 80800, Train loss: 9.145e+02, Test loss: 6.551e+05, MSE(e): 2.066e-05, MSE(pi1): 1.030e-02, MSE(pi2): 1.406e-05, MSE(pi3): 6.049e-03\n",
      "Epoch 80900, Train loss: 9.085e+02, Test loss: 6.553e+05, MSE(e): 2.073e-05, MSE(pi1): 9.559e-03, MSE(pi2): 1.414e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 81000, Train loss: 9.069e+02, Test loss: 6.552e+05, MSE(e): 2.056e-05, MSE(pi1): 9.668e-03, MSE(pi2): 1.404e-05, MSE(pi3): 6.046e-03\n",
      "Epoch 81100, Train loss: 9.144e+02, Test loss: 6.560e+05, MSE(e): 2.098e-05, MSE(pi1): 9.059e-03, MSE(pi2): 1.420e-05, MSE(pi3): 6.140e-03\n",
      "Epoch 81200, Train loss: 9.060e+02, Test loss: 6.552e+05, MSE(e): 2.048e-05, MSE(pi1): 9.536e-03, MSE(pi2): 1.397e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 81300, Train loss: 9.061e+02, Test loss: 6.552e+05, MSE(e): 2.047e-05, MSE(pi1): 9.513e-03, MSE(pi2): 1.394e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 81400, Train loss: 9.282e+02, Test loss: 6.544e+05, MSE(e): 2.237e-05, MSE(pi1): 1.035e-02, MSE(pi2): 1.482e-05, MSE(pi3): 6.010e-03\n",
      "Epoch 81500, Train loss: 9.053e+02, Test loss: 6.552e+05, MSE(e): 2.041e-05, MSE(pi1): 9.555e-03, MSE(pi2): 1.394e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 81600, Train loss: 1.324e+03, Test loss: 6.558e+05, MSE(e): 6.170e-05, MSE(pi1): 8.192e-03, MSE(pi2): 3.011e-05, MSE(pi3): 6.253e-03\n",
      "Epoch 81700, Train loss: 9.046e+02, Test loss: 6.552e+05, MSE(e): 2.033e-05, MSE(pi1): 9.505e-03, MSE(pi2): 1.387e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 81800, Train loss: 1.097e+03, Test loss: 6.546e+05, MSE(e): 3.931e-05, MSE(pi1): 9.112e-03, MSE(pi2): 2.114e-05, MSE(pi3): 6.124e-03\n",
      "Epoch 81900, Train loss: 9.041e+02, Test loss: 6.552e+05, MSE(e): 2.028e-05, MSE(pi1): 9.491e-03, MSE(pi2): 1.383e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 82000, Train loss: 9.614e+02, Test loss: 6.570e+05, MSE(e): 2.375e-05, MSE(pi1): 9.619e-03, MSE(pi2): 1.616e-05, MSE(pi3): 6.277e-03\n",
      "Epoch 82100, Train loss: 9.038e+02, Test loss: 6.551e+05, MSE(e): 2.026e-05, MSE(pi1): 9.507e-03, MSE(pi2): 1.379e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 82200, Train loss: 9.048e+02, Test loss: 6.552e+05, MSE(e): 2.036e-05, MSE(pi1): 9.532e-03, MSE(pi2): 1.391e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 82300, Train loss: 9.030e+02, Test loss: 6.552e+05, MSE(e): 2.016e-05, MSE(pi1): 9.497e-03, MSE(pi2): 1.376e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 82400, Train loss: 1.026e+03, Test loss: 6.553e+05, MSE(e): 3.179e-05, MSE(pi1): 9.569e-03, MSE(pi2): 1.801e-05, MSE(pi3): 6.121e-03\n",
      "Epoch 82500, Train loss: 9.023e+02, Test loss: 6.552e+05, MSE(e): 2.010e-05, MSE(pi1): 9.515e-03, MSE(pi2): 1.374e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 82600, Train loss: 9.474e+02, Test loss: 6.553e+05, MSE(e): 2.460e-05, MSE(pi1): 9.508e-03, MSE(pi2): 1.585e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 82700, Train loss: 9.017e+02, Test loss: 6.552e+05, MSE(e): 2.005e-05, MSE(pi1): 9.517e-03, MSE(pi2): 1.370e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 82800, Train loss: 1.318e+03, Test loss: 6.564e+05, MSE(e): 6.152e-05, MSE(pi1): 1.005e-02, MSE(pi2): 3.167e-05, MSE(pi3): 6.021e-03\n",
      "Epoch 82900, Train loss: 9.011e+02, Test loss: 6.551e+05, MSE(e): 1.999e-05, MSE(pi1): 9.520e-03, MSE(pi2): 1.367e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 83000, Train loss: 9.052e+02, Test loss: 6.550e+05, MSE(e): 2.038e-05, MSE(pi1): 9.766e-03, MSE(pi2): 1.383e-05, MSE(pi3): 6.037e-03\n",
      "Epoch 83100, Train loss: 9.006e+02, Test loss: 6.551e+05, MSE(e): 1.993e-05, MSE(pi1): 9.512e-03, MSE(pi2): 1.363e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 83200, Train loss: 9.020e+02, Test loss: 6.551e+05, MSE(e): 2.008e-05, MSE(pi1): 9.601e-03, MSE(pi2): 1.374e-05, MSE(pi3): 6.052e-03\n",
      "Epoch 83300, Train loss: 9.000e+02, Test loss: 6.551e+05, MSE(e): 1.988e-05, MSE(pi1): 9.515e-03, MSE(pi2): 1.360e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 83400, Train loss: 1.069e+03, Test loss: 6.552e+05, MSE(e): 3.648e-05, MSE(pi1): 1.087e-02, MSE(pi2): 2.116e-05, MSE(pi3): 5.950e-03\n",
      "Epoch 83500, Train loss: 8.995e+02, Test loss: 6.551e+05, MSE(e): 1.983e-05, MSE(pi1): 9.516e-03, MSE(pi2): 1.357e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 83600, Train loss: 8.992e+02, Test loss: 6.550e+05, MSE(e): 1.980e-05, MSE(pi1): 9.515e-03, MSE(pi2): 1.355e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 83700, Train loss: 9.179e+02, Test loss: 6.547e+05, MSE(e): 2.150e-05, MSE(pi1): 9.913e-03, MSE(pi2): 1.421e-05, MSE(pi3): 6.038e-03\n",
      "Epoch 83800, Train loss: 8.987e+02, Test loss: 6.551e+05, MSE(e): 1.975e-05, MSE(pi1): 9.516e-03, MSE(pi2): 1.352e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 83900, Train loss: 8.984e+02, Test loss: 6.550e+05, MSE(e): 1.972e-05, MSE(pi1): 9.512e-03, MSE(pi2): 1.350e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 84000, Train loss: 1.006e+03, Test loss: 6.549e+05, MSE(e): 3.040e-05, MSE(pi1): 9.155e-03, MSE(pi2): 1.747e-05, MSE(pi3): 6.108e-03\n",
      "Epoch 84100, Train loss: 8.979e+02, Test loss: 6.550e+05, MSE(e): 1.967e-05, MSE(pi1): 9.509e-03, MSE(pi2): 1.346e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 84200, Train loss: 9.113e+02, Test loss: 6.550e+05, MSE(e): 2.103e-05, MSE(pi1): 1.003e-02, MSE(pi2): 1.428e-05, MSE(pi3): 6.007e-03\n",
      "Epoch 84300, Train loss: 8.973e+02, Test loss: 6.550e+05, MSE(e): 1.962e-05, MSE(pi1): 9.514e-03, MSE(pi2): 1.344e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 84400, Train loss: 9.037e+02, Test loss: 6.549e+05, MSE(e): 2.022e-05, MSE(pi1): 9.403e-03, MSE(pi2): 1.356e-05, MSE(pi3): 6.074e-03\n",
      "Epoch 84500, Train loss: 1.488e+03, Test loss: 6.544e+05, MSE(e): 7.831e-05, MSE(pi1): 8.962e-03, MSE(pi2): 3.674e-05, MSE(pi3): 6.148e-03\n",
      "Epoch 84600, Train loss: 8.965e+02, Test loss: 6.550e+05, MSE(e): 1.954e-05, MSE(pi1): 9.515e-03, MSE(pi2): 1.339e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 84700, Train loss: 9.936e+02, Test loss: 6.561e+05, MSE(e): 2.922e-05, MSE(pi1): 9.829e-03, MSE(pi2): 1.778e-05, MSE(pi3): 6.030e-03\n",
      "Epoch 84800, Train loss: 8.960e+02, Test loss: 6.550e+05, MSE(e): 1.948e-05, MSE(pi1): 9.508e-03, MSE(pi2): 1.335e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 84900, Train loss: 9.115e+02, Test loss: 6.547e+05, MSE(e): 2.099e-05, MSE(pi1): 9.464e-03, MSE(pi2): 1.381e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 85000, Train loss: 8.957e+02, Test loss: 6.550e+05, MSE(e): 1.945e-05, MSE(pi1): 9.582e-03, MSE(pi2): 1.335e-05, MSE(pi3): 6.053e-03\n",
      "Epoch 85100, Train loss: 9.067e+02, Test loss: 6.547e+05, MSE(e): 2.051e-05, MSE(pi1): 9.376e-03, MSE(pi2): 1.360e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 85200, Train loss: 8.950e+02, Test loss: 6.550e+05, MSE(e): 1.938e-05, MSE(pi1): 9.469e-03, MSE(pi2): 1.328e-05, MSE(pi3): 6.065e-03\n",
      "Epoch 85300, Train loss: 8.973e+02, Test loss: 6.550e+05, MSE(e): 1.961e-05, MSE(pi1): 9.481e-03, MSE(pi2): 1.343e-05, MSE(pi3): 6.063e-03\n",
      "Epoch 85400, Train loss: 1.022e+03, Test loss: 6.546e+05, MSE(e): 3.194e-05, MSE(pi1): 9.082e-03, MSE(pi2): 1.798e-05, MSE(pi3): 6.116e-03\n",
      "Epoch 85500, Train loss: 8.943e+02, Test loss: 6.550e+05, MSE(e): 1.931e-05, MSE(pi1): 9.518e-03, MSE(pi2): 1.326e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 85600, Train loss: 8.964e+02, Test loss: 6.550e+05, MSE(e): 1.930e-05, MSE(pi1): 9.567e-03, MSE(pi2): 1.321e-05, MSE(pi3): 6.077e-03\n",
      "Epoch 85700, Train loss: 8.949e+02, Test loss: 6.551e+05, MSE(e): 1.938e-05, MSE(pi1): 9.534e-03, MSE(pi2): 1.330e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 85800, Train loss: 8.941e+02, Test loss: 6.549e+05, MSE(e): 1.925e-05, MSE(pi1): 9.367e-03, MSE(pi2): 1.318e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 85900, Train loss: 1.326e+03, Test loss: 6.561e+05, MSE(e): 5.835e-05, MSE(pi1): 1.004e-02, MSE(pi2): 2.971e-05, MSE(pi3): 6.423e-03\n",
      "Epoch 86000, Train loss: 8.929e+02, Test loss: 6.549e+05, MSE(e): 1.918e-05, MSE(pi1): 9.505e-03, MSE(pi2): 1.316e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 86100, Train loss: 8.926e+02, Test loss: 6.548e+05, MSE(e): 1.915e-05, MSE(pi1): 9.513e-03, MSE(pi2): 1.314e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 86200, Train loss: 8.966e+02, Test loss: 6.559e+05, MSE(e): 1.948e-05, MSE(pi1): 9.422e-03, MSE(pi2): 1.332e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 86300, Train loss: 8.922e+02, Test loss: 6.550e+05, MSE(e): 1.911e-05, MSE(pi1): 9.513e-03, MSE(pi2): 1.312e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 86400, Train loss: 8.919e+02, Test loss: 6.550e+05, MSE(e): 1.908e-05, MSE(pi1): 9.512e-03, MSE(pi2): 1.310e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 86500, Train loss: 8.917e+02, Test loss: 6.549e+05, MSE(e): 1.906e-05, MSE(pi1): 9.473e-03, MSE(pi2): 1.308e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 86600, Train loss: 8.915e+02, Test loss: 6.548e+05, MSE(e): 1.903e-05, MSE(pi1): 9.546e-03, MSE(pi2): 1.308e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 86700, Train loss: 1.242e+03, Test loss: 6.543e+05, MSE(e): 5.380e-05, MSE(pi1): 8.876e-03, MSE(pi2): 2.669e-05, MSE(pi3): 6.149e-03\n",
      "Epoch 86800, Train loss: 9.746e+02, Test loss: 6.544e+05, MSE(e): 2.725e-05, MSE(pi1): 9.216e-03, MSE(pi2): 1.609e-05, MSE(pi3): 6.100e-03\n",
      "Epoch 86900, Train loss: 8.907e+02, Test loss: 6.548e+05, MSE(e): 1.896e-05, MSE(pi1): 9.515e-03, MSE(pi2): 1.303e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 87000, Train loss: 8.941e+02, Test loss: 6.546e+05, MSE(e): 1.922e-05, MSE(pi1): 9.886e-03, MSE(pi2): 1.314e-05, MSE(pi3): 6.031e-03\n",
      "Epoch 87100, Train loss: 8.902e+02, Test loss: 6.548e+05, MSE(e): 1.891e-05, MSE(pi1): 9.506e-03, MSE(pi2): 1.299e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 87200, Train loss: 1.433e+03, Test loss: 6.544e+05, MSE(e): 7.212e-05, MSE(pi1): 1.067e-02, MSE(pi2): 3.460e-05, MSE(pi3): 6.047e-03\n",
      "Epoch 87300, Train loss: 8.897e+02, Test loss: 6.548e+05, MSE(e): 1.886e-05, MSE(pi1): 9.508e-03, MSE(pi2): 1.297e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 87400, Train loss: 8.895e+02, Test loss: 6.547e+05, MSE(e): 1.884e-05, MSE(pi1): 9.514e-03, MSE(pi2): 1.295e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 87500, Train loss: 1.024e+03, Test loss: 6.547e+05, MSE(e): 3.222e-05, MSE(pi1): 9.495e-03, MSE(pi2): 1.820e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 87600, Train loss: 8.890e+02, Test loss: 6.548e+05, MSE(e): 1.879e-05, MSE(pi1): 9.491e-03, MSE(pi2): 1.292e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 87700, Train loss: 8.888e+02, Test loss: 6.548e+05, MSE(e): 1.877e-05, MSE(pi1): 9.444e-03, MSE(pi2): 1.290e-05, MSE(pi3): 6.067e-03\n",
      "Epoch 87800, Train loss: 8.885e+02, Test loss: 6.547e+05, MSE(e): 1.874e-05, MSE(pi1): 9.500e-03, MSE(pi2): 1.289e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 87900, Train loss: 8.886e+02, Test loss: 6.547e+05, MSE(e): 1.876e-05, MSE(pi1): 9.585e-03, MSE(pi2): 1.293e-05, MSE(pi3): 6.051e-03\n",
      "Epoch 88000, Train loss: 8.880e+02, Test loss: 6.547e+05, MSE(e): 1.869e-05, MSE(pi1): 9.511e-03, MSE(pi2): 1.286e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 88100, Train loss: 9.594e+02, Test loss: 6.555e+05, MSE(e): 2.586e-05, MSE(pi1): 9.672e-03, MSE(pi2): 1.618e-05, MSE(pi3): 6.040e-03\n",
      "Epoch 88200, Train loss: 8.876e+02, Test loss: 6.547e+05, MSE(e): 1.865e-05, MSE(pi1): 9.511e-03, MSE(pi2): 1.283e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 88300, Train loss: 8.873e+02, Test loss: 6.547e+05, MSE(e): 1.862e-05, MSE(pi1): 9.509e-03, MSE(pi2): 1.282e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 88400, Train loss: 9.860e+02, Test loss: 6.542e+05, MSE(e): 2.836e-05, MSE(pi1): 9.600e-03, MSE(pi2): 1.653e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 88500, Train loss: 8.868e+02, Test loss: 6.546e+05, MSE(e): 1.857e-05, MSE(pi1): 9.512e-03, MSE(pi2): 1.279e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 88600, Train loss: 9.526e+02, Test loss: 6.555e+05, MSE(e): 2.443e-05, MSE(pi1): 8.770e-03, MSE(pi2): 1.501e-05, MSE(pi3): 6.206e-03\n",
      "Epoch 88700, Train loss: 8.863e+02, Test loss: 6.546e+05, MSE(e): 1.853e-05, MSE(pi1): 9.505e-03, MSE(pi2): 1.275e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 88800, Train loss: 1.167e+03, Test loss: 6.535e+05, MSE(e): 4.615e-05, MSE(pi1): 1.009e-02, MSE(pi2): 2.402e-05, MSE(pi3): 6.048e-03\n",
      "Epoch 88900, Train loss: 8.859e+02, Test loss: 6.546e+05, MSE(e): 1.848e-05, MSE(pi1): 9.510e-03, MSE(pi2): 1.274e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 89000, Train loss: 1.271e+03, Test loss: 6.557e+05, MSE(e): 5.707e-05, MSE(pi1): 1.003e-02, MSE(pi2): 2.952e-05, MSE(pi3): 6.003e-03\n",
      "Epoch 89100, Train loss: 8.856e+02, Test loss: 6.546e+05, MSE(e): 1.844e-05, MSE(pi1): 9.555e-03, MSE(pi2): 1.271e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 89200, Train loss: 9.992e+02, Test loss: 6.562e+05, MSE(e): 2.930e-05, MSE(pi1): 9.183e-03, MSE(pi2): 1.792e-05, MSE(pi3): 6.144e-03\n",
      "Epoch 89300, Train loss: 8.850e+02, Test loss: 6.546e+05, MSE(e): 1.839e-05, MSE(pi1): 9.465e-03, MSE(pi2): 1.266e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 89400, Train loss: 8.847e+02, Test loss: 6.545e+05, MSE(e): 1.836e-05, MSE(pi1): 9.513e-03, MSE(pi2): 1.266e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 89500, Train loss: 8.971e+02, Test loss: 6.545e+05, MSE(e): 1.957e-05, MSE(pi1): 9.426e-03, MSE(pi2): 1.300e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 89600, Train loss: 8.842e+02, Test loss: 6.545e+05, MSE(e): 1.832e-05, MSE(pi1): 9.511e-03, MSE(pi2): 1.263e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 89700, Train loss: 8.841e+02, Test loss: 6.544e+05, MSE(e): 1.830e-05, MSE(pi1): 9.529e-03, MSE(pi2): 1.261e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 89800, Train loss: 8.846e+02, Test loss: 6.547e+05, MSE(e): 1.836e-05, MSE(pi1): 9.536e-03, MSE(pi2): 1.268e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 89900, Train loss: 8.836e+02, Test loss: 6.545e+05, MSE(e): 1.825e-05, MSE(pi1): 9.508e-03, MSE(pi2): 1.259e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 90000, Train loss: 8.833e+02, Test loss: 6.545e+05, MSE(e): 1.823e-05, MSE(pi1): 9.512e-03, MSE(pi2): 1.257e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 90100, Train loss: 8.959e+02, Test loss: 6.546e+05, MSE(e): 1.944e-05, MSE(pi1): 9.346e-03, MSE(pi2): 1.291e-05, MSE(pi3): 6.080e-03\n",
      "Epoch 90200, Train loss: 8.829e+02, Test loss: 6.545e+05, MSE(e): 1.818e-05, MSE(pi1): 9.499e-03, MSE(pi2): 1.254e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 90300, Train loss: 9.131e+02, Test loss: 6.547e+05, MSE(e): 2.125e-05, MSE(pi1): 9.938e-03, MSE(pi2): 1.408e-05, MSE(pi3): 6.012e-03\n",
      "Epoch 90400, Train loss: 8.824e+02, Test loss: 6.544e+05, MSE(e): 1.814e-05, MSE(pi1): 9.511e-03, MSE(pi2): 1.251e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 90500, Train loss: 8.829e+02, Test loss: 6.544e+05, MSE(e): 1.819e-05, MSE(pi1): 9.528e-03, MSE(pi2): 1.257e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 90600, Train loss: 8.820e+02, Test loss: 6.545e+05, MSE(e): 1.809e-05, MSE(pi1): 9.511e-03, MSE(pi2): 1.249e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 90700, Train loss: 8.817e+02, Test loss: 6.544e+05, MSE(e): 1.807e-05, MSE(pi1): 9.538e-03, MSE(pi2): 1.248e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 90800, Train loss: 8.842e+02, Test loss: 6.539e+05, MSE(e): 1.828e-05, MSE(pi1): 9.573e-03, MSE(pi2): 1.261e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 90900, Train loss: 8.813e+02, Test loss: 6.544e+05, MSE(e): 1.803e-05, MSE(pi1): 9.511e-03, MSE(pi2): 1.244e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 91000, Train loss: 1.997e+03, Test loss: 6.541e+05, MSE(e): 1.290e-04, MSE(pi1): 8.623e-03, MSE(pi2): 5.710e-05, MSE(pi3): 6.203e-03\n",
      "Epoch 91100, Train loss: 8.809e+02, Test loss: 6.543e+05, MSE(e): 1.799e-05, MSE(pi1): 9.525e-03, MSE(pi2): 1.243e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 91200, Train loss: 8.913e+02, Test loss: 6.544e+05, MSE(e): 1.899e-05, MSE(pi1): 9.330e-03, MSE(pi2): 1.268e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 91300, Train loss: 2.052e+03, Test loss: 6.571e+05, MSE(e): 1.351e-04, MSE(pi1): 1.051e-02, MSE(pi2): 6.243e-05, MSE(pi3): 5.956e-03\n",
      "Epoch 91400, Train loss: 8.804e+02, Test loss: 6.542e+05, MSE(e): 1.792e-05, MSE(pi1): 9.545e-03, MSE(pi2): 1.237e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 91500, Train loss: 9.734e+02, Test loss: 6.541e+05, MSE(e): 2.693e-05, MSE(pi1): 9.213e-03, MSE(pi2): 1.557e-05, MSE(pi3): 6.120e-03\n",
      "Epoch 91600, Train loss: 8.797e+02, Test loss: 6.542e+05, MSE(e): 1.787e-05, MSE(pi1): 9.514e-03, MSE(pi2): 1.235e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 91700, Train loss: 8.811e+02, Test loss: 6.543e+05, MSE(e): 1.785e-05, MSE(pi1): 9.574e-03, MSE(pi2): 1.232e-05, MSE(pi3): 6.069e-03\n",
      "Epoch 91800, Train loss: 8.801e+02, Test loss: 6.543e+05, MSE(e): 1.792e-05, MSE(pi1): 9.546e-03, MSE(pi2): 1.240e-05, MSE(pi3): 6.055e-03\n",
      "Epoch 91900, Train loss: 8.790e+02, Test loss: 6.542e+05, MSE(e): 1.780e-05, MSE(pi1): 9.509e-03, MSE(pi2): 1.230e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 92000, Train loss: 8.788e+02, Test loss: 6.541e+05, MSE(e): 1.778e-05, MSE(pi1): 9.508e-03, MSE(pi2): 1.229e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 92100, Train loss: 9.181e+02, Test loss: 6.543e+05, MSE(e): 2.175e-05, MSE(pi1): 9.675e-03, MSE(pi2): 1.420e-05, MSE(pi3): 6.039e-03\n",
      "Epoch 92200, Train loss: 8.784e+02, Test loss: 6.542e+05, MSE(e): 1.774e-05, MSE(pi1): 9.507e-03, MSE(pi2): 1.226e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 92300, Train loss: 8.806e+02, Test loss: 6.543e+05, MSE(e): 1.786e-05, MSE(pi1): 9.431e-03, MSE(pi2): 1.234e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 92400, Train loss: 8.788e+02, Test loss: 6.540e+05, MSE(e): 1.778e-05, MSE(pi1): 9.484e-03, MSE(pi2): 1.223e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 92500, Train loss: 9.237e+02, Test loss: 6.546e+05, MSE(e): 2.222e-05, MSE(pi1): 1.010e-02, MSE(pi2): 1.443e-05, MSE(pi3): 6.006e-03\n",
      "Epoch 92600, Train loss: 8.775e+02, Test loss: 6.541e+05, MSE(e): 1.765e-05, MSE(pi1): 9.510e-03, MSE(pi2): 1.221e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 92700, Train loss: 2.183e+03, Test loss: 6.538e+05, MSE(e): 1.475e-04, MSE(pi1): 8.634e-03, MSE(pi2): 6.434e-05, MSE(pi3): 6.213e-03\n",
      "Epoch 92800, Train loss: 8.771e+02, Test loss: 6.540e+05, MSE(e): 1.761e-05, MSE(pi1): 9.516e-03, MSE(pi2): 1.218e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 92900, Train loss: 9.316e+02, Test loss: 6.542e+05, MSE(e): 2.299e-05, MSE(pi1): 1.008e-02, MSE(pi2): 1.476e-05, MSE(pi3): 6.009e-03\n",
      "Epoch 93000, Train loss: 8.783e+02, Test loss: 6.540e+05, MSE(e): 1.775e-05, MSE(pi1): 9.562e-03, MSE(pi2): 1.229e-05, MSE(pi3): 6.052e-03\n",
      "Epoch 93100, Train loss: 8.765e+02, Test loss: 6.539e+05, MSE(e): 1.755e-05, MSE(pi1): 9.496e-03, MSE(pi2): 1.213e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 93200, Train loss: 9.432e+02, Test loss: 6.546e+05, MSE(e): 2.419e-05, MSE(pi1): 9.668e-03, MSE(pi2): 1.520e-05, MSE(pi3): 6.047e-03\n",
      "Epoch 93300, Train loss: 8.760e+02, Test loss: 6.539e+05, MSE(e): 1.750e-05, MSE(pi1): 9.505e-03, MSE(pi2): 1.211e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 93400, Train loss: 8.911e+02, Test loss: 6.536e+05, MSE(e): 1.773e-05, MSE(pi1): 1.086e-02, MSE(pi2): 1.216e-05, MSE(pi3): 6.051e-03\n",
      "Epoch 93500, Train loss: 8.757e+02, Test loss: 6.541e+05, MSE(e): 1.747e-05, MSE(pi1): 9.501e-03, MSE(pi2): 1.211e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 93600, Train loss: 8.754e+02, Test loss: 6.540e+05, MSE(e): 1.744e-05, MSE(pi1): 9.509e-03, MSE(pi2): 1.208e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 93700, Train loss: 8.752e+02, Test loss: 6.539e+05, MSE(e): 1.742e-05, MSE(pi1): 9.507e-03, MSE(pi2): 1.207e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 93800, Train loss: 8.801e+02, Test loss: 6.539e+05, MSE(e): 1.744e-05, MSE(pi1): 9.798e-03, MSE(pi2): 1.204e-05, MSE(pi3): 6.078e-03\n",
      "Epoch 93900, Train loss: 9.084e+02, Test loss: 6.533e+05, MSE(e): 2.047e-05, MSE(pi1): 1.021e-02, MSE(pi2): 1.336e-05, MSE(pi3): 6.016e-03\n",
      "Epoch 94000, Train loss: 8.745e+02, Test loss: 6.537e+05, MSE(e): 1.736e-05, MSE(pi1): 9.514e-03, MSE(pi2): 1.203e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 94100, Train loss: 8.745e+02, Test loss: 6.538e+05, MSE(e): 1.736e-05, MSE(pi1): 9.533e-03, MSE(pi2): 1.204e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 94200, Train loss: 8.741e+02, Test loss: 6.537e+05, MSE(e): 1.732e-05, MSE(pi1): 9.508e-03, MSE(pi2): 1.200e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 94300, Train loss: 9.299e+02, Test loss: 6.539e+05, MSE(e): 2.267e-05, MSE(pi1): 9.837e-03, MSE(pi2): 1.448e-05, MSE(pi3): 6.048e-03\n",
      "Epoch 94400, Train loss: 8.737e+02, Test loss: 6.537e+05, MSE(e): 1.728e-05, MSE(pi1): 9.506e-03, MSE(pi2): 1.198e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 94500, Train loss: 8.735e+02, Test loss: 6.537e+05, MSE(e): 1.726e-05, MSE(pi1): 9.509e-03, MSE(pi2): 1.196e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 94600, Train loss: 8.870e+02, Test loss: 6.553e+05, MSE(e): 1.815e-05, MSE(pi1): 8.877e-03, MSE(pi2): 1.244e-05, MSE(pi3): 6.167e-03\n",
      "Epoch 94700, Train loss: 8.731e+02, Test loss: 6.537e+05, MSE(e): 1.722e-05, MSE(pi1): 9.535e-03, MSE(pi2): 1.195e-05, MSE(pi3): 6.055e-03\n",
      "Epoch 94800, Train loss: 8.798e+02, Test loss: 6.537e+05, MSE(e): 1.724e-05, MSE(pi1): 9.995e-03, MSE(pi2): 1.192e-05, MSE(pi3): 6.075e-03\n",
      "Epoch 94900, Train loss: 8.742e+02, Test loss: 6.536e+05, MSE(e): 1.730e-05, MSE(pi1): 9.379e-03, MSE(pi2): 1.190e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 95000, Train loss: 8.726e+02, Test loss: 6.536e+05, MSE(e): 1.717e-05, MSE(pi1): 9.523e-03, MSE(pi2): 1.192e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 95100, Train loss: 8.729e+02, Test loss: 6.535e+05, MSE(e): 1.721e-05, MSE(pi1): 9.540e-03, MSE(pi2): 1.195e-05, MSE(pi3): 6.054e-03\n",
      "Epoch 95200, Train loss: 8.721e+02, Test loss: 6.536e+05, MSE(e): 1.711e-05, MSE(pi1): 9.503e-03, MSE(pi2): 1.187e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 95300, Train loss: 8.718e+02, Test loss: 6.535e+05, MSE(e): 1.709e-05, MSE(pi1): 9.509e-03, MSE(pi2): 1.186e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 95400, Train loss: 9.283e+02, Test loss: 6.551e+05, MSE(e): 2.197e-05, MSE(pi1): 9.570e-03, MSE(pi2): 1.420e-05, MSE(pi3): 6.129e-03\n",
      "Epoch 95500, Train loss: 8.715e+02, Test loss: 6.536e+05, MSE(e): 1.705e-05, MSE(pi1): 9.488e-03, MSE(pi2): 1.183e-05, MSE(pi3): 6.060e-03\n",
      "Epoch 95600, Train loss: 8.715e+02, Test loss: 6.535e+05, MSE(e): 1.704e-05, MSE(pi1): 9.543e-03, MSE(pi2): 1.182e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 95700, Train loss: 8.711e+02, Test loss: 6.534e+05, MSE(e): 1.701e-05, MSE(pi1): 9.502e-03, MSE(pi2): 1.181e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 95800, Train loss: 8.732e+02, Test loss: 6.535e+05, MSE(e): 1.721e-05, MSE(pi1): 9.515e-03, MSE(pi2): 1.183e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 95900, Train loss: 8.707e+02, Test loss: 6.534e+05, MSE(e): 1.698e-05, MSE(pi1): 9.506e-03, MSE(pi2): 1.178e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 96000, Train loss: 5.514e+03, Test loss: 6.568e+05, MSE(e): 4.795e-04, MSE(pi1): 7.513e-03, MSE(pi2): 2.004e-04, MSE(pi3): 6.433e-03\n",
      "Epoch 96100, Train loss: 8.704e+02, Test loss: 6.535e+05, MSE(e): 1.695e-05, MSE(pi1): 9.509e-03, MSE(pi2): 1.175e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 96200, Train loss: 8.701e+02, Test loss: 6.534e+05, MSE(e): 1.692e-05, MSE(pi1): 9.506e-03, MSE(pi2): 1.175e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 96300, Train loss: 8.699e+02, Test loss: 6.533e+05, MSE(e): 1.690e-05, MSE(pi1): 9.508e-03, MSE(pi2): 1.174e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 96400, Train loss: 8.887e+02, Test loss: 6.530e+05, MSE(e): 1.873e-05, MSE(pi1): 9.423e-03, MSE(pi2): 1.233e-05, MSE(pi3): 6.071e-03\n",
      "Epoch 96500, Train loss: 8.696e+02, Test loss: 6.532e+05, MSE(e): 1.687e-05, MSE(pi1): 9.523e-03, MSE(pi2): 1.171e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 96600, Train loss: 8.711e+02, Test loss: 6.535e+05, MSE(e): 1.696e-05, MSE(pi1): 9.322e-03, MSE(pi2): 1.176e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 96700, Train loss: 8.738e+02, Test loss: 6.534e+05, MSE(e): 1.687e-05, MSE(pi1): 9.703e-03, MSE(pi2): 1.169e-05, MSE(pi3): 6.080e-03\n",
      "Epoch 96800, Train loss: 8.695e+02, Test loss: 6.532e+05, MSE(e): 1.685e-05, MSE(pi1): 9.517e-03, MSE(pi2): 1.167e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 96900, Train loss: 8.687e+02, Test loss: 6.532e+05, MSE(e): 1.678e-05, MSE(pi1): 9.504e-03, MSE(pi2): 1.166e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 97000, Train loss: 8.754e+02, Test loss: 6.533e+05, MSE(e): 1.747e-05, MSE(pi1): 9.554e-03, MSE(pi2): 1.205e-05, MSE(pi3): 6.052e-03\n",
      "Epoch 97100, Train loss: 8.741e+02, Test loss: 6.532e+05, MSE(e): 1.734e-05, MSE(pi1): 9.583e-03, MSE(pi2): 1.199e-05, MSE(pi3): 6.048e-03\n",
      "Epoch 97200, Train loss: 8.699e+02, Test loss: 6.530e+05, MSE(e): 1.687e-05, MSE(pi1): 9.635e-03, MSE(pi2): 1.166e-05, MSE(pi3): 6.048e-03\n",
      "Epoch 97300, Train loss: 8.681e+02, Test loss: 6.531e+05, MSE(e): 1.672e-05, MSE(pi1): 9.518e-03, MSE(pi2): 1.164e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 97400, Train loss: 8.707e+02, Test loss: 6.533e+05, MSE(e): 1.694e-05, MSE(pi1): 9.304e-03, MSE(pi2): 1.175e-05, MSE(pi3): 6.082e-03\n",
      "Epoch 97500, Train loss: 8.772e+02, Test loss: 6.529e+05, MSE(e): 1.759e-05, MSE(pi1): 9.517e-03, MSE(pi2): 1.185e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 97600, Train loss: 8.673e+02, Test loss: 6.531e+05, MSE(e): 1.664e-05, MSE(pi1): 9.468e-03, MSE(pi2): 1.156e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 97700, Train loss: 8.678e+02, Test loss: 6.528e+05, MSE(e): 1.667e-05, MSE(pi1): 9.382e-03, MSE(pi2): 1.155e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 97800, Train loss: 8.669e+02, Test loss: 6.530e+05, MSE(e): 1.661e-05, MSE(pi1): 9.508e-03, MSE(pi2): 1.155e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 97900, Train loss: 9.623e+02, Test loss: 6.525e+05, MSE(e): 2.605e-05, MSE(pi1): 9.367e-03, MSE(pi2): 1.510e-05, MSE(pi3): 6.081e-03\n",
      "Epoch 98000, Train loss: 8.668e+02, Test loss: 6.531e+05, MSE(e): 1.659e-05, MSE(pi1): 9.555e-03, MSE(pi2): 1.153e-05, MSE(pi3): 6.053e-03\n",
      "Epoch 98100, Train loss: 8.664e+02, Test loss: 6.530e+05, MSE(e): 1.655e-05, MSE(pi1): 9.504e-03, MSE(pi2): 1.152e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 98200, Train loss: 8.787e+02, Test loss: 6.528e+05, MSE(e): 1.663e-05, MSE(pi1): 1.078e-02, MSE(pi2): 1.155e-05, MSE(pi3): 6.046e-03\n",
      "Epoch 98300, Train loss: 1.797e+03, Test loss: 6.539e+05, MSE(e): 1.095e-04, MSE(pi1): 1.076e-02, MSE(pi2): 5.129e-05, MSE(pi3): 5.946e-03\n",
      "Epoch 98400, Train loss: 8.658e+02, Test loss: 6.528e+05, MSE(e): 1.649e-05, MSE(pi1): 9.516e-03, MSE(pi2): 1.148e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 98500, Train loss: 3.369e+03, Test loss: 6.517e+05, MSE(e): 2.659e-04, MSE(pi1): 8.531e-03, MSE(pi2): 1.132e-04, MSE(pi3): 6.239e-03\n",
      "Epoch 98600, Train loss: 8.655e+02, Test loss: 6.530e+05, MSE(e): 1.646e-05, MSE(pi1): 9.499e-03, MSE(pi2): 1.146e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 98700, Train loss: 8.653e+02, Test loss: 6.529e+05, MSE(e): 1.644e-05, MSE(pi1): 9.505e-03, MSE(pi2): 1.145e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 98800, Train loss: 8.770e+02, Test loss: 6.526e+05, MSE(e): 1.657e-05, MSE(pi1): 1.118e-02, MSE(pi2): 1.157e-05, MSE(pi3): 5.995e-03\n",
      "Epoch 98900, Train loss: 8.649e+02, Test loss: 6.527e+05, MSE(e): 1.641e-05, MSE(pi1): 9.544e-03, MSE(pi2): 1.143e-05, MSE(pi3): 6.054e-03\n",
      "Epoch 99000, Train loss: 8.733e+02, Test loss: 6.528e+05, MSE(e): 1.720e-05, MSE(pi1): 9.300e-03, MSE(pi2): 1.161e-05, MSE(pi3): 6.084e-03\n",
      "Epoch 99100, Train loss: 9.188e+02, Test loss: 6.529e+05, MSE(e): 2.184e-05, MSE(pi1): 9.691e-03, MSE(pi2): 1.397e-05, MSE(pi3): 6.035e-03\n",
      "Epoch 99200, Train loss: 1.599e+03, Test loss: 6.554e+05, MSE(e): 8.873e-05, MSE(pi1): 9.981e-03, MSE(pi2): 4.336e-05, MSE(pi3): 6.122e-03\n",
      "Epoch 99300, Train loss: 8.642e+02, Test loss: 6.527e+05, MSE(e): 1.634e-05, MSE(pi1): 9.505e-03, MSE(pi2): 1.139e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 99400, Train loss: 3.720e+03, Test loss: 6.531e+05, MSE(e): 3.009e-04, MSE(pi1): 8.720e-03, MSE(pi2): 1.274e-04, MSE(pi3): 6.238e-03\n",
      "Epoch 99500, Train loss: 8.639e+02, Test loss: 6.527e+05, MSE(e): 1.630e-05, MSE(pi1): 9.493e-03, MSE(pi2): 1.134e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 99600, Train loss: 8.636e+02, Test loss: 6.526e+05, MSE(e): 1.627e-05, MSE(pi1): 9.501e-03, MSE(pi2): 1.134e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 99700, Train loss: 8.917e+02, Test loss: 6.524e+05, MSE(e): 1.902e-05, MSE(pi1): 9.513e-03, MSE(pi2): 1.228e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 99800, Train loss: 8.632e+02, Test loss: 6.525e+05, MSE(e): 1.624e-05, MSE(pi1): 9.498e-03, MSE(pi2): 1.131e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 99900, Train loss: 8.831e+02, Test loss: 6.528e+05, MSE(e): 1.825e-05, MSE(pi1): 9.548e-03, MSE(pi2): 1.233e-05, MSE(pi3): 6.051e-03\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "params_to_update = filter(lambda p: p.requires_grad, pretrained_pgnniv.parameters())\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=3e-4)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "train_loop(pretrained_pgnniv, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_epoch = n_epochs-1\n",
    "# n_epochs = 20000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 5\n",
    "\n",
    "# second_lr = 3e-4\n",
    "\n",
    "# train_loop(pretrained_pgnniv, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7eff28a16360>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parametros de entrenamiento\n",
    "# start_epoch = 9000\n",
    "# n_epochs = 10000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 100\n",
    "\n",
    "# second_lr = 1e-4\n",
    "\n",
    "# train_loop(model, optimizer, X_train_NN, y_train_NN, f_train_NN, X_test_NN, y_test_NN, f_test_NN,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
