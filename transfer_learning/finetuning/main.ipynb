{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import GPUtil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from utils.checkpoints import load_results\n",
    "\n",
    "from architectures.pgnniv_baseline import PGNNIVBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_1000\n",
      "Folder successfully created at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_1000/finetuning\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear_1000/sigmoid_nonlinear_1000.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_1000')\n",
    "\n",
    "PRETRAINED_RESULTS_PATH = os.path.join(ROOT_PATH, r'results/non_linear_1000_0/baseline_model_10')\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_1000/finetuning')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_TRANSFERLEARNING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear_1000/sigmoid_nonlinear_1000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 800\n",
      "Validation dataset length: 200\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X_train, y_train, K_train, f_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other parameters\n",
    "n_filters_explanatory = 5\n",
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_autoencoder = PretrainedAutoencoder(autoencoder_input_shape, latent_space_dim, autoencoder_output_shape).to(DEVICE)\n",
    "pretrained_pgnniv = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(pretrained_pgnniv.parameters(), lr=1e-4)\n",
    "pretrained_pgnniv, optimizer, lists = load_results(pretrained_pgnniv, optimizer, PRETRAINED_RESULTS_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6190527050>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgnniv_pretrained_encoder = pretrained_pgnniv.encoder\n",
    "pgnniv_pretrained_decoder = pretrained_pgnniv.decoder\n",
    "pgnniv_pretrained_exp = pretrained_pgnniv.explanatory\n",
    "\n",
    "for param in pgnniv_pretrained_encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pgnniv_pretrained_decoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pgnniv_pretrained_exp.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def reinitialize_model(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            # Reinitialize Conv2d weights and biases\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            # Reinitialize Linear weights and biases\n",
    "            nn.init.kaiming_uniform_(module.weight, a=math.sqrt(5))\n",
    "            if module.bias is not None:\n",
    "                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(module.weight)\n",
    "                bound = 1 / math.sqrt(fan_in)\n",
    "                nn.init.uniform_(module.bias, -bound, bound)\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            # Reinitialize BatchNorm layers\n",
    "            nn.init.constant_(module.weight, 1)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "\n",
    "# reinitialize_model(pgnniv_pretrained_decoder)\n",
    "# reinitialize_model(pgnniv_pretrained_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 4.094e+08, Test loss: 4.201e+08, MSE(e): 4.089e+01, MSE(pi1): 2.640e+01, MSE(pi2): 1.746e+01, MSE(pi3): 2.147e+00\n",
      "Epoch 100, Train loss: 2.053e+07, Test loss: 2.204e+07, MSE(e): 1.990e+00, MSE(pi1): 2.994e+01, MSE(pi2): 1.500e+00, MSE(pi3): 3.268e+00\n",
      "Epoch 200, Train loss: 1.010e+07, Test loss: 1.049e+07, MSE(e): 9.647e-01, MSE(pi1): 2.442e+01, MSE(pi2): 6.744e-01, MSE(pi3): 2.089e+00\n",
      "Epoch 300, Train loss: 5.833e+06, Test loss: 6.224e+06, MSE(e): 5.518e-01, MSE(pi1): 1.943e+01, MSE(pi2): 3.372e-01, MSE(pi3): 1.205e+00\n",
      "Epoch 400, Train loss: 3.438e+06, Test loss: 3.719e+06, MSE(e): 3.187e-01, MSE(pi1): 1.610e+01, MSE(pi2): 1.780e-01, MSE(pi3): 9.043e-01\n",
      "Epoch 500, Train loss: 2.252e+06, Test loss: 2.584e+06, MSE(e): 2.217e-01, MSE(pi1): 2.047e+00, MSE(pi2): 1.200e-01, MSE(pi3): 1.433e-01\n",
      "Epoch 600, Train loss: 1.591e+06, Test loss: 1.892e+06, MSE(e): 1.579e-01, MSE(pi1): 5.731e-01, MSE(pi2): 8.479e-02, MSE(pi3): 5.601e-02\n",
      "Epoch 700, Train loss: 1.170e+06, Test loss: 1.418e+06, MSE(e): 1.161e-01, MSE(pi1): 4.218e-01, MSE(pi2): 6.159e-02, MSE(pi3): 4.118e-02\n",
      "Epoch 800, Train loss: 8.797e+05, Test loss: 1.074e+06, MSE(e): 8.734e-02, MSE(pi1): 3.062e-01, MSE(pi2): 4.562e-02, MSE(pi3): 3.132e-02\n",
      "Epoch 900, Train loss: 6.737e+05, Test loss: 8.163e+05, MSE(e): 6.690e-02, MSE(pi1): 2.160e-01, MSE(pi2): 3.453e-02, MSE(pi3): 2.459e-02\n",
      "Epoch 1000, Train loss: 5.227e+05, Test loss: 6.019e+05, MSE(e): 5.192e-02, MSE(pi1): 1.516e-01, MSE(pi2): 2.648e-02, MSE(pi3): 1.952e-02\n",
      "Epoch 1100, Train loss: 4.186e+05, Test loss: 4.781e+05, MSE(e): 4.158e-02, MSE(pi1): 1.173e-01, MSE(pi2): 2.110e-02, MSE(pi3): 1.644e-02\n",
      "Epoch 1200, Train loss: 3.175e+05, Test loss: 4.008e+05, MSE(e): 3.151e-02, MSE(pi1): 9.447e-02, MSE(pi2): 1.618e-02, MSE(pi3): 1.422e-02\n",
      "Epoch 1300, Train loss: 2.510e+05, Test loss: 3.328e+05, MSE(e): 2.489e-02, MSE(pi1): 7.768e-02, MSE(pi2): 1.288e-02, MSE(pi3): 1.278e-02\n",
      "Epoch 1400, Train loss: 2.012e+05, Test loss: 2.728e+05, MSE(e): 1.993e-02, MSE(pi1): 6.545e-02, MSE(pi2): 1.043e-02, MSE(pi3): 1.174e-02\n",
      "Epoch 1500, Train loss: 1.603e+05, Test loss: 2.200e+05, MSE(e): 1.586e-02, MSE(pi1): 5.471e-02, MSE(pi2): 8.443e-03, MSE(pi3): 1.100e-02\n",
      "Epoch 1600, Train loss: 1.288e+05, Test loss: 1.769e+05, MSE(e): 1.273e-02, MSE(pi1): 4.488e-02, MSE(pi2): 6.891e-03, MSE(pi3): 1.053e-02\n",
      "Epoch 1700, Train loss: 1.003e+05, Test loss: 1.395e+05, MSE(e): 9.889e-03, MSE(pi1): 3.804e-02, MSE(pi2): 5.493e-03, MSE(pi3): 1.015e-02\n",
      "Epoch 1800, Train loss: 8.132e+04, Test loss: 1.140e+05, MSE(e): 7.998e-03, MSE(pi1): 3.457e-02, MSE(pi2): 4.511e-03, MSE(pi3): 9.893e-03\n",
      "Epoch 1900, Train loss: 6.926e+04, Test loss: 9.668e+04, MSE(e): 6.797e-03, MSE(pi1): 3.161e-02, MSE(pi2): 3.854e-03, MSE(pi3): 9.678e-03\n",
      "Epoch 2000, Train loss: 6.042e+04, Test loss: 8.432e+04, MSE(e): 5.917e-03, MSE(pi1): 2.967e-02, MSE(pi2): 3.366e-03, MSE(pi3): 9.495e-03\n",
      "Epoch 2100, Train loss: 5.348e+04, Test loss: 7.515e+04, MSE(e): 5.226e-03, MSE(pi1): 2.799e-02, MSE(pi2): 2.981e-03, MSE(pi3): 9.336e-03\n",
      "Epoch 2200, Train loss: 4.770e+04, Test loss: 6.782e+04, MSE(e): 4.652e-03, MSE(pi1): 2.605e-02, MSE(pi2): 2.663e-03, MSE(pi3): 9.186e-03\n",
      "Epoch 2300, Train loss: 4.224e+04, Test loss: 6.055e+04, MSE(e): 4.107e-03, MSE(pi1): 2.541e-02, MSE(pi2): 2.374e-03, MSE(pi3): 9.057e-03\n",
      "Epoch 2400, Train loss: 3.811e+04, Test loss: 5.482e+04, MSE(e): 3.698e-03, MSE(pi1): 2.381e-02, MSE(pi2): 2.144e-03, MSE(pi3): 8.948e-03\n",
      "Epoch 2500, Train loss: 3.468e+04, Test loss: 5.020e+04, MSE(e): 3.357e-03, MSE(pi1): 2.249e-02, MSE(pi2): 1.951e-03, MSE(pi3): 8.849e-03\n",
      "Epoch 2600, Train loss: 3.165e+04, Test loss: 4.626e+04, MSE(e): 3.055e-03, MSE(pi1): 2.207e-02, MSE(pi2): 1.779e-03, MSE(pi3): 8.758e-03\n",
      "Epoch 2700, Train loss: 2.892e+04, Test loss: 4.288e+04, MSE(e): 2.783e-03, MSE(pi1): 2.169e-02, MSE(pi2): 1.622e-03, MSE(pi3): 8.680e-03\n",
      "Epoch 2800, Train loss: 2.655e+04, Test loss: 3.998e+04, MSE(e): 2.549e-03, MSE(pi1): 1.974e-02, MSE(pi2): 1.487e-03, MSE(pi3): 8.600e-03\n",
      "Epoch 2900, Train loss: 2.452e+04, Test loss: 3.734e+04, MSE(e): 2.347e-03, MSE(pi1): 1.880e-02, MSE(pi2): 1.371e-03, MSE(pi3): 8.538e-03\n",
      "Epoch 3000, Train loss: 2.275e+04, Test loss: 3.487e+04, MSE(e): 2.172e-03, MSE(pi1): 1.827e-02, MSE(pi2): 1.269e-03, MSE(pi3): 8.482e-03\n",
      "Epoch 3100, Train loss: 2.119e+04, Test loss: 3.257e+04, MSE(e): 2.017e-03, MSE(pi1): 1.723e-02, MSE(pi2): 1.179e-03, MSE(pi3): 8.436e-03\n",
      "Epoch 3200, Train loss: 1.980e+04, Test loss: 3.041e+04, MSE(e): 1.879e-03, MSE(pi1): 1.700e-02, MSE(pi2): 1.099e-03, MSE(pi3): 8.396e-03\n",
      "Epoch 3300, Train loss: 1.856e+04, Test loss: 2.841e+04, MSE(e): 1.755e-03, MSE(pi1): 1.750e-02, MSE(pi2): 1.027e-03, MSE(pi3): 8.363e-03\n",
      "Epoch 3400, Train loss: 1.745e+04, Test loss: 2.661e+04, MSE(e): 1.645e-03, MSE(pi1): 1.682e-02, MSE(pi2): 9.633e-04, MSE(pi3): 8.333e-03\n",
      "Epoch 3500, Train loss: 1.641e+04, Test loss: 2.494e+04, MSE(e): 1.544e-03, MSE(pi1): 1.441e-02, MSE(pi2): 9.044e-04, MSE(pi3): 8.293e-03\n",
      "Epoch 3600, Train loss: 1.560e+04, Test loss: 2.354e+04, MSE(e): 1.462e-03, MSE(pi1): 1.494e-02, MSE(pi2): 8.556e-04, MSE(pi3): 8.273e-03\n",
      "Epoch 3700, Train loss: 1.484e+04, Test loss: 2.222e+04, MSE(e): 1.388e-03, MSE(pi1): 1.377e-02, MSE(pi2): 8.114e-04, MSE(pi3): 8.250e-03\n",
      "Epoch 3800, Train loss: 1.415e+04, Test loss: 2.108e+04, MSE(e): 1.318e-03, MSE(pi1): 1.417e-02, MSE(pi2): 7.701e-04, MSE(pi3): 8.234e-03\n",
      "Epoch 3900, Train loss: 1.348e+04, Test loss: 2.008e+04, MSE(e): 1.252e-03, MSE(pi1): 1.335e-02, MSE(pi2): 7.310e-04, MSE(pi3): 8.210e-03\n",
      "Epoch 4000, Train loss: 1.265e+04, Test loss: 1.912e+04, MSE(e): 1.169e-03, MSE(pi1): 1.371e-02, MSE(pi2): 6.859e-04, MSE(pi3): 8.184e-03\n",
      "Epoch 4100, Train loss: 1.212e+04, Test loss: 1.836e+04, MSE(e): 1.118e-03, MSE(pi1): 1.245e-02, MSE(pi2): 6.539e-04, MSE(pi3): 8.167e-03\n",
      "Epoch 4200, Train loss: 1.161e+04, Test loss: 1.848e+04, MSE(e): 1.066e-03, MSE(pi1): 1.335e-02, MSE(pi2): 6.236e-04, MSE(pi3): 8.160e-03\n",
      "Epoch 4300, Train loss: 1.134e+04, Test loss: 1.680e+04, MSE(e): 1.040e-03, MSE(pi1): 1.223e-02, MSE(pi2): 6.054e-04, MSE(pi3): 8.157e-03\n",
      "Epoch 4400, Train loss: 1.071e+04, Test loss: 1.637e+04, MSE(e): 9.763e-04, MSE(pi1): 1.323e-02, MSE(pi2): 5.708e-04, MSE(pi3): 8.136e-03\n",
      "Epoch 4500, Train loss: 1.011e+04, Test loss: 1.587e+04, MSE(e): 9.125e-04, MSE(pi1): 1.711e-02, MSE(pi2): 5.377e-04, MSE(pi3): 8.125e-03\n",
      "Epoch 4600, Train loss: 9.678e+03, Test loss: 1.554e+04, MSE(e): 8.753e-04, MSE(pi1): 1.142e-02, MSE(pi2): 5.161e-04, MSE(pi3): 8.106e-03\n",
      "Epoch 4700, Train loss: 9.374e+03, Test loss: 1.531e+04, MSE(e): 8.438e-04, MSE(pi1): 1.256e-02, MSE(pi2): 4.971e-04, MSE(pi3): 8.103e-03\n",
      "Epoch 4800, Train loss: 9.001e+03, Test loss: 1.495e+04, MSE(e): 8.077e-04, MSE(pi1): 1.151e-02, MSE(pi2): 4.755e-04, MSE(pi3): 8.092e-03\n",
      "Epoch 4900, Train loss: 8.652e+03, Test loss: 1.466e+04, MSE(e): 7.727e-04, MSE(pi1): 1.163e-02, MSE(pi2): 4.548e-04, MSE(pi3): 8.083e-03\n",
      "Epoch 5000, Train loss: 8.321e+03, Test loss: 1.441e+04, MSE(e): 7.402e-04, MSE(pi1): 1.110e-02, MSE(pi2): 4.355e-04, MSE(pi3): 8.073e-03\n",
      "Epoch 5100, Train loss: 8.015e+03, Test loss: 1.422e+04, MSE(e): 7.101e-04, MSE(pi1): 1.068e-02, MSE(pi2): 4.176e-04, MSE(pi3): 8.063e-03\n",
      "Epoch 5200, Train loss: 7.739e+03, Test loss: 1.407e+04, MSE(e): 6.821e-04, MSE(pi1): 1.117e-02, MSE(pi2): 4.009e-04, MSE(pi3): 8.059e-03\n",
      "Epoch 5300, Train loss: 7.468e+03, Test loss: 1.394e+04, MSE(e): 6.555e-04, MSE(pi1): 1.076e-02, MSE(pi2): 3.851e-04, MSE(pi3): 8.050e-03\n",
      "Epoch 5400, Train loss: 7.234e+03, Test loss: 1.384e+04, MSE(e): 6.306e-04, MSE(pi1): 1.231e-02, MSE(pi2): 3.701e-04, MSE(pi3): 8.040e-03\n",
      "Epoch 5500, Train loss: 6.989e+03, Test loss: 1.373e+04, MSE(e): 6.075e-04, MSE(pi1): 1.097e-02, MSE(pi2): 3.565e-04, MSE(pi3): 8.034e-03\n",
      "Epoch 5600, Train loss: 6.765e+03, Test loss: 1.362e+04, MSE(e): 5.857e-04, MSE(pi1): 1.052e-02, MSE(pi2): 3.434e-04, MSE(pi3): 8.028e-03\n",
      "Epoch 5700, Train loss: 6.567e+03, Test loss: 1.354e+04, MSE(e): 5.651e-04, MSE(pi1): 1.134e-02, MSE(pi2): 3.312e-04, MSE(pi3): 8.025e-03\n",
      "Epoch 5800, Train loss: 6.361e+03, Test loss: 1.343e+04, MSE(e): 5.456e-04, MSE(pi1): 1.029e-02, MSE(pi2): 3.195e-04, MSE(pi3): 8.017e-03\n",
      "Epoch 5900, Train loss: 6.195e+03, Test loss: 1.336e+04, MSE(e): 5.272e-04, MSE(pi1): 1.223e-02, MSE(pi2): 3.084e-04, MSE(pi3): 8.014e-03\n",
      "Epoch 6000, Train loss: 5.997e+03, Test loss: 1.321e+04, MSE(e): 5.099e-04, MSE(pi1): 9.693e-03, MSE(pi2): 2.982e-04, MSE(pi3): 8.007e-03\n",
      "Epoch 6100, Train loss: 5.841e+03, Test loss: 1.312e+04, MSE(e): 4.934e-04, MSE(pi1): 1.055e-02, MSE(pi2): 2.883e-04, MSE(pi3): 8.003e-03\n",
      "Epoch 6200, Train loss: 5.686e+03, Test loss: 1.300e+04, MSE(e): 4.779e-04, MSE(pi1): 1.075e-02, MSE(pi2): 2.790e-04, MSE(pi3): 7.999e-03\n",
      "Epoch 6300, Train loss: 5.532e+03, Test loss: 1.288e+04, MSE(e): 4.629e-04, MSE(pi1): 1.029e-02, MSE(pi2): 2.700e-04, MSE(pi3): 7.993e-03\n",
      "Epoch 6400, Train loss: 5.394e+03, Test loss: 1.276e+04, MSE(e): 4.489e-04, MSE(pi1): 1.051e-02, MSE(pi2): 2.617e-04, MSE(pi3): 7.989e-03\n",
      "Epoch 6500, Train loss: 5.260e+03, Test loss: 1.263e+04, MSE(e): 4.356e-04, MSE(pi1): 1.052e-02, MSE(pi2): 2.537e-04, MSE(pi3): 7.986e-03\n",
      "Epoch 6600, Train loss: 5.121e+03, Test loss: 1.249e+04, MSE(e): 4.230e-04, MSE(pi1): 9.330e-03, MSE(pi2): 2.462e-04, MSE(pi3): 7.980e-03\n",
      "Epoch 6700, Train loss: 5.010e+03, Test loss: 1.237e+04, MSE(e): 4.112e-04, MSE(pi1): 9.942e-03, MSE(pi2): 2.391e-04, MSE(pi3): 7.978e-03\n",
      "Epoch 6800, Train loss: 4.899e+03, Test loss: 1.225e+04, MSE(e): 3.999e-04, MSE(pi1): 1.021e-02, MSE(pi2): 2.324e-04, MSE(pi3): 7.976e-03\n",
      "Epoch 6900, Train loss: 4.817e+03, Test loss: 1.216e+04, MSE(e): 3.889e-04, MSE(pi1): 1.307e-02, MSE(pi2): 2.257e-04, MSE(pi3): 7.975e-03\n",
      "Epoch 7000, Train loss: 4.681e+03, Test loss: 1.197e+04, MSE(e): 3.789e-04, MSE(pi1): 9.528e-03, MSE(pi2): 2.198e-04, MSE(pi3): 7.968e-03\n",
      "Epoch 7100, Train loss: 4.586e+03, Test loss: 1.185e+04, MSE(e): 3.691e-04, MSE(pi1): 9.773e-03, MSE(pi2): 2.140e-04, MSE(pi3): 7.966e-03\n",
      "Epoch 7200, Train loss: 4.498e+03, Test loss: 1.172e+04, MSE(e): 3.600e-04, MSE(pi1): 1.014e-02, MSE(pi2): 2.086e-04, MSE(pi3): 7.963e-03\n",
      "Epoch 7300, Train loss: 4.415e+03, Test loss: 1.160e+04, MSE(e): 3.508e-04, MSE(pi1): 1.108e-02, MSE(pi2): 2.031e-04, MSE(pi3): 7.962e-03\n",
      "Epoch 7400, Train loss: 4.317e+03, Test loss: 1.146e+04, MSE(e): 3.427e-04, MSE(pi1): 9.466e-03, MSE(pi2): 1.983e-04, MSE(pi3): 7.958e-03\n",
      "Epoch 7500, Train loss: 4.236e+03, Test loss: 1.134e+04, MSE(e): 3.348e-04, MSE(pi1): 9.211e-03, MSE(pi2): 1.936e-04, MSE(pi3): 7.956e-03\n",
      "Epoch 7600, Train loss: 4.169e+03, Test loss: 1.123e+04, MSE(e): 3.267e-04, MSE(pi1): 1.067e-02, MSE(pi2): 1.889e-04, MSE(pi3): 7.955e-03\n",
      "Epoch 7700, Train loss: 4.088e+03, Test loss: 1.109e+04, MSE(e): 3.198e-04, MSE(pi1): 9.403e-03, MSE(pi2): 1.848e-04, MSE(pi3): 7.952e-03\n",
      "Epoch 7800, Train loss: 4.014e+03, Test loss: 1.097e+04, MSE(e): 3.126e-04, MSE(pi1): 9.338e-03, MSE(pi2): 1.805e-04, MSE(pi3): 7.948e-03\n",
      "Epoch 7900, Train loss: 3.953e+03, Test loss: 1.085e+04, MSE(e): 3.063e-04, MSE(pi1): 9.579e-03, MSE(pi2): 1.766e-04, MSE(pi3): 7.946e-03\n",
      "Epoch 8000, Train loss: 3.907e+03, Test loss: 1.076e+04, MSE(e): 2.996e-04, MSE(pi1): 1.159e-02, MSE(pi2): 1.728e-04, MSE(pi3): 7.948e-03\n",
      "Epoch 8100, Train loss: 3.825e+03, Test loss: 1.061e+04, MSE(e): 2.934e-04, MSE(pi1): 9.675e-03, MSE(pi2): 1.692e-04, MSE(pi3): 7.943e-03\n",
      "Epoch 8200, Train loss: 3.773e+03, Test loss: 1.050e+04, MSE(e): 2.877e-04, MSE(pi1): 1.014e-02, MSE(pi2): 1.659e-04, MSE(pi3): 7.943e-03\n",
      "Epoch 8300, Train loss: 3.704e+03, Test loss: 1.036e+04, MSE(e): 2.821e-04, MSE(pi1): 8.922e-03, MSE(pi2): 1.625e-04, MSE(pi3): 7.938e-03\n",
      "Epoch 8400, Train loss: 3.658e+03, Test loss: 1.025e+04, MSE(e): 2.767e-04, MSE(pi1): 9.775e-03, MSE(pi2): 1.594e-04, MSE(pi3): 7.938e-03\n",
      "Epoch 8500, Train loss: 3.615e+03, Test loss: 1.015e+04, MSE(e): 2.717e-04, MSE(pi1): 1.040e-02, MSE(pi2): 1.565e-04, MSE(pi3): 7.938e-03\n",
      "Epoch 8600, Train loss: 3.558e+03, Test loss: 1.002e+04, MSE(e): 2.669e-04, MSE(pi1): 9.532e-03, MSE(pi2): 1.537e-04, MSE(pi3): 7.935e-03\n",
      "Epoch 8700, Train loss: 3.503e+03, Test loss: 9.898e+03, MSE(e): 2.617e-04, MSE(pi1): 9.235e-03, MSE(pi2): 1.506e-04, MSE(pi3): 7.932e-03\n",
      "Epoch 8800, Train loss: 3.457e+03, Test loss: 9.785e+03, MSE(e): 2.573e-04, MSE(pi1): 9.086e-03, MSE(pi2): 1.481e-04, MSE(pi3): 7.932e-03\n",
      "Epoch 8900, Train loss: 3.412e+03, Test loss: 9.679e+03, MSE(e): 2.523e-04, MSE(pi1): 9.519e-03, MSE(pi2): 1.453e-04, MSE(pi3): 7.930e-03\n",
      "Epoch 9000, Train loss: 3.378e+03, Test loss: 9.584e+03, MSE(e): 2.483e-04, MSE(pi1): 1.018e-02, MSE(pi2): 1.429e-04, MSE(pi3): 7.931e-03\n",
      "Epoch 9100, Train loss: 3.335e+03, Test loss: 9.488e+03, MSE(e): 2.443e-04, MSE(pi1): 9.902e-03, MSE(pi2): 1.405e-04, MSE(pi3): 7.928e-03\n",
      "Epoch 9200, Train loss: 3.282e+03, Test loss: 9.387e+03, MSE(e): 2.393e-04, MSE(pi1): 9.625e-03, MSE(pi2): 1.377e-04, MSE(pi3): 7.925e-03\n",
      "Epoch 9300, Train loss: 3.254e+03, Test loss: 9.316e+03, MSE(e): 2.364e-04, MSE(pi1): 9.706e-03, MSE(pi2): 1.360e-04, MSE(pi3): 7.926e-03\n",
      "Epoch 9400, Train loss: 3.213e+03, Test loss: 9.242e+03, MSE(e): 2.323e-04, MSE(pi1): 9.787e-03, MSE(pi2): 1.336e-04, MSE(pi3): 7.924e-03\n",
      "Epoch 9500, Train loss: 3.188e+03, Test loss: 9.178e+03, MSE(e): 2.300e-04, MSE(pi1): 9.564e-03, MSE(pi2): 1.321e-04, MSE(pi3): 7.924e-03\n",
      "Epoch 9600, Train loss: 3.128e+03, Test loss: 9.093e+03, MSE(e): 2.243e-04, MSE(pi1): 9.287e-03, MSE(pi2): 1.290e-04, MSE(pi3): 7.920e-03\n",
      "Epoch 9700, Train loss: 3.084e+03, Test loss: 9.029e+03, MSE(e): 2.194e-04, MSE(pi1): 9.742e-03, MSE(pi2): 1.265e-04, MSE(pi3): 7.920e-03\n",
      "Epoch 9800, Train loss: 3.129e+03, Test loss: 8.997e+03, MSE(e): 2.242e-04, MSE(pi1): 9.483e-03, MSE(pi2): 1.280e-04, MSE(pi3): 7.919e-03\n",
      "Epoch 9900, Train loss: 2.993e+03, Test loss: 8.834e+03, MSE(e): 2.106e-04, MSE(pi1): 9.504e-03, MSE(pi2): 1.216e-04, MSE(pi3): 7.922e-03\n",
      "Epoch 10000, Train loss: 2.847e+03, Test loss: 8.582e+03, MSE(e): 1.966e-04, MSE(pi1): 8.972e-03, MSE(pi2): 1.151e-04, MSE(pi3): 7.916e-03\n",
      "Epoch 10100, Train loss: 3.244e+03, Test loss: 8.779e+03, MSE(e): 2.350e-04, MSE(pi1): 1.016e-02, MSE(pi2): 1.310e-04, MSE(pi3): 7.923e-03\n",
      "Epoch 10200, Train loss: 3.167e+03, Test loss: 8.784e+03, MSE(e): 2.274e-04, MSE(pi1): 1.011e-02, MSE(pi2): 1.274e-04, MSE(pi3): 7.918e-03\n",
      "Epoch 10300, Train loss: 3.127e+03, Test loss: 8.776e+03, MSE(e): 2.235e-04, MSE(pi1): 1.002e-02, MSE(pi2): 1.252e-04, MSE(pi3): 7.915e-03\n",
      "Epoch 10400, Train loss: 3.047e+03, Test loss: 8.750e+03, MSE(e): 2.159e-04, MSE(pi1): 9.637e-03, MSE(pi2): 1.216e-04, MSE(pi3): 7.911e-03\n",
      "Epoch 10500, Train loss: 2.944e+03, Test loss: 8.723e+03, MSE(e): 2.054e-04, MSE(pi1): 9.917e-03, MSE(pi2): 1.167e-04, MSE(pi3): 7.907e-03\n",
      "Epoch 10600, Train loss: 2.804e+03, Test loss: 8.630e+03, MSE(e): 1.914e-04, MSE(pi1): 9.888e-03, MSE(pi2): 1.102e-04, MSE(pi3): 7.902e-03\n",
      "Epoch 10700, Train loss: 2.654e+03, Test loss: 8.488e+03, MSE(e): 1.776e-04, MSE(pi1): 8.836e-03, MSE(pi2): 1.040e-04, MSE(pi3): 7.899e-03\n",
      "Epoch 10800, Train loss: 2.588e+03, Test loss: 8.376e+03, MSE(e): 1.711e-04, MSE(pi1): 8.649e-03, MSE(pi2): 1.007e-04, MSE(pi3): 7.899e-03\n",
      "Epoch 10900, Train loss: 2.620e+03, Test loss: 8.376e+03, MSE(e): 1.733e-04, MSE(pi1): 9.636e-03, MSE(pi2): 1.013e-04, MSE(pi3): 7.907e-03\n",
      "Epoch 11000, Train loss: 3.030e+03, Test loss: 8.560e+03, MSE(e): 2.139e-04, MSE(pi1): 9.988e-03, MSE(pi2): 1.183e-04, MSE(pi3): 7.913e-03\n",
      "Epoch 11100, Train loss: 2.666e+03, Test loss: 8.456e+03, MSE(e): 1.781e-04, MSE(pi1): 9.546e-03, MSE(pi2): 1.028e-04, MSE(pi3): 7.898e-03\n",
      "Epoch 11200, Train loss: 2.498e+03, Test loss: 8.221e+03, MSE(e): 1.619e-04, MSE(pi1): 8.928e-03, MSE(pi2): 9.522e-05, MSE(pi3): 7.897e-03\n",
      "Epoch 11300, Train loss: 2.984e+03, Test loss: 8.470e+03, MSE(e): 2.097e-04, MSE(pi1): 9.577e-03, MSE(pi2): 1.155e-04, MSE(pi3): 7.911e-03\n",
      "Epoch 11400, Train loss: 2.484e+03, Test loss: 8.252e+03, MSE(e): 1.603e-04, MSE(pi1): 9.211e-03, MSE(pi2): 9.402e-05, MSE(pi3): 7.891e-03\n",
      "Epoch 11500, Train loss: 2.651e+03, Test loss: 8.319e+03, MSE(e): 1.775e-04, MSE(pi1): 8.548e-03, MSE(pi2): 1.011e-04, MSE(pi3): 7.906e-03\n",
      "Epoch 11600, Train loss: 2.455e+03, Test loss: 8.209e+03, MSE(e): 1.576e-04, MSE(pi1): 9.013e-03, MSE(pi2): 9.236e-05, MSE(pi3): 7.889e-03\n",
      "Epoch 11700, Train loss: 2.822e+03, Test loss: 8.345e+03, MSE(e): 1.946e-04, MSE(pi1): 8.540e-03, MSE(pi2): 1.078e-04, MSE(pi3): 7.906e-03\n",
      "Epoch 11800, Train loss: 2.375e+03, Test loss: 8.056e+03, MSE(e): 1.498e-04, MSE(pi1): 8.785e-03, MSE(pi2): 8.827e-05, MSE(pi3): 7.889e-03\n",
      "Epoch 11900, Train loss: 2.647e+03, Test loss: 8.296e+03, MSE(e): 1.757e-04, MSE(pi1): 1.011e-02, MSE(pi2): 9.930e-05, MSE(pi3): 7.893e-03\n",
      "Epoch 12000, Train loss: 2.648e+03, Test loss: 8.244e+03, MSE(e): 1.770e-04, MSE(pi1): 8.812e-03, MSE(pi2): 9.947e-05, MSE(pi3): 7.904e-03\n",
      "Epoch 12100, Train loss: 2.330e+03, Test loss: 7.947e+03, MSE(e): 1.456e-04, MSE(pi1): 8.514e-03, MSE(pi2): 8.570e-05, MSE(pi3): 7.889e-03\n",
      "Epoch 12200, Train loss: 2.337e+03, Test loss: 8.024e+03, MSE(e): 1.457e-04, MSE(pi1): 9.111e-03, MSE(pi2): 8.562e-05, MSE(pi3): 7.885e-03\n",
      "Epoch 12300, Train loss: 2.542e+03, Test loss: 8.193e+03, MSE(e): 1.643e-04, MSE(pi1): 1.094e-02, MSE(pi2): 9.346e-05, MSE(pi3): 7.893e-03\n",
      "Epoch 12400, Train loss: 2.756e+03, Test loss: 8.168e+03, MSE(e): 1.867e-04, MSE(pi1): 9.939e-03, MSE(pi2): 1.026e-04, MSE(pi3): 7.896e-03\n",
      "Epoch 12500, Train loss: 2.719e+03, Test loss: 8.132e+03, MSE(e): 1.844e-04, MSE(pi1): 8.526e-03, MSE(pi2): 1.012e-04, MSE(pi3): 7.902e-03\n",
      "Epoch 12600, Train loss: 2.481e+03, Test loss: 8.056e+03, MSE(e): 1.601e-04, MSE(pi1): 8.957e-03, MSE(pi2): 9.073e-05, MSE(pi3): 7.899e-03\n",
      "Epoch 12700, Train loss: 2.383e+03, Test loss: 7.971e+03, MSE(e): 1.508e-04, MSE(pi1): 8.446e-03, MSE(pi2): 8.653e-05, MSE(pi3): 7.895e-03\n",
      "Epoch 12800, Train loss: 2.517e+03, Test loss: 8.057e+03, MSE(e): 1.639e-04, MSE(pi1): 8.778e-03, MSE(pi2): 9.192e-05, MSE(pi3): 7.899e-03\n",
      "Epoch 12900, Train loss: 2.695e+03, Test loss: 8.071e+03, MSE(e): 1.818e-04, MSE(pi1): 8.628e-03, MSE(pi2): 9.925e-05, MSE(pi3): 7.900e-03\n",
      "Epoch 13000, Train loss: 2.720e+03, Test loss: 8.028e+03, MSE(e): 1.834e-04, MSE(pi1): 9.698e-03, MSE(pi2): 9.987e-05, MSE(pi3): 7.897e-03\n",
      "Epoch 13100, Train loss: 2.554e+03, Test loss: 8.064e+03, MSE(e): 1.648e-04, MSE(pi1): 1.167e-02, MSE(pi2): 9.167e-05, MSE(pi3): 7.890e-03\n",
      "Epoch 13200, Train loss: 2.272e+03, Test loss: 7.850e+03, MSE(e): 1.392e-04, MSE(pi1): 9.182e-03, MSE(pi2): 8.046e-05, MSE(pi3): 7.879e-03\n",
      "Epoch 13300, Train loss: 2.157e+03, Test loss: 7.685e+03, MSE(e): 1.277e-04, MSE(pi1): 9.265e-03, MSE(pi2): 7.518e-05, MSE(pi3): 7.877e-03\n",
      "Epoch 13400, Train loss: 2.468e+03, Test loss: 8.003e+03, MSE(e): 1.589e-04, MSE(pi1): 8.979e-03, MSE(pi2): 8.847e-05, MSE(pi3): 7.899e-03\n",
      "Epoch 13500, Train loss: 2.368e+03, Test loss: 7.935e+03, MSE(e): 1.479e-04, MSE(pi1): 1.003e-02, MSE(pi2): 8.405e-05, MSE(pi3): 7.888e-03\n",
      "Epoch 13600, Train loss: 2.118e+03, Test loss: 7.634e+03, MSE(e): 1.243e-04, MSE(pi1): 8.734e-03, MSE(pi2): 7.324e-05, MSE(pi3): 7.877e-03\n",
      "Epoch 13700, Train loss: 2.242e+03, Test loss: 7.824e+03, MSE(e): 1.362e-04, MSE(pi1): 9.158e-03, MSE(pi2): 7.861e-05, MSE(pi3): 7.883e-03\n",
      "Epoch 13800, Train loss: 2.153e+03, Test loss: 7.552e+03, MSE(e): 1.281e-04, MSE(pi1): 8.366e-03, MSE(pi2): 7.444e-05, MSE(pi3): 7.877e-03\n",
      "Epoch 13900, Train loss: 2.126e+03, Test loss: 7.648e+03, MSE(e): 1.248e-04, MSE(pi1): 8.982e-03, MSE(pi2): 7.315e-05, MSE(pi3): 7.876e-03\n",
      "Epoch 14000, Train loss: 2.224e+03, Test loss: 7.556e+03, MSE(e): 1.344e-04, MSE(pi1): 9.113e-03, MSE(pi2): 7.823e-05, MSE(pi3): 7.885e-03\n",
      "Epoch 14100, Train loss: 2.224e+03, Test loss: 7.717e+03, MSE(e): 1.342e-04, MSE(pi1): 9.381e-03, MSE(pi2): 7.766e-05, MSE(pi3): 7.882e-03\n",
      "Epoch 14200, Train loss: 2.186e+03, Test loss: 7.761e+03, MSE(e): 1.305e-04, MSE(pi1): 9.358e-03, MSE(pi2): 7.581e-05, MSE(pi3): 7.881e-03\n",
      "Epoch 14300, Train loss: 2.232e+03, Test loss: 7.640e+03, MSE(e): 1.347e-04, MSE(pi1): 9.647e-03, MSE(pi2): 7.754e-05, MSE(pi3): 7.880e-03\n",
      "Epoch 14400, Train loss: 2.168e+03, Test loss: 7.682e+03, MSE(e): 1.283e-04, MSE(pi1): 9.603e-03, MSE(pi2): 7.468e-05, MSE(pi3): 7.885e-03\n",
      "Epoch 14500, Train loss: 2.132e+03, Test loss: 7.670e+03, MSE(e): 1.252e-04, MSE(pi1): 9.239e-03, MSE(pi2): 7.295e-05, MSE(pi3): 7.876e-03\n",
      "Epoch 14600, Train loss: 2.235e+03, Test loss: 7.637e+03, MSE(e): 1.338e-04, MSE(pi1): 1.088e-02, MSE(pi2): 7.646e-05, MSE(pi3): 7.883e-03\n",
      "Epoch 14700, Train loss: 2.123e+03, Test loss: 7.606e+03, MSE(e): 1.242e-04, MSE(pi1): 9.265e-03, MSE(pi2): 7.231e-05, MSE(pi3): 7.881e-03\n",
      "Epoch 14800, Train loss: 2.099e+03, Test loss: 7.635e+03, MSE(e): 1.220e-04, MSE(pi1): 9.152e-03, MSE(pi2): 7.100e-05, MSE(pi3): 7.875e-03\n",
      "Epoch 14900, Train loss: 2.162e+03, Test loss: 7.526e+03, MSE(e): 1.273e-04, MSE(pi1): 1.015e-02, MSE(pi2): 7.318e-05, MSE(pi3): 7.876e-03\n",
      "Epoch 15000, Train loss: 2.102e+03, Test loss: 7.530e+03, MSE(e): 1.230e-04, MSE(pi1): 8.409e-03, MSE(pi2): 7.117e-05, MSE(pi3): 7.880e-03\n",
      "Epoch 15100, Train loss: 2.069e+03, Test loss: 7.572e+03, MSE(e): 1.191e-04, MSE(pi1): 9.058e-03, MSE(pi2): 6.917e-05, MSE(pi3): 7.874e-03\n",
      "Epoch 15200, Train loss: 2.052e+03, Test loss: 7.497e+03, MSE(e): 1.164e-04, MSE(pi1): 1.016e-02, MSE(pi2): 6.794e-05, MSE(pi3): 7.873e-03\n",
      "Epoch 15300, Train loss: 2.158e+03, Test loss: 7.494e+03, MSE(e): 1.278e-04, MSE(pi1): 9.128e-03, MSE(pi2): 7.305e-05, MSE(pi3): 7.880e-03\n",
      "Epoch 15400, Train loss: 2.026e+03, Test loss: 7.457e+03, MSE(e): 1.145e-04, MSE(pi1): 9.319e-03, MSE(pi2): 6.672e-05, MSE(pi3): 7.876e-03\n",
      "Epoch 15500, Train loss: 2.049e+03, Test loss: 7.520e+03, MSE(e): 1.148e-04, MSE(pi1): 1.134e-02, MSE(pi2): 6.645e-05, MSE(pi3): 7.874e-03\n",
      "Epoch 15600, Train loss: 2.007e+03, Test loss: 7.347e+03, MSE(e): 1.126e-04, MSE(pi1): 9.407e-03, MSE(pi2): 6.582e-05, MSE(pi3): 7.870e-03\n",
      "Epoch 15700, Train loss: 2.093e+03, Test loss: 7.388e+03, MSE(e): 1.219e-04, MSE(pi1): 8.612e-03, MSE(pi2): 6.995e-05, MSE(pi3): 7.877e-03\n",
      "Epoch 15800, Train loss: 1.985e+03, Test loss: 7.295e+03, MSE(e): 1.104e-04, MSE(pi1): 9.274e-03, MSE(pi2): 6.432e-05, MSE(pi3): 7.874e-03\n",
      "Epoch 15900, Train loss: 1.982e+03, Test loss: 7.277e+03, MSE(e): 1.101e-04, MSE(pi1): 9.455e-03, MSE(pi2): 6.384e-05, MSE(pi3): 7.871e-03\n",
      "Epoch 16000, Train loss: 1.965e+03, Test loss: 7.196e+03, MSE(e): 1.091e-04, MSE(pi1): 8.747e-03, MSE(pi2): 6.364e-05, MSE(pi3): 7.867e-03\n",
      "Epoch 16100, Train loss: 2.094e+03, Test loss: 7.147e+03, MSE(e): 1.224e-04, MSE(pi1): 8.316e-03, MSE(pi2): 6.992e-05, MSE(pi3): 7.872e-03\n",
      "Epoch 16200, Train loss: 1.980e+03, Test loss: 7.069e+03, MSE(e): 1.108e-04, MSE(pi1): 8.553e-03, MSE(pi2): 6.395e-05, MSE(pi3): 7.872e-03\n",
      "Epoch 16300, Train loss: 1.965e+03, Test loss: 6.988e+03, MSE(e): 1.082e-04, MSE(pi1): 9.603e-03, MSE(pi2): 6.263e-05, MSE(pi3): 7.873e-03\n",
      "Epoch 16400, Train loss: 1.935e+03, Test loss: 6.919e+03, MSE(e): 1.054e-04, MSE(pi1): 9.429e-03, MSE(pi2): 6.122e-05, MSE(pi3): 7.873e-03\n",
      "Epoch 16500, Train loss: 1.975e+03, Test loss: 7.020e+03, MSE(e): 1.086e-04, MSE(pi1): 1.016e-02, MSE(pi2): 6.323e-05, MSE(pi3): 7.872e-03\n",
      "Epoch 16600, Train loss: 1.910e+03, Test loss: 7.048e+03, MSE(e): 1.039e-04, MSE(pi1): 8.464e-03, MSE(pi2): 6.073e-05, MSE(pi3): 7.862e-03\n",
      "Epoch 16700, Train loss: 1.910e+03, Test loss: 6.975e+03, MSE(e): 1.015e-04, MSE(pi1): 1.078e-02, MSE(pi2): 5.930e-05, MSE(pi3): 7.865e-03\n",
      "Epoch 16800, Train loss: 1.886e+03, Test loss: 6.836e+03, MSE(e): 1.010e-04, MSE(pi1): 8.994e-03, MSE(pi2): 5.886e-05, MSE(pi3): 7.861e-03\n",
      "Epoch 16900, Train loss: 1.903e+03, Test loss: 6.631e+03, MSE(e): 1.030e-04, MSE(pi1): 8.717e-03, MSE(pi2): 5.973e-05, MSE(pi3): 7.861e-03\n",
      "Epoch 17000, Train loss: 1.957e+03, Test loss: 6.603e+03, MSE(e): 1.072e-04, MSE(pi1): 9.810e-03, MSE(pi2): 6.153e-05, MSE(pi3): 7.870e-03\n",
      "Epoch 17100, Train loss: 1.943e+03, Test loss: 6.688e+03, MSE(e): 1.067e-04, MSE(pi1): 8.898e-03, MSE(pi2): 6.217e-05, MSE(pi3): 7.874e-03\n",
      "Epoch 17200, Train loss: 1.899e+03, Test loss: 6.593e+03, MSE(e): 1.028e-04, MSE(pi1): 8.400e-03, MSE(pi2): 5.927e-05, MSE(pi3): 7.868e-03\n",
      "Epoch 17300, Train loss: 1.895e+03, Test loss: 6.481e+03, MSE(e): 1.015e-04, MSE(pi1): 9.396e-03, MSE(pi2): 5.863e-05, MSE(pi3): 7.861e-03\n",
      "Epoch 17400, Train loss: 1.914e+03, Test loss: 6.400e+03, MSE(e): 1.030e-04, MSE(pi1): 9.761e-03, MSE(pi2): 5.914e-05, MSE(pi3): 7.863e-03\n",
      "Epoch 17500, Train loss: 1.866e+03, Test loss: 6.352e+03, MSE(e): 9.833e-05, MSE(pi1): 9.563e-03, MSE(pi2): 5.684e-05, MSE(pi3): 7.867e-03\n",
      "Epoch 17600, Train loss: 1.828e+03, Test loss: 6.313e+03, MSE(e): 9.585e-05, MSE(pi1): 8.302e-03, MSE(pi2): 5.577e-05, MSE(pi3): 7.863e-03\n",
      "Epoch 17700, Train loss: 1.905e+03, Test loss: 6.524e+03, MSE(e): 1.010e-04, MSE(pi1): 1.077e-02, MSE(pi2): 5.913e-05, MSE(pi3): 7.867e-03\n",
      "Epoch 17800, Train loss: 1.856e+03, Test loss: 6.448e+03, MSE(e): 9.830e-05, MSE(pi1): 8.653e-03, MSE(pi2): 5.728e-05, MSE(pi3): 7.865e-03\n",
      "Epoch 17900, Train loss: 1.895e+03, Test loss: 6.199e+03, MSE(e): 1.014e-04, MSE(pi1): 9.469e-03, MSE(pi2): 5.788e-05, MSE(pi3): 7.862e-03\n",
      "Epoch 18000, Train loss: 1.796e+03, Test loss: 6.207e+03, MSE(e): 9.211e-05, MSE(pi1): 8.902e-03, MSE(pi2): 5.391e-05, MSE(pi3): 7.855e-03\n",
      "Epoch 18100, Train loss: 1.813e+03, Test loss: 6.072e+03, MSE(e): 9.291e-05, MSE(pi1): 9.859e-03, MSE(pi2): 5.411e-05, MSE(pi3): 7.856e-03\n",
      "Epoch 18200, Train loss: 1.858e+03, Test loss: 5.980e+03, MSE(e): 9.799e-05, MSE(pi1): 9.156e-03, MSE(pi2): 5.619e-05, MSE(pi3): 7.862e-03\n",
      "Epoch 18300, Train loss: 1.808e+03, Test loss: 5.938e+03, MSE(e): 9.177e-05, MSE(pi1): 1.037e-02, MSE(pi2): 5.327e-05, MSE(pi3): 7.867e-03\n",
      "Epoch 18400, Train loss: 1.777e+03, Test loss: 5.910e+03, MSE(e): 9.029e-05, MSE(pi1): 8.824e-03, MSE(pi2): 5.253e-05, MSE(pi3): 7.861e-03\n",
      "Epoch 18500, Train loss: 1.793e+03, Test loss: 5.902e+03, MSE(e): 9.075e-05, MSE(pi1): 9.881e-03, MSE(pi2): 5.287e-05, MSE(pi3): 7.863e-03\n",
      "Epoch 18600, Train loss: 1.805e+03, Test loss: 5.786e+03, MSE(e): 9.302e-05, MSE(pi1): 8.794e-03, MSE(pi2): 5.396e-05, MSE(pi3): 7.866e-03\n",
      "Epoch 18700, Train loss: 1.776e+03, Test loss: 5.884e+03, MSE(e): 9.012e-05, MSE(pi1): 8.952e-03, MSE(pi2): 5.284e-05, MSE(pi3): 7.853e-03\n",
      "Epoch 18800, Train loss: 1.841e+03, Test loss: 5.718e+03, MSE(e): 9.619e-05, MSE(pi1): 9.370e-03, MSE(pi2): 5.471e-05, MSE(pi3): 7.858e-03\n",
      "Epoch 18900, Train loss: 1.750e+03, Test loss: 5.787e+03, MSE(e): 8.809e-05, MSE(pi1): 8.386e-03, MSE(pi2): 5.116e-05, MSE(pi3): 7.855e-03\n",
      "Epoch 19000, Train loss: 1.727e+03, Test loss: 5.631e+03, MSE(e): 8.534e-05, MSE(pi1): 8.725e-03, MSE(pi2): 4.977e-05, MSE(pi3): 7.858e-03\n",
      "Epoch 19100, Train loss: 1.747e+03, Test loss: 5.653e+03, MSE(e): 8.637e-05, MSE(pi1): 9.738e-03, MSE(pi2): 5.012e-05, MSE(pi3): 7.859e-03\n",
      "Epoch 19200, Train loss: 1.734e+03, Test loss: 5.626e+03, MSE(e): 8.643e-05, MSE(pi1): 8.468e-03, MSE(pi2): 5.009e-05, MSE(pi3): 7.854e-03\n",
      "Epoch 19300, Train loss: 1.739e+03, Test loss: 5.644e+03, MSE(e): 8.660e-05, MSE(pi1): 8.767e-03, MSE(pi2): 5.016e-05, MSE(pi3): 7.852e-03\n",
      "Epoch 19400, Train loss: 1.727e+03, Test loss: 5.568e+03, MSE(e): 8.563e-05, MSE(pi1): 8.584e-03, MSE(pi2): 4.971e-05, MSE(pi3): 7.852e-03\n",
      "Epoch 19500, Train loss: 1.714e+03, Test loss: 5.464e+03, MSE(e): 8.462e-05, MSE(pi1): 8.309e-03, MSE(pi2): 4.916e-05, MSE(pi3): 7.851e-03\n",
      "Epoch 19600, Train loss: 1.719e+03, Test loss: 5.396e+03, MSE(e): 8.441e-05, MSE(pi1): 8.994e-03, MSE(pi2): 4.889e-05, MSE(pi3): 7.851e-03\n",
      "Epoch 19700, Train loss: 1.711e+03, Test loss: 5.261e+03, MSE(e): 8.311e-05, MSE(pi1): 9.459e-03, MSE(pi2): 4.829e-05, MSE(pi3): 7.854e-03\n",
      "Epoch 19800, Train loss: 1.730e+03, Test loss: 5.128e+03, MSE(e): 8.530e-05, MSE(pi1): 9.091e-03, MSE(pi2): 4.942e-05, MSE(pi3): 7.859e-03\n",
      "Epoch 19900, Train loss: 1.707e+03, Test loss: 5.189e+03, MSE(e): 8.256e-05, MSE(pi1): 9.624e-03, MSE(pi2): 4.821e-05, MSE(pi3): 7.850e-03\n",
      "Epoch 20000, Train loss: 1.708e+03, Test loss: 5.060e+03, MSE(e): 8.360e-05, MSE(pi1): 8.574e-03, MSE(pi2): 4.865e-05, MSE(pi3): 7.858e-03\n",
      "Epoch 20100, Train loss: 1.688e+03, Test loss: 5.084e+03, MSE(e): 8.135e-05, MSE(pi1): 8.875e-03, MSE(pi2): 4.740e-05, MSE(pi3): 7.856e-03\n",
      "Epoch 20200, Train loss: 1.693e+03, Test loss: 5.150e+03, MSE(e): 8.198e-05, MSE(pi1): 8.774e-03, MSE(pi2): 4.747e-05, MSE(pi3): 7.852e-03\n",
      "Epoch 20300, Train loss: 1.701e+03, Test loss: 5.042e+03, MSE(e): 8.055e-05, MSE(pi1): 1.104e-02, MSE(pi2): 4.722e-05, MSE(pi3): 7.849e-03\n",
      "Epoch 20400, Train loss: 1.678e+03, Test loss: 4.888e+03, MSE(e): 8.031e-05, MSE(pi1): 8.926e-03, MSE(pi2): 4.653e-05, MSE(pi3): 7.857e-03\n",
      "Epoch 20500, Train loss: 1.656e+03, Test loss: 4.916e+03, MSE(e): 7.774e-05, MSE(pi1): 9.406e-03, MSE(pi2): 4.564e-05, MSE(pi3): 7.847e-03\n",
      "Epoch 20600, Train loss: 1.690e+03, Test loss: 5.034e+03, MSE(e): 8.061e-05, MSE(pi1): 9.892e-03, MSE(pi2): 4.666e-05, MSE(pi3): 7.853e-03\n",
      "Epoch 20700, Train loss: 1.678e+03, Test loss: 4.755e+03, MSE(e): 8.087e-05, MSE(pi1): 8.346e-03, MSE(pi2): 4.686e-05, MSE(pi3): 7.856e-03\n",
      "Epoch 20800, Train loss: 1.646e+03, Test loss: 4.834e+03, MSE(e): 7.641e-05, MSE(pi1): 9.752e-03, MSE(pi2): 4.481e-05, MSE(pi3): 7.847e-03\n",
      "Epoch 20900, Train loss: 1.634e+03, Test loss: 4.708e+03, MSE(e): 7.557e-05, MSE(pi1): 9.253e-03, MSE(pi2): 4.416e-05, MSE(pi3): 7.854e-03\n",
      "Epoch 21000, Train loss: 1.775e+03, Test loss: 4.640e+03, MSE(e): 9.005e-05, MSE(pi1): 8.890e-03, MSE(pi2): 5.055e-05, MSE(pi3): 7.852e-03\n",
      "Epoch 21100, Train loss: 1.644e+03, Test loss: 4.774e+03, MSE(e): 7.707e-05, MSE(pi1): 8.891e-03, MSE(pi2): 4.532e-05, MSE(pi3): 7.845e-03\n",
      "Epoch 21200, Train loss: 1.720e+03, Test loss: 4.615e+03, MSE(e): 8.343e-05, MSE(pi1): 9.958e-03, MSE(pi2): 4.756e-05, MSE(pi3): 7.859e-03\n",
      "Epoch 21300, Train loss: 1.641e+03, Test loss: 4.753e+03, MSE(e): 7.692e-05, MSE(pi1): 8.738e-03, MSE(pi2): 4.442e-05, MSE(pi3): 7.846e-03\n",
      "Epoch 21400, Train loss: 1.733e+03, Test loss: 4.554e+03, MSE(e): 8.395e-05, MSE(pi1): 1.080e-02, MSE(pi2): 4.751e-05, MSE(pi3): 7.859e-03\n",
      "Epoch 21500, Train loss: 1.591e+03, Test loss: 4.484e+03, MSE(e): 7.209e-05, MSE(pi1): 8.669e-03, MSE(pi2): 4.233e-05, MSE(pi3): 7.838e-03\n",
      "Epoch 21600, Train loss: 1.577e+03, Test loss: 4.562e+03, MSE(e): 7.023e-05, MSE(pi1): 9.055e-03, MSE(pi2): 4.129e-05, MSE(pi3): 7.838e-03\n",
      "Epoch 21700, Train loss: 1.637e+03, Test loss: 4.358e+03, MSE(e): 7.602e-05, MSE(pi1): 9.305e-03, MSE(pi2): 4.364e-05, MSE(pi3): 7.840e-03\n",
      "Epoch 21800, Train loss: 1.554e+03, Test loss: 4.379e+03, MSE(e): 6.865e-05, MSE(pi1): 8.304e-03, MSE(pi2): 4.008e-05, MSE(pi3): 7.848e-03\n",
      "Epoch 21900, Train loss: 1.595e+03, Test loss: 4.336e+03, MSE(e): 7.255e-05, MSE(pi1): 8.540e-03, MSE(pi2): 4.191e-05, MSE(pi3): 7.838e-03\n",
      "Epoch 22000, Train loss: 1.599e+03, Test loss: 4.600e+03, MSE(e): 7.285e-05, MSE(pi1): 8.620e-03, MSE(pi2): 4.169e-05, MSE(pi3): 7.843e-03\n",
      "Epoch 22100, Train loss: 1.570e+03, Test loss: 4.354e+03, MSE(e): 6.958e-05, MSE(pi1): 8.932e-03, MSE(pi2): 4.028e-05, MSE(pi3): 7.851e-03\n",
      "Epoch 22200, Train loss: 1.560e+03, Test loss: 4.319e+03, MSE(e): 6.851e-05, MSE(pi1): 9.047e-03, MSE(pi2): 3.987e-05, MSE(pi3): 7.840e-03\n",
      "Epoch 22300, Train loss: 1.573e+03, Test loss: 4.616e+03, MSE(e): 7.019e-05, MSE(pi1): 8.750e-03, MSE(pi2): 4.042e-05, MSE(pi3): 7.839e-03\n",
      "Epoch 22400, Train loss: 1.555e+03, Test loss: 4.359e+03, MSE(e): 6.670e-05, MSE(pi1): 1.033e-02, MSE(pi2): 3.872e-05, MSE(pi3): 7.847e-03\n",
      "Epoch 22500, Train loss: 1.529e+03, Test loss: 4.314e+03, MSE(e): 6.601e-05, MSE(pi1): 8.475e-03, MSE(pi2): 3.864e-05, MSE(pi3): 7.839e-03\n",
      "Epoch 22600, Train loss: 1.544e+03, Test loss: 4.408e+03, MSE(e): 6.793e-05, MSE(pi1): 8.034e-03, MSE(pi2): 3.929e-05, MSE(pi3): 7.844e-03\n",
      "Epoch 22700, Train loss: 1.818e+03, Test loss: 4.663e+03, MSE(e): 9.273e-05, MSE(pi1): 1.049e-02, MSE(pi2): 4.989e-05, MSE(pi3): 7.858e-03\n",
      "Epoch 22800, Train loss: 1.556e+03, Test loss: 4.497e+03, MSE(e): 6.745e-05, MSE(pi1): 9.685e-03, MSE(pi2): 3.893e-05, MSE(pi3): 7.843e-03\n",
      "Epoch 22900, Train loss: 1.574e+03, Test loss: 4.258e+03, MSE(e): 6.915e-05, MSE(pi1): 9.781e-03, MSE(pi2): 3.965e-05, MSE(pi3): 7.843e-03\n",
      "Epoch 23000, Train loss: 1.552e+03, Test loss: 4.493e+03, MSE(e): 6.769e-05, MSE(pi1): 9.065e-03, MSE(pi2): 3.876e-05, MSE(pi3): 7.842e-03\n",
      "Epoch 23100, Train loss: 1.787e+03, Test loss: 4.648e+03, MSE(e): 8.931e-05, MSE(pi1): 1.075e-02, MSE(pi2): 4.817e-05, MSE(pi3): 7.860e-03\n",
      "Epoch 23200, Train loss: 1.537e+03, Test loss: 4.434e+03, MSE(e): 6.571e-05, MSE(pi1): 9.564e-03, MSE(pi2): 3.793e-05, MSE(pi3): 7.843e-03\n",
      "Epoch 23300, Train loss: 1.520e+03, Test loss: 4.303e+03, MSE(e): 6.321e-05, MSE(pi1): 1.035e-02, MSE(pi2): 3.696e-05, MSE(pi3): 7.841e-03\n",
      "Epoch 23400, Train loss: 1.491e+03, Test loss: 4.222e+03, MSE(e): 6.213e-05, MSE(pi1): 8.576e-03, MSE(pi2): 3.627e-05, MSE(pi3): 7.843e-03\n",
      "Epoch 23500, Train loss: 1.558e+03, Test loss: 4.520e+03, MSE(e): 6.774e-05, MSE(pi1): 9.723e-03, MSE(pi2): 3.904e-05, MSE(pi3): 7.832e-03\n",
      "Epoch 23600, Train loss: 1.626e+03, Test loss: 4.423e+03, MSE(e): 7.355e-05, MSE(pi1): 1.047e-02, MSE(pi2): 4.114e-05, MSE(pi3): 7.854e-03\n",
      "Epoch 23700, Train loss: 1.511e+03, Test loss: 4.331e+03, MSE(e): 6.223e-05, MSE(pi1): 1.043e-02, MSE(pi2): 3.612e-05, MSE(pi3): 7.843e-03\n",
      "Epoch 23800, Train loss: 1.470e+03, Test loss: 4.265e+03, MSE(e): 6.057e-05, MSE(pi1): 8.045e-03, MSE(pi2): 3.549e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 23900, Train loss: 1.529e+03, Test loss: 4.172e+03, MSE(e): 6.608e-05, MSE(pi1): 8.414e-03, MSE(pi2): 3.783e-05, MSE(pi3): 7.839e-03\n",
      "Epoch 24000, Train loss: 1.495e+03, Test loss: 4.286e+03, MSE(e): 6.216e-05, MSE(pi1): 8.898e-03, MSE(pi2): 3.600e-05, MSE(pi3): 7.842e-03\n",
      "Epoch 24100, Train loss: 1.533e+03, Test loss: 4.524e+03, MSE(e): 6.571e-05, MSE(pi1): 9.188e-03, MSE(pi2): 3.759e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 24200, Train loss: 1.811e+03, Test loss: 4.422e+03, MSE(e): 9.134e-05, MSE(pi1): 1.121e-02, MSE(pi2): 4.847e-05, MSE(pi3): 7.854e-03\n",
      "Epoch 24300, Train loss: 1.500e+03, Test loss: 4.199e+03, MSE(e): 6.167e-05, MSE(pi1): 9.837e-03, MSE(pi2): 3.564e-05, MSE(pi3): 7.845e-03\n",
      "Epoch 24400, Train loss: 1.502e+03, Test loss: 4.332e+03, MSE(e): 6.211e-05, MSE(pi1): 9.696e-03, MSE(pi2): 3.570e-05, MSE(pi3): 7.842e-03\n",
      "Epoch 24500, Train loss: 1.482e+03, Test loss: 4.405e+03, MSE(e): 6.143e-05, MSE(pi1): 8.425e-03, MSE(pi2): 3.543e-05, MSE(pi3): 7.836e-03\n",
      "Epoch 24600, Train loss: 1.460e+03, Test loss: 4.240e+03, MSE(e): 5.845e-05, MSE(pi1): 9.194e-03, MSE(pi2): 3.418e-05, MSE(pi3): 7.836e-03\n",
      "Epoch 24700, Train loss: 1.485e+03, Test loss: 4.157e+03, MSE(e): 6.114e-05, MSE(pi1): 8.995e-03, MSE(pi2): 3.527e-05, MSE(pi3): 7.837e-03\n",
      "Epoch 24800, Train loss: 1.497e+03, Test loss: 4.151e+03, MSE(e): 6.237e-05, MSE(pi1): 8.940e-03, MSE(pi2): 3.571e-05, MSE(pi3): 7.841e-03\n",
      "Epoch 24900, Train loss: 1.450e+03, Test loss: 4.137e+03, MSE(e): 5.745e-05, MSE(pi1): 9.163e-03, MSE(pi2): 3.351e-05, MSE(pi3): 7.841e-03\n",
      "Epoch 25000, Train loss: 1.444e+03, Test loss: 4.169e+03, MSE(e): 5.717e-05, MSE(pi1): 8.844e-03, MSE(pi2): 3.340e-05, MSE(pi3): 7.839e-03\n",
      "Epoch 25100, Train loss: 1.442e+03, Test loss: 4.179e+03, MSE(e): 5.742e-05, MSE(pi1): 8.405e-03, MSE(pi2): 3.338e-05, MSE(pi3): 7.841e-03\n",
      "Epoch 25200, Train loss: 1.457e+03, Test loss: 4.253e+03, MSE(e): 5.845e-05, MSE(pi1): 8.889e-03, MSE(pi2): 3.374e-05, MSE(pi3): 7.839e-03\n",
      "Epoch 25300, Train loss: 1.433e+03, Test loss: 4.181e+03, MSE(e): 5.689e-05, MSE(pi1): 8.018e-03, MSE(pi2): 3.311e-05, MSE(pi3): 7.838e-03\n",
      "Epoch 25400, Train loss: 1.505e+03, Test loss: 4.685e+03, MSE(e): 6.396e-05, MSE(pi1): 8.254e-03, MSE(pi2): 3.614e-05, MSE(pi3): 7.829e-03\n",
      "Epoch 25500, Train loss: 1.473e+03, Test loss: 4.377e+03, MSE(e): 5.986e-05, MSE(pi1): 9.074e-03, MSE(pi2): 3.428e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 25600, Train loss: 1.587e+03, Test loss: 4.583e+03, MSE(e): 7.028e-05, MSE(pi1): 1.010e-02, MSE(pi2): 3.899e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 25700, Train loss: 1.562e+03, Test loss: 4.497e+03, MSE(e): 6.914e-05, MSE(pi1): 8.775e-03, MSE(pi2): 3.861e-05, MSE(pi3): 7.831e-03\n",
      "Epoch 25800, Train loss: 1.518e+03, Test loss: 4.361e+03, MSE(e): 6.538e-05, MSE(pi1): 8.102e-03, MSE(pi2): 3.677e-05, MSE(pi3): 7.836e-03\n",
      "Epoch 25900, Train loss: 1.582e+03, Test loss: 4.624e+03, MSE(e): 7.119e-05, MSE(pi1): 8.638e-03, MSE(pi2): 3.897e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 26000, Train loss: 1.467e+03, Test loss: 4.256e+03, MSE(e): 5.986e-05, MSE(pi1): 8.473e-03, MSE(pi2): 3.397e-05, MSE(pi3): 7.839e-03\n",
      "Epoch 26100, Train loss: 1.408e+03, Test loss: 4.133e+03, MSE(e): 5.446e-05, MSE(pi1): 7.983e-03, MSE(pi2): 3.170e-05, MSE(pi3): 7.837e-03\n",
      "Epoch 26200, Train loss: 1.401e+03, Test loss: 4.091e+03, MSE(e): 5.358e-05, MSE(pi1): 8.176e-03, MSE(pi2): 3.138e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 26300, Train loss: 1.450e+03, Test loss: 4.093e+03, MSE(e): 5.780e-05, MSE(pi1): 8.793e-03, MSE(pi2): 3.314e-05, MSE(pi3): 7.837e-03\n",
      "Epoch 26400, Train loss: 1.416e+03, Test loss: 4.121e+03, MSE(e): 5.458e-05, MSE(pi1): 8.699e-03, MSE(pi2): 3.171e-05, MSE(pi3): 7.833e-03\n",
      "Epoch 26500, Train loss: 1.416e+03, Test loss: 4.269e+03, MSE(e): 5.361e-05, MSE(pi1): 9.658e-03, MSE(pi2): 3.129e-05, MSE(pi3): 7.831e-03\n",
      "Epoch 26600, Train loss: 1.416e+03, Test loss: 4.140e+03, MSE(e): 5.329e-05, MSE(pi1): 9.949e-03, MSE(pi2): 3.107e-05, MSE(pi3): 7.840e-03\n",
      "Epoch 26700, Train loss: 1.592e+03, Test loss: 4.140e+03, MSE(e): 7.192e-05, MSE(pi1): 8.849e-03, MSE(pi2): 3.915e-05, MSE(pi3): 7.839e-03\n",
      "Epoch 26800, Train loss: 1.413e+03, Test loss: 4.321e+03, MSE(e): 5.358e-05, MSE(pi1): 9.432e-03, MSE(pi2): 3.107e-05, MSE(pi3): 7.833e-03\n",
      "Epoch 26900, Train loss: 1.641e+03, Test loss: 4.848e+03, MSE(e): 7.552e-05, MSE(pi1): 1.020e-02, MSE(pi2): 4.039e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 27000, Train loss: 1.422e+03, Test loss: 4.225e+03, MSE(e): 5.348e-05, MSE(pi1): 1.034e-02, MSE(pi2): 3.089e-05, MSE(pi3): 7.839e-03\n",
      "Epoch 27100, Train loss: 1.418e+03, Test loss: 4.081e+03, MSE(e): 5.525e-05, MSE(pi1): 8.197e-03, MSE(pi2): 3.178e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 27200, Train loss: 1.421e+03, Test loss: 4.085e+03, MSE(e): 5.477e-05, MSE(pi1): 9.026e-03, MSE(pi2): 3.159e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 27300, Train loss: 1.481e+03, Test loss: 4.209e+03, MSE(e): 6.066e-05, MSE(pi1): 9.050e-03, MSE(pi2): 3.373e-05, MSE(pi3): 7.844e-03\n",
      "Epoch 27400, Train loss: 1.583e+03, Test loss: 4.307e+03, MSE(e): 7.145e-05, MSE(pi1): 8.398e-03, MSE(pi2): 3.862e-05, MSE(pi3): 7.841e-03\n",
      "Epoch 27500, Train loss: 1.418e+03, Test loss: 4.220e+03, MSE(e): 5.363e-05, MSE(pi1): 9.749e-03, MSE(pi2): 3.074e-05, MSE(pi3): 7.838e-03\n",
      "Epoch 27600, Train loss: 1.444e+03, Test loss: 4.238e+03, MSE(e): 5.671e-05, MSE(pi1): 9.267e-03, MSE(pi2): 3.204e-05, MSE(pi3): 7.838e-03\n",
      "Epoch 27700, Train loss: 1.718e+03, Test loss: 4.517e+03, MSE(e): 8.402e-05, MSE(pi1): 9.268e-03, MSE(pi2): 4.397e-05, MSE(pi3): 7.849e-03\n",
      "Epoch 27800, Train loss: 1.521e+03, Test loss: 4.452e+03, MSE(e): 6.549e-05, MSE(pi1): 8.273e-03, MSE(pi2): 3.586e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 27900, Train loss: 1.360e+03, Test loss: 4.057e+03, MSE(e): 4.976e-05, MSE(pi1): 7.906e-03, MSE(pi2): 2.915e-05, MSE(pi3): 7.830e-03\n",
      "Epoch 28000, Train loss: 1.355e+03, Test loss: 4.182e+03, MSE(e): 4.935e-05, MSE(pi1): 7.846e-03, MSE(pi2): 2.891e-05, MSE(pi3): 7.828e-03\n",
      "Epoch 28100, Train loss: 1.381e+03, Test loss: 4.196e+03, MSE(e): 4.975e-05, MSE(pi1): 1.002e-02, MSE(pi2): 2.890e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 28200, Train loss: 1.620e+03, Test loss: 4.150e+03, MSE(e): 7.538e-05, MSE(pi1): 8.271e-03, MSE(pi2): 4.012e-05, MSE(pi3): 7.838e-03\n",
      "Epoch 28300, Train loss: 1.619e+03, Test loss: 4.846e+03, MSE(e): 7.569e-05, MSE(pi1): 7.911e-03, MSE(pi2): 4.005e-05, MSE(pi3): 7.831e-03\n",
      "Epoch 28400, Train loss: 1.402e+03, Test loss: 4.091e+03, MSE(e): 5.234e-05, MSE(pi1): 9.470e-03, MSE(pi2): 3.012e-05, MSE(pi3): 7.836e-03\n",
      "Epoch 28500, Train loss: 1.390e+03, Test loss: 4.095e+03, MSE(e): 5.132e-05, MSE(pi1): 9.312e-03, MSE(pi2): 2.958e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 28600, Train loss: 1.568e+03, Test loss: 4.381e+03, MSE(e): 6.804e-05, MSE(pi1): 1.031e-02, MSE(pi2): 3.681e-05, MSE(pi3): 7.847e-03\n",
      "Epoch 28700, Train loss: 1.504e+03, Test loss: 4.461e+03, MSE(e): 6.390e-05, MSE(pi1): 8.117e-03, MSE(pi2): 3.484e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 28800, Train loss: 2.004e+03, Test loss: 4.169e+03, MSE(e): 1.122e-04, MSE(pi1): 9.778e-03, MSE(pi2): 5.578e-05, MSE(pi3): 7.840e-03\n",
      "Epoch 28900, Train loss: 1.386e+03, Test loss: 4.082e+03, MSE(e): 5.195e-05, MSE(pi1): 8.321e-03, MSE(pi2): 2.976e-05, MSE(pi3): 7.831e-03\n",
      "Epoch 29000, Train loss: 1.348e+03, Test loss: 4.132e+03, MSE(e): 4.785e-05, MSE(pi1): 8.659e-03, MSE(pi2): 2.803e-05, MSE(pi3): 7.828e-03\n",
      "Epoch 29100, Train loss: 1.381e+03, Test loss: 4.122e+03, MSE(e): 5.111e-05, MSE(pi1): 8.659e-03, MSE(pi2): 2.930e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 29200, Train loss: 1.373e+03, Test loss: 4.315e+03, MSE(e): 5.032e-05, MSE(pi1): 8.670e-03, MSE(pi2): 2.892e-05, MSE(pi3): 7.829e-03\n",
      "Epoch 29300, Train loss: 1.735e+03, Test loss: 4.378e+03, MSE(e): 8.650e-05, MSE(pi1): 8.593e-03, MSE(pi2): 4.449e-05, MSE(pi3): 7.843e-03\n",
      "Epoch 29400, Train loss: 1.400e+03, Test loss: 4.169e+03, MSE(e): 5.335e-05, MSE(pi1): 8.287e-03, MSE(pi2): 3.015e-05, MSE(pi3): 7.837e-03\n",
      "Epoch 29500, Train loss: 1.345e+03, Test loss: 4.088e+03, MSE(e): 4.805e-05, MSE(pi1): 8.158e-03, MSE(pi2): 2.795e-05, MSE(pi3): 7.829e-03\n",
      "Epoch 29600, Train loss: 1.423e+03, Test loss: 4.621e+03, MSE(e): 5.341e-05, MSE(pi1): 1.065e-02, MSE(pi2): 3.025e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 29700, Train loss: 1.345e+03, Test loss: 4.126e+03, MSE(e): 4.775e-05, MSE(pi1): 8.529e-03, MSE(pi2): 2.787e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 29800, Train loss: 1.392e+03, Test loss: 4.147e+03, MSE(e): 5.079e-05, MSE(pi1): 1.002e-02, MSE(pi2): 2.898e-05, MSE(pi3): 7.836e-03\n",
      "Epoch 29900, Train loss: 1.526e+03, Test loss: 4.409e+03, MSE(e): 6.636e-05, MSE(pi1): 7.886e-03, MSE(pi2): 3.549e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 30000, Train loss: 1.452e+03, Test loss: 4.157e+03, MSE(e): 5.894e-05, MSE(pi1): 8.043e-03, MSE(pi2): 3.295e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 30100, Train loss: 1.420e+03, Test loss: 4.252e+03, MSE(e): 5.536e-05, MSE(pi1): 8.254e-03, MSE(pi2): 3.082e-05, MSE(pi3): 7.838e-03\n",
      "Epoch 30200, Train loss: 1.365e+03, Test loss: 4.091e+03, MSE(e): 4.921e-05, MSE(pi1): 8.964e-03, MSE(pi2): 2.821e-05, MSE(pi3): 7.832e-03\n",
      "Epoch 30300, Train loss: 1.316e+03, Test loss: 4.121e+03, MSE(e): 4.475e-05, MSE(pi1): 8.505e-03, MSE(pi2): 2.627e-05, MSE(pi3): 7.830e-03\n",
      "Epoch 30400, Train loss: 1.333e+03, Test loss: 4.136e+03, MSE(e): 4.599e-05, MSE(pi1): 9.012e-03, MSE(pi2): 2.662e-05, MSE(pi3): 7.833e-03\n",
      "Epoch 30500, Train loss: 1.320e+03, Test loss: 4.156e+03, MSE(e): 4.586e-05, MSE(pi1): 7.819e-03, MSE(pi2): 2.658e-05, MSE(pi3): 7.831e-03\n",
      "Epoch 30600, Train loss: 1.373e+03, Test loss: 4.250e+03, MSE(e): 4.979e-05, MSE(pi1): 9.163e-03, MSE(pi2): 2.816e-05, MSE(pi3): 7.833e-03\n",
      "Epoch 30700, Train loss: 1.348e+03, Test loss: 4.096e+03, MSE(e): 4.844e-05, MSE(pi1): 8.068e-03, MSE(pi2): 2.780e-05, MSE(pi3): 7.831e-03\n",
      "Epoch 30800, Train loss: 1.549e+03, Test loss: 5.047e+03, MSE(e): 6.776e-05, MSE(pi1): 8.882e-03, MSE(pi2): 3.594e-05, MSE(pi3): 7.829e-03\n",
      "Epoch 30900, Train loss: 1.358e+03, Test loss: 4.193e+03, MSE(e): 4.866e-05, MSE(pi1): 8.799e-03, MSE(pi2): 2.766e-05, MSE(pi3): 7.832e-03\n",
      "Epoch 31000, Train loss: 1.302e+03, Test loss: 4.118e+03, MSE(e): 4.299e-05, MSE(pi1): 8.918e-03, MSE(pi2): 2.537e-05, MSE(pi3): 7.829e-03\n",
      "Epoch 31100, Train loss: 1.307e+03, Test loss: 4.272e+03, MSE(e): 4.409e-05, MSE(pi1): 8.375e-03, MSE(pi2): 2.577e-05, MSE(pi3): 7.826e-03\n",
      "Epoch 31200, Train loss: 1.303e+03, Test loss: 4.103e+03, MSE(e): 4.390e-05, MSE(pi1): 8.166e-03, MSE(pi2): 2.575e-05, MSE(pi3): 7.827e-03\n",
      "Epoch 31300, Train loss: 1.294e+03, Test loss: 4.116e+03, MSE(e): 4.293e-05, MSE(pi1): 8.189e-03, MSE(pi2): 2.528e-05, MSE(pi3): 7.826e-03\n",
      "Epoch 31400, Train loss: 1.441e+03, Test loss: 4.520e+03, MSE(e): 5.677e-05, MSE(pi1): 9.019e-03, MSE(pi2): 3.106e-05, MSE(pi3): 7.830e-03\n",
      "Epoch 31500, Train loss: 1.319e+03, Test loss: 4.162e+03, MSE(e): 4.276e-05, MSE(pi1): 1.082e-02, MSE(pi2): 2.522e-05, MSE(pi3): 7.829e-03\n",
      "Epoch 31600, Train loss: 1.371e+03, Test loss: 4.170e+03, MSE(e): 4.923e-05, MSE(pi1): 9.536e-03, MSE(pi2): 2.793e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 31700, Train loss: 1.696e+03, Test loss: 4.496e+03, MSE(e): 8.198e-05, MSE(pi1): 9.166e-03, MSE(pi2): 4.206e-05, MSE(pi3): 7.843e-03\n",
      "Epoch 31800, Train loss: 1.466e+03, Test loss: 4.191e+03, MSE(e): 5.953e-05, MSE(pi1): 8.783e-03, MSE(pi2): 3.235e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 31900, Train loss: 1.325e+03, Test loss: 4.262e+03, MSE(e): 4.537e-05, MSE(pi1): 8.954e-03, MSE(pi2): 2.658e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 32000, Train loss: 1.281e+03, Test loss: 4.145e+03, MSE(e): 4.137e-05, MSE(pi1): 8.486e-03, MSE(pi2): 2.441e-05, MSE(pi3): 7.826e-03\n",
      "Epoch 32100, Train loss: 1.450e+03, Test loss: 4.160e+03, MSE(e): 5.632e-05, MSE(pi1): 1.037e-02, MSE(pi2): 3.095e-05, MSE(pi3): 7.832e-03\n",
      "Epoch 32200, Train loss: 1.305e+03, Test loss: 4.141e+03, MSE(e): 4.360e-05, MSE(pi1): 8.588e-03, MSE(pi2): 2.543e-05, MSE(pi3): 7.831e-03\n",
      "Epoch 32300, Train loss: 1.285e+03, Test loss: 4.153e+03, MSE(e): 4.118e-05, MSE(pi1): 9.036e-03, MSE(pi2): 2.431e-05, MSE(pi3): 7.827e-03\n",
      "Epoch 32400, Train loss: 1.300e+03, Test loss: 4.128e+03, MSE(e): 4.269e-05, MSE(pi1): 9.011e-03, MSE(pi2): 2.489e-05, MSE(pi3): 7.828e-03\n",
      "Epoch 32500, Train loss: 1.549e+03, Test loss: 4.977e+03, MSE(e): 6.846e-05, MSE(pi1): 7.953e-03, MSE(pi2): 3.584e-05, MSE(pi3): 7.845e-03\n",
      "Epoch 32600, Train loss: 1.538e+03, Test loss: 5.069e+03, MSE(e): 6.682e-05, MSE(pi1): 8.783e-03, MSE(pi2): 3.529e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 32700, Train loss: 1.274e+03, Test loss: 4.173e+03, MSE(e): 4.070e-05, MSE(pi1): 8.472e-03, MSE(pi2): 2.394e-05, MSE(pi3): 7.827e-03\n",
      "Epoch 32800, Train loss: 1.330e+03, Test loss: 4.152e+03, MSE(e): 4.595e-05, MSE(pi1): 8.736e-03, MSE(pi2): 2.625e-05, MSE(pi3): 7.830e-03\n",
      "Epoch 32900, Train loss: 1.272e+03, Test loss: 4.138e+03, MSE(e): 4.074e-05, MSE(pi1): 8.194e-03, MSE(pi2): 2.414e-05, MSE(pi3): 7.823e-03\n",
      "Epoch 33000, Train loss: 1.288e+03, Test loss: 4.166e+03, MSE(e): 4.055e-05, MSE(pi1): 9.959e-03, MSE(pi2): 2.386e-05, MSE(pi3): 7.828e-03\n",
      "Epoch 33100, Train loss: 1.304e+03, Test loss: 4.154e+03, MSE(e): 4.275e-05, MSE(pi1): 9.387e-03, MSE(pi2): 2.473e-05, MSE(pi3): 7.828e-03\n",
      "Epoch 33200, Train loss: 1.319e+03, Test loss: 4.246e+03, MSE(e): 4.535e-05, MSE(pi1): 8.211e-03, MSE(pi2): 2.596e-05, MSE(pi3): 7.830e-03\n",
      "Epoch 33300, Train loss: 1.581e+03, Test loss: 5.502e+03, MSE(e): 7.090e-05, MSE(pi1): 8.955e-03, MSE(pi2): 3.680e-05, MSE(pi3): 7.824e-03\n",
      "Epoch 33400, Train loss: 1.265e+03, Test loss: 4.195e+03, MSE(e): 3.984e-05, MSE(pi1): 8.351e-03, MSE(pi2): 2.345e-05, MSE(pi3): 7.827e-03\n",
      "Epoch 33500, Train loss: 1.283e+03, Test loss: 4.208e+03, MSE(e): 4.014e-05, MSE(pi1): 9.904e-03, MSE(pi2): 2.361e-05, MSE(pi3): 7.827e-03\n",
      "Epoch 33600, Train loss: 1.265e+03, Test loss: 4.172e+03, MSE(e): 3.959e-05, MSE(pi1): 8.643e-03, MSE(pi2): 2.334e-05, MSE(pi3): 7.824e-03\n",
      "Epoch 33700, Train loss: 1.421e+03, Test loss: 4.657e+03, MSE(e): 5.483e-05, MSE(pi1): 8.978e-03, MSE(pi2): 2.976e-05, MSE(pi3): 7.828e-03\n",
      "Epoch 33800, Train loss: 1.292e+03, Test loss: 4.239e+03, MSE(e): 4.128e-05, MSE(pi1): 9.664e-03, MSE(pi2): 2.402e-05, MSE(pi3): 7.822e-03\n",
      "Epoch 33900, Train loss: 1.262e+03, Test loss: 4.276e+03, MSE(e): 3.993e-05, MSE(pi1): 8.038e-03, MSE(pi2): 2.337e-05, MSE(pi3): 7.823e-03\n",
      "Epoch 34000, Train loss: 1.349e+03, Test loss: 4.245e+03, MSE(e): 4.808e-05, MSE(pi1): 8.514e-03, MSE(pi2): 2.701e-05, MSE(pi3): 7.831e-03\n",
      "Epoch 34100, Train loss: 1.287e+03, Test loss: 4.163e+03, MSE(e): 4.118e-05, MSE(pi1): 9.259e-03, MSE(pi2): 2.405e-05, MSE(pi3): 7.828e-03\n",
      "Epoch 34200, Train loss: 1.610e+03, Test loss: 5.170e+03, MSE(e): 7.428e-05, MSE(pi1): 8.253e-03, MSE(pi2): 3.812e-05, MSE(pi3): 7.843e-03\n",
      "Epoch 34300, Train loss: 1.650e+03, Test loss: 4.724e+03, MSE(e): 7.715e-05, MSE(pi1): 9.470e-03, MSE(pi2): 3.911e-05, MSE(pi3): 7.836e-03\n",
      "Epoch 34400, Train loss: 1.243e+03, Test loss: 4.217e+03, MSE(e): 3.809e-05, MSE(pi1): 7.970e-03, MSE(pi2): 2.252e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 34500, Train loss: 1.258e+03, Test loss: 4.220e+03, MSE(e): 3.804e-05, MSE(pi1): 9.507e-03, MSE(pi2): 2.242e-05, MSE(pi3): 7.824e-03\n",
      "Epoch 34600, Train loss: 1.255e+03, Test loss: 4.222e+03, MSE(e): 3.784e-05, MSE(pi1): 9.417e-03, MSE(pi2): 2.245e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 34700, Train loss: 1.949e+03, Test loss: 4.451e+03, MSE(e): 1.036e-04, MSE(pi1): 1.285e-02, MSE(pi2): 5.062e-05, MSE(pi3): 7.844e-03\n",
      "Epoch 34800, Train loss: 1.264e+03, Test loss: 4.184e+03, MSE(e): 3.979e-05, MSE(pi1): 8.452e-03, MSE(pi2): 2.332e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 34900, Train loss: 1.243e+03, Test loss: 4.338e+03, MSE(e): 3.827e-05, MSE(pi1): 7.914e-03, MSE(pi2): 2.286e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 35000, Train loss: 1.427e+03, Test loss: 5.153e+03, MSE(e): 5.485e-05, MSE(pi1): 9.659e-03, MSE(pi2): 2.961e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 35100, Train loss: 1.429e+03, Test loss: 4.172e+03, MSE(e): 5.657e-05, MSE(pi1): 8.211e-03, MSE(pi2): 3.094e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 35200, Train loss: 1.237e+03, Test loss: 4.219e+03, MSE(e): 3.760e-05, MSE(pi1): 7.924e-03, MSE(pi2): 2.225e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 35300, Train loss: 1.236e+03, Test loss: 4.208e+03, MSE(e): 3.749e-05, MSE(pi1): 7.856e-03, MSE(pi2): 2.207e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 35400, Train loss: 1.485e+03, Test loss: 5.044e+03, MSE(e): 6.186e-05, MSE(pi1): 8.429e-03, MSE(pi2): 3.286e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 35500, Train loss: 1.260e+03, Test loss: 4.309e+03, MSE(e): 3.747e-05, MSE(pi1): 1.024e-02, MSE(pi2): 2.203e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 35600, Train loss: 1.230e+03, Test loss: 4.226e+03, MSE(e): 3.698e-05, MSE(pi1): 7.832e-03, MSE(pi2): 2.185e-05, MSE(pi3): 7.822e-03\n",
      "Epoch 35700, Train loss: 1.232e+03, Test loss: 4.237e+03, MSE(e): 3.665e-05, MSE(pi1): 8.328e-03, MSE(pi2): 2.167e-05, MSE(pi3): 7.823e-03\n",
      "Epoch 35800, Train loss: 1.441e+03, Test loss: 4.209e+03, MSE(e): 5.762e-05, MSE(pi1): 8.271e-03, MSE(pi2): 3.149e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 35900, Train loss: 1.445e+03, Test loss: 4.363e+03, MSE(e): 5.639e-05, MSE(pi1): 9.746e-03, MSE(pi2): 3.019e-05, MSE(pi3): 7.832e-03\n",
      "Epoch 36000, Train loss: 1.458e+03, Test loss: 5.257e+03, MSE(e): 5.895e-05, MSE(pi1): 8.661e-03, MSE(pi2): 3.121e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 36100, Train loss: 1.243e+03, Test loss: 4.222e+03, MSE(e): 3.831e-05, MSE(pi1): 7.824e-03, MSE(pi2): 2.242e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 36200, Train loss: 1.251e+03, Test loss: 4.205e+03, MSE(e): 3.905e-05, MSE(pi1): 7.926e-03, MSE(pi2): 2.291e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 36300, Train loss: 1.249e+03, Test loss: 4.211e+03, MSE(e): 3.778e-05, MSE(pi1): 8.928e-03, MSE(pi2): 2.222e-05, MSE(pi3): 7.824e-03\n",
      "Epoch 36400, Train loss: 1.263e+03, Test loss: 4.451e+03, MSE(e): 4.014e-05, MSE(pi1): 7.995e-03, MSE(pi2): 2.309e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 36500, Train loss: 1.287e+03, Test loss: 4.265e+03, MSE(e): 3.802e-05, MSE(pi1): 1.231e-02, MSE(pi2): 2.218e-05, MSE(pi3): 7.832e-03\n",
      "Epoch 36600, Train loss: 1.600e+03, Test loss: 5.374e+03, MSE(e): 7.330e-05, MSE(pi1): 8.565e-03, MSE(pi2): 3.783e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 36700, Train loss: 1.285e+03, Test loss: 4.240e+03, MSE(e): 4.247e-05, MSE(pi1): 7.791e-03, MSE(pi2): 2.431e-05, MSE(pi3): 7.822e-03\n",
      "Epoch 36800, Train loss: 1.436e+03, Test loss: 4.338e+03, MSE(e): 5.745e-05, MSE(pi1): 7.813e-03, MSE(pi2): 3.062e-05, MSE(pi3): 7.836e-03\n",
      "Epoch 36900, Train loss: 1.443e+03, Test loss: 4.328e+03, MSE(e): 5.809e-05, MSE(pi1): 7.761e-03, MSE(pi2): 3.036e-05, MSE(pi3): 7.840e-03\n",
      "Epoch 37000, Train loss: 1.275e+03, Test loss: 4.280e+03, MSE(e): 4.131e-05, MSE(pi1): 7.987e-03, MSE(pi2): 2.369e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 37100, Train loss: 1.262e+03, Test loss: 4.191e+03, MSE(e): 4.008e-05, MSE(pi1): 7.914e-03, MSE(pi2): 2.321e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 37200, Train loss: 1.217e+03, Test loss: 4.234e+03, MSE(e): 3.564e-05, MSE(pi1): 7.819e-03, MSE(pi2): 2.108e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 37300, Train loss: 1.273e+03, Test loss: 4.557e+03, MSE(e): 4.033e-05, MSE(pi1): 8.784e-03, MSE(pi2): 2.304e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 37400, Train loss: 1.987e+03, Test loss: 5.549e+03, MSE(e): 1.120e-04, MSE(pi1): 8.424e-03, MSE(pi2): 5.349e-05, MSE(pi3): 7.832e-03\n",
      "Epoch 37500, Train loss: 1.469e+03, Test loss: 4.270e+03, MSE(e): 6.070e-05, MSE(pi1): 7.801e-03, MSE(pi2): 3.228e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 37600, Train loss: 1.227e+03, Test loss: 4.300e+03, MSE(e): 3.466e-05, MSE(pi1): 9.822e-03, MSE(pi2): 2.062e-05, MSE(pi3): 7.823e-03\n",
      "Epoch 37700, Train loss: 1.223e+03, Test loss: 4.310e+03, MSE(e): 3.522e-05, MSE(pi1): 8.833e-03, MSE(pi2): 2.082e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 37800, Train loss: 1.278e+03, Test loss: 4.211e+03, MSE(e): 4.095e-05, MSE(pi1): 8.638e-03, MSE(pi2): 2.348e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 37900, Train loss: 1.245e+03, Test loss: 4.241e+03, MSE(e): 3.831e-05, MSE(pi1): 8.020e-03, MSE(pi2): 2.237e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 38000, Train loss: 1.205e+03, Test loss: 4.288e+03, MSE(e): 3.425e-05, MSE(pi1): 8.023e-03, MSE(pi2): 2.036e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 38100, Train loss: 1.244e+03, Test loss: 4.277e+03, MSE(e): 3.723e-05, MSE(pi1): 8.889e-03, MSE(pi2): 2.172e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 38200, Train loss: 1.227e+03, Test loss: 4.277e+03, MSE(e): 3.531e-05, MSE(pi1): 9.087e-03, MSE(pi2): 2.077e-05, MSE(pi3): 7.826e-03\n",
      "Epoch 38300, Train loss: 1.236e+03, Test loss: 4.316e+03, MSE(e): 3.612e-05, MSE(pi1): 9.196e-03, MSE(pi2): 2.115e-05, MSE(pi3): 7.827e-03\n",
      "Epoch 38400, Train loss: 1.425e+03, Test loss: 4.788e+03, MSE(e): 5.398e-05, MSE(pi1): 1.015e-02, MSE(pi2): 2.894e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 38500, Train loss: 1.408e+03, Test loss: 4.499e+03, MSE(e): 5.440e-05, MSE(pi1): 8.096e-03, MSE(pi2): 2.904e-05, MSE(pi3): 7.828e-03\n",
      "Epoch 38600, Train loss: 1.322e+03, Test loss: 4.393e+03, MSE(e): 4.602e-05, MSE(pi1): 7.873e-03, MSE(pi2): 2.516e-05, MSE(pi3): 7.829e-03\n",
      "Epoch 38700, Train loss: 1.285e+03, Test loss: 4.379e+03, MSE(e): 4.230e-05, MSE(pi1): 7.958e-03, MSE(pi2): 2.361e-05, MSE(pi3): 7.828e-03\n",
      "Epoch 38800, Train loss: 1.217e+03, Test loss: 4.444e+03, MSE(e): 3.571e-05, MSE(pi1): 7.921e-03, MSE(pi2): 2.114e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 38900, Train loss: 1.209e+03, Test loss: 4.321e+03, MSE(e): 3.382e-05, MSE(pi1): 8.836e-03, MSE(pi2): 2.013e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 39000, Train loss: 1.260e+03, Test loss: 4.606e+03, MSE(e): 3.832e-05, MSE(pi1): 9.466e-03, MSE(pi2): 2.190e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 39100, Train loss: 1.433e+03, Test loss: 4.445e+03, MSE(e): 5.666e-05, MSE(pi1): 8.505e-03, MSE(pi2): 3.028e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 39200, Train loss: 1.244e+03, Test loss: 4.351e+03, MSE(e): 3.652e-05, MSE(pi1): 9.599e-03, MSE(pi2): 2.118e-05, MSE(pi3): 7.824e-03\n",
      "Epoch 39300, Train loss: 1.248e+03, Test loss: 4.335e+03, MSE(e): 3.735e-05, MSE(pi1): 9.249e-03, MSE(pi2): 2.161e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 39400, Train loss: 1.210e+03, Test loss: 4.346e+03, MSE(e): 3.344e-05, MSE(pi1): 9.366e-03, MSE(pi2): 1.983e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 39500, Train loss: 1.295e+03, Test loss: 4.534e+03, MSE(e): 4.295e-05, MSE(pi1): 8.294e-03, MSE(pi2): 2.482e-05, MSE(pi3): 7.830e-03\n",
      "Epoch 39600, Train loss: 1.264e+03, Test loss: 4.304e+03, MSE(e): 3.953e-05, MSE(pi1): 8.687e-03, MSE(pi2): 2.257e-05, MSE(pi3): 7.822e-03\n",
      "Epoch 39700, Train loss: 1.404e+03, Test loss: 4.909e+03, MSE(e): 5.280e-05, MSE(pi1): 9.554e-03, MSE(pi2): 2.863e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 39800, Train loss: 1.282e+03, Test loss: 4.526e+03, MSE(e): 4.118e-05, MSE(pi1): 8.772e-03, MSE(pi2): 2.307e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 39900, Train loss: 1.222e+03, Test loss: 4.397e+03, MSE(e): 3.285e-05, MSE(pi1): 1.113e-02, MSE(pi2): 1.946e-05, MSE(pi3): 7.824e-03\n",
      "Epoch 40000, Train loss: 1.247e+03, Test loss: 4.352e+03, MSE(e): 3.714e-05, MSE(pi1): 9.309e-03, MSE(pi2): 2.140e-05, MSE(pi3): 7.824e-03\n",
      "Epoch 40100, Train loss: 1.397e+03, Test loss: 4.882e+03, MSE(e): 5.050e-05, MSE(pi1): 1.087e-02, MSE(pi2): 2.696e-05, MSE(pi3): 7.836e-03\n",
      "Epoch 40200, Train loss: 1.877e+03, Test loss: 4.578e+03, MSE(e): 1.014e-04, MSE(pi1): 7.995e-03, MSE(pi2): 4.932e-05, MSE(pi3): 7.829e-03\n",
      "Epoch 40300, Train loss: 1.203e+03, Test loss: 4.507e+03, MSE(e): 3.417e-05, MSE(pi1): 8.020e-03, MSE(pi2): 2.025e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 40400, Train loss: 1.226e+03, Test loss: 4.433e+03, MSE(e): 3.622e-05, MSE(pi1): 8.277e-03, MSE(pi2): 2.149e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 40500, Train loss: 1.189e+03, Test loss: 4.377e+03, MSE(e): 3.206e-05, MSE(pi1): 8.636e-03, MSE(pi2): 1.906e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 40600, Train loss: 1.207e+03, Test loss: 4.329e+03, MSE(e): 3.362e-05, MSE(pi1): 8.872e-03, MSE(pi2): 1.982e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 40700, Train loss: 1.185e+03, Test loss: 4.386e+03, MSE(e): 3.164e-05, MSE(pi1): 8.682e-03, MSE(pi2): 1.891e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 40800, Train loss: 1.197e+03, Test loss: 4.369e+03, MSE(e): 3.197e-05, MSE(pi1): 9.496e-03, MSE(pi2): 1.923e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 40900, Train loss: 1.224e+03, Test loss: 4.394e+03, MSE(e): 3.305e-05, MSE(pi1): 1.113e-02, MSE(pi2): 1.942e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 41000, Train loss: 1.646e+03, Test loss: 5.269e+03, MSE(e): 7.524e-05, MSE(pi1): 1.095e-02, MSE(pi2): 3.755e-05, MSE(pi3): 7.843e-03\n",
      "Epoch 41100, Train loss: 1.211e+03, Test loss: 4.360e+03, MSE(e): 3.348e-05, MSE(pi1): 9.382e-03, MSE(pi2): 1.969e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 41200, Train loss: 1.207e+03, Test loss: 4.375e+03, MSE(e): 3.242e-05, MSE(pi1): 1.010e-02, MSE(pi2): 1.924e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 41300, Train loss: 1.214e+03, Test loss: 4.375e+03, MSE(e): 3.465e-05, MSE(pi1): 8.579e-03, MSE(pi2): 2.022e-05, MSE(pi3): 7.822e-03\n",
      "Epoch 41400, Train loss: 1.226e+03, Test loss: 4.327e+03, MSE(e): 3.647e-05, MSE(pi1): 7.976e-03, MSE(pi2): 2.120e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 41500, Train loss: 1.645e+03, Test loss: 4.544e+03, MSE(e): 7.752e-05, MSE(pi1): 8.649e-03, MSE(pi2): 3.838e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 41600, Train loss: 1.361e+03, Test loss: 4.558e+03, MSE(e): 4.954e-05, MSE(pi1): 8.273e-03, MSE(pi2): 2.659e-05, MSE(pi3): 7.826e-03\n",
      "Epoch 41700, Train loss: 1.191e+03, Test loss: 4.434e+03, MSE(e): 3.215e-05, MSE(pi1): 8.735e-03, MSE(pi2): 1.908e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 41800, Train loss: 1.170e+03, Test loss: 4.434e+03, MSE(e): 3.108e-05, MSE(pi1): 7.836e-03, MSE(pi2): 1.855e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 41900, Train loss: 1.173e+03, Test loss: 4.400e+03, MSE(e): 3.103e-05, MSE(pi1): 8.101e-03, MSE(pi2): 1.857e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 42000, Train loss: 1.171e+03, Test loss: 4.454e+03, MSE(e): 3.089e-05, MSE(pi1): 8.052e-03, MSE(pi2): 1.847e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 42100, Train loss: 1.203e+03, Test loss: 4.358e+03, MSE(e): 3.345e-05, MSE(pi1): 8.671e-03, MSE(pi2): 1.962e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 42200, Train loss: 1.213e+03, Test loss: 4.413e+03, MSE(e): 3.180e-05, MSE(pi1): 1.124e-02, MSE(pi2): 1.889e-05, MSE(pi3): 7.823e-03\n",
      "Epoch 42300, Train loss: 1.178e+03, Test loss: 4.405e+03, MSE(e): 3.089e-05, MSE(pi1): 8.694e-03, MSE(pi2): 1.857e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 42400, Train loss: 1.171e+03, Test loss: 4.439e+03, MSE(e): 3.043e-05, MSE(pi1): 8.549e-03, MSE(pi2): 1.821e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 42500, Train loss: 1.172e+03, Test loss: 4.417e+03, MSE(e): 3.063e-05, MSE(pi1): 8.351e-03, MSE(pi2): 1.828e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 42600, Train loss: 1.172e+03, Test loss: 4.474e+03, MSE(e): 3.097e-05, MSE(pi1): 8.067e-03, MSE(pi2): 1.829e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 42700, Train loss: 1.175e+03, Test loss: 4.470e+03, MSE(e): 3.135e-05, MSE(pi1): 7.991e-03, MSE(pi2): 1.848e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 42800, Train loss: 1.397e+03, Test loss: 4.364e+03, MSE(e): 5.274e-05, MSE(pi1): 8.811e-03, MSE(pi2): 2.824e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 42900, Train loss: 1.182e+03, Test loss: 4.450e+03, MSE(e): 3.005e-05, MSE(pi1): 9.926e-03, MSE(pi2): 1.797e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 43000, Train loss: 1.177e+03, Test loss: 4.395e+03, MSE(e): 3.110e-05, MSE(pi1): 8.447e-03, MSE(pi2): 1.853e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 43100, Train loss: 1.166e+03, Test loss: 4.463e+03, MSE(e): 3.043e-05, MSE(pi1): 8.004e-03, MSE(pi2): 1.805e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 43200, Train loss: 1.166e+03, Test loss: 4.424e+03, MSE(e): 3.021e-05, MSE(pi1): 8.272e-03, MSE(pi2): 1.805e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 43300, Train loss: 1.252e+03, Test loss: 4.484e+03, MSE(e): 3.531e-05, MSE(pi1): 1.159e-02, MSE(pi2): 2.030e-05, MSE(pi3): 7.827e-03\n",
      "Epoch 43400, Train loss: 1.293e+03, Test loss: 4.532e+03, MSE(e): 4.303e-05, MSE(pi1): 8.018e-03, MSE(pi2): 2.327e-05, MSE(pi3): 7.827e-03\n",
      "Epoch 43500, Train loss: 1.481e+03, Test loss: 5.804e+03, MSE(e): 6.176e-05, MSE(pi1): 8.367e-03, MSE(pi2): 3.270e-05, MSE(pi3): 7.795e-03\n",
      "Epoch 43600, Train loss: 1.171e+03, Test loss: 4.474e+03, MSE(e): 3.095e-05, MSE(pi1): 7.997e-03, MSE(pi2): 1.836e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 43700, Train loss: 1.651e+03, Test loss: 5.060e+03, MSE(e): 7.780e-05, MSE(pi1): 9.176e-03, MSE(pi2): 3.921e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 43800, Train loss: 1.216e+03, Test loss: 4.446e+03, MSE(e): 3.465e-05, MSE(pi1): 8.748e-03, MSE(pi2): 2.002e-05, MSE(pi3): 7.822e-03\n",
      "Epoch 43900, Train loss: 1.199e+03, Test loss: 4.476e+03, MSE(e): 3.006e-05, MSE(pi1): 1.162e-02, MSE(pi2): 1.794e-05, MSE(pi3): 7.822e-03\n",
      "Epoch 44000, Train loss: 1.193e+03, Test loss: 4.562e+03, MSE(e): 3.133e-05, MSE(pi1): 9.803e-03, MSE(pi2): 1.850e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 44100, Train loss: 1.388e+03, Test loss: 4.597e+03, MSE(e): 5.181e-05, MSE(pi1): 8.653e-03, MSE(pi2): 2.699e-05, MSE(pi3): 7.833e-03\n",
      "Epoch 44200, Train loss: 1.449e+03, Test loss: 4.911e+03, MSE(e): 5.623e-05, MSE(pi1): 1.041e-02, MSE(pi2): 2.893e-05, MSE(pi3): 7.831e-03\n",
      "Epoch 44300, Train loss: 1.179e+03, Test loss: 4.535e+03, MSE(e): 3.025e-05, MSE(pi1): 9.474e-03, MSE(pi2): 1.795e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 44400, Train loss: 1.175e+03, Test loss: 4.556e+03, MSE(e): 3.039e-05, MSE(pi1): 8.972e-03, MSE(pi2): 1.795e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 44500, Train loss: 1.155e+03, Test loss: 4.483e+03, MSE(e): 2.937e-05, MSE(pi1): 7.985e-03, MSE(pi2): 1.761e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 44600, Train loss: 1.174e+03, Test loss: 4.476e+03, MSE(e): 3.000e-05, MSE(pi1): 9.231e-03, MSE(pi2): 1.781e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 44700, Train loss: 1.174e+03, Test loss: 4.508e+03, MSE(e): 2.948e-05, MSE(pi1): 9.737e-03, MSE(pi2): 1.760e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 44800, Train loss: 1.165e+03, Test loss: 4.483e+03, MSE(e): 2.919e-05, MSE(pi1): 9.093e-03, MSE(pi2): 1.742e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 44900, Train loss: 1.477e+03, Test loss: 5.784e+03, MSE(e): 6.084e-05, MSE(pi1): 8.835e-03, MSE(pi2): 3.218e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 45000, Train loss: 1.181e+03, Test loss: 4.478e+03, MSE(e): 3.020e-05, MSE(pi1): 9.740e-03, MSE(pi2): 1.788e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 45100, Train loss: 1.181e+03, Test loss: 4.491e+03, MSE(e): 2.979e-05, MSE(pi1): 1.006e-02, MSE(pi2): 1.769e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 45200, Train loss: 1.189e+03, Test loss: 4.639e+03, MSE(e): 3.036e-05, MSE(pi1): 1.037e-02, MSE(pi2): 1.784e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 45300, Train loss: 1.150e+03, Test loss: 4.588e+03, MSE(e): 2.878e-05, MSE(pi1): 8.126e-03, MSE(pi2): 1.730e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 45400, Train loss: 1.179e+03, Test loss: 4.547e+03, MSE(e): 3.123e-05, MSE(pi1): 8.491e-03, MSE(pi2): 1.824e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 45500, Train loss: 1.162e+03, Test loss: 4.505e+03, MSE(e): 2.891e-05, MSE(pi1): 9.106e-03, MSE(pi2): 1.721e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 45600, Train loss: 1.152e+03, Test loss: 4.489e+03, MSE(e): 2.895e-05, MSE(pi1): 8.081e-03, MSE(pi2): 1.731e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 45700, Train loss: 1.158e+03, Test loss: 4.502e+03, MSE(e): 2.884e-05, MSE(pi1): 8.857e-03, MSE(pi2): 1.729e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 45800, Train loss: 2.120e+03, Test loss: 6.720e+03, MSE(e): 1.244e-04, MSE(pi1): 9.029e-03, MSE(pi2): 5.815e-05, MSE(pi3): 7.857e-03\n",
      "Epoch 45900, Train loss: 1.267e+03, Test loss: 4.793e+03, MSE(e): 3.710e-05, MSE(pi1): 1.132e-02, MSE(pi2): 2.064e-05, MSE(pi3): 7.824e-03\n",
      "Epoch 46000, Train loss: 1.178e+03, Test loss: 4.523e+03, MSE(e): 2.977e-05, MSE(pi1): 9.826e-03, MSE(pi2): 1.762e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 46100, Train loss: 1.168e+03, Test loss: 4.641e+03, MSE(e): 3.096e-05, MSE(pi1): 7.746e-03, MSE(pi2): 1.835e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 46200, Train loss: 1.179e+03, Test loss: 4.467e+03, MSE(e): 3.161e-05, MSE(pi1): 8.235e-03, MSE(pi2): 1.866e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 46300, Train loss: 1.151e+03, Test loss: 4.510e+03, MSE(e): 2.870e-05, MSE(pi1): 8.218e-03, MSE(pi2): 1.704e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 46400, Train loss: 1.157e+03, Test loss: 4.603e+03, MSE(e): 2.853e-05, MSE(pi1): 8.965e-03, MSE(pi2): 1.700e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 46500, Train loss: 1.315e+03, Test loss: 5.393e+03, MSE(e): 4.513e-05, MSE(pi1): 8.338e-03, MSE(pi2): 2.486e-05, MSE(pi3): 7.799e-03\n",
      "Epoch 46600, Train loss: 1.325e+03, Test loss: 5.090e+03, MSE(e): 4.619e-05, MSE(pi1): 8.149e-03, MSE(pi2): 2.452e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 46700, Train loss: 1.204e+03, Test loss: 4.788e+03, MSE(e): 3.311e-05, MSE(pi1): 9.148e-03, MSE(pi2): 1.889e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 46800, Train loss: 1.423e+03, Test loss: 5.188e+03, MSE(e): 5.633e-05, MSE(pi1): 7.834e-03, MSE(pi2): 2.920e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 46900, Train loss: 1.336e+03, Test loss: 4.604e+03, MSE(e): 4.712e-05, MSE(pi1): 8.272e-03, MSE(pi2): 2.528e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 47000, Train loss: 1.313e+03, Test loss: 4.661e+03, MSE(e): 4.410e-05, MSE(pi1): 8.987e-03, MSE(pi2): 2.396e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 47100, Train loss: 1.714e+03, Test loss: 5.417e+03, MSE(e): 8.493e-05, MSE(pi1): 8.142e-03, MSE(pi2): 4.150e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 47200, Train loss: 1.186e+03, Test loss: 4.727e+03, MSE(e): 3.114e-05, MSE(pi1): 9.226e-03, MSE(pi2): 1.909e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 47300, Train loss: 1.375e+03, Test loss: 4.749e+03, MSE(e): 4.976e-05, MSE(pi1): 9.517e-03, MSE(pi2): 2.630e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 47400, Train loss: 1.281e+03, Test loss: 5.308e+03, MSE(e): 4.034e-05, MSE(pi1): 9.667e-03, MSE(pi2): 2.184e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 47500, Train loss: 1.129e+03, Test loss: 4.689e+03, MSE(e): 2.706e-05, MSE(pi1): 7.742e-03, MSE(pi2): 1.624e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 47600, Train loss: 1.133e+03, Test loss: 4.687e+03, MSE(e): 2.744e-05, MSE(pi1): 7.807e-03, MSE(pi2): 1.655e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 47700, Train loss: 1.463e+03, Test loss: 5.751e+03, MSE(e): 5.905e-05, MSE(pi1): 8.942e-03, MSE(pi2): 2.999e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 47800, Train loss: 1.144e+03, Test loss: 4.651e+03, MSE(e): 2.746e-05, MSE(pi1): 8.797e-03, MSE(pi2): 1.650e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 47900, Train loss: 1.131e+03, Test loss: 4.675e+03, MSE(e): 2.674e-05, MSE(pi1): 8.250e-03, MSE(pi2): 1.605e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 48000, Train loss: 1.159e+03, Test loss: 4.737e+03, MSE(e): 2.733e-05, MSE(pi1): 1.045e-02, MSE(pi2): 1.625e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 48100, Train loss: 1.146e+03, Test loss: 4.778e+03, MSE(e): 2.869e-05, MSE(pi1): 7.932e-03, MSE(pi2): 1.729e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 48200, Train loss: 1.148e+03, Test loss: 4.703e+03, MSE(e): 2.723e-05, MSE(pi1): 9.387e-03, MSE(pi2): 1.613e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 48300, Train loss: 1.193e+03, Test loss: 4.648e+03, MSE(e): 3.272e-05, MSE(pi1): 8.419e-03, MSE(pi2): 1.878e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 48400, Train loss: 1.129e+03, Test loss: 4.663e+03, MSE(e): 2.672e-05, MSE(pi1): 8.092e-03, MSE(pi2): 1.596e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 48500, Train loss: 1.421e+03, Test loss: 5.651e+03, MSE(e): 5.508e-05, MSE(pi1): 8.711e-03, MSE(pi2): 2.820e-05, MSE(pi3): 7.831e-03\n",
      "Epoch 48600, Train loss: 2.057e+03, Test loss: 5.119e+03, MSE(e): 1.171e-04, MSE(pi1): 1.041e-02, MSE(pi2): 5.693e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 48700, Train loss: 1.165e+03, Test loss: 4.660e+03, MSE(e): 2.924e-05, MSE(pi1): 9.072e-03, MSE(pi2): 1.717e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 48800, Train loss: 1.141e+03, Test loss: 4.670e+03, MSE(e): 2.736e-05, MSE(pi1): 8.636e-03, MSE(pi2): 1.636e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 48900, Train loss: 1.129e+03, Test loss: 4.656e+03, MSE(e): 2.698e-05, MSE(pi1): 7.821e-03, MSE(pi2): 1.605e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 49000, Train loss: 1.604e+03, Test loss: 5.576e+03, MSE(e): 7.370e-05, MSE(pi1): 8.300e-03, MSE(pi2): 3.628e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 49100, Train loss: 1.164e+03, Test loss: 4.612e+03, MSE(e): 2.998e-05, MSE(pi1): 8.286e-03, MSE(pi2): 1.749e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 49200, Train loss: 1.373e+03, Test loss: 5.590e+03, MSE(e): 5.010e-05, MSE(pi1): 9.075e-03, MSE(pi2): 2.591e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 49300, Train loss: 1.161e+03, Test loss: 4.725e+03, MSE(e): 2.777e-05, MSE(pi1): 1.018e-02, MSE(pi2): 1.633e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 49400, Train loss: 1.124e+03, Test loss: 4.675e+03, MSE(e): 2.620e-05, MSE(pi1): 8.086e-03, MSE(pi2): 1.573e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 49500, Train loss: 1.520e+03, Test loss: 5.131e+03, MSE(e): 6.451e-05, MSE(pi1): 9.151e-03, MSE(pi2): 3.218e-05, MSE(pi3): 7.829e-03\n",
      "Epoch 49600, Train loss: 1.140e+03, Test loss: 4.695e+03, MSE(e): 2.657e-05, MSE(pi1): 9.305e-03, MSE(pi2): 1.594e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 49700, Train loss: 1.154e+03, Test loss: 4.702e+03, MSE(e): 2.687e-05, MSE(pi1): 1.032e-02, MSE(pi2): 1.599e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 49800, Train loss: 1.141e+03, Test loss: 4.752e+03, MSE(e): 2.715e-05, MSE(pi1): 8.827e-03, MSE(pi2): 1.613e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 49900, Train loss: 1.139e+03, Test loss: 4.715e+03, MSE(e): 2.629e-05, MSE(pi1): 9.476e-03, MSE(pi2): 1.571e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 50000, Train loss: 1.123e+03, Test loss: 4.700e+03, MSE(e): 2.638e-05, MSE(pi1): 7.806e-03, MSE(pi2): 1.585e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 50100, Train loss: 1.231e+03, Test loss: 4.724e+03, MSE(e): 3.710e-05, MSE(pi1): 7.946e-03, MSE(pi2): 2.064e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 50200, Train loss: 1.151e+03, Test loss: 4.733e+03, MSE(e): 2.634e-05, MSE(pi1): 1.063e-02, MSE(pi2): 1.557e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 50300, Train loss: 1.123e+03, Test loss: 4.707e+03, MSE(e): 2.611e-05, MSE(pi1): 8.051e-03, MSE(pi2): 1.563e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 50400, Train loss: 1.125e+03, Test loss: 4.717e+03, MSE(e): 2.664e-05, MSE(pi1): 7.795e-03, MSE(pi2): 1.575e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 50500, Train loss: 1.179e+03, Test loss: 4.915e+03, MSE(e): 3.041e-05, MSE(pi1): 9.371e-03, MSE(pi2): 1.735e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 50600, Train loss: 1.116e+03, Test loss: 4.674e+03, MSE(e): 2.568e-05, MSE(pi1): 7.816e-03, MSE(pi2): 1.538e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 50700, Train loss: 1.124e+03, Test loss: 4.701e+03, MSE(e): 2.630e-05, MSE(pi1): 7.992e-03, MSE(pi2): 1.564e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 50800, Train loss: 1.130e+03, Test loss: 4.650e+03, MSE(e): 2.619e-05, MSE(pi1): 8.665e-03, MSE(pi2): 1.560e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 50900, Train loss: 1.122e+03, Test loss: 4.704e+03, MSE(e): 2.573e-05, MSE(pi1): 8.346e-03, MSE(pi2): 1.544e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 51000, Train loss: 1.806e+03, Test loss: 6.299e+03, MSE(e): 9.194e-05, MSE(pi1): 1.041e-02, MSE(pi2): 4.356e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 51100, Train loss: 2.040e+03, Test loss: 5.602e+03, MSE(e): 1.171e-04, MSE(pi1): 8.620e-03, MSE(pi2): 5.429e-05, MSE(pi3): 7.827e-03\n",
      "Epoch 51200, Train loss: 1.869e+03, Test loss: 5.116e+03, MSE(e): 9.988e-05, MSE(pi1): 8.584e-03, MSE(pi2): 4.710e-05, MSE(pi3): 7.843e-03\n",
      "Epoch 51300, Train loss: 1.158e+03, Test loss: 4.663e+03, MSE(e): 2.968e-05, MSE(pi1): 7.963e-03, MSE(pi2): 1.708e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 51400, Train loss: 1.126e+03, Test loss: 4.877e+03, MSE(e): 2.646e-05, MSE(pi1): 8.124e-03, MSE(pi2): 1.579e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 51500, Train loss: 1.116e+03, Test loss: 4.699e+03, MSE(e): 2.535e-05, MSE(pi1): 8.124e-03, MSE(pi2): 1.524e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 51600, Train loss: 1.116e+03, Test loss: 4.714e+03, MSE(e): 2.574e-05, MSE(pi1): 7.828e-03, MSE(pi2): 1.544e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 51700, Train loss: 1.120e+03, Test loss: 4.714e+03, MSE(e): 2.572e-05, MSE(pi1): 8.240e-03, MSE(pi2): 1.550e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 51800, Train loss: 1.127e+03, Test loss: 4.724e+03, MSE(e): 2.528e-05, MSE(pi1): 9.275e-03, MSE(pi2): 1.511e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 51900, Train loss: 1.121e+03, Test loss: 4.715e+03, MSE(e): 2.535e-05, MSE(pi1): 8.631e-03, MSE(pi2): 1.522e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 52000, Train loss: 1.133e+03, Test loss: 4.670e+03, MSE(e): 2.708e-05, MSE(pi1): 8.260e-03, MSE(pi2): 1.638e-05, MSE(pi3): 7.799e-03\n",
      "Epoch 52100, Train loss: 1.142e+03, Test loss: 4.724e+03, MSE(e): 2.792e-05, MSE(pi1): 8.157e-03, MSE(pi2): 1.626e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 52200, Train loss: 2.303e+03, Test loss: 4.793e+03, MSE(e): 1.423e-04, MSE(pi1): 9.576e-03, MSE(pi2): 6.702e-05, MSE(pi3): 7.847e-03\n",
      "Epoch 52300, Train loss: 1.345e+03, Test loss: 5.312e+03, MSE(e): 4.603e-05, MSE(pi1): 1.015e-02, MSE(pi2): 2.420e-05, MSE(pi3): 7.827e-03\n",
      "Epoch 52400, Train loss: 1.299e+03, Test loss: 4.800e+03, MSE(e): 4.366e-05, MSE(pi1): 8.124e-03, MSE(pi2): 2.361e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 52500, Train loss: 1.265e+03, Test loss: 4.817e+03, MSE(e): 4.018e-05, MSE(pi1): 8.229e-03, MSE(pi2): 2.199e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 52600, Train loss: 1.243e+03, Test loss: 4.849e+03, MSE(e): 3.740e-05, MSE(pi1): 8.752e-03, MSE(pi2): 2.246e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 52700, Train loss: 1.204e+03, Test loss: 4.703e+03, MSE(e): 3.421e-05, MSE(pi1): 8.086e-03, MSE(pi2): 2.001e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 52800, Train loss: 1.277e+03, Test loss: 5.336e+03, MSE(e): 4.163e-05, MSE(pi1): 8.093e-03, MSE(pi2): 2.357e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 52900, Train loss: 1.267e+03, Test loss: 4.860e+03, MSE(e): 4.050e-05, MSE(pi1): 8.142e-03, MSE(pi2): 2.295e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 53000, Train loss: 1.243e+03, Test loss: 4.886e+03, MSE(e): 3.737e-05, MSE(pi1): 8.908e-03, MSE(pi2): 2.155e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 53100, Train loss: 1.231e+03, Test loss: 4.904e+03, MSE(e): 3.646e-05, MSE(pi1): 8.540e-03, MSE(pi2): 2.113e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 53200, Train loss: 1.217e+03, Test loss: 5.009e+03, MSE(e): 3.456e-05, MSE(pi1): 9.072e-03, MSE(pi2): 2.032e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 53300, Train loss: 1.216e+03, Test loss: 5.107e+03, MSE(e): 3.457e-05, MSE(pi1): 8.956e-03, MSE(pi2): 2.036e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 53400, Train loss: 1.224e+03, Test loss: 5.173e+03, MSE(e): 3.554e-05, MSE(pi1): 8.797e-03, MSE(pi2): 2.058e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 53500, Train loss: 1.235e+03, Test loss: 5.145e+03, MSE(e): 3.660e-05, MSE(pi1): 8.835e-03, MSE(pi2): 2.092e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 53600, Train loss: 1.232e+03, Test loss: 5.046e+03, MSE(e): 3.694e-05, MSE(pi1): 8.143e-03, MSE(pi2): 2.100e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 53700, Train loss: 1.212e+03, Test loss: 4.916e+03, MSE(e): 3.456e-05, MSE(pi1): 8.482e-03, MSE(pi2): 1.995e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 53800, Train loss: 1.178e+03, Test loss: 4.851e+03, MSE(e): 3.146e-05, MSE(pi1): 8.196e-03, MSE(pi2): 1.856e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 53900, Train loss: 1.213e+03, Test loss: 4.910e+03, MSE(e): 3.345e-05, MSE(pi1): 9.615e-03, MSE(pi2): 1.953e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 54000, Train loss: 1.280e+03, Test loss: 4.936e+03, MSE(e): 4.022e-05, MSE(pi1): 9.514e-03, MSE(pi2): 2.244e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 54100, Train loss: 1.301e+03, Test loss: 4.864e+03, MSE(e): 4.395e-05, MSE(pi1): 7.975e-03, MSE(pi2): 2.419e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 54200, Train loss: 1.276e+03, Test loss: 4.886e+03, MSE(e): 4.047e-05, MSE(pi1): 8.980e-03, MSE(pi2): 2.272e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 54300, Train loss: 1.204e+03, Test loss: 5.121e+03, MSE(e): 3.283e-05, MSE(pi1): 9.513e-03, MSE(pi2): 1.926e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 54400, Train loss: 1.212e+03, Test loss: 5.249e+03, MSE(e): 3.431e-05, MSE(pi1): 8.832e-03, MSE(pi2): 1.995e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 54500, Train loss: 1.252e+03, Test loss: 5.208e+03, MSE(e): 3.818e-05, MSE(pi1): 8.945e-03, MSE(pi2): 2.141e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 54600, Train loss: 1.249e+03, Test loss: 5.114e+03, MSE(e): 3.825e-05, MSE(pi1): 8.546e-03, MSE(pi2): 2.135e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 54700, Train loss: 1.185e+03, Test loss: 4.938e+03, MSE(e): 3.182e-05, MSE(pi1): 8.474e-03, MSE(pi2): 1.867e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 54800, Train loss: 1.197e+03, Test loss: 4.978e+03, MSE(e): 3.142e-05, MSE(pi1): 9.987e-03, MSE(pi2): 1.837e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 54900, Train loss: 1.238e+03, Test loss: 4.981e+03, MSE(e): 3.740e-05, MSE(pi1): 8.210e-03, MSE(pi2): 2.117e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 55000, Train loss: 1.313e+03, Test loss: 4.988e+03, MSE(e): 4.493e-05, MSE(pi1): 8.215e-03, MSE(pi2): 2.449e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 55100, Train loss: 1.283e+03, Test loss: 4.934e+03, MSE(e): 4.167e-05, MSE(pi1): 8.468e-03, MSE(pi2): 2.319e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 55200, Train loss: 1.192e+03, Test loss: 5.093e+03, MSE(e): 3.326e-05, MSE(pi1): 7.909e-03, MSE(pi2): 1.955e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 55300, Train loss: 1.200e+03, Test loss: 5.314e+03, MSE(e): 3.346e-05, MSE(pi1): 8.549e-03, MSE(pi2): 1.948e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 55400, Train loss: 1.237e+03, Test loss: 5.298e+03, MSE(e): 3.742e-05, MSE(pi1): 8.172e-03, MSE(pi2): 2.099e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 55500, Train loss: 1.244e+03, Test loss: 5.140e+03, MSE(e): 3.723e-05, MSE(pi1): 9.007e-03, MSE(pi2): 2.074e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 55600, Train loss: 1.183e+03, Test loss: 5.000e+03, MSE(e): 3.092e-05, MSE(pi1): 9.164e-03, MSE(pi2): 1.820e-05, MSE(pi3): 7.822e-03\n",
      "Epoch 55700, Train loss: 1.178e+03, Test loss: 5.012e+03, MSE(e): 3.144e-05, MSE(pi1): 8.152e-03, MSE(pi2): 1.847e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 55800, Train loss: 1.262e+03, Test loss: 5.050e+03, MSE(e): 3.885e-05, MSE(pi1): 9.130e-03, MSE(pi2): 2.179e-05, MSE(pi3): 7.823e-03\n",
      "Epoch 55900, Train loss: 1.316e+03, Test loss: 5.008e+03, MSE(e): 4.458e-05, MSE(pi1): 8.835e-03, MSE(pi2): 2.432e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 56000, Train loss: 1.270e+03, Test loss: 5.019e+03, MSE(e): 3.986e-05, MSE(pi1): 9.036e-03, MSE(pi2): 2.232e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 56100, Train loss: 1.191e+03, Test loss: 5.282e+03, MSE(e): 3.228e-05, MSE(pi1): 8.781e-03, MSE(pi2): 1.904e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 56200, Train loss: 1.232e+03, Test loss: 5.459e+03, MSE(e): 3.664e-05, MSE(pi1): 8.464e-03, MSE(pi2): 2.066e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 56300, Train loss: 1.267e+03, Test loss: 5.309e+03, MSE(e): 4.008e-05, MSE(pi1): 8.523e-03, MSE(pi2): 2.196e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 56400, Train loss: 1.199e+03, Test loss: 5.097e+03, MSE(e): 3.282e-05, MSE(pi1): 8.880e-03, MSE(pi2): 1.882e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 56500, Train loss: 1.173e+03, Test loss: 5.066e+03, MSE(e): 2.966e-05, MSE(pi1): 9.476e-03, MSE(pi2): 1.748e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 56600, Train loss: 1.219e+03, Test loss: 5.055e+03, MSE(e): 3.580e-05, MSE(pi1): 7.965e-03, MSE(pi2): 2.037e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 56700, Train loss: 1.260e+03, Test loss: 5.044e+03, MSE(e): 3.968e-05, MSE(pi1): 8.194e-03, MSE(pi2): 2.215e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 56800, Train loss: 1.257e+03, Test loss: 5.149e+03, MSE(e): 3.947e-05, MSE(pi1): 7.986e-03, MSE(pi2): 2.180e-05, MSE(pi3): 7.822e-03\n",
      "Epoch 56900, Train loss: 1.316e+03, Test loss: 5.301e+03, MSE(e): 4.281e-05, MSE(pi1): 1.051e-02, MSE(pi2): 2.279e-05, MSE(pi3): 7.830e-03\n",
      "Epoch 57000, Train loss: 1.094e+03, Test loss: 5.083e+03, MSE(e): 2.336e-05, MSE(pi1): 7.925e-03, MSE(pi2): 1.418e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 57100, Train loss: 1.097e+03, Test loss: 5.129e+03, MSE(e): 2.389e-05, MSE(pi1): 7.743e-03, MSE(pi2): 1.444e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 57200, Train loss: 1.568e+03, Test loss: 5.218e+03, MSE(e): 6.703e-05, MSE(pi1): 1.149e-02, MSE(pi2): 3.332e-05, MSE(pi3): 7.829e-03\n",
      "Epoch 57300, Train loss: 1.101e+03, Test loss: 5.144e+03, MSE(e): 2.334e-05, MSE(pi1): 8.661e-03, MSE(pi2): 1.401e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 57400, Train loss: 1.131e+03, Test loss: 5.087e+03, MSE(e): 2.729e-05, MSE(pi1): 7.801e-03, MSE(pi2): 1.569e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 57500, Train loss: 1.114e+03, Test loss: 5.159e+03, MSE(e): 2.426e-05, MSE(pi1): 9.042e-03, MSE(pi2): 1.450e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 57600, Train loss: 1.091e+03, Test loss: 5.106e+03, MSE(e): 2.316e-05, MSE(pi1): 7.874e-03, MSE(pi2): 1.394e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 57700, Train loss: 1.648e+03, Test loss: 5.353e+03, MSE(e): 7.776e-05, MSE(pi1): 8.772e-03, MSE(pi2): 3.760e-05, MSE(pi3): 7.824e-03\n",
      "Epoch 57800, Train loss: 1.700e+03, Test loss: 5.395e+03, MSE(e): 8.217e-05, MSE(pi1): 9.665e-03, MSE(pi2): 4.015e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 57900, Train loss: 1.812e+03, Test loss: 6.204e+03, MSE(e): 9.481e-05, MSE(pi1): 8.406e-03, MSE(pi2): 4.658e-05, MSE(pi3): 7.797e-03\n",
      "Epoch 58000, Train loss: 1.086e+03, Test loss: 5.083e+03, MSE(e): 2.260e-05, MSE(pi1): 7.946e-03, MSE(pi2): 1.375e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 58100, Train loss: 1.096e+03, Test loss: 5.136e+03, MSE(e): 2.349e-05, MSE(pi1): 8.095e-03, MSE(pi2): 1.417e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 58200, Train loss: 1.402e+03, Test loss: 5.200e+03, MSE(e): 5.304e-05, MSE(pi1): 8.799e-03, MSE(pi2): 2.692e-05, MSE(pi3): 7.832e-03\n",
      "Epoch 58300, Train loss: 1.145e+03, Test loss: 5.089e+03, MSE(e): 2.809e-05, MSE(pi1): 8.222e-03, MSE(pi2): 1.638e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 58400, Train loss: 1.110e+03, Test loss: 5.069e+03, MSE(e): 2.360e-05, MSE(pi1): 9.233e-03, MSE(pi2): 1.420e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 58500, Train loss: 1.086e+03, Test loss: 5.107e+03, MSE(e): 2.244e-05, MSE(pi1): 8.117e-03, MSE(pi2): 1.361e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 58600, Train loss: 1.852e+03, Test loss: 6.431e+03, MSE(e): 9.839e-05, MSE(pi1): 8.777e-03, MSE(pi2): 4.820e-05, MSE(pi3): 7.798e-03\n",
      "Epoch 58700, Train loss: 1.092e+03, Test loss: 5.124e+03, MSE(e): 2.322e-05, MSE(pi1): 7.834e-03, MSE(pi2): 1.389e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 58800, Train loss: 1.218e+03, Test loss: 5.189e+03, MSE(e): 3.551e-05, MSE(pi1): 8.143e-03, MSE(pi2): 1.968e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 58900, Train loss: 1.262e+03, Test loss: 5.223e+03, MSE(e): 3.967e-05, MSE(pi1): 8.384e-03, MSE(pi2): 2.136e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 59000, Train loss: 1.081e+03, Test loss: 5.199e+03, MSE(e): 2.183e-05, MSE(pi1): 8.189e-03, MSE(pi2): 1.340e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 59100, Train loss: 1.164e+03, Test loss: 5.495e+03, MSE(e): 3.026e-05, MSE(pi1): 8.067e-03, MSE(pi2): 1.684e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 59200, Train loss: 1.088e+03, Test loss: 5.233e+03, MSE(e): 2.159e-05, MSE(pi1): 9.088e-03, MSE(pi2): 1.315e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 59300, Train loss: 1.083e+03, Test loss: 5.221e+03, MSE(e): 2.161e-05, MSE(pi1): 8.604e-03, MSE(pi2): 1.317e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 59400, Train loss: 1.512e+03, Test loss: 6.501e+03, MSE(e): 6.461e-05, MSE(pi1): 8.232e-03, MSE(pi2): 3.142e-05, MSE(pi3): 7.838e-03\n",
      "Epoch 59500, Train loss: 1.095e+03, Test loss: 5.168e+03, MSE(e): 2.254e-05, MSE(pi1): 8.831e-03, MSE(pi2): 1.354e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 59600, Train loss: 1.569e+03, Test loss: 5.301e+03, MSE(e): 6.919e-05, MSE(pi1): 9.634e-03, MSE(pi2): 3.413e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 59700, Train loss: 1.075e+03, Test loss: 5.199e+03, MSE(e): 2.160e-05, MSE(pi1): 7.839e-03, MSE(pi2): 1.317e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 59800, Train loss: 1.085e+03, Test loss: 5.206e+03, MSE(e): 2.172e-05, MSE(pi1): 8.642e-03, MSE(pi2): 1.323e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 59900, Train loss: 1.075e+03, Test loss: 5.171e+03, MSE(e): 2.161e-05, MSE(pi1): 7.796e-03, MSE(pi2): 1.324e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 60000, Train loss: 2.148e+03, Test loss: 5.739e+03, MSE(e): 1.274e-04, MSE(pi1): 8.572e-03, MSE(pi2): 6.001e-05, MSE(pi3): 7.875e-03\n",
      "Epoch 60100, Train loss: 1.131e+03, Test loss: 5.277e+03, MSE(e): 2.414e-05, MSE(pi1): 1.090e-02, MSE(pi2): 1.446e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 60200, Train loss: 1.348e+03, Test loss: 5.295e+03, MSE(e): 4.869e-05, MSE(pi1): 8.089e-03, MSE(pi2): 2.586e-05, MSE(pi3): 7.797e-03\n",
      "Epoch 60300, Train loss: 1.083e+03, Test loss: 5.179e+03, MSE(e): 2.174e-05, MSE(pi1): 8.507e-03, MSE(pi2): 1.319e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 60400, Train loss: 1.082e+03, Test loss: 5.211e+03, MSE(e): 2.239e-05, MSE(pi1): 7.834e-03, MSE(pi2): 1.343e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 60500, Train loss: 1.075e+03, Test loss: 5.217e+03, MSE(e): 2.152e-05, MSE(pi1): 7.960e-03, MSE(pi2): 1.309e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 60600, Train loss: 1.233e+03, Test loss: 5.511e+03, MSE(e): 3.602e-05, MSE(pi1): 9.004e-03, MSE(pi2): 2.017e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 60700, Train loss: 1.107e+03, Test loss: 5.151e+03, MSE(e): 2.341e-05, MSE(pi1): 9.182e-03, MSE(pi2): 1.401e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 60800, Train loss: 1.093e+03, Test loss: 5.212e+03, MSE(e): 2.186e-05, MSE(pi1): 9.333e-03, MSE(pi2): 1.313e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 60900, Train loss: 1.081e+03, Test loss: 5.184e+03, MSE(e): 2.173e-05, MSE(pi1): 8.265e-03, MSE(pi2): 1.316e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 61000, Train loss: 1.092e+03, Test loss: 5.218e+03, MSE(e): 2.185e-05, MSE(pi1): 9.324e-03, MSE(pi2): 1.315e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 61100, Train loss: 1.101e+03, Test loss: 5.166e+03, MSE(e): 2.328e-05, MSE(pi1): 8.761e-03, MSE(pi2): 1.398e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 61200, Train loss: 1.072e+03, Test loss: 5.196e+03, MSE(e): 2.125e-05, MSE(pi1): 7.918e-03, MSE(pi2): 1.304e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 61300, Train loss: 1.130e+03, Test loss: 5.285e+03, MSE(e): 2.186e-05, MSE(pi1): 1.307e-02, MSE(pi2): 1.319e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 61400, Train loss: 1.087e+03, Test loss: 5.236e+03, MSE(e): 2.154e-05, MSE(pi1): 9.090e-03, MSE(pi2): 1.298e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 61500, Train loss: 1.091e+03, Test loss: 5.306e+03, MSE(e): 2.345e-05, MSE(pi1): 7.687e-03, MSE(pi2): 1.394e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 61600, Train loss: 1.080e+03, Test loss: 5.227e+03, MSE(e): 2.215e-05, MSE(pi1): 7.739e-03, MSE(pi2): 1.334e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 61700, Train loss: 1.088e+03, Test loss: 5.228e+03, MSE(e): 2.157e-05, MSE(pi1): 9.150e-03, MSE(pi2): 1.293e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 61800, Train loss: 1.130e+03, Test loss: 5.130e+03, MSE(e): 2.656e-05, MSE(pi1): 8.387e-03, MSE(pi2): 1.542e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 61900, Train loss: 1.179e+03, Test loss: 5.357e+03, MSE(e): 3.182e-05, MSE(pi1): 7.957e-03, MSE(pi2): 1.752e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 62000, Train loss: 1.077e+03, Test loss: 5.291e+03, MSE(e): 2.193e-05, MSE(pi1): 7.683e-03, MSE(pi2): 1.319e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 62100, Train loss: 2.295e+03, Test loss: 6.053e+03, MSE(e): 1.420e-04, MSE(pi1): 9.278e-03, MSE(pi2): 6.536e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 62200, Train loss: 1.074e+03, Test loss: 5.336e+03, MSE(e): 2.160e-05, MSE(pi1): 7.812e-03, MSE(pi2): 1.309e-05, MSE(pi3): 7.799e-03\n",
      "Epoch 62300, Train loss: 1.950e+03, Test loss: 6.365e+03, MSE(e): 1.062e-04, MSE(pi1): 1.040e-02, MSE(pi2): 4.947e-05, MSE(pi3): 7.841e-03\n",
      "Epoch 62400, Train loss: 1.380e+03, Test loss: 5.317e+03, MSE(e): 5.208e-05, MSE(pi1): 8.286e-03, MSE(pi2): 2.811e-05, MSE(pi3): 7.764e-03\n",
      "Epoch 62500, Train loss: 1.265e+03, Test loss: 5.350e+03, MSE(e): 4.027e-05, MSE(pi1): 8.085e-03, MSE(pi2): 2.174e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 62600, Train loss: 1.235e+03, Test loss: 5.358e+03, MSE(e): 3.645e-05, MSE(pi1): 8.978e-03, MSE(pi2): 2.001e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 62700, Train loss: 1.060e+03, Test loss: 5.245e+03, MSE(e): 2.007e-05, MSE(pi1): 7.861e-03, MSE(pi2): 1.235e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 62800, Train loss: 1.100e+03, Test loss: 5.372e+03, MSE(e): 2.062e-05, MSE(pi1): 1.129e-02, MSE(pi2): 1.253e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 62900, Train loss: 1.117e+03, Test loss: 5.257e+03, MSE(e): 2.547e-05, MSE(pi1): 8.172e-03, MSE(pi2): 1.489e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 63000, Train loss: 1.065e+03, Test loss: 5.285e+03, MSE(e): 2.040e-05, MSE(pi1): 8.035e-03, MSE(pi2): 1.252e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 63100, Train loss: 1.070e+03, Test loss: 5.244e+03, MSE(e): 2.098e-05, MSE(pi1): 8.015e-03, MSE(pi2): 1.288e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 63200, Train loss: 1.158e+03, Test loss: 5.276e+03, MSE(e): 2.975e-05, MSE(pi1): 8.070e-03, MSE(pi2): 1.696e-05, MSE(pi3): 7.799e-03\n",
      "Epoch 63300, Train loss: 1.102e+03, Test loss: 5.466e+03, MSE(e): 2.334e-05, MSE(pi1): 8.822e-03, MSE(pi2): 1.368e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 63400, Train loss: 1.081e+03, Test loss: 5.366e+03, MSE(e): 2.220e-05, MSE(pi1): 7.871e-03, MSE(pi2): 1.325e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 63500, Train loss: 1.069e+03, Test loss: 5.290e+03, MSE(e): 2.099e-05, MSE(pi1): 7.815e-03, MSE(pi2): 1.271e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 63600, Train loss: 1.062e+03, Test loss: 5.296e+03, MSE(e): 2.032e-05, MSE(pi1): 7.794e-03, MSE(pi2): 1.253e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 63700, Train loss: 1.093e+03, Test loss: 5.442e+03, MSE(e): 2.351e-05, MSE(pi1): 7.746e-03, MSE(pi2): 1.380e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 63800, Train loss: 1.063e+03, Test loss: 5.265e+03, MSE(e): 2.052e-05, MSE(pi1): 7.737e-03, MSE(pi2): 1.258e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 63900, Train loss: 1.069e+03, Test loss: 5.258e+03, MSE(e): 2.097e-05, MSE(pi1): 7.863e-03, MSE(pi2): 1.286e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 64000, Train loss: 1.110e+03, Test loss: 5.162e+03, MSE(e): 2.510e-05, MSE(pi1): 7.739e-03, MSE(pi2): 1.444e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 64100, Train loss: 1.065e+03, Test loss: 5.290e+03, MSE(e): 2.069e-05, MSE(pi1): 7.778e-03, MSE(pi2): 1.257e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 64200, Train loss: 1.357e+03, Test loss: 5.282e+03, MSE(e): 4.936e-05, MSE(pi1): 8.288e-03, MSE(pi2): 2.548e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 64300, Train loss: 1.107e+03, Test loss: 5.512e+03, MSE(e): 2.455e-05, MSE(pi1): 8.114e-03, MSE(pi2): 1.415e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 64400, Train loss: 1.106e+03, Test loss: 5.283e+03, MSE(e): 2.199e-05, MSE(pi1): 1.054e-02, MSE(pi2): 1.302e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 64500, Train loss: 1.063e+03, Test loss: 5.275e+03, MSE(e): 2.013e-05, MSE(pi1): 8.089e-03, MSE(pi2): 1.240e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 64600, Train loss: 1.070e+03, Test loss: 5.300e+03, MSE(e): 2.120e-05, MSE(pi1): 7.713e-03, MSE(pi2): 1.280e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 64700, Train loss: 2.132e+03, Test loss: 5.570e+03, MSE(e): 1.265e-04, MSE(pi1): 8.510e-03, MSE(pi2): 5.834e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 64800, Train loss: 1.209e+03, Test loss: 5.654e+03, MSE(e): 3.460e-05, MSE(pi1): 8.164e-03, MSE(pi2): 1.857e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 64900, Train loss: 1.065e+03, Test loss: 5.327e+03, MSE(e): 2.030e-05, MSE(pi1): 8.190e-03, MSE(pi2): 1.238e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 65000, Train loss: 1.093e+03, Test loss: 5.374e+03, MSE(e): 2.042e-05, MSE(pi1): 1.077e-02, MSE(pi2): 1.228e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 65100, Train loss: 1.731e+03, Test loss: 5.722e+03, MSE(e): 8.623e-05, MSE(pi1): 8.371e-03, MSE(pi2): 4.178e-05, MSE(pi3): 7.850e-03\n",
      "Epoch 65200, Train loss: 1.066e+03, Test loss: 5.316e+03, MSE(e): 2.060e-05, MSE(pi1): 7.912e-03, MSE(pi2): 1.249e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 65300, Train loss: 1.257e+03, Test loss: 5.484e+03, MSE(e): 3.896e-05, MSE(pi1): 8.445e-03, MSE(pi2): 2.170e-05, MSE(pi3): 7.834e-03\n",
      "Epoch 65400, Train loss: 1.469e+03, Test loss: 5.779e+03, MSE(e): 6.052e-05, MSE(pi1): 7.973e-03, MSE(pi2): 3.162e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 65500, Train loss: 1.307e+03, Test loss: 5.366e+03, MSE(e): 4.495e-05, MSE(pi1): 7.855e-03, MSE(pi2): 2.471e-05, MSE(pi3): 7.791e-03\n",
      "Epoch 65600, Train loss: 1.085e+03, Test loss: 5.302e+03, MSE(e): 2.063e-05, MSE(pi1): 9.724e-03, MSE(pi2): 1.253e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 65700, Train loss: 1.063e+03, Test loss: 5.345e+03, MSE(e): 2.010e-05, MSE(pi1): 8.120e-03, MSE(pi2): 1.227e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 65800, Train loss: 1.060e+03, Test loss: 5.358e+03, MSE(e): 2.011e-05, MSE(pi1): 7.856e-03, MSE(pi2): 1.223e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 65900, Train loss: 1.082e+03, Test loss: 5.350e+03, MSE(e): 2.017e-05, MSE(pi1): 9.938e-03, MSE(pi2): 1.225e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 66000, Train loss: 1.301e+03, Test loss: 6.374e+03, MSE(e): 4.196e-05, MSE(pi1): 1.008e-02, MSE(pi2): 2.145e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 66100, Train loss: 1.066e+03, Test loss: 5.330e+03, MSE(e): 2.014e-05, MSE(pi1): 8.402e-03, MSE(pi2): 1.236e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 66200, Train loss: 1.191e+03, Test loss: 5.427e+03, MSE(e): 3.215e-05, MSE(pi1): 8.869e-03, MSE(pi2): 1.813e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 66300, Train loss: 1.256e+03, Test loss: 5.467e+03, MSE(e): 3.944e-05, MSE(pi1): 8.060e-03, MSE(pi2): 2.119e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 66400, Train loss: 1.101e+03, Test loss: 5.445e+03, MSE(e): 2.354e-05, MSE(pi1): 8.490e-03, MSE(pi2): 1.451e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 66500, Train loss: 1.055e+03, Test loss: 5.378e+03, MSE(e): 1.918e-05, MSE(pi1): 8.222e-03, MSE(pi2): 1.192e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 66600, Train loss: 1.052e+03, Test loss: 5.395e+03, MSE(e): 1.906e-05, MSE(pi1): 8.068e-03, MSE(pi2): 1.188e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 66700, Train loss: 1.063e+03, Test loss: 5.441e+03, MSE(e): 1.949e-05, MSE(pi1): 8.748e-03, MSE(pi2): 1.192e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 66800, Train loss: 1.090e+03, Test loss: 5.466e+03, MSE(e): 2.276e-05, MSE(pi1): 8.259e-03, MSE(pi2): 1.353e-05, MSE(pi3): 7.798e-03\n",
      "Epoch 66900, Train loss: 1.078e+03, Test loss: 5.575e+03, MSE(e): 2.096e-05, MSE(pi1): 8.837e-03, MSE(pi2): 1.273e-05, MSE(pi3): 7.799e-03\n",
      "Epoch 67000, Train loss: 1.228e+03, Test loss: 5.606e+03, MSE(e): 3.608e-05, MSE(pi1): 8.453e-03, MSE(pi2): 1.963e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 67100, Train loss: 1.068e+03, Test loss: 5.454e+03, MSE(e): 1.969e-05, MSE(pi1): 9.043e-03, MSE(pi2): 1.199e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 67200, Train loss: 1.057e+03, Test loss: 5.384e+03, MSE(e): 1.950e-05, MSE(pi1): 8.175e-03, MSE(pi2): 1.204e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 67300, Train loss: 1.053e+03, Test loss: 5.421e+03, MSE(e): 1.945e-05, MSE(pi1): 7.819e-03, MSE(pi2): 1.193e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 67400, Train loss: 1.056e+03, Test loss: 5.424e+03, MSE(e): 1.969e-05, MSE(pi1): 7.915e-03, MSE(pi2): 1.205e-05, MSE(pi3): 7.798e-03\n",
      "Epoch 67500, Train loss: 1.353e+03, Test loss: 6.257e+03, MSE(e): 4.927e-05, MSE(pi1): 7.860e-03, MSE(pi2): 2.480e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 67600, Train loss: 1.065e+03, Test loss: 5.425e+03, MSE(e): 1.956e-05, MSE(pi1): 8.916e-03, MSE(pi2): 1.192e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 67700, Train loss: 1.061e+03, Test loss: 5.435e+03, MSE(e): 1.968e-05, MSE(pi1): 8.417e-03, MSE(pi2): 1.201e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 67800, Train loss: 1.078e+03, Test loss: 5.455e+03, MSE(e): 1.953e-05, MSE(pi1): 1.016e-02, MSE(pi2): 1.194e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 67900, Train loss: 1.124e+03, Test loss: 5.509e+03, MSE(e): 2.605e-05, MSE(pi1): 8.275e-03, MSE(pi2): 1.482e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 68000, Train loss: 1.063e+03, Test loss: 5.366e+03, MSE(e): 2.031e-05, MSE(pi1): 7.913e-03, MSE(pi2): 1.232e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 68100, Train loss: 1.095e+03, Test loss: 5.349e+03, MSE(e): 2.312e-05, MSE(pi1): 8.344e-03, MSE(pi2): 1.340e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 68200, Train loss: 1.553e+03, Test loss: 7.133e+03, MSE(e): 6.798e-05, MSE(pi1): 9.241e-03, MSE(pi2): 3.269e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 68300, Train loss: 1.309e+03, Test loss: 5.613e+03, MSE(e): 4.387e-05, MSE(pi1): 8.913e-03, MSE(pi2): 2.272e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 68400, Train loss: 1.064e+03, Test loss: 5.436e+03, MSE(e): 1.917e-05, MSE(pi1): 9.203e-03, MSE(pi2): 1.174e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 68500, Train loss: 1.634e+03, Test loss: 7.409e+03, MSE(e): 7.649e-05, MSE(pi1): 8.826e-03, MSE(pi2): 3.631e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 68600, Train loss: 1.410e+03, Test loss: 5.636e+03, MSE(e): 5.343e-05, MSE(pi1): 9.356e-03, MSE(pi2): 2.693e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 68700, Train loss: 1.517e+03, Test loss: 6.569e+03, MSE(e): 6.470e-05, MSE(pi1): 8.860e-03, MSE(pi2): 3.118e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 68800, Train loss: 1.275e+03, Test loss: 6.367e+03, MSE(e): 3.974e-05, MSE(pi1): 9.744e-03, MSE(pi2): 2.049e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 68900, Train loss: 1.110e+03, Test loss: 5.620e+03, MSE(e): 2.185e-05, MSE(pi1): 1.108e-02, MSE(pi2): 1.273e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 69000, Train loss: 1.077e+03, Test loss: 5.414e+03, MSE(e): 1.986e-05, MSE(pi1): 9.741e-03, MSE(pi2): 1.215e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 69100, Train loss: 1.071e+03, Test loss: 5.398e+03, MSE(e): 1.948e-05, MSE(pi1): 9.554e-03, MSE(pi2): 1.185e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 69200, Train loss: 1.079e+03, Test loss: 5.401e+03, MSE(e): 2.083e-05, MSE(pi1): 8.982e-03, MSE(pi2): 1.249e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 69300, Train loss: 1.280e+03, Test loss: 6.664e+03, MSE(e): 4.063e-05, MSE(pi1): 9.391e-03, MSE(pi2): 2.103e-05, MSE(pi3): 7.798e-03\n",
      "Epoch 69400, Train loss: 1.061e+03, Test loss: 5.446e+03, MSE(e): 1.931e-05, MSE(pi1): 8.743e-03, MSE(pi2): 1.173e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 69500, Train loss: 1.340e+03, Test loss: 5.740e+03, MSE(e): 4.772e-05, MSE(pi1): 8.397e-03, MSE(pi2): 2.532e-05, MSE(pi3): 7.789e-03\n",
      "Epoch 69600, Train loss: 1.056e+03, Test loss: 5.434e+03, MSE(e): 1.982e-05, MSE(pi1): 7.745e-03, MSE(pi2): 1.204e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 69700, Train loss: 1.049e+03, Test loss: 5.430e+03, MSE(e): 1.895e-05, MSE(pi1): 7.936e-03, MSE(pi2): 1.156e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 69800, Train loss: 1.050e+03, Test loss: 5.401e+03, MSE(e): 1.890e-05, MSE(pi1): 8.034e-03, MSE(pi2): 1.164e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 69900, Train loss: 1.058e+03, Test loss: 5.466e+03, MSE(e): 1.888e-05, MSE(pi1): 8.901e-03, MSE(pi2): 1.150e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 70000, Train loss: 1.051e+03, Test loss: 5.423e+03, MSE(e): 1.927e-05, MSE(pi1): 7.748e-03, MSE(pi2): 1.175e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 70100, Train loss: 1.100e+03, Test loss: 5.408e+03, MSE(e): 2.393e-05, MSE(pi1): 7.940e-03, MSE(pi2): 1.406e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 70200, Train loss: 1.076e+03, Test loss: 5.505e+03, MSE(e): 1.911e-05, MSE(pi1): 1.043e-02, MSE(pi2): 1.158e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 70300, Train loss: 1.103e+03, Test loss: 5.482e+03, MSE(e): 2.431e-05, MSE(pi1): 7.983e-03, MSE(pi2): 1.440e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 70400, Train loss: 1.055e+03, Test loss: 5.471e+03, MSE(e): 1.879e-05, MSE(pi1): 8.718e-03, MSE(pi2): 1.152e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 70500, Train loss: 1.156e+03, Test loss: 5.655e+03, MSE(e): 2.822e-05, MSE(pi1): 9.244e-03, MSE(pi2): 1.547e-05, MSE(pi3): 7.812e-03\n",
      "Epoch 70600, Train loss: 1.249e+03, Test loss: 6.402e+03, MSE(e): 3.598e-05, MSE(pi1): 1.088e-02, MSE(pi2): 1.878e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 70700, Train loss: 1.084e+03, Test loss: 5.541e+03, MSE(e): 1.930e-05, MSE(pi1): 1.099e-02, MSE(pi2): 1.177e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 70800, Train loss: 1.074e+03, Test loss: 5.483e+03, MSE(e): 1.884e-05, MSE(pi1): 1.050e-02, MSE(pi2): 1.156e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 70900, Train loss: 1.310e+03, Test loss: 6.146e+03, MSE(e): 4.233e-05, MSE(pi1): 1.040e-02, MSE(pi2): 2.144e-05, MSE(pi3): 7.822e-03\n",
      "Epoch 71000, Train loss: 1.077e+03, Test loss: 5.443e+03, MSE(e): 1.998e-05, MSE(pi1): 9.703e-03, MSE(pi2): 1.215e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 71100, Train loss: 1.050e+03, Test loss: 5.463e+03, MSE(e): 1.849e-05, MSE(pi1): 8.433e-03, MSE(pi2): 1.136e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 71200, Train loss: 1.181e+03, Test loss: 5.740e+03, MSE(e): 3.151e-05, MSE(pi1): 8.500e-03, MSE(pi2): 1.692e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 71300, Train loss: 1.062e+03, Test loss: 5.413e+03, MSE(e): 1.998e-05, MSE(pi1): 8.215e-03, MSE(pi2): 1.216e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 71400, Train loss: 1.063e+03, Test loss: 5.438e+03, MSE(e): 1.950e-05, MSE(pi1): 8.735e-03, MSE(pi2): 1.194e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 71500, Train loss: 1.140e+03, Test loss: 5.550e+03, MSE(e): 2.339e-05, MSE(pi1): 1.249e-02, MSE(pi2): 1.329e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 71600, Train loss: 1.108e+03, Test loss: 5.353e+03, MSE(e): 2.468e-05, MSE(pi1): 7.965e-03, MSE(pi2): 1.426e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 71700, Train loss: 1.068e+03, Test loss: 5.380e+03, MSE(e): 2.080e-05, MSE(pi1): 7.946e-03, MSE(pi2): 1.254e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 71800, Train loss: 1.222e+03, Test loss: 6.070e+03, MSE(e): 3.557e-05, MSE(pi1): 8.719e-03, MSE(pi2): 1.956e-05, MSE(pi3): 7.791e-03\n",
      "Epoch 71900, Train loss: 1.904e+03, Test loss: 5.751e+03, MSE(e): 1.034e-04, MSE(pi1): 8.850e-03, MSE(pi2): 4.863e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 72000, Train loss: 1.051e+03, Test loss: 5.457e+03, MSE(e): 1.837e-05, MSE(pi1): 8.726e-03, MSE(pi2): 1.127e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 72100, Train loss: 1.050e+03, Test loss: 5.411e+03, MSE(e): 1.836e-05, MSE(pi1): 8.555e-03, MSE(pi2): 1.129e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 72200, Train loss: 1.502e+03, Test loss: 5.605e+03, MSE(e): 6.228e-05, MSE(pi1): 9.670e-03, MSE(pi2): 2.965e-05, MSE(pi3): 7.823e-03\n",
      "Epoch 72300, Train loss: 1.051e+03, Test loss: 5.436e+03, MSE(e): 1.835e-05, MSE(pi1): 8.753e-03, MSE(pi2): 1.138e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 72400, Train loss: 1.094e+03, Test loss: 5.723e+03, MSE(e): 2.214e-05, MSE(pi1): 9.206e-03, MSE(pi2): 1.282e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 72500, Train loss: 1.054e+03, Test loss: 5.465e+03, MSE(e): 1.830e-05, MSE(pi1): 9.092e-03, MSE(pi2): 1.134e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 72600, Train loss: 1.266e+03, Test loss: 5.999e+03, MSE(e): 3.835e-05, MSE(pi1): 1.032e-02, MSE(pi2): 2.097e-05, MSE(pi3): 7.797e-03\n",
      "Epoch 72700, Train loss: 1.568e+03, Test loss: 6.719e+03, MSE(e): 7.053e-05, MSE(pi1): 8.424e-03, MSE(pi2): 3.561e-05, MSE(pi3): 7.787e-03\n",
      "Epoch 72800, Train loss: 1.064e+03, Test loss: 5.546e+03, MSE(e): 1.934e-05, MSE(pi1): 9.050e-03, MSE(pi2): 1.163e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 72900, Train loss: 1.671e+03, Test loss: 6.653e+03, MSE(e): 8.069e-05, MSE(pi1): 8.355e-03, MSE(pi2): 3.798e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 73000, Train loss: 1.069e+03, Test loss: 5.472e+03, MSE(e): 1.832e-05, MSE(pi1): 1.053e-02, MSE(pi2): 1.114e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 73100, Train loss: 1.080e+03, Test loss: 5.509e+03, MSE(e): 1.865e-05, MSE(pi1): 1.127e-02, MSE(pi2): 1.129e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 73200, Train loss: 1.359e+03, Test loss: 6.241e+03, MSE(e): 4.924e-05, MSE(pi1): 8.467e-03, MSE(pi2): 2.448e-05, MSE(pi3): 7.815e-03\n",
      "Epoch 73300, Train loss: 1.257e+03, Test loss: 5.652e+03, MSE(e): 3.909e-05, MSE(pi1): 8.544e-03, MSE(pi2): 2.106e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 73400, Train loss: 1.276e+03, Test loss: 5.738e+03, MSE(e): 4.023e-05, MSE(pi1): 9.232e-03, MSE(pi2): 2.150e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 73500, Train loss: 1.076e+03, Test loss: 5.584e+03, MSE(e): 1.812e-05, MSE(pi1): 1.142e-02, MSE(pi2): 1.109e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 73600, Train loss: 1.038e+03, Test loss: 5.502e+03, MSE(e): 1.802e-05, MSE(pi1): 7.786e-03, MSE(pi2): 1.123e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 73700, Train loss: 1.052e+03, Test loss: 5.647e+03, MSE(e): 1.847e-05, MSE(pi1): 8.701e-03, MSE(pi2): 1.134e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 73800, Train loss: 1.043e+03, Test loss: 5.520e+03, MSE(e): 1.828e-05, MSE(pi1): 7.935e-03, MSE(pi2): 1.112e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 73900, Train loss: 1.043e+03, Test loss: 5.515e+03, MSE(e): 1.756e-05, MSE(pi1): 8.721e-03, MSE(pi2): 1.085e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 74000, Train loss: 1.041e+03, Test loss: 5.514e+03, MSE(e): 1.794e-05, MSE(pi1): 8.162e-03, MSE(pi2): 1.105e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 74100, Train loss: 1.037e+03, Test loss: 5.505e+03, MSE(e): 1.783e-05, MSE(pi1): 7.819e-03, MSE(pi2): 1.109e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 74200, Train loss: 1.042e+03, Test loss: 5.530e+03, MSE(e): 1.778e-05, MSE(pi1): 8.382e-03, MSE(pi2): 1.101e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 74300, Train loss: 1.136e+03, Test loss: 5.333e+03, MSE(e): 2.654e-05, MSE(pi1): 9.078e-03, MSE(pi2): 1.576e-05, MSE(pi3): 7.799e-03\n",
      "Epoch 74400, Train loss: 1.036e+03, Test loss: 5.505e+03, MSE(e): 1.776e-05, MSE(pi1): 7.825e-03, MSE(pi2): 1.096e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 74500, Train loss: 1.056e+03, Test loss: 5.536e+03, MSE(e): 1.815e-05, MSE(pi1): 9.388e-03, MSE(pi2): 1.106e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 74600, Train loss: 1.061e+03, Test loss: 5.538e+03, MSE(e): 1.884e-05, MSE(pi1): 9.273e-03, MSE(pi2): 1.141e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 74700, Train loss: 1.069e+03, Test loss: 5.530e+03, MSE(e): 1.799e-05, MSE(pi1): 1.087e-02, MSE(pi2): 1.102e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 74800, Train loss: 1.046e+03, Test loss: 5.515e+03, MSE(e): 1.810e-05, MSE(pi1): 8.484e-03, MSE(pi2): 1.112e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 74900, Train loss: 1.839e+03, Test loss: 8.196e+03, MSE(e): 9.698e-05, MSE(pi1): 8.854e-03, MSE(pi2): 4.500e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 75000, Train loss: 1.070e+03, Test loss: 5.575e+03, MSE(e): 2.028e-05, MSE(pi1): 8.630e-03, MSE(pi2): 1.210e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 75100, Train loss: 1.044e+03, Test loss: 5.481e+03, MSE(e): 1.769e-05, MSE(pi1): 8.716e-03, MSE(pi2): 1.086e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 75200, Train loss: 1.043e+03, Test loss: 5.468e+03, MSE(e): 1.784e-05, MSE(pi1): 8.378e-03, MSE(pi2): 1.092e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 75300, Train loss: 1.039e+03, Test loss: 5.474e+03, MSE(e): 1.762e-05, MSE(pi1): 8.263e-03, MSE(pi2): 1.083e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 75400, Train loss: 1.071e+03, Test loss: 5.515e+03, MSE(e): 2.110e-05, MSE(pi1): 8.069e-03, MSE(pi2): 1.294e-05, MSE(pi3): 7.796e-03\n",
      "Epoch 75500, Train loss: 1.055e+03, Test loss: 5.523e+03, MSE(e): 1.772e-05, MSE(pi1): 9.747e-03, MSE(pi2): 1.083e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 75600, Train loss: 1.118e+03, Test loss: 5.871e+03, MSE(e): 2.476e-05, MSE(pi1): 8.985e-03, MSE(pi2): 1.388e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 75700, Train loss: 1.051e+03, Test loss: 5.497e+03, MSE(e): 1.755e-05, MSE(pi1): 9.535e-03, MSE(pi2): 1.077e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 75800, Train loss: 1.043e+03, Test loss: 5.443e+03, MSE(e): 1.780e-05, MSE(pi1): 8.483e-03, MSE(pi2): 1.101e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 75900, Train loss: 1.248e+03, Test loss: 6.523e+03, MSE(e): 3.627e-05, MSE(pi1): 1.052e-02, MSE(pi2): 1.876e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 76000, Train loss: 1.440e+03, Test loss: 5.900e+03, MSE(e): 5.764e-05, MSE(pi1): 8.021e-03, MSE(pi2): 2.794e-05, MSE(pi3): 7.836e-03\n",
      "Epoch 76100, Train loss: 1.150e+03, Test loss: 5.678e+03, MSE(e): 2.817e-05, MSE(pi1): 8.633e-03, MSE(pi2): 1.663e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 76200, Train loss: 1.035e+03, Test loss: 5.491e+03, MSE(e): 1.729e-05, MSE(pi1): 8.131e-03, MSE(pi2): 1.071e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 76300, Train loss: 1.161e+03, Test loss: 5.773e+03, MSE(e): 3.022e-05, MSE(pi1): 7.804e-03, MSE(pi2): 1.661e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 76400, Train loss: 1.088e+03, Test loss: 5.627e+03, MSE(e): 2.160e-05, MSE(pi1): 9.183e-03, MSE(pi2): 1.257e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 76500, Train loss: 1.037e+03, Test loss: 5.459e+03, MSE(e): 1.766e-05, MSE(pi1): 8.005e-03, MSE(pi2): 1.085e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 76600, Train loss: 1.044e+03, Test loss: 5.444e+03, MSE(e): 1.786e-05, MSE(pi1): 8.552e-03, MSE(pi2): 1.107e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 76700, Train loss: 1.343e+03, Test loss: 5.573e+03, MSE(e): 4.818e-05, MSE(pi1): 7.924e-03, MSE(pi2): 2.411e-05, MSE(pi3): 7.824e-03\n",
      "Epoch 76800, Train loss: 1.048e+03, Test loss: 5.482e+03, MSE(e): 1.730e-05, MSE(pi1): 9.491e-03, MSE(pi2): 1.064e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 76900, Train loss: 1.043e+03, Test loss: 5.435e+03, MSE(e): 1.745e-05, MSE(pi1): 8.781e-03, MSE(pi2): 1.076e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 77000, Train loss: 1.047e+03, Test loss: 5.509e+03, MSE(e): 1.888e-05, MSE(pi1): 7.825e-03, MSE(pi2): 1.142e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 77100, Train loss: 1.318e+03, Test loss: 7.064e+03, MSE(e): 4.522e-05, MSE(pi1): 8.605e-03, MSE(pi2): 2.262e-05, MSE(pi3): 7.797e-03\n",
      "Epoch 77200, Train loss: 1.301e+03, Test loss: 6.118e+03, MSE(e): 4.432e-05, MSE(pi1): 7.772e-03, MSE(pi2): 2.219e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 77300, Train loss: 1.254e+03, Test loss: 5.697e+03, MSE(e): 3.845e-05, MSE(pi1): 8.868e-03, MSE(pi2): 2.069e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 77400, Train loss: 1.246e+03, Test loss: 5.707e+03, MSE(e): 3.853e-05, MSE(pi1): 8.009e-03, MSE(pi2): 2.053e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 77500, Train loss: 1.111e+03, Test loss: 5.670e+03, MSE(e): 2.394e-05, MSE(pi1): 9.149e-03, MSE(pi2): 1.426e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 77600, Train loss: 1.472e+03, Test loss: 6.370e+03, MSE(e): 5.889e-05, MSE(pi1): 1.041e-02, MSE(pi2): 3.086e-05, MSE(pi3): 7.789e-03\n",
      "Epoch 77700, Train loss: 1.153e+03, Test loss: 5.452e+03, MSE(e): 2.894e-05, MSE(pi1): 8.313e-03, MSE(pi2): 1.726e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 77800, Train loss: 1.028e+03, Test loss: 5.562e+03, MSE(e): 1.655e-05, MSE(pi1): 8.258e-03, MSE(pi2): 1.031e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 77900, Train loss: 1.161e+03, Test loss: 5.746e+03, MSE(e): 2.955e-05, MSE(pi1): 8.397e-03, MSE(pi2): 1.687e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 78000, Train loss: 1.088e+03, Test loss: 5.575e+03, MSE(e): 2.201e-05, MSE(pi1): 8.711e-03, MSE(pi2): 1.281e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 78100, Train loss: 1.056e+03, Test loss: 5.405e+03, MSE(e): 1.978e-05, MSE(pi1): 7.894e-03, MSE(pi2): 1.202e-05, MSE(pi3): 7.795e-03\n",
      "Epoch 78200, Train loss: 1.067e+03, Test loss: 5.570e+03, MSE(e): 1.800e-05, MSE(pi1): 1.067e-02, MSE(pi2): 1.086e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 78300, Train loss: 1.810e+03, Test loss: 5.618e+03, MSE(e): 9.362e-05, MSE(pi1): 9.283e-03, MSE(pi2): 4.496e-05, MSE(pi3): 7.809e-03\n",
      "Epoch 78400, Train loss: 1.178e+03, Test loss: 5.680e+03, MSE(e): 3.135e-05, MSE(pi1): 8.316e-03, MSE(pi2): 1.726e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 78500, Train loss: 1.051e+03, Test loss: 5.375e+03, MSE(e): 1.922e-05, MSE(pi1): 7.893e-03, MSE(pi2): 1.170e-05, MSE(pi3): 7.798e-03\n",
      "Epoch 78600, Train loss: 1.034e+03, Test loss: 5.504e+03, MSE(e): 1.741e-05, MSE(pi1): 7.964e-03, MSE(pi2): 1.076e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 78700, Train loss: 1.032e+03, Test loss: 5.495e+03, MSE(e): 1.678e-05, MSE(pi1): 8.425e-03, MSE(pi2): 1.038e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 78800, Train loss: 1.118e+03, Test loss: 5.589e+03, MSE(e): 2.462e-05, MSE(pi1): 9.167e-03, MSE(pi2): 1.399e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 78900, Train loss: 1.043e+03, Test loss: 5.546e+03, MSE(e): 1.724e-05, MSE(pi1): 9.057e-03, MSE(pi2): 1.067e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 79000, Train loss: 1.035e+03, Test loss: 5.519e+03, MSE(e): 1.766e-05, MSE(pi1): 7.846e-03, MSE(pi2): 1.090e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 79100, Train loss: 1.030e+03, Test loss: 5.517e+03, MSE(e): 1.671e-05, MSE(pi1): 8.285e-03, MSE(pi2): 1.034e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 79200, Train loss: 1.037e+03, Test loss: 5.503e+03, MSE(e): 1.761e-05, MSE(pi1): 8.015e-03, MSE(pi2): 1.079e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 79300, Train loss: 1.223e+03, Test loss: 5.510e+03, MSE(e): 3.598e-05, MSE(pi1): 7.935e-03, MSE(pi2): 1.883e-05, MSE(pi3): 7.837e-03\n",
      "Epoch 79400, Train loss: 1.057e+03, Test loss: 5.548e+03, MSE(e): 1.942e-05, MSE(pi1): 8.245e-03, MSE(pi2): 1.215e-05, MSE(pi3): 7.799e-03\n",
      "Epoch 79500, Train loss: 1.584e+03, Test loss: 6.853e+03, MSE(e): 7.163e-05, MSE(pi1): 8.419e-03, MSE(pi2): 3.396e-05, MSE(pi3): 7.830e-03\n",
      "Epoch 79600, Train loss: 1.032e+03, Test loss: 5.550e+03, MSE(e): 1.688e-05, MSE(pi1): 8.279e-03, MSE(pi2): 1.037e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 79700, Train loss: 1.052e+03, Test loss: 5.492e+03, MSE(e): 1.827e-05, MSE(pi1): 8.859e-03, MSE(pi2): 1.112e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 79800, Train loss: 1.234e+03, Test loss: 5.826e+03, MSE(e): 3.599e-05, MSE(pi1): 9.278e-03, MSE(pi2): 1.881e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 79900, Train loss: 1.105e+03, Test loss: 5.628e+03, MSE(e): 2.340e-05, MSE(pi1): 9.016e-03, MSE(pi2): 1.321e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 80000, Train loss: 1.030e+03, Test loss: 5.529e+03, MSE(e): 1.667e-05, MSE(pi1): 8.334e-03, MSE(pi2): 1.029e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 80100, Train loss: 1.037e+03, Test loss: 5.536e+03, MSE(e): 1.664e-05, MSE(pi1): 8.992e-03, MSE(pi2): 1.024e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 80200, Train loss: 1.171e+03, Test loss: 5.442e+03, MSE(e): 3.085e-05, MSE(pi1): 7.853e-03, MSE(pi2): 1.648e-05, MSE(pi3): 7.835e-03\n",
      "Epoch 80300, Train loss: 1.119e+03, Test loss: 5.323e+03, MSE(e): 2.587e-05, MSE(pi1): 8.163e-03, MSE(pi2): 1.560e-05, MSE(pi3): 7.788e-03\n",
      "Epoch 80400, Train loss: 1.036e+03, Test loss: 5.569e+03, MSE(e): 1.711e-05, MSE(pi1): 8.507e-03, MSE(pi2): 1.056e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 80500, Train loss: 1.031e+03, Test loss: 5.517e+03, MSE(e): 1.695e-05, MSE(pi1): 8.132e-03, MSE(pi2): 1.039e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 80600, Train loss: 1.694e+03, Test loss: 6.847e+03, MSE(e): 8.217e-05, MSE(pi1): 9.080e-03, MSE(pi2): 3.838e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 80700, Train loss: 1.433e+03, Test loss: 5.688e+03, MSE(e): 5.719e-05, MSE(pi1): 8.104e-03, MSE(pi2): 2.871e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 80800, Train loss: 1.032e+03, Test loss: 5.539e+03, MSE(e): 1.728e-05, MSE(pi1): 7.947e-03, MSE(pi2): 1.053e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 80900, Train loss: 1.035e+03, Test loss: 5.509e+03, MSE(e): 1.666e-05, MSE(pi1): 8.849e-03, MSE(pi2): 1.040e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 81000, Train loss: 1.031e+03, Test loss: 5.538e+03, MSE(e): 1.648e-05, MSE(pi1): 8.550e-03, MSE(pi2): 1.022e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 81100, Train loss: 1.197e+03, Test loss: 5.566e+03, MSE(e): 3.371e-05, MSE(pi1): 7.912e-03, MSE(pi2): 1.820e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 81200, Train loss: 1.039e+03, Test loss: 5.554e+03, MSE(e): 1.798e-05, MSE(pi1): 7.874e-03, MSE(pi2): 1.097e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 81300, Train loss: 1.141e+03, Test loss: 5.383e+03, MSE(e): 2.816e-05, MSE(pi1): 7.817e-03, MSE(pi2): 1.531e-05, MSE(pi3): 7.814e-03\n",
      "Epoch 81400, Train loss: 1.430e+03, Test loss: 6.636e+03, MSE(e): 5.484e-05, MSE(pi1): 1.008e-02, MSE(pi2): 2.655e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 81500, Train loss: 1.063e+03, Test loss: 5.500e+03, MSE(e): 2.004e-05, MSE(pi1): 8.150e-03, MSE(pi2): 1.232e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 81600, Train loss: 2.260e+03, Test loss: 8.477e+03, MSE(e): 1.371e-04, MSE(pi1): 1.066e-02, MSE(pi2): 6.219e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 81700, Train loss: 1.128e+03, Test loss: 6.191e+03, MSE(e): 2.555e-05, MSE(pi1): 9.355e-03, MSE(pi2): 1.452e-05, MSE(pi3): 7.791e-03\n",
      "Epoch 81800, Train loss: 1.044e+03, Test loss: 5.516e+03, MSE(e): 1.837e-05, MSE(pi1): 7.996e-03, MSE(pi2): 1.102e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 81900, Train loss: 1.099e+03, Test loss: 5.930e+03, MSE(e): 2.290e-05, MSE(pi1): 9.060e-03, MSE(pi2): 1.289e-05, MSE(pi3): 7.798e-03\n",
      "Epoch 82000, Train loss: 1.202e+03, Test loss: 5.963e+03, MSE(e): 3.241e-05, MSE(pi1): 9.602e-03, MSE(pi2): 1.667e-05, MSE(pi3): 7.823e-03\n",
      "Epoch 82100, Train loss: 1.032e+03, Test loss: 5.508e+03, MSE(e): 1.688e-05, MSE(pi1): 8.423e-03, MSE(pi2): 1.055e-05, MSE(pi3): 7.792e-03\n",
      "Epoch 82200, Train loss: 1.031e+03, Test loss: 5.518e+03, MSE(e): 1.619e-05, MSE(pi1): 8.889e-03, MSE(pi2): 1.006e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 82300, Train loss: 1.038e+03, Test loss: 5.484e+03, MSE(e): 1.793e-05, MSE(pi1): 7.896e-03, MSE(pi2): 1.095e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 82400, Train loss: 1.038e+03, Test loss: 5.493e+03, MSE(e): 1.669e-05, MSE(pi1): 9.039e-03, MSE(pi2): 1.026e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 82500, Train loss: 1.068e+03, Test loss: 5.515e+03, MSE(e): 1.881e-05, MSE(pi1): 9.883e-03, MSE(pi2): 1.118e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 82600, Train loss: 1.027e+03, Test loss: 5.517e+03, MSE(e): 1.621e-05, MSE(pi1): 8.465e-03, MSE(pi2): 1.003e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 82700, Train loss: 1.034e+03, Test loss: 5.474e+03, MSE(e): 1.727e-05, MSE(pi1): 8.047e-03, MSE(pi2): 1.049e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 82800, Train loss: 1.127e+03, Test loss: 5.666e+03, MSE(e): 2.433e-05, MSE(pi1): 1.040e-02, MSE(pi2): 1.394e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 82900, Train loss: 1.068e+03, Test loss: 5.709e+03, MSE(e): 1.948e-05, MSE(pi1): 9.298e-03, MSE(pi2): 1.137e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 83000, Train loss: 1.022e+03, Test loss: 5.582e+03, MSE(e): 1.656e-05, MSE(pi1): 7.701e-03, MSE(pi2): 1.028e-05, MSE(pi3): 7.795e-03\n",
      "Epoch 83100, Train loss: 1.150e+03, Test loss: 6.229e+03, MSE(e): 2.838e-05, MSE(pi1): 8.637e-03, MSE(pi2): 1.523e-05, MSE(pi3): 7.797e-03\n",
      "Epoch 83200, Train loss: 1.082e+03, Test loss: 5.523e+03, MSE(e): 2.179e-05, MSE(pi1): 8.322e-03, MSE(pi2): 1.257e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 83300, Train loss: 1.032e+03, Test loss: 5.533e+03, MSE(e): 1.634e-05, MSE(pi1): 8.813e-03, MSE(pi2): 1.010e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 83400, Train loss: 1.022e+03, Test loss: 5.506e+03, MSE(e): 1.626e-05, MSE(pi1): 7.895e-03, MSE(pi2): 1.013e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 83500, Train loss: 1.042e+03, Test loss: 5.673e+03, MSE(e): 1.855e-05, MSE(pi1): 7.727e-03, MSE(pi2): 1.124e-05, MSE(pi3): 7.793e-03\n",
      "Epoch 83600, Train loss: 1.024e+03, Test loss: 5.522e+03, MSE(e): 1.604e-05, MSE(pi1): 8.327e-03, MSE(pi2): 1.007e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 83700, Train loss: 1.029e+03, Test loss: 5.533e+03, MSE(e): 1.609e-05, MSE(pi1): 8.813e-03, MSE(pi2): 1.006e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 83800, Train loss: 1.044e+03, Test loss: 5.538e+03, MSE(e): 1.633e-05, MSE(pi1): 1.001e-02, MSE(pi2): 1.009e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 83900, Train loss: 1.054e+03, Test loss: 5.695e+03, MSE(e): 1.812e-05, MSE(pi1): 9.306e-03, MSE(pi2): 1.080e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 84000, Train loss: 1.331e+03, Test loss: 5.771e+03, MSE(e): 4.434e-05, MSE(pi1): 1.062e-02, MSE(pi2): 2.240e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 84100, Train loss: 1.048e+03, Test loss: 5.520e+03, MSE(e): 1.739e-05, MSE(pi1): 9.315e-03, MSE(pi2): 1.051e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 84200, Train loss: 1.055e+03, Test loss: 5.551e+03, MSE(e): 1.974e-05, MSE(pi1): 7.791e-03, MSE(pi2): 1.169e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 84300, Train loss: 1.080e+03, Test loss: 5.592e+03, MSE(e): 2.000e-05, MSE(pi1): 9.960e-03, MSE(pi2): 1.152e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 84400, Train loss: 1.026e+03, Test loss: 5.551e+03, MSE(e): 1.581e-05, MSE(pi1): 8.769e-03, MSE(pi2): 9.850e-06, MSE(pi3): 7.802e-03\n",
      "Epoch 84500, Train loss: 1.693e+03, Test loss: 8.139e+03, MSE(e): 8.245e-05, MSE(pi1): 8.817e-03, MSE(pi2): 3.860e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 84600, Train loss: 1.541e+03, Test loss: 5.614e+03, MSE(e): 6.771e-05, MSE(pi1): 8.205e-03, MSE(pi2): 3.174e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 84700, Train loss: 1.022e+03, Test loss: 5.520e+03, MSE(e): 1.621e-05, MSE(pi1): 8.035e-03, MSE(pi2): 1.009e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 84800, Train loss: 1.903e+03, Test loss: 6.269e+03, MSE(e): 1.028e-04, MSE(pi1): 9.169e-03, MSE(pi2): 4.758e-05, MSE(pi3): 7.837e-03\n",
      "Epoch 84900, Train loss: 1.028e+03, Test loss: 5.564e+03, MSE(e): 1.602e-05, MSE(pi1): 8.823e-03, MSE(pi2): 9.955e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 85000, Train loss: 1.029e+03, Test loss: 5.537e+03, MSE(e): 1.661e-05, MSE(pi1): 8.247e-03, MSE(pi2): 1.020e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 85100, Train loss: 1.027e+03, Test loss: 5.522e+03, MSE(e): 1.645e-05, MSE(pi1): 8.204e-03, MSE(pi2): 1.011e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 85200, Train loss: 1.024e+03, Test loss: 5.510e+03, MSE(e): 1.627e-05, MSE(pi1): 8.139e-03, MSE(pi2): 1.011e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 85300, Train loss: 1.052e+03, Test loss: 5.538e+03, MSE(e): 1.810e-05, MSE(pi1): 9.040e-03, MSE(pi2): 1.077e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 85400, Train loss: 1.147e+03, Test loss: 5.582e+03, MSE(e): 2.829e-05, MSE(pi1): 8.225e-03, MSE(pi2): 1.565e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 85500, Train loss: 1.043e+03, Test loss: 5.521e+03, MSE(e): 1.668e-05, MSE(pi1): 9.596e-03, MSE(pi2): 1.024e-05, MSE(pi3): 7.806e-03\n",
      "Epoch 85600, Train loss: 1.030e+03, Test loss: 5.557e+03, MSE(e): 1.580e-05, MSE(pi1): 9.231e-03, MSE(pi2): 9.739e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 85700, Train loss: 1.588e+03, Test loss: 5.891e+03, MSE(e): 7.234e-05, MSE(pi1): 8.094e-03, MSE(pi2): 3.404e-05, MSE(pi3): 7.838e-03\n",
      "Epoch 85800, Train loss: 1.167e+03, Test loss: 5.563e+03, MSE(e): 2.947e-05, MSE(pi1): 9.176e-03, MSE(pi2): 1.580e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 85900, Train loss: 1.044e+03, Test loss: 5.584e+03, MSE(e): 1.749e-05, MSE(pi1): 8.955e-03, MSE(pi2): 1.059e-05, MSE(pi3): 7.799e-03\n",
      "Epoch 86000, Train loss: 1.078e+03, Test loss: 5.839e+03, MSE(e): 2.073e-05, MSE(pi1): 9.083e-03, MSE(pi2): 1.183e-05, MSE(pi3): 7.801e-03\n",
      "Epoch 86100, Train loss: 1.039e+03, Test loss: 5.604e+03, MSE(e): 1.591e-05, MSE(pi1): 9.935e-03, MSE(pi2): 9.749e-06, MSE(pi3): 7.802e-03\n",
      "Epoch 86200, Train loss: 1.057e+03, Test loss: 5.540e+03, MSE(e): 1.862e-05, MSE(pi1): 9.044e-03, MSE(pi2): 1.094e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 86300, Train loss: 1.157e+03, Test loss: 6.356e+03, MSE(e): 2.910e-05, MSE(pi1): 8.591e-03, MSE(pi2): 1.545e-05, MSE(pi3): 7.797e-03\n",
      "Epoch 86400, Train loss: 2.169e+03, Test loss: 6.489e+03, MSE(e): 1.272e-04, MSE(pi1): 1.156e-02, MSE(pi2): 5.821e-05, MSE(pi3): 7.813e-03\n",
      "Epoch 86500, Train loss: 1.020e+03, Test loss: 5.566e+03, MSE(e): 1.560e-05, MSE(pi1): 8.363e-03, MSE(pi2): 9.671e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 86600, Train loss: 1.049e+03, Test loss: 5.632e+03, MSE(e): 1.914e-05, MSE(pi1): 7.742e-03, MSE(pi2): 1.130e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 86700, Train loss: 1.020e+03, Test loss: 5.522e+03, MSE(e): 1.588e-05, MSE(pi1): 8.167e-03, MSE(pi2): 9.781e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 86800, Train loss: 1.300e+03, Test loss: 7.018e+03, MSE(e): 4.144e-05, MSE(pi1): 1.056e-02, MSE(pi2): 2.070e-05, MSE(pi3): 7.797e-03\n",
      "Epoch 86900, Train loss: 1.744e+03, Test loss: 7.787e+03, MSE(e): 8.525e-05, MSE(pi1): 1.102e-02, MSE(pi2): 3.963e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 87000, Train loss: 1.517e+03, Test loss: 6.034e+03, MSE(e): 6.530e-05, MSE(pi1): 7.966e-03, MSE(pi2): 3.110e-05, MSE(pi3): 7.839e-03\n",
      "Epoch 87100, Train loss: 1.032e+03, Test loss: 5.528e+03, MSE(e): 1.681e-05, MSE(pi1): 8.348e-03, MSE(pi2): 1.023e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 87200, Train loss: 1.018e+03, Test loss: 5.549e+03, MSE(e): 1.533e-05, MSE(pi1): 8.414e-03, MSE(pi2): 9.580e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 87300, Train loss: 1.025e+03, Test loss: 5.543e+03, MSE(e): 1.635e-05, MSE(pi1): 8.167e-03, MSE(pi2): 1.017e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 87400, Train loss: 1.044e+03, Test loss: 5.545e+03, MSE(e): 1.826e-05, MSE(pi1): 8.097e-03, MSE(pi2): 1.084e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 87500, Train loss: 1.019e+03, Test loss: 5.578e+03, MSE(e): 1.556e-05, MSE(pi1): 8.326e-03, MSE(pi2): 9.817e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 87600, Train loss: 1.022e+03, Test loss: 5.576e+03, MSE(e): 1.566e-05, MSE(pi1): 8.553e-03, MSE(pi2): 9.794e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 87700, Train loss: 1.026e+03, Test loss: 5.518e+03, MSE(e): 1.635e-05, MSE(pi1): 8.197e-03, MSE(pi2): 1.010e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 87800, Train loss: 1.041e+03, Test loss: 5.535e+03, MSE(e): 1.752e-05, MSE(pi1): 8.492e-03, MSE(pi2): 1.053e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 87900, Train loss: 1.175e+03, Test loss: 6.491e+03, MSE(e): 2.966e-05, MSE(pi1): 9.898e-03, MSE(pi2): 1.566e-05, MSE(pi3): 7.796e-03\n",
      "Epoch 88000, Train loss: 1.280e+03, Test loss: 6.894e+03, MSE(e): 4.028e-05, MSE(pi1): 9.775e-03, MSE(pi2): 2.023e-05, MSE(pi3): 7.799e-03\n",
      "Epoch 88100, Train loss: 1.639e+03, Test loss: 5.929e+03, MSE(e): 7.777e-05, MSE(pi1): 8.054e-03, MSE(pi2): 3.615e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 88200, Train loss: 1.038e+03, Test loss: 5.606e+03, MSE(e): 1.789e-05, MSE(pi1): 7.927e-03, MSE(pi2): 1.066e-05, MSE(pi3): 7.798e-03\n",
      "Epoch 88300, Train loss: 1.023e+03, Test loss: 5.656e+03, MSE(e): 1.590e-05, MSE(pi1): 8.387e-03, MSE(pi2): 9.764e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 88400, Train loss: 1.047e+03, Test loss: 5.542e+03, MSE(e): 1.877e-05, MSE(pi1): 7.970e-03, MSE(pi2): 1.115e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 88500, Train loss: 1.054e+03, Test loss: 5.675e+03, MSE(e): 1.564e-05, MSE(pi1): 1.169e-02, MSE(pi2): 9.591e-06, MSE(pi3): 7.804e-03\n",
      "Epoch 88600, Train loss: 1.191e+03, Test loss: 5.543e+03, MSE(e): 3.302e-05, MSE(pi1): 7.884e-03, MSE(pi2): 1.738e-05, MSE(pi3): 7.818e-03\n",
      "Epoch 88700, Train loss: 1.017e+03, Test loss: 5.572e+03, MSE(e): 1.533e-05, MSE(pi1): 8.319e-03, MSE(pi2): 9.609e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 88800, Train loss: 1.032e+03, Test loss: 5.534e+03, MSE(e): 1.718e-05, MSE(pi1): 8.006e-03, MSE(pi2): 1.031e-05, MSE(pi3): 7.802e-03\n",
      "Epoch 88900, Train loss: 1.015e+03, Test loss: 5.570e+03, MSE(e): 1.511e-05, MSE(pi1): 8.415e-03, MSE(pi2): 9.476e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 89000, Train loss: 1.110e+03, Test loss: 5.645e+03, MSE(e): 2.278e-05, MSE(pi1): 1.011e-02, MSE(pi2): 1.273e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 89100, Train loss: 1.094e+03, Test loss: 5.612e+03, MSE(e): 2.282e-05, MSE(pi1): 8.357e-03, MSE(pi2): 1.350e-05, MSE(pi3): 7.819e-03\n",
      "Epoch 89200, Train loss: 1.024e+03, Test loss: 5.619e+03, MSE(e): 1.649e-05, MSE(pi1): 7.962e-03, MSE(pi2): 1.004e-05, MSE(pi3): 7.799e-03\n",
      "Epoch 89300, Train loss: 1.019e+03, Test loss: 5.648e+03, MSE(e): 1.592e-05, MSE(pi1): 8.044e-03, MSE(pi2): 9.902e-06, MSE(pi3): 7.789e-03\n",
      "Epoch 89400, Train loss: 1.035e+03, Test loss: 5.584e+03, MSE(e): 1.739e-05, MSE(pi1): 8.135e-03, MSE(pi2): 1.054e-05, MSE(pi3): 7.797e-03\n",
      "Epoch 89500, Train loss: 1.022e+03, Test loss: 5.606e+03, MSE(e): 1.544e-05, MSE(pi1): 8.785e-03, MSE(pi2): 9.626e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 89600, Train loss: 1.638e+03, Test loss: 5.765e+03, MSE(e): 7.661e-05, MSE(pi1): 9.058e-03, MSE(pi2): 3.625e-05, MSE(pi3): 7.816e-03\n",
      "Epoch 89700, Train loss: 1.060e+03, Test loss: 5.904e+03, MSE(e): 1.923e-05, MSE(pi1): 8.795e-03, MSE(pi2): 1.114e-05, MSE(pi3): 7.797e-03\n",
      "Epoch 89800, Train loss: 1.022e+03, Test loss: 5.613e+03, MSE(e): 1.612e-05, MSE(pi1): 8.066e-03, MSE(pi2): 9.805e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 89900, Train loss: 1.014e+03, Test loss: 5.560e+03, MSE(e): 1.525e-05, MSE(pi1): 8.164e-03, MSE(pi2): 9.432e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 90000, Train loss: 1.030e+03, Test loss: 5.638e+03, MSE(e): 1.523e-05, MSE(pi1): 9.790e-03, MSE(pi2): 9.453e-06, MSE(pi3): 7.802e-03\n",
      "Epoch 90100, Train loss: 1.016e+03, Test loss: 5.603e+03, MSE(e): 1.530e-05, MSE(pi1): 8.264e-03, MSE(pi2): 9.564e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 90200, Train loss: 1.117e+03, Test loss: 5.703e+03, MSE(e): 2.513e-05, MSE(pi1): 8.610e-03, MSE(pi2): 1.406e-05, MSE(pi3): 7.799e-03\n",
      "Epoch 90300, Train loss: 1.013e+03, Test loss: 5.616e+03, MSE(e): 1.561e-05, MSE(pi1): 7.726e-03, MSE(pi2): 9.549e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 90400, Train loss: 1.185e+03, Test loss: 5.612e+03, MSE(e): 3.246e-05, MSE(pi1): 7.787e-03, MSE(pi2): 1.669e-05, MSE(pi3): 7.826e-03\n",
      "Epoch 90500, Train loss: 1.014e+03, Test loss: 5.596e+03, MSE(e): 1.566e-05, MSE(pi1): 7.720e-03, MSE(pi2): 9.599e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 90600, Train loss: 1.013e+03, Test loss: 5.603e+03, MSE(e): 1.557e-05, MSE(pi1): 7.764e-03, MSE(pi2): 9.656e-06, MSE(pi3): 7.797e-03\n",
      "Epoch 90700, Train loss: 1.011e+03, Test loss: 5.569e+03, MSE(e): 1.514e-05, MSE(pi1): 7.924e-03, MSE(pi2): 9.537e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 90800, Train loss: 1.016e+03, Test loss: 5.567e+03, MSE(e): 1.518e-05, MSE(pi1): 8.368e-03, MSE(pi2): 9.488e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 90900, Train loss: 1.418e+03, Test loss: 5.701e+03, MSE(e): 5.445e-05, MSE(pi1): 9.233e-03, MSE(pi2): 2.662e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 91000, Train loss: 1.012e+03, Test loss: 5.629e+03, MSE(e): 1.516e-05, MSE(pi1): 8.052e-03, MSE(pi2): 9.416e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 91100, Train loss: 1.021e+03, Test loss: 5.658e+03, MSE(e): 1.503e-05, MSE(pi1): 9.098e-03, MSE(pi2): 9.322e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 91200, Train loss: 1.036e+03, Test loss: 5.765e+03, MSE(e): 1.606e-05, MSE(pi1): 9.581e-03, MSE(pi2): 9.796e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 91300, Train loss: 1.025e+03, Test loss: 5.648e+03, MSE(e): 1.671e-05, MSE(pi1): 7.874e-03, MSE(pi2): 1.021e-05, MSE(pi3): 7.796e-03\n",
      "Epoch 91400, Train loss: 1.019e+03, Test loss: 5.677e+03, MSE(e): 1.569e-05, MSE(pi1): 8.261e-03, MSE(pi2): 9.643e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 91500, Train loss: 1.022e+03, Test loss: 5.648e+03, MSE(e): 1.488e-05, MSE(pi1): 9.302e-03, MSE(pi2): 9.222e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 91600, Train loss: 1.018e+03, Test loss: 5.645e+03, MSE(e): 1.593e-05, MSE(pi1): 7.860e-03, MSE(pi2): 9.795e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 91700, Train loss: 1.043e+03, Test loss: 5.576e+03, MSE(e): 1.769e-05, MSE(pi1): 8.605e-03, MSE(pi2): 1.052e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 91800, Train loss: 1.068e+03, Test loss: 5.627e+03, MSE(e): 1.964e-05, MSE(pi1): 9.107e-03, MSE(pi2): 1.132e-05, MSE(pi3): 7.805e-03\n",
      "Epoch 91900, Train loss: 1.010e+03, Test loss: 5.631e+03, MSE(e): 1.481e-05, MSE(pi1): 8.218e-03, MSE(pi2): 9.209e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 92000, Train loss: 1.061e+03, Test loss: 5.607e+03, MSE(e): 1.699e-05, MSE(pi1): 1.103e-02, MSE(pi2): 1.022e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 92100, Train loss: 1.022e+03, Test loss: 5.575e+03, MSE(e): 1.575e-05, MSE(pi1): 8.432e-03, MSE(pi2): 9.690e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 92200, Train loss: 1.017e+03, Test loss: 5.617e+03, MSE(e): 1.516e-05, MSE(pi1): 8.480e-03, MSE(pi2): 9.345e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 92300, Train loss: 1.039e+03, Test loss: 5.612e+03, MSE(e): 1.559e-05, MSE(pi1): 1.024e-02, MSE(pi2): 9.604e-06, MSE(pi3): 7.802e-03\n",
      "Epoch 92400, Train loss: 1.021e+03, Test loss: 5.650e+03, MSE(e): 1.475e-05, MSE(pi1): 9.341e-03, MSE(pi2): 9.100e-06, MSE(pi3): 7.802e-03\n",
      "Epoch 92500, Train loss: 1.018e+03, Test loss: 5.652e+03, MSE(e): 1.527e-05, MSE(pi1): 8.530e-03, MSE(pi2): 9.435e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 92600, Train loss: 1.275e+03, Test loss: 5.763e+03, MSE(e): 4.041e-05, MSE(pi1): 8.963e-03, MSE(pi2): 2.035e-05, MSE(pi3): 7.808e-03\n",
      "Epoch 92700, Train loss: 1.053e+03, Test loss: 5.670e+03, MSE(e): 1.571e-05, MSE(pi1): 1.153e-02, MSE(pi2): 9.390e-06, MSE(pi3): 7.806e-03\n",
      "Epoch 92800, Train loss: 1.014e+03, Test loss: 5.612e+03, MSE(e): 1.496e-05, MSE(pi1): 8.414e-03, MSE(pi2): 9.399e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 92900, Train loss: 1.010e+03, Test loss: 5.634e+03, MSE(e): 1.483e-05, MSE(pi1): 8.179e-03, MSE(pi2): 9.392e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 93000, Train loss: 1.020e+03, Test loss: 5.633e+03, MSE(e): 1.491e-05, MSE(pi1): 9.084e-03, MSE(pi2): 9.324e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 93100, Train loss: 1.019e+03, Test loss: 5.582e+03, MSE(e): 1.573e-05, MSE(pi1): 8.162e-03, MSE(pi2): 9.668e-06, MSE(pi3): 7.802e-03\n",
      "Epoch 93200, Train loss: 1.071e+03, Test loss: 5.630e+03, MSE(e): 2.083e-05, MSE(pi1): 8.287e-03, MSE(pi2): 1.194e-05, MSE(pi3): 7.803e-03\n",
      "Epoch 93300, Train loss: 1.020e+03, Test loss: 5.624e+03, MSE(e): 1.493e-05, MSE(pi1): 9.025e-03, MSE(pi2): 9.311e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 93400, Train loss: 1.590e+03, Test loss: 5.642e+03, MSE(e): 7.231e-05, MSE(pi1): 8.461e-03, MSE(pi2): 3.406e-05, MSE(pi3): 7.826e-03\n",
      "Epoch 93500, Train loss: 1.926e+03, Test loss: 6.558e+03, MSE(e): 1.058e-04, MSE(pi1): 8.639e-03, MSE(pi2): 4.812e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 93600, Train loss: 1.019e+03, Test loss: 5.617e+03, MSE(e): 1.485e-05, MSE(pi1): 9.019e-03, MSE(pi2): 9.162e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 93700, Train loss: 1.009e+03, Test loss: 5.638e+03, MSE(e): 1.457e-05, MSE(pi1): 8.378e-03, MSE(pi2): 9.126e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 93800, Train loss: 1.024e+03, Test loss: 5.631e+03, MSE(e): 1.638e-05, MSE(pi1): 8.061e-03, MSE(pi2): 1.001e-05, MSE(pi3): 7.800e-03\n",
      "Epoch 93900, Train loss: 1.009e+03, Test loss: 5.616e+03, MSE(e): 1.494e-05, MSE(pi1): 7.932e-03, MSE(pi2): 9.325e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 94000, Train loss: 1.012e+03, Test loss: 5.728e+03, MSE(e): 1.489e-05, MSE(pi1): 8.323e-03, MSE(pi2): 9.287e-06, MSE(pi3): 7.796e-03\n",
      "Epoch 94100, Train loss: 1.113e+03, Test loss: 5.502e+03, MSE(e): 2.493e-05, MSE(pi1): 8.524e-03, MSE(pi2): 1.466e-05, MSE(pi3): 7.785e-03\n",
      "Epoch 94200, Train loss: 1.008e+03, Test loss: 5.656e+03, MSE(e): 1.489e-05, MSE(pi1): 7.920e-03, MSE(pi2): 9.294e-06, MSE(pi3): 7.797e-03\n",
      "Epoch 94300, Train loss: 1.281e+03, Test loss: 6.336e+03, MSE(e): 4.181e-05, MSE(pi1): 8.196e-03, MSE(pi2): 2.061e-05, MSE(pi3): 7.811e-03\n",
      "Epoch 94400, Train loss: 1.013e+03, Test loss: 5.680e+03, MSE(e): 1.469e-05, MSE(pi1): 8.630e-03, MSE(pi2): 9.112e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 94500, Train loss: 1.011e+03, Test loss: 5.637e+03, MSE(e): 1.456e-05, MSE(pi1): 8.500e-03, MSE(pi2): 9.142e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 94600, Train loss: 1.006e+03, Test loss: 5.655e+03, MSE(e): 1.481e-05, MSE(pi1): 7.836e-03, MSE(pi2): 9.229e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 94700, Train loss: 1.312e+03, Test loss: 6.091e+03, MSE(e): 4.466e-05, MSE(pi1): 8.650e-03, MSE(pi2): 2.422e-05, MSE(pi3): 7.788e-03\n",
      "Epoch 94800, Train loss: 1.012e+03, Test loss: 5.637e+03, MSE(e): 1.462e-05, MSE(pi1): 8.557e-03, MSE(pi2): 9.081e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 94900, Train loss: 1.652e+03, Test loss: 5.772e+03, MSE(e): 7.745e-05, MSE(pi1): 9.508e-03, MSE(pi2): 3.553e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 95000, Train loss: 1.011e+03, Test loss: 5.667e+03, MSE(e): 1.465e-05, MSE(pi1): 8.478e-03, MSE(pi2): 9.053e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 95100, Train loss: 1.098e+03, Test loss: 5.606e+03, MSE(e): 2.319e-05, MSE(pi1): 8.506e-03, MSE(pi2): 1.303e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 95200, Train loss: 1.009e+03, Test loss: 5.645e+03, MSE(e): 1.505e-05, MSE(pi1): 7.901e-03, MSE(pi2): 9.246e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 95300, Train loss: 1.013e+03, Test loss: 5.637e+03, MSE(e): 1.465e-05, MSE(pi1): 8.674e-03, MSE(pi2): 9.113e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 95400, Train loss: 1.363e+03, Test loss: 7.158e+03, MSE(e): 4.925e-05, MSE(pi1): 9.226e-03, MSE(pi2): 2.486e-05, MSE(pi3): 7.784e-03\n",
      "Epoch 95500, Train loss: 1.013e+03, Test loss: 5.682e+03, MSE(e): 1.535e-05, MSE(pi1): 7.935e-03, MSE(pi2): 9.535e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 95600, Train loss: 1.244e+03, Test loss: 6.240e+03, MSE(e): 3.810e-05, MSE(pi1): 8.166e-03, MSE(pi2): 1.906e-05, MSE(pi3): 7.810e-03\n",
      "Epoch 95700, Train loss: 1.006e+03, Test loss: 5.712e+03, MSE(e): 1.473e-05, MSE(pi1): 7.950e-03, MSE(pi2): 9.250e-06, MSE(pi3): 7.793e-03\n",
      "Epoch 95800, Train loss: 1.171e+03, Test loss: 6.606e+03, MSE(e): 3.000e-05, MSE(pi1): 9.096e-03, MSE(pi2): 1.561e-05, MSE(pi3): 7.797e-03\n",
      "Epoch 95900, Train loss: 1.003e+03, Test loss: 5.642e+03, MSE(e): 1.459e-05, MSE(pi1): 7.723e-03, MSE(pi2): 9.031e-06, MSE(pi3): 7.797e-03\n",
      "Epoch 96000, Train loss: 1.012e+03, Test loss: 5.655e+03, MSE(e): 1.461e-05, MSE(pi1): 8.606e-03, MSE(pi2): 9.108e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 96100, Train loss: 1.038e+03, Test loss: 5.834e+03, MSE(e): 1.582e-05, MSE(pi1): 1.006e-02, MSE(pi2): 9.518e-06, MSE(pi3): 7.797e-03\n",
      "Epoch 96200, Train loss: 1.046e+03, Test loss: 5.678e+03, MSE(e): 1.758e-05, MSE(pi1): 9.025e-03, MSE(pi2): 1.033e-05, MSE(pi3): 7.798e-03\n",
      "Epoch 96300, Train loss: 1.050e+03, Test loss: 5.996e+03, MSE(e): 1.754e-05, MSE(pi1): 9.497e-03, MSE(pi2): 1.039e-05, MSE(pi3): 7.792e-03\n",
      "Epoch 96400, Train loss: 1.171e+03, Test loss: 6.009e+03, MSE(e): 3.113e-05, MSE(pi1): 7.851e-03, MSE(pi2): 1.605e-05, MSE(pi3): 7.817e-03\n",
      "Epoch 96500, Train loss: 1.888e+03, Test loss: 8.314e+03, MSE(e): 1.007e-04, MSE(pi1): 1.005e-02, MSE(pi2): 4.629e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 96600, Train loss: 1.419e+03, Test loss: 5.921e+03, MSE(e): 5.558e-05, MSE(pi1): 8.137e-03, MSE(pi2): 2.637e-05, MSE(pi3): 7.821e-03\n",
      "Epoch 96700, Train loss: 1.029e+03, Test loss: 5.734e+03, MSE(e): 1.692e-05, MSE(pi1): 7.922e-03, MSE(pi2): 1.018e-05, MSE(pi3): 7.804e-03\n",
      "Epoch 96800, Train loss: 1.522e+03, Test loss: 5.786e+03, MSE(e): 6.589e-05, MSE(pi1): 8.238e-03, MSE(pi2): 3.186e-05, MSE(pi3): 7.807e-03\n",
      "Epoch 96900, Train loss: 1.010e+03, Test loss: 5.658e+03, MSE(e): 1.472e-05, MSE(pi1): 8.327e-03, MSE(pi2): 9.337e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 97000, Train loss: 1.052e+03, Test loss: 5.770e+03, MSE(e): 1.948e-05, MSE(pi1): 7.811e-03, MSE(pi2): 1.151e-05, MSE(pi3): 7.789e-03\n",
      "Epoch 97100, Train loss: 1.032e+03, Test loss: 5.717e+03, MSE(e): 1.467e-05, MSE(pi1): 1.050e-02, MSE(pi2): 8.992e-06, MSE(pi3): 7.802e-03\n",
      "Epoch 97200, Train loss: 1.003e+03, Test loss: 5.708e+03, MSE(e): 1.455e-05, MSE(pi1): 7.770e-03, MSE(pi2): 9.052e-06, MSE(pi3): 7.793e-03\n",
      "Epoch 97300, Train loss: 1.016e+03, Test loss: 5.685e+03, MSE(e): 1.578e-05, MSE(pi1): 7.874e-03, MSE(pi2): 9.540e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 97400, Train loss: 1.008e+03, Test loss: 5.669e+03, MSE(e): 1.479e-05, MSE(pi1): 8.054e-03, MSE(pi2): 9.184e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 97500, Train loss: 1.048e+03, Test loss: 5.724e+03, MSE(e): 1.681e-05, MSE(pi1): 9.982e-03, MSE(pi2): 9.906e-06, MSE(pi3): 7.800e-03\n",
      "Epoch 97600, Train loss: 1.029e+03, Test loss: 5.718e+03, MSE(e): 1.447e-05, MSE(pi1): 1.044e-02, MSE(pi2): 8.900e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 97700, Train loss: 1.013e+03, Test loss: 5.794e+03, MSE(e): 1.533e-05, MSE(pi1): 8.032e-03, MSE(pi2): 9.379e-06, MSE(pi3): 7.796e-03\n",
      "Epoch 97800, Train loss: 1.453e+03, Test loss: 5.775e+03, MSE(e): 5.858e-05, MSE(pi1): 8.489e-03, MSE(pi2): 2.835e-05, MSE(pi3): 7.824e-03\n",
      "Epoch 97900, Train loss: 1.105e+03, Test loss: 5.887e+03, MSE(e): 2.356e-05, MSE(pi1): 8.746e-03, MSE(pi2): 1.420e-05, MSE(pi3): 7.820e-03\n",
      "Epoch 98000, Train loss: 1.840e+03, Test loss: 5.790e+03, MSE(e): 9.778e-05, MSE(pi1): 7.979e-03, MSE(pi2): 4.442e-05, MSE(pi3): 7.825e-03\n",
      "Epoch 98100, Train loss: 1.556e+03, Test loss: 5.783e+03, MSE(e): 6.910e-05, MSE(pi1): 8.158e-03, MSE(pi2): 3.274e-05, MSE(pi3): 7.831e-03\n",
      "Epoch 98200, Train loss: 1.021e+03, Test loss: 5.718e+03, MSE(e): 1.610e-05, MSE(pi1): 8.013e-03, MSE(pi2): 9.766e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 98300, Train loss: 1.020e+03, Test loss: 5.829e+03, MSE(e): 1.496e-05, MSE(pi1): 9.041e-03, MSE(pi2): 9.117e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 98400, Train loss: 1.002e+03, Test loss: 5.700e+03, MSE(e): 1.397e-05, MSE(pi1): 8.289e-03, MSE(pi2): 8.740e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 98500, Train loss: 1.013e+03, Test loss: 5.726e+03, MSE(e): 1.432e-05, MSE(pi1): 9.048e-03, MSE(pi2): 8.913e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 98600, Train loss: 1.009e+03, Test loss: 5.802e+03, MSE(e): 1.433e-05, MSE(pi1): 8.634e-03, MSE(pi2): 8.876e-06, MSE(pi3): 7.795e-03\n",
      "Epoch 98700, Train loss: 1.108e+03, Test loss: 6.316e+03, MSE(e): 2.313e-05, MSE(pi1): 9.692e-03, MSE(pi2): 1.258e-05, MSE(pi3): 7.796e-03\n",
      "Epoch 98800, Train loss: 1.011e+03, Test loss: 5.781e+03, MSE(e): 1.511e-05, MSE(pi1): 8.002e-03, MSE(pi2): 9.369e-06, MSE(pi3): 7.796e-03\n",
      "Epoch 98900, Train loss: 1.013e+03, Test loss: 5.792e+03, MSE(e): 1.442e-05, MSE(pi1): 8.887e-03, MSE(pi2): 8.883e-06, MSE(pi3): 7.798e-03\n",
      "Epoch 99000, Train loss: 1.021e+03, Test loss: 5.802e+03, MSE(e): 1.653e-05, MSE(pi1): 7.673e-03, MSE(pi2): 9.918e-06, MSE(pi3): 7.794e-03\n",
      "Epoch 99100, Train loss: 1.009e+03, Test loss: 5.678e+03, MSE(e): 1.487e-05, MSE(pi1): 8.023e-03, MSE(pi2): 9.276e-06, MSE(pi3): 7.797e-03\n",
      "Epoch 99200, Train loss: 1.016e+03, Test loss: 5.688e+03, MSE(e): 1.445e-05, MSE(pi1): 9.117e-03, MSE(pi2): 8.882e-06, MSE(pi3): 7.801e-03\n",
      "Epoch 99300, Train loss: 1.015e+03, Test loss: 5.758e+03, MSE(e): 1.420e-05, MSE(pi1): 9.335e-03, MSE(pi2): 8.759e-06, MSE(pi3): 7.797e-03\n",
      "Epoch 99400, Train loss: 1.177e+03, Test loss: 6.829e+03, MSE(e): 2.992e-05, MSE(pi1): 9.909e-03, MSE(pi2): 1.573e-05, MSE(pi3): 7.791e-03\n",
      "Epoch 99500, Train loss: 1.021e+03, Test loss: 5.822e+03, MSE(e): 1.557e-05, MSE(pi1): 8.559e-03, MSE(pi2): 9.342e-06, MSE(pi3): 7.797e-03\n",
      "Epoch 99600, Train loss: 1.003e+03, Test loss: 5.708e+03, MSE(e): 1.459e-05, MSE(pi1): 7.806e-03, MSE(pi2): 9.009e-06, MSE(pi3): 7.792e-03\n",
      "Epoch 99700, Train loss: 1.027e+03, Test loss: 5.784e+03, MSE(e): 1.468e-05, MSE(pi1): 1.003e-02, MSE(pi2): 8.916e-06, MSE(pi3): 7.799e-03\n",
      "Epoch 99800, Train loss: 1.774e+03, Test loss: 6.393e+03, MSE(e): 8.765e-05, MSE(pi1): 1.138e-02, MSE(pi2): 4.035e-05, MSE(pi3): 7.832e-03\n",
      "Epoch 99900, Train loss: 1.027e+03, Test loss: 5.555e+03, MSE(e): 1.692e-05, MSE(pi1): 7.847e-03, MSE(pi2): 1.039e-05, MSE(pi3): 7.794e-03\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "params_to_update = filter(lambda p: p.requires_grad, pretrained_pgnniv.parameters())\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=3e-4)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "train_loop(pretrained_pgnniv, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_epoch = n_epochs-1\n",
    "# n_epochs = 20000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 5\n",
    "\n",
    "# second_lr = 3e-4\n",
    "\n",
    "# train_loop(pretrained_pgnniv, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6190526d20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(pretrained_pgnniv(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            pretrained_pgnniv(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Parametros de entrenamiento\n",
    "# start_epoch = 9000\n",
    "# n_epochs = 10000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 100\n",
    "\n",
    "# second_lr = 1e-4\n",
    "\n",
    "# train_loop(model, optimizer, X_train_NN, y_train_NN, f_train_NN, X_test_NN, y_test_NN, f_test_NN,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
