{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from model.baseline_model import BaselineNonlinearModel\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from vecopsciml.operators.zero_order import Mx, My"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/transfer_learning/results/sigmoid_nonlinear\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/transfer_learning/results/sigmoid_nonlinear/baseline\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear/sigmoid_nonlinear.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/sigmoid_nonlinear')\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/sigmoid_nonlinear/baseline')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear/sigmoid_nonlinear.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data splitting in train/test\n",
    "X = torch.tensor(dataset['X_train'], dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(dataset['y_train'], dtype=torch.float32).unsqueeze(1)\n",
    "K = torch.tensor(dataset['k_train'], dtype=torch.float32).unsqueeze(1)\n",
    "f = torch.tensor(dataset['f_train'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X, y, K, f, test_size=0.3, random_state=42)\n",
    "\n",
    "# Data processing and adequacy with our TensOps library\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "# Loading and processing validation data\n",
    "X_val = torch.tensor(dataset['X_val'], dtype=torch.float32).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 1.555e+09, Test loss: 1.781e+09, MSE(e): 1.111e+02, MSE(pi1): 4.380e+04, MSE(pi2): 4.659e+01, MSE(pi3): 4.977e+01\n",
      "Epoch 100, Train loss: 9.858e+07, Test loss: 1.215e+08, MSE(e): 9.829e+00, MSE(pi1): 1.633e+01, MSE(pi2): 4.370e+00, MSE(pi3): 1.286e+00\n",
      "Epoch 200, Train loss: 3.253e+07, Test loss: 3.797e+07, MSE(e): 3.208e+00, MSE(pi1): 3.235e+01, MSE(pi2): 1.660e+00, MSE(pi3): 1.275e+00\n",
      "Epoch 300, Train loss: 1.832e+07, Test loss: 2.220e+07, MSE(e): 1.796e+00, MSE(pi1): 2.221e+01, MSE(pi2): 1.091e+00, MSE(pi3): 1.360e+00\n",
      "Epoch 400, Train loss: 1.580e+07, Test loss: 1.945e+07, MSE(e): 1.546e+00, MSE(pi1): 1.913e+01, MSE(pi2): 9.948e-01, MSE(pi3): 1.417e+00\n",
      "Epoch 500, Train loss: 1.491e+07, Test loss: 1.843e+07, MSE(e): 1.459e+00, MSE(pi1): 1.797e+01, MSE(pi2): 9.626e-01, MSE(pi3): 1.448e+00\n",
      "Epoch 600, Train loss: 1.447e+07, Test loss: 1.784e+07, MSE(e): 1.414e+00, MSE(pi1): 1.747e+01, MSE(pi2): 9.467e-01, MSE(pi3): 1.462e+00\n",
      "Epoch 700, Train loss: 1.419e+07, Test loss: 1.753e+07, MSE(e): 1.387e+00, MSE(pi1): 1.722e+01, MSE(pi2): 9.371e-01, MSE(pi3): 1.463e+00\n",
      "Epoch 800, Train loss: 1.401e+07, Test loss: 1.736e+07, MSE(e): 1.369e+00, MSE(pi1): 1.706e+01, MSE(pi2): 9.303e-01, MSE(pi3): 1.455e+00\n",
      "Epoch 900, Train loss: 1.387e+07, Test loss: 1.725e+07, MSE(e): 1.356e+00, MSE(pi1): 1.693e+01, MSE(pi2): 9.249e-01, MSE(pi3): 1.440e+00\n",
      "Epoch 1000, Train loss: 1.377e+07, Test loss: 1.721e+07, MSE(e): 1.346e+00, MSE(pi1): 1.681e+01, MSE(pi2): 9.205e-01, MSE(pi3): 1.419e+00\n",
      "Epoch 1100, Train loss: 1.368e+07, Test loss: 1.720e+07, MSE(e): 1.338e+00, MSE(pi1): 1.670e+01, MSE(pi2): 9.160e-01, MSE(pi3): 1.393e+00\n",
      "Epoch 1200, Train loss: 1.361e+07, Test loss: 1.722e+07, MSE(e): 1.331e+00, MSE(pi1): 1.660e+01, MSE(pi2): 9.118e-01, MSE(pi3): 1.363e+00\n",
      "Epoch 1300, Train loss: 1.354e+07, Test loss: 1.726e+07, MSE(e): 1.324e+00, MSE(pi1): 1.651e+01, MSE(pi2): 9.078e-01, MSE(pi3): 1.331e+00\n",
      "Epoch 1400, Train loss: 1.348e+07, Test loss: 1.732e+07, MSE(e): 1.318e+00, MSE(pi1): 1.644e+01, MSE(pi2): 9.032e-01, MSE(pi3): 1.298e+00\n",
      "Epoch 1500, Train loss: 1.341e+07, Test loss: 1.741e+07, MSE(e): 1.312e+00, MSE(pi1): 1.636e+01, MSE(pi2): 8.986e-01, MSE(pi3): 1.264e+00\n",
      "Epoch 1600, Train loss: 1.334e+07, Test loss: 1.748e+07, MSE(e): 1.305e+00, MSE(pi1): 1.628e+01, MSE(pi2): 8.941e-01, MSE(pi3): 1.230e+00\n",
      "Epoch 1700, Train loss: 1.327e+07, Test loss: 1.756e+07, MSE(e): 1.299e+00, MSE(pi1): 1.617e+01, MSE(pi2): 8.896e-01, MSE(pi3): 1.196e+00\n",
      "Epoch 1800, Train loss: 1.321e+07, Test loss: 1.766e+07, MSE(e): 1.293e+00, MSE(pi1): 1.603e+01, MSE(pi2): 8.853e-01, MSE(pi3): 1.163e+00\n",
      "Epoch 1900, Train loss: 1.314e+07, Test loss: 1.775e+07, MSE(e): 1.287e+00, MSE(pi1): 1.584e+01, MSE(pi2): 8.810e-01, MSE(pi3): 1.129e+00\n",
      "Epoch 2000, Train loss: 1.307e+07, Test loss: 1.782e+07, MSE(e): 1.280e+00, MSE(pi1): 1.560e+01, MSE(pi2): 8.758e-01, MSE(pi3): 1.095e+00\n",
      "Epoch 2100, Train loss: 1.296e+07, Test loss: 1.784e+07, MSE(e): 1.270e+00, MSE(pi1): 1.531e+01, MSE(pi2): 8.682e-01, MSE(pi3): 1.062e+00\n",
      "Epoch 2200, Train loss: 1.271e+07, Test loss: 1.760e+07, MSE(e): 1.245e+00, MSE(pi1): 1.492e+01, MSE(pi2): 8.506e-01, MSE(pi3): 1.027e+00\n",
      "Epoch 2300, Train loss: 1.121e+07, Test loss: 1.529e+07, MSE(e): 1.096e+00, MSE(pi1): 1.508e+01, MSE(pi2): 7.381e-01, MSE(pi3): 9.841e-01\n",
      "Epoch 2400, Train loss: 6.704e+06, Test loss: 8.724e+06, MSE(e): 6.427e-01, MSE(pi1): 1.777e+01, MSE(pi2): 4.268e-01, MSE(pi3): 9.883e-01\n",
      "Epoch 2500, Train loss: 5.635e+06, Test loss: 7.525e+06, MSE(e): 5.385e-01, MSE(pi1): 1.530e+01, MSE(pi2): 3.622e-01, MSE(pi3): 9.668e-01\n",
      "Epoch 2600, Train loss: 5.309e+06, Test loss: 7.207e+06, MSE(e): 5.073e-01, MSE(pi1): 1.434e+01, MSE(pi2): 3.447e-01, MSE(pi3): 9.156e-01\n",
      "Epoch 2700, Train loss: 5.182e+06, Test loss: 7.032e+06, MSE(e): 4.956e-01, MSE(pi1): 1.379e+01, MSE(pi2): 3.371e-01, MSE(pi3): 8.749e-01\n",
      "Epoch 2800, Train loss: 5.119e+06, Test loss: 6.988e+06, MSE(e): 4.900e-01, MSE(pi1): 1.342e+01, MSE(pi2): 3.345e-01, MSE(pi3): 8.420e-01\n",
      "Epoch 2900, Train loss: 5.091e+06, Test loss: 6.955e+06, MSE(e): 4.878e-01, MSE(pi1): 1.311e+01, MSE(pi2): 3.338e-01, MSE(pi3): 8.137e-01\n",
      "Epoch 3000, Train loss: 5.071e+06, Test loss: 6.930e+06, MSE(e): 4.863e-01, MSE(pi1): 1.284e+01, MSE(pi2): 3.327e-01, MSE(pi3): 7.886e-01\n",
      "Epoch 3100, Train loss: 5.055e+06, Test loss: 6.900e+06, MSE(e): 4.853e-01, MSE(pi1): 1.254e+01, MSE(pi2): 3.320e-01, MSE(pi3): 7.638e-01\n",
      "Epoch 3200, Train loss: 5.041e+06, Test loss: 6.878e+06, MSE(e): 4.845e-01, MSE(pi1): 1.219e+01, MSE(pi2): 3.316e-01, MSE(pi3): 7.381e-01\n",
      "Epoch 3300, Train loss: 5.032e+06, Test loss: 6.854e+06, MSE(e): 4.842e-01, MSE(pi1): 1.183e+01, MSE(pi2): 3.308e-01, MSE(pi3): 7.116e-01\n",
      "Epoch 3400, Train loss: 5.013e+06, Test loss: 6.831e+06, MSE(e): 4.831e-01, MSE(pi1): 1.136e+01, MSE(pi2): 3.307e-01, MSE(pi3): 6.801e-01\n",
      "Epoch 3500, Train loss: 4.997e+06, Test loss: 6.805e+06, MSE(e): 4.824e-01, MSE(pi1): 1.083e+01, MSE(pi2): 3.303e-01, MSE(pi3): 6.464e-01\n",
      "Epoch 3600, Train loss: 4.983e+06, Test loss: 6.786e+06, MSE(e): 4.819e-01, MSE(pi1): 1.023e+01, MSE(pi2): 3.302e-01, MSE(pi3): 6.094e-01\n",
      "Epoch 3700, Train loss: 4.964e+06, Test loss: 6.754e+06, MSE(e): 4.811e-01, MSE(pi1): 9.563e+00, MSE(pi2): 3.294e-01, MSE(pi3): 5.715e-01\n",
      "Epoch 3800, Train loss: 4.947e+06, Test loss: 6.727e+06, MSE(e): 4.804e-01, MSE(pi1): 8.854e+00, MSE(pi2): 3.290e-01, MSE(pi3): 5.327e-01\n",
      "Epoch 3900, Train loss: 4.930e+06, Test loss: 6.709e+06, MSE(e): 4.799e-01, MSE(pi1): 8.130e+00, MSE(pi2): 3.287e-01, MSE(pi3): 4.940e-01\n",
      "Epoch 4000, Train loss: 4.911e+06, Test loss: 6.677e+06, MSE(e): 4.791e-01, MSE(pi1): 7.438e+00, MSE(pi2): 3.280e-01, MSE(pi3): 4.583e-01\n",
      "Epoch 4100, Train loss: 4.894e+06, Test loss: 6.651e+06, MSE(e): 4.783e-01, MSE(pi1): 6.796e+00, MSE(pi2): 3.275e-01, MSE(pi3): 4.247e-01\n",
      "Epoch 4200, Train loss: 4.879e+06, Test loss: 6.636e+06, MSE(e): 4.777e-01, MSE(pi1): 6.227e+00, MSE(pi2): 3.272e-01, MSE(pi3): 3.934e-01\n",
      "Epoch 4300, Train loss: 4.863e+06, Test loss: 6.610e+06, MSE(e): 4.768e-01, MSE(pi1): 5.754e+00, MSE(pi2): 3.263e-01, MSE(pi3): 3.673e-01\n",
      "Epoch 4400, Train loss: 4.848e+06, Test loss: 6.589e+06, MSE(e): 4.760e-01, MSE(pi1): 5.367e+00, MSE(pi2): 3.257e-01, MSE(pi3): 3.435e-01\n",
      "Epoch 4500, Train loss: 4.834e+06, Test loss: 6.572e+06, MSE(e): 4.751e-01, MSE(pi1): 5.063e+00, MSE(pi2): 3.251e-01, MSE(pi3): 3.227e-01\n",
      "Epoch 4600, Train loss: 4.821e+06, Test loss: 6.558e+06, MSE(e): 4.742e-01, MSE(pi1): 4.825e+00, MSE(pi2): 3.244e-01, MSE(pi3): 3.049e-01\n",
      "Epoch 4700, Train loss: 4.807e+06, Test loss: 6.543e+06, MSE(e): 4.731e-01, MSE(pi1): 4.641e+00, MSE(pi2): 3.236e-01, MSE(pi3): 2.892e-01\n",
      "Epoch 4800, Train loss: 4.796e+06, Test loss: 6.520e+06, MSE(e): 4.723e-01, MSE(pi1): 4.503e+00, MSE(pi2): 3.226e-01, MSE(pi3): 2.773e-01\n",
      "Epoch 4900, Train loss: 4.778e+06, Test loss: 6.518e+06, MSE(e): 4.708e-01, MSE(pi1): 4.368e+00, MSE(pi2): 3.218e-01, MSE(pi3): 2.633e-01\n",
      "Epoch 5000, Train loss: 4.762e+06, Test loss: 6.505e+06, MSE(e): 4.694e-01, MSE(pi1): 4.259e+00, MSE(pi2): 3.208e-01, MSE(pi3): 2.524e-01\n",
      "Epoch 5100, Train loss: 4.746e+06, Test loss: 6.498e+06, MSE(e): 4.680e-01, MSE(pi1): 4.174e+00, MSE(pi2): 3.197e-01, MSE(pi3): 2.423e-01\n",
      "Epoch 5200, Train loss: 4.727e+06, Test loss: 6.481e+06, MSE(e): 4.663e-01, MSE(pi1): 4.064e+00, MSE(pi2): 3.183e-01, MSE(pi3): 2.337e-01\n",
      "Epoch 5300, Train loss: 4.710e+06, Test loss: 6.486e+06, MSE(e): 4.648e-01, MSE(pi1): 3.981e+00, MSE(pi2): 3.173e-01, MSE(pi3): 2.237e-01\n",
      "Epoch 5400, Train loss: 4.719e+06, Test loss: 6.492e+06, MSE(e): 4.656e-01, MSE(pi1): 4.179e+00, MSE(pi2): 3.174e-01, MSE(pi3): 2.128e-01\n",
      "Epoch 5500, Train loss: 4.661e+06, Test loss: 6.447e+06, MSE(e): 4.600e-01, MSE(pi1): 3.922e+00, MSE(pi2): 3.136e-01, MSE(pi3): 2.117e-01\n",
      "Epoch 5600, Train loss: 4.633e+06, Test loss: 6.420e+06, MSE(e): 4.575e-01, MSE(pi1): 3.725e+00, MSE(pi2): 3.116e-01, MSE(pi3): 2.068e-01\n",
      "Epoch 5700, Train loss: 4.618e+06, Test loss: 6.465e+06, MSE(e): 4.560e-01, MSE(pi1): 3.793e+00, MSE(pi2): 3.105e-01, MSE(pi3): 1.962e-01\n",
      "Epoch 5800, Train loss: 4.560e+06, Test loss: 6.371e+06, MSE(e): 4.502e-01, MSE(pi1): 3.758e+00, MSE(pi2): 3.061e-01, MSE(pi3): 1.957e-01\n",
      "Epoch 5900, Train loss: 4.494e+06, Test loss: 6.340e+06, MSE(e): 4.442e-01, MSE(pi1): 3.344e+00, MSE(pi2): 3.017e-01, MSE(pi3): 1.844e-01\n",
      "Epoch 6000, Train loss: 4.352e+06, Test loss: 6.306e+06, MSE(e): 4.302e-01, MSE(pi1): 3.204e+00, MSE(pi2): 2.912e-01, MSE(pi3): 1.760e-01\n",
      "Epoch 6100, Train loss: 1.187e+06, Test loss: 2.468e+06, MSE(e): 1.148e-01, MSE(pi1): 2.982e+00, MSE(pi2): 6.729e-02, MSE(pi3): 9.249e-02\n",
      "Epoch 6200, Train loss: 2.190e+05, Test loss: 1.232e+06, MSE(e): 2.059e-02, MSE(pi1): 8.409e-01, MSE(pi2): 1.254e-02, MSE(pi3): 4.676e-02\n",
      "Epoch 6300, Train loss: 1.472e+05, Test loss: 1.034e+06, MSE(e): 1.361e-02, MSE(pi1): 7.351e-01, MSE(pi2): 8.574e-03, MSE(pi3): 3.777e-02\n",
      "Epoch 6400, Train loss: 1.264e+05, Test loss: 9.506e+05, MSE(e): 1.111e-02, MSE(pi1): 1.169e+00, MSE(pi2): 6.823e-03, MSE(pi3): 3.638e-02\n",
      "Epoch 6500, Train loss: 9.844e+04, Test loss: 8.234e+05, MSE(e): 8.831e-03, MSE(pi1): 7.003e-01, MSE(pi2): 5.619e-03, MSE(pi3): 3.122e-02\n",
      "Epoch 6600, Train loss: 1.256e+05, Test loss: 8.601e+05, MSE(e): 1.155e-02, MSE(pi1): 7.348e-01, MSE(pi2): 6.330e-03, MSE(pi3): 2.706e-02\n",
      "Epoch 6700, Train loss: 6.682e+04, Test loss: 6.673e+05, MSE(e): 5.962e-03, MSE(pi1): 5.256e-01, MSE(pi2): 3.796e-03, MSE(pi3): 1.936e-02\n",
      "Epoch 6800, Train loss: 5.580e+04, Test loss: 6.193e+05, MSE(e): 5.057e-03, MSE(pi1): 3.319e-01, MSE(pi2): 3.192e-03, MSE(pi3): 1.907e-02\n",
      "Epoch 6900, Train loss: 5.092e+04, Test loss: 5.563e+05, MSE(e): 4.559e-03, MSE(pi1): 2.933e-01, MSE(pi2): 2.900e-03, MSE(pi3): 2.388e-02\n",
      "Epoch 7000, Train loss: 5.784e+04, Test loss: 5.645e+05, MSE(e): 4.208e-03, MSE(pi1): 1.322e+00, MSE(pi2): 2.605e-03, MSE(pi3): 2.533e-02\n",
      "Epoch 7100, Train loss: 5.032e+04, Test loss: 4.869e+05, MSE(e): 3.598e-03, MSE(pi1): 1.223e+00, MSE(pi2): 2.203e-03, MSE(pi3): 2.105e-02\n",
      "Epoch 7200, Train loss: 7.057e+04, Test loss: 4.346e+05, MSE(e): 5.365e-03, MSE(pi1): 1.569e+00, MSE(pi2): 3.192e-03, MSE(pi3): 1.234e-02\n",
      "Epoch 7300, Train loss: 5.664e+04, Test loss: 4.826e+05, MSE(e): 3.861e-03, MSE(pi1): 1.690e+00, MSE(pi2): 2.028e-03, MSE(pi3): 1.129e-02\n",
      "Epoch 7400, Train loss: 9.448e+04, Test loss: 5.236e+05, MSE(e): 6.877e-03, MSE(pi1): 2.306e+00, MSE(pi2): 3.618e-03, MSE(pi3): 2.643e-02\n",
      "Epoch 7500, Train loss: 1.417e+05, Test loss: 6.000e+05, MSE(e): 1.234e-02, MSE(pi1): 1.617e+00, MSE(pi2): 5.798e-03, MSE(pi3): 2.069e-02\n",
      "Epoch 7600, Train loss: 2.652e+04, Test loss: 3.480e+05, MSE(e): 2.330e-03, MSE(pi1): 2.124e-01, MSE(pi2): 1.413e-03, MSE(pi3): 1.103e-02\n",
      "Epoch 7700, Train loss: 6.251e+04, Test loss: 4.185e+05, MSE(e): 5.906e-03, MSE(pi1): 1.990e-01, MSE(pi2): 2.905e-03, MSE(pi3): 1.455e-02\n",
      "Epoch 7800, Train loss: 3.010e+04, Test loss: 3.503e+05, MSE(e): 2.386e-03, MSE(pi1): 3.953e-01, MSE(pi2): 1.542e-03, MSE(pi3): 2.283e-02\n",
      "Epoch 7900, Train loss: 2.716e+04, Test loss: 3.235e+05, MSE(e): 1.772e-03, MSE(pi1): 7.909e-01, MSE(pi2): 1.083e-03, MSE(pi3): 1.534e-02\n",
      "Epoch 8000, Train loss: 2.336e+04, Test loss: 2.977e+05, MSE(e): 2.039e-03, MSE(pi1): 1.970e-01, MSE(pi2): 1.206e-03, MSE(pi3): 1.006e-02\n",
      "Epoch 8100, Train loss: 4.051e+04, Test loss: 3.014e+05, MSE(e): 3.344e-03, MSE(pi1): 5.703e-01, MSE(pi2): 1.827e-03, MSE(pi3): 1.366e-02\n",
      "Epoch 8200, Train loss: 1.725e+04, Test loss: 2.838e+05, MSE(e): 1.501e-03, MSE(pi1): 1.354e-01, MSE(pi2): 9.237e-04, MSE(pi3): 8.916e-03\n",
      "Epoch 8300, Train loss: 1.793e+04, Test loss: 2.614e+05, MSE(e): 1.484e-03, MSE(pi1): 2.387e-01, MSE(pi2): 9.420e-04, MSE(pi3): 7.015e-03\n",
      "Epoch 8400, Train loss: 3.989e+04, Test loss: 2.924e+05, MSE(e): 3.369e-03, MSE(pi1): 4.338e-01, MSE(pi2): 2.181e-03, MSE(pi3): 1.855e-02\n",
      "Epoch 8500, Train loss: 1.943e+04, Test loss: 2.415e+05, MSE(e): 1.412e-03, MSE(pi1): 4.636e-01, MSE(pi2): 9.064e-04, MSE(pi3): 6.675e-03\n",
      "Epoch 8600, Train loss: 5.683e+04, Test loss: 2.889e+05, MSE(e): 5.230e-03, MSE(pi1): 2.396e-01, MSE(pi2): 2.825e-03, MSE(pi3): 2.128e-02\n",
      "Epoch 8700, Train loss: 2.154e+04, Test loss: 2.510e+05, MSE(e): 1.838e-03, MSE(pi1): 2.289e-01, MSE(pi2): 9.931e-04, MSE(pi3): 8.765e-03\n",
      "Epoch 8800, Train loss: 2.968e+04, Test loss: 2.383e+05, MSE(e): 2.690e-03, MSE(pi1): 1.955e-01, MSE(pi2): 1.414e-03, MSE(pi3): 8.194e-03\n",
      "Epoch 8900, Train loss: 4.327e+04, Test loss: 2.560e+05, MSE(e): 4.126e-03, MSE(pi1): 1.434e-01, MSE(pi2): 1.988e-03, MSE(pi3): 5.779e-03\n",
      "Epoch 9000, Train loss: 1.653e+04, Test loss: 2.249e+05, MSE(e): 1.108e-03, MSE(pi1): 4.665e-01, MSE(pi2): 7.042e-04, MSE(pi3): 7.786e-03\n",
      "Epoch 9100, Train loss: 1.312e+04, Test loss: 2.235e+05, MSE(e): 9.709e-04, MSE(pi1): 2.734e-01, MSE(pi2): 5.978e-04, MSE(pi3): 6.779e-03\n",
      "Epoch 9200, Train loss: 1.452e+04, Test loss: 2.124e+05, MSE(e): 1.113e-03, MSE(pi1): 2.787e-01, MSE(pi2): 7.169e-04, MSE(pi3): 6.019e-03\n",
      "Epoch 9300, Train loss: 1.908e+04, Test loss: 2.166e+05, MSE(e): 1.640e-03, MSE(pi1): 2.055e-01, MSE(pi2): 8.683e-04, MSE(pi3): 6.166e-03\n",
      "Epoch 9400, Train loss: 1.447e+04, Test loss: 2.118e+05, MSE(e): 1.077e-03, MSE(pi1): 3.142e-01, MSE(pi2): 6.243e-04, MSE(pi3): 5.518e-03\n",
      "Epoch 9500, Train loss: 1.261e+04, Test loss: 2.149e+05, MSE(e): 9.044e-04, MSE(pi1): 2.828e-01, MSE(pi2): 5.578e-04, MSE(pi3): 7.333e-03\n",
      "Epoch 9600, Train loss: 1.078e+04, Test loss: 2.001e+05, MSE(e): 9.164e-04, MSE(pi1): 1.084e-01, MSE(pi2): 5.586e-04, MSE(pi3): 5.307e-03\n",
      "Epoch 9700, Train loss: 6.955e+04, Test loss: 2.820e+05, MSE(e): 2.864e-03, MSE(pi1): 4.024e+00, MSE(pi2): 1.629e-03, MSE(pi3): 6.664e-03\n",
      "Epoch 9800, Train loss: 1.063e+04, Test loss: 2.008e+05, MSE(e): 7.824e-04, MSE(pi1): 2.135e-01, MSE(pi2): 4.819e-04, MSE(pi3): 6.709e-03\n",
      "Epoch 9900, Train loss: 1.002e+04, Test loss: 1.952e+05, MSE(e): 7.743e-04, MSE(pi1): 1.582e-01, MSE(pi2): 4.824e-04, MSE(pi3): 6.921e-03\n",
      "Epoch 10000, Train loss: 2.155e+04, Test loss: 2.205e+05, MSE(e): 1.844e-03, MSE(pi1): 2.067e-01, MSE(pi2): 9.876e-04, MSE(pi3): 1.040e-02\n",
      "Epoch 10100, Train loss: 3.014e+04, Test loss: 2.127e+05, MSE(e): 2.695e-03, MSE(pi1): 2.553e-01, MSE(pi2): 1.449e-03, MSE(pi3): 6.298e-03\n",
      "Epoch 10200, Train loss: 1.199e+04, Test loss: 2.080e+05, MSE(e): 8.046e-04, MSE(pi1): 2.650e-01, MSE(pi2): 5.039e-04, MSE(pi3): 1.295e-02\n",
      "Epoch 10300, Train loss: 1.439e+04, Test loss: 2.036e+05, MSE(e): 1.099e-03, MSE(pi1): 2.632e-01, MSE(pi2): 6.125e-04, MSE(pi3): 7.658e-03\n",
      "Epoch 10400, Train loss: 9.275e+03, Test loss: 1.880e+05, MSE(e): 7.489e-04, MSE(pi1): 1.144e-01, MSE(pi2): 4.475e-04, MSE(pi3): 6.417e-03\n",
      "Epoch 10500, Train loss: 9.284e+04, Test loss: 2.978e+05, MSE(e): 8.606e-03, MSE(pi1): 5.139e-01, MSE(pi2): 3.799e-03, MSE(pi3): 1.644e-02\n",
      "Epoch 10600, Train loss: 2.389e+04, Test loss: 2.014e+05, MSE(e): 1.960e-03, MSE(pi1): 3.837e-01, MSE(pi2): 1.054e-03, MSE(pi3): 4.524e-03\n",
      "Epoch 10700, Train loss: 2.407e+04, Test loss: 2.154e+05, MSE(e): 1.075e-03, MSE(pi1): 1.260e+00, MSE(pi2): 6.164e-04, MSE(pi3): 7.228e-03\n",
      "Epoch 10800, Train loss: 1.181e+04, Test loss: 1.744e+05, MSE(e): 7.877e-04, MSE(pi1): 3.199e-01, MSE(pi2): 4.931e-04, MSE(pi3): 7.297e-03\n",
      "Epoch 10900, Train loss: 8.409e+03, Test loss: 1.769e+05, MSE(e): 6.654e-04, MSE(pi1): 1.190e-01, MSE(pi2): 4.155e-04, MSE(pi3): 5.650e-03\n",
      "Epoch 11000, Train loss: 2.759e+04, Test loss: 2.127e+05, MSE(e): 1.994e-03, MSE(pi1): 5.645e-01, MSE(pi2): 1.251e-03, MSE(pi3): 2.001e-02\n",
      "Epoch 11100, Train loss: 1.072e+04, Test loss: 1.864e+05, MSE(e): 8.651e-04, MSE(pi1): 1.163e-01, MSE(pi2): 4.808e-04, MSE(pi3): 9.043e-03\n",
      "Epoch 11200, Train loss: 1.331e+04, Test loss: 1.808e+05, MSE(e): 7.361e-04, MSE(pi1): 4.853e-01, MSE(pi2): 4.301e-04, MSE(pi3): 1.094e-02\n",
      "Epoch 11300, Train loss: 5.472e+04, Test loss: 2.397e+05, MSE(e): 4.985e-03, MSE(pi1): 2.794e-01, MSE(pi2): 2.421e-03, MSE(pi3): 2.075e-02\n",
      "Epoch 11400, Train loss: 2.269e+04, Test loss: 1.678e+05, MSE(e): 1.606e-03, MSE(pi1): 6.138e-01, MSE(pi2): 9.167e-04, MSE(pi3): 4.909e-03\n",
      "Epoch 11500, Train loss: 1.988e+04, Test loss: 2.028e+05, MSE(e): 8.877e-04, MSE(pi1): 9.916e-01, MSE(pi2): 5.444e-04, MSE(pi3): 1.088e-02\n",
      "Epoch 11600, Train loss: 7.535e+03, Test loss: 1.709e+05, MSE(e): 5.892e-04, MSE(pi1): 1.136e-01, MSE(pi2): 3.607e-04, MSE(pi3): 5.062e-03\n",
      "Epoch 11700, Train loss: 1.583e+04, Test loss: 1.749e+05, MSE(e): 1.025e-03, MSE(pi1): 3.778e-01, MSE(pi2): 6.282e-04, MSE(pi3): 1.795e-02\n",
      "Epoch 11800, Train loss: 1.643e+04, Test loss: 1.854e+05, MSE(e): 1.051e-03, MSE(pi1): 3.804e-01, MSE(pi2): 7.120e-04, MSE(pi3): 2.121e-02\n",
      "Epoch 11900, Train loss: 8.408e+04, Test loss: 2.805e+05, MSE(e): 7.769e-03, MSE(pi1): 5.337e-01, MSE(pi2): 3.743e-03, MSE(pi3): 1.040e-02\n",
      "Epoch 12000, Train loss: 1.751e+04, Test loss: 1.812e+05, MSE(e): 1.312e-03, MSE(pi1): 3.388e-01, MSE(pi2): 6.210e-04, MSE(pi3): 9.964e-03\n",
      "Epoch 12100, Train loss: 7.334e+03, Test loss: 1.642e+05, MSE(e): 5.670e-04, MSE(pi1): 9.963e-02, MSE(pi2): 3.428e-04, MSE(pi3): 6.676e-03\n",
      "Epoch 12200, Train loss: 8.422e+03, Test loss: 1.610e+05, MSE(e): 6.767e-04, MSE(pi1): 1.033e-01, MSE(pi2): 4.424e-04, MSE(pi3): 6.219e-03\n",
      "Epoch 12300, Train loss: 6.058e+03, Test loss: 1.612e+05, MSE(e): 5.015e-04, MSE(pi1): 4.781e-02, MSE(pi2): 3.135e-04, MSE(pi3): 5.642e-03\n",
      "Epoch 12400, Train loss: 9.499e+03, Test loss: 1.682e+05, MSE(e): 7.804e-04, MSE(pi1): 1.040e-01, MSE(pi2): 4.387e-04, MSE(pi3): 6.544e-03\n",
      "Epoch 12500, Train loss: 8.605e+03, Test loss: 1.536e+05, MSE(e): 6.744e-04, MSE(pi1): 1.321e-01, MSE(pi2): 4.244e-04, MSE(pi3): 5.396e-03\n",
      "Epoch 12600, Train loss: 7.316e+03, Test loss: 1.639e+05, MSE(e): 6.174e-04, MSE(pi1): 4.694e-02, MSE(pi2): 3.950e-04, MSE(pi3): 6.725e-03\n",
      "Epoch 12700, Train loss: 5.686e+04, Test loss: 2.376e+05, MSE(e): 4.823e-03, MSE(pi1): 7.408e-01, MSE(pi2): 2.253e-03, MSE(pi3): 1.220e-02\n",
      "Epoch 12800, Train loss: 1.650e+05, Test loss: 3.090e+05, MSE(e): 1.592e-02, MSE(pi1): 2.243e-01, MSE(pi2): 6.873e-03, MSE(pi3): 3.558e-02\n",
      "Epoch 12900, Train loss: 8.525e+03, Test loss: 1.607e+05, MSE(e): 6.959e-04, MSE(pi1): 9.692e-02, MSE(pi2): 4.319e-04, MSE(pi3): 5.967e-03\n",
      "Epoch 13000, Train loss: 1.422e+04, Test loss: 1.683e+05, MSE(e): 1.241e-03, MSE(pi1): 1.057e-01, MSE(pi2): 6.261e-04, MSE(pi3): 7.528e-03\n",
      "Epoch 13100, Train loss: 1.669e+04, Test loss: 1.706e+05, MSE(e): 6.680e-04, MSE(pi1): 7.827e-01, MSE(pi2): 4.109e-04, MSE(pi3): 2.183e-02\n",
      "Epoch 13200, Train loss: 9.976e+03, Test loss: 1.542e+05, MSE(e): 8.653e-04, MSE(pi1): 5.715e-02, MSE(pi2): 5.514e-04, MSE(pi3): 7.508e-03\n",
      "Epoch 13300, Train loss: 4.074e+04, Test loss: 1.993e+05, MSE(e): 3.833e-03, MSE(pi1): 1.323e-01, MSE(pi2): 2.382e-03, MSE(pi3): 1.085e-02\n",
      "Epoch 13400, Train loss: 7.806e+03, Test loss: 1.569e+05, MSE(e): 6.197e-04, MSE(pi1): 8.248e-02, MSE(pi2): 3.815e-04, MSE(pi3): 7.841e-03\n",
      "Epoch 13500, Train loss: 1.063e+04, Test loss: 1.534e+05, MSE(e): 9.557e-04, MSE(pi1): 4.962e-02, MSE(pi2): 5.501e-04, MSE(pi3): 5.780e-03\n",
      "Epoch 13600, Train loss: 1.351e+04, Test loss: 1.681e+05, MSE(e): 7.113e-04, MSE(pi1): 5.866e-01, MSE(pi2): 4.094e-04, MSE(pi3): 5.292e-03\n",
      "Epoch 13700, Train loss: 1.804e+04, Test loss: 1.569e+05, MSE(e): 8.116e-04, MSE(pi1): 9.423e-01, MSE(pi2): 5.440e-04, MSE(pi3): 5.037e-03\n",
      "Epoch 13800, Train loss: 4.143e+04, Test loss: 2.129e+05, MSE(e): 3.924e-03, MSE(pi1): 9.695e-02, MSE(pi2): 1.802e-03, MSE(pi3): 1.219e-02\n",
      "Epoch 13900, Train loss: 1.223e+04, Test loss: 1.602e+05, MSE(e): 9.815e-04, MSE(pi1): 1.771e-01, MSE(pi2): 5.791e-04, MSE(pi3): 6.419e-03\n",
      "Epoch 14000, Train loss: 3.596e+04, Test loss: 1.972e+05, MSE(e): 2.840e-03, MSE(pi1): 5.174e-01, MSE(pi2): 1.237e-03, MSE(pi3): 2.383e-02\n",
      "Epoch 14100, Train loss: 1.097e+04, Test loss: 1.551e+05, MSE(e): 9.887e-04, MSE(pi1): 5.356e-02, MSE(pi2): 5.968e-04, MSE(pi3): 5.415e-03\n",
      "Epoch 14200, Train loss: 8.522e+03, Test loss: 1.598e+05, MSE(e): 4.923e-04, MSE(pi1): 2.970e-01, MSE(pi2): 2.819e-04, MSE(pi3): 6.286e-03\n",
      "Epoch 14300, Train loss: 5.740e+03, Test loss: 1.498e+05, MSE(e): 4.387e-04, MSE(pi1): 5.816e-02, MSE(pi2): 2.745e-04, MSE(pi3): 7.707e-03\n",
      "Epoch 14400, Train loss: 8.819e+03, Test loss: 1.491e+05, MSE(e): 6.689e-04, MSE(pi1): 1.426e-01, MSE(pi2): 3.998e-04, MSE(pi3): 7.026e-03\n",
      "Epoch 14500, Train loss: 1.545e+04, Test loss: 1.722e+05, MSE(e): 6.895e-04, MSE(pi1): 7.586e-01, MSE(pi2): 4.395e-04, MSE(pi3): 9.665e-03\n",
      "Epoch 14600, Train loss: 2.964e+04, Test loss: 1.801e+05, MSE(e): 2.725e-03, MSE(pi1): 1.195e-01, MSE(pi2): 1.896e-03, MSE(pi3): 1.189e-02\n",
      "Epoch 14700, Train loss: 1.038e+04, Test loss: 1.442e+05, MSE(e): 6.879e-04, MSE(pi1): 2.766e-01, MSE(pi2): 4.495e-04, MSE(pi3): 7.361e-03\n",
      "Epoch 14800, Train loss: 1.398e+04, Test loss: 1.452e+05, MSE(e): 1.063e-03, MSE(pi1): 2.404e-01, MSE(pi2): 5.589e-04, MSE(pi3): 9.489e-03\n",
      "Epoch 14900, Train loss: 1.513e+04, Test loss: 1.630e+05, MSE(e): 7.365e-04, MSE(pi1): 7.251e-01, MSE(pi2): 3.785e-04, MSE(pi3): 5.167e-03\n",
      "Epoch 15000, Train loss: 1.158e+04, Test loss: 1.493e+05, MSE(e): 7.204e-04, MSE(pi1): 3.715e-01, MSE(pi2): 4.064e-04, MSE(pi3): 6.576e-03\n",
      "Epoch 15100, Train loss: 1.491e+04, Test loss: 1.641e+05, MSE(e): 5.726e-04, MSE(pi1): 8.364e-01, MSE(pi2): 3.581e-04, MSE(pi3): 8.214e-03\n",
      "Epoch 15200, Train loss: 5.421e+04, Test loss: 2.497e+05, MSE(e): 4.369e-03, MSE(pi1): 9.131e-01, MSE(pi2): 1.981e-03, MSE(pi3): 1.393e-02\n",
      "Epoch 15300, Train loss: 8.245e+03, Test loss: 1.443e+05, MSE(e): 3.981e-04, MSE(pi1): 3.390e-01, MSE(pi2): 2.376e-04, MSE(pi3): 8.746e-03\n",
      "Epoch 15400, Train loss: 7.707e+03, Test loss: 1.453e+05, MSE(e): 6.716e-04, MSE(pi1): 3.757e-02, MSE(pi2): 3.612e-04, MSE(pi3): 6.151e-03\n",
      "Epoch 15500, Train loss: 1.347e+04, Test loss: 1.648e+05, MSE(e): 8.662e-04, MSE(pi1): 2.908e-01, MSE(pi2): 5.787e-04, MSE(pi3): 1.900e-02\n",
      "Epoch 15600, Train loss: 2.475e+04, Test loss: 1.635e+05, MSE(e): 9.031e-04, MSE(pi1): 1.496e+00, MSE(pi2): 5.070e-04, MSE(pi3): 7.551e-03\n",
      "Epoch 15700, Train loss: 5.875e+03, Test loss: 1.474e+05, MSE(e): 4.587e-04, MSE(pi1): 6.621e-02, MSE(pi2): 2.742e-04, MSE(pi3): 6.253e-03\n",
      "Epoch 15800, Train loss: 2.920e+04, Test loss: 1.556e+05, MSE(e): 2.551e-03, MSE(pi1): 1.760e-01, MSE(pi2): 1.834e-03, MSE(pi3): 1.934e-02\n",
      "Epoch 15900, Train loss: 6.334e+04, Test loss: 1.823e+05, MSE(e): 2.086e-03, MSE(pi1): 4.183e+00, MSE(pi2): 1.192e-03, MSE(pi3): 6.507e-03\n",
      "Epoch 16000, Train loss: 6.337e+03, Test loss: 1.428e+05, MSE(e): 4.433e-04, MSE(pi1): 1.317e-01, MSE(pi2): 2.597e-04, MSE(pi3): 5.865e-03\n",
      "Epoch 16100, Train loss: 1.018e+04, Test loss: 1.541e+05, MSE(e): 8.149e-04, MSE(pi1): 1.118e-01, MSE(pi2): 5.588e-04, MSE(pi3): 9.100e-03\n",
      "Epoch 16200, Train loss: 1.786e+04, Test loss: 1.519e+05, MSE(e): 7.215e-04, MSE(pi1): 7.881e-01, MSE(pi2): 4.154e-04, MSE(pi3): 2.765e-02\n",
      "Epoch 16300, Train loss: 2.202e+04, Test loss: 1.615e+05, MSE(e): 1.311e-03, MSE(pi1): 8.197e-01, MSE(pi2): 6.920e-04, MSE(pi3): 7.109e-03\n",
      "Epoch 16400, Train loss: 1.246e+04, Test loss: 1.638e+05, MSE(e): 6.233e-04, MSE(pi1): 5.288e-01, MSE(pi2): 3.600e-04, MSE(pi3): 9.380e-03\n",
      "Epoch 16500, Train loss: 7.467e+03, Test loss: 1.355e+05, MSE(e): 4.144e-04, MSE(pi1): 2.309e-01, MSE(pi2): 2.663e-04, MSE(pi3): 1.015e-02\n",
      "Epoch 16600, Train loss: 4.397e+03, Test loss: 1.374e+05, MSE(e): 3.299e-04, MSE(pi1): 5.559e-02, MSE(pi2): 2.066e-04, MSE(pi3): 5.419e-03\n",
      "Epoch 16700, Train loss: 6.441e+03, Test loss: 1.347e+05, MSE(e): 4.908e-04, MSE(pi1): 1.017e-01, MSE(pi2): 3.304e-04, MSE(pi3): 5.152e-03\n",
      "Epoch 16800, Train loss: 6.740e+03, Test loss: 1.358e+05, MSE(e): 3.735e-04, MSE(pi1): 2.498e-01, MSE(pi2): 2.411e-04, MSE(pi3): 5.069e-03\n",
      "Epoch 16900, Train loss: 3.041e+04, Test loss: 1.575e+05, MSE(e): 8.850e-04, MSE(pi1): 2.105e+00, MSE(pi2): 6.040e-04, MSE(pi3): 5.112e-03\n",
      "Epoch 17000, Train loss: 5.915e+03, Test loss: 1.494e+05, MSE(e): 4.171e-04, MSE(pi1): 1.023e-01, MSE(pi2): 2.417e-04, MSE(pi3): 7.214e-03\n",
      "Epoch 17100, Train loss: 1.933e+04, Test loss: 1.490e+05, MSE(e): 1.329e-03, MSE(pi1): 4.710e-01, MSE(pi2): 8.961e-04, MSE(pi3): 1.336e-02\n",
      "Epoch 17200, Train loss: 7.627e+03, Test loss: 1.502e+05, MSE(e): 4.039e-04, MSE(pi1): 2.945e-01, MSE(pi2): 2.477e-04, MSE(pi3): 6.431e-03\n",
      "Epoch 17300, Train loss: 6.344e+03, Test loss: 1.396e+05, MSE(e): 5.203e-04, MSE(pi1): 5.437e-02, MSE(pi2): 3.432e-04, MSE(pi3): 5.965e-03\n",
      "Epoch 17400, Train loss: 4.532e+03, Test loss: 1.387e+05, MSE(e): 3.257e-04, MSE(pi1): 6.157e-02, MSE(pi2): 1.976e-04, MSE(pi3): 6.598e-03\n",
      "Epoch 17500, Train loss: 1.287e+04, Test loss: 1.423e+05, MSE(e): 5.188e-04, MSE(pi1): 7.215e-01, MSE(pi2): 3.259e-04, MSE(pi3): 4.619e-03\n",
      "Epoch 17600, Train loss: 9.519e+03, Test loss: 1.478e+05, MSE(e): 7.454e-04, MSE(pi1): 1.383e-01, MSE(pi2): 4.693e-04, MSE(pi3): 6.814e-03\n",
      "Epoch 17700, Train loss: 5.244e+03, Test loss: 1.393e+05, MSE(e): 3.663e-04, MSE(pi1): 8.929e-02, MSE(pi2): 2.197e-04, MSE(pi3): 6.871e-03\n",
      "Epoch 17800, Train loss: 3.507e+04, Test loss: 1.473e+05, MSE(e): 7.258e-04, MSE(pi1): 2.725e+00, MSE(pi2): 3.472e-04, MSE(pi3): 5.647e-03\n",
      "Epoch 17900, Train loss: 5.483e+03, Test loss: 1.350e+05, MSE(e): 4.571e-04, MSE(pi1): 3.674e-02, MSE(pi2): 3.012e-04, MSE(pi3): 5.444e-03\n",
      "Epoch 18000, Train loss: 2.405e+04, Test loss: 1.555e+05, MSE(e): 2.265e-03, MSE(pi1): 7.686e-02, MSE(pi2): 1.410e-03, MSE(pi3): 6.259e-03\n",
      "Epoch 18100, Train loss: 1.067e+04, Test loss: 1.299e+05, MSE(e): 8.028e-04, MSE(pi1): 2.129e-01, MSE(pi2): 5.250e-04, MSE(pi3): 5.155e-03\n",
      "Epoch 18200, Train loss: 1.995e+04, Test loss: 1.376e+05, MSE(e): 1.068e-03, MSE(pi1): 4.930e-01, MSE(pi2): 6.968e-04, MSE(pi3): 4.334e-02\n",
      "Epoch 18300, Train loss: 6.045e+03, Test loss: 1.358e+05, MSE(e): 4.516e-04, MSE(pi1): 1.008e-01, MSE(pi2): 2.957e-04, MSE(pi3): 5.209e-03\n",
      "Epoch 18400, Train loss: 3.801e+04, Test loss: 1.784e+05, MSE(e): 3.198e-03, MSE(pi1): 3.441e-01, MSE(pi2): 2.142e-03, MSE(pi3): 2.588e-02\n",
      "Epoch 18500, Train loss: 1.561e+04, Test loss: 1.489e+05, MSE(e): 1.000e-03, MSE(pi1): 4.788e-01, MSE(pi2): 6.895e-04, MSE(pi3): 8.178e-03\n",
      "Epoch 18600, Train loss: 4.498e+03, Test loss: 1.351e+05, MSE(e): 3.404e-04, MSE(pi1): 4.779e-02, MSE(pi2): 2.018e-04, MSE(pi3): 6.162e-03\n",
      "Epoch 18700, Train loss: 1.217e+04, Test loss: 1.408e+05, MSE(e): 4.060e-04, MSE(pi1): 7.215e-01, MSE(pi2): 2.048e-04, MSE(pi3): 8.955e-03\n",
      "Epoch 18800, Train loss: 4.266e+04, Test loss: 2.024e+05, MSE(e): 7.311e-04, MSE(pi1): 3.474e+00, MSE(pi2): 3.937e-04, MSE(pi3): 6.072e-03\n",
      "Epoch 18900, Train loss: 6.412e+03, Test loss: 1.388e+05, MSE(e): 4.203e-04, MSE(pi1): 1.241e-01, MSE(pi2): 2.774e-04, MSE(pi3): 9.672e-03\n",
      "Epoch 19000, Train loss: 1.371e+04, Test loss: 1.574e+05, MSE(e): 4.105e-04, MSE(pi1): 8.757e-01, MSE(pi2): 2.454e-04, MSE(pi3): 8.524e-03\n",
      "Epoch 19100, Train loss: 8.407e+03, Test loss: 1.441e+05, MSE(e): 5.112e-04, MSE(pi1): 2.286e-01, MSE(pi2): 2.964e-04, MSE(pi3): 1.008e-02\n",
      "Epoch 19200, Train loss: 3.702e+03, Test loss: 1.281e+05, MSE(e): 2.857e-04, MSE(pi1): 3.017e-02, MSE(pi2): 1.736e-04, MSE(pi3): 5.432e-03\n",
      "Epoch 19300, Train loss: 3.281e+04, Test loss: 1.632e+05, MSE(e): 7.925e-04, MSE(pi1): 2.410e+00, MSE(pi2): 4.930e-04, MSE(pi3): 7.795e-03\n",
      "Epoch 19400, Train loss: 7.939e+03, Test loss: 1.347e+05, MSE(e): 6.408e-04, MSE(pi1): 9.696e-02, MSE(pi2): 3.758e-04, MSE(pi3): 5.616e-03\n",
      "Epoch 19500, Train loss: 1.873e+05, Test loss: 2.657e+05, MSE(e): 1.799e-02, MSE(pi1): 6.948e-01, MSE(pi2): 7.918e-03, MSE(pi3): 4.487e-03\n",
      "Epoch 19600, Train loss: 3.628e+04, Test loss: 1.793e+05, MSE(e): 8.250e-04, MSE(pi1): 2.737e+00, MSE(pi2): 5.506e-04, MSE(pi3): 6.601e-03\n",
      "Epoch 19700, Train loss: 5.034e+03, Test loss: 1.311e+05, MSE(e): 3.407e-04, MSE(pi1): 9.001e-02, MSE(pi2): 2.141e-04, MSE(pi3): 7.264e-03\n",
      "Epoch 19800, Train loss: 7.927e+03, Test loss: 1.330e+05, MSE(e): 6.237e-04, MSE(pi1): 1.105e-01, MSE(pi2): 4.301e-04, MSE(pi3): 5.851e-03\n",
      "Epoch 19900, Train loss: 2.165e+04, Test loss: 1.314e+05, MSE(e): 9.020e-04, MSE(pi1): 1.198e+00, MSE(pi2): 6.622e-04, MSE(pi3): 6.503e-03\n",
      "\n",
      "Training process finished after 20000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = BaselineNonlinearModel(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 20000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 18000.\n",
      "Epoch 18000, Train loss: 1.879e+04, Test loss: 1.473e+05, MSE(e): 1.755e-03, MSE(pi1): 5.840e-02, MSE(pi2): 1.257e-03, MSE(pi3): 6.612e-03\n",
      "Epoch 18100, Train loss: 3.605e+03, Test loss: 1.334e+05, MSE(e): 2.849e-04, MSE(pi1): 1.855e-02, MSE(pi2): 1.774e-04, MSE(pi3): 5.709e-03\n",
      "Epoch 18200, Train loss: 3.589e+03, Test loss: 1.331e+05, MSE(e): 2.835e-04, MSE(pi1): 1.856e-02, MSE(pi2): 1.766e-04, MSE(pi3): 5.686e-03\n",
      "Epoch 18300, Train loss: 3.579e+03, Test loss: 1.329e+05, MSE(e): 2.825e-04, MSE(pi1): 1.851e-02, MSE(pi2): 1.760e-04, MSE(pi3): 5.684e-03\n",
      "Epoch 18400, Train loss: 3.570e+03, Test loss: 1.328e+05, MSE(e): 2.817e-04, MSE(pi1): 1.845e-02, MSE(pi2): 1.756e-04, MSE(pi3): 5.687e-03\n",
      "Epoch 18500, Train loss: 3.562e+03, Test loss: 1.326e+05, MSE(e): 2.809e-04, MSE(pi1): 1.839e-02, MSE(pi2): 1.751e-04, MSE(pi3): 5.689e-03\n",
      "Epoch 18600, Train loss: 3.555e+03, Test loss: 1.325e+05, MSE(e): 2.802e-04, MSE(pi1): 1.834e-02, MSE(pi2): 1.747e-04, MSE(pi3): 5.691e-03\n",
      "Epoch 18700, Train loss: 3.547e+03, Test loss: 1.323e+05, MSE(e): 2.795e-04, MSE(pi1): 1.829e-02, MSE(pi2): 1.742e-04, MSE(pi3): 5.692e-03\n",
      "Epoch 18800, Train loss: 3.540e+03, Test loss: 1.322e+05, MSE(e): 2.788e-04, MSE(pi1): 1.825e-02, MSE(pi2): 1.738e-04, MSE(pi3): 5.693e-03\n",
      "Epoch 18900, Train loss: 3.532e+03, Test loss: 1.320e+05, MSE(e): 2.780e-04, MSE(pi1): 1.822e-02, MSE(pi2): 1.734e-04, MSE(pi3): 5.695e-03\n",
      "Epoch 19000, Train loss: 3.524e+03, Test loss: 1.319e+05, MSE(e): 2.773e-04, MSE(pi1): 1.818e-02, MSE(pi2): 1.729e-04, MSE(pi3): 5.696e-03\n",
      "Epoch 19100, Train loss: 3.517e+03, Test loss: 1.317e+05, MSE(e): 2.765e-04, MSE(pi1): 1.815e-02, MSE(pi2): 1.725e-04, MSE(pi3): 5.697e-03\n",
      "Epoch 19200, Train loss: 3.508e+03, Test loss: 1.315e+05, MSE(e): 2.757e-04, MSE(pi1): 1.811e-02, MSE(pi2): 1.720e-04, MSE(pi3): 5.697e-03\n",
      "Epoch 19300, Train loss: 3.500e+03, Test loss: 1.314e+05, MSE(e): 2.749e-04, MSE(pi1): 1.808e-02, MSE(pi2): 1.715e-04, MSE(pi3): 5.698e-03\n",
      "Epoch 19400, Train loss: 3.492e+03, Test loss: 1.312e+05, MSE(e): 2.741e-04, MSE(pi1): 1.805e-02, MSE(pi2): 1.710e-04, MSE(pi3): 5.699e-03\n",
      "Epoch 19500, Train loss: 3.483e+03, Test loss: 1.310e+05, MSE(e): 2.733e-04, MSE(pi1): 1.802e-02, MSE(pi2): 1.705e-04, MSE(pi3): 5.699e-03\n",
      "Epoch 19600, Train loss: 3.474e+03, Test loss: 1.308e+05, MSE(e): 2.724e-04, MSE(pi1): 1.799e-02, MSE(pi2): 1.699e-04, MSE(pi3): 5.699e-03\n",
      "Epoch 19700, Train loss: 3.464e+03, Test loss: 1.306e+05, MSE(e): 2.715e-04, MSE(pi1): 1.796e-02, MSE(pi2): 1.693e-04, MSE(pi3): 5.700e-03\n",
      "Epoch 19800, Train loss: 3.454e+03, Test loss: 1.304e+05, MSE(e): 2.705e-04, MSE(pi1): 1.793e-02, MSE(pi2): 1.688e-04, MSE(pi3): 5.700e-03\n",
      "Epoch 19900, Train loss: 3.444e+03, Test loss: 1.302e+05, MSE(e): 2.695e-04, MSE(pi1): 1.790e-02, MSE(pi2): 1.681e-04, MSE(pi3): 5.700e-03\n",
      "Epoch 20000, Train loss: 3.434e+03, Test loss: 1.300e+05, MSE(e): 2.685e-04, MSE(pi1): 1.787e-02, MSE(pi2): 1.675e-04, MSE(pi3): 5.700e-03\n",
      "Epoch 20100, Train loss: 3.423e+03, Test loss: 1.298e+05, MSE(e): 2.675e-04, MSE(pi1): 1.784e-02, MSE(pi2): 1.669e-04, MSE(pi3): 5.700e-03\n",
      "Epoch 20200, Train loss: 3.412e+03, Test loss: 1.295e+05, MSE(e): 2.664e-04, MSE(pi1): 1.780e-02, MSE(pi2): 1.662e-04, MSE(pi3): 5.700e-03\n",
      "Epoch 20300, Train loss: 3.400e+03, Test loss: 1.293e+05, MSE(e): 2.652e-04, MSE(pi1): 1.777e-02, MSE(pi2): 1.655e-04, MSE(pi3): 5.700e-03\n",
      "Epoch 20400, Train loss: 3.388e+03, Test loss: 1.290e+05, MSE(e): 2.641e-04, MSE(pi1): 1.774e-02, MSE(pi2): 1.648e-04, MSE(pi3): 5.700e-03\n",
      "Epoch 20500, Train loss: 3.375e+03, Test loss: 1.288e+05, MSE(e): 2.628e-04, MSE(pi1): 1.771e-02, MSE(pi2): 1.640e-04, MSE(pi3): 5.699e-03\n",
      "Epoch 20600, Train loss: 3.363e+03, Test loss: 1.285e+05, MSE(e): 2.616e-04, MSE(pi1): 1.767e-02, MSE(pi2): 1.632e-04, MSE(pi3): 5.699e-03\n",
      "Epoch 20700, Train loss: 3.349e+03, Test loss: 1.282e+05, MSE(e): 2.603e-04, MSE(pi1): 1.764e-02, MSE(pi2): 1.624e-04, MSE(pi3): 5.699e-03\n",
      "Epoch 20800, Train loss: 3.335e+03, Test loss: 1.280e+05, MSE(e): 2.589e-04, MSE(pi1): 1.760e-02, MSE(pi2): 1.615e-04, MSE(pi3): 5.698e-03\n",
      "Epoch 20900, Train loss: 3.321e+03, Test loss: 1.277e+05, MSE(e): 2.575e-04, MSE(pi1): 1.757e-02, MSE(pi2): 1.607e-04, MSE(pi3): 5.698e-03\n",
      "Epoch 21000, Train loss: 3.306e+03, Test loss: 1.273e+05, MSE(e): 2.561e-04, MSE(pi1): 1.753e-02, MSE(pi2): 1.598e-04, MSE(pi3): 5.697e-03\n",
      "Epoch 21100, Train loss: 3.290e+03, Test loss: 1.270e+05, MSE(e): 2.546e-04, MSE(pi1): 1.749e-02, MSE(pi2): 1.588e-04, MSE(pi3): 5.697e-03\n",
      "Epoch 21200, Train loss: 3.274e+03, Test loss: 1.267e+05, MSE(e): 2.530e-04, MSE(pi1): 1.745e-02, MSE(pi2): 1.578e-04, MSE(pi3): 5.696e-03\n",
      "Epoch 21300, Train loss: 3.258e+03, Test loss: 1.264e+05, MSE(e): 2.514e-04, MSE(pi1): 1.740e-02, MSE(pi2): 1.568e-04, MSE(pi3): 5.696e-03\n",
      "Epoch 21400, Train loss: 3.240e+03, Test loss: 1.260e+05, MSE(e): 2.497e-04, MSE(pi1): 1.736e-02, MSE(pi2): 1.558e-04, MSE(pi3): 5.695e-03\n",
      "Epoch 21500, Train loss: 3.223e+03, Test loss: 1.257e+05, MSE(e): 2.480e-04, MSE(pi1): 1.731e-02, MSE(pi2): 1.547e-04, MSE(pi3): 5.695e-03\n",
      "Epoch 21600, Train loss: 3.204e+03, Test loss: 1.253e+05, MSE(e): 2.462e-04, MSE(pi1): 1.726e-02, MSE(pi2): 1.536e-04, MSE(pi3): 5.694e-03\n",
      "Epoch 21700, Train loss: 3.185e+03, Test loss: 1.249e+05, MSE(e): 2.444e-04, MSE(pi1): 1.721e-02, MSE(pi2): 1.524e-04, MSE(pi3): 5.694e-03\n",
      "Epoch 21800, Train loss: 3.166e+03, Test loss: 1.245e+05, MSE(e): 2.425e-04, MSE(pi1): 1.716e-02, MSE(pi2): 1.512e-04, MSE(pi3): 5.693e-03\n",
      "Epoch 21900, Train loss: 3.145e+03, Test loss: 1.241e+05, MSE(e): 2.405e-04, MSE(pi1): 1.710e-02, MSE(pi2): 1.500e-04, MSE(pi3): 5.693e-03\n",
      "Epoch 22000, Train loss: 3.125e+03, Test loss: 1.237e+05, MSE(e): 2.385e-04, MSE(pi1): 1.704e-02, MSE(pi2): 1.487e-04, MSE(pi3): 5.692e-03\n",
      "Epoch 22100, Train loss: 3.103e+03, Test loss: 1.232e+05, MSE(e): 2.364e-04, MSE(pi1): 1.699e-02, MSE(pi2): 1.474e-04, MSE(pi3): 5.691e-03\n",
      "Epoch 22200, Train loss: 3.081e+03, Test loss: 1.228e+05, MSE(e): 2.342e-04, MSE(pi1): 1.692e-02, MSE(pi2): 1.460e-04, MSE(pi3): 5.691e-03\n",
      "Epoch 22300, Train loss: 3.058e+03, Test loss: 1.223e+05, MSE(e): 2.320e-04, MSE(pi1): 1.686e-02, MSE(pi2): 1.446e-04, MSE(pi3): 5.690e-03\n",
      "Epoch 22400, Train loss: 3.034e+03, Test loss: 1.218e+05, MSE(e): 2.297e-04, MSE(pi1): 1.680e-02, MSE(pi2): 1.432e-04, MSE(pi3): 5.689e-03\n",
      "Epoch 22500, Train loss: 3.009e+03, Test loss: 1.213e+05, MSE(e): 2.273e-04, MSE(pi1): 1.673e-02, MSE(pi2): 1.417e-04, MSE(pi3): 5.688e-03\n",
      "Epoch 22600, Train loss: 2.984e+03, Test loss: 1.208e+05, MSE(e): 2.249e-04, MSE(pi1): 1.661e-02, MSE(pi2): 1.401e-04, MSE(pi3): 5.693e-03\n",
      "Epoch 22700, Train loss: 2.960e+03, Test loss: 1.203e+05, MSE(e): 2.226e-04, MSE(pi1): 1.653e-02, MSE(pi2): 1.386e-04, MSE(pi3): 5.695e-03\n",
      "Epoch 22800, Train loss: 2.992e+03, Test loss: 1.195e+05, MSE(e): 2.246e-04, MSE(pi1): 1.857e-02, MSE(pi2): 1.397e-04, MSE(pi3): 5.601e-03\n",
      "Epoch 22900, Train loss: 2.914e+03, Test loss: 1.193e+05, MSE(e): 2.180e-04, MSE(pi1): 1.675e-02, MSE(pi2): 1.358e-04, MSE(pi3): 5.667e-03\n",
      "Epoch 23000, Train loss: 3.066e+03, Test loss: 1.179e+05, MSE(e): 2.270e-04, MSE(pi1): 2.559e-02, MSE(pi2): 1.409e-04, MSE(pi3): 5.400e-03\n",
      "Epoch 23100, Train loss: 2.888e+03, Test loss: 1.184e+05, MSE(e): 2.155e-04, MSE(pi1): 1.645e-02, MSE(pi2): 1.343e-04, MSE(pi3): 5.681e-03\n",
      "Epoch 23200, Train loss: 2.858e+03, Test loss: 1.179e+05, MSE(e): 2.125e-04, MSE(pi1): 1.642e-02, MSE(pi2): 1.321e-04, MSE(pi3): 5.683e-03\n",
      "Epoch 23300, Train loss: 3.451e+03, Test loss: 1.170e+05, MSE(e): 2.721e-04, MSE(pi1): 1.724e-02, MSE(pi2): 1.571e-04, MSE(pi3): 5.575e-03\n",
      "Epoch 23400, Train loss: 2.804e+03, Test loss: 1.171e+05, MSE(e): 2.074e-04, MSE(pi1): 1.640e-02, MSE(pi2): 1.291e-04, MSE(pi3): 5.663e-03\n",
      "Epoch 23500, Train loss: 2.795e+03, Test loss: 1.170e+05, MSE(e): 2.064e-04, MSE(pi1): 1.591e-02, MSE(pi2): 1.285e-04, MSE(pi3): 5.711e-03\n",
      "Epoch 23600, Train loss: 2.914e+03, Test loss: 1.163e+05, MSE(e): 2.060e-04, MSE(pi1): 2.900e-02, MSE(pi2): 1.283e-04, MSE(pi3): 5.631e-03\n",
      "Epoch 23700, Train loss: 3.483e+03, Test loss: 1.160e+05, MSE(e): 2.590e-04, MSE(pi1): 3.171e-02, MSE(pi2): 1.582e-04, MSE(pi3): 5.765e-03\n",
      "Epoch 23800, Train loss: 2.859e+03, Test loss: 1.164e+05, MSE(e): 2.044e-04, MSE(pi1): 2.182e-02, MSE(pi2): 1.270e-04, MSE(pi3): 5.962e-03\n",
      "Epoch 23900, Train loss: 2.742e+03, Test loss: 1.145e+05, MSE(e): 2.003e-04, MSE(pi1): 1.804e-02, MSE(pi2): 1.245e-04, MSE(pi3): 5.589e-03\n",
      "Epoch 24000, Train loss: 2.884e+03, Test loss: 1.140e+05, MSE(e): 2.051e-04, MSE(pi1): 2.907e-02, MSE(pi2): 1.275e-04, MSE(pi3): 5.418e-03\n",
      "Epoch 24100, Train loss: 2.988e+03, Test loss: 1.154e+05, MSE(e): 2.250e-04, MSE(pi1): 1.611e-02, MSE(pi2): 1.348e-04, MSE(pi3): 5.763e-03\n",
      "Epoch 24200, Train loss: 2.744e+03, Test loss: 1.132e+05, MSE(e): 2.003e-04, MSE(pi1): 1.836e-02, MSE(pi2): 1.241e-04, MSE(pi3): 5.572e-03\n",
      "Epoch 24300, Train loss: 2.800e+03, Test loss: 1.124e+05, MSE(e): 1.972e-04, MSE(pi1): 2.808e-02, MSE(pi2): 1.221e-04, MSE(pi3): 5.474e-03\n",
      "Epoch 24400, Train loss: 2.646e+03, Test loss: 1.126e+05, MSE(e): 1.907e-04, MSE(pi1): 1.823e-02, MSE(pi2): 1.188e-04, MSE(pi3): 5.561e-03\n",
      "Epoch 24500, Train loss: 2.630e+03, Test loss: 1.122e+05, MSE(e): 1.875e-04, MSE(pi1): 2.014e-02, MSE(pi2): 1.165e-04, MSE(pi3): 5.544e-03\n",
      "Epoch 24600, Train loss: 2.952e+03, Test loss: 1.113e+05, MSE(e): 2.054e-04, MSE(pi1): 3.634e-02, MSE(pi2): 1.275e-04, MSE(pi3): 5.344e-03\n",
      "Epoch 24700, Train loss: 2.580e+03, Test loss: 1.116e+05, MSE(e): 1.836e-04, MSE(pi1): 1.861e-02, MSE(pi2): 1.142e-04, MSE(pi3): 5.575e-03\n",
      "Epoch 24800, Train loss: 2.878e+03, Test loss: 1.113e+05, MSE(e): 2.157e-04, MSE(pi1): 1.555e-02, MSE(pi2): 1.272e-04, MSE(pi3): 5.656e-03\n",
      "Epoch 24900, Train loss: 3.183e+03, Test loss: 1.133e+05, MSE(e): 2.439e-04, MSE(pi1): 1.613e-02, MSE(pi2): 1.386e-04, MSE(pi3): 5.822e-03\n",
      "Epoch 25000, Train loss: 2.642e+03, Test loss: 1.114e+05, MSE(e): 1.884e-04, MSE(pi1): 1.780e-02, MSE(pi2): 1.147e-04, MSE(pi3): 5.804e-03\n",
      "Epoch 25100, Train loss: 2.515e+03, Test loss: 1.105e+05, MSE(e): 1.776e-04, MSE(pi1): 1.784e-02, MSE(pi2): 1.102e-04, MSE(pi3): 5.602e-03\n",
      "Epoch 25200, Train loss: 2.941e+03, Test loss: 1.109e+05, MSE(e): 2.119e-04, MSE(pi1): 2.398e-02, MSE(pi2): 1.277e-04, MSE(pi3): 5.824e-03\n",
      "Epoch 25300, Train loss: 2.524e+03, Test loss: 1.105e+05, MSE(e): 1.799e-04, MSE(pi1): 1.552e-02, MSE(pi2): 1.105e-04, MSE(pi3): 5.688e-03\n",
      "Epoch 25400, Train loss: 2.793e+03, Test loss: 1.113e+05, MSE(e): 2.052e-04, MSE(pi1): 1.594e-02, MSE(pi2): 1.206e-04, MSE(pi3): 5.810e-03\n",
      "Epoch 25500, Train loss: 3.324e+03, Test loss: 1.111e+05, MSE(e): 2.295e-04, MSE(pi1): 4.350e-02, MSE(pi2): 1.453e-04, MSE(pi3): 5.938e-03\n",
      "Epoch 25600, Train loss: 2.415e+03, Test loss: 1.091e+05, MSE(e): 1.696e-04, MSE(pi1): 1.522e-02, MSE(pi2): 1.049e-04, MSE(pi3): 5.666e-03\n",
      "Epoch 25700, Train loss: 2.402e+03, Test loss: 1.089e+05, MSE(e): 1.684e-04, MSE(pi1): 1.501e-02, MSE(pi2): 1.043e-04, MSE(pi3): 5.677e-03\n",
      "Epoch 25800, Train loss: 2.707e+03, Test loss: 1.082e+05, MSE(e): 1.984e-04, MSE(pi1): 1.622e-02, MSE(pi2): 1.183e-04, MSE(pi3): 5.604e-03\n",
      "Epoch 25900, Train loss: 2.366e+03, Test loss: 1.080e+05, MSE(e): 1.646e-04, MSE(pi1): 1.564e-02, MSE(pi2): 1.020e-04, MSE(pi3): 5.631e-03\n",
      "Epoch 26000, Train loss: 2.401e+03, Test loss: 1.081e+05, MSE(e): 1.665e-04, MSE(pi1): 1.617e-02, MSE(pi2): 1.024e-04, MSE(pi3): 5.743e-03\n",
      "Epoch 26100, Train loss: 2.350e+03, Test loss: 1.079e+05, MSE(e): 1.626e-04, MSE(pi1): 1.494e-02, MSE(pi2): 1.007e-04, MSE(pi3): 5.748e-03\n",
      "Epoch 26200, Train loss: 2.329e+03, Test loss: 1.072e+05, MSE(e): 1.611e-04, MSE(pi1): 1.481e-02, MSE(pi2): 9.957e-05, MSE(pi3): 5.700e-03\n",
      "Epoch 26300, Train loss: 2.325e+03, Test loss: 1.070e+05, MSE(e): 1.597e-04, MSE(pi1): 1.599e-02, MSE(pi2): 9.893e-05, MSE(pi3): 5.681e-03\n",
      "Epoch 26400, Train loss: 2.406e+03, Test loss: 1.072e+05, MSE(e): 1.668e-04, MSE(pi1): 1.575e-02, MSE(pi2): 1.035e-04, MSE(pi3): 5.804e-03\n",
      "Epoch 26500, Train loss: 2.297e+03, Test loss: 1.065e+05, MSE(e): 1.578e-04, MSE(pi1): 1.486e-02, MSE(pi2): 9.779e-05, MSE(pi3): 5.706e-03\n",
      "Epoch 26600, Train loss: 2.292e+03, Test loss: 1.063e+05, MSE(e): 1.569e-04, MSE(pi1): 1.506e-02, MSE(pi2): 9.664e-05, MSE(pi3): 5.722e-03\n",
      "Epoch 26700, Train loss: 2.920e+03, Test loss: 1.038e+05, MSE(e): 1.929e-04, MSE(pi1): 4.676e-02, MSE(pi2): 1.166e-04, MSE(pi3): 5.236e-03\n",
      "Epoch 26800, Train loss: 2.334e+03, Test loss: 1.054e+05, MSE(e): 1.612e-04, MSE(pi1): 1.538e-02, MSE(pi2): 1.003e-04, MSE(pi3): 5.680e-03\n",
      "Epoch 26900, Train loss: 2.229e+03, Test loss: 1.050e+05, MSE(e): 1.517e-04, MSE(pi1): 1.460e-02, MSE(pi2): 9.375e-05, MSE(pi3): 5.660e-03\n",
      "Epoch 27000, Train loss: 2.263e+03, Test loss: 1.043e+05, MSE(e): 1.517e-04, MSE(pi1): 1.958e-02, MSE(pi2): 9.398e-05, MSE(pi3): 5.507e-03\n",
      "Epoch 27100, Train loss: 2.328e+03, Test loss: 1.057e+05, MSE(e): 1.555e-04, MSE(pi1): 1.820e-02, MSE(pi2): 9.569e-05, MSE(pi3): 5.905e-03\n",
      "Epoch 27200, Train loss: 2.278e+03, Test loss: 1.043e+05, MSE(e): 1.539e-04, MSE(pi1): 1.826e-02, MSE(pi2): 9.420e-05, MSE(pi3): 5.562e-03\n",
      "Epoch 27300, Train loss: 2.211e+03, Test loss: 1.039e+05, MSE(e): 1.480e-04, MSE(pi1): 1.738e-02, MSE(pi2): 9.150e-05, MSE(pi3): 5.567e-03\n",
      "Epoch 27400, Train loss: 2.232e+03, Test loss: 1.045e+05, MSE(e): 1.489e-04, MSE(pi1): 1.637e-02, MSE(pi2): 9.225e-05, MSE(pi3): 5.783e-03\n",
      "Epoch 27500, Train loss: 2.523e+03, Test loss: 1.050e+05, MSE(e): 1.699e-04, MSE(pi1): 2.394e-02, MSE(pi2): 1.070e-04, MSE(pi3): 5.852e-03\n",
      "Epoch 27600, Train loss: 2.166e+03, Test loss: 1.031e+05, MSE(e): 1.454e-04, MSE(pi1): 1.524e-02, MSE(pi2): 8.979e-05, MSE(pi3): 5.597e-03\n",
      "Epoch 27700, Train loss: 2.164e+03, Test loss: 1.033e+05, MSE(e): 1.443e-04, MSE(pi1): 1.457e-02, MSE(pi2): 8.880e-05, MSE(pi3): 5.754e-03\n",
      "Epoch 27800, Train loss: 2.196e+03, Test loss: 1.024e+05, MSE(e): 1.473e-04, MSE(pi1): 1.713e-02, MSE(pi2): 9.102e-05, MSE(pi3): 5.511e-03\n",
      "Epoch 27900, Train loss: 2.176e+03, Test loss: 1.026e+05, MSE(e): 1.452e-04, MSE(pi1): 1.571e-02, MSE(pi2): 8.906e-05, MSE(pi3): 5.670e-03\n",
      "Epoch 28000, Train loss: 2.178e+03, Test loss: 1.031e+05, MSE(e): 1.436e-04, MSE(pi1): 1.570e-02, MSE(pi2): 8.786e-05, MSE(pi3): 5.854e-03\n",
      "Epoch 28100, Train loss: 2.161e+03, Test loss: 1.016e+05, MSE(e): 1.409e-04, MSE(pi1): 1.980e-02, MSE(pi2): 8.700e-05, MSE(pi3): 5.543e-03\n",
      "Epoch 28200, Train loss: 2.260e+03, Test loss: 1.007e+05, MSE(e): 1.457e-04, MSE(pi1): 2.644e-02, MSE(pi2): 9.021e-05, MSE(pi3): 5.384e-03\n",
      "Epoch 28300, Train loss: 2.099e+03, Test loss: 1.014e+05, MSE(e): 1.387e-04, MSE(pi1): 1.502e-02, MSE(pi2): 8.514e-05, MSE(pi3): 5.617e-03\n",
      "Epoch 28400, Train loss: 2.271e+03, Test loss: 1.008e+05, MSE(e): 1.479e-04, MSE(pi1): 2.505e-02, MSE(pi2): 9.043e-05, MSE(pi3): 5.420e-03\n",
      "Epoch 28500, Train loss: 2.168e+03, Test loss: 1.013e+05, MSE(e): 1.444e-04, MSE(pi1): 1.611e-02, MSE(pi2): 8.746e-05, MSE(pi3): 5.628e-03\n",
      "Epoch 28600, Train loss: 2.124e+03, Test loss: 1.015e+05, MSE(e): 1.402e-04, MSE(pi1): 1.510e-02, MSE(pi2): 8.699e-05, MSE(pi3): 5.710e-03\n",
      "Epoch 28700, Train loss: 2.097e+03, Test loss: 1.000e+05, MSE(e): 1.344e-04, MSE(pi1): 2.054e-02, MSE(pi2): 8.317e-05, MSE(pi3): 5.483e-03\n",
      "Epoch 28800, Train loss: 2.112e+03, Test loss: 1.002e+05, MSE(e): 1.407e-04, MSE(pi1): 1.450e-02, MSE(pi2): 8.503e-05, MSE(pi3): 5.603e-03\n",
      "Epoch 28900, Train loss: 2.100e+03, Test loss: 9.951e+04, MSE(e): 1.333e-04, MSE(pi1): 2.191e-02, MSE(pi2): 8.236e-05, MSE(pi3): 5.470e-03\n",
      "Epoch 29000, Train loss: 2.019e+03, Test loss: 1.000e+05, MSE(e): 1.312e-04, MSE(pi1): 1.389e-02, MSE(pi2): 8.053e-05, MSE(pi3): 5.679e-03\n",
      "Epoch 29100, Train loss: 2.057e+03, Test loss: 1.001e+05, MSE(e): 1.347e-04, MSE(pi1): 1.438e-02, MSE(pi2): 8.219e-05, MSE(pi3): 5.665e-03\n",
      "Epoch 29200, Train loss: 2.185e+03, Test loss: 9.887e+04, MSE(e): 1.442e-04, MSE(pi1): 1.805e-02, MSE(pi2): 8.948e-05, MSE(pi3): 5.628e-03\n",
      "Epoch 29300, Train loss: 1.969e+03, Test loss: 9.930e+04, MSE(e): 1.266e-04, MSE(pi1): 1.384e-02, MSE(pi2): 7.786e-05, MSE(pi3): 5.651e-03\n",
      "Epoch 29400, Train loss: 2.065e+03, Test loss: 9.942e+04, MSE(e): 1.332e-04, MSE(pi1): 1.528e-02, MSE(pi2): 8.070e-05, MSE(pi3): 5.797e-03\n",
      "Epoch 29500, Train loss: 2.035e+03, Test loss: 9.954e+04, MSE(e): 1.310e-04, MSE(pi1): 1.535e-02, MSE(pi2): 8.009e-05, MSE(pi3): 5.717e-03\n",
      "Epoch 29600, Train loss: 1.951e+03, Test loss: 9.893e+04, MSE(e): 1.242e-04, MSE(pi1): 1.378e-02, MSE(pi2): 7.633e-05, MSE(pi3): 5.710e-03\n",
      "Epoch 29700, Train loss: 2.146e+03, Test loss: 9.924e+04, MSE(e): 1.437e-04, MSE(pi1): 1.403e-02, MSE(pi2): 8.425e-05, MSE(pi3): 5.685e-03\n",
      "Epoch 29800, Train loss: 2.206e+03, Test loss: 9.888e+04, MSE(e): 1.486e-04, MSE(pi1): 1.538e-02, MSE(pi2): 8.613e-05, MSE(pi3): 5.660e-03\n",
      "Epoch 29900, Train loss: 1.936e+03, Test loss: 9.790e+04, MSE(e): 1.223e-04, MSE(pi1): 1.541e-02, MSE(pi2): 7.524e-05, MSE(pi3): 5.595e-03\n",
      "Epoch 30000, Train loss: 2.097e+03, Test loss: 9.801e+04, MSE(e): 1.369e-04, MSE(pi1): 1.706e-02, MSE(pi2): 8.587e-05, MSE(pi3): 5.578e-03\n",
      "Epoch 30100, Train loss: 1.948e+03, Test loss: 9.710e+04, MSE(e): 1.230e-04, MSE(pi1): 1.643e-02, MSE(pi2): 7.529e-05, MSE(pi3): 5.537e-03\n",
      "Epoch 30200, Train loss: 1.909e+03, Test loss: 9.721e+04, MSE(e): 1.196e-04, MSE(pi1): 1.540e-02, MSE(pi2): 7.342e-05, MSE(pi3): 5.590e-03\n",
      "Epoch 30300, Train loss: 2.112e+03, Test loss: 9.742e+04, MSE(e): 1.309e-04, MSE(pi1): 2.454e-02, MSE(pi2): 8.234e-05, MSE(pi3): 5.570e-03\n",
      "Epoch 30400, Train loss: 1.971e+03, Test loss: 9.708e+04, MSE(e): 1.257e-04, MSE(pi1): 1.460e-02, MSE(pi2): 7.740e-05, MSE(pi3): 5.673e-03\n",
      "Epoch 30500, Train loss: 1.882e+03, Test loss: 9.711e+04, MSE(e): 1.171e-04, MSE(pi1): 1.378e-02, MSE(pi2): 7.176e-05, MSE(pi3): 5.738e-03\n",
      "Epoch 30600, Train loss: 2.157e+03, Test loss: 9.774e+04, MSE(e): 1.391e-04, MSE(pi1): 1.860e-02, MSE(pi2): 8.216e-05, MSE(pi3): 5.804e-03\n",
      "Epoch 30700, Train loss: 1.956e+03, Test loss: 9.691e+04, MSE(e): 1.207e-04, MSE(pi1): 1.795e-02, MSE(pi2): 7.460e-05, MSE(pi3): 5.694e-03\n",
      "Epoch 30800, Train loss: 2.008e+03, Test loss: 9.659e+04, MSE(e): 1.283e-04, MSE(pi1): 1.482e-02, MSE(pi2): 7.634e-05, MSE(pi3): 5.770e-03\n",
      "Epoch 30900, Train loss: 3.079e+03, Test loss: 9.632e+04, MSE(e): 2.360e-04, MSE(pi1): 1.680e-02, MSE(pi2): 1.222e-04, MSE(pi3): 5.508e-03\n",
      "Epoch 31000, Train loss: 1.833e+03, Test loss: 9.568e+04, MSE(e): 1.131e-04, MSE(pi1): 1.404e-02, MSE(pi2): 6.935e-05, MSE(pi3): 5.614e-03\n",
      "Epoch 31100, Train loss: 2.141e+03, Test loss: 9.696e+04, MSE(e): 1.434e-04, MSE(pi1): 1.337e-02, MSE(pi2): 8.234e-05, MSE(pi3): 5.736e-03\n",
      "Epoch 31200, Train loss: 1.917e+03, Test loss: 9.638e+04, MSE(e): 1.193e-04, MSE(pi1): 1.421e-02, MSE(pi2): 7.192e-05, MSE(pi3): 5.827e-03\n",
      "Epoch 31300, Train loss: 2.093e+03, Test loss: 9.424e+04, MSE(e): 1.331e-04, MSE(pi1): 2.215e-02, MSE(pi2): 7.859e-05, MSE(pi3): 5.403e-03\n",
      "Epoch 31400, Train loss: 2.056e+03, Test loss: 9.668e+04, MSE(e): 1.197e-04, MSE(pi1): 2.535e-02, MSE(pi2): 7.357e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 31500, Train loss: 1.870e+03, Test loss: 9.536e+04, MSE(e): 1.158e-04, MSE(pi1): 1.430e-02, MSE(pi2): 6.968e-05, MSE(pi3): 5.690e-03\n",
      "Epoch 31600, Train loss: 1.857e+03, Test loss: 9.488e+04, MSE(e): 1.131e-04, MSE(pi1): 1.630e-02, MSE(pi2): 6.896e-05, MSE(pi3): 5.629e-03\n",
      "Epoch 31700, Train loss: 1.905e+03, Test loss: 9.435e+04, MSE(e): 1.161e-04, MSE(pi1): 1.815e-02, MSE(pi2): 6.949e-05, MSE(pi3): 5.633e-03\n",
      "Epoch 31800, Train loss: 1.951e+03, Test loss: 9.496e+04, MSE(e): 1.115e-04, MSE(pi1): 2.447e-02, MSE(pi2): 6.757e-05, MSE(pi3): 5.912e-03\n",
      "Epoch 31900, Train loss: 1.764e+03, Test loss: 9.415e+04, MSE(e): 1.067e-04, MSE(pi1): 1.316e-02, MSE(pi2): 6.528e-05, MSE(pi3): 5.649e-03\n",
      "Epoch 32000, Train loss: 1.781e+03, Test loss: 9.409e+04, MSE(e): 1.079e-04, MSE(pi1): 1.399e-02, MSE(pi2): 6.591e-05, MSE(pi3): 5.620e-03\n",
      "Epoch 32100, Train loss: 2.105e+03, Test loss: 9.379e+04, MSE(e): 1.402e-04, MSE(pi1): 1.352e-02, MSE(pi2): 7.974e-05, MSE(pi3): 5.680e-03\n",
      "Epoch 32200, Train loss: 1.750e+03, Test loss: 9.354e+04, MSE(e): 1.050e-04, MSE(pi1): 1.370e-02, MSE(pi2): 6.421e-05, MSE(pi3): 5.631e-03\n",
      "Epoch 32300, Train loss: 1.778e+03, Test loss: 9.336e+04, MSE(e): 1.078e-04, MSE(pi1): 1.338e-02, MSE(pi2): 6.519e-05, MSE(pi3): 5.663e-03\n",
      "Epoch 32400, Train loss: 1.855e+03, Test loss: 9.289e+04, MSE(e): 1.077e-04, MSE(pi1): 2.335e-02, MSE(pi2): 6.657e-05, MSE(pi3): 5.445e-03\n",
      "Epoch 32500, Train loss: 1.774e+03, Test loss: 9.261e+04, MSE(e): 1.041e-04, MSE(pi1): 1.826e-02, MSE(pi2): 6.382e-05, MSE(pi3): 5.500e-03\n",
      "Epoch 32600, Train loss: 1.774e+03, Test loss: 9.312e+04, MSE(e): 1.063e-04, MSE(pi1): 1.428e-02, MSE(pi2): 6.471e-05, MSE(pi3): 5.681e-03\n",
      "Epoch 32700, Train loss: 1.733e+03, Test loss: 9.252e+04, MSE(e): 1.021e-04, MSE(pi1): 1.561e-02, MSE(pi2): 6.244e-05, MSE(pi3): 5.559e-03\n",
      "Epoch 32800, Train loss: 1.819e+03, Test loss: 9.276e+04, MSE(e): 1.107e-04, MSE(pi1): 1.430e-02, MSE(pi2): 6.868e-05, MSE(pi3): 5.682e-03\n",
      "Epoch 32900, Train loss: 1.710e+03, Test loss: 9.262e+04, MSE(e): 1.011e-04, MSE(pi1): 1.312e-02, MSE(pi2): 6.164e-05, MSE(pi3): 5.672e-03\n",
      "Epoch 33000, Train loss: 1.715e+03, Test loss: 9.272e+04, MSE(e): 1.009e-04, MSE(pi1): 1.335e-02, MSE(pi2): 6.168e-05, MSE(pi3): 5.721e-03\n",
      "Epoch 33100, Train loss: 1.882e+03, Test loss: 9.249e+04, MSE(e): 1.126e-04, MSE(pi1): 1.788e-02, MSE(pi2): 6.822e-05, MSE(pi3): 5.770e-03\n",
      "Epoch 33200, Train loss: 1.694e+03, Test loss: 9.205e+04, MSE(e): 9.969e-05, MSE(pi1): 1.295e-02, MSE(pi2): 6.069e-05, MSE(pi3): 5.675e-03\n",
      "Epoch 33300, Train loss: 1.833e+03, Test loss: 9.152e+04, MSE(e): 1.080e-04, MSE(pi1): 1.924e-02, MSE(pi2): 6.570e-05, MSE(pi3): 5.605e-03\n",
      "Epoch 33400, Train loss: 1.990e+03, Test loss: 9.385e+04, MSE(e): 1.092e-04, MSE(pi1): 2.854e-02, MSE(pi2): 6.639e-05, MSE(pi3): 6.124e-03\n",
      "Epoch 33500, Train loss: 1.762e+03, Test loss: 9.216e+04, MSE(e): 1.060e-04, MSE(pi1): 1.289e-02, MSE(pi2): 6.284e-05, MSE(pi3): 5.726e-03\n",
      "Epoch 33600, Train loss: 1.887e+03, Test loss: 9.216e+04, MSE(e): 1.164e-04, MSE(pi1): 1.492e-02, MSE(pi2): 6.765e-05, MSE(pi3): 5.741e-03\n",
      "Epoch 33700, Train loss: 1.698e+03, Test loss: 9.136e+04, MSE(e): 9.919e-05, MSE(pi1): 1.452e-02, MSE(pi2): 5.980e-05, MSE(pi3): 5.608e-03\n",
      "Epoch 33800, Train loss: 1.796e+03, Test loss: 9.117e+04, MSE(e): 1.085e-04, MSE(pi1): 1.458e-02, MSE(pi2): 6.439e-05, MSE(pi3): 5.649e-03\n",
      "Epoch 33900, Train loss: 1.798e+03, Test loss: 9.106e+04, MSE(e): 1.082e-04, MSE(pi1): 1.485e-02, MSE(pi2): 6.440e-05, MSE(pi3): 5.669e-03\n",
      "Epoch 34000, Train loss: 1.757e+03, Test loss: 9.116e+04, MSE(e): 1.015e-04, MSE(pi1): 1.745e-02, MSE(pi2): 6.247e-05, MSE(pi3): 5.673e-03\n",
      "Epoch 34100, Train loss: 2.124e+03, Test loss: 9.273e+04, MSE(e): 1.074e-04, MSE(pi1): 4.317e-02, MSE(pi2): 6.638e-05, MSE(pi3): 6.184e-03\n",
      "Epoch 34200, Train loss: 1.642e+03, Test loss: 9.056e+04, MSE(e): 9.398e-05, MSE(pi1): 1.355e-02, MSE(pi2): 5.719e-05, MSE(pi3): 5.666e-03\n",
      "Epoch 34300, Train loss: 1.656e+03, Test loss: 9.002e+04, MSE(e): 9.517e-05, MSE(pi1): 1.483e-02, MSE(pi2): 5.766e-05, MSE(pi3): 5.561e-03\n",
      "Epoch 34400, Train loss: 1.698e+03, Test loss: 8.988e+04, MSE(e): 1.002e-04, MSE(pi1): 1.379e-02, MSE(pi2): 6.001e-05, MSE(pi3): 5.578e-03\n",
      "Epoch 34500, Train loss: 1.868e+03, Test loss: 8.982e+04, MSE(e): 1.112e-04, MSE(pi1): 1.951e-02, MSE(pi2): 6.667e-05, MSE(pi3): 5.601e-03\n",
      "Epoch 34600, Train loss: 2.520e+03, Test loss: 9.065e+04, MSE(e): 1.770e-04, MSE(pi1): 1.750e-02, MSE(pi2): 9.717e-05, MSE(pi3): 5.756e-03\n",
      "Epoch 34700, Train loss: 1.656e+03, Test loss: 8.970e+04, MSE(e): 9.639e-05, MSE(pi1): 1.268e-02, MSE(pi2): 5.750e-05, MSE(pi3): 5.654e-03\n",
      "Epoch 34800, Train loss: 2.063e+03, Test loss: 9.091e+04, MSE(e): 1.201e-04, MSE(pi1): 2.846e-02, MSE(pi2): 7.725e-05, MSE(pi3): 5.770e-03\n",
      "Epoch 34900, Train loss: 1.652e+03, Test loss: 8.937e+04, MSE(e): 9.269e-05, MSE(pi1): 1.669e-02, MSE(pi2): 5.663e-05, MSE(pi3): 5.583e-03\n",
      "Epoch 35000, Train loss: 1.594e+03, Test loss: 8.951e+04, MSE(e): 8.932e-05, MSE(pi1): 1.322e-02, MSE(pi2): 5.422e-05, MSE(pi3): 5.684e-03\n",
      "Epoch 35100, Train loss: 2.088e+03, Test loss: 9.021e+04, MSE(e): 1.357e-04, MSE(pi1): 1.528e-02, MSE(pi2): 7.984e-05, MSE(pi3): 5.780e-03\n",
      "Epoch 35200, Train loss: 1.610e+03, Test loss: 8.920e+04, MSE(e): 9.087e-05, MSE(pi1): 1.424e-02, MSE(pi2): 5.513e-05, MSE(pi3): 5.593e-03\n",
      "Epoch 35300, Train loss: 2.811e+03, Test loss: 9.066e+04, MSE(e): 2.107e-04, MSE(pi1): 1.422e-02, MSE(pi2): 1.061e-04, MSE(pi3): 5.620e-03\n",
      "Epoch 35400, Train loss: 1.775e+03, Test loss: 8.816e+04, MSE(e): 9.442e-05, MSE(pi1): 2.945e-02, MSE(pi2): 5.873e-05, MSE(pi3): 5.361e-03\n",
      "Epoch 35500, Train loss: 1.576e+03, Test loss: 8.842e+04, MSE(e): 8.747e-05, MSE(pi1): 1.452e-02, MSE(pi2): 5.319e-05, MSE(pi3): 5.562e-03\n",
      "Epoch 35600, Train loss: 1.593e+03, Test loss: 8.853e+04, MSE(e): 9.033e-05, MSE(pi1): 1.252e-02, MSE(pi2): 5.423e-05, MSE(pi3): 5.641e-03\n",
      "Epoch 35700, Train loss: 1.641e+03, Test loss: 8.773e+04, MSE(e): 9.003e-05, MSE(pi1): 2.000e-02, MSE(pi2): 5.495e-05, MSE(pi3): 5.405e-03\n",
      "Epoch 35800, Train loss: 1.822e+03, Test loss: 8.791e+04, MSE(e): 1.073e-04, MSE(pi1): 1.856e-02, MSE(pi2): 6.316e-05, MSE(pi3): 5.629e-03\n",
      "Epoch 35900, Train loss: 2.063e+03, Test loss: 8.728e+04, MSE(e): 9.567e-05, MSE(pi1): 5.806e-02, MSE(pi2): 5.956e-05, MSE(pi3): 5.253e-03\n",
      "Epoch 36000, Train loss: 1.545e+03, Test loss: 8.824e+04, MSE(e): 8.485e-05, MSE(pi1): 1.334e-02, MSE(pi2): 5.150e-05, MSE(pi3): 5.629e-03\n",
      "Epoch 36100, Train loss: 1.566e+03, Test loss: 8.829e+04, MSE(e): 8.544e-05, MSE(pi1): 1.322e-02, MSE(pi2): 5.176e-05, MSE(pi3): 5.789e-03\n",
      "Epoch 36200, Train loss: 1.569e+03, Test loss: 8.804e+04, MSE(e): 8.772e-05, MSE(pi1): 1.250e-02, MSE(pi2): 5.255e-05, MSE(pi3): 5.667e-03\n",
      "Epoch 36300, Train loss: 1.527e+03, Test loss: 8.772e+04, MSE(e): 8.383e-05, MSE(pi1): 1.230e-02, MSE(pi2): 5.078e-05, MSE(pi3): 5.658e-03\n",
      "Epoch 36400, Train loss: 1.524e+03, Test loss: 8.771e+04, MSE(e): 8.312e-05, MSE(pi1): 1.267e-02, MSE(pi2): 5.038e-05, MSE(pi3): 5.665e-03\n",
      "Epoch 36500, Train loss: 1.950e+03, Test loss: 8.918e+04, MSE(e): 9.920e-05, MSE(pi1): 3.636e-02, MSE(pi2): 6.216e-05, MSE(pi3): 5.943e-03\n",
      "Epoch 36600, Train loss: 2.376e+03, Test loss: 8.754e+04, MSE(e): 1.649e-04, MSE(pi1): 1.801e-02, MSE(pi2): 8.636e-05, MSE(pi3): 5.466e-03\n",
      "Epoch 36700, Train loss: 1.990e+03, Test loss: 8.844e+04, MSE(e): 1.298e-04, MSE(pi1): 1.275e-02, MSE(pi2): 6.964e-05, MSE(pi3): 5.652e-03\n",
      "Epoch 36800, Train loss: 1.528e+03, Test loss: 8.693e+04, MSE(e): 8.274e-05, MSE(pi1): 1.398e-02, MSE(pi2): 5.034e-05, MSE(pi3): 5.603e-03\n",
      "Epoch 36900, Train loss: 1.505e+03, Test loss: 8.714e+04, MSE(e): 8.132e-05, MSE(pi1): 1.235e-02, MSE(pi2): 4.919e-05, MSE(pi3): 5.681e-03\n",
      "Epoch 37000, Train loss: 1.493e+03, Test loss: 8.686e+04, MSE(e): 8.050e-05, MSE(pi1): 1.229e-02, MSE(pi2): 4.874e-05, MSE(pi3): 5.648e-03\n",
      "Epoch 37100, Train loss: 1.753e+03, Test loss: 8.626e+04, MSE(e): 1.038e-04, MSE(pi1): 1.674e-02, MSE(pi2): 5.916e-05, MSE(pi3): 5.475e-03\n",
      "Epoch 37200, Train loss: 1.722e+03, Test loss: 8.686e+04, MSE(e): 1.018e-04, MSE(pi1): 1.497e-02, MSE(pi2): 5.852e-05, MSE(pi3): 5.540e-03\n",
      "Epoch 37300, Train loss: 1.594e+03, Test loss: 8.641e+04, MSE(e): 8.920e-05, MSE(pi1): 1.410e-02, MSE(pi2): 5.348e-05, MSE(pi3): 5.610e-03\n",
      "Epoch 37400, Train loss: 1.475e+03, Test loss: 8.644e+04, MSE(e): 7.891e-05, MSE(pi1): 1.230e-02, MSE(pi2): 4.776e-05, MSE(pi3): 5.633e-03\n",
      "Epoch 37500, Train loss: 1.507e+03, Test loss: 8.605e+04, MSE(e): 8.173e-05, MSE(pi1): 1.304e-02, MSE(pi2): 4.964e-05, MSE(pi3): 5.589e-03\n",
      "Epoch 37600, Train loss: 1.534e+03, Test loss: 8.677e+04, MSE(e): 8.093e-05, MSE(pi1): 1.356e-02, MSE(pi2): 4.887e-05, MSE(pi3): 5.890e-03\n",
      "Epoch 37700, Train loss: 1.776e+03, Test loss: 8.618e+04, MSE(e): 8.989e-05, MSE(pi1): 3.247e-02, MSE(pi2): 5.627e-05, MSE(pi3): 5.519e-03\n",
      "Epoch 37800, Train loss: 1.514e+03, Test loss: 8.664e+04, MSE(e): 7.832e-05, MSE(pi1): 1.502e-02, MSE(pi2): 4.724e-05, MSE(pi3): 5.803e-03\n",
      "Epoch 37900, Train loss: 1.555e+03, Test loss: 8.597e+04, MSE(e): 8.566e-05, MSE(pi1): 1.307e-02, MSE(pi2): 5.035e-05, MSE(pi3): 5.680e-03\n",
      "Epoch 38000, Train loss: 1.511e+03, Test loss: 8.609e+04, MSE(e): 7.925e-05, MSE(pi1): 1.473e-02, MSE(pi2): 4.759e-05, MSE(pi3): 5.713e-03\n",
      "Epoch 38100, Train loss: 1.688e+03, Test loss: 8.716e+04, MSE(e): 8.156e-05, MSE(pi1): 2.661e-02, MSE(pi2): 4.950e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 38200, Train loss: 1.704e+03, Test loss: 8.523e+04, MSE(e): 1.002e-04, MSE(pi1): 1.508e-02, MSE(pi2): 5.656e-05, MSE(pi3): 5.521e-03\n",
      "Epoch 38300, Train loss: 1.475e+03, Test loss: 8.576e+04, MSE(e): 7.668e-05, MSE(pi1): 1.424e-02, MSE(pi2): 4.642e-05, MSE(pi3): 5.657e-03\n",
      "Epoch 38400, Train loss: 1.499e+03, Test loss: 8.606e+04, MSE(e): 7.645e-05, MSE(pi1): 1.512e-02, MSE(pi2): 4.613e-05, MSE(pi3): 5.830e-03\n",
      "Epoch 38500, Train loss: 1.660e+03, Test loss: 8.545e+04, MSE(e): 9.526e-05, MSE(pi1): 1.419e-02, MSE(pi2): 5.428e-05, MSE(pi3): 5.649e-03\n",
      "Epoch 38600, Train loss: 1.473e+03, Test loss: 8.587e+04, MSE(e): 7.682e-05, MSE(pi1): 1.275e-02, MSE(pi2): 4.613e-05, MSE(pi3): 5.776e-03\n",
      "Epoch 38700, Train loss: 1.461e+03, Test loss: 8.506e+04, MSE(e): 7.692e-05, MSE(pi1): 1.300e-02, MSE(pi2): 4.620e-05, MSE(pi3): 5.615e-03\n",
      "Epoch 38800, Train loss: 2.523e+03, Test loss: 8.539e+04, MSE(e): 1.791e-04, MSE(pi1): 1.469e-02, MSE(pi2): 9.580e-05, MSE(pi3): 5.847e-03\n",
      "Epoch 38900, Train loss: 1.421e+03, Test loss: 8.492e+04, MSE(e): 7.357e-05, MSE(pi1): 1.223e-02, MSE(pi2): 4.442e-05, MSE(pi3): 5.626e-03\n",
      "Epoch 39000, Train loss: 1.438e+03, Test loss: 8.438e+04, MSE(e): 7.391e-05, MSE(pi1): 1.475e-02, MSE(pi2): 4.484e-05, MSE(pi3): 5.516e-03\n",
      "Epoch 39100, Train loss: 1.638e+03, Test loss: 8.560e+04, MSE(e): 8.856e-05, MSE(pi1): 1.622e-02, MSE(pi2): 5.164e-05, MSE(pi3): 5.900e-03\n",
      "Epoch 39200, Train loss: 1.531e+03, Test loss: 8.489e+04, MSE(e): 8.096e-05, MSE(pi1): 1.562e-02, MSE(pi2): 4.963e-05, MSE(pi3): 5.649e-03\n",
      "Epoch 39300, Train loss: 1.595e+03, Test loss: 8.612e+04, MSE(e): 8.298e-05, MSE(pi1): 1.731e-02, MSE(pi2): 4.959e-05, MSE(pi3): 5.922e-03\n",
      "Epoch 39400, Train loss: 1.514e+03, Test loss: 8.459e+04, MSE(e): 7.709e-05, MSE(pi1): 1.855e-02, MSE(pi2): 4.637e-05, MSE(pi3): 5.579e-03\n",
      "Epoch 39500, Train loss: 1.423e+03, Test loss: 8.435e+04, MSE(e): 7.270e-05, MSE(pi1): 1.332e-02, MSE(pi2): 4.376e-05, MSE(pi3): 5.626e-03\n",
      "Epoch 39600, Train loss: 1.404e+03, Test loss: 8.414e+04, MSE(e): 7.151e-05, MSE(pi1): 1.300e-02, MSE(pi2): 4.317e-05, MSE(pi3): 5.584e-03\n",
      "Epoch 39700, Train loss: 1.422e+03, Test loss: 8.408e+04, MSE(e): 7.284e-05, MSE(pi1): 1.352e-02, MSE(pi2): 4.359e-05, MSE(pi3): 5.580e-03\n",
      "Epoch 39800, Train loss: 1.411e+03, Test loss: 8.420e+04, MSE(e): 7.167e-05, MSE(pi1): 1.259e-02, MSE(pi2): 4.311e-05, MSE(pi3): 5.685e-03\n",
      "Epoch 39900, Train loss: 1.584e+03, Test loss: 8.460e+04, MSE(e): 8.181e-05, MSE(pi1): 1.794e-02, MSE(pi2): 5.004e-05, MSE(pi3): 5.864e-03\n",
      "Epoch 40000, Train loss: 1.408e+03, Test loss: 8.388e+04, MSE(e): 7.247e-05, MSE(pi1): 1.207e-02, MSE(pi2): 4.335e-05, MSE(pi3): 5.627e-03\n",
      "Epoch 40100, Train loss: 1.393e+03, Test loss: 8.391e+04, MSE(e): 7.045e-05, MSE(pi1): 1.227e-02, MSE(pi2): 4.238e-05, MSE(pi3): 5.662e-03\n",
      "Epoch 40200, Train loss: 1.388e+03, Test loss: 8.349e+04, MSE(e): 7.003e-05, MSE(pi1): 1.329e-02, MSE(pi2): 4.235e-05, MSE(pi3): 5.551e-03\n",
      "Epoch 40300, Train loss: 1.496e+03, Test loss: 8.436e+04, MSE(e): 7.460e-05, MSE(pi1): 1.634e-02, MSE(pi2): 4.447e-05, MSE(pi3): 5.868e-03\n",
      "Epoch 40400, Train loss: 1.389e+03, Test loss: 8.360e+04, MSE(e): 7.064e-05, MSE(pi1): 1.210e-02, MSE(pi2): 4.250e-05, MSE(pi3): 5.613e-03\n",
      "Epoch 40500, Train loss: 1.563e+03, Test loss: 8.338e+04, MSE(e): 7.809e-05, MSE(pi1): 2.183e-02, MSE(pi2): 4.791e-05, MSE(pi3): 5.639e-03\n",
      "Epoch 40600, Train loss: 2.106e+03, Test loss: 8.517e+04, MSE(e): 1.419e-04, MSE(pi1): 1.187e-02, MSE(pi2): 7.178e-05, MSE(pi3): 5.687e-03\n",
      "Epoch 40700, Train loss: 1.369e+03, Test loss: 8.349e+04, MSE(e): 6.805e-05, MSE(pi1): 1.197e-02, MSE(pi2): 4.090e-05, MSE(pi3): 5.691e-03\n",
      "Epoch 40800, Train loss: 1.363e+03, Test loss: 8.344e+04, MSE(e): 6.780e-05, MSE(pi1): 1.173e-02, MSE(pi2): 4.078e-05, MSE(pi3): 5.674e-03\n",
      "Epoch 40900, Train loss: 1.596e+03, Test loss: 8.301e+04, MSE(e): 9.152e-05, MSE(pi1): 1.217e-02, MSE(pi2): 5.131e-05, MSE(pi3): 5.591e-03\n",
      "Epoch 41000, Train loss: 2.054e+03, Test loss: 8.498e+04, MSE(e): 1.316e-04, MSE(pi1): 1.509e-02, MSE(pi2): 6.757e-05, MSE(pi3): 5.875e-03\n",
      "Epoch 41100, Train loss: 1.813e+03, Test loss: 8.332e+04, MSE(e): 9.513e-05, MSE(pi1): 2.694e-02, MSE(pi2): 5.908e-05, MSE(pi3): 5.924e-03\n",
      "Epoch 41200, Train loss: 1.354e+03, Test loss: 8.322e+04, MSE(e): 6.683e-05, MSE(pi1): 1.169e-02, MSE(pi2): 4.010e-05, MSE(pi3): 5.691e-03\n",
      "Epoch 41300, Train loss: 2.731e+03, Test loss: 8.507e+04, MSE(e): 2.040e-04, MSE(pi1): 1.205e-02, MSE(pi2): 9.801e-05, MSE(pi3): 5.703e-03\n",
      "Epoch 41400, Train loss: 1.461e+03, Test loss: 8.215e+04, MSE(e): 7.121e-05, MSE(pi1): 2.099e-02, MSE(pi2): 4.391e-05, MSE(pi3): 5.388e-03\n",
      "Epoch 41500, Train loss: 1.400e+03, Test loss: 8.256e+04, MSE(e): 7.189e-05, MSE(pi1): 1.193e-02, MSE(pi2): 4.274e-05, MSE(pi3): 5.613e-03\n",
      "Epoch 41600, Train loss: 1.446e+03, Test loss: 8.290e+04, MSE(e): 7.060e-05, MSE(pi1): 1.604e-02, MSE(pi2): 4.285e-05, MSE(pi3): 5.795e-03\n",
      "Epoch 41700, Train loss: 1.341e+03, Test loss: 8.254e+04, MSE(e): 6.595e-05, MSE(pi1): 1.208e-02, MSE(pi2): 3.960e-05, MSE(pi3): 5.608e-03\n",
      "Epoch 41800, Train loss: 1.375e+03, Test loss: 8.266e+04, MSE(e): 6.868e-05, MSE(pi1): 1.229e-02, MSE(pi2): 4.099e-05, MSE(pi3): 5.656e-03\n",
      "Epoch 41900, Train loss: 1.636e+03, Test loss: 8.205e+04, MSE(e): 8.273e-05, MSE(pi1): 2.599e-02, MSE(pi2): 4.969e-05, MSE(pi3): 5.491e-03\n",
      "Epoch 42000, Train loss: 1.340e+03, Test loss: 8.251e+04, MSE(e): 6.481e-05, MSE(pi1): 1.233e-02, MSE(pi2): 3.882e-05, MSE(pi3): 5.686e-03\n",
      "Epoch 42100, Train loss: 1.371e+03, Test loss: 8.242e+04, MSE(e): 6.648e-05, MSE(pi1): 1.401e-02, MSE(pi2): 3.947e-05, MSE(pi3): 5.661e-03\n",
      "Epoch 42200, Train loss: 1.731e+03, Test loss: 8.290e+04, MSE(e): 1.022e-04, MSE(pi1): 1.410e-02, MSE(pi2): 5.467e-05, MSE(pi3): 5.680e-03\n",
      "Epoch 42300, Train loss: 1.319e+03, Test loss: 8.207e+04, MSE(e): 6.372e-05, MSE(pi1): 1.224e-02, MSE(pi2): 3.832e-05, MSE(pi3): 5.595e-03\n",
      "Epoch 42400, Train loss: 1.356e+03, Test loss: 8.224e+04, MSE(e): 6.754e-05, MSE(pi1): 1.187e-02, MSE(pi2): 3.975e-05, MSE(pi3): 5.621e-03\n",
      "Epoch 42500, Train loss: 1.327e+03, Test loss: 8.233e+04, MSE(e): 6.367e-05, MSE(pi1): 1.169e-02, MSE(pi2): 3.820e-05, MSE(pi3): 5.738e-03\n",
      "Epoch 42600, Train loss: 1.312e+03, Test loss: 8.181e+04, MSE(e): 6.316e-05, MSE(pi1): 1.206e-02, MSE(pi2): 3.793e-05, MSE(pi3): 5.598e-03\n",
      "Epoch 42700, Train loss: 1.308e+03, Test loss: 8.184e+04, MSE(e): 6.293e-05, MSE(pi1): 1.156e-02, MSE(pi2): 3.774e-05, MSE(pi3): 5.635e-03\n",
      "Epoch 42800, Train loss: 1.368e+03, Test loss: 8.217e+04, MSE(e): 6.556e-05, MSE(pi1): 1.345e-02, MSE(pi2): 3.896e-05, MSE(pi3): 5.775e-03\n",
      "Epoch 42900, Train loss: 1.412e+03, Test loss: 8.121e+04, MSE(e): 7.064e-05, MSE(pi1): 1.547e-02, MSE(pi2): 4.198e-05, MSE(pi3): 5.511e-03\n",
      "Epoch 43000, Train loss: 1.539e+03, Test loss: 8.170e+04, MSE(e): 7.580e-05, MSE(pi1): 2.248e-02, MSE(pi2): 4.415e-05, MSE(pi3): 5.560e-03\n",
      "Epoch 43100, Train loss: 1.323e+03, Test loss: 8.177e+04, MSE(e): 6.428e-05, MSE(pi1): 1.137e-02, MSE(pi2): 3.799e-05, MSE(pi3): 5.668e-03\n",
      "Epoch 43200, Train loss: 1.378e+03, Test loss: 8.191e+04, MSE(e): 6.602e-05, MSE(pi1): 1.522e-02, MSE(pi2): 4.035e-05, MSE(pi3): 5.660e-03\n",
      "Epoch 43300, Train loss: 1.292e+03, Test loss: 8.143e+04, MSE(e): 6.129e-05, MSE(pi1): 1.151e-02, MSE(pi2): 3.675e-05, MSE(pi3): 5.637e-03\n",
      "Epoch 43400, Train loss: 1.290e+03, Test loss: 8.136e+04, MSE(e): 6.113e-05, MSE(pi1): 1.163e-02, MSE(pi2): 3.665e-05, MSE(pi3): 5.625e-03\n",
      "Epoch 43500, Train loss: 1.305e+03, Test loss: 8.138e+04, MSE(e): 6.250e-05, MSE(pi1): 1.170e-02, MSE(pi2): 3.714e-05, MSE(pi3): 5.630e-03\n",
      "Epoch 43600, Train loss: 1.305e+03, Test loss: 8.155e+04, MSE(e): 6.087e-05, MSE(pi1): 1.237e-02, MSE(pi2): 3.645e-05, MSE(pi3): 5.731e-03\n",
      "Epoch 43700, Train loss: 1.328e+03, Test loss: 8.130e+04, MSE(e): 6.069e-05, MSE(pi1): 1.588e-02, MSE(pi2): 3.629e-05, MSE(pi3): 5.621e-03\n",
      "Epoch 43800, Train loss: 1.341e+03, Test loss: 8.104e+04, MSE(e): 6.536e-05, MSE(pi1): 1.315e-02, MSE(pi2): 3.868e-05, MSE(pi3): 5.554e-03\n",
      "Epoch 43900, Train loss: 1.624e+03, Test loss: 8.293e+04, MSE(e): 7.723e-05, MSE(pi1): 2.496e-02, MSE(pi2): 4.664e-05, MSE(pi3): 6.017e-03\n",
      "Epoch 44000, Train loss: 1.444e+03, Test loss: 8.133e+04, MSE(e): 6.653e-05, MSE(pi1): 2.037e-02, MSE(pi2): 4.072e-05, MSE(pi3): 5.751e-03\n",
      "Epoch 44100, Train loss: 1.362e+03, Test loss: 8.143e+04, MSE(e): 6.513e-05, MSE(pi1): 1.472e-02, MSE(pi2): 3.993e-05, MSE(pi3): 5.634e-03\n",
      "Epoch 44200, Train loss: 1.287e+03, Test loss: 8.081e+04, MSE(e): 5.979e-05, MSE(pi1): 1.290e-02, MSE(pi2): 3.585e-05, MSE(pi3): 5.601e-03\n",
      "Epoch 44300, Train loss: 1.353e+03, Test loss: 8.116e+04, MSE(e): 6.587e-05, MSE(pi1): 1.255e-02, MSE(pi2): 3.951e-05, MSE(pi3): 5.689e-03\n",
      "Epoch 44400, Train loss: 1.268e+03, Test loss: 8.087e+04, MSE(e): 5.893e-05, MSE(pi1): 1.125e-02, MSE(pi2): 3.529e-05, MSE(pi3): 5.657e-03\n",
      "Epoch 44500, Train loss: 1.328e+03, Test loss: 8.028e+04, MSE(e): 6.030e-05, MSE(pi1): 1.779e-02, MSE(pi2): 3.633e-05, MSE(pi3): 5.466e-03\n",
      "Epoch 44600, Train loss: 1.262e+03, Test loss: 8.066e+04, MSE(e): 5.830e-05, MSE(pi1): 1.160e-02, MSE(pi2): 3.491e-05, MSE(pi3): 5.628e-03\n",
      "Epoch 44700, Train loss: 1.260e+03, Test loss: 8.068e+04, MSE(e): 5.821e-05, MSE(pi1): 1.124e-02, MSE(pi2): 3.483e-05, MSE(pi3): 5.659e-03\n",
      "Epoch 44800, Train loss: 1.431e+03, Test loss: 8.037e+04, MSE(e): 7.499e-05, MSE(pi1): 1.181e-02, MSE(pi2): 4.331e-05, MSE(pi3): 5.631e-03\n",
      "Epoch 44900, Train loss: 1.643e+03, Test loss: 8.033e+04, MSE(e): 7.356e-05, MSE(pi1): 3.469e-02, MSE(pi2): 4.633e-05, MSE(pi3): 5.600e-03\n",
      "Epoch 45000, Train loss: 1.493e+03, Test loss: 8.182e+04, MSE(e): 6.614e-05, MSE(pi1): 2.281e-02, MSE(pi2): 3.969e-05, MSE(pi3): 6.037e-03\n",
      "Epoch 45100, Train loss: 1.382e+03, Test loss: 8.001e+04, MSE(e): 6.468e-05, MSE(pi1): 1.824e-02, MSE(pi2): 3.903e-05, MSE(pi3): 5.525e-03\n",
      "Epoch 45200, Train loss: 1.261e+03, Test loss: 8.010e+04, MSE(e): 5.811e-05, MSE(pi1): 1.227e-02, MSE(pi2): 3.465e-05, MSE(pi3): 5.573e-03\n",
      "Epoch 45300, Train loss: 1.285e+03, Test loss: 8.040e+04, MSE(e): 5.858e-05, MSE(pi1): 1.378e-02, MSE(pi2): 3.493e-05, MSE(pi3): 5.611e-03\n",
      "Epoch 45400, Train loss: 1.602e+03, Test loss: 8.076e+04, MSE(e): 8.936e-05, MSE(pi1): 1.561e-02, MSE(pi2): 4.766e-05, MSE(pi3): 5.523e-03\n",
      "Epoch 45500, Train loss: 1.242e+03, Test loss: 8.015e+04, MSE(e): 5.647e-05, MSE(pi1): 1.152e-02, MSE(pi2): 3.379e-05, MSE(pi3): 5.624e-03\n",
      "Epoch 45600, Train loss: 1.586e+03, Test loss: 7.996e+04, MSE(e): 8.503e-05, MSE(pi1): 1.780e-02, MSE(pi2): 4.624e-05, MSE(pi3): 5.576e-03\n",
      "Epoch 45700, Train loss: 1.312e+03, Test loss: 7.999e+04, MSE(e): 6.027e-05, MSE(pi1): 1.587e-02, MSE(pi2): 3.660e-05, MSE(pi3): 5.507e-03\n",
      "Epoch 45800, Train loss: 1.241e+03, Test loss: 8.008e+04, MSE(e): 5.644e-05, MSE(pi1): 1.128e-02, MSE(pi2): 3.365e-05, MSE(pi3): 5.640e-03\n",
      "Epoch 45900, Train loss: 1.413e+03, Test loss: 8.003e+04, MSE(e): 7.328e-05, MSE(pi1): 1.147e-02, MSE(pi2): 4.126e-05, MSE(pi3): 5.654e-03\n",
      "Epoch 46000, Train loss: 1.241e+03, Test loss: 7.987e+04, MSE(e): 5.585e-05, MSE(pi1): 1.153e-02, MSE(pi2): 3.337e-05, MSE(pi3): 5.670e-03\n",
      "Epoch 46100, Train loss: 1.976e+03, Test loss: 7.903e+04, MSE(e): 7.464e-05, MSE(pi1): 7.174e-02, MSE(pi2): 4.757e-05, MSE(pi3): 5.119e-03\n",
      "Epoch 46200, Train loss: 1.471e+03, Test loss: 7.974e+04, MSE(e): 7.901e-05, MSE(pi1): 1.174e-02, MSE(pi2): 4.349e-05, MSE(pi3): 5.633e-03\n",
      "Epoch 46300, Train loss: 1.258e+03, Test loss: 7.951e+04, MSE(e): 5.629e-05, MSE(pi1): 1.408e-02, MSE(pi2): 3.350e-05, MSE(pi3): 5.540e-03\n",
      "Epoch 46400, Train loss: 1.228e+03, Test loss: 7.967e+04, MSE(e): 5.514e-05, MSE(pi1): 1.144e-02, MSE(pi2): 3.295e-05, MSE(pi3): 5.626e-03\n",
      "Epoch 46500, Train loss: 1.229e+03, Test loss: 7.966e+04, MSE(e): 5.506e-05, MSE(pi1): 1.120e-02, MSE(pi2): 3.283e-05, MSE(pi3): 5.659e-03\n",
      "Epoch 46600, Train loss: 1.221e+03, Test loss: 7.954e+04, MSE(e): 5.444e-05, MSE(pi1): 1.132e-02, MSE(pi2): 3.252e-05, MSE(pi3): 5.630e-03\n",
      "Epoch 46700, Train loss: 1.219e+03, Test loss: 7.942e+04, MSE(e): 5.436e-05, MSE(pi1): 1.141e-02, MSE(pi2): 3.248e-05, MSE(pi3): 5.609e-03\n",
      "Epoch 46800, Train loss: 1.217e+03, Test loss: 7.945e+04, MSE(e): 5.405e-05, MSE(pi1): 1.122e-02, MSE(pi2): 3.227e-05, MSE(pi3): 5.639e-03\n",
      "Epoch 46900, Train loss: 1.214e+03, Test loss: 7.936e+04, MSE(e): 5.390e-05, MSE(pi1): 1.143e-02, MSE(pi2): 3.218e-05, MSE(pi3): 5.610e-03\n",
      "Epoch 47000, Train loss: 1.218e+03, Test loss: 7.932e+04, MSE(e): 5.423e-05, MSE(pi1): 1.151e-02, MSE(pi2): 3.227e-05, MSE(pi3): 5.608e-03\n",
      "Epoch 47100, Train loss: 1.713e+03, Test loss: 7.976e+04, MSE(e): 9.328e-05, MSE(pi1): 1.977e-02, MSE(pi2): 4.901e-05, MSE(pi3): 5.826e-03\n",
      "Epoch 47200, Train loss: 1.216e+03, Test loss: 7.915e+04, MSE(e): 5.388e-05, MSE(pi1): 1.177e-02, MSE(pi2): 3.223e-05, MSE(pi3): 5.594e-03\n",
      "Epoch 47300, Train loss: 1.214e+03, Test loss: 7.903e+04, MSE(e): 5.333e-05, MSE(pi1): 1.242e-02, MSE(pi2): 3.194e-05, MSE(pi3): 5.560e-03\n",
      "Epoch 47400, Train loss: 1.213e+03, Test loss: 7.912e+04, MSE(e): 5.321e-05, MSE(pi1): 1.196e-02, MSE(pi2): 3.172e-05, MSE(pi3): 5.616e-03\n",
      "Epoch 47500, Train loss: 1.263e+03, Test loss: 7.925e+04, MSE(e): 5.844e-05, MSE(pi1): 1.141e-02, MSE(pi2): 3.408e-05, MSE(pi3): 5.640e-03\n",
      "Epoch 47600, Train loss: 1.348e+03, Test loss: 7.941e+04, MSE(e): 6.403e-05, MSE(pi1): 1.362e-02, MSE(pi2): 3.625e-05, MSE(pi3): 5.719e-03\n",
      "Epoch 47700, Train loss: 1.663e+03, Test loss: 8.021e+04, MSE(e): 9.715e-05, MSE(pi1): 1.124e-02, MSE(pi2): 5.012e-05, MSE(pi3): 5.793e-03\n",
      "Epoch 47800, Train loss: 1.232e+03, Test loss: 7.895e+04, MSE(e): 5.469e-05, MSE(pi1): 1.255e-02, MSE(pi2): 3.247e-05, MSE(pi3): 5.591e-03\n",
      "Epoch 47900, Train loss: 1.386e+03, Test loss: 7.892e+04, MSE(e): 7.059e-05, MSE(pi1): 1.153e-02, MSE(pi2): 3.947e-05, MSE(pi3): 5.652e-03\n",
      "Epoch 48000, Train loss: 1.245e+03, Test loss: 7.884e+04, MSE(e): 5.664e-05, MSE(pi1): 1.206e-02, MSE(pi2): 3.302e-05, MSE(pi3): 5.576e-03\n",
      "Epoch 48100, Train loss: 1.202e+03, Test loss: 7.889e+04, MSE(e): 5.272e-05, MSE(pi1): 1.101e-02, MSE(pi2): 3.123e-05, MSE(pi3): 5.647e-03\n",
      "Epoch 48200, Train loss: 1.198e+03, Test loss: 7.871e+04, MSE(e): 5.235e-05, MSE(pi1): 1.130e-02, MSE(pi2): 3.129e-05, MSE(pi3): 5.613e-03\n",
      "Epoch 48300, Train loss: 1.572e+03, Test loss: 7.859e+04, MSE(e): 7.394e-05, MSE(pi1): 2.962e-02, MSE(pi2): 4.136e-05, MSE(pi3): 5.362e-03\n",
      "Epoch 48400, Train loss: 1.298e+03, Test loss: 7.864e+04, MSE(e): 5.473e-05, MSE(pi1): 1.877e-02, MSE(pi2): 3.298e-05, MSE(pi3): 5.627e-03\n",
      "Epoch 48500, Train loss: 1.636e+03, Test loss: 7.989e+04, MSE(e): 6.869e-05, MSE(pi1): 3.774e-02, MSE(pi2): 4.260e-05, MSE(pi3): 5.716e-03\n",
      "Epoch 48600, Train loss: 1.318e+03, Test loss: 7.955e+04, MSE(e): 5.702e-05, MSE(pi1): 1.618e-02, MSE(pi2): 3.408e-05, MSE(pi3): 5.863e-03\n",
      "Epoch 48700, Train loss: 1.209e+03, Test loss: 7.847e+04, MSE(e): 5.245e-05, MSE(pi1): 1.300e-02, MSE(pi2): 3.160e-05, MSE(pi3): 5.548e-03\n",
      "Epoch 48800, Train loss: 1.237e+03, Test loss: 7.869e+04, MSE(e): 5.267e-05, MSE(pi1): 1.496e-02, MSE(pi2): 3.138e-05, MSE(pi3): 5.609e-03\n",
      "Epoch 48900, Train loss: 1.204e+03, Test loss: 7.813e+04, MSE(e): 5.137e-05, MSE(pi1): 1.359e-02, MSE(pi2): 3.081e-05, MSE(pi3): 5.545e-03\n",
      "Epoch 49000, Train loss: 1.200e+03, Test loss: 7.842e+04, MSE(e): 5.079e-05, MSE(pi1): 1.276e-02, MSE(pi2): 3.026e-05, MSE(pi3): 5.643e-03\n",
      "Epoch 49100, Train loss: 1.199e+03, Test loss: 7.824e+04, MSE(e): 5.229e-05, MSE(pi1): 1.159e-02, MSE(pi2): 3.125e-05, MSE(pi3): 5.602e-03\n",
      "Epoch 49200, Train loss: 1.248e+03, Test loss: 7.842e+04, MSE(e): 5.741e-05, MSE(pi1): 1.126e-02, MSE(pi2): 3.284e-05, MSE(pi3): 5.616e-03\n",
      "Epoch 49300, Train loss: 1.553e+03, Test loss: 7.953e+04, MSE(e): 5.938e-05, MSE(pi1): 3.398e-02, MSE(pi2): 3.590e-05, MSE(pi3): 6.198e-03\n",
      "Epoch 49400, Train loss: 1.240e+03, Test loss: 7.815e+04, MSE(e): 5.671e-05, MSE(pi1): 1.139e-02, MSE(pi2): 3.282e-05, MSE(pi3): 5.586e-03\n",
      "Epoch 49500, Train loss: 1.173e+03, Test loss: 7.810e+04, MSE(e): 4.992e-05, MSE(pi1): 1.141e-02, MSE(pi2): 2.973e-05, MSE(pi3): 5.592e-03\n",
      "Epoch 49600, Train loss: 1.233e+03, Test loss: 7.795e+04, MSE(e): 5.090e-05, MSE(pi1): 1.681e-02, MSE(pi2): 3.051e-05, MSE(pi3): 5.554e-03\n",
      "Epoch 49700, Train loss: 1.637e+03, Test loss: 7.923e+04, MSE(e): 7.881e-05, MSE(pi1): 2.551e-02, MSE(pi2): 4.677e-05, MSE(pi3): 5.933e-03\n",
      "Epoch 49800, Train loss: 1.180e+03, Test loss: 7.817e+04, MSE(e): 5.053e-05, MSE(pi1): 1.091e-02, MSE(pi2): 2.991e-05, MSE(pi3): 5.656e-03\n",
      "Epoch 49900, Train loss: 1.174e+03, Test loss: 7.801e+04, MSE(e): 4.988e-05, MSE(pi1): 1.129e-02, MSE(pi2): 2.968e-05, MSE(pi3): 5.626e-03\n",
      "Epoch 50000, Train loss: 1.266e+03, Test loss: 7.780e+04, MSE(e): 5.905e-05, MSE(pi1): 1.228e-02, MSE(pi2): 3.404e-05, MSE(pi3): 5.530e-03\n",
      "Epoch 50100, Train loss: 1.173e+03, Test loss: 7.779e+04, MSE(e): 4.916e-05, MSE(pi1): 1.263e-02, MSE(pi2): 2.934e-05, MSE(pi3): 5.549e-03\n",
      "Epoch 50200, Train loss: 2.075e+03, Test loss: 7.909e+04, MSE(e): 1.271e-04, MSE(pi1): 2.350e-02, MSE(pi2): 6.439e-05, MSE(pi3): 5.685e-03\n",
      "Epoch 50300, Train loss: 1.204e+03, Test loss: 7.784e+04, MSE(e): 5.074e-05, MSE(pi1): 1.427e-02, MSE(pi2): 3.046e-05, MSE(pi3): 5.533e-03\n",
      "Epoch 50400, Train loss: 1.297e+03, Test loss: 7.863e+04, MSE(e): 5.477e-05, MSE(pi1): 1.659e-02, MSE(pi2): 3.172e-05, MSE(pi3): 5.832e-03\n",
      "Epoch 50500, Train loss: 1.165e+03, Test loss: 7.762e+04, MSE(e): 4.852e-05, MSE(pi1): 1.236e-02, MSE(pi2): 2.893e-05, MSE(pi3): 5.565e-03\n",
      "Epoch 50600, Train loss: 1.663e+03, Test loss: 7.756e+04, MSE(e): 9.736e-05, MSE(pi1): 1.308e-02, MSE(pi2): 5.242e-05, MSE(pi3): 5.587e-03\n",
      "Epoch 50700, Train loss: 1.160e+03, Test loss: 7.781e+04, MSE(e): 4.817e-05, MSE(pi1): 1.169e-02, MSE(pi2): 2.866e-05, MSE(pi3): 5.611e-03\n",
      "Epoch 50800, Train loss: 1.668e+03, Test loss: 7.898e+04, MSE(e): 9.061e-05, MSE(pi1): 1.751e-02, MSE(pi2): 4.736e-05, MSE(pi3): 5.870e-03\n",
      "Epoch 50900, Train loss: 1.180e+03, Test loss: 7.783e+04, MSE(e): 5.007e-05, MSE(pi1): 1.147e-02, MSE(pi2): 2.979e-05, MSE(pi3): 5.648e-03\n",
      "Epoch 51000, Train loss: 1.292e+03, Test loss: 7.712e+04, MSE(e): 5.707e-05, MSE(pi1): 1.783e-02, MSE(pi2): 3.416e-05, MSE(pi3): 5.426e-03\n",
      "Epoch 51100, Train loss: 1.194e+03, Test loss: 7.780e+04, MSE(e): 4.949e-05, MSE(pi1): 1.271e-02, MSE(pi2): 2.944e-05, MSE(pi3): 5.720e-03\n",
      "Epoch 51200, Train loss: 1.238e+03, Test loss: 7.792e+04, MSE(e): 5.091e-05, MSE(pi1): 1.637e-02, MSE(pi2): 3.041e-05, MSE(pi3): 5.657e-03\n",
      "Epoch 51300, Train loss: 1.712e+03, Test loss: 7.829e+04, MSE(e): 1.039e-04, MSE(pi1): 1.104e-02, MSE(pi2): 5.278e-05, MSE(pi3): 5.625e-03\n",
      "Epoch 51400, Train loss: 1.323e+03, Test loss: 7.681e+04, MSE(e): 5.641e-05, MSE(pi1): 2.193e-02, MSE(pi2): 3.532e-05, MSE(pi3): 5.394e-03\n",
      "Epoch 51500, Train loss: 1.345e+03, Test loss: 7.871e+04, MSE(e): 5.791e-05, MSE(pi1): 1.741e-02, MSE(pi2): 3.439e-05, MSE(pi3): 5.919e-03\n",
      "Epoch 51600, Train loss: 1.518e+03, Test loss: 7.782e+04, MSE(e): 8.341e-05, MSE(pi1): 1.272e-02, MSE(pi2): 4.333e-05, MSE(pi3): 5.565e-03\n",
      "Epoch 51700, Train loss: 1.206e+03, Test loss: 7.696e+04, MSE(e): 4.844e-05, MSE(pi1): 1.548e-02, MSE(pi2): 2.894e-05, MSE(pi3): 5.667e-03\n",
      "Epoch 51800, Train loss: 1.424e+03, Test loss: 7.730e+04, MSE(e): 5.627e-05, MSE(pi1): 2.987e-02, MSE(pi2): 3.479e-05, MSE(pi3): 5.629e-03\n",
      "Epoch 51900, Train loss: 1.216e+03, Test loss: 7.694e+04, MSE(e): 4.900e-05, MSE(pi1): 1.828e-02, MSE(pi2): 2.939e-05, MSE(pi3): 5.434e-03\n",
      "Epoch 52000, Train loss: 1.142e+03, Test loss: 7.727e+04, MSE(e): 4.684e-05, MSE(pi1): 1.118e-02, MSE(pi2): 2.782e-05, MSE(pi3): 5.613e-03\n",
      "Epoch 52100, Train loss: 1.235e+03, Test loss: 7.755e+04, MSE(e): 5.044e-05, MSE(pi1): 1.466e-02, MSE(pi2): 3.034e-05, MSE(pi3): 5.841e-03\n",
      "Epoch 52200, Train loss: 1.604e+03, Test loss: 7.799e+04, MSE(e): 9.245e-05, MSE(pi1): 1.075e-02, MSE(pi2): 4.667e-05, MSE(pi3): 5.718e-03\n",
      "Epoch 52300, Train loss: 2.479e+03, Test loss: 7.839e+04, MSE(e): 1.738e-04, MSE(pi1): 1.749e-02, MSE(pi2): 8.586e-05, MSE(pi3): 5.659e-03\n",
      "Epoch 52400, Train loss: 1.132e+03, Test loss: 7.706e+04, MSE(e): 4.597e-05, MSE(pi1): 1.141e-02, MSE(pi2): 2.734e-05, MSE(pi3): 5.586e-03\n",
      "Epoch 52500, Train loss: 1.460e+03, Test loss: 7.867e+04, MSE(e): 5.194e-05, MSE(pi1): 3.302e-02, MSE(pi2): 3.108e-05, MSE(pi3): 6.104e-03\n",
      "Epoch 52600, Train loss: 1.154e+03, Test loss: 7.704e+04, MSE(e): 4.688e-05, MSE(pi1): 1.286e-02, MSE(pi2): 2.797e-05, MSE(pi3): 5.564e-03\n",
      "Epoch 52700, Train loss: 1.125e+03, Test loss: 7.695e+04, MSE(e): 4.550e-05, MSE(pi1): 1.095e-02, MSE(pi2): 2.705e-05, MSE(pi3): 5.606e-03\n",
      "Epoch 52800, Train loss: 1.130e+03, Test loss: 7.708e+04, MSE(e): 4.565e-05, MSE(pi1): 1.073e-02, MSE(pi2): 2.713e-05, MSE(pi3): 5.666e-03\n",
      "Epoch 52900, Train loss: 1.198e+03, Test loss: 7.683e+04, MSE(e): 5.169e-05, MSE(pi1): 1.262e-02, MSE(pi2): 2.986e-05, MSE(pi3): 5.553e-03\n",
      "Epoch 53000, Train loss: 1.421e+03, Test loss: 7.681e+04, MSE(e): 6.786e-05, MSE(pi1): 1.993e-02, MSE(pi2): 3.755e-05, MSE(pi3): 5.431e-03\n",
      "Epoch 53100, Train loss: 1.509e+03, Test loss: 7.684e+04, MSE(e): 5.685e-05, MSE(pi1): 3.881e-02, MSE(pi2): 3.532e-05, MSE(pi3): 5.525e-03\n",
      "Epoch 53200, Train loss: 1.148e+03, Test loss: 7.701e+04, MSE(e): 4.768e-05, MSE(pi1): 1.081e-02, MSE(pi2): 2.774e-05, MSE(pi3): 5.627e-03\n",
      "Epoch 53300, Train loss: 1.128e+03, Test loss: 7.669e+04, MSE(e): 4.512e-05, MSE(pi1): 1.188e-02, MSE(pi2): 2.687e-05, MSE(pi3): 5.578e-03\n",
      "Epoch 53400, Train loss: 1.251e+03, Test loss: 7.669e+04, MSE(e): 4.815e-05, MSE(pi1): 2.174e-02, MSE(pi2): 2.887e-05, MSE(pi3): 5.525e-03\n",
      "Epoch 53500, Train loss: 1.175e+03, Test loss: 7.660e+04, MSE(e): 4.696e-05, MSE(pi1): 1.520e-02, MSE(pi2): 2.797e-05, MSE(pi3): 5.537e-03\n",
      "Epoch 53600, Train loss: 1.113e+03, Test loss: 7.675e+04, MSE(e): 4.434e-05, MSE(pi1): 1.084e-02, MSE(pi2): 2.634e-05, MSE(pi3): 5.611e-03\n",
      "Epoch 53700, Train loss: 1.423e+03, Test loss: 7.602e+04, MSE(e): 5.301e-05, MSE(pi1): 3.653e-02, MSE(pi2): 3.254e-05, MSE(pi3): 5.280e-03\n",
      "Epoch 53800, Train loss: 1.122e+03, Test loss: 7.682e+04, MSE(e): 4.450e-05, MSE(pi1): 1.085e-02, MSE(pi2): 2.641e-05, MSE(pi3): 5.683e-03\n",
      "Epoch 53900, Train loss: 1.144e+03, Test loss: 7.680e+04, MSE(e): 4.508e-05, MSE(pi1): 1.315e-02, MSE(pi2): 2.683e-05, MSE(pi3): 5.621e-03\n",
      "Epoch 54000, Train loss: 1.287e+03, Test loss: 7.767e+04, MSE(e): 4.793e-05, MSE(pi1): 2.132e-02, MSE(pi2): 2.841e-05, MSE(pi3): 5.943e-03\n",
      "Epoch 54100, Train loss: 1.127e+03, Test loss: 7.656e+04, MSE(e): 4.585e-05, MSE(pi1): 1.085e-02, MSE(pi2): 2.698e-05, MSE(pi3): 5.602e-03\n",
      "Epoch 54200, Train loss: 1.313e+03, Test loss: 7.780e+04, MSE(e): 4.956e-05, MSE(pi1): 2.159e-02, MSE(pi2): 2.993e-05, MSE(pi3): 6.015e-03\n",
      "Epoch 54300, Train loss: 1.187e+03, Test loss: 7.685e+04, MSE(e): 4.883e-05, MSE(pi1): 1.371e-02, MSE(pi2): 2.931e-05, MSE(pi3): 5.613e-03\n",
      "Epoch 54400, Train loss: 1.205e+03, Test loss: 7.707e+04, MSE(e): 5.040e-05, MSE(pi1): 1.256e-02, MSE(pi2): 3.001e-05, MSE(pi3): 5.750e-03\n",
      "Epoch 54500, Train loss: 1.575e+03, Test loss: 7.715e+04, MSE(e): 8.998e-05, MSE(pi1): 1.131e-02, MSE(pi2): 4.623e-05, MSE(pi3): 5.622e-03\n",
      "Epoch 54600, Train loss: 1.159e+03, Test loss: 7.607e+04, MSE(e): 4.572e-05, MSE(pi1): 1.491e-02, MSE(pi2): 2.762e-05, MSE(pi3): 5.523e-03\n",
      "Epoch 54700, Train loss: 1.517e+03, Test loss: 7.714e+04, MSE(e): 5.664e-05, MSE(pi1): 3.670e-02, MSE(pi2): 3.524e-05, MSE(pi3): 5.840e-03\n",
      "Epoch 54800, Train loss: 1.100e+03, Test loss: 7.634e+04, MSE(e): 4.303e-05, MSE(pi1): 1.067e-02, MSE(pi2): 2.552e-05, MSE(pi3): 5.629e-03\n",
      "Epoch 54900, Train loss: 1.479e+03, Test loss: 7.551e+04, MSE(e): 5.542e-05, MSE(pi1): 4.003e-02, MSE(pi2): 3.512e-05, MSE(pi3): 5.243e-03\n",
      "Epoch 55000, Train loss: 1.123e+03, Test loss: 7.654e+04, MSE(e): 4.400e-05, MSE(pi1): 1.152e-02, MSE(pi2): 2.608e-05, MSE(pi3): 5.681e-03\n",
      "Epoch 55100, Train loss: 1.097e+03, Test loss: 7.633e+04, MSE(e): 4.271e-05, MSE(pi1): 1.051e-02, MSE(pi2): 2.532e-05, MSE(pi3): 5.647e-03\n",
      "Epoch 55200, Train loss: 1.100e+03, Test loss: 7.633e+04, MSE(e): 4.286e-05, MSE(pi1): 1.064e-02, MSE(pi2): 2.539e-05, MSE(pi3): 5.646e-03\n",
      "Epoch 55300, Train loss: 1.097e+03, Test loss: 7.621e+04, MSE(e): 4.277e-05, MSE(pi1): 1.088e-02, MSE(pi2): 2.530e-05, MSE(pi3): 5.601e-03\n",
      "Epoch 55400, Train loss: 1.115e+03, Test loss: 7.616e+04, MSE(e): 4.431e-05, MSE(pi1): 1.129e-02, MSE(pi2): 2.609e-05, MSE(pi3): 5.589e-03\n",
      "Epoch 55500, Train loss: 1.729e+03, Test loss: 7.658e+04, MSE(e): 1.037e-04, MSE(pi1): 1.173e-02, MSE(pi2): 5.055e-05, MSE(pi3): 5.742e-03\n",
      "Epoch 55600, Train loss: 1.506e+03, Test loss: 7.592e+04, MSE(e): 7.812e-05, MSE(pi1): 1.800e-02, MSE(pi2): 4.121e-05, MSE(pi3): 5.443e-03\n",
      "Epoch 55700, Train loss: 1.200e+03, Test loss: 7.654e+04, MSE(e): 5.258e-05, MSE(pi1): 1.080e-02, MSE(pi2): 3.014e-05, MSE(pi3): 5.665e-03\n",
      "Epoch 55800, Train loss: 1.364e+03, Test loss: 7.754e+04, MSE(e): 4.910e-05, MSE(pi1): 2.735e-02, MSE(pi2): 2.964e-05, MSE(pi3): 5.998e-03\n",
      "Epoch 55900, Train loss: 1.432e+03, Test loss: 7.641e+04, MSE(e): 7.101e-05, MSE(pi1): 1.625e-02, MSE(pi2): 3.776e-05, MSE(pi3): 5.593e-03\n",
      "Epoch 56000, Train loss: 1.128e+03, Test loss: 7.596e+04, MSE(e): 4.465e-05, MSE(pi1): 1.295e-02, MSE(pi2): 2.637e-05, MSE(pi3): 5.520e-03\n",
      "Epoch 56100, Train loss: 1.327e+03, Test loss: 7.639e+04, MSE(e): 5.314e-05, MSE(pi1): 2.111e-02, MSE(pi2): 3.294e-05, MSE(pi3): 5.845e-03\n",
      "Epoch 56200, Train loss: 1.215e+03, Test loss: 7.615e+04, MSE(e): 4.657e-05, MSE(pi1): 1.813e-02, MSE(pi2): 2.730e-05, MSE(pi3): 5.679e-03\n",
      "Epoch 56300, Train loss: 1.677e+03, Test loss: 7.650e+04, MSE(e): 9.942e-05, MSE(pi1): 1.240e-02, MSE(pi2): 4.877e-05, MSE(pi3): 5.586e-03\n",
      "Epoch 56400, Train loss: 1.087e+03, Test loss: 7.606e+04, MSE(e): 4.146e-05, MSE(pi1): 1.049e-02, MSE(pi2): 2.454e-05, MSE(pi3): 5.672e-03\n",
      "Epoch 56500, Train loss: 1.086e+03, Test loss: 7.592e+04, MSE(e): 4.153e-05, MSE(pi1): 1.112e-02, MSE(pi2): 2.456e-05, MSE(pi3): 5.593e-03\n",
      "Epoch 56600, Train loss: 1.132e+03, Test loss: 7.628e+04, MSE(e): 4.609e-05, MSE(pi1): 1.069e-02, MSE(pi2): 2.746e-05, MSE(pi3): 5.643e-03\n",
      "Epoch 56700, Train loss: 1.113e+03, Test loss: 7.584e+04, MSE(e): 4.438e-05, MSE(pi1): 1.072e-02, MSE(pi2): 2.594e-05, MSE(pi3): 5.620e-03\n",
      "Epoch 56800, Train loss: 1.079e+03, Test loss: 7.581e+04, MSE(e): 4.107e-05, MSE(pi1): 1.063e-02, MSE(pi2): 2.431e-05, MSE(pi3): 5.616e-03\n",
      "Epoch 56900, Train loss: 1.795e+03, Test loss: 7.850e+04, MSE(e): 6.243e-05, MSE(pi1): 5.243e-02, MSE(pi2): 3.945e-05, MSE(pi3): 6.461e-03\n",
      "Epoch 57000, Train loss: 1.696e+03, Test loss: 7.625e+04, MSE(e): 1.025e-04, MSE(pi1): 1.176e-02, MSE(pi2): 5.140e-05, MSE(pi3): 5.534e-03\n",
      "Epoch 57100, Train loss: 1.212e+03, Test loss: 7.588e+04, MSE(e): 5.147e-05, MSE(pi1): 1.364e-02, MSE(pi2): 2.960e-05, MSE(pi3): 5.606e-03\n",
      "Epoch 57200, Train loss: 1.429e+03, Test loss: 7.709e+04, MSE(e): 5.625e-05, MSE(pi1): 2.720e-02, MSE(pi2): 3.291e-05, MSE(pi3): 5.949e-03\n",
      "Epoch 57300, Train loss: 1.307e+03, Test loss: 7.513e+04, MSE(e): 4.620e-05, MSE(pi1): 3.137e-02, MSE(pi2): 2.829e-05, MSE(pi3): 5.315e-03\n",
      "Epoch 57400, Train loss: 1.083e+03, Test loss: 7.559e+04, MSE(e): 4.156e-05, MSE(pi1): 1.092e-02, MSE(pi2): 2.464e-05, MSE(pi3): 5.584e-03\n",
      "Epoch 57500, Train loss: 1.073e+03, Test loss: 7.562e+04, MSE(e): 4.043e-05, MSE(pi1): 1.100e-02, MSE(pi2): 2.395e-05, MSE(pi3): 5.589e-03\n",
      "Epoch 57600, Train loss: 1.150e+03, Test loss: 7.622e+04, MSE(e): 4.507e-05, MSE(pi1): 1.217e-02, MSE(pi2): 2.584e-05, MSE(pi3): 5.777e-03\n",
      "Epoch 57700, Train loss: 2.100e+03, Test loss: 7.639e+04, MSE(e): 8.933e-05, MSE(pi1): 6.245e-02, MSE(pi2): 5.363e-05, MSE(pi3): 5.824e-03\n",
      "Epoch 57800, Train loss: 1.285e+03, Test loss: 7.515e+04, MSE(e): 5.018e-05, MSE(pi1): 2.463e-02, MSE(pi2): 2.980e-05, MSE(pi3): 5.368e-03\n",
      "Epoch 57900, Train loss: 1.141e+03, Test loss: 7.612e+04, MSE(e): 4.269e-05, MSE(pi1): 1.353e-02, MSE(pi2): 2.477e-05, MSE(pi3): 5.783e-03\n",
      "Epoch 58000, Train loss: 1.247e+03, Test loss: 7.624e+04, MSE(e): 5.697e-05, MSE(pi1): 1.117e-02, MSE(pi2): 3.217e-05, MSE(pi3): 5.656e-03\n",
      "Epoch 58100, Train loss: 1.152e+03, Test loss: 7.523e+04, MSE(e): 4.178e-05, MSE(pi1): 1.913e-02, MSE(pi2): 2.517e-05, MSE(pi3): 5.425e-03\n",
      "Epoch 58200, Train loss: 1.066e+03, Test loss: 7.553e+04, MSE(e): 3.987e-05, MSE(pi1): 1.055e-02, MSE(pi2): 2.362e-05, MSE(pi3): 5.622e-03\n",
      "Epoch 58300, Train loss: 2.034e+03, Test loss: 7.694e+04, MSE(e): 1.354e-04, MSE(pi1): 1.092e-02, MSE(pi2): 6.354e-05, MSE(pi3): 5.701e-03\n",
      "Epoch 58400, Train loss: 1.100e+03, Test loss: 7.575e+04, MSE(e): 4.095e-05, MSE(pi1): 1.174e-02, MSE(pi2): 2.399e-05, MSE(pi3): 5.734e-03\n",
      "Epoch 58500, Train loss: 1.096e+03, Test loss: 7.513e+04, MSE(e): 4.079e-05, MSE(pi1): 1.390e-02, MSE(pi2): 2.436e-05, MSE(pi3): 5.493e-03\n",
      "Epoch 58600, Train loss: 1.825e+03, Test loss: 7.597e+04, MSE(e): 8.724e-05, MSE(pi1): 3.669e-02, MSE(pi2): 5.692e-05, MSE(pi3): 5.853e-03\n",
      "Epoch 58700, Train loss: 1.607e+03, Test loss: 7.544e+04, MSE(e): 9.249e-05, MSE(pi1): 1.378e-02, MSE(pi2): 4.717e-05, MSE(pi3): 5.447e-03\n",
      "Epoch 58800, Train loss: 1.082e+03, Test loss: 7.579e+04, MSE(e): 4.098e-05, MSE(pi1): 1.040e-02, MSE(pi2): 2.432e-05, MSE(pi3): 5.685e-03\n",
      "Epoch 58900, Train loss: 1.081e+03, Test loss: 7.519e+04, MSE(e): 4.026e-05, MSE(pi1): 1.266e-02, MSE(pi2): 2.379e-05, MSE(pi3): 5.521e-03\n",
      "Epoch 59000, Train loss: 1.081e+03, Test loss: 7.535e+04, MSE(e): 4.094e-05, MSE(pi1): 1.141e-02, MSE(pi2): 2.416e-05, MSE(pi3): 5.570e-03\n",
      "Epoch 59100, Train loss: 1.057e+03, Test loss: 7.530e+04, MSE(e): 3.907e-05, MSE(pi1): 1.070e-02, MSE(pi2): 2.310e-05, MSE(pi3): 5.596e-03\n",
      "Epoch 59200, Train loss: 1.167e+03, Test loss: 7.491e+04, MSE(e): 4.363e-05, MSE(pi1): 1.823e-02, MSE(pi2): 2.670e-05, MSE(pi3): 5.488e-03\n",
      "Epoch 59300, Train loss: 1.110e+03, Test loss: 7.549e+04, MSE(e): 4.272e-05, MSE(pi1): 1.134e-02, MSE(pi2): 2.487e-05, MSE(pi3): 5.693e-03\n",
      "Epoch 59400, Train loss: 1.074e+03, Test loss: 7.516e+04, MSE(e): 4.067e-05, MSE(pi1): 1.099e-02, MSE(pi2): 2.390e-05, MSE(pi3): 5.572e-03\n",
      "Epoch 59500, Train loss: 1.106e+03, Test loss: 7.501e+04, MSE(e): 4.063e-05, MSE(pi1): 1.521e-02, MSE(pi2): 2.432e-05, MSE(pi3): 5.479e-03\n",
      "Epoch 59600, Train loss: 1.179e+03, Test loss: 7.505e+04, MSE(e): 4.293e-05, MSE(pi1): 1.931e-02, MSE(pi2): 2.606e-05, MSE(pi3): 5.571e-03\n",
      "Epoch 59700, Train loss: 1.739e+03, Test loss: 7.508e+04, MSE(e): 9.174e-05, MSE(pi1): 2.960e-02, MSE(pi2): 4.859e-05, MSE(pi3): 5.257e-03\n",
      "Epoch 59800, Train loss: 1.071e+03, Test loss: 7.541e+04, MSE(e): 4.035e-05, MSE(pi1): 1.032e-02, MSE(pi2): 2.373e-05, MSE(pi3): 5.646e-03\n",
      "Epoch 59900, Train loss: 2.003e+03, Test loss: 7.640e+04, MSE(e): 1.013e-04, MSE(pi1): 3.910e-02, MSE(pi2): 5.056e-05, MSE(pi3): 5.989e-03\n",
      "Epoch 60000, Train loss: 1.267e+03, Test loss: 7.495e+04, MSE(e): 5.921e-05, MSE(pi1): 1.059e-02, MSE(pi2): 3.262e-05, MSE(pi3): 5.689e-03\n",
      "Epoch 60100, Train loss: 1.227e+03, Test loss: 7.532e+04, MSE(e): 5.509e-05, MSE(pi1): 1.143e-02, MSE(pi2): 2.963e-05, MSE(pi3): 5.616e-03\n",
      "Epoch 60200, Train loss: 1.059e+03, Test loss: 7.517e+04, MSE(e): 3.867e-05, MSE(pi1): 1.047e-02, MSE(pi2): 2.290e-05, MSE(pi3): 5.680e-03\n",
      "Epoch 60300, Train loss: 1.047e+03, Test loss: 7.508e+04, MSE(e): 3.809e-05, MSE(pi1): 1.050e-02, MSE(pi2): 2.255e-05, MSE(pi3): 5.607e-03\n",
      "Epoch 60400, Train loss: 1.046e+03, Test loss: 7.508e+04, MSE(e): 3.797e-05, MSE(pi1): 1.033e-02, MSE(pi2): 2.246e-05, MSE(pi3): 5.626e-03\n",
      "Epoch 60500, Train loss: 1.080e+03, Test loss: 7.495e+04, MSE(e): 4.127e-05, MSE(pi1): 1.085e-02, MSE(pi2): 2.387e-05, MSE(pi3): 5.593e-03\n",
      "Epoch 60600, Train loss: 1.120e+03, Test loss: 7.508e+04, MSE(e): 3.972e-05, MSE(pi1): 1.690e-02, MSE(pi2): 2.384e-05, MSE(pi3): 5.536e-03\n",
      "Epoch 60700, Train loss: 1.046e+03, Test loss: 7.510e+04, MSE(e): 3.790e-05, MSE(pi1): 1.027e-02, MSE(pi2): 2.233e-05, MSE(pi3): 5.643e-03\n",
      "Epoch 60800, Train loss: 1.169e+03, Test loss: 7.516e+04, MSE(e): 4.956e-05, MSE(pi1): 1.127e-02, MSE(pi2): 2.715e-05, MSE(pi3): 5.604e-03\n",
      "Epoch 60900, Train loss: 1.088e+03, Test loss: 7.461e+04, MSE(e): 3.839e-05, MSE(pi1): 1.541e-02, MSE(pi2): 2.288e-05, MSE(pi3): 5.500e-03\n",
      "Epoch 61000, Train loss: 1.046e+03, Test loss: 7.489e+04, MSE(e): 3.798e-05, MSE(pi1): 1.045e-02, MSE(pi2): 2.251e-05, MSE(pi3): 5.616e-03\n",
      "Epoch 61100, Train loss: 1.475e+03, Test loss: 7.435e+04, MSE(e): 6.042e-05, MSE(pi1): 3.312e-02, MSE(pi2): 3.973e-05, MSE(pi3): 5.392e-03\n",
      "Epoch 61200, Train loss: 1.040e+03, Test loss: 7.496e+04, MSE(e): 3.741e-05, MSE(pi1): 1.045e-02, MSE(pi2): 2.212e-05, MSE(pi3): 5.610e-03\n",
      "Epoch 61300, Train loss: 1.148e+03, Test loss: 7.481e+04, MSE(e): 4.733e-05, MSE(pi1): 1.206e-02, MSE(pi2): 2.660e-05, MSE(pi3): 5.542e-03\n",
      "Epoch 61400, Train loss: 1.265e+03, Test loss: 7.492e+04, MSE(e): 5.725e-05, MSE(pi1): 1.337e-02, MSE(pi2): 3.075e-05, MSE(pi3): 5.584e-03\n",
      "Epoch 61500, Train loss: 1.061e+03, Test loss: 7.480e+04, MSE(e): 3.930e-05, MSE(pi1): 1.108e-02, MSE(pi2): 2.304e-05, MSE(pi3): 5.570e-03\n",
      "Epoch 61600, Train loss: 1.087e+03, Test loss: 7.488e+04, MSE(e): 4.074e-05, MSE(pi1): 1.140e-02, MSE(pi2): 2.331e-05, MSE(pi3): 5.656e-03\n",
      "Epoch 61700, Train loss: 1.177e+03, Test loss: 7.479e+04, MSE(e): 4.299e-05, MSE(pi1): 1.932e-02, MSE(pi2): 2.491e-05, MSE(pi3): 5.542e-03\n",
      "Epoch 61800, Train loss: 1.049e+03, Test loss: 7.473e+04, MSE(e): 3.821e-05, MSE(pi1): 1.099e-02, MSE(pi2): 2.235e-05, MSE(pi3): 5.572e-03\n",
      "Epoch 61900, Train loss: 1.051e+03, Test loss: 7.483e+04, MSE(e): 3.853e-05, MSE(pi1): 1.050e-02, MSE(pi2): 2.248e-05, MSE(pi3): 5.608e-03\n",
      "Epoch 62000, Train loss: 1.363e+03, Test loss: 7.507e+04, MSE(e): 6.773e-05, MSE(pi1): 1.170e-02, MSE(pi2): 3.511e-05, MSE(pi3): 5.684e-03\n",
      "Epoch 62100, Train loss: 1.427e+03, Test loss: 7.542e+04, MSE(e): 5.919e-05, MSE(pi1): 2.311e-02, MSE(pi2): 3.289e-05, MSE(pi3): 6.042e-03\n",
      "Epoch 62200, Train loss: 1.952e+03, Test loss: 7.607e+04, MSE(e): 1.043e-04, MSE(pi1): 3.125e-02, MSE(pi2): 5.390e-05, MSE(pi3): 5.962e-03\n",
      "Epoch 62300, Train loss: 1.154e+03, Test loss: 7.513e+04, MSE(e): 4.896e-05, MSE(pi1): 1.019e-02, MSE(pi2): 2.772e-05, MSE(pi3): 5.626e-03\n",
      "Epoch 62400, Train loss: 1.057e+03, Test loss: 7.416e+04, MSE(e): 3.758e-05, MSE(pi1): 1.274e-02, MSE(pi2): 2.257e-05, MSE(pi3): 5.542e-03\n",
      "Epoch 62500, Train loss: 1.028e+03, Test loss: 7.467e+04, MSE(e): 3.636e-05, MSE(pi1): 1.036e-02, MSE(pi2): 2.150e-05, MSE(pi3): 5.609e-03\n",
      "Epoch 62600, Train loss: 1.028e+03, Test loss: 7.467e+04, MSE(e): 3.630e-05, MSE(pi1): 1.025e-02, MSE(pi2): 2.145e-05, MSE(pi3): 5.624e-03\n",
      "Epoch 62700, Train loss: 1.104e+03, Test loss: 7.484e+04, MSE(e): 3.714e-05, MSE(pi1): 1.630e-02, MSE(pi2): 2.181e-05, MSE(pi3): 5.697e-03\n",
      "Epoch 62800, Train loss: 1.072e+03, Test loss: 7.439e+04, MSE(e): 3.852e-05, MSE(pi1): 1.354e-02, MSE(pi2): 2.257e-05, MSE(pi3): 5.510e-03\n",
      "Epoch 62900, Train loss: 1.139e+03, Test loss: 7.407e+04, MSE(e): 4.136e-05, MSE(pi1): 1.851e-02, MSE(pi2): 2.532e-05, MSE(pi3): 5.407e-03\n",
      "Epoch 63000, Train loss: 1.182e+03, Test loss: 7.495e+04, MSE(e): 4.766e-05, MSE(pi1): 1.400e-02, MSE(pi2): 2.665e-05, MSE(pi3): 5.655e-03\n",
      "Epoch 63100, Train loss: 1.135e+03, Test loss: 7.457e+04, MSE(e): 4.593e-05, MSE(pi1): 1.179e-02, MSE(pi2): 2.604e-05, MSE(pi3): 5.581e-03\n",
      "Epoch 63200, Train loss: 1.028e+03, Test loss: 7.450e+04, MSE(e): 3.601e-05, MSE(pi1): 1.103e-02, MSE(pi2): 2.133e-05, MSE(pi3): 5.572e-03\n",
      "Epoch 63300, Train loss: 1.896e+03, Test loss: 7.545e+04, MSE(e): 1.214e-04, MSE(pi1): 1.279e-02, MSE(pi2): 5.938e-05, MSE(pi3): 5.539e-03\n",
      "Epoch 63400, Train loss: 1.211e+03, Test loss: 7.418e+04, MSE(e): 4.808e-05, MSE(pi1): 1.802e-02, MSE(pi2): 2.854e-05, MSE(pi3): 5.500e-03\n",
      "Epoch 63500, Train loss: 1.250e+03, Test loss: 7.483e+04, MSE(e): 5.649e-05, MSE(pi1): 1.199e-02, MSE(pi2): 3.040e-05, MSE(pi3): 5.649e-03\n",
      "Epoch 63600, Train loss: 1.363e+03, Test loss: 7.495e+04, MSE(e): 6.948e-05, MSE(pi1): 1.083e-02, MSE(pi2): 3.582e-05, MSE(pi3): 5.595e-03\n",
      "Epoch 63700, Train loss: 1.952e+03, Test loss: 7.481e+04, MSE(e): 1.201e-04, MSE(pi1): 2.086e-02, MSE(pi2): 7.293e-05, MSE(pi3): 5.427e-03\n",
      "Epoch 63800, Train loss: 1.025e+03, Test loss: 7.444e+04, MSE(e): 3.586e-05, MSE(pi1): 1.041e-02, MSE(pi2): 2.120e-05, MSE(pi3): 5.625e-03\n",
      "Epoch 63900, Train loss: 1.137e+03, Test loss: 7.436e+04, MSE(e): 4.278e-05, MSE(pi1): 1.611e-02, MSE(pi2): 2.552e-05, MSE(pi3): 5.481e-03\n",
      "Epoch 64000, Train loss: 1.029e+03, Test loss: 7.444e+04, MSE(e): 3.641e-05, MSE(pi1): 1.037e-02, MSE(pi2): 2.146e-05, MSE(pi3): 5.609e-03\n",
      "Epoch 64100, Train loss: 1.077e+03, Test loss: 7.485e+04, MSE(e): 3.679e-05, MSE(pi1): 1.307e-02, MSE(pi2): 2.173e-05, MSE(pi3): 5.787e-03\n",
      "Epoch 64200, Train loss: 1.408e+03, Test loss: 7.524e+04, MSE(e): 7.421e-05, MSE(pi1): 1.063e-02, MSE(pi2): 3.850e-05, MSE(pi3): 5.593e-03\n",
      "Epoch 64300, Train loss: 1.371e+03, Test loss: 7.454e+04, MSE(e): 7.058e-05, MSE(pi1): 1.076e-02, MSE(pi2): 3.662e-05, MSE(pi3): 5.572e-03\n",
      "Epoch 64400, Train loss: 2.527e+03, Test loss: 7.585e+04, MSE(e): 1.783e-04, MSE(pi1): 1.574e-02, MSE(pi2): 8.152e-05, MSE(pi3): 5.866e-03\n",
      "Epoch 64500, Train loss: 1.024e+03, Test loss: 7.445e+04, MSE(e): 3.530e-05, MSE(pi1): 1.071e-02, MSE(pi2): 2.076e-05, MSE(pi3): 5.636e-03\n",
      "Epoch 64600, Train loss: 1.020e+03, Test loss: 7.436e+04, MSE(e): 3.564e-05, MSE(pi1): 1.024e-02, MSE(pi2): 2.101e-05, MSE(pi3): 5.609e-03\n",
      "Epoch 64700, Train loss: 1.025e+03, Test loss: 7.448e+04, MSE(e): 3.613e-05, MSE(pi1): 1.012e-02, MSE(pi2): 2.152e-05, MSE(pi3): 5.625e-03\n",
      "Epoch 64800, Train loss: 1.038e+03, Test loss: 7.461e+04, MSE(e): 3.555e-05, MSE(pi1): 1.099e-02, MSE(pi2): 2.095e-05, MSE(pi3): 5.728e-03\n",
      "Epoch 64900, Train loss: 1.017e+03, Test loss: 7.429e+04, MSE(e): 3.479e-05, MSE(pi1): 1.078e-02, MSE(pi2): 2.053e-05, MSE(pi3): 5.608e-03\n",
      "Epoch 65000, Train loss: 2.407e+03, Test loss: 7.602e+04, MSE(e): 1.734e-04, MSE(pi1): 1.086e-02, MSE(pi2): 7.893e-05, MSE(pi3): 5.644e-03\n",
      "Epoch 65100, Train loss: 1.225e+03, Test loss: 7.458e+04, MSE(e): 4.684e-05, MSE(pi1): 1.834e-02, MSE(pi2): 2.941e-05, MSE(pi3): 5.735e-03\n",
      "Epoch 65200, Train loss: 2.810e+03, Test loss: 7.574e+04, MSE(e): 1.876e-04, MSE(pi1): 3.770e-02, MSE(pi2): 9.134e-05, MSE(pi3): 5.574e-03\n",
      "Epoch 65300, Train loss: 1.079e+03, Test loss: 7.423e+04, MSE(e): 4.108e-05, MSE(pi1): 1.044e-02, MSE(pi2): 2.337e-05, MSE(pi3): 5.641e-03\n",
      "Epoch 65400, Train loss: 1.212e+03, Test loss: 7.432e+04, MSE(e): 5.470e-05, MSE(pi1): 1.110e-02, MSE(pi2): 2.961e-05, MSE(pi3): 5.535e-03\n",
      "Epoch 65500, Train loss: 1.370e+03, Test loss: 7.350e+04, MSE(e): 5.957e-05, MSE(pi1): 2.374e-02, MSE(pi2): 3.839e-05, MSE(pi3): 5.370e-03\n",
      "Epoch 65600, Train loss: 1.028e+03, Test loss: 7.409e+04, MSE(e): 3.619e-05, MSE(pi1): 1.061e-02, MSE(pi2): 2.148e-05, MSE(pi3): 5.600e-03\n",
      "Epoch 65700, Train loss: 1.008e+03, Test loss: 7.408e+04, MSE(e): 3.439e-05, MSE(pi1): 1.080e-02, MSE(pi2): 2.038e-05, MSE(pi3): 5.564e-03\n",
      "Epoch 65800, Train loss: 1.112e+03, Test loss: 7.385e+04, MSE(e): 3.763e-05, MSE(pi1): 1.965e-02, MSE(pi2): 2.290e-05, MSE(pi3): 5.392e-03\n",
      "Epoch 65900, Train loss: 1.058e+03, Test loss: 7.373e+04, MSE(e): 3.678e-05, MSE(pi1): 1.469e-02, MSE(pi2): 2.229e-05, MSE(pi3): 5.429e-03\n",
      "Epoch 66000, Train loss: 1.413e+03, Test loss: 7.551e+04, MSE(e): 6.169e-05, MSE(pi1): 1.981e-02, MSE(pi2): 3.842e-05, MSE(pi3): 5.979e-03\n",
      "Epoch 66100, Train loss: 1.119e+03, Test loss: 7.458e+04, MSE(e): 3.841e-05, MSE(pi1): 1.546e-02, MSE(pi2): 2.280e-05, MSE(pi3): 5.805e-03\n",
      "Epoch 66200, Train loss: 1.008e+03, Test loss: 7.400e+04, MSE(e): 3.433e-05, MSE(pi1): 1.081e-02, MSE(pi2): 2.035e-05, MSE(pi3): 5.564e-03\n",
      "Epoch 66300, Train loss: 1.018e+03, Test loss: 7.417e+04, MSE(e): 3.458e-05, MSE(pi1): 1.070e-02, MSE(pi2): 2.038e-05, MSE(pi3): 5.655e-03\n",
      "Epoch 66400, Train loss: 1.003e+03, Test loss: 7.410e+04, MSE(e): 3.393e-05, MSE(pi1): 1.019e-02, MSE(pi2): 2.006e-05, MSE(pi3): 5.614e-03\n",
      "Epoch 66500, Train loss: 1.529e+03, Test loss: 7.620e+04, MSE(e): 6.863e-05, MSE(pi1): 2.397e-02, MSE(pi2): 4.124e-05, MSE(pi3): 6.028e-03\n",
      "Epoch 66600, Train loss: 1.061e+03, Test loss: 7.391e+04, MSE(e): 3.818e-05, MSE(pi1): 1.221e-02, MSE(pi2): 2.173e-05, MSE(pi3): 5.566e-03\n",
      "Epoch 66700, Train loss: 1.468e+03, Test loss: 7.601e+04, MSE(e): 5.926e-05, MSE(pi1): 2.669e-02, MSE(pi2): 3.487e-05, MSE(pi3): 6.083e-03\n",
      "Epoch 66800, Train loss: 1.140e+03, Test loss: 7.415e+04, MSE(e): 4.476e-05, MSE(pi1): 1.369e-02, MSE(pi2): 2.591e-05, MSE(pi3): 5.551e-03\n",
      "Epoch 66900, Train loss: 1.074e+03, Test loss: 7.370e+04, MSE(e): 4.077e-05, MSE(pi1): 1.087e-02, MSE(pi2): 2.517e-05, MSE(pi3): 5.579e-03\n",
      "Epoch 67000, Train loss: 1.007e+03, Test loss: 7.402e+04, MSE(e): 3.451e-05, MSE(pi1): 1.018e-02, MSE(pi2): 2.030e-05, MSE(pi3): 5.604e-03\n",
      "Epoch 67100, Train loss: 1.010e+03, Test loss: 7.409e+04, MSE(e): 3.449e-05, MSE(pi1): 1.026e-02, MSE(pi2): 2.027e-05, MSE(pi3): 5.624e-03\n",
      "Epoch 67200, Train loss: 1.175e+03, Test loss: 7.379e+04, MSE(e): 3.952e-05, MSE(pi1): 2.384e-02, MSE(pi2): 2.327e-05, MSE(pi3): 5.416e-03\n",
      "Epoch 67300, Train loss: 1.072e+03, Test loss: 7.402e+04, MSE(e): 3.521e-05, MSE(pi1): 1.600e-02, MSE(pi2): 2.050e-05, MSE(pi3): 5.595e-03\n",
      "Epoch 67400, Train loss: 1.632e+03, Test loss: 7.596e+04, MSE(e): 6.879e-05, MSE(pi1): 3.405e-02, MSE(pi2): 4.571e-05, MSE(pi3): 6.037e-03\n",
      "Epoch 67500, Train loss: 1.141e+03, Test loss: 7.388e+04, MSE(e): 4.528e-05, MSE(pi1): 1.369e-02, MSE(pi2): 2.466e-05, MSE(pi3): 5.511e-03\n",
      "Epoch 67600, Train loss: 1.317e+03, Test loss: 7.315e+04, MSE(e): 4.382e-05, MSE(pi1): 3.544e-02, MSE(pi2): 2.802e-05, MSE(pi3): 5.249e-03\n",
      "Epoch 67700, Train loss: 1.021e+03, Test loss: 7.400e+04, MSE(e): 3.365e-05, MSE(pi1): 1.228e-02, MSE(pi2): 1.978e-05, MSE(pi3): 5.616e-03\n",
      "Epoch 67800, Train loss: 1.449e+03, Test loss: 7.462e+04, MSE(e): 6.873e-05, MSE(pi1): 1.814e-02, MSE(pi2): 3.991e-05, MSE(pi3): 5.807e-03\n",
      "Epoch 67900, Train loss: 1.037e+03, Test loss: 7.397e+04, MSE(e): 3.414e-05, MSE(pi1): 1.291e-02, MSE(pi2): 2.023e-05, MSE(pi3): 5.666e-03\n",
      "Epoch 68000, Train loss: 9.932e+02, Test loss: 7.391e+04, MSE(e): 3.310e-05, MSE(pi1): 1.014e-02, MSE(pi2): 1.956e-05, MSE(pi3): 5.607e-03\n",
      "Epoch 68100, Train loss: 1.370e+03, Test loss: 7.442e+04, MSE(e): 6.972e-05, MSE(pi1): 1.076e-02, MSE(pi2): 3.531e-05, MSE(pi3): 5.649e-03\n",
      "Epoch 68200, Train loss: 1.013e+03, Test loss: 7.412e+04, MSE(e): 3.424e-05, MSE(pi1): 1.037e-02, MSE(pi2): 2.022e-05, MSE(pi3): 5.668e-03\n",
      "Epoch 68300, Train loss: 2.210e+03, Test loss: 7.444e+04, MSE(e): 1.286e-04, MSE(pi1): 3.803e-02, MSE(pi2): 6.660e-05, MSE(pi3): 5.438e-03\n",
      "Epoch 68400, Train loss: 9.950e+02, Test loss: 7.410e+04, MSE(e): 3.290e-05, MSE(pi1): 9.945e-03, MSE(pi2): 1.938e-05, MSE(pi3): 5.665e-03\n",
      "Epoch 68500, Train loss: 1.032e+03, Test loss: 7.363e+04, MSE(e): 3.363e-05, MSE(pi1): 1.479e-02, MSE(pi2): 2.006e-05, MSE(pi3): 5.478e-03\n",
      "Epoch 68600, Train loss: 1.072e+03, Test loss: 7.429e+04, MSE(e): 3.490e-05, MSE(pi1): 1.398e-02, MSE(pi2): 2.067e-05, MSE(pi3): 5.835e-03\n",
      "Epoch 68700, Train loss: 1.196e+03, Test loss: 7.357e+04, MSE(e): 4.747e-05, MSE(pi1): 1.684e-02, MSE(pi2): 3.013e-05, MSE(pi3): 5.529e-03\n",
      "Epoch 68800, Train loss: 1.377e+03, Test loss: 7.337e+04, MSE(e): 4.584e-05, MSE(pi1): 3.904e-02, MSE(pi2): 2.670e-05, MSE(pi3): 5.281e-03\n",
      "Epoch 68900, Train loss: 1.752e+03, Test loss: 7.454e+04, MSE(e): 1.082e-04, MSE(pi1): 1.108e-02, MSE(pi2): 5.198e-05, MSE(pi3): 5.587e-03\n",
      "Epoch 69000, Train loss: 1.359e+03, Test loss: 7.410e+04, MSE(e): 6.656e-05, MSE(pi1): 1.405e-02, MSE(pi2): 3.357e-05, MSE(pi3): 5.528e-03\n",
      "Epoch 69100, Train loss: 1.016e+03, Test loss: 7.378e+04, MSE(e): 3.414e-05, MSE(pi1): 1.078e-02, MSE(pi2): 2.002e-05, MSE(pi3): 5.665e-03\n",
      "Epoch 69200, Train loss: 9.963e+02, Test loss: 7.367e+04, MSE(e): 3.277e-05, MSE(pi1): 1.118e-02, MSE(pi2): 1.930e-05, MSE(pi3): 5.568e-03\n",
      "Epoch 69300, Train loss: 1.435e+03, Test loss: 7.415e+04, MSE(e): 7.663e-05, MSE(pi1): 9.934e-03, MSE(pi2): 3.757e-05, MSE(pi3): 5.695e-03\n",
      "Epoch 69400, Train loss: 1.270e+03, Test loss: 7.415e+04, MSE(e): 6.043e-05, MSE(pi1): 1.070e-02, MSE(pi2): 3.159e-05, MSE(pi3): 5.586e-03\n",
      "Epoch 69500, Train loss: 1.023e+03, Test loss: 7.373e+04, MSE(e): 3.434e-05, MSE(pi1): 1.089e-02, MSE(pi2): 2.029e-05, MSE(pi3): 5.707e-03\n",
      "Epoch 69600, Train loss: 1.144e+03, Test loss: 7.470e+04, MSE(e): 3.991e-05, MSE(pi1): 1.542e-02, MSE(pi2): 2.445e-05, MSE(pi3): 5.903e-03\n",
      "Epoch 69700, Train loss: 9.924e+02, Test loss: 7.363e+04, MSE(e): 3.266e-05, MSE(pi1): 1.066e-02, MSE(pi2): 1.925e-05, MSE(pi3): 5.592e-03\n",
      "Epoch 69800, Train loss: 2.704e+03, Test loss: 7.487e+04, MSE(e): 2.043e-04, MSE(pi1): 1.095e-02, MSE(pi2): 9.405e-05, MSE(pi3): 5.511e-03\n",
      "Epoch 69900, Train loss: 1.036e+03, Test loss: 7.329e+04, MSE(e): 3.512e-05, MSE(pi1): 1.371e-02, MSE(pi2): 2.130e-05, MSE(pi3): 5.477e-03\n",
      "Epoch 70000, Train loss: 1.000e+03, Test loss: 7.356e+04, MSE(e): 3.370e-05, MSE(pi1): 1.008e-02, MSE(pi2): 1.970e-05, MSE(pi3): 5.623e-03\n",
      "Epoch 70100, Train loss: 9.965e+02, Test loss: 7.358e+04, MSE(e): 3.356e-05, MSE(pi1): 1.018e-02, MSE(pi2): 1.967e-05, MSE(pi3): 5.590e-03\n",
      "Epoch 70200, Train loss: 1.006e+03, Test loss: 7.377e+04, MSE(e): 3.362e-05, MSE(pi1): 1.033e-02, MSE(pi2): 1.966e-05, MSE(pi3): 5.667e-03\n",
      "Epoch 70300, Train loss: 9.863e+02, Test loss: 7.356e+04, MSE(e): 3.214e-05, MSE(pi1): 1.077e-02, MSE(pi2): 1.901e-05, MSE(pi3): 5.571e-03\n",
      "Epoch 70400, Train loss: 1.124e+03, Test loss: 7.392e+04, MSE(e): 4.519e-05, MSE(pi1): 1.034e-02, MSE(pi2): 2.554e-05, MSE(pi3): 5.687e-03\n",
      "Epoch 70500, Train loss: 1.041e+03, Test loss: 7.373e+04, MSE(e): 3.570e-05, MSE(pi1): 1.310e-02, MSE(pi2): 2.177e-05, MSE(pi3): 5.535e-03\n",
      "Epoch 70600, Train loss: 1.413e+03, Test loss: 7.501e+04, MSE(e): 3.831e-05, MSE(pi1): 4.323e-02, MSE(pi2): 2.260e-05, MSE(pi3): 5.975e-03\n",
      "Epoch 70700, Train loss: 1.257e+03, Test loss: 7.294e+04, MSE(e): 4.433e-05, MSE(pi1): 2.787e-02, MSE(pi2): 2.569e-05, MSE(pi3): 5.351e-03\n",
      "Epoch 70800, Train loss: 1.024e+03, Test loss: 7.338e+04, MSE(e): 3.547e-05, MSE(pi1): 1.142e-02, MSE(pi2): 2.020e-05, MSE(pi3): 5.554e-03\n",
      "Epoch 70900, Train loss: 9.888e+02, Test loss: 7.343e+04, MSE(e): 3.272e-05, MSE(pi1): 1.016e-02, MSE(pi2): 1.942e-05, MSE(pi3): 5.600e-03\n",
      "Epoch 71000, Train loss: 1.351e+03, Test loss: 7.299e+04, MSE(e): 4.421e-05, MSE(pi1): 3.757e-02, MSE(pi2): 2.835e-05, MSE(pi3): 5.336e-03\n",
      "Epoch 71100, Train loss: 9.830e+02, Test loss: 7.354e+04, MSE(e): 3.216e-05, MSE(pi1): 1.013e-02, MSE(pi2): 1.885e-05, MSE(pi3): 5.601e-03\n",
      "Epoch 71200, Train loss: 1.043e+03, Test loss: 7.336e+04, MSE(e): 3.618e-05, MSE(pi1): 1.179e-02, MSE(pi2): 2.204e-05, MSE(pi3): 5.627e-03\n",
      "Epoch 71300, Train loss: 9.811e+02, Test loss: 7.343e+04, MSE(e): 3.144e-05, MSE(pi1): 1.109e-02, MSE(pi2): 1.863e-05, MSE(pi3): 5.558e-03\n",
      "Epoch 71400, Train loss: 9.959e+02, Test loss: 7.372e+04, MSE(e): 3.304e-05, MSE(pi1): 1.014e-02, MSE(pi2): 1.950e-05, MSE(pi3): 5.641e-03\n",
      "Epoch 71500, Train loss: 2.139e+03, Test loss: 7.521e+04, MSE(e): 1.457e-04, MSE(pi1): 1.133e-02, MSE(pi2): 6.834e-05, MSE(pi3): 5.677e-03\n",
      "Epoch 71600, Train loss: 9.874e+02, Test loss: 7.329e+04, MSE(e): 3.257e-05, MSE(pi1): 1.042e-02, MSE(pi2): 1.942e-05, MSE(pi3): 5.575e-03\n",
      "Epoch 71700, Train loss: 1.245e+03, Test loss: 7.477e+04, MSE(e): 5.261e-05, MSE(pi1): 1.346e-02, MSE(pi2): 3.414e-05, MSE(pi3): 5.840e-03\n",
      "Epoch 71800, Train loss: 1.225e+03, Test loss: 7.444e+04, MSE(e): 4.358e-05, MSE(pi1): 2.161e-02, MSE(pi2): 2.769e-05, MSE(pi3): 5.728e-03\n",
      "Epoch 71900, Train loss: 1.390e+03, Test loss: 7.512e+04, MSE(e): 4.982e-05, MSE(pi1): 2.766e-02, MSE(pi2): 2.866e-05, MSE(pi3): 6.157e-03\n",
      "Epoch 72000, Train loss: 1.059e+03, Test loss: 7.324e+04, MSE(e): 3.592e-05, MSE(pi1): 1.508e-02, MSE(pi2): 2.044e-05, MSE(pi3): 5.492e-03\n",
      "Epoch 72100, Train loss: 1.062e+03, Test loss: 7.369e+04, MSE(e): 3.934e-05, MSE(pi1): 1.056e-02, MSE(pi2): 2.220e-05, MSE(pi3): 5.634e-03\n",
      "Epoch 72200, Train loss: 1.439e+03, Test loss: 7.325e+04, MSE(e): 6.994e-05, MSE(pi1): 1.942e-02, MSE(pi2): 3.985e-05, MSE(pi3): 5.450e-03\n",
      "Epoch 72300, Train loss: 9.776e+02, Test loss: 7.337e+04, MSE(e): 3.141e-05, MSE(pi1): 1.079e-02, MSE(pi2): 1.857e-05, MSE(pi3): 5.555e-03\n",
      "Epoch 72400, Train loss: 1.133e+03, Test loss: 7.443e+04, MSE(e): 4.344e-05, MSE(pi1): 1.239e-02, MSE(pi2): 2.594e-05, MSE(pi3): 5.750e-03\n",
      "Epoch 72500, Train loss: 9.806e+02, Test loss: 7.340e+04, MSE(e): 3.202e-05, MSE(pi1): 9.928e-03, MSE(pi2): 1.877e-05, MSE(pi3): 5.611e-03\n",
      "Epoch 72600, Train loss: 1.004e+03, Test loss: 7.326e+04, MSE(e): 3.374e-05, MSE(pi1): 1.030e-02, MSE(pi2): 1.959e-05, MSE(pi3): 5.638e-03\n",
      "Epoch 72700, Train loss: 1.443e+03, Test loss: 7.465e+04, MSE(e): 7.388e-05, MSE(pi1): 1.282e-02, MSE(pi2): 3.771e-05, MSE(pi3): 5.757e-03\n",
      "Epoch 72800, Train loss: 9.948e+02, Test loss: 7.344e+04, MSE(e): 3.244e-05, MSE(pi1): 9.829e-03, MSE(pi2): 1.890e-05, MSE(pi3): 5.721e-03\n",
      "Epoch 72900, Train loss: 1.095e+03, Test loss: 7.369e+04, MSE(e): 3.297e-05, MSE(pi1): 1.893e-02, MSE(pi2): 1.932e-05, MSE(pi3): 5.763e-03\n",
      "Epoch 73000, Train loss: 1.164e+03, Test loss: 7.375e+04, MSE(e): 4.686e-05, MSE(pi1): 1.239e-02, MSE(pi2): 2.667e-05, MSE(pi3): 5.719e-03\n",
      "Epoch 73100, Train loss: 9.678e+02, Test loss: 7.334e+04, MSE(e): 3.057e-05, MSE(pi1): 1.028e-02, MSE(pi2): 1.808e-05, MSE(pi3): 5.592e-03\n",
      "Epoch 73200, Train loss: 1.202e+03, Test loss: 7.338e+04, MSE(e): 5.150e-05, MSE(pi1): 1.294e-02, MSE(pi2): 2.732e-05, MSE(pi3): 5.580e-03\n",
      "Epoch 73300, Train loss: 9.715e+02, Test loss: 7.304e+04, MSE(e): 3.079e-05, MSE(pi1): 1.081e-02, MSE(pi2): 1.830e-05, MSE(pi3): 5.555e-03\n",
      "Epoch 73400, Train loss: 9.644e+02, Test loss: 7.325e+04, MSE(e): 3.030e-05, MSE(pi1): 1.030e-02, MSE(pi2): 1.790e-05, MSE(pi3): 5.583e-03\n",
      "Epoch 73500, Train loss: 1.018e+03, Test loss: 7.381e+04, MSE(e): 3.156e-05, MSE(pi1): 1.240e-02, MSE(pi2): 1.860e-05, MSE(pi3): 5.788e-03\n",
      "Epoch 73600, Train loss: 9.651e+02, Test loss: 7.329e+04, MSE(e): 3.028e-05, MSE(pi1): 1.023e-02, MSE(pi2): 1.789e-05, MSE(pi3): 5.600e-03\n",
      "Epoch 73700, Train loss: 1.044e+03, Test loss: 7.344e+04, MSE(e): 3.625e-05, MSE(pi1): 1.185e-02, MSE(pi2): 2.049e-05, MSE(pi3): 5.630e-03\n",
      "Epoch 73800, Train loss: 9.752e+02, Test loss: 7.330e+04, MSE(e): 3.101e-05, MSE(pi1): 1.035e-02, MSE(pi2): 1.806e-05, MSE(pi3): 5.616e-03\n",
      "Epoch 73900, Train loss: 9.643e+02, Test loss: 7.312e+04, MSE(e): 3.017e-05, MSE(pi1): 1.065e-02, MSE(pi2): 1.783e-05, MSE(pi3): 5.561e-03\n",
      "Epoch 74000, Train loss: 9.608e+02, Test loss: 7.319e+04, MSE(e): 3.004e-05, MSE(pi1): 1.012e-02, MSE(pi2): 1.775e-05, MSE(pi3): 5.592e-03\n",
      "Epoch 74100, Train loss: 9.596e+02, Test loss: 7.320e+04, MSE(e): 2.996e-05, MSE(pi1): 9.915e-03, MSE(pi2): 1.766e-05, MSE(pi3): 5.609e-03\n",
      "Epoch 74200, Train loss: 9.635e+02, Test loss: 7.311e+04, MSE(e): 3.004e-05, MSE(pi1): 1.000e-02, MSE(pi2): 1.771e-05, MSE(pi3): 5.630e-03\n",
      "Epoch 74300, Train loss: 9.615e+02, Test loss: 7.322e+04, MSE(e): 2.994e-05, MSE(pi1): 1.012e-02, MSE(pi2): 1.767e-05, MSE(pi3): 5.609e-03\n",
      "Epoch 74400, Train loss: 1.082e+03, Test loss: 7.334e+04, MSE(e): 4.052e-05, MSE(pi1): 1.238e-02, MSE(pi2): 2.265e-05, MSE(pi3): 5.529e-03\n",
      "Epoch 74500, Train loss: 9.774e+02, Test loss: 7.332e+04, MSE(e): 3.065e-05, MSE(pi1): 1.073e-02, MSE(pi2): 1.807e-05, MSE(pi3): 5.637e-03\n",
      "Epoch 74600, Train loss: 1.047e+03, Test loss: 7.275e+04, MSE(e): 3.222e-05, MSE(pi1): 1.842e-02, MSE(pi2): 1.952e-05, MSE(pi3): 5.408e-03\n",
      "Epoch 74700, Train loss: 1.010e+03, Test loss: 7.306e+04, MSE(e): 3.266e-05, MSE(pi1): 1.218e-02, MSE(pi2): 1.890e-05, MSE(pi3): 5.617e-03\n",
      "Epoch 74800, Train loss: 1.149e+03, Test loss: 7.352e+04, MSE(e): 3.760e-05, MSE(pi1): 1.864e-02, MSE(pi2): 2.312e-05, MSE(pi3): 5.867e-03\n",
      "Epoch 74900, Train loss: 9.657e+02, Test loss: 7.311e+04, MSE(e): 3.025e-05, MSE(pi1): 1.028e-02, MSE(pi2): 1.784e-05, MSE(pi3): 5.604e-03\n",
      "Epoch 75000, Train loss: 9.690e+02, Test loss: 7.326e+04, MSE(e): 3.086e-05, MSE(pi1): 9.731e-03, MSE(pi2): 1.809e-05, MSE(pi3): 5.631e-03\n",
      "Epoch 75100, Train loss: 1.157e+03, Test loss: 7.266e+04, MSE(e): 3.910e-05, MSE(pi1): 2.344e-02, MSE(pi2): 2.308e-05, MSE(pi3): 5.318e-03\n",
      "Epoch 75200, Train loss: 1.157e+03, Test loss: 7.350e+04, MSE(e): 3.319e-05, MSE(pi1): 2.666e-02, MSE(pi2): 1.958e-05, MSE(pi3): 5.582e-03\n",
      "Epoch 75300, Train loss: 9.602e+02, Test loss: 7.306e+04, MSE(e): 2.996e-05, MSE(pi1): 1.006e-02, MSE(pi2): 1.752e-05, MSE(pi3): 5.600e-03\n",
      "Epoch 75400, Train loss: 9.680e+02, Test loss: 7.302e+04, MSE(e): 2.999e-05, MSE(pi1): 1.103e-02, MSE(pi2): 1.757e-05, MSE(pi3): 5.578e-03\n",
      "Epoch 75500, Train loss: 9.632e+02, Test loss: 7.310e+04, MSE(e): 3.026e-05, MSE(pi1): 1.033e-02, MSE(pi2): 1.785e-05, MSE(pi3): 5.574e-03\n",
      "Epoch 75600, Train loss: 1.135e+03, Test loss: 7.393e+04, MSE(e): 3.772e-05, MSE(pi1): 1.682e-02, MSE(pi2): 2.159e-05, MSE(pi3): 5.896e-03\n",
      "Epoch 75700, Train loss: 1.462e+03, Test loss: 7.424e+04, MSE(e): 7.054e-05, MSE(pi1): 1.912e-02, MSE(pi2): 3.814e-05, MSE(pi3): 5.659e-03\n",
      "Epoch 75800, Train loss: 9.802e+02, Test loss: 7.327e+04, MSE(e): 3.100e-05, MSE(pi1): 1.055e-02, MSE(pi2): 1.810e-05, MSE(pi3): 5.647e-03\n",
      "Epoch 75900, Train loss: 1.026e+03, Test loss: 7.280e+04, MSE(e): 3.126e-05, MSE(pi1): 1.742e-02, MSE(pi2): 1.885e-05, MSE(pi3): 5.396e-03\n",
      "Epoch 76000, Train loss: 9.533e+02, Test loss: 7.304e+04, MSE(e): 2.928e-05, MSE(pi1): 1.005e-02, MSE(pi2): 1.729e-05, MSE(pi3): 5.599e-03\n",
      "Epoch 76100, Train loss: 1.096e+03, Test loss: 7.330e+04, MSE(e): 4.305e-05, MSE(pi1): 1.018e-02, MSE(pi2): 2.349e-05, MSE(pi3): 5.636e-03\n",
      "Epoch 76200, Train loss: 1.089e+03, Test loss: 7.328e+04, MSE(e): 4.075e-05, MSE(pi1): 1.226e-02, MSE(pi2): 2.277e-05, MSE(pi3): 5.587e-03\n",
      "Epoch 76300, Train loss: 1.183e+03, Test loss: 7.256e+04, MSE(e): 4.994e-05, MSE(pi1): 1.304e-02, MSE(pi2): 3.180e-05, MSE(pi3): 5.527e-03\n",
      "Epoch 76400, Train loss: 1.165e+03, Test loss: 7.305e+04, MSE(e): 4.341e-05, MSE(pi1): 1.672e-02, MSE(pi2): 2.279e-05, MSE(pi3): 5.638e-03\n",
      "Epoch 76500, Train loss: 1.178e+03, Test loss: 7.270e+04, MSE(e): 4.522e-05, MSE(pi1): 1.881e-02, MSE(pi2): 2.619e-05, MSE(pi3): 5.373e-03\n",
      "Epoch 76600, Train loss: 1.861e+03, Test loss: 7.445e+04, MSE(e): 1.195e-04, MSE(pi1): 1.126e-02, MSE(pi2): 5.699e-05, MSE(pi3): 5.528e-03\n",
      "Epoch 76700, Train loss: 9.540e+02, Test loss: 7.304e+04, MSE(e): 2.923e-05, MSE(pi1): 9.822e-03, MSE(pi2): 1.722e-05, MSE(pi3): 5.635e-03\n",
      "Epoch 76800, Train loss: 1.188e+03, Test loss: 7.255e+04, MSE(e): 4.767e-05, MSE(pi1): 1.661e-02, MSE(pi2): 2.629e-05, MSE(pi3): 5.455e-03\n",
      "Epoch 76900, Train loss: 1.022e+03, Test loss: 7.267e+04, MSE(e): 3.468e-05, MSE(pi1): 1.276e-02, MSE(pi2): 2.030e-05, MSE(pi3): 5.477e-03\n",
      "Epoch 77000, Train loss: 1.038e+03, Test loss: 7.248e+04, MSE(e): 3.522e-05, MSE(pi1): 1.424e-02, MSE(pi2): 2.158e-05, MSE(pi3): 5.431e-03\n",
      "Epoch 77100, Train loss: 1.098e+03, Test loss: 7.348e+04, MSE(e): 4.319e-05, MSE(pi1): 9.874e-03, MSE(pi2): 2.577e-05, MSE(pi3): 5.671e-03\n",
      "Epoch 77200, Train loss: 1.060e+03, Test loss: 7.286e+04, MSE(e): 3.951e-05, MSE(pi1): 1.056e-02, MSE(pi2): 2.170e-05, MSE(pi3): 5.590e-03\n",
      "Epoch 77300, Train loss: 1.498e+03, Test loss: 7.236e+04, MSE(e): 5.567e-05, MSE(pi1): 4.175e-02, MSE(pi2): 3.208e-05, MSE(pi3): 5.233e-03\n",
      "Epoch 77400, Train loss: 9.961e+02, Test loss: 7.315e+04, MSE(e): 3.001e-05, MSE(pi1): 1.340e-02, MSE(pi2): 1.787e-05, MSE(pi3): 5.619e-03\n",
      "Epoch 77500, Train loss: 9.511e+02, Test loss: 7.297e+04, MSE(e): 2.895e-05, MSE(pi1): 9.884e-03, MSE(pi2): 1.707e-05, MSE(pi3): 5.627e-03\n",
      "Epoch 77600, Train loss: 1.261e+03, Test loss: 7.299e+04, MSE(e): 5.080e-05, MSE(pi1): 1.905e-02, MSE(pi2): 2.647e-05, MSE(pi3): 5.623e-03\n",
      "Epoch 77700, Train loss: 9.473e+02, Test loss: 7.292e+04, MSE(e): 2.867e-05, MSE(pi1): 9.957e-03, MSE(pi2): 1.695e-05, MSE(pi3): 5.610e-03\n",
      "Epoch 77800, Train loss: 9.498e+02, Test loss: 7.283e+04, MSE(e): 2.885e-05, MSE(pi1): 1.055e-02, MSE(pi2): 1.709e-05, MSE(pi3): 5.558e-03\n",
      "Epoch 77900, Train loss: 9.575e+02, Test loss: 7.291e+04, MSE(e): 2.976e-05, MSE(pi1): 9.919e-03, MSE(pi2): 1.744e-05, MSE(pi3): 5.607e-03\n",
      "Epoch 78000, Train loss: 1.346e+03, Test loss: 7.330e+04, MSE(e): 5.867e-05, MSE(pi1): 2.016e-02, MSE(pi2): 3.212e-05, MSE(pi3): 5.580e-03\n",
      "Epoch 78100, Train loss: 1.277e+03, Test loss: 7.303e+04, MSE(e): 5.448e-05, MSE(pi1): 1.705e-02, MSE(pi2): 3.278e-05, MSE(pi3): 5.614e-03\n",
      "Epoch 78200, Train loss: 1.351e+03, Test loss: 7.238e+04, MSE(e): 3.676e-05, MSE(pi1): 4.605e-02, MSE(pi2): 2.315e-05, MSE(pi3): 5.228e-03\n",
      "Epoch 78300, Train loss: 1.048e+03, Test loss: 7.305e+04, MSE(e): 3.905e-05, MSE(pi1): 9.877e-03, MSE(pi2): 2.159e-05, MSE(pi3): 5.590e-03\n",
      "Epoch 78400, Train loss: 1.017e+03, Test loss: 7.300e+04, MSE(e): 3.385e-05, MSE(pi1): 1.168e-02, MSE(pi2): 1.905e-05, MSE(pi3): 5.614e-03\n",
      "Epoch 78500, Train loss: 1.063e+03, Test loss: 7.280e+04, MSE(e): 3.370e-05, MSE(pi1): 1.650e-02, MSE(pi2): 2.001e-05, MSE(pi3): 5.606e-03\n",
      "Epoch 78600, Train loss: 9.548e+02, Test loss: 7.301e+04, MSE(e): 2.953e-05, MSE(pi1): 9.736e-03, MSE(pi2): 1.758e-05, MSE(pi3): 5.621e-03\n",
      "Epoch 78700, Train loss: 9.416e+02, Test loss: 7.271e+04, MSE(e): 2.816e-05, MSE(pi1): 1.029e-02, MSE(pi2): 1.664e-05, MSE(pi3): 5.571e-03\n",
      "Epoch 78800, Train loss: 9.653e+02, Test loss: 7.284e+04, MSE(e): 2.886e-05, MSE(pi1): 1.167e-02, MSE(pi2): 1.691e-05, MSE(pi3): 5.600e-03\n",
      "Epoch 78900, Train loss: 1.010e+03, Test loss: 7.236e+04, MSE(e): 3.032e-05, MSE(pi1): 1.625e-02, MSE(pi2): 1.827e-05, MSE(pi3): 5.444e-03\n",
      "Epoch 79000, Train loss: 9.399e+02, Test loss: 7.272e+04, MSE(e): 2.809e-05, MSE(pi1): 1.007e-02, MSE(pi2): 1.661e-05, MSE(pi3): 5.583e-03\n",
      "Epoch 79100, Train loss: 9.999e+02, Test loss: 7.274e+04, MSE(e): 3.402e-05, MSE(pi1): 9.859e-03, MSE(pi2): 1.882e-05, MSE(pi3): 5.610e-03\n",
      "Epoch 79200, Train loss: 1.035e+03, Test loss: 7.334e+04, MSE(e): 3.721e-05, MSE(pi1): 1.007e-02, MSE(pi2): 2.302e-05, MSE(pi3): 5.620e-03\n",
      "Epoch 79300, Train loss: 1.054e+03, Test loss: 7.355e+04, MSE(e): 3.083e-05, MSE(pi1): 1.592e-02, MSE(pi2): 1.827e-05, MSE(pi3): 5.863e-03\n",
      "Epoch 79400, Train loss: 9.383e+02, Test loss: 7.266e+04, MSE(e): 2.792e-05, MSE(pi1): 1.017e-02, MSE(pi2): 1.651e-05, MSE(pi3): 5.574e-03\n",
      "Epoch 79500, Train loss: 1.171e+03, Test loss: 7.252e+04, MSE(e): 5.030e-05, MSE(pi1): 1.133e-02, MSE(pi2): 2.598e-05, MSE(pi3): 5.547e-03\n",
      "Epoch 79600, Train loss: 1.087e+03, Test loss: 7.344e+04, MSE(e): 3.550e-05, MSE(pi1): 1.335e-02, MSE(pi2): 2.130e-05, MSE(pi3): 5.981e-03\n",
      "Epoch 79700, Train loss: 1.053e+03, Test loss: 7.299e+04, MSE(e): 3.869e-05, MSE(pi1): 1.116e-02, MSE(pi2): 2.166e-05, MSE(pi3): 5.543e-03\n",
      "Epoch 79800, Train loss: 1.061e+03, Test loss: 7.258e+04, MSE(e): 3.258e-05, MSE(pi1): 1.849e-02, MSE(pi2): 1.916e-05, MSE(pi3): 5.505e-03\n",
      "Epoch 79900, Train loss: 9.551e+02, Test loss: 7.275e+04, MSE(e): 2.974e-05, MSE(pi1): 9.868e-03, MSE(pi2): 1.737e-05, MSE(pi3): 5.590e-03\n",
      "Epoch 80000, Train loss: 9.441e+02, Test loss: 7.275e+04, MSE(e): 2.800e-05, MSE(pi1): 1.011e-02, MSE(pi2): 1.639e-05, MSE(pi3): 5.630e-03\n",
      "Epoch 80100, Train loss: 1.078e+03, Test loss: 7.353e+04, MSE(e): 3.068e-05, MSE(pi1): 1.813e-02, MSE(pi2): 1.815e-05, MSE(pi3): 5.899e-03\n",
      "Epoch 80200, Train loss: 9.350e+02, Test loss: 7.261e+04, MSE(e): 2.760e-05, MSE(pi1): 1.015e-02, MSE(pi2): 1.632e-05, MSE(pi3): 5.575e-03\n",
      "Epoch 80300, Train loss: 9.777e+02, Test loss: 7.283e+04, MSE(e): 3.162e-05, MSE(pi1): 9.623e-03, MSE(pi2): 1.800e-05, MSE(pi3): 5.653e-03\n",
      "Epoch 80400, Train loss: 9.429e+02, Test loss: 7.287e+04, MSE(e): 2.766e-05, MSE(pi1): 1.014e-02, MSE(pi2): 1.627e-05, MSE(pi3): 5.649e-03\n",
      "Epoch 80500, Train loss: 9.727e+02, Test loss: 7.241e+04, MSE(e): 3.080e-05, MSE(pi1): 1.095e-02, MSE(pi2): 1.767e-05, MSE(pi3): 5.552e-03\n",
      "Epoch 80600, Train loss: 9.553e+02, Test loss: 7.235e+04, MSE(e): 2.927e-05, MSE(pi1): 1.091e-02, MSE(pi2): 1.733e-05, MSE(pi3): 5.535e-03\n",
      "Epoch 80700, Train loss: 1.068e+03, Test loss: 7.343e+04, MSE(e): 3.800e-05, MSE(pi1): 1.135e-02, MSE(pi2): 2.146e-05, MSE(pi3): 5.745e-03\n",
      "Epoch 80800, Train loss: 1.040e+03, Test loss: 7.298e+04, MSE(e): 3.629e-05, MSE(pi1): 1.035e-02, MSE(pi2): 1.963e-05, MSE(pi3): 5.732e-03\n",
      "Epoch 80900, Train loss: 1.041e+03, Test loss: 7.351e+04, MSE(e): 3.060e-05, MSE(pi1): 1.483e-02, MSE(pi2): 1.823e-05, MSE(pi3): 5.867e-03\n",
      "Epoch 81000, Train loss: 1.008e+03, Test loss: 7.252e+04, MSE(e): 3.347e-05, MSE(pi1): 1.144e-02, MSE(pi2): 1.857e-05, MSE(pi3): 5.591e-03\n",
      "Epoch 81100, Train loss: 9.425e+02, Test loss: 7.240e+04, MSE(e): 2.786e-05, MSE(pi1): 1.123e-02, MSE(pi2): 1.659e-05, MSE(pi3): 5.515e-03\n",
      "Epoch 81200, Train loss: 1.302e+03, Test loss: 7.290e+04, MSE(e): 3.403e-05, MSE(pi1): 3.892e-02, MSE(pi2): 2.044e-05, MSE(pi3): 5.730e-03\n",
      "Epoch 81300, Train loss: 9.589e+02, Test loss: 7.275e+04, MSE(e): 2.843e-05, MSE(pi1): 1.149e-02, MSE(pi2): 1.699e-05, MSE(pi3): 5.597e-03\n",
      "Epoch 81400, Train loss: 9.455e+02, Test loss: 7.275e+04, MSE(e): 2.736e-05, MSE(pi1): 1.028e-02, MSE(pi2): 1.609e-05, MSE(pi3): 5.690e-03\n",
      "Epoch 81500, Train loss: 9.751e+02, Test loss: 7.279e+04, MSE(e): 3.013e-05, MSE(pi1): 1.104e-02, MSE(pi2): 1.757e-05, MSE(pi3): 5.634e-03\n",
      "Epoch 81600, Train loss: 9.471e+02, Test loss: 7.288e+04, MSE(e): 2.794e-05, MSE(pi1): 9.884e-03, MSE(pi2): 1.647e-05, MSE(pi3): 5.689e-03\n",
      "Epoch 81700, Train loss: 9.285e+02, Test loss: 7.257e+04, MSE(e): 2.708e-05, MSE(pi1): 9.741e-03, MSE(pi2): 1.598e-05, MSE(pi3): 5.603e-03\n",
      "Epoch 81800, Train loss: 9.508e+02, Test loss: 7.252e+04, MSE(e): 2.933e-05, MSE(pi1): 1.009e-02, MSE(pi2): 1.719e-05, MSE(pi3): 5.565e-03\n",
      "Epoch 81900, Train loss: 9.515e+02, Test loss: 7.243e+04, MSE(e): 2.922e-05, MSE(pi1): 1.009e-02, MSE(pi2): 1.697e-05, MSE(pi3): 5.585e-03\n",
      "Epoch 82000, Train loss: 1.302e+03, Test loss: 7.252e+04, MSE(e): 5.285e-05, MSE(pi1): 1.887e-02, MSE(pi2): 3.473e-05, MSE(pi3): 5.850e-03\n",
      "Epoch 82100, Train loss: 1.268e+03, Test loss: 7.203e+04, MSE(e): 3.590e-05, MSE(pi1): 3.801e-02, MSE(pi2): 2.263e-05, MSE(pi3): 5.285e-03\n",
      "Epoch 82200, Train loss: 9.692e+02, Test loss: 7.255e+04, MSE(e): 2.802e-05, MSE(pi1): 1.363e-02, MSE(pi2): 1.648e-05, MSE(pi3): 5.527e-03\n",
      "Epoch 82300, Train loss: 9.833e+02, Test loss: 7.201e+04, MSE(e): 2.909e-05, MSE(pi1): 1.504e-02, MSE(pi2): 1.763e-05, MSE(pi3): 5.419e-03\n",
      "Epoch 82400, Train loss: 2.486e+03, Test loss: 7.438e+04, MSE(e): 1.701e-04, MSE(pi1): 1.785e-02, MSE(pi2): 7.749e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 82500, Train loss: 9.988e+02, Test loss: 7.199e+04, MSE(e): 2.997e-05, MSE(pi1): 1.557e-02, MSE(pi2): 1.826e-05, MSE(pi3): 5.434e-03\n",
      "Epoch 82600, Train loss: 1.056e+03, Test loss: 7.279e+04, MSE(e): 3.762e-05, MSE(pi1): 1.060e-02, MSE(pi2): 2.029e-05, MSE(pi3): 5.737e-03\n",
      "Epoch 82700, Train loss: 9.543e+02, Test loss: 7.264e+04, MSE(e): 2.847e-05, MSE(pi1): 1.111e-02, MSE(pi2): 1.712e-05, MSE(pi3): 5.585e-03\n",
      "Epoch 82800, Train loss: 1.091e+03, Test loss: 7.280e+04, MSE(e): 3.591e-05, MSE(pi1): 1.712e-02, MSE(pi2): 2.093e-05, MSE(pi3): 5.611e-03\n",
      "Epoch 82900, Train loss: 9.768e+02, Test loss: 7.203e+04, MSE(e): 2.976e-05, MSE(pi1): 1.313e-02, MSE(pi2): 1.777e-05, MSE(pi3): 5.479e-03\n",
      "Epoch 83000, Train loss: 9.262e+02, Test loss: 7.241e+04, MSE(e): 2.672e-05, MSE(pi1): 9.794e-03, MSE(pi2): 1.578e-05, MSE(pi3): 5.611e-03\n",
      "Epoch 83100, Train loss: 1.021e+03, Test loss: 7.270e+04, MSE(e): 2.878e-05, MSE(pi1): 1.699e-02, MSE(pi2): 1.716e-05, MSE(pi3): 5.637e-03\n",
      "Epoch 83200, Train loss: 9.263e+02, Test loss: 7.248e+04, MSE(e): 2.669e-05, MSE(pi1): 9.760e-03, MSE(pi2): 1.576e-05, MSE(pi3): 5.618e-03\n",
      "Epoch 83300, Train loss: 9.911e+02, Test loss: 7.214e+04, MSE(e): 3.208e-05, MSE(pi1): 1.178e-02, MSE(pi2): 1.821e-05, MSE(pi3): 5.525e-03\n",
      "Epoch 83400, Train loss: 1.078e+03, Test loss: 7.260e+04, MSE(e): 3.677e-05, MSE(pi1): 1.271e-02, MSE(pi2): 2.105e-05, MSE(pi3): 5.829e-03\n",
      "Epoch 83500, Train loss: 1.016e+03, Test loss: 7.270e+04, MSE(e): 2.851e-05, MSE(pi1): 1.667e-02, MSE(pi2): 1.628e-05, MSE(pi3): 5.646e-03\n",
      "Epoch 83600, Train loss: 1.057e+03, Test loss: 7.321e+04, MSE(e): 3.796e-05, MSE(pi1): 1.206e-02, MSE(pi2): 2.328e-05, MSE(pi3): 5.568e-03\n",
      "Epoch 83700, Train loss: 9.798e+02, Test loss: 7.246e+04, MSE(e): 3.143e-05, MSE(pi1): 1.010e-02, MSE(pi2): 1.801e-05, MSE(pi3): 5.645e-03\n",
      "Epoch 83800, Train loss: 9.856e+02, Test loss: 7.300e+04, MSE(e): 2.880e-05, MSE(pi1): 1.161e-02, MSE(pi2): 1.708e-05, MSE(pi3): 5.815e-03\n",
      "Epoch 83900, Train loss: 1.009e+03, Test loss: 7.276e+04, MSE(e): 2.895e-05, MSE(pi1): 1.567e-02, MSE(pi2): 1.715e-05, MSE(pi3): 5.628e-03\n",
      "Epoch 84000, Train loss: 1.087e+03, Test loss: 7.325e+04, MSE(e): 3.403e-05, MSE(pi1): 1.558e-02, MSE(pi2): 2.068e-05, MSE(pi3): 5.909e-03\n",
      "Epoch 84100, Train loss: 9.441e+02, Test loss: 7.224e+04, MSE(e): 2.851e-05, MSE(pi1): 1.003e-02, MSE(pi2): 1.638e-05, MSE(pi3): 5.588e-03\n",
      "Epoch 84200, Train loss: 1.110e+03, Test loss: 7.331e+04, MSE(e): 3.802e-05, MSE(pi1): 1.404e-02, MSE(pi2): 2.202e-05, MSE(pi3): 5.890e-03\n",
      "Epoch 84300, Train loss: 1.192e+03, Test loss: 7.269e+04, MSE(e): 5.091e-05, MSE(pi1): 1.176e-02, MSE(pi2): 2.654e-05, MSE(pi3): 5.649e-03\n",
      "Epoch 84400, Train loss: 1.154e+03, Test loss: 7.229e+04, MSE(e): 3.866e-05, MSE(pi1): 1.951e-02, MSE(pi2): 2.306e-05, MSE(pi3): 5.727e-03\n",
      "Epoch 84500, Train loss: 9.246e+02, Test loss: 7.242e+04, MSE(e): 2.655e-05, MSE(pi1): 9.541e-03, MSE(pi2): 1.556e-05, MSE(pi3): 5.638e-03\n",
      "Epoch 84600, Train loss: 9.214e+02, Test loss: 7.234e+04, MSE(e): 2.616e-05, MSE(pi1): 1.003e-02, MSE(pi2): 1.546e-05, MSE(pi3): 5.594e-03\n",
      "Epoch 84700, Train loss: 1.268e+03, Test loss: 7.284e+04, MSE(e): 6.021e-05, MSE(pi1): 1.146e-02, MSE(pi2): 3.066e-05, MSE(pi3): 5.510e-03\n",
      "Epoch 84800, Train loss: 1.388e+03, Test loss: 7.265e+04, MSE(e): 6.663e-05, MSE(pi1): 1.463e-02, MSE(pi2): 3.531e-05, MSE(pi3): 5.749e-03\n",
      "Epoch 84900, Train loss: 2.393e+03, Test loss: 7.454e+04, MSE(e): 1.440e-04, MSE(pi1): 3.618e-02, MSE(pi2): 7.024e-05, MSE(pi3): 5.910e-03\n",
      "Epoch 85000, Train loss: 1.007e+03, Test loss: 7.284e+04, MSE(e): 3.195e-05, MSE(pi1): 1.142e-02, MSE(pi2): 1.822e-05, MSE(pi3): 5.731e-03\n",
      "Epoch 85100, Train loss: 9.268e+02, Test loss: 7.237e+04, MSE(e): 2.696e-05, MSE(pi1): 9.706e-03, MSE(pi2): 1.585e-05, MSE(pi3): 5.602e-03\n",
      "Epoch 85200, Train loss: 1.749e+03, Test loss: 7.427e+04, MSE(e): 7.426e-05, MSE(pi1): 3.979e-02, MSE(pi2): 5.124e-05, MSE(pi3): 6.085e-03\n",
      "Epoch 85300, Train loss: 9.175e+02, Test loss: 7.228e+04, MSE(e): 2.608e-05, MSE(pi1): 9.774e-03, MSE(pi2): 1.542e-05, MSE(pi3): 5.589e-03\n",
      "Epoch 85400, Train loss: 9.559e+02, Test loss: 7.222e+04, MSE(e): 2.923e-05, MSE(pi1): 1.053e-02, MSE(pi2): 1.660e-05, MSE(pi3): 5.583e-03\n",
      "Epoch 85500, Train loss: 9.428e+02, Test loss: 7.216e+04, MSE(e): 2.684e-05, MSE(pi1): 1.233e-02, MSE(pi2): 1.586e-05, MSE(pi3): 5.510e-03\n",
      "Epoch 85600, Train loss: 9.231e+02, Test loss: 7.230e+04, MSE(e): 2.590e-05, MSE(pi1): 1.010e-02, MSE(pi2): 1.521e-05, MSE(pi3): 5.631e-03\n",
      "Epoch 85700, Train loss: 9.360e+02, Test loss: 7.233e+04, MSE(e): 2.763e-05, MSE(pi1): 1.014e-02, MSE(pi2): 1.614e-05, MSE(pi3): 5.583e-03\n",
      "Epoch 85800, Train loss: 1.645e+03, Test loss: 7.297e+04, MSE(e): 7.914e-05, MSE(pi1): 2.746e-02, MSE(pi2): 3.821e-05, MSE(pi3): 5.792e-03\n",
      "Epoch 85900, Train loss: 9.163e+02, Test loss: 7.222e+04, MSE(e): 2.580e-05, MSE(pi1): 1.003e-02, MSE(pi2): 1.523e-05, MSE(pi3): 5.580e-03\n",
      "Epoch 86000, Train loss: 9.374e+02, Test loss: 7.229e+04, MSE(e): 2.784e-05, MSE(pi1): 9.461e-03, MSE(pi2): 1.591e-05, MSE(pi3): 5.645e-03\n",
      "Epoch 86100, Train loss: 9.783e+02, Test loss: 7.296e+04, MSE(e): 3.018e-05, MSE(pi1): 1.045e-02, MSE(pi2): 1.802e-05, MSE(pi3): 5.720e-03\n",
      "Epoch 86200, Train loss: 9.392e+02, Test loss: 7.209e+04, MSE(e): 2.810e-05, MSE(pi1): 9.991e-03, MSE(pi2): 1.608e-05, MSE(pi3): 5.582e-03\n",
      "Epoch 86300, Train loss: 1.363e+03, Test loss: 7.198e+04, MSE(e): 3.695e-05, MSE(pi1): 4.558e-02, MSE(pi2): 2.358e-05, MSE(pi3): 5.378e-03\n",
      "Epoch 86400, Train loss: 9.531e+02, Test loss: 7.226e+04, MSE(e): 2.967e-05, MSE(pi1): 9.985e-03, MSE(pi2): 1.710e-05, MSE(pi3): 5.565e-03\n",
      "Epoch 86500, Train loss: 9.152e+02, Test loss: 7.214e+04, MSE(e): 2.560e-05, MSE(pi1): 1.006e-02, MSE(pi2): 1.510e-05, MSE(pi3): 5.585e-03\n",
      "Epoch 86600, Train loss: 9.219e+02, Test loss: 7.213e+04, MSE(e): 2.629e-05, MSE(pi1): 9.646e-03, MSE(pi2): 1.529e-05, MSE(pi3): 5.625e-03\n",
      "Epoch 86700, Train loss: 9.132e+02, Test loss: 7.225e+04, MSE(e): 2.565e-05, MSE(pi1): 9.654e-03, MSE(pi2): 1.517e-05, MSE(pi3): 5.602e-03\n",
      "Epoch 86800, Train loss: 1.258e+03, Test loss: 7.295e+04, MSE(e): 5.998e-05, MSE(pi1): 9.772e-03, MSE(pi2): 3.024e-05, MSE(pi3): 5.602e-03\n",
      "Epoch 86900, Train loss: 9.173e+02, Test loss: 7.211e+04, MSE(e): 2.574e-05, MSE(pi1): 1.021e-02, MSE(pi2): 1.513e-05, MSE(pi3): 5.578e-03\n",
      "Epoch 87000, Train loss: 1.073e+03, Test loss: 7.162e+04, MSE(e): 3.270e-05, MSE(pi1): 2.146e-02, MSE(pi2): 2.092e-05, MSE(pi3): 5.312e-03\n",
      "Epoch 87100, Train loss: 1.449e+03, Test loss: 7.292e+04, MSE(e): 7.939e-05, MSE(pi1): 1.023e-02, MSE(pi2): 3.945e-05, MSE(pi3): 5.528e-03\n",
      "Epoch 87200, Train loss: 9.453e+02, Test loss: 7.250e+04, MSE(e): 2.794e-05, MSE(pi1): 9.761e-03, MSE(pi2): 1.655e-05, MSE(pi3): 5.682e-03\n",
      "Epoch 87300, Train loss: 9.957e+02, Test loss: 7.178e+04, MSE(e): 2.836e-05, MSE(pi1): 1.643e-02, MSE(pi2): 1.737e-05, MSE(pi3): 5.478e-03\n",
      "Epoch 87400, Train loss: 1.127e+03, Test loss: 7.189e+04, MSE(e): 3.978e-05, MSE(pi1): 1.855e-02, MSE(pi2): 2.182e-05, MSE(pi3): 5.439e-03\n",
      "Epoch 87500, Train loss: 1.152e+03, Test loss: 7.240e+04, MSE(e): 3.356e-05, MSE(pi1): 2.166e-02, MSE(pi2): 2.063e-05, MSE(pi3): 5.993e-03\n",
      "Epoch 87600, Train loss: 9.280e+02, Test loss: 7.204e+04, MSE(e): 2.706e-05, MSE(pi1): 9.870e-03, MSE(pi2): 1.554e-05, MSE(pi3): 5.587e-03\n",
      "Epoch 87700, Train loss: 9.327e+02, Test loss: 7.219e+04, MSE(e): 2.740e-05, MSE(pi1): 9.393e-03, MSE(pi2): 1.564e-05, MSE(pi3): 5.648e-03\n",
      "Epoch 87800, Train loss: 1.015e+03, Test loss: 7.291e+04, MSE(e): 2.836e-05, MSE(pi1): 1.435e-02, MSE(pi2): 1.698e-05, MSE(pi3): 5.883e-03\n",
      "Epoch 87900, Train loss: 2.073e+03, Test loss: 7.171e+04, MSE(e): 1.026e-04, MSE(pi1): 5.133e-02, MSE(pi2): 6.666e-05, MSE(pi3): 5.339e-03\n",
      "Epoch 88000, Train loss: 9.149e+02, Test loss: 7.207e+04, MSE(e): 2.577e-05, MSE(pi1): 9.996e-03, MSE(pi2): 1.523e-05, MSE(pi3): 5.572e-03\n",
      "Epoch 88100, Train loss: 9.167e+02, Test loss: 7.208e+04, MSE(e): 2.576e-05, MSE(pi1): 9.445e-03, MSE(pi2): 1.502e-05, MSE(pi3): 5.646e-03\n",
      "Epoch 88200, Train loss: 1.206e+03, Test loss: 7.154e+04, MSE(e): 3.412e-05, MSE(pi1): 3.338e-02, MSE(pi2): 2.187e-05, MSE(pi3): 5.309e-03\n",
      "Epoch 88300, Train loss: 9.174e+02, Test loss: 7.224e+04, MSE(e): 2.565e-05, MSE(pi1): 1.011e-02, MSE(pi2): 1.514e-05, MSE(pi3): 5.599e-03\n",
      "Epoch 88400, Train loss: 9.252e+02, Test loss: 7.227e+04, MSE(e): 2.609e-05, MSE(pi1): 1.035e-02, MSE(pi2): 1.559e-05, MSE(pi3): 5.607e-03\n",
      "Epoch 88500, Train loss: 9.055e+02, Test loss: 7.204e+04, MSE(e): 2.495e-05, MSE(pi1): 9.682e-03, MSE(pi2): 1.475e-05, MSE(pi3): 5.591e-03\n",
      "Epoch 88600, Train loss: 9.127e+02, Test loss: 7.216e+04, MSE(e): 2.556e-05, MSE(pi1): 9.835e-03, MSE(pi2): 1.521e-05, MSE(pi3): 5.588e-03\n",
      "Epoch 88700, Train loss: 9.076e+02, Test loss: 7.209e+04, MSE(e): 2.507e-05, MSE(pi1): 9.641e-03, MSE(pi2): 1.477e-05, MSE(pi3): 5.604e-03\n",
      "Epoch 88800, Train loss: 1.130e+03, Test loss: 7.246e+04, MSE(e): 4.756e-05, MSE(pi1): 9.863e-03, MSE(pi2): 2.496e-05, MSE(pi3): 5.562e-03\n",
      "Epoch 88900, Train loss: 1.004e+03, Test loss: 7.183e+04, MSE(e): 3.193e-05, MSE(pi1): 1.169e-02, MSE(pi2): 1.947e-05, MSE(pi3): 5.678e-03\n",
      "Epoch 89000, Train loss: 9.166e+02, Test loss: 7.218e+04, MSE(e): 2.568e-05, MSE(pi1): 9.563e-03, MSE(pi2): 1.512e-05, MSE(pi3): 5.642e-03\n",
      "Epoch 89100, Train loss: 9.068e+02, Test loss: 7.201e+04, MSE(e): 2.491e-05, MSE(pi1): 9.643e-03, MSE(pi2): 1.473e-05, MSE(pi3): 5.612e-03\n",
      "Epoch 89200, Train loss: 9.068e+02, Test loss: 7.205e+04, MSE(e): 2.507e-05, MSE(pi1): 9.548e-03, MSE(pi2): 1.481e-05, MSE(pi3): 5.606e-03\n",
      "Epoch 89300, Train loss: 9.188e+02, Test loss: 7.182e+04, MSE(e): 2.589e-05, MSE(pi1): 1.048e-02, MSE(pi2): 1.510e-05, MSE(pi3): 5.551e-03\n",
      "Epoch 89400, Train loss: 9.436e+02, Test loss: 7.188e+04, MSE(e): 2.785e-05, MSE(pi1): 1.112e-02, MSE(pi2): 1.637e-05, MSE(pi3): 5.539e-03\n",
      "Epoch 89500, Train loss: 9.186e+02, Test loss: 7.213e+04, MSE(e): 2.510e-05, MSE(pi1): 9.814e-03, MSE(pi2): 1.477e-05, MSE(pi3): 5.695e-03\n",
      "Epoch 89600, Train loss: 9.053e+02, Test loss: 7.204e+04, MSE(e): 2.481e-05, MSE(pi1): 9.536e-03, MSE(pi2): 1.465e-05, MSE(pi3): 5.618e-03\n",
      "Epoch 89700, Train loss: 1.106e+03, Test loss: 7.199e+04, MSE(e): 4.464e-05, MSE(pi1): 1.000e-02, MSE(pi2): 2.279e-05, MSE(pi3): 5.596e-03\n",
      "Epoch 89800, Train loss: 9.234e+02, Test loss: 7.228e+04, MSE(e): 2.507e-05, MSE(pi1): 1.009e-02, MSE(pi2): 1.477e-05, MSE(pi3): 5.719e-03\n",
      "Epoch 89900, Train loss: 9.264e+02, Test loss: 7.198e+04, MSE(e): 2.475e-05, MSE(pi1): 1.192e-02, MSE(pi2): 1.457e-05, MSE(pi3): 5.598e-03\n",
      "Epoch 90000, Train loss: 1.732e+03, Test loss: 7.163e+04, MSE(e): 7.856e-05, MSE(pi1): 3.984e-02, MSE(pi2): 4.998e-05, MSE(pi3): 5.483e-03\n",
      "Epoch 90100, Train loss: 1.412e+03, Test loss: 7.246e+04, MSE(e): 7.267e-05, MSE(pi1): 1.192e-02, MSE(pi2): 3.475e-05, MSE(pi3): 5.663e-03\n",
      "Epoch 90200, Train loss: 9.886e+02, Test loss: 7.187e+04, MSE(e): 2.990e-05, MSE(pi1): 1.358e-02, MSE(pi2): 1.654e-05, MSE(pi3): 5.538e-03\n",
      "Epoch 90300, Train loss: 9.213e+02, Test loss: 7.175e+04, MSE(e): 2.607e-05, MSE(pi1): 1.081e-02, MSE(pi2): 1.556e-05, MSE(pi3): 5.524e-03\n",
      "Epoch 90400, Train loss: 9.025e+02, Test loss: 7.201e+04, MSE(e): 2.467e-05, MSE(pi1): 9.431e-03, MSE(pi2): 1.459e-05, MSE(pi3): 5.616e-03\n",
      "Epoch 90500, Train loss: 9.099e+02, Test loss: 7.192e+04, MSE(e): 2.542e-05, MSE(pi1): 9.501e-03, MSE(pi2): 1.496e-05, MSE(pi3): 5.607e-03\n",
      "Epoch 90600, Train loss: 9.238e+02, Test loss: 7.191e+04, MSE(e): 2.639e-05, MSE(pi1): 1.070e-02, MSE(pi2): 1.551e-05, MSE(pi3): 5.529e-03\n",
      "Epoch 90700, Train loss: 9.089e+02, Test loss: 7.177e+04, MSE(e): 2.532e-05, MSE(pi1): 9.754e-03, MSE(pi2): 1.510e-05, MSE(pi3): 5.581e-03\n",
      "Epoch 90800, Train loss: 8.994e+02, Test loss: 7.192e+04, MSE(e): 2.432e-05, MSE(pi1): 9.500e-03, MSE(pi2): 1.435e-05, MSE(pi3): 5.611e-03\n",
      "Epoch 90900, Train loss: 9.047e+02, Test loss: 7.190e+04, MSE(e): 2.482e-05, MSE(pi1): 9.461e-03, MSE(pi2): 1.449e-05, MSE(pi3): 5.619e-03\n",
      "Epoch 91000, Train loss: 1.225e+03, Test loss: 7.263e+04, MSE(e): 5.577e-05, MSE(pi1): 1.086e-02, MSE(pi2): 2.842e-05, MSE(pi3): 5.591e-03\n",
      "Epoch 91100, Train loss: 9.413e+02, Test loss: 7.170e+04, MSE(e): 2.763e-05, MSE(pi1): 1.135e-02, MSE(pi2): 1.630e-05, MSE(pi3): 5.514e-03\n",
      "Epoch 91200, Train loss: 9.901e+02, Test loss: 7.263e+04, MSE(e): 2.791e-05, MSE(pi1): 1.282e-02, MSE(pi2): 1.657e-05, MSE(pi3): 5.828e-03\n",
      "Epoch 91300, Train loss: 8.997e+02, Test loss: 7.189e+04, MSE(e): 2.434e-05, MSE(pi1): 9.686e-03, MSE(pi2): 1.440e-05, MSE(pi3): 5.594e-03\n",
      "Epoch 91400, Train loss: 9.203e+02, Test loss: 7.200e+04, MSE(e): 2.621e-05, MSE(pi1): 9.902e-03, MSE(pi2): 1.549e-05, MSE(pi3): 5.591e-03\n",
      "Epoch 91500, Train loss: 1.028e+03, Test loss: 7.188e+04, MSE(e): 3.695e-05, MSE(pi1): 9.357e-03, MSE(pi2): 1.931e-05, MSE(pi3): 5.652e-03\n",
      "Epoch 91600, Train loss: 1.150e+03, Test loss: 7.214e+04, MSE(e): 3.411e-05, MSE(pi1): 2.641e-02, MSE(pi2): 2.163e-05, MSE(pi3): 5.446e-03\n",
      "Epoch 91700, Train loss: 9.201e+02, Test loss: 7.177e+04, MSE(e): 2.634e-05, MSE(pi1): 9.539e-03, MSE(pi2): 1.508e-05, MSE(pi3): 5.613e-03\n",
      "Epoch 91800, Train loss: 1.552e+03, Test loss: 7.323e+04, MSE(e): 8.888e-05, MSE(pi1): 1.103e-02, MSE(pi2): 4.282e-05, MSE(pi3): 5.529e-03\n",
      "Epoch 91900, Train loss: 9.538e+02, Test loss: 7.185e+04, MSE(e): 2.657e-05, MSE(pi1): 1.429e-02, MSE(pi2): 1.604e-05, MSE(pi3): 5.452e-03\n",
      "Epoch 92000, Train loss: 1.208e+03, Test loss: 7.331e+04, MSE(e): 3.265e-05, MSE(pi1): 2.744e-02, MSE(pi2): 2.017e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 92100, Train loss: 1.211e+03, Test loss: 7.276e+04, MSE(e): 5.418e-05, MSE(pi1): 1.059e-02, MSE(pi2): 2.875e-05, MSE(pi3): 5.637e-03\n",
      "Epoch 92200, Train loss: 1.008e+03, Test loss: 7.174e+04, MSE(e): 2.856e-05, MSE(pi1): 1.703e-02, MSE(pi2): 1.684e-05, MSE(pi3): 5.516e-03\n",
      "Epoch 92300, Train loss: 9.666e+02, Test loss: 7.200e+04, MSE(e): 3.118e-05, MSE(pi1): 9.633e-03, MSE(pi2): 1.751e-05, MSE(pi3): 5.585e-03\n",
      "Epoch 92400, Train loss: 9.131e+02, Test loss: 7.200e+04, MSE(e): 2.572e-05, MSE(pi1): 9.330e-03, MSE(pi2): 1.504e-05, MSE(pi3): 5.626e-03\n",
      "Epoch 92500, Train loss: 9.129e+02, Test loss: 7.203e+04, MSE(e): 2.425e-05, MSE(pi1): 1.011e-02, MSE(pi2): 1.429e-05, MSE(pi3): 5.694e-03\n",
      "Epoch 92600, Train loss: 9.060e+02, Test loss: 7.189e+04, MSE(e): 2.456e-05, MSE(pi1): 9.883e-03, MSE(pi2): 1.444e-05, MSE(pi3): 5.615e-03\n",
      "Epoch 92700, Train loss: 9.271e+02, Test loss: 7.192e+04, MSE(e): 2.454e-05, MSE(pi1): 1.106e-02, MSE(pi2): 1.444e-05, MSE(pi3): 5.711e-03\n",
      "Epoch 92800, Train loss: 9.008e+02, Test loss: 7.190e+04, MSE(e): 2.404e-05, MSE(pi1): 9.491e-03, MSE(pi2): 1.417e-05, MSE(pi3): 5.655e-03\n",
      "Epoch 92900, Train loss: 9.080e+02, Test loss: 7.192e+04, MSE(e): 2.477e-05, MSE(pi1): 1.017e-02, MSE(pi2): 1.479e-05, MSE(pi3): 5.585e-03\n",
      "Epoch 93000, Train loss: 9.783e+02, Test loss: 7.225e+04, MSE(e): 2.833e-05, MSE(pi1): 1.264e-02, MSE(pi2): 1.686e-05, MSE(pi3): 5.686e-03\n",
      "Epoch 93100, Train loss: 9.523e+02, Test loss: 7.196e+04, MSE(e): 2.515e-05, MSE(pi1): 1.316e-02, MSE(pi2): 1.467e-05, MSE(pi3): 5.692e-03\n",
      "Epoch 93200, Train loss: 1.036e+03, Test loss: 7.130e+04, MSE(e): 3.696e-05, MSE(pi1): 1.006e-02, MSE(pi2): 1.947e-05, MSE(pi3): 5.657e-03\n",
      "Epoch 93300, Train loss: 8.932e+02, Test loss: 7.175e+04, MSE(e): 2.368e-05, MSE(pi1): 9.767e-03, MSE(pi2): 1.401e-05, MSE(pi3): 5.587e-03\n",
      "Epoch 93400, Train loss: 9.303e+02, Test loss: 7.195e+04, MSE(e): 2.756e-05, MSE(pi1): 9.423e-03, MSE(pi2): 1.586e-05, MSE(pi3): 5.605e-03\n",
      "Epoch 93500, Train loss: 9.980e+02, Test loss: 7.199e+04, MSE(e): 2.957e-05, MSE(pi1): 1.543e-02, MSE(pi2): 1.817e-05, MSE(pi3): 5.480e-03\n",
      "Epoch 93600, Train loss: 1.025e+03, Test loss: 7.195e+04, MSE(e): 3.710e-05, MSE(pi1): 9.489e-03, MSE(pi2): 2.011e-05, MSE(pi3): 5.595e-03\n",
      "Epoch 93700, Train loss: 9.011e+02, Test loss: 7.173e+04, MSE(e): 2.379e-05, MSE(pi1): 1.005e-02, MSE(pi2): 1.405e-05, MSE(pi3): 5.627e-03\n",
      "Epoch 93800, Train loss: 1.355e+03, Test loss: 7.222e+04, MSE(e): 6.692e-05, MSE(pi1): 1.439e-02, MSE(pi2): 3.370e-05, MSE(pi3): 5.414e-03\n",
      "Epoch 93900, Train loss: 8.977e+02, Test loss: 7.192e+04, MSE(e): 2.392e-05, MSE(pi1): 9.297e-03, MSE(pi2): 1.415e-05, MSE(pi3): 5.655e-03\n",
      "Epoch 94000, Train loss: 8.906e+02, Test loss: 7.175e+04, MSE(e): 2.356e-05, MSE(pi1): 9.497e-03, MSE(pi2): 1.394e-05, MSE(pi3): 5.600e-03\n",
      "Epoch 94100, Train loss: 9.115e+02, Test loss: 7.171e+04, MSE(e): 2.477e-05, MSE(pi1): 1.009e-02, MSE(pi2): 1.464e-05, MSE(pi3): 5.629e-03\n",
      "Epoch 94200, Train loss: 1.092e+03, Test loss: 7.238e+04, MSE(e): 3.774e-05, MSE(pi1): 1.445e-02, MSE(pi2): 2.199e-05, MSE(pi3): 5.698e-03\n",
      "Epoch 94300, Train loss: 9.446e+02, Test loss: 7.223e+04, MSE(e): 2.877e-05, MSE(pi1): 9.614e-03, MSE(pi2): 1.696e-05, MSE(pi3): 5.607e-03\n",
      "Epoch 94400, Train loss: 8.925e+02, Test loss: 7.179e+04, MSE(e): 2.369e-05, MSE(pi1): 9.274e-03, MSE(pi2): 1.397e-05, MSE(pi3): 5.628e-03\n",
      "Epoch 94500, Train loss: 8.999e+02, Test loss: 7.182e+04, MSE(e): 2.412e-05, MSE(pi1): 9.669e-03, MSE(pi2): 1.426e-05, MSE(pi3): 5.620e-03\n",
      "Epoch 94600, Train loss: 9.300e+02, Test loss: 7.152e+04, MSE(e): 2.702e-05, MSE(pi1): 1.018e-02, MSE(pi2): 1.602e-05, MSE(pi3): 5.579e-03\n",
      "Epoch 94700, Train loss: 1.037e+03, Test loss: 7.164e+04, MSE(e): 3.799e-05, MSE(pi1): 9.554e-03, MSE(pi2): 1.963e-05, MSE(pi3): 5.616e-03\n",
      "Epoch 94800, Train loss: 9.210e+02, Test loss: 7.182e+04, MSE(e): 2.396e-05, MSE(pi1): 1.090e-02, MSE(pi2): 1.407e-05, MSE(pi3): 5.724e-03\n",
      "Epoch 94900, Train loss: 8.966e+02, Test loss: 7.177e+04, MSE(e): 2.349e-05, MSE(pi1): 9.612e-03, MSE(pi2): 1.379e-05, MSE(pi3): 5.655e-03\n",
      "Epoch 95000, Train loss: 9.359e+02, Test loss: 7.194e+04, MSE(e): 2.716e-05, MSE(pi1): 9.940e-03, MSE(pi2): 1.580e-05, MSE(pi3): 5.650e-03\n",
      "Epoch 95100, Train loss: 9.020e+02, Test loss: 7.143e+04, MSE(e): 2.420e-05, MSE(pi1): 1.057e-02, MSE(pi2): 1.421e-05, MSE(pi3): 5.544e-03\n",
      "Epoch 95200, Train loss: 9.588e+02, Test loss: 7.192e+04, MSE(e): 2.929e-05, MSE(pi1): 1.038e-02, MSE(pi2): 1.708e-05, MSE(pi3): 5.621e-03\n",
      "Epoch 95300, Train loss: 1.116e+03, Test loss: 7.135e+04, MSE(e): 4.426e-05, MSE(pi1): 1.219e-02, MSE(pi2): 2.238e-05, MSE(pi3): 5.514e-03\n",
      "Epoch 95400, Train loss: 8.864e+02, Test loss: 7.165e+04, MSE(e): 2.316e-05, MSE(pi1): 9.433e-03, MSE(pi2): 1.368e-05, MSE(pi3): 5.604e-03\n",
      "Epoch 95500, Train loss: 9.285e+02, Test loss: 7.174e+04, MSE(e): 2.734e-05, MSE(pi1): 9.957e-03, MSE(pi2): 1.574e-05, MSE(pi3): 5.555e-03\n",
      "Epoch 95600, Train loss: 9.181e+02, Test loss: 7.147e+04, MSE(e): 2.529e-05, MSE(pi1): 1.088e-02, MSE(pi2): 1.524e-05, MSE(pi3): 5.564e-03\n",
      "Epoch 95700, Train loss: 9.728e+02, Test loss: 7.289e+04, MSE(e): 3.036e-05, MSE(pi1): 9.102e-03, MSE(pi2): 1.806e-05, MSE(pi3): 5.781e-03\n",
      "Epoch 95800, Train loss: 8.850e+02, Test loss: 7.159e+04, MSE(e): 2.305e-05, MSE(pi1): 9.525e-03, MSE(pi2): 1.364e-05, MSE(pi3): 5.593e-03\n",
      "Epoch 95900, Train loss: 8.893e+02, Test loss: 7.167e+04, MSE(e): 2.341e-05, MSE(pi1): 9.291e-03, MSE(pi2): 1.374e-05, MSE(pi3): 5.623e-03\n",
      "Epoch 96000, Train loss: 8.862e+02, Test loss: 7.163e+04, MSE(e): 2.306e-05, MSE(pi1): 9.457e-03, MSE(pi2): 1.360e-05, MSE(pi3): 5.610e-03\n",
      "Epoch 96100, Train loss: 9.799e+02, Test loss: 7.199e+04, MSE(e): 3.253e-05, MSE(pi1): 9.349e-03, MSE(pi2): 1.802e-05, MSE(pi3): 5.611e-03\n",
      "Epoch 96200, Train loss: 8.883e+02, Test loss: 7.152e+04, MSE(e): 2.314e-05, MSE(pi1): 1.016e-02, MSE(pi2): 1.373e-05, MSE(pi3): 5.552e-03\n",
      "Epoch 96300, Train loss: 9.199e+02, Test loss: 7.149e+04, MSE(e): 2.643e-05, MSE(pi1): 9.570e-03, MSE(pi2): 1.488e-05, MSE(pi3): 5.599e-03\n",
      "Epoch 96400, Train loss: 8.956e+02, Test loss: 7.163e+04, MSE(e): 2.382e-05, MSE(pi1): 9.853e-03, MSE(pi2): 1.404e-05, MSE(pi3): 5.589e-03\n",
      "Epoch 96500, Train loss: 9.220e+02, Test loss: 7.163e+04, MSE(e): 2.346e-05, MSE(pi1): 1.310e-02, MSE(pi2): 1.391e-05, MSE(pi3): 5.563e-03\n",
      "Epoch 96600, Train loss: 9.137e+02, Test loss: 7.163e+04, MSE(e): 2.570e-05, MSE(pi1): 9.466e-03, MSE(pi2): 1.467e-05, MSE(pi3): 5.621e-03\n",
      "Epoch 96700, Train loss: 9.035e+02, Test loss: 7.135e+04, MSE(e): 2.470e-05, MSE(pi1): 1.027e-02, MSE(pi2): 1.478e-05, MSE(pi3): 5.538e-03\n",
      "Epoch 96800, Train loss: 9.449e+02, Test loss: 7.132e+04, MSE(e): 2.677e-05, MSE(pi1): 1.174e-02, MSE(pi2): 1.595e-05, MSE(pi3): 5.598e-03\n",
      "Epoch 96900, Train loss: 8.836e+02, Test loss: 7.153e+04, MSE(e): 2.291e-05, MSE(pi1): 9.663e-03, MSE(pi2): 1.359e-05, MSE(pi3): 5.579e-03\n",
      "Epoch 97000, Train loss: 8.978e+02, Test loss: 7.129e+04, MSE(e): 2.425e-05, MSE(pi1): 9.925e-03, MSE(pi2): 1.452e-05, MSE(pi3): 5.561e-03\n",
      "Epoch 97100, Train loss: 8.872e+02, Test loss: 7.157e+04, MSE(e): 2.329e-05, MSE(pi1): 9.574e-03, MSE(pi2): 1.377e-05, MSE(pi3): 5.586e-03\n",
      "Epoch 97200, Train loss: 9.224e+02, Test loss: 7.171e+04, MSE(e): 2.601e-05, MSE(pi1): 1.017e-02, MSE(pi2): 1.524e-05, MSE(pi3): 5.607e-03\n",
      "Epoch 97300, Train loss: 1.067e+03, Test loss: 7.130e+04, MSE(e): 3.525e-05, MSE(pi1): 1.720e-02, MSE(pi2): 1.971e-05, MSE(pi3): 5.428e-03\n",
      "Epoch 97400, Train loss: 1.410e+03, Test loss: 7.100e+04, MSE(e): 5.165e-05, MSE(pi1): 3.454e-02, MSE(pi2): 3.389e-05, MSE(pi3): 5.478e-03\n",
      "Epoch 97500, Train loss: 2.158e+03, Test loss: 7.409e+04, MSE(e): 1.121e-04, MSE(pi1): 4.127e-02, MSE(pi2): 5.485e-05, MSE(pi3): 6.241e-03\n",
      "Epoch 97600, Train loss: 9.842e+02, Test loss: 7.159e+04, MSE(e): 3.145e-05, MSE(pi1): 1.181e-02, MSE(pi2): 1.795e-05, MSE(pi3): 5.516e-03\n",
      "Epoch 97700, Train loss: 9.101e+02, Test loss: 7.177e+04, MSE(e): 2.561e-05, MSE(pi1): 9.319e-03, MSE(pi2): 1.499e-05, MSE(pi3): 5.607e-03\n",
      "Epoch 97800, Train loss: 9.018e+02, Test loss: 7.178e+04, MSE(e): 2.404e-05, MSE(pi1): 9.739e-03, MSE(pi2): 1.418e-05, MSE(pi3): 5.640e-03\n",
      "Epoch 97900, Train loss: 1.066e+03, Test loss: 7.159e+04, MSE(e): 4.074e-05, MSE(pi1): 9.849e-03, MSE(pi2): 2.081e-05, MSE(pi3): 5.601e-03\n",
      "Epoch 98000, Train loss: 9.345e+02, Test loss: 7.146e+04, MSE(e): 2.417e-05, MSE(pi1): 1.384e-02, MSE(pi2): 1.412e-05, MSE(pi3): 5.544e-03\n",
      "Epoch 98100, Train loss: 8.963e+02, Test loss: 7.175e+04, MSE(e): 2.309e-05, MSE(pi1): 9.868e-03, MSE(pi2): 1.364e-05, MSE(pi3): 5.667e-03\n",
      "Epoch 98200, Train loss: 8.998e+02, Test loss: 7.139e+04, MSE(e): 2.422e-05, MSE(pi1): 9.830e-03, MSE(pi2): 1.445e-05, MSE(pi3): 5.593e-03\n",
      "Epoch 98300, Train loss: 9.048e+02, Test loss: 7.119e+04, MSE(e): 2.366e-05, MSE(pi1): 1.162e-02, MSE(pi2): 1.411e-05, MSE(pi3): 5.521e-03\n",
      "Epoch 98400, Train loss: 1.207e+03, Test loss: 7.165e+04, MSE(e): 5.215e-05, MSE(pi1): 1.167e-02, MSE(pi2): 2.527e-05, MSE(pi3): 5.692e-03\n",
      "Epoch 98500, Train loss: 9.290e+02, Test loss: 7.135e+04, MSE(e): 2.365e-05, MSE(pi1): 1.458e-02, MSE(pi2): 1.428e-05, MSE(pi3): 5.467e-03\n",
      "Epoch 98600, Train loss: 9.908e+02, Test loss: 7.156e+04, MSE(e): 3.281e-05, MSE(pi1): 9.773e-03, MSE(pi2): 1.743e-05, MSE(pi3): 5.650e-03\n",
      "Epoch 98700, Train loss: 1.008e+03, Test loss: 7.082e+04, MSE(e): 3.352e-05, MSE(pi1): 1.263e-02, MSE(pi2): 2.131e-05, MSE(pi3): 5.468e-03\n",
      "Epoch 98800, Train loss: 8.828e+02, Test loss: 7.143e+04, MSE(e): 2.243e-05, MSE(pi1): 9.779e-03, MSE(pi2): 1.325e-05, MSE(pi3): 5.607e-03\n",
      "Epoch 98900, Train loss: 8.903e+02, Test loss: 7.157e+04, MSE(e): 2.274e-05, MSE(pi1): 9.568e-03, MSE(pi2): 1.333e-05, MSE(pi3): 5.672e-03\n",
      "Epoch 99000, Train loss: 1.233e+03, Test loss: 7.229e+04, MSE(e): 3.719e-05, MSE(pi1): 3.031e-02, MSE(pi2): 2.441e-05, MSE(pi3): 5.581e-03\n",
      "Epoch 99100, Train loss: 1.255e+03, Test loss: 7.299e+04, MSE(e): 3.821e-05, MSE(pi1): 2.622e-02, MSE(pi2): 2.310e-05, MSE(pi3): 6.107e-03\n",
      "Epoch 99200, Train loss: 1.188e+03, Test loss: 7.117e+04, MSE(e): 3.935e-05, MSE(pi1): 2.335e-02, MSE(pi2): 2.603e-05, MSE(pi3): 5.612e-03\n",
      "Epoch 99300, Train loss: 8.772e+02, Test loss: 7.139e+04, MSE(e): 2.229e-05, MSE(pi1): 9.497e-03, MSE(pi2): 1.320e-05, MSE(pi3): 5.593e-03\n",
      "Epoch 99400, Train loss: 8.795e+02, Test loss: 7.148e+04, MSE(e): 2.252e-05, MSE(pi1): 9.503e-03, MSE(pi2): 1.331e-05, MSE(pi3): 5.592e-03\n",
      "Epoch 99500, Train loss: 9.817e+02, Test loss: 7.132e+04, MSE(e): 2.495e-05, MSE(pi1): 1.870e-02, MSE(pi2): 1.506e-05, MSE(pi3): 5.452e-03\n",
      "Epoch 99600, Train loss: 1.007e+03, Test loss: 7.164e+04, MSE(e): 3.436e-05, MSE(pi1): 9.840e-03, MSE(pi2): 1.829e-05, MSE(pi3): 5.648e-03\n",
      "Epoch 99700, Train loss: 9.363e+02, Test loss: 7.127e+04, MSE(e): 2.766e-05, MSE(pi1): 1.040e-02, MSE(pi2): 1.532e-05, MSE(pi3): 5.557e-03\n",
      "Epoch 99800, Train loss: 8.843e+02, Test loss: 7.132e+04, MSE(e): 2.262e-05, MSE(pi1): 1.038e-02, MSE(pi2): 1.349e-05, MSE(pi3): 5.542e-03\n",
      "Epoch 99900, Train loss: 1.092e+03, Test loss: 7.240e+04, MSE(e): 2.882e-05, MSE(pi1): 2.016e-02, MSE(pi2): 1.757e-05, MSE(pi3): 6.019e-03\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 18000\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "second_lr = 3e-4\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
