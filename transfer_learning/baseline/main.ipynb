{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Own library imports\n",
    "from vecopsciml.utils import TensOps\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "\n",
    "# Function from this project\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "# Import model\n",
    "from architectures.pgnniv_baseline import PGNNIVBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Embedding-Oriented-PGNNIV/results/transfer_learning_1000\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Embedding-Oriented-PGNNIV/results/transfer_learning_1000/baseline\n"
     ]
    }
   ],
   "source": [
    "# Create folders paths\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear_1000/sigmoid_nonlinear_1000.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_1000')\n",
    "\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_1000/baseline')\n",
    "\n",
    "# Create folders (if necessary)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_TRANSFERLEARNING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Embedding-Oriented-PGNNIV/data/sigmoid_nonlinear_1000/sigmoid_nonlinear_1000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 800\n",
      "Validation dataset length: 200\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X_train, y_train, K_train, f_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 1.813e+09, Test loss: 1.734e+09, MSE(e): 1.269e+02, MSE(pi1): 5.348e+04, MSE(pi2): 5.575e+01, MSE(pi3): 8.897e+01\n",
      "Epoch 10, Train loss: 9.511e+08, Test loss: 9.491e+08, MSE(e): 8.671e+01, MSE(pi1): 8.092e+03, MSE(pi2): 3.526e+01, MSE(pi3): 3.025e+01\n",
      "Epoch 20, Train loss: 5.853e+08, Test loss: 5.917e+08, MSE(e): 5.489e+01, MSE(pi1): 3.417e+03, MSE(pi2): 2.125e+01, MSE(pi3): 2.267e+01\n",
      "Epoch 30, Train loss: 3.500e+08, Test loss: 3.614e+08, MSE(e): 3.286e+01, MSE(pi1): 1.962e+03, MSE(pi2): 1.263e+01, MSE(pi3): 1.742e+01\n",
      "Epoch 40, Train loss: 2.195e+08, Test loss: 2.355e+08, MSE(e): 2.083e+01, MSE(pi1): 9.986e+02, MSE(pi2): 8.399e+00, MSE(pi3): 1.142e+01\n",
      "Epoch 50, Train loss: 1.684e+08, Test loss: 1.869e+08, MSE(e): 1.634e+01, MSE(pi1): 4.248e+02, MSE(pi2): 6.922e+00, MSE(pi3): 7.458e+00\n",
      "Epoch 60, Train loss: 1.518e+08, Test loss: 1.708e+08, MSE(e): 1.495e+01, MSE(pi1): 1.712e+02, MSE(pi2): 6.451e+00, MSE(pi3): 5.854e+00\n",
      "Epoch 70, Train loss: 1.451e+08, Test loss: 1.641e+08, MSE(e): 1.438e+01, MSE(pi1): 7.394e+01, MSE(pi2): 6.243e+00, MSE(pi3): 5.295e+00\n",
      "Epoch 80, Train loss: 1.409e+08, Test loss: 1.596e+08, MSE(e): 1.400e+01, MSE(pi1): 3.953e+01, MSE(pi2): 6.093e+00, MSE(pi3): 5.087e+00\n",
      "Epoch 90, Train loss: 1.367e+08, Test loss: 1.550e+08, MSE(e): 1.358e+01, MSE(pi1): 2.965e+01, MSE(pi2): 5.925e+00, MSE(pi3): 5.006e+00\n",
      "Epoch 100, Train loss: 1.303e+08, Test loss: 1.481e+08, MSE(e): 1.295e+01, MSE(pi1): 3.229e+01, MSE(pi2): 5.663e+00, MSE(pi3): 4.971e+00\n",
      "Epoch 110, Train loss: 1.193e+08, Test loss: 1.362e+08, MSE(e): 1.183e+01, MSE(pi1): 4.984e+01, MSE(pi2): 5.206e+00, MSE(pi3): 4.980e+00\n",
      "Epoch 120, Train loss: 1.037e+08, Test loss: 1.190e+08, MSE(e): 1.022e+01, MSE(pi1): 9.185e+01, MSE(pi2): 4.544e+00, MSE(pi3): 5.032e+00\n",
      "Epoch 130, Train loss: 8.587e+07, Test loss: 9.937e+07, MSE(e): 8.378e+00, MSE(pi1): 1.577e+02, MSE(pi2): 3.788e+00, MSE(pi3): 5.118e+00\n",
      "Epoch 140, Train loss: 7.127e+07, Test loss: 8.320e+07, MSE(e): 6.866e+00, MSE(pi1): 2.096e+02, MSE(pi2): 3.172e+00, MSE(pi3): 5.185e+00\n",
      "Epoch 150, Train loss: 6.166e+07, Test loss: 7.237e+07, MSE(e): 5.893e+00, MSE(pi1): 2.211e+02, MSE(pi2): 2.781e+00, MSE(pi3): 5.173e+00\n",
      "Epoch 160, Train loss: 5.544e+07, Test loss: 6.514e+07, MSE(e): 5.288e+00, MSE(pi1): 2.051e+02, MSE(pi2): 2.542e+00, MSE(pi3): 5.092e+00\n",
      "Epoch 170, Train loss: 5.083e+07, Test loss: 5.967e+07, MSE(e): 4.854e+00, MSE(pi1): 1.785e+02, MSE(pi2): 2.372e+00, MSE(pi3): 4.972e+00\n",
      "Epoch 180, Train loss: 4.635e+07, Test loss: 5.457e+07, MSE(e): 4.438e+00, MSE(pi1): 1.491e+02, MSE(pi2): 2.203e+00, MSE(pi3): 4.834e+00\n",
      "Epoch 190, Train loss: 4.245e+07, Test loss: 4.999e+07, MSE(e): 4.067e+00, MSE(pi1): 1.301e+02, MSE(pi2): 2.049e+00, MSE(pi3): 4.741e+00\n",
      "Epoch 200, Train loss: 3.919e+07, Test loss: 4.608e+07, MSE(e): 3.755e+00, MSE(pi1): 1.167e+02, MSE(pi2): 1.921e+00, MSE(pi3): 4.660e+00\n",
      "Epoch 210, Train loss: 3.641e+07, Test loss: 4.272e+07, MSE(e): 3.490e+00, MSE(pi1): 1.055e+02, MSE(pi2): 1.813e+00, MSE(pi3): 4.578e+00\n",
      "Epoch 220, Train loss: 3.402e+07, Test loss: 3.982e+07, MSE(e): 3.261e+00, MSE(pi1): 9.579e+01, MSE(pi2): 1.721e+00, MSE(pi3): 4.498e+00\n",
      "Epoch 230, Train loss: 3.196e+07, Test loss: 3.734e+07, MSE(e): 3.065e+00, MSE(pi1): 8.738e+01, MSE(pi2): 1.641e+00, MSE(pi3): 4.420e+00\n",
      "Epoch 240, Train loss: 3.022e+07, Test loss: 3.521e+07, MSE(e): 2.899e+00, MSE(pi1): 8.002e+01, MSE(pi2): 1.574e+00, MSE(pi3): 4.343e+00\n",
      "Epoch 250, Train loss: 2.874e+07, Test loss: 3.337e+07, MSE(e): 2.757e+00, MSE(pi1): 7.343e+01, MSE(pi2): 1.518e+00, MSE(pi3): 4.268e+00\n",
      "Epoch 260, Train loss: 2.746e+07, Test loss: 3.176e+07, MSE(e): 2.636e+00, MSE(pi1): 6.751e+01, MSE(pi2): 1.469e+00, MSE(pi3): 4.195e+00\n",
      "Epoch 270, Train loss: 2.634e+07, Test loss: 3.035e+07, MSE(e): 2.531e+00, MSE(pi1): 6.220e+01, MSE(pi2): 1.427e+00, MSE(pi3): 4.124e+00\n",
      "Epoch 280, Train loss: 2.536e+07, Test loss: 2.908e+07, MSE(e): 2.438e+00, MSE(pi1): 5.744e+01, MSE(pi2): 1.390e+00, MSE(pi3): 4.054e+00\n",
      "Epoch 290, Train loss: 2.449e+07, Test loss: 2.793e+07, MSE(e): 2.356e+00, MSE(pi1): 5.318e+01, MSE(pi2): 1.357e+00, MSE(pi3): 3.986e+00\n",
      "Epoch 300, Train loss: 2.369e+07, Test loss: 2.687e+07, MSE(e): 2.281e+00, MSE(pi1): 4.940e+01, MSE(pi2): 1.326e+00, MSE(pi3): 3.919e+00\n",
      "Epoch 310, Train loss: 2.297e+07, Test loss: 2.588e+07, MSE(e): 2.212e+00, MSE(pi1): 4.607e+01, MSE(pi2): 1.298e+00, MSE(pi3): 3.855e+00\n",
      "Epoch 320, Train loss: 2.230e+07, Test loss: 2.496e+07, MSE(e): 2.148e+00, MSE(pi1): 4.315e+01, MSE(pi2): 1.273e+00, MSE(pi3): 3.793e+00\n",
      "Epoch 330, Train loss: 2.168e+07, Test loss: 2.411e+07, MSE(e): 2.090e+00, MSE(pi1): 4.059e+01, MSE(pi2): 1.249e+00, MSE(pi3): 3.733e+00\n",
      "Epoch 340, Train loss: 2.112e+07, Test loss: 2.333e+07, MSE(e): 2.037e+00, MSE(pi1): 3.833e+01, MSE(pi2): 1.227e+00, MSE(pi3): 3.675e+00\n",
      "Epoch 350, Train loss: 2.060e+07, Test loss: 2.261e+07, MSE(e): 1.987e+00, MSE(pi1): 3.634e+01, MSE(pi2): 1.207e+00, MSE(pi3): 3.618e+00\n",
      "Epoch 360, Train loss: 2.013e+07, Test loss: 2.195e+07, MSE(e): 1.942e+00, MSE(pi1): 3.457e+01, MSE(pi2): 1.189e+00, MSE(pi3): 3.563e+00\n",
      "Epoch 370, Train loss: 1.969e+07, Test loss: 2.134e+07, MSE(e): 1.901e+00, MSE(pi1): 3.300e+01, MSE(pi2): 1.172e+00, MSE(pi3): 3.509e+00\n",
      "Epoch 380, Train loss: 1.930e+07, Test loss: 2.079e+07, MSE(e): 1.864e+00, MSE(pi1): 3.161e+01, MSE(pi2): 1.157e+00, MSE(pi3): 3.456e+00\n",
      "Epoch 390, Train loss: 1.894e+07, Test loss: 2.027e+07, MSE(e): 1.830e+00, MSE(pi1): 3.036e+01, MSE(pi2): 1.143e+00, MSE(pi3): 3.405e+00\n",
      "Epoch 400, Train loss: 1.862e+07, Test loss: 1.981e+07, MSE(e): 1.799e+00, MSE(pi1): 2.926e+01, MSE(pi2): 1.130e+00, MSE(pi3): 3.355e+00\n",
      "Epoch 410, Train loss: 1.832e+07, Test loss: 1.938e+07, MSE(e): 1.771e+00, MSE(pi1): 2.827e+01, MSE(pi2): 1.119e+00, MSE(pi3): 3.307e+00\n",
      "Epoch 420, Train loss: 1.805e+07, Test loss: 1.899e+07, MSE(e): 1.745e+00, MSE(pi1): 2.740e+01, MSE(pi2): 1.108e+00, MSE(pi3): 3.260e+00\n",
      "Epoch 430, Train loss: 1.781e+07, Test loss: 1.863e+07, MSE(e): 1.722e+00, MSE(pi1): 2.662e+01, MSE(pi2): 1.099e+00, MSE(pi3): 3.213e+00\n",
      "Epoch 440, Train loss: 1.758e+07, Test loss: 1.831e+07, MSE(e): 1.700e+00, MSE(pi1): 2.594e+01, MSE(pi2): 1.090e+00, MSE(pi3): 3.168e+00\n",
      "Epoch 450, Train loss: 1.737e+07, Test loss: 1.801e+07, MSE(e): 1.681e+00, MSE(pi1): 2.533e+01, MSE(pi2): 1.082e+00, MSE(pi3): 3.124e+00\n",
      "Epoch 460, Train loss: 1.718e+07, Test loss: 1.773e+07, MSE(e): 1.663e+00, MSE(pi1): 2.480e+01, MSE(pi2): 1.075e+00, MSE(pi3): 3.081e+00\n",
      "Epoch 470, Train loss: 1.701e+07, Test loss: 1.747e+07, MSE(e): 1.646e+00, MSE(pi1): 2.434e+01, MSE(pi2): 1.068e+00, MSE(pi3): 3.038e+00\n",
      "Epoch 480, Train loss: 1.685e+07, Test loss: 1.723e+07, MSE(e): 1.631e+00, MSE(pi1): 2.393e+01, MSE(pi2): 1.061e+00, MSE(pi3): 2.997e+00\n",
      "Epoch 490, Train loss: 1.670e+07, Test loss: 1.701e+07, MSE(e): 1.616e+00, MSE(pi1): 2.358e+01, MSE(pi2): 1.056e+00, MSE(pi3): 2.956e+00\n",
      "Epoch 500, Train loss: 1.656e+07, Test loss: 1.681e+07, MSE(e): 1.603e+00, MSE(pi1): 2.328e+01, MSE(pi2): 1.050e+00, MSE(pi3): 2.916e+00\n",
      "Epoch 510, Train loss: 1.643e+07, Test loss: 1.662e+07, MSE(e): 1.591e+00, MSE(pi1): 2.303e+01, MSE(pi2): 1.045e+00, MSE(pi3): 2.876e+00\n",
      "Epoch 520, Train loss: 1.631e+07, Test loss: 1.645e+07, MSE(e): 1.580e+00, MSE(pi1): 2.282e+01, MSE(pi2): 1.040e+00, MSE(pi3): 2.837e+00\n",
      "Epoch 530, Train loss: 1.620e+07, Test loss: 1.628e+07, MSE(e): 1.569e+00, MSE(pi1): 2.264e+01, MSE(pi2): 1.036e+00, MSE(pi3): 2.798e+00\n",
      "Epoch 540, Train loss: 1.609e+07, Test loss: 1.613e+07, MSE(e): 1.559e+00, MSE(pi1): 2.249e+01, MSE(pi2): 1.032e+00, MSE(pi3): 2.759e+00\n",
      "Epoch 550, Train loss: 1.600e+07, Test loss: 1.599e+07, MSE(e): 1.550e+00, MSE(pi1): 2.237e+01, MSE(pi2): 1.028e+00, MSE(pi3): 2.720e+00\n",
      "Epoch 560, Train loss: 1.590e+07, Test loss: 1.586e+07, MSE(e): 1.541e+00, MSE(pi1): 2.228e+01, MSE(pi2): 1.025e+00, MSE(pi3): 2.681e+00\n",
      "Epoch 570, Train loss: 1.582e+07, Test loss: 1.574e+07, MSE(e): 1.533e+00, MSE(pi1): 2.220e+01, MSE(pi2): 1.022e+00, MSE(pi3): 2.642e+00\n",
      "Epoch 580, Train loss: 1.574e+07, Test loss: 1.562e+07, MSE(e): 1.526e+00, MSE(pi1): 2.214e+01, MSE(pi2): 1.018e+00, MSE(pi3): 2.602e+00\n",
      "Epoch 590, Train loss: 1.567e+07, Test loss: 1.552e+07, MSE(e): 1.519e+00, MSE(pi1): 2.209e+01, MSE(pi2): 1.016e+00, MSE(pi3): 2.562e+00\n",
      "Epoch 600, Train loss: 1.560e+07, Test loss: 1.542e+07, MSE(e): 1.512e+00, MSE(pi1): 2.205e+01, MSE(pi2): 1.013e+00, MSE(pi3): 2.521e+00\n",
      "Epoch 610, Train loss: 1.553e+07, Test loss: 1.532e+07, MSE(e): 1.506e+00, MSE(pi1): 2.201e+01, MSE(pi2): 1.011e+00, MSE(pi3): 2.479e+00\n",
      "Epoch 620, Train loss: 1.547e+07, Test loss: 1.524e+07, MSE(e): 1.500e+00, MSE(pi1): 2.198e+01, MSE(pi2): 1.008e+00, MSE(pi3): 2.435e+00\n",
      "Epoch 630, Train loss: 1.541e+07, Test loss: 1.515e+07, MSE(e): 1.495e+00, MSE(pi1): 2.193e+01, MSE(pi2): 1.006e+00, MSE(pi3): 2.391e+00\n",
      "Epoch 640, Train loss: 1.535e+07, Test loss: 1.508e+07, MSE(e): 1.490e+00, MSE(pi1): 2.189e+01, MSE(pi2): 1.004e+00, MSE(pi3): 2.344e+00\n",
      "Epoch 650, Train loss: 1.530e+07, Test loss: 1.500e+07, MSE(e): 1.485e+00, MSE(pi1): 2.183e+01, MSE(pi2): 1.002e+00, MSE(pi3): 2.297e+00\n",
      "Epoch 660, Train loss: 1.525e+07, Test loss: 1.493e+07, MSE(e): 1.480e+00, MSE(pi1): 2.175e+01, MSE(pi2): 1.000e+00, MSE(pi3): 2.247e+00\n",
      "Epoch 670, Train loss: 1.520e+07, Test loss: 1.487e+07, MSE(e): 1.476e+00, MSE(pi1): 2.166e+01, MSE(pi2): 9.988e-01, MSE(pi3): 2.196e+00\n",
      "Epoch 680, Train loss: 1.516e+07, Test loss: 1.480e+07, MSE(e): 1.472e+00, MSE(pi1): 2.156e+01, MSE(pi2): 9.973e-01, MSE(pi3): 2.144e+00\n",
      "Epoch 690, Train loss: 1.511e+07, Test loss: 1.474e+07, MSE(e): 1.469e+00, MSE(pi1): 2.143e+01, MSE(pi2): 9.960e-01, MSE(pi3): 2.090e+00\n",
      "Epoch 700, Train loss: 1.507e+07, Test loss: 1.469e+07, MSE(e): 1.466e+00, MSE(pi1): 2.130e+01, MSE(pi2): 9.947e-01, MSE(pi3): 2.036e+00\n",
      "Epoch 710, Train loss: 1.504e+07, Test loss: 1.463e+07, MSE(e): 1.463e+00, MSE(pi1): 2.114e+01, MSE(pi2): 9.935e-01, MSE(pi3): 1.981e+00\n",
      "Epoch 720, Train loss: 1.500e+07, Test loss: 1.458e+07, MSE(e): 1.460e+00, MSE(pi1): 2.098e+01, MSE(pi2): 9.924e-01, MSE(pi3): 1.926e+00\n",
      "Epoch 730, Train loss: 1.497e+07, Test loss: 1.453e+07, MSE(e): 1.457e+00, MSE(pi1): 2.080e+01, MSE(pi2): 9.914e-01, MSE(pi3): 1.871e+00\n",
      "Epoch 740, Train loss: 1.494e+07, Test loss: 1.449e+07, MSE(e): 1.455e+00, MSE(pi1): 2.062e+01, MSE(pi2): 9.905e-01, MSE(pi3): 1.816e+00\n",
      "Epoch 750, Train loss: 1.491e+07, Test loss: 1.444e+07, MSE(e): 1.452e+00, MSE(pi1): 2.043e+01, MSE(pi2): 9.897e-01, MSE(pi3): 1.763e+00\n",
      "Epoch 760, Train loss: 1.488e+07, Test loss: 1.440e+07, MSE(e): 1.450e+00, MSE(pi1): 2.024e+01, MSE(pi2): 9.889e-01, MSE(pi3): 1.711e+00\n",
      "Epoch 770, Train loss: 1.485e+07, Test loss: 1.436e+07, MSE(e): 1.448e+00, MSE(pi1): 2.004e+01, MSE(pi2): 9.881e-01, MSE(pi3): 1.660e+00\n",
      "Epoch 780, Train loss: 1.483e+07, Test loss: 1.432e+07, MSE(e): 1.447e+00, MSE(pi1): 1.985e+01, MSE(pi2): 9.875e-01, MSE(pi3): 1.612e+00\n",
      "Epoch 790, Train loss: 1.480e+07, Test loss: 1.429e+07, MSE(e): 1.445e+00, MSE(pi1): 1.965e+01, MSE(pi2): 9.868e-01, MSE(pi3): 1.566e+00\n",
      "Epoch 800, Train loss: 1.478e+07, Test loss: 1.426e+07, MSE(e): 1.443e+00, MSE(pi1): 1.946e+01, MSE(pi2): 9.863e-01, MSE(pi3): 1.522e+00\n",
      "Epoch 810, Train loss: 1.476e+07, Test loss: 1.422e+07, MSE(e): 1.442e+00, MSE(pi1): 1.927e+01, MSE(pi2): 9.857e-01, MSE(pi3): 1.482e+00\n",
      "Epoch 820, Train loss: 1.474e+07, Test loss: 1.419e+07, MSE(e): 1.440e+00, MSE(pi1): 1.909e+01, MSE(pi2): 9.852e-01, MSE(pi3): 1.444e+00\n",
      "Epoch 830, Train loss: 1.472e+07, Test loss: 1.417e+07, MSE(e): 1.439e+00, MSE(pi1): 1.891e+01, MSE(pi2): 9.848e-01, MSE(pi3): 1.409e+00\n",
      "Epoch 840, Train loss: 1.471e+07, Test loss: 1.414e+07, MSE(e): 1.438e+00, MSE(pi1): 1.874e+01, MSE(pi2): 9.844e-01, MSE(pi3): 1.377e+00\n",
      "Epoch 850, Train loss: 1.469e+07, Test loss: 1.412e+07, MSE(e): 1.437e+00, MSE(pi1): 1.858e+01, MSE(pi2): 9.840e-01, MSE(pi3): 1.348e+00\n",
      "Epoch 860, Train loss: 1.468e+07, Test loss: 1.409e+07, MSE(e): 1.436e+00, MSE(pi1): 1.842e+01, MSE(pi2): 9.836e-01, MSE(pi3): 1.322e+00\n",
      "Epoch 870, Train loss: 1.466e+07, Test loss: 1.407e+07, MSE(e): 1.435e+00, MSE(pi1): 1.827e+01, MSE(pi2): 9.832e-01, MSE(pi3): 1.299e+00\n",
      "Epoch 880, Train loss: 1.465e+07, Test loss: 1.405e+07, MSE(e): 1.434e+00, MSE(pi1): 1.813e+01, MSE(pi2): 9.829e-01, MSE(pi3): 1.279e+00\n",
      "Epoch 890, Train loss: 1.464e+07, Test loss: 1.403e+07, MSE(e): 1.433e+00, MSE(pi1): 1.799e+01, MSE(pi2): 9.826e-01, MSE(pi3): 1.261e+00\n",
      "Epoch 900, Train loss: 1.463e+07, Test loss: 1.401e+07, MSE(e): 1.433e+00, MSE(pi1): 1.786e+01, MSE(pi2): 9.823e-01, MSE(pi3): 1.246e+00\n",
      "Epoch 910, Train loss: 1.462e+07, Test loss: 1.400e+07, MSE(e): 1.432e+00, MSE(pi1): 1.774e+01, MSE(pi2): 9.820e-01, MSE(pi3): 1.233e+00\n",
      "Epoch 920, Train loss: 1.461e+07, Test loss: 1.398e+07, MSE(e): 1.431e+00, MSE(pi1): 1.762e+01, MSE(pi2): 9.818e-01, MSE(pi3): 1.222e+00\n",
      "Epoch 930, Train loss: 1.460e+07, Test loss: 1.397e+07, MSE(e): 1.431e+00, MSE(pi1): 1.751e+01, MSE(pi2): 9.815e-01, MSE(pi3): 1.212e+00\n",
      "Epoch 940, Train loss: 1.460e+07, Test loss: 1.395e+07, MSE(e): 1.430e+00, MSE(pi1): 1.740e+01, MSE(pi2): 9.813e-01, MSE(pi3): 1.204e+00\n",
      "Epoch 950, Train loss: 1.459e+07, Test loss: 1.394e+07, MSE(e): 1.430e+00, MSE(pi1): 1.729e+01, MSE(pi2): 9.811e-01, MSE(pi3): 1.197e+00\n",
      "Epoch 960, Train loss: 1.458e+07, Test loss: 1.393e+07, MSE(e): 1.429e+00, MSE(pi1): 1.719e+01, MSE(pi2): 9.809e-01, MSE(pi3): 1.192e+00\n",
      "Epoch 970, Train loss: 1.458e+07, Test loss: 1.391e+07, MSE(e): 1.429e+00, MSE(pi1): 1.709e+01, MSE(pi2): 9.807e-01, MSE(pi3): 1.186e+00\n",
      "Epoch 980, Train loss: 1.457e+07, Test loss: 1.390e+07, MSE(e): 1.428e+00, MSE(pi1): 1.699e+01, MSE(pi2): 9.806e-01, MSE(pi3): 1.182e+00\n",
      "Epoch 990, Train loss: 1.457e+07, Test loss: 1.389e+07, MSE(e): 1.428e+00, MSE(pi1): 1.690e+01, MSE(pi2): 9.804e-01, MSE(pi3): 1.178e+00\n",
      "\n",
      "Training process finished after 1000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "# Training parameters\n",
    "start_epoch = 0\n",
    "n_epochs = 1000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8184934dd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvFUlEQVR4nO3de3QU9f3/8dcmIQkIiXILQSLEG6LxRhBJEFH4GgWrorbQH99ysUpNBflC6gXEryK1jbZI0SIoX1FKvRQVaLFQS9pyE7DVGBSNd8AgJMaAZoNIQpL5/YFEY247s7M7O7PPxzk5pxk+791X5sxpXs5MZn2GYRgCAABwSIzTAQAAQHSjjAAAAEdRRgAAgKMoIwAAwFGUEQAA4CjKCAAAcBRlBAAAOIoyAgAAHBXndIBA1NfXa9++ferUqZN8Pp/TcQAAQAAMw1BVVZV69uypmJiWz3+4oozs27dPaWlpTscAAAAW7NmzR7169Wrx311RRjp16iTp6A+TlJTkcBoAABAIv9+vtLS0ht/jLXFFGTl2aSYpKYkyAgCAy7R1iwU3sAIAAEdRRgAAgKMoIwAAwFGUEQAA4CjKCAAAcBRlBAAAOIoyAgAAHEUZAQAAjnLFQ88AAEAI1NdJn2yVDn4mdUyRemdLMbFhj2G6jGzatEm//e1vVVhYqNLSUq1atUqjRo1qdWbjxo3Ky8vTO++8o549e+qOO+5Qbm6u1cwAALjb4YPSypuk8mIp8QSp7w+k+q8lxUjpQ6ReA6XXn5BKXpXij5PO+X9Sn8FHi8Mnr0iGpJMGSZ+/K31ZIp3QR7pgkhQXH3iG4tXSy3dK/n3fbkvqKV3xoHTm1Tb/wK0zXUa++uornXvuubrhhht0/fXXt7l+165dGjlypCZNmqSnn35aW7Zs0S233KJu3boFNA8AQEQ5eEBaeoV04BPJJyklQ+o7Qtr/sfTh36Ujh6X2XaUOnaQjX0vtjpM6nyx9/YVUd1gqe1s68tV3XvATqWz7t99u/m3T93xredu51t0tZU2Rcn7Z9tri1dLz43W01XyHv/To9tHLwlpIfIZhGG0va2HY52vzzMidd96p1atX6913323YlpubqzfffFPbtm0L6H38fr+Sk5NVWVnJZ9MAAOxX87W09rajv6RrqvTtL+k4Kb6jFBsvVX8h1R9xMmVgsqe2Xkjq66T5GY3PiDTiO3qGZNqOoC/ZBPr7O+T3jGzbtk05OTmNtl1++eVasmSJjhw5onbt2jWZqa6uVnV1dcP3fr8/1DEBAF52+KC0cpL0aaF06DMTg7VSzZehShUa2x6Vhv1vy5dsPtnaShGRJEPy7z26Ln1ISCJ+X8jLSFlZmVJSUhptS0lJUW1trSoqKpSamtpkJj8/X/fdd1+oowEAvKS2RtrwW+mVuZLqnU7jHKNOeu3/pKzJzf/7wQDLWKDrbBCWv6b5/kcHH7sy1NJHCs+cOVN5eXkN3/v9fqWlpYUuIADAXSpKpIUXSPWHnU4Smb7Y3fK/dUxp+d+srLNByMtIjx49VFZW1mhbeXm54uLi1KVLl2ZnEhISlJCQEOpoAAA3qK2R1j8gbXnI6STucUKflv+td/bRe0L8pWpyA6ukhntGemeHKFxTIS8jWVlZeumllxptW7dunQYMGNDs/SIAgCh3YK/0+0zJ+NrpJO7kiz36Z74tiYk9+ue7z4/X0T8H+m4h+eaKxRUPhPV5I6bLyMGDB/XRRx81fL9r1y5t375dnTt31kknnaSZM2dq7969WrZsmaSjfzmzYMEC5eXladKkSdq2bZuWLFmi5557zr6fAgDgXgcPSI8NlQ6WOJ3EG7Imt/28kTOvPvrnu80+Z+SBsD9nxPSf9m7YsEGXXnppk+0TJkzQ0qVLNXHiRO3evVsbNmxo+LeNGzdq+vTpDQ89u/POO0099Iw/7QUAjyn7SHos0+kU3uKLPVpEAnnOyDEhfgJroL+/g3rOSLhQRgDAA8p3SQszJdU5nSSC+KTjT5LOHRf+J7CGAWUEAOA8/+fSo4Ok6gqnk4TOcSnSwJ8F/gTWuPbSif2l9KFHi4cDnwUTLhHz0DMAQBR6+1/Si9c6ncIG33sCqyEpLlFKGySdesnREhJhZyPciDICALDHl2XSw5mScdDpJBbFSO07SzdvkY7v4XSYqEIZAQAEZ/d2aelQp1ME5vhTpJv+IXXs7HQSfAdlBABgzZdl0vy+TqdoXvLJ0qR/UjpcgjICADDn02LpiSynUxzV/Wxp+D3SacM9fSOo11FGAACBiYRng/TMlsa/ICV2dDYHbEUZAQC0rnij9Hx4n8jZ4NSrpdGLpfj2zrw/woIyAgBo3sED0tz08L4nN5hGJcoIAKCp2d0lVYfv/XILpR6nhu/9EFEoIwCAb5XskJ68KPTv0y5Jmvwaz/OAJMoIAOCY2cmhf4+btkm9zgz9+8BVKCMAEO1C/byQ65ZL51wRuteH61FGACCahfJsyMSNUp/zQvf68AzKCABEo8MHpQdODM1r37aLv4aBKZQRAIg2jwyUDrxv/+veVcbzQGAJZQQAokkoLsvkfSQldbP/dRE1KCMAEC3sLiKUENiEMgIAXldfJ82x8R6O0aulM4fa93qIepQRAPCyN56VVv/cntdKOlnKK7LntYDvoIwAgFfN7iapxp7XmrGXT8pFyMQ4HQAAEAKzk2VLETnreml2JUUEIcWZEQDwGrtuVL37cyku3p7XAlpBGQEAL7GriMyutOd1gABQRgDAK+woIlN2SF1PCv51ABMoIwDgBXYUEc6GwCHcwAoAbkcRgctRRgDAzYIuIjEUETiOyzQA4FbBFpGpxVLnEH1yL2ACZQQA3CjYIsLZEEQQLtMAgNtQROAxlBEAcJM53YObp4ggAlFGAMAtviyT6qutz1NEEKEoIwDgFvP7Wp+liCCCUUYAwA2CuU+EIoIIRxkBgEhHEYHHUUYAIJJRRBAFKCMAEKkoIogSlBEAiERlH1mfpYjAZSgjABCJHsu0NndHib05gDCgjABApLF6eaZDqtTBhk/wBcKMMgIAkSSY+0TueM++HEAYUUYAIFLs3m59lvtE4GKUEQCIFEuHWpujiMDlKCMAEAmsXp6554C9OQAHUEYAwGkPZFibu+JBKSbW3iyAAygjAOCkwwelw3uszQ7KtTcL4BDKCAA46YETrc1xnwg8hDICAE6xep/IXWX25gAcRhkBACcc2GttLnWgFN/e3iyAwygjAOCER860Nndzgb05gAhAGQGAcLN6eYb7ROBRlBEACCerl2d+vMbeHEAEoYwAQDhZvTxzxkX25gAiCGUEAMLlteetzXF5Bh5HGQGAcFkzyfzMT1+xPwcQYSyVkYULFyo9PV2JiYnKzMzU5s2bW13/zDPP6Nxzz1WHDh2UmpqqG264Qfv377cUGABcyepNqyedbW8OIAKZLiPLly/XtGnTNGvWLBUVFWnIkCEaMWKESkpKml3/yiuvaPz48brxxhv1zjvv6IUXXtBrr72mm266KejwAOAKJTuszXF5BlHCdBmZN2+ebrzxRt10003q16+f5s+fr7S0NC1atKjZ9a+++qr69OmjqVOnKj09XRdddJFuvvlmvf7660GHBwBXeNLCzadjX7Y/BxChTJWRmpoaFRYWKicnp9H2nJwcbd26tdmZ7Oxsffrpp1q7dq0Mw9Bnn32mF198UVdeeWWL71NdXS2/39/oCwBcaeNCa3OnZ9mbA4hgpspIRUWF6urqlJKS0mh7SkqKysqa/6yE7OxsPfPMMxozZozi4+PVo0cPHX/88fr973/f4vvk5+crOTm54SstLc1MTACIHOtnmp/h8gyijKUbWH0+X6PvDcNosu2Y4uJiTZ06Vffcc48KCwv18ssva9euXcrNbfmjr2fOnKnKysqGrz17LH68NgA4ycpNq1f+n/05gAgXZ2Zx165dFRsb2+QsSHl5eZOzJcfk5+dr8ODBuv322yVJ55xzjo477jgNGTJE999/v1JTU5vMJCQkKCEhwUw0AIgsFc3f1N+mC0bbmwNwAVNnRuLj45WZmamCgsYf1FRQUKDs7OxmZw4dOqSYmMZvExsbK+noGRUA8KQFFv4kd+JG+3MALmD6Mk1eXp6eeOIJPfnkk3r33Xc1ffp0lZSUNFx2mTlzpsaPH9+w/qqrrtLKlSu1aNEi7dy5U1u2bNHUqVM1cOBA9ezZ076fBAAixc5Ca3N9zrM1BuAWpi7TSNKYMWO0f/9+zZkzR6WlpcrIyNDatWvVu3dvSVJpaWmjZ45MnDhRVVVVWrBggX7xi1/o+OOP17Bhw/Tggw/a91MAQCRZNsz8DDetIor5DBdcK/H7/UpOTlZlZaWSkpKcjgMALdtRIK34obmZHyyRBpicAVwg0N/ffDYNANjJbBGRKCKIepQRALCLlT/lvfoP9ucAXIYyAgB28H9uba7/KFtjAG5EGQEAO8w71fzM1GL7cwAuRBkBgGDt3m5trvOJtsYA3IoyAgDBWjrU/Mxtu+zPAbgUZQQAglGyw8JQnNSxs+1RALeijABAMJ68yPzM7P325wBcjDICAFZ99B/zM0N/aX8OwOUoIwBg1dOXmZ+5dKr9OQCXo4wAgBU7Ctpe830jFtmfA/AAyggAWGHlse8XjrU/B+ABlBEAMKtotfmZYXxSOdASyggAmPWXceZnLs61PwfgEZQRADDDytNWr1tuewzASygjAGCGlaetnnOF/TkAD6GMAECgdhaan7nmj/bnADyGMgIAgVo2zPzM+VfbnwPwGMoIAATiwF7zMxffZ38OwIMoIwAQiEfOND8zbJrtMQAvoowAQFsOHjA/c9VT9ucAPIoyAgBtmXua+ZnM6+zPAXgUZQQA2lRrbvmQe0MTA/AoyggAtOaFW8zPDM+zPwfgYZQRAGjNO8+YW5/zcGhyAB5GGQGAlhT8xvxM9kTbYwBeRxkBgJZs+ZXJgRNCEgPwOsoIADRn2zLzMzPetj8HEAUoIwDQnL/fan4msaP9OYAoQBkBgO8r+8j8zE3b7M8BRAnKCAB832OZ5md6WXhcPABJlBEAaKzma/MzEzfanwOIIpQRAPiuBwebn+lznu0xgGhCGQGA76r72Nx6Hv0OBI0yAgDHbF1qfoZHvwNBo4wAwDHr/sfc+qG/DE0OIMpQRgBAkl592vzMpVPtzwFEIcoIAEjSy5OdTgBELcoIABzYa35m2vv25wCiFGUEAB6x8MCy43vYnwOIUpQRADDrqqecTgB4CmUEQHT713zzM5nX2R4DiGaUEQDRbZPJh5YNezA0OYAoRhkBEL1ee978zMW59ucAohxlBED0WjPJ5EB8SGIA0Y4yAiA6HTxgfiav2P4cACgjAKLU3HTzM0nd7M8BgDICAAG5/PdOJwA8izICIPpY+XTerPG2xwBwFGUEQPTh03mBiEIZARBdPthmfoZP5wVCijICILo8e4XTCQB8D2UEAFqTW+h0AsDzKCMAose6B8zP9DjV/hwAGqGMAIgeW/PNrb/kV6HJAaARygiA6FC80fzMJVPszwGgCUtlZOHChUpPT1diYqIyMzO1efPmVtdXV1dr1qxZ6t27txISEnTKKafoySeftBQYACx5/mqnEwBoQZzZgeXLl2vatGlauHChBg8erMcff1wjRoxQcXGxTjrppGZnRo8erc8++0xLlizRqaeeqvLyctXW1gYdHgBCZqKFMykALPEZhmGYGbjwwgvVv39/LVq0qGFbv379NGrUKOXnN70e+/LLL+vHP/6xdu7cqc6dO1sK6ff7lZycrMrKSiUlJVl6DQBRbMVUaccfzM3MrgxNFiCKBPr729RlmpqaGhUWFionJ6fR9pycHG3durXZmdWrV2vAgAH6zW9+oxNPPFGnn366brvtNn399ddm3hoArDNbRK56KjQ5ADTL1GWaiooK1dXVKSUlpdH2lJQUlZWVNTuzc+dOvfLKK0pMTNSqVatUUVGhW265RQcOHGjxvpHq6mpVV1c3fO/3+83EBIBvvfeK+ZnM6+zPAaBFlm5g9fl8jb43DKPJtmPq6+vl8/n0zDPPaODAgRo5cqTmzZunpUuXtnh2JD8/X8nJyQ1faWlpVmICgPSnK82t96W0vQaArUyVka5duyo2NrbJWZDy8vImZ0uOSU1N1Yknnqjk5OSGbf369ZNhGPr000+bnZk5c6YqKysbvvbs2WMmJgBYd/trTicAoo6pMhIfH6/MzEwVFBQ02l5QUKDs7OxmZwYPHqx9+/bp4MGDDds++OADxcTEqFevXs3OJCQkKCkpqdEXAJj217vNz3RIbnsNAFuZvkyTl5enJ554Qk8++aTeffddTZ8+XSUlJcrNzZV09KzG+PHjG9aPHTtWXbp00Q033KDi4mJt2rRJt99+u37605+qffv29v0kAPB9r//e3PorHg1NDgCtMv2ckTFjxmj//v2aM2eOSktLlZGRobVr16p3796SpNLSUpWUlDSs79ixowoKCnTrrbdqwIAB6tKli0aPHq3777/fvp8CAL5vR0Hba75v0E/szwGgTaafM+IEnjMCwLTZFi638GwRwFYhec4IAHjWTducTgBELcoIAO8p+I35mV5n2p8DQEAoIwC8Z8uvzK3nxlXAUZQRAN7yZfNPg24VN64CjqKMAPCW+X2dTgDAJMoIgOh2y3anEwBRjzICwDtee978TPd0+3MAMIUyAsA71kwyt/48k+sBhARlBIA3HDxgfmbUXPtzADCNMgLAG+ZyuQVwK8oIgOg09mWnEwD4BmUEgPu98WfzM6dn2R4DgDWUEQDut3qCufXn3BCaHAAsoYwAiD7XzXc6AYDvoIwAcLeV05xOACBIlBEA7vbWU+bWX/tcaHIAsIwyAsC9dm83P3PuSNtjAAgOZQSAey0d6nQCADagjACIHrmFTicA0AzKCAB3Wj3D/EyPU+3PASBolBEA7vTGInPrB88KTQ4AQaOMAHCfA3vNz1x2h/05ANiCMgLAfR450+kEAGxEGQHgfT9c5XQCAK2gjABwl/WPmJ/JGGZ/DgC2oYwAcJeN/2tuPR+KB0Q8yggAb+ND8YCIRxkB4B4rpjqdAEAIUEYAuMeOP5hbP/Lx0OQAYCvKCAB3+Og/5mcG/tj+HABsRxkB4A5PX2ZywBeSGADsRxkB4E15HzqdAECAKCMAIt/f5pifSepmfw4AIUEZARD5/v2QufXZM0OTA0BIUEYARLaDB8zP5MywPweAkKGMAIhsc093OgGAEKOMAIhwR8wtv+aPoYkBIGQoIwAi12vPm585/2r7cwAIKcoIgMi1ZpK59ZmTQ5MDQEhRRgB4x1W/djoBAAsoIwAi0wu3OJ0AQJhQRgBEpneeMbd++G9DkwNAyFFGAEQeKzeuDvmZ/TkAhAVlBEDkMXvjKgBXo4wAcL+8j5xOACAIlBEAkWW1hUe586F4gKtRRgBEljcWmVt//s2hyQEgbCgjACJHmYXLLdf8xv4cAMKKMgIgcjyW6XQCAA6gjABwr58UOJ0AgA0oIwAiw1/vNj9z6kD7cwAIO8oIgMjw+u/NrT/3xtDkABB2lBEAzvN/bn7m2nn25wDgCMoIAOfNO9XpBAAcRBkB4D7Xv+h0AgA2oowAcFaBheeEnH2Z/TkAOIYyAsBZW35lbv1p14UmBwDHWCojCxcuVHp6uhITE5WZmanNmzcHNLdlyxbFxcXpvPPOs/K2ACD991NOJwBgM9NlZPny5Zo2bZpmzZqloqIiDRkyRCNGjFBJSUmrc5WVlRo/fryGDx9uOSwAj3n8R04nABABTJeRefPm6cYbb9RNN92kfv36af78+UpLS9OiRa1/uNXNN9+ssWPHKisry3JYAB5Tus7c+hEmP0QPgCuYKiM1NTUqLCxUTk5Oo+05OTnaunVri3NPPfWUPv74Y917770BvU91dbX8fn+jLwAe86/55mcuHGt7DADOM1VGKioqVFdXp5SUlEbbU1JSVFZW1uzMhx9+qBkzZuiZZ55RXFxcQO+Tn5+v5OTkhq+0tDQzMQG4wabA/uOkQWpO22sAuJKlG1h9Pl+j7w3DaLJNkurq6jR27Fjdd999Ov300wN+/ZkzZ6qysrLha8+ePVZiAohU9XXmZ25+wf4cACJCYKcqvtG1a1fFxsY2OQtSXl7e5GyJJFVVVen1119XUVGRpkyZIkmqr6+XYRiKi4vTunXrNGzYsCZzCQkJSkhIMBMNgJvMucDpBAAiiKkzI/Hx8crMzFRBQeOP7S4oKFB2dnaT9UlJSdqxY4e2b9/e8JWbm6u+fftq+/btuvDCC4NLD8ClPja3fNDtoYkBICKYOjMiSXl5eRo3bpwGDBigrKwsLV68WCUlJcrNzZV09BLL3r17tWzZMsXExCgjI6PRfPfu3ZWYmNhkO4AosXmx+Zkr7rY/B4CIYbqMjBkzRvv379ecOXNUWlqqjIwMrV27Vr1795YklZaWtvnMEQBR7J8mz3L04NHvgNf5DMMwnA7RFr/fr+TkZFVWViopKcnpOACs+rJMmt/X3MzsytBkARBygf7+5rNpAISP2SICICpQRgBErpyHnU4AIAwoIwDCY8VU8zPZE22PASDyUEYAhMeOP5hb33loaHIAiDiUEQChV7Ta/MxUCzMAXIkyAiD0/jLO6QQAIhhlBEDk+cESpxMACCPKCIDQWvoT8zMDfmh/DgARy/QTWAHAlN0vmVt/9oTQ5ACaUVdvaNN75fptwXvaXXFItfWGEuN8Or59vLp0StBJnTvouvN6KSbWp1d37de+L75Wz+PbK/uUrurf+wT9ceturSsuk7/6iPqmdNJZqcmqqqmVT1LWyV016JQuio1p+qn2aIwnsAIInX/OkzbfZ26GJ656TuWhI/rJE1u1Y9/BoF8rRlJ9G2tiJdV987/jY6QeSYnK6JWk2JhYfV51WHsOHFJdvRQXK336ZXXQmVpzfId2euC6s3VFRmpI3ydSBfr7mzMjAELHbBFByLz82l7lrtjudIygtVVEpG+LiCTV1EslXx5WyZeHQxWpVV8eOqLcp9/QYz/pH7WFJBCUEQChsXu7+ZmpxbbHiGTFn/o1csFmp2MgDGavfkeXndmDSzYtoIwACI2lFh5a1vlE+3PYIHfJ3/Tyh4H8NznQvDJ/tf6z64CyTunidJSIRBkBEBkutu+SzoAZa1Rh26sB9iivcuZSkRtQRgDY75cWzooMm6bhM9boY/vTABGhe6dEpyNELMoIANv0mbFGkvRxu+2KjQ1sxjCkX1YP1JPfzAJe1CMpQQPTOzsdI2JRRgA0MmTGGu0JYj5HLyrGxOMUDUN6UtOCeEcg8s2++ixuXm0FZQTwqMKdX+j6xVvD/r6L2q2Uz8T/59ZG/JOOAOui/TkjgaKMAC7RxwWXMc7TdtNnRS45Mjd0gQAL2sf51K1jAk9gDSOewAo45NZl/9BLxaF9+mO4fdxubMD3ikhSXZ10ypFnQxcInmPnE1i7dGynk7sep9iYWJ14Qntln9pVg06mPNiJJ7ACDpj2zHr9ecchp2M4xszlGcOQ/ufID0IXBhGpzwmJWjl5iDp3jHc6CiIIZQQIgBsukTjtAd1iqozU10t/1djQBUKLfn5xqm674nzOACBiUEYQ1cbMXaN/83QsW/yo3ZcBlxHDkBYc6RvaQC50y0WpuuMH/Z2OAYQdZQSexdmM8Pm5HjR142p9vfQ73Ru6QCGUc4q0eNKVTscAPIUyAle6cvYavcOTlSPGbe3eNHVWZOWRDqEN9D3r8y5RevfjwvqeAAJHGUFE4qyGe9ygh03/Oe/teiKgtTOG91HuZWdZTAbALSgjcARlwzvubvdvUzeuxsRIux/gMgeAb1FGEBLnzlijSqdDwBZnd5BeuqeF8vD3X0vbTL7g6NVBZwLgLZQRWFL8qV8jF2x2OgZMsv2MxLYHzc+caeETfQF4GmUELVr8j2L9+h+7nI6BVjh6uWPjQvMz/X9ufw4ArkcZiXLrXt+nn71Y5HQMfMNV91Ksn2l+5uoH7M8BwPUoI1GCh3s5x1UFI1AVJeZnTrvO/hwAPIEy4iF/2vyxZqx5z+kYUaGzpDe8WDICteBs8zP//ZT9OQB4AmXEhW5bvlkvFvmdjuFZnjyTYaeyj8zPdBtmfw4AnkEZiWBP/PNd3V+w0+kYnhEr6WOKRvAeyzQ/M3mV/TkAeAZlJAL89d97NGXVW07HcD3OaEQqPhAPQOsoI2H0/r4qXf7IJqdjuNKcK07T+EtOdzoGZg+0MPMf+3MA8BTKSAhUHjqiMYs2673Pv3Y6imss/uH5yhnQ0+kYaNP7JtenhiQFAG+hjASp7MvDypn3T/lrnE4S2a4+K1GPjBvudAwEY/Y5Fmb46y4AbaOMBKiu3tCm98r1wN+K9cHnh2Q4HSgCcc+G131icn2vkKQA4D2UkWbU1NbrqS27tO6dMu378it95j+ieqdDRYCukl6ncESn2ckWZt6xPwcAT6KMfEddvaGpz76hNW+XOR3FMSdK2kLhwHfVcg0SQGhRRr7x8tulmvJskWrro+MCzD+mDdWpPTo6HQNucH838zN3RW+hB2AeZURHi0ju0284HcN2N2V1193XXOB0DLhZucVPbY5vb28OAJ4W9WWkrt7QvX9x97XtFT/LVubJJzgdA1608DzzM3d/bnsMAN4W9WXkP7sO6LOqaqdjtMkn6ZU7hunEzvwXJ8KkcKW1ubh4e3MA8LyoLyPlVYedjtDICYkxWpc3TN2SEpyOgmj30g3mZ2ZX2p8DgOdFfRnp3inRkfc9PsGngl8Mp3QgMm1YYGHoFNtjAIgOUV9GBqZ3VkqnhJBeqlk7ZYjO7JUUstcHbLdhlvmZ2d67CRxAeER9GYmN8em+a86y5a9pBp2crCfGD1LHxKjfrXCz5260MMQn8wKwjt+akq7ISNVjP+mvvOff1KGauib/7pMaHv8e55N6d+2gF24erM4duVEPHvT+i+Zn+GReAEGgjHzjioxUXXZmD239qEIr3vhUh2pqdUGfLpqQ3UfxcTFOxwPC44H/sjDU2/YYAKILZeQ7YmN8GnJ6Nw053cITJwEvOPya+ZnZb9mfA0BU4T/5ARxl5cPw4jPtzwEg6lBGAEgVJdbm7vqXvTkARCXKCABpwdnmZ/pcZX8OAFHJUhlZuHCh0tPTlZiYqMzMTG3evLnFtStXrtRll12mbt26KSkpSVlZWfr73/9uOTAAm62dbW1u4tO2xgAQvUyXkeXLl2vatGmaNWuWioqKNGTIEI0YMUIlJc2f5t20aZMuu+wyrV27VoWFhbr00kt11VVXqaioKOjwAGzwn9+Zn8l52P4cAKKWzzAMo+1l37rwwgvVv39/LVq0qGFbv379NGrUKOXn5wf0GmeddZbGjBmje+65J6D1fr9fycnJqqysVFISTzIFbGPlplWJz6ABEJBAf3+bOjNSU1OjwsJC5eTkNNqek5OjrVu3BvQa9fX1qqqqUufOnVtcU11dLb/f3+gLgM1qvrY2RxEBYDNTZaSiokJ1dXVKSUlptD0lJUVlZWUBvcZDDz2kr776SqNHj25xTX5+vpKTkxu+0tLSzMQEEIhf9zA/4zvH/hwAop6lG1h9Pl+j7w3DaLKtOc8995xmz56t5cuXq3v37i2umzlzpiorKxu+9uzZYyUmgJY8eq21uXtbvlkdAKwy9QTWrl27KjY2tslZkPLy8iZnS75v+fLluvHGG/XCCy/ov/6r9UdOJyQkKCEhwUw0AGZ8buH5IEPutT8HAMjkmZH4+HhlZmaqoKCg0faCggJlZ2e3OPfcc89p4sSJevbZZ3XllVdaSwrAHlZvWh2eZ28OAPiG6c+mycvL07hx4zRgwABlZWVp8eLFKikpUW5urqSjl1j27t2rZcuWSTpaRMaPH6+HH35YgwYNajir0r59eyUnW/w/RQDW/HOetTluWgUQQqbLyJgxY7R//37NmTNHpaWlysjI0Nq1a9W799FP7iwtLW30zJHHH39ctbW1mjx5siZPntywfcKECVq6dGnwPwGAwG2+z8JQhu0xAOC7TD9nxAk8ZwSwAc8UARBmIXnOCACXKlptbe6qp+zNAQDNoIwA0eAv46zNZV5nbw4AaAZlBPA6Ls8AiHCUEcDLrH4ib9adtsYAgNZQRgAvs/KJvJJ0+V325gCAVlBGAK/i8gwAl6CMAF5ktYice6O9OQAgAJQRwGt2FLS9piXXWnxCKwAEgTICeM2KH1qb4/IMAIdQRgAvsXp55pJf2ZsDAEygjABeYbWISNIlU+zLAQAmUUYAL3jlCeuzXJ4B4DDKCOAF//iFtTmKCIAIQBkB3M7q5Zn0q+3NAQAWUUYANwvmPpEJf7QvBwAEgTICuFUwRYTLMwAiCGUEcCOKCAAPoYwAbhNMERm92r4cAGATygjgJrNTgps/c6g9OQDARpQRwC0OHpB02Po8l2cARCjKCOAWc9Otz1JEAEQwygjgBtywCsDDKCNAJCvfRREB4HlxTgcA0IJgSohEEQHgGpwZASIRRQRAFKGMAJEm2CLys//YkwMAwoQyAkSSYIuIJPXsG/xrAEAYUUaASGFHEeHyDAAXoowATtuwgCICIKrx1zSAk+woIRJFBICrcWYEcApFBAAkUUaA8FuVZ08RaZdMEQHgCVymAcLJrrMht+2SOna257UAwGGUESAcHhohVW2157U4GwLAYygjQKjZdTZEoogA8CTKCBAqdpYQiSICwLMoI4DdHv+RVLrO3tekiADwMMoIYJedhdKyYfa/LkUEgMdRRgA72H1JRpIGTpdGzrb/dQEgwlBGAKsOHpDmpofmtTkbAiCKUEYAs/42R/r3Q6F7fYoIgChDGQECFYpLMd91zg3SdfND+x4AEIEoI0BbQl1CJM6GAIhqlBGgOeEoIJKUMECa+c/wvBcARCjKCHBMuApIw/txNgQAJMoIol24C4gknfEj6cdPhP99ASBCUUYQXSpKpAVnO/f+nA0BgCYoI/A+J85+NMlACQGAllBG4C0rpko7/uB0im9RQgCgTZQRuNdLd0mFjzqdonm37ZI6dnY6BQC4AmUE7hAJl1oCwZkQADCNMoLIcPig9MCJTqewjhICAJZRRhAebjmzYRYlBACCRhmBeU/9t/TJX51O4ZypxVJnF5/FAYAIQxmJBv83Rtr7stMpXC5Nmv220yEAwJOit4zU10nvr5M2/Fra/5FUe8jpRIhEXIYBgJCLsTK0cOFCpaenKzExUZmZmdq8eXOr6zdu3KjMzEwlJibq5JNP1mOPPWYprG2KV0v3d5eW/1j67C2KCL6jx9ECcuwLABByps+MLF++XNOmTdPChQs1ePBgPf744xoxYoSKi4t10kknNVm/a9cujRw5UpMmTdLTTz+tLVu26JZbblG3bt10/fXX2/JDmFK8Wnp+XPjfF5GL0gEAjvIZhmGYGbjwwgvVv39/LVq0qGFbv379NGrUKOXn5zdZf+edd2r16tV69913G7bl5ubqzTff1LZt2wJ6T7/fr+TkZFVWViopKclM3Mbq66S5Z0iHyq2/Btzvkl9Jl0xxOgUAeF6gv79NnRmpqalRYWGhZsyY0Wh7Tk6Otm7d2uzMtm3blJOT02jb5ZdfriVLlujIkSNq166dmQjB+WQrRSQaceYDACKaqTJSUVGhuro6paSkNNqekpKisrKyZmfKysqaXV9bW6uKigqlpqY2mamurlZ1dXXD936/30zMlh38zJ7XQeSieACA61j6axqfz9foe8Mwmmxra31z24/Jz8/XfffdZyVa6zqmtL0G7sCzPgDAM0yVka5duyo2NrbJWZDy8vImZz+O6dGjR7Pr4+Li1KVLl2ZnZs6cqby8vIbv/X6/0tLSzERtXu9sqUN3LtW4BWc5ACAqmCoj8fHxyszMVEFBga699tqG7QUFBbrmmmuancnKytJLL73UaNu6des0YMCAFu8XSUhIUEJCgplogYmJlX7wEH9NEwnyPpKSujmdAgAQAUxfpsnLy9O4ceM0YMAAZWVlafHixSopKVFubq6ko2c19u7dq2XLlkk6+pczCxYsUF5eniZNmqRt27ZpyZIleu655+z9SQJ15tXS6D9KL94g1dc6k8FzEqXZ3I8DALDGdBkZM2aM9u/frzlz5qi0tFQZGRlau3atevfuLUkqLS1VSUlJw/r09HStXbtW06dP16OPPqqePXvqkUceceYZI8ecebV0d3kUP4E1Q5q9xekQAABIsvCcESfY9pwRAAAQNoH+/rb0OHgAAAC7UEYAAICjKCMAAMBRlBEAAOAoyggAAHAUZQQAADiKMgIAABxFGQEAAI6ijAAAAEeZfhy8E449JNbv9zucBAAABOrY7+22HvbuijJSVVUlSUpLS3M4CQAAMKuqqkrJyckt/rsrPpumvr5e+/btU6dOneTz+Wx7Xb/fr7S0NO3Zs4fPvLGA/Rc89mHw2IfBYx8Gj33YPMMwVFVVpZ49eyompuU7Q1xxZiQmJka9evUK2esnJSVx8ASB/Rc89mHw2IfBYx8Gj33YVGtnRI7hBlYAAOAoyggAAHBUVJeRhIQE3XvvvUpISHA6iiux/4LHPgwe+zB47MPgsQ+D44obWAEAgHdF9ZkRAADgPMoIAABwFGUEAAA4ijICAAAc5ekysnDhQqWnpysxMVGZmZnavHlzq+s3btyozMxMJSYm6uSTT9Zjjz0WpqSRy8w+3LBhg3w+X5Ov9957L4yJI8umTZt01VVXqWfPnvL5fPrzn//c5gzH4bfM7j+Owaby8/N1wQUXqFOnTurevbtGjRql999/v805jsNvWdmHHIvmeLaMLF++XNOmTdOsWbNUVFSkIUOGaMSIESopKWl2/a5duzRy5EgNGTJERUVFuuuuuzR16lStWLEizMkjh9l9eMz777+v0tLShq/TTjstTIkjz1dffaVzzz1XCxYsCGg9x2FjZvffMRyD39q4caMmT56sV199VQUFBaqtrVVOTo6++uqrFmc4Dhuzsg+P4VgMkOFRAwcONHJzcxttO+OMM4wZM2Y0u/6OO+4wzjjjjEbbbr75ZmPQoEEhyxjpzO7D9evXG5KML774Igzp3EeSsWrVqlbXcBy2LJD9xzHYtvLyckOSsXHjxhbXcBy2LpB9yLFojifPjNTU1KiwsFA5OTmNtufk5Gjr1q3Nzmzbtq3J+ssvv1yvv/66jhw5ErKskcrKPjzm/PPPV2pqqoYPH67169eHMqbncBzag2OwZZWVlZKkzp07t7iG47B1gezDYzgWA+PJMlJRUaG6ujqlpKQ02p6SkqKysrJmZ8rKyppdX1tbq4qKipBljVRW9mFqaqoWL16sFStWaOXKlerbt6+GDx+uTZs2hSOyJ3AcBodjsHWGYSgvL08XXXSRMjIyWlzHcdiyQPchx6I5rvjUXqt8Pl+j7w3DaLKtrfXNbY8mZvZh37591bdv34bvs7KytGfPHs2dO1cXX3xxSHN6CcehdRyDrZsyZYreeustvfLKK22u5ThsXqD7kGPRHE+eGenatatiY2Ob/Bd8eXl5k7Z/TI8ePZpdHxcXpy5duoQsa6Sysg+bM2jQIH344Yd2x/MsjkP7cQwedeutt2r16tVav369evXq1epajsPmmdmHzeFYbJkny0h8fLwyMzNVUFDQaHtBQYGys7ObncnKymqyft26dRowYIDatWsXsqyRyso+bE5RUZFSU1PtjudZHIf2i/Zj0DAMTZkyRStXrtS//vUvpaentznDcdiYlX3YnGg/Flvl2K2zIfanP/3JaNeunbFkyRKjuLjYmDZtmnHccccZu3fvNgzDMGbMmGGMGzeuYf3OnTuNDh06GNOnTzeKi4uNJUuWGO3atTNefPFFp34Ex5ndh7/73e+MVatWGR988IHx9ttvGzNmzDAkGStWrHDqR3BcVVWVUVRUZBQVFRmSjHnz5hlFRUXGJ598YhgGx2FbzO4/jsGmfv7znxvJycnGhg0bjNLS0oavQ4cONazhOGydlX3IsWiOZ8uIYRjGo48+avTu3duIj483+vfv3+jPsCZMmGAMHTq00foNGzYY559/vhEfH2/06dPHWLRoUZgTRx4z+/DBBx80TjnlFCMxMdE44YQTjIsuushYs2aNA6kjx7E/7/v+14QJEwzD4Dhsi9n9xzHYVHP7T5Lx1FNPNazhOGydlX3IsWiOzzC+uSsJAADAAZ68ZwQAALgHZQQAADiKMgIAABxFGQEAAI6ijAAAAEdRRgAAgKMoIwAAwFGUEQAA4CjKCAAAcBRlBAAAOIoyAgAAHEUZAQAAjvr/NEzxz6ak/44AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Mx(My(TensOps(model(X_train)[0], space_dimension=2, contravariance=0, covariance=0))).values.cpu().detach().numpy().flatten(), \n",
    "            model(X_train)[1].cpu().detach().numpy().flatten())\n",
    "\n",
    "plt.scatter(y_train.values.cpu().detach().numpy().flatten(), \n",
    "           K_train.values.cpu().detach().numpy().flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
