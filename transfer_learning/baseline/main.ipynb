{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Own library imports\n",
    "from vecopsciml.utils import TensOps\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "\n",
    "# Function from this project\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "# Import model\n",
    "from architectures.pgnniv_baseline import PGNNIVBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_100\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_100/baseline\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear/sigmoid_nonlinear.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_100')\n",
    "\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_100/baseline')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_TRANSFERLEARNING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear/sigmoid_nonlinear.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 80\n",
      "Validation dataset length: 20\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X_train, y_train, K_train, f_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 1.740e+09, Test loss: 2.120e+09, MSE(e): 1.121e+02, MSE(pi1): 6.094e+04, MSE(pi2): 4.978e+01, MSE(pi3): 9.685e+01\n",
      "Epoch 100, Train loss: 8.399e+08, Test loss: 1.162e+09, MSE(e): 7.545e+01, MSE(pi1): 8.246e+03, MSE(pi2): 3.099e+01, MSE(pi3): 2.965e+01\n",
      "Epoch 200, Train loss: 5.028e+08, Test loss: 7.448e+08, MSE(e): 4.686e+01, MSE(pi1): 3.206e+03, MSE(pi2): 1.825e+01, MSE(pi3): 2.100e+01\n",
      "Epoch 300, Train loss: 2.952e+08, Test loss: 4.597e+08, MSE(e): 2.759e+01, MSE(pi1): 1.770e+03, MSE(pi2): 1.065e+01, MSE(pi3): 1.580e+01\n",
      "Epoch 400, Train loss: 1.812e+08, Test loss: 2.809e+08, MSE(e): 1.712e+01, MSE(pi1): 9.015e+02, MSE(pi2): 6.953e+00, MSE(pi3): 1.014e+01\n",
      "Epoch 500, Train loss: 1.357e+08, Test loss: 1.937e+08, MSE(e): 1.312e+01, MSE(pi1): 3.865e+02, MSE(pi2): 5.642e+00, MSE(pi3): 6.456e+00\n",
      "Epoch 600, Train loss: 1.207e+08, Test loss: 1.587e+08, MSE(e): 1.187e+01, MSE(pi1): 1.548e+02, MSE(pi2): 5.225e+00, MSE(pi3): 4.971e+00\n",
      "Epoch 700, Train loss: 1.151e+08, Test loss: 1.445e+08, MSE(e): 1.140e+01, MSE(pi1): 6.438e+01, MSE(pi2): 5.056e+00, MSE(pi3): 4.441e+00\n",
      "Epoch 800, Train loss: 1.120e+08, Test loss: 1.374e+08, MSE(e): 1.113e+01, MSE(pi1): 3.213e+01, MSE(pi2): 4.952e+00, MSE(pi3): 4.226e+00\n",
      "Epoch 900, Train loss: 1.091e+08, Test loss: 1.318e+08, MSE(e): 1.085e+01, MSE(pi1): 2.274e+01, MSE(pi2): 4.841e+00, MSE(pi3): 4.129e+00\n",
      "Epoch 1000, Train loss: 1.045e+08, Test loss: 1.244e+08, MSE(e): 1.039e+01, MSE(pi1): 2.486e+01, MSE(pi2): 4.658e+00, MSE(pi3): 4.080e+00\n",
      "Epoch 1100, Train loss: 9.649e+07, Test loss: 1.118e+08, MSE(e): 9.567e+00, MSE(pi1): 4.141e+01, MSE(pi2): 4.328e+00, MSE(pi3): 4.073e+00\n",
      "Epoch 1200, Train loss: 8.419e+07, Test loss: 9.335e+07, MSE(e): 8.290e+00, MSE(pi1): 8.761e+01, MSE(pi2): 3.814e+00, MSE(pi3): 4.101e+00\n",
      "Epoch 1300, Train loss: 6.938e+07, Test loss: 7.130e+07, MSE(e): 6.727e+00, MSE(pi1): 1.693e+02, MSE(pi2): 3.181e+00, MSE(pi3): 4.175e+00\n",
      "Epoch 1400, Train loss: 5.788e+07, Test loss: 5.444e+07, MSE(e): 5.528e+00, MSE(pi1): 2.175e+02, MSE(pi2): 2.687e+00, MSE(pi3): 4.247e+00\n",
      "Epoch 1500, Train loss: 5.112e+07, Test loss: 4.619e+07, MSE(e): 4.867e+00, MSE(pi1): 2.032e+02, MSE(pi2): 2.410e+00, MSE(pi3): 4.199e+00\n",
      "Epoch 1600, Train loss: 4.625e+07, Test loss: 4.149e+07, MSE(e): 4.411e+00, MSE(pi1): 1.723e+02, MSE(pi2): 2.220e+00, MSE(pi3): 4.097e+00\n",
      "Epoch 1700, Train loss: 4.234e+07, Test loss: 3.758e+07, MSE(e): 4.044e+00, MSE(pi1): 1.495e+02, MSE(pi2): 2.069e+00, MSE(pi3): 4.011e+00\n",
      "Epoch 1800, Train loss: 3.911e+07, Test loss: 3.404e+07, MSE(e): 3.739e+00, MSE(pi1): 1.322e+02, MSE(pi2): 1.945e+00, MSE(pi3): 3.937e+00\n",
      "Epoch 1900, Train loss: 3.652e+07, Test loss: 3.133e+07, MSE(e): 3.495e+00, MSE(pi1): 1.183e+02, MSE(pi2): 1.845e+00, MSE(pi3): 3.868e+00\n",
      "Epoch 2000, Train loss: 3.440e+07, Test loss: 2.938e+07, MSE(e): 3.296e+00, MSE(pi1): 1.063e+02, MSE(pi2): 1.764e+00, MSE(pi3): 3.800e+00\n",
      "Epoch 2100, Train loss: 3.259e+07, Test loss: 2.786e+07, MSE(e): 3.126e+00, MSE(pi1): 9.602e+01, MSE(pi2): 1.695e+00, MSE(pi3): 3.732e+00\n",
      "Epoch 2200, Train loss: 3.102e+07, Test loss: 2.660e+07, MSE(e): 2.978e+00, MSE(pi1): 8.715e+01, MSE(pi2): 1.635e+00, MSE(pi3): 3.667e+00\n",
      "Epoch 2300, Train loss: 2.963e+07, Test loss: 2.552e+07, MSE(e): 2.847e+00, MSE(pi1): 7.948e+01, MSE(pi2): 1.583e+00, MSE(pi3): 3.603e+00\n",
      "Epoch 2400, Train loss: 2.840e+07, Test loss: 2.459e+07, MSE(e): 2.731e+00, MSE(pi1): 7.279e+01, MSE(pi2): 1.537e+00, MSE(pi3): 3.541e+00\n",
      "Epoch 2500, Train loss: 2.729e+07, Test loss: 2.377e+07, MSE(e): 2.628e+00, MSE(pi1): 6.688e+01, MSE(pi2): 1.496e+00, MSE(pi3): 3.479e+00\n",
      "Epoch 2600, Train loss: 2.630e+07, Test loss: 2.303e+07, MSE(e): 2.534e+00, MSE(pi1): 6.163e+01, MSE(pi2): 1.459e+00, MSE(pi3): 3.417e+00\n",
      "Epoch 2700, Train loss: 2.540e+07, Test loss: 2.236e+07, MSE(e): 2.449e+00, MSE(pi1): 5.696e+01, MSE(pi2): 1.425e+00, MSE(pi3): 3.357e+00\n",
      "Epoch 2800, Train loss: 2.457e+07, Test loss: 2.173e+07, MSE(e): 2.371e+00, MSE(pi1): 5.280e+01, MSE(pi2): 1.394e+00, MSE(pi3): 3.297e+00\n",
      "Epoch 2900, Train loss: 2.381e+07, Test loss: 2.116e+07, MSE(e): 2.299e+00, MSE(pi1): 4.911e+01, MSE(pi2): 1.366e+00, MSE(pi3): 3.238e+00\n",
      "Epoch 3000, Train loss: 2.311e+07, Test loss: 2.066e+07, MSE(e): 2.233e+00, MSE(pi1): 4.582e+01, MSE(pi2): 1.340e+00, MSE(pi3): 3.181e+00\n",
      "Epoch 3100, Train loss: 2.248e+07, Test loss: 2.024e+07, MSE(e): 2.173e+00, MSE(pi1): 4.288e+01, MSE(pi2): 1.317e+00, MSE(pi3): 3.125e+00\n",
      "Epoch 3200, Train loss: 2.190e+07, Test loss: 1.989e+07, MSE(e): 2.119e+00, MSE(pi1): 4.024e+01, MSE(pi2): 1.295e+00, MSE(pi3): 3.069e+00\n",
      "Epoch 3300, Train loss: 2.136e+07, Test loss: 1.958e+07, MSE(e): 2.068e+00, MSE(pi1): 3.787e+01, MSE(pi2): 1.275e+00, MSE(pi3): 3.015e+00\n",
      "Epoch 3400, Train loss: 2.088e+07, Test loss: 1.932e+07, MSE(e): 2.022e+00, MSE(pi1): 3.573e+01, MSE(pi2): 1.257e+00, MSE(pi3): 2.961e+00\n",
      "Epoch 3500, Train loss: 2.043e+07, Test loss: 1.908e+07, MSE(e): 1.980e+00, MSE(pi1): 3.380e+01, MSE(pi2): 1.240e+00, MSE(pi3): 2.909e+00\n",
      "Epoch 3600, Train loss: 2.002e+07, Test loss: 1.887e+07, MSE(e): 1.941e+00, MSE(pi1): 3.205e+01, MSE(pi2): 1.225e+00, MSE(pi3): 2.857e+00\n",
      "Epoch 3700, Train loss: 1.964e+07, Test loss: 1.868e+07, MSE(e): 1.906e+00, MSE(pi1): 3.045e+01, MSE(pi2): 1.211e+00, MSE(pi3): 2.807e+00\n",
      "Epoch 3800, Train loss: 1.930e+07, Test loss: 1.851e+07, MSE(e): 1.873e+00, MSE(pi1): 2.901e+01, MSE(pi2): 1.198e+00, MSE(pi3): 2.758e+00\n",
      "Epoch 3900, Train loss: 1.898e+07, Test loss: 1.835e+07, MSE(e): 1.843e+00, MSE(pi1): 2.769e+01, MSE(pi2): 1.186e+00, MSE(pi3): 2.711e+00\n",
      "Epoch 4000, Train loss: 1.869e+07, Test loss: 1.822e+07, MSE(e): 1.816e+00, MSE(pi1): 2.650e+01, MSE(pi2): 1.175e+00, MSE(pi3): 2.664e+00\n",
      "Epoch 4100, Train loss: 1.843e+07, Test loss: 1.810e+07, MSE(e): 1.791e+00, MSE(pi1): 2.542e+01, MSE(pi2): 1.165e+00, MSE(pi3): 2.619e+00\n",
      "Epoch 4200, Train loss: 1.818e+07, Test loss: 1.799e+07, MSE(e): 1.768e+00, MSE(pi1): 2.444e+01, MSE(pi2): 1.155e+00, MSE(pi3): 2.575e+00\n",
      "Epoch 4300, Train loss: 1.796e+07, Test loss: 1.791e+07, MSE(e): 1.747e+00, MSE(pi1): 2.357e+01, MSE(pi2): 1.147e+00, MSE(pi3): 2.532e+00\n",
      "Epoch 4400, Train loss: 1.775e+07, Test loss: 1.783e+07, MSE(e): 1.728e+00, MSE(pi1): 2.278e+01, MSE(pi2): 1.139e+00, MSE(pi3): 2.490e+00\n",
      "Epoch 4500, Train loss: 1.756e+07, Test loss: 1.776e+07, MSE(e): 1.710e+00, MSE(pi1): 2.207e+01, MSE(pi2): 1.132e+00, MSE(pi3): 2.450e+00\n",
      "Epoch 4600, Train loss: 1.739e+07, Test loss: 1.771e+07, MSE(e): 1.693e+00, MSE(pi1): 2.143e+01, MSE(pi2): 1.124e+00, MSE(pi3): 2.410e+00\n",
      "Epoch 4700, Train loss: 1.723e+07, Test loss: 1.766e+07, MSE(e): 1.678e+00, MSE(pi1): 2.087e+01, MSE(pi2): 1.118e+00, MSE(pi3): 2.372e+00\n",
      "Epoch 4800, Train loss: 1.708e+07, Test loss: 1.763e+07, MSE(e): 1.665e+00, MSE(pi1): 2.036e+01, MSE(pi2): 1.112e+00, MSE(pi3): 2.334e+00\n",
      "Epoch 4900, Train loss: 1.695e+07, Test loss: 1.759e+07, MSE(e): 1.652e+00, MSE(pi1): 1.992e+01, MSE(pi2): 1.107e+00, MSE(pi3): 2.298e+00\n",
      "Epoch 5000, Train loss: 1.683e+07, Test loss: 1.757e+07, MSE(e): 1.640e+00, MSE(pi1): 1.953e+01, MSE(pi2): 1.102e+00, MSE(pi3): 2.262e+00\n",
      "Epoch 5100, Train loss: 1.671e+07, Test loss: 1.755e+07, MSE(e): 1.630e+00, MSE(pi1): 1.919e+01, MSE(pi2): 1.097e+00, MSE(pi3): 2.228e+00\n",
      "Epoch 5200, Train loss: 1.661e+07, Test loss: 1.753e+07, MSE(e): 1.620e+00, MSE(pi1): 1.890e+01, MSE(pi2): 1.093e+00, MSE(pi3): 2.194e+00\n",
      "Epoch 5300, Train loss: 1.652e+07, Test loss: 1.752e+07, MSE(e): 1.611e+00, MSE(pi1): 1.865e+01, MSE(pi2): 1.089e+00, MSE(pi3): 2.161e+00\n",
      "Epoch 5400, Train loss: 1.643e+07, Test loss: 1.753e+07, MSE(e): 1.603e+00, MSE(pi1): 1.844e+01, MSE(pi2): 1.085e+00, MSE(pi3): 2.128e+00\n",
      "Epoch 5500, Train loss: 1.635e+07, Test loss: 1.751e+07, MSE(e): 1.595e+00, MSE(pi1): 1.826e+01, MSE(pi2): 1.081e+00, MSE(pi3): 2.096e+00\n",
      "Epoch 5600, Train loss: 1.627e+07, Test loss: 1.750e+07, MSE(e): 1.588e+00, MSE(pi1): 1.812e+01, MSE(pi2): 1.078e+00, MSE(pi3): 2.065e+00\n",
      "Epoch 5700, Train loss: 1.620e+07, Test loss: 1.752e+07, MSE(e): 1.581e+00, MSE(pi1): 1.800e+01, MSE(pi2): 1.075e+00, MSE(pi3): 2.033e+00\n",
      "Epoch 5800, Train loss: 1.613e+07, Test loss: 1.753e+07, MSE(e): 1.575e+00, MSE(pi1): 1.791e+01, MSE(pi2): 1.072e+00, MSE(pi3): 2.002e+00\n",
      "Epoch 5900, Train loss: 1.607e+07, Test loss: 1.754e+07, MSE(e): 1.570e+00, MSE(pi1): 1.783e+01, MSE(pi2): 1.069e+00, MSE(pi3): 1.971e+00\n",
      "Epoch 6000, Train loss: 1.601e+07, Test loss: 1.756e+07, MSE(e): 1.564e+00, MSE(pi1): 1.778e+01, MSE(pi2): 1.066e+00, MSE(pi3): 1.940e+00\n",
      "Epoch 6100, Train loss: 1.596e+07, Test loss: 1.758e+07, MSE(e): 1.559e+00, MSE(pi1): 1.773e+01, MSE(pi2): 1.063e+00, MSE(pi3): 1.909e+00\n",
      "Epoch 6200, Train loss: 1.590e+07, Test loss: 1.761e+07, MSE(e): 1.554e+00, MSE(pi1): 1.770e+01, MSE(pi2): 1.061e+00, MSE(pi3): 1.878e+00\n",
      "Epoch 6300, Train loss: 1.585e+07, Test loss: 1.764e+07, MSE(e): 1.549e+00, MSE(pi1): 1.768e+01, MSE(pi2): 1.058e+00, MSE(pi3): 1.847e+00\n",
      "Epoch 6400, Train loss: 1.580e+07, Test loss: 1.767e+07, MSE(e): 1.544e+00, MSE(pi1): 1.766e+01, MSE(pi2): 1.055e+00, MSE(pi3): 1.815e+00\n",
      "Epoch 6500, Train loss: 1.575e+07, Test loss: 1.769e+07, MSE(e): 1.540e+00, MSE(pi1): 1.764e+01, MSE(pi2): 1.053e+00, MSE(pi3): 1.783e+00\n",
      "Epoch 6600, Train loss: 1.570e+07, Test loss: 1.773e+07, MSE(e): 1.535e+00, MSE(pi1): 1.762e+01, MSE(pi2): 1.050e+00, MSE(pi3): 1.751e+00\n",
      "Epoch 6700, Train loss: 1.565e+07, Test loss: 1.776e+07, MSE(e): 1.530e+00, MSE(pi1): 1.760e+01, MSE(pi2): 1.047e+00, MSE(pi3): 1.718e+00\n",
      "Epoch 6800, Train loss: 1.560e+07, Test loss: 1.780e+07, MSE(e): 1.526e+00, MSE(pi1): 1.758e+01, MSE(pi2): 1.044e+00, MSE(pi3): 1.685e+00\n",
      "Epoch 6900, Train loss: 1.555e+07, Test loss: 1.783e+07, MSE(e): 1.521e+00, MSE(pi1): 1.756e+01, MSE(pi2): 1.041e+00, MSE(pi3): 1.653e+00\n",
      "Epoch 7000, Train loss: 1.549e+07, Test loss: 1.787e+07, MSE(e): 1.516e+00, MSE(pi1): 1.753e+01, MSE(pi2): 1.037e+00, MSE(pi3): 1.620e+00\n",
      "Epoch 7100, Train loss: 1.543e+07, Test loss: 1.790e+07, MSE(e): 1.510e+00, MSE(pi1): 1.751e+01, MSE(pi2): 1.033e+00, MSE(pi3): 1.588e+00\n",
      "Epoch 7200, Train loss: 1.536e+07, Test loss: 1.793e+07, MSE(e): 1.503e+00, MSE(pi1): 1.748e+01, MSE(pi2): 1.029e+00, MSE(pi3): 1.556e+00\n",
      "Epoch 7300, Train loss: 1.528e+07, Test loss: 1.794e+07, MSE(e): 1.495e+00, MSE(pi1): 1.746e+01, MSE(pi2): 1.023e+00, MSE(pi3): 1.526e+00\n",
      "Epoch 7400, Train loss: 1.517e+07, Test loss: 1.792e+07, MSE(e): 1.485e+00, MSE(pi1): 1.743e+01, MSE(pi2): 1.015e+00, MSE(pi3): 1.496e+00\n",
      "Epoch 7500, Train loss: 1.501e+07, Test loss: 1.786e+07, MSE(e): 1.469e+00, MSE(pi1): 1.742e+01, MSE(pi2): 1.004e+00, MSE(pi3): 1.468e+00\n",
      "Epoch 7600, Train loss: 1.475e+07, Test loss: 1.769e+07, MSE(e): 1.443e+00, MSE(pi1): 1.741e+01, MSE(pi2): 9.842e-01, MSE(pi3): 1.441e+00\n",
      "Epoch 7700, Train loss: 1.424e+07, Test loss: 1.723e+07, MSE(e): 1.392e+00, MSE(pi1): 1.743e+01, MSE(pi2): 9.460e-01, MSE(pi3): 1.417e+00\n",
      "Epoch 7800, Train loss: 1.313e+07, Test loss: 1.606e+07, MSE(e): 1.281e+00, MSE(pi1): 1.767e+01, MSE(pi2): 8.620e-01, MSE(pi3): 1.398e+00\n",
      "Epoch 7900, Train loss: 1.125e+07, Test loss: 1.381e+07, MSE(e): 1.093e+00, MSE(pi1): 1.865e+01, MSE(pi2): 7.232e-01, MSE(pi3): 1.403e+00\n",
      "Epoch 8000, Train loss: 9.796e+06, Test loss: 1.185e+07, MSE(e): 9.463e-01, MSE(pi1): 1.886e+01, MSE(pi2): 6.231e-01, MSE(pi3): 1.440e+00\n",
      "Epoch 8100, Train loss: 9.047e+06, Test loss: 1.089e+07, MSE(e): 8.720e-01, MSE(pi1): 1.802e+01, MSE(pi2): 5.757e-01, MSE(pi3): 1.464e+00\n",
      "Epoch 8200, Train loss: 8.582e+06, Test loss: 1.032e+07, MSE(e): 8.259e-01, MSE(pi1): 1.758e+01, MSE(pi2): 5.466e-01, MSE(pi3): 1.459e+00\n",
      "Epoch 8300, Train loss: 8.235e+06, Test loss: 9.882e+06, MSE(e): 7.917e-01, MSE(pi1): 1.734e+01, MSE(pi2): 5.256e-01, MSE(pi3): 1.434e+00\n",
      "Epoch 8400, Train loss: 7.941e+06, Test loss: 9.478e+06, MSE(e): 7.629e-01, MSE(pi1): 1.717e+01, MSE(pi2): 5.082e-01, MSE(pi3): 1.398e+00\n",
      "Epoch 8500, Train loss: 7.666e+06, Test loss: 9.057e+06, MSE(e): 7.360e-01, MSE(pi1): 1.702e+01, MSE(pi2): 4.920e-01, MSE(pi3): 1.356e+00\n",
      "Epoch 8600, Train loss: 7.412e+06, Test loss: 8.726e+06, MSE(e): 7.111e-01, MSE(pi1): 1.686e+01, MSE(pi2): 4.767e-01, MSE(pi3): 1.311e+00\n",
      "Epoch 8700, Train loss: 7.176e+06, Test loss: 8.459e+06, MSE(e): 6.883e-01, MSE(pi1): 1.671e+01, MSE(pi2): 4.623e-01, MSE(pi3): 1.264e+00\n",
      "Epoch 8800, Train loss: 6.962e+06, Test loss: 8.180e+06, MSE(e): 6.675e-01, MSE(pi1): 1.657e+01, MSE(pi2): 4.490e-01, MSE(pi3): 1.218e+00\n",
      "Epoch 8900, Train loss: 6.778e+06, Test loss: 7.923e+06, MSE(e): 6.496e-01, MSE(pi1): 1.641e+01, MSE(pi2): 4.379e-01, MSE(pi3): 1.174e+00\n",
      "Epoch 9000, Train loss: 6.623e+06, Test loss: 7.691e+06, MSE(e): 6.347e-01, MSE(pi1): 1.623e+01, MSE(pi2): 4.288e-01, MSE(pi3): 1.133e+00\n",
      "Epoch 9100, Train loss: 6.493e+06, Test loss: 7.485e+06, MSE(e): 6.223e-01, MSE(pi1): 1.603e+01, MSE(pi2): 4.213e-01, MSE(pi3): 1.094e+00\n",
      "Epoch 9200, Train loss: 6.384e+06, Test loss: 7.318e+06, MSE(e): 6.119e-01, MSE(pi1): 1.581e+01, MSE(pi2): 4.150e-01, MSE(pi3): 1.057e+00\n",
      "Epoch 9300, Train loss: 6.292e+06, Test loss: 7.183e+06, MSE(e): 6.033e-01, MSE(pi1): 1.560e+01, MSE(pi2): 4.099e-01, MSE(pi3): 1.023e+00\n",
      "Epoch 9400, Train loss: 6.215e+06, Test loss: 7.076e+06, MSE(e): 5.961e-01, MSE(pi1): 1.539e+01, MSE(pi2): 4.057e-01, MSE(pi3): 9.931e-01\n",
      "Epoch 9500, Train loss: 6.150e+06, Test loss: 6.991e+06, MSE(e): 5.901e-01, MSE(pi1): 1.520e+01, MSE(pi2): 4.022e-01, MSE(pi3): 9.664e-01\n",
      "Epoch 9600, Train loss: 6.097e+06, Test loss: 6.924e+06, MSE(e): 5.852e-01, MSE(pi1): 1.503e+01, MSE(pi2): 3.992e-01, MSE(pi3): 9.436e-01\n",
      "Epoch 9700, Train loss: 6.054e+06, Test loss: 6.870e+06, MSE(e): 5.812e-01, MSE(pi1): 1.489e+01, MSE(pi2): 3.972e-01, MSE(pi3): 9.246e-01\n",
      "Epoch 9800, Train loss: 6.015e+06, Test loss: 6.827e+06, MSE(e): 5.776e-01, MSE(pi1): 1.477e+01, MSE(pi2): 3.946e-01, MSE(pi3): 9.088e-01\n",
      "Epoch 9900, Train loss: 5.984e+06, Test loss: 6.792e+06, MSE(e): 5.747e-01, MSE(pi1): 1.467e+01, MSE(pi2): 3.928e-01, MSE(pi3): 8.961e-01\n",
      "Epoch 10000, Train loss: 5.956e+06, Test loss: 6.762e+06, MSE(e): 5.721e-01, MSE(pi1): 1.458e+01, MSE(pi2): 3.912e-01, MSE(pi3): 8.857e-01\n",
      "Epoch 10100, Train loss: 5.932e+06, Test loss: 6.737e+06, MSE(e): 5.699e-01, MSE(pi1): 1.451e+01, MSE(pi2): 3.898e-01, MSE(pi3): 8.771e-01\n",
      "Epoch 10200, Train loss: 5.910e+06, Test loss: 6.716e+06, MSE(e): 5.678e-01, MSE(pi1): 1.444e+01, MSE(pi2): 3.884e-01, MSE(pi3): 8.698e-01\n",
      "Epoch 10300, Train loss: 5.889e+06, Test loss: 6.698e+06, MSE(e): 5.659e-01, MSE(pi1): 1.437e+01, MSE(pi2): 3.872e-01, MSE(pi3): 8.634e-01\n",
      "Epoch 10400, Train loss: 5.871e+06, Test loss: 6.684e+06, MSE(e): 5.642e-01, MSE(pi1): 1.430e+01, MSE(pi2): 3.857e-01, MSE(pi3): 8.573e-01\n",
      "Epoch 10500, Train loss: 5.851e+06, Test loss: 6.671e+06, MSE(e): 5.623e-01, MSE(pi1): 1.422e+01, MSE(pi2): 3.848e-01, MSE(pi3): 8.518e-01\n",
      "Epoch 10600, Train loss: 5.832e+06, Test loss: 6.660e+06, MSE(e): 5.606e-01, MSE(pi1): 1.414e+01, MSE(pi2): 3.837e-01, MSE(pi3): 8.462e-01\n",
      "Epoch 10700, Train loss: 5.814e+06, Test loss: 6.650e+06, MSE(e): 5.589e-01, MSE(pi1): 1.405e+01, MSE(pi2): 3.825e-01, MSE(pi3): 8.405e-01\n",
      "Epoch 10800, Train loss: 5.796e+06, Test loss: 6.642e+06, MSE(e): 5.572e-01, MSE(pi1): 1.396e+01, MSE(pi2): 3.814e-01, MSE(pi3): 8.344e-01\n",
      "Epoch 10900, Train loss: 5.777e+06, Test loss: 6.635e+06, MSE(e): 5.556e-01, MSE(pi1): 1.386e+01, MSE(pi2): 3.801e-01, MSE(pi3): 8.278e-01\n",
      "Epoch 11000, Train loss: 5.758e+06, Test loss: 6.630e+06, MSE(e): 5.538e-01, MSE(pi1): 1.376e+01, MSE(pi2): 3.791e-01, MSE(pi3): 8.208e-01\n",
      "Epoch 11100, Train loss: 5.740e+06, Test loss: 6.626e+06, MSE(e): 5.522e-01, MSE(pi1): 1.364e+01, MSE(pi2): 3.780e-01, MSE(pi3): 8.131e-01\n",
      "Epoch 11200, Train loss: 5.721e+06, Test loss: 6.623e+06, MSE(e): 5.505e-01, MSE(pi1): 1.352e+01, MSE(pi2): 3.769e-01, MSE(pi3): 8.045e-01\n",
      "Epoch 11300, Train loss: 5.702e+06, Test loss: 6.620e+06, MSE(e): 5.488e-01, MSE(pi1): 1.338e+01, MSE(pi2): 3.757e-01, MSE(pi3): 7.950e-01\n",
      "Epoch 11400, Train loss: 5.683e+06, Test loss: 6.619e+06, MSE(e): 5.472e-01, MSE(pi1): 1.324e+01, MSE(pi2): 3.746e-01, MSE(pi3): 7.844e-01\n",
      "Epoch 11500, Train loss: 5.664e+06, Test loss: 6.617e+06, MSE(e): 5.456e-01, MSE(pi1): 1.308e+01, MSE(pi2): 3.735e-01, MSE(pi3): 7.727e-01\n",
      "Epoch 11600, Train loss: 5.645e+06, Test loss: 6.616e+06, MSE(e): 5.440e-01, MSE(pi1): 1.291e+01, MSE(pi2): 3.723e-01, MSE(pi3): 7.594e-01\n",
      "Epoch 11700, Train loss: 5.626e+06, Test loss: 6.616e+06, MSE(e): 5.424e-01, MSE(pi1): 1.272e+01, MSE(pi2): 3.714e-01, MSE(pi3): 7.448e-01\n",
      "Epoch 11800, Train loss: 5.606e+06, Test loss: 6.616e+06, MSE(e): 5.408e-01, MSE(pi1): 1.251e+01, MSE(pi2): 3.704e-01, MSE(pi3): 7.283e-01\n",
      "Epoch 11900, Train loss: 5.587e+06, Test loss: 6.615e+06, MSE(e): 5.392e-01, MSE(pi1): 1.228e+01, MSE(pi2): 3.693e-01, MSE(pi3): 7.096e-01\n",
      "Epoch 12000, Train loss: 5.566e+06, Test loss: 6.615e+06, MSE(e): 5.377e-01, MSE(pi1): 1.202e+01, MSE(pi2): 3.683e-01, MSE(pi3): 6.885e-01\n",
      "Epoch 12100, Train loss: 5.545e+06, Test loss: 6.615e+06, MSE(e): 5.361e-01, MSE(pi1): 1.174e+01, MSE(pi2): 3.673e-01, MSE(pi3): 6.649e-01\n",
      "Epoch 12200, Train loss: 5.523e+06, Test loss: 6.615e+06, MSE(e): 5.345e-01, MSE(pi1): 1.143e+01, MSE(pi2): 3.662e-01, MSE(pi3): 6.385e-01\n",
      "Epoch 12300, Train loss: 5.500e+06, Test loss: 6.620e+06, MSE(e): 5.328e-01, MSE(pi1): 1.109e+01, MSE(pi2): 3.649e-01, MSE(pi3): 6.093e-01\n",
      "Epoch 12400, Train loss: 5.475e+06, Test loss: 6.616e+06, MSE(e): 5.310e-01, MSE(pi1): 1.071e+01, MSE(pi2): 3.638e-01, MSE(pi3): 5.778e-01\n",
      "Epoch 12500, Train loss: 5.449e+06, Test loss: 6.619e+06, MSE(e): 5.291e-01, MSE(pi1): 1.030e+01, MSE(pi2): 3.625e-01, MSE(pi3): 5.441e-01\n",
      "Epoch 12600, Train loss: 5.420e+06, Test loss: 6.628e+06, MSE(e): 5.270e-01, MSE(pi1): 9.869e+00, MSE(pi2): 3.610e-01, MSE(pi3): 5.093e-01\n",
      "Epoch 12700, Train loss: 5.389e+06, Test loss: 6.639e+06, MSE(e): 5.247e-01, MSE(pi1): 9.404e+00, MSE(pi2): 3.595e-01, MSE(pi3): 4.743e-01\n",
      "Epoch 12800, Train loss: 5.355e+06, Test loss: 6.665e+06, MSE(e): 5.222e-01, MSE(pi1): 8.917e+00, MSE(pi2): 3.577e-01, MSE(pi3): 4.398e-01\n",
      "Epoch 12900, Train loss: 5.318e+06, Test loss: 6.700e+06, MSE(e): 5.193e-01, MSE(pi1): 8.411e+00, MSE(pi2): 3.557e-01, MSE(pi3): 4.070e-01\n",
      "Epoch 13000, Train loss: 5.277e+06, Test loss: 6.766e+06, MSE(e): 5.160e-01, MSE(pi1): 7.891e+00, MSE(pi2): 3.533e-01, MSE(pi3): 3.760e-01\n",
      "Epoch 13100, Train loss: 5.230e+06, Test loss: 6.871e+06, MSE(e): 5.121e-01, MSE(pi1): 7.362e+00, MSE(pi2): 3.505e-01, MSE(pi3): 3.469e-01\n",
      "Epoch 13200, Train loss: 5.176e+06, Test loss: 7.040e+06, MSE(e): 5.075e-01, MSE(pi1): 6.826e+00, MSE(pi2): 3.472e-01, MSE(pi3): 3.204e-01\n",
      "Epoch 13300, Train loss: 5.112e+06, Test loss: 7.296e+06, MSE(e): 5.019e-01, MSE(pi1): 6.296e+00, MSE(pi2): 3.431e-01, MSE(pi3): 2.949e-01\n",
      "Epoch 13400, Train loss: 5.037e+06, Test loss: 7.674e+06, MSE(e): 4.952e-01, MSE(pi1): 5.777e+00, MSE(pi2): 3.382e-01, MSE(pi3): 2.711e-01\n",
      "Epoch 13500, Train loss: 4.949e+06, Test loss: 8.171e+06, MSE(e): 4.871e-01, MSE(pi1): 5.281e+00, MSE(pi2): 3.324e-01, MSE(pi3): 2.479e-01\n",
      "Epoch 13600, Train loss: 4.842e+06, Test loss: 8.883e+06, MSE(e): 4.771e-01, MSE(pi1): 4.818e+00, MSE(pi2): 3.252e-01, MSE(pi3): 2.286e-01\n",
      "Epoch 13700, Train loss: 4.707e+06, Test loss: 9.670e+06, MSE(e): 4.642e-01, MSE(pi1): 4.411e+00, MSE(pi2): 3.161e-01, MSE(pi3): 2.090e-01\n",
      "Epoch 13800, Train loss: 4.551e+06, Test loss: 1.081e+07, MSE(e): 4.492e-01, MSE(pi1): 3.999e+00, MSE(pi2): 3.056e-01, MSE(pi3): 1.885e-01\n",
      "Epoch 13900, Train loss: 4.377e+06, Test loss: 1.259e+07, MSE(e): 4.324e-01, MSE(pi1): 3.528e+00, MSE(pi2): 2.937e-01, MSE(pi3): 1.719e-01\n",
      "Epoch 14000, Train loss: 4.182e+06, Test loss: 1.439e+07, MSE(e): 4.136e-01, MSE(pi1): 3.044e+00, MSE(pi2): 2.804e-01, MSE(pi3): 1.525e-01\n",
      "Epoch 14100, Train loss: 3.995e+06, Test loss: 1.612e+07, MSE(e): 3.955e-01, MSE(pi1): 2.604e+00, MSE(pi2): 2.677e-01, MSE(pi3): 1.348e-01\n",
      "Epoch 14200, Train loss: 3.850e+06, Test loss: 1.733e+07, MSE(e): 3.815e-01, MSE(pi1): 2.200e+00, MSE(pi2): 2.581e-01, MSE(pi3): 1.208e-01\n",
      "Epoch 14300, Train loss: 3.727e+06, Test loss: 1.806e+07, MSE(e): 3.696e-01, MSE(pi1): 1.928e+00, MSE(pi2): 2.499e-01, MSE(pi3): 1.112e-01\n",
      "Epoch 14400, Train loss: 3.602e+06, Test loss: 1.837e+07, MSE(e): 3.574e-01, MSE(pi1): 1.723e+00, MSE(pi2): 2.414e-01, MSE(pi3): 1.036e-01\n",
      "Epoch 14500, Train loss: 3.470e+06, Test loss: 1.851e+07, MSE(e): 3.444e-01, MSE(pi1): 1.562e+00, MSE(pi2): 2.323e-01, MSE(pi3): 9.681e-02\n",
      "Epoch 14600, Train loss: 3.340e+06, Test loss: 1.853e+07, MSE(e): 3.316e-01, MSE(pi1): 1.428e+00, MSE(pi2): 2.233e-01, MSE(pi3): 9.069e-02\n",
      "Epoch 14700, Train loss: 3.212e+06, Test loss: 1.838e+07, MSE(e): 3.190e-01, MSE(pi1): 1.311e+00, MSE(pi2): 2.144e-01, MSE(pi3): 8.493e-02\n",
      "Epoch 14800, Train loss: 3.082e+06, Test loss: 1.829e+07, MSE(e): 3.062e-01, MSE(pi1): 1.205e+00, MSE(pi2): 2.055e-01, MSE(pi3): 8.020e-02\n",
      "Epoch 14900, Train loss: 2.949e+06, Test loss: 1.819e+07, MSE(e): 2.930e-01, MSE(pi1): 1.108e+00, MSE(pi2): 1.964e-01, MSE(pi3): 7.545e-02\n",
      "Epoch 15000, Train loss: 2.803e+06, Test loss: 1.809e+07, MSE(e): 2.786e-01, MSE(pi1): 1.013e+00, MSE(pi2): 1.866e-01, MSE(pi3): 7.058e-02\n",
      "Epoch 15100, Train loss: 2.615e+06, Test loss: 1.788e+07, MSE(e): 2.599e-01, MSE(pi1): 9.100e-01, MSE(pi2): 1.734e-01, MSE(pi3): 6.655e-02\n",
      "Epoch 15200, Train loss: 2.268e+06, Test loss: 1.651e+07, MSE(e): 2.254e-01, MSE(pi1): 7.869e-01, MSE(pi2): 1.499e-01, MSE(pi3): 5.792e-02\n",
      "Epoch 15300, Train loss: 1.732e+06, Test loss: 1.335e+07, MSE(e): 1.721e-01, MSE(pi1): 6.678e-01, MSE(pi2): 1.142e-01, MSE(pi3): 4.820e-02\n",
      "Epoch 15400, Train loss: 1.200e+06, Test loss: 9.283e+06, MSE(e): 1.190e-01, MSE(pi1): 5.901e-01, MSE(pi2): 7.852e-02, MSE(pi3): 3.792e-02\n",
      "Epoch 15500, Train loss: 8.408e+05, Test loss: 6.415e+06, MSE(e): 8.323e-02, MSE(pi1): 5.435e-01, MSE(pi2): 5.458e-02, MSE(pi3): 3.061e-02\n",
      "Epoch 15600, Train loss: 6.182e+05, Test loss: 4.723e+06, MSE(e): 6.104e-02, MSE(pi1): 5.201e-01, MSE(pi2): 4.003e-02, MSE(pi3): 2.535e-02\n",
      "Epoch 15700, Train loss: 4.794e+05, Test loss: 3.743e+06, MSE(e): 4.728e-02, MSE(pi1): 4.360e-01, MSE(pi2): 3.113e-02, MSE(pi3): 2.192e-02\n",
      "Epoch 15800, Train loss: 3.907e+05, Test loss: 3.122e+06, MSE(e): 3.849e-02, MSE(pi1): 3.872e-01, MSE(pi2): 2.530e-02, MSE(pi3): 1.949e-02\n",
      "Epoch 15900, Train loss: 3.303e+05, Test loss: 2.691e+06, MSE(e): 3.251e-02, MSE(pi1): 3.405e-01, MSE(pi2): 2.130e-02, MSE(pi3): 1.785e-02\n",
      "Epoch 16000, Train loss: 2.854e+05, Test loss: 2.367e+06, MSE(e): 2.808e-02, MSE(pi1): 2.999e-01, MSE(pi2): 1.832e-02, MSE(pi3): 1.591e-02\n",
      "Epoch 16100, Train loss: 2.492e+05, Test loss: 2.120e+06, MSE(e): 2.451e-02, MSE(pi1): 2.674e-01, MSE(pi2): 1.589e-02, MSE(pi3): 1.433e-02\n",
      "Epoch 16200, Train loss: 2.172e+05, Test loss: 1.934e+06, MSE(e): 2.133e-02, MSE(pi1): 2.598e-01, MSE(pi2): 1.371e-02, MSE(pi3): 1.312e-02\n",
      "Epoch 16300, Train loss: 1.866e+05, Test loss: 1.801e+06, MSE(e): 1.832e-02, MSE(pi1): 2.184e-01, MSE(pi2): 1.167e-02, MSE(pi3): 1.180e-02\n",
      "Epoch 16400, Train loss: 1.631e+05, Test loss: 1.692e+06, MSE(e): 1.600e-02, MSE(pi1): 2.008e-01, MSE(pi2): 1.012e-02, MSE(pi3): 1.103e-02\n",
      "Epoch 16500, Train loss: 1.453e+05, Test loss: 1.612e+06, MSE(e): 1.424e-02, MSE(pi1): 1.832e-01, MSE(pi2): 8.983e-03, MSE(pi3): 1.059e-02\n",
      "Epoch 16600, Train loss: 1.310e+05, Test loss: 1.533e+06, MSE(e): 1.283e-02, MSE(pi1): 1.700e-01, MSE(pi2): 8.075e-03, MSE(pi3): 1.007e-02\n",
      "Epoch 16700, Train loss: 1.192e+05, Test loss: 1.462e+06, MSE(e): 1.167e-02, MSE(pi1): 1.578e-01, MSE(pi2): 7.329e-03, MSE(pi3): 9.649e-03\n",
      "Epoch 16800, Train loss: 1.093e+05, Test loss: 1.396e+06, MSE(e): 1.069e-02, MSE(pi1): 1.504e-01, MSE(pi2): 6.701e-03, MSE(pi3): 9.169e-03\n",
      "Epoch 16900, Train loss: 1.007e+05, Test loss: 1.338e+06, MSE(e): 9.837e-03, MSE(pi1): 1.379e-01, MSE(pi2): 6.159e-03, MSE(pi3): 9.026e-03\n",
      "Epoch 17000, Train loss: 9.319e+04, Test loss: 1.284e+06, MSE(e): 9.101e-03, MSE(pi1): 1.297e-01, MSE(pi2): 5.688e-03, MSE(pi3): 8.827e-03\n",
      "Epoch 17100, Train loss: 8.905e+04, Test loss: 1.238e+06, MSE(e): 8.678e-03, MSE(pi1): 1.314e-01, MSE(pi2): 5.376e-03, MSE(pi3): 9.440e-03\n",
      "Epoch 17200, Train loss: 8.108e+04, Test loss: 1.185e+06, MSE(e): 7.886e-03, MSE(pi1): 1.374e-01, MSE(pi2): 4.914e-03, MSE(pi3): 8.429e-03\n",
      "Epoch 17300, Train loss: 7.578e+04, Test loss: 1.139e+06, MSE(e): 7.385e-03, MSE(pi1): 1.116e-01, MSE(pi2): 4.594e-03, MSE(pi3): 8.095e-03\n",
      "Epoch 17400, Train loss: 7.155e+04, Test loss: 1.101e+06, MSE(e): 6.955e-03, MSE(pi1): 1.183e-01, MSE(pi2): 4.313e-03, MSE(pi3): 8.084e-03\n",
      "Epoch 17500, Train loss: 6.677e+04, Test loss: 1.057e+06, MSE(e): 6.497e-03, MSE(pi1): 1.003e-01, MSE(pi2): 4.033e-03, MSE(pi3): 7.923e-03\n",
      "Epoch 17600, Train loss: 6.302e+04, Test loss: 1.020e+06, MSE(e): 6.127e-03, MSE(pi1): 9.600e-02, MSE(pi2): 3.800e-03, MSE(pi3): 7.811e-03\n",
      "Epoch 17700, Train loss: 5.957e+04, Test loss: 9.841e+05, MSE(e): 5.787e-03, MSE(pi1): 9.304e-02, MSE(pi2): 3.585e-03, MSE(pi3): 7.653e-03\n",
      "Epoch 17800, Train loss: 5.637e+04, Test loss: 9.507e+05, MSE(e): 5.472e-03, MSE(pi1): 8.823e-02, MSE(pi2): 3.386e-03, MSE(pi3): 7.631e-03\n",
      "Epoch 17900, Train loss: 5.379e+04, Test loss: 9.158e+05, MSE(e): 5.184e-03, MSE(pi1): 1.225e-01, MSE(pi2): 3.205e-03, MSE(pi3): 7.235e-03\n",
      "Epoch 18000, Train loss: 5.200e+04, Test loss: 8.915e+05, MSE(e): 5.038e-03, MSE(pi1): 8.146e-02, MSE(pi2): 3.091e-03, MSE(pi3): 7.999e-03\n",
      "Epoch 18100, Train loss: 4.844e+04, Test loss: 8.625e+05, MSE(e): 4.664e-03, MSE(pi1): 1.030e-01, MSE(pi2): 2.879e-03, MSE(pi3): 7.584e-03\n",
      "Epoch 18200, Train loss: 4.564e+04, Test loss: 8.298e+05, MSE(e): 4.415e-03, MSE(pi1): 7.574e-02, MSE(pi2): 2.728e-03, MSE(pi3): 7.325e-03\n",
      "Epoch 18300, Train loss: 4.358e+04, Test loss: 8.063e+05, MSE(e): 4.195e-03, MSE(pi1): 8.822e-02, MSE(pi2): 2.591e-03, MSE(pi3): 7.429e-03\n",
      "Epoch 18400, Train loss: 4.119e+04, Test loss: 7.767e+05, MSE(e): 3.976e-03, MSE(pi1): 7.062e-02, MSE(pi2): 2.458e-03, MSE(pi3): 7.213e-03\n",
      "Epoch 18500, Train loss: 3.914e+04, Test loss: 7.506e+05, MSE(e): 3.774e-03, MSE(pi1): 6.840e-02, MSE(pi2): 2.334e-03, MSE(pi3): 7.158e-03\n",
      "Epoch 18600, Train loss: 3.730e+04, Test loss: 7.275e+05, MSE(e): 3.592e-03, MSE(pi1): 6.623e-02, MSE(pi2): 2.222e-03, MSE(pi3): 7.117e-03\n",
      "Epoch 18700, Train loss: 3.624e+04, Test loss: 7.061e+05, MSE(e): 3.488e-03, MSE(pi1): 6.248e-02, MSE(pi2): 2.146e-03, MSE(pi3): 7.308e-03\n",
      "Epoch 18800, Train loss: 3.408e+04, Test loss: 6.835e+05, MSE(e): 3.274e-03, MSE(pi1): 6.155e-02, MSE(pi2): 2.026e-03, MSE(pi3): 7.136e-03\n",
      "Epoch 18900, Train loss: 3.264e+04, Test loss: 6.603e+05, MSE(e): 3.130e-03, MSE(pi1): 6.581e-02, MSE(pi2): 1.940e-03, MSE(pi3): 6.847e-03\n",
      "Epoch 19000, Train loss: 3.242e+04, Test loss: 6.525e+05, MSE(e): 3.077e-03, MSE(pi1): 8.562e-02, MSE(pi2): 1.902e-03, MSE(pi3): 7.893e-03\n",
      "Epoch 19100, Train loss: 2.999e+04, Test loss: 6.243e+05, MSE(e): 2.872e-03, MSE(pi1): 5.744e-02, MSE(pi2): 1.783e-03, MSE(pi3): 6.943e-03\n",
      "Epoch 19200, Train loss: 2.883e+04, Test loss: 6.073e+05, MSE(e): 2.758e-03, MSE(pi1): 5.579e-02, MSE(pi2): 1.714e-03, MSE(pi3): 6.934e-03\n",
      "Epoch 19300, Train loss: 2.820e+04, Test loss: 5.904e+05, MSE(e): 2.695e-03, MSE(pi1): 5.691e-02, MSE(pi2): 1.668e-03, MSE(pi3): 6.777e-03\n",
      "Epoch 19400, Train loss: 2.678e+04, Test loss: 5.757e+05, MSE(e): 2.554e-03, MSE(pi1): 5.441e-02, MSE(pi2): 1.590e-03, MSE(pi3): 6.985e-03\n",
      "Epoch 19500, Train loss: 2.583e+04, Test loss: 5.594e+05, MSE(e): 2.462e-03, MSE(pi1): 5.192e-02, MSE(pi2): 1.534e-03, MSE(pi3): 6.851e-03\n",
      "Epoch 19600, Train loss: 2.551e+04, Test loss: 5.481e+05, MSE(e): 2.428e-03, MSE(pi1): 5.137e-02, MSE(pi2): 1.504e-03, MSE(pi3): 7.187e-03\n",
      "Epoch 19700, Train loss: 2.413e+04, Test loss: 5.309e+05, MSE(e): 2.295e-03, MSE(pi1): 4.994e-02, MSE(pi2): 1.431e-03, MSE(pi3): 6.797e-03\n",
      "Epoch 19800, Train loss: 2.352e+04, Test loss: 5.195e+05, MSE(e): 2.235e-03, MSE(pi1): 4.737e-02, MSE(pi2): 1.391e-03, MSE(pi3): 6.913e-03\n",
      "Epoch 19900, Train loss: 2.261e+04, Test loss: 5.065e+05, MSE(e): 2.146e-03, MSE(pi1): 4.755e-02, MSE(pi2): 1.340e-03, MSE(pi3): 6.754e-03\n",
      "Epoch 20000, Train loss: 2.195e+04, Test loss: 4.952e+05, MSE(e): 2.081e-03, MSE(pi1): 4.596e-02, MSE(pi2): 1.299e-03, MSE(pi3): 6.806e-03\n",
      "Epoch 20100, Train loss: 2.159e+04, Test loss: 4.828e+05, MSE(e): 2.038e-03, MSE(pi1): 5.574e-02, MSE(pi2): 1.269e-03, MSE(pi3): 6.523e-03\n",
      "Epoch 20200, Train loss: 2.066e+04, Test loss: 4.730e+05, MSE(e): 1.953e-03, MSE(pi1): 4.528e-02, MSE(pi2): 1.221e-03, MSE(pi3): 6.668e-03\n",
      "Epoch 20300, Train loss: 2.007e+04, Test loss: 4.635e+05, MSE(e): 1.896e-03, MSE(pi1): 4.365e-02, MSE(pi2): 1.185e-03, MSE(pi3): 6.706e-03\n",
      "Epoch 20400, Train loss: 1.983e+04, Test loss: 4.560e+05, MSE(e): 1.858e-03, MSE(pi1): 5.607e-02, MSE(pi2): 1.158e-03, MSE(pi3): 6.950e-03\n",
      "Epoch 20500, Train loss: 1.898e+04, Test loss: 4.451e+05, MSE(e): 1.789e-03, MSE(pi1): 4.242e-02, MSE(pi2): 1.118e-03, MSE(pi3): 6.672e-03\n",
      "Epoch 20600, Train loss: 1.849e+04, Test loss: 4.365e+05, MSE(e): 1.741e-03, MSE(pi1): 4.097e-02, MSE(pi2): 1.088e-03, MSE(pi3): 6.693e-03\n",
      "Epoch 20700, Train loss: 1.799e+04, Test loss: 4.282e+05, MSE(e): 1.692e-03, MSE(pi1): 4.103e-02, MSE(pi2): 1.057e-03, MSE(pi3): 6.623e-03\n",
      "Epoch 20800, Train loss: 1.754e+04, Test loss: 4.205e+05, MSE(e): 1.648e-03, MSE(pi1): 3.992e-02, MSE(pi2): 1.030e-03, MSE(pi3): 6.634e-03\n",
      "Epoch 20900, Train loss: 1.727e+04, Test loss: 4.137e+05, MSE(e): 1.605e-03, MSE(pi1): 5.645e-02, MSE(pi2): 1.002e-03, MSE(pi3): 6.595e-03\n",
      "Epoch 21000, Train loss: 1.667e+04, Test loss: 4.063e+05, MSE(e): 1.563e-03, MSE(pi1): 3.917e-02, MSE(pi2): 9.761e-04, MSE(pi3): 6.543e-03\n",
      "Epoch 21100, Train loss: 1.624e+04, Test loss: 3.996e+05, MSE(e): 1.520e-03, MSE(pi1): 3.829e-02, MSE(pi2): 9.495e-04, MSE(pi3): 6.557e-03\n",
      "Epoch 21200, Train loss: 1.586e+04, Test loss: 3.934e+05, MSE(e): 1.482e-03, MSE(pi1): 3.799e-02, MSE(pi2): 9.255e-04, MSE(pi3): 6.532e-03\n",
      "Epoch 21300, Train loss: 1.547e+04, Test loss: 3.876e+05, MSE(e): 1.445e-03, MSE(pi1): 3.679e-02, MSE(pi2): 9.018e-04, MSE(pi3): 6.560e-03\n",
      "Epoch 21400, Train loss: 1.515e+04, Test loss: 3.839e+05, MSE(e): 1.412e-03, MSE(pi1): 3.645e-02, MSE(pi2): 8.806e-04, MSE(pi3): 6.635e-03\n",
      "Epoch 21500, Train loss: 1.537e+04, Test loss: 3.780e+05, MSE(e): 1.379e-03, MSE(pi1): 9.105e-02, MSE(pi2): 8.579e-04, MSE(pi3): 6.716e-03\n",
      "Epoch 21600, Train loss: 1.453e+04, Test loss: 3.694e+05, MSE(e): 1.351e-03, MSE(pi1): 3.876e-02, MSE(pi2): 8.419e-04, MSE(pi3): 6.314e-03\n",
      "Epoch 21700, Train loss: 1.408e+04, Test loss: 3.665e+05, MSE(e): 1.308e-03, MSE(pi1): 3.464e-02, MSE(pi2): 8.153e-04, MSE(pi3): 6.522e-03\n",
      "Epoch 21800, Train loss: 1.401e+04, Test loss: 3.622e+05, MSE(e): 1.301e-03, MSE(pi1): 3.670e-02, MSE(pi2): 8.064e-04, MSE(pi3): 6.365e-03\n",
      "Epoch 21900, Train loss: 1.350e+04, Test loss: 3.574e+05, MSE(e): 1.248e-03, MSE(pi1): 3.729e-02, MSE(pi2): 7.768e-04, MSE(pi3): 6.480e-03\n",
      "Epoch 22000, Train loss: 1.315e+04, Test loss: 3.527e+05, MSE(e): 1.217e-03, MSE(pi1): 3.354e-02, MSE(pi2): 7.576e-04, MSE(pi3): 6.471e-03\n",
      "Epoch 22100, Train loss: 1.287e+04, Test loss: 3.486e+05, MSE(e): 1.189e-03, MSE(pi1): 3.303e-02, MSE(pi2): 7.401e-04, MSE(pi3): 6.467e-03\n",
      "Epoch 22200, Train loss: 1.369e+04, Test loss: 3.482e+05, MSE(e): 1.270e-03, MSE(pi1): 3.559e-02, MSE(pi2): 7.700e-04, MSE(pi3): 6.411e-03\n",
      "Epoch 22300, Train loss: 1.264e+04, Test loss: 3.400e+05, MSE(e): 1.165e-03, MSE(pi1): 3.644e-02, MSE(pi2): 7.201e-04, MSE(pi3): 6.233e-03\n",
      "Epoch 22400, Train loss: 1.250e+04, Test loss: 3.415e+05, MSE(e): 1.139e-03, MSE(pi1): 4.543e-02, MSE(pi2): 7.027e-04, MSE(pi3): 6.609e-03\n",
      "Epoch 22500, Train loss: 1.408e+04, Test loss: 3.357e+05, MSE(e): 1.308e-03, MSE(pi1): 4.074e-02, MSE(pi2): 7.740e-04, MSE(pi3): 5.992e-03\n",
      "Epoch 22600, Train loss: 1.160e+04, Test loss: 3.298e+05, MSE(e): 1.063e-03, MSE(pi1): 3.184e-02, MSE(pi2): 6.608e-04, MSE(pi3): 6.449e-03\n",
      "Epoch 22700, Train loss: 1.136e+04, Test loss: 3.264e+05, MSE(e): 1.041e-03, MSE(pi1): 3.059e-02, MSE(pi2): 6.468e-04, MSE(pi3): 6.451e-03\n",
      "Epoch 22800, Train loss: 1.115e+04, Test loss: 3.237e+05, MSE(e): 1.020e-03, MSE(pi1): 3.047e-02, MSE(pi2): 6.340e-04, MSE(pi3): 6.430e-03\n",
      "Epoch 22900, Train loss: 1.094e+04, Test loss: 3.197e+05, MSE(e): 9.991e-04, MSE(pi1): 3.037e-02, MSE(pi2): 6.208e-04, MSE(pi3): 6.403e-03\n",
      "Epoch 23000, Train loss: 1.102e+04, Test loss: 3.178e+05, MSE(e): 1.004e-03, MSE(pi1): 3.136e-02, MSE(pi2): 6.190e-04, MSE(pi3): 6.706e-03\n",
      "Epoch 23100, Train loss: 1.061e+04, Test loss: 3.134e+05, MSE(e): 9.661e-04, MSE(pi1): 3.146e-02, MSE(pi2): 5.994e-04, MSE(pi3): 6.356e-03\n",
      "Epoch 23200, Train loss: 1.043e+04, Test loss: 3.108e+05, MSE(e): 9.494e-04, MSE(pi1): 2.996e-02, MSE(pi2): 5.884e-04, MSE(pi3): 6.362e-03\n",
      "Epoch 23300, Train loss: 1.017e+04, Test loss: 3.073e+05, MSE(e): 9.224e-04, MSE(pi1): 3.103e-02, MSE(pi2): 5.729e-04, MSE(pi3): 6.370e-03\n",
      "Epoch 23400, Train loss: 9.993e+03, Test loss: 3.052e+05, MSE(e): 9.056e-04, MSE(pi1): 2.921e-02, MSE(pi2): 5.626e-04, MSE(pi3): 6.441e-03\n",
      "Epoch 23500, Train loss: 9.842e+03, Test loss: 3.018e+05, MSE(e): 8.903e-04, MSE(pi1): 3.014e-02, MSE(pi2): 5.530e-04, MSE(pi3): 6.365e-03\n",
      "Epoch 23600, Train loss: 9.687e+03, Test loss: 2.993e+05, MSE(e): 8.764e-04, MSE(pi1): 2.853e-02, MSE(pi2): 5.439e-04, MSE(pi3): 6.371e-03\n",
      "Epoch 23700, Train loss: 9.568e+03, Test loss: 2.963e+05, MSE(e): 8.646e-04, MSE(pi1): 2.904e-02, MSE(pi2): 5.361e-04, MSE(pi3): 6.302e-03\n",
      "Epoch 23800, Train loss: 9.370e+03, Test loss: 2.934e+05, MSE(e): 8.406e-04, MSE(pi1): 3.249e-02, MSE(pi2): 5.224e-04, MSE(pi3): 6.384e-03\n",
      "Epoch 23900, Train loss: 9.177e+03, Test loss: 2.907e+05, MSE(e): 8.261e-04, MSE(pi1): 2.758e-02, MSE(pi2): 5.134e-04, MSE(pi3): 6.392e-03\n",
      "Epoch 24000, Train loss: 9.118e+03, Test loss: 2.884e+05, MSE(e): 8.148e-04, MSE(pi1): 3.252e-02, MSE(pi2): 5.056e-04, MSE(pi3): 6.436e-03\n",
      "Epoch 24100, Train loss: 8.917e+03, Test loss: 2.861e+05, MSE(e): 7.978e-04, MSE(pi1): 2.989e-02, MSE(pi2): 4.960e-04, MSE(pi3): 6.393e-03\n",
      "Epoch 24200, Train loss: 8.964e+03, Test loss: 2.845e+05, MSE(e): 7.858e-04, MSE(pi1): 4.577e-02, MSE(pi2): 4.879e-04, MSE(pi3): 6.478e-03\n",
      "Epoch 24300, Train loss: 8.684e+03, Test loss: 2.810e+05, MSE(e): 7.772e-04, MSE(pi1): 2.746e-02, MSE(pi2): 4.818e-04, MSE(pi3): 6.369e-03\n",
      "Epoch 24400, Train loss: 9.216e+03, Test loss: 2.840e+05, MSE(e): 8.069e-04, MSE(pi1): 4.324e-02, MSE(pi2): 4.974e-04, MSE(pi3): 7.141e-03\n",
      "Epoch 24500, Train loss: 1.233e+04, Test loss: 2.798e+05, MSE(e): 1.129e-03, MSE(pi1): 4.669e-02, MSE(pi2): 6.365e-04, MSE(pi3): 5.744e-03\n",
      "Epoch 24600, Train loss: 8.256e+03, Test loss: 2.738e+05, MSE(e): 7.350e-04, MSE(pi1): 2.742e-02, MSE(pi2): 4.573e-04, MSE(pi3): 6.307e-03\n",
      "Epoch 24700, Train loss: 8.208e+03, Test loss: 2.722e+05, MSE(e): 7.251e-04, MSE(pi1): 3.249e-02, MSE(pi2): 4.509e-04, MSE(pi3): 6.325e-03\n",
      "Epoch 24800, Train loss: 8.102e+03, Test loss: 2.717e+05, MSE(e): 7.135e-04, MSE(pi1): 3.091e-02, MSE(pi2): 4.439e-04, MSE(pi3): 6.578e-03\n",
      "Epoch 24900, Train loss: 7.948e+03, Test loss: 2.679e+05, MSE(e): 7.050e-04, MSE(pi1): 2.534e-02, MSE(pi2): 4.379e-04, MSE(pi3): 6.446e-03\n",
      "Epoch 25000, Train loss: 7.818e+03, Test loss: 2.653e+05, MSE(e): 6.925e-04, MSE(pi1): 2.609e-02, MSE(pi2): 4.309e-04, MSE(pi3): 6.314e-03\n",
      "Epoch 25100, Train loss: 7.725e+03, Test loss: 2.637e+05, MSE(e): 6.835e-04, MSE(pi1): 2.566e-02, MSE(pi2): 4.251e-04, MSE(pi3): 6.332e-03\n",
      "Epoch 25200, Train loss: 8.052e+03, Test loss: 2.615e+05, MSE(e): 7.113e-04, MSE(pi1): 3.219e-02, MSE(pi2): 4.362e-04, MSE(pi3): 6.172e-03\n",
      "Epoch 25300, Train loss: 7.600e+03, Test loss: 2.591e+05, MSE(e): 6.698e-04, MSE(pi1): 2.619e-02, MSE(pi2): 4.148e-04, MSE(pi3): 6.406e-03\n",
      "Epoch 25400, Train loss: 8.179e+03, Test loss: 2.569e+05, MSE(e): 7.162e-04, MSE(pi1): 3.589e-02, MSE(pi2): 4.319e-04, MSE(pi3): 6.574e-03\n",
      "Epoch 25500, Train loss: 7.549e+03, Test loss: 2.587e+05, MSE(e): 6.480e-04, MSE(pi1): 3.912e-02, MSE(pi2): 4.038e-04, MSE(pi3): 6.778e-03\n",
      "Epoch 25600, Train loss: 8.529e+03, Test loss: 2.542e+05, MSE(e): 7.620e-04, MSE(pi1): 2.310e-02, MSE(pi2): 4.491e-04, MSE(pi3): 6.781e-03\n",
      "Epoch 25700, Train loss: 7.212e+03, Test loss: 2.503e+05, MSE(e): 6.282e-04, MSE(pi1): 2.975e-02, MSE(pi2): 3.910e-04, MSE(pi3): 6.313e-03\n",
      "Epoch 25800, Train loss: 7.043e+03, Test loss: 2.474e+05, MSE(e): 6.165e-04, MSE(pi1): 2.432e-02, MSE(pi2): 3.842e-04, MSE(pi3): 6.343e-03\n",
      "Epoch 25900, Train loss: 7.070e+03, Test loss: 2.451e+05, MSE(e): 6.188e-04, MSE(pi1): 2.603e-02, MSE(pi2): 3.843e-04, MSE(pi3): 6.214e-03\n",
      "Epoch 26000, Train loss: 8.118e+03, Test loss: 2.437e+05, MSE(e): 7.191e-04, MSE(pi1): 2.441e-02, MSE(pi2): 4.251e-04, MSE(pi3): 6.822e-03\n",
      "Epoch 26100, Train loss: 7.255e+03, Test loss: 2.411e+05, MSE(e): 6.333e-04, MSE(pi1): 3.143e-02, MSE(pi2): 3.887e-04, MSE(pi3): 6.071e-03\n",
      "Epoch 26200, Train loss: 6.737e+03, Test loss: 2.373e+05, MSE(e): 5.850e-04, MSE(pi1): 2.619e-02, MSE(pi2): 3.650e-04, MSE(pi3): 6.247e-03\n",
      "Epoch 26300, Train loss: 6.674e+03, Test loss: 2.366e+05, MSE(e): 5.775e-04, MSE(pi1): 2.581e-02, MSE(pi2): 3.602e-04, MSE(pi3): 6.409e-03\n",
      "Epoch 26400, Train loss: 6.603e+03, Test loss: 2.341e+05, MSE(e): 5.734e-04, MSE(pi1): 2.427e-02, MSE(pi2): 3.575e-04, MSE(pi3): 6.263e-03\n",
      "Epoch 26500, Train loss: 6.613e+03, Test loss: 2.310e+05, MSE(e): 5.645e-04, MSE(pi1): 3.429e-02, MSE(pi2): 3.519e-04, MSE(pi3): 6.243e-03\n",
      "Epoch 26600, Train loss: 6.623e+03, Test loss: 2.301e+05, MSE(e): 5.753e-04, MSE(pi1): 2.212e-02, MSE(pi2): 3.548e-04, MSE(pi3): 6.486e-03\n",
      "Epoch 26700, Train loss: 6.874e+03, Test loss: 2.304e+05, MSE(e): 5.994e-04, MSE(pi1): 2.174e-02, MSE(pi2): 3.646e-04, MSE(pi3): 6.622e-03\n",
      "Epoch 26800, Train loss: 7.563e+03, Test loss: 2.270e+05, MSE(e): 6.691e-04, MSE(pi1): 2.077e-02, MSE(pi2): 3.910e-04, MSE(pi3): 6.642e-03\n",
      "Epoch 26900, Train loss: 6.334e+03, Test loss: 2.257e+05, MSE(e): 5.397e-04, MSE(pi1): 2.924e-02, MSE(pi2): 3.368e-04, MSE(pi3): 6.439e-03\n",
      "Epoch 27000, Train loss: 6.165e+03, Test loss: 2.231e+05, MSE(e): 5.306e-04, MSE(pi1): 2.293e-02, MSE(pi2): 3.314e-04, MSE(pi3): 6.298e-03\n",
      "Epoch 27100, Train loss: 6.149e+03, Test loss: 2.219e+05, MSE(e): 5.288e-04, MSE(pi1): 2.196e-02, MSE(pi2): 3.291e-04, MSE(pi3): 6.405e-03\n",
      "Epoch 27200, Train loss: 6.165e+03, Test loss: 2.205e+05, MSE(e): 5.307e-04, MSE(pi1): 2.349e-02, MSE(pi2): 3.296e-04, MSE(pi3): 6.223e-03\n",
      "Epoch 27300, Train loss: 5.998e+03, Test loss: 2.194e+05, MSE(e): 5.135e-04, MSE(pi1): 2.309e-02, MSE(pi2): 3.207e-04, MSE(pi3): 6.320e-03\n",
      "Epoch 27400, Train loss: 5.993e+03, Test loss: 2.175e+05, MSE(e): 5.138e-04, MSE(pi1): 2.306e-02, MSE(pi2): 3.202e-04, MSE(pi3): 6.241e-03\n",
      "Epoch 27500, Train loss: 6.183e+03, Test loss: 2.191e+05, MSE(e): 5.079e-04, MSE(pi1): 4.215e-02, MSE(pi2): 3.174e-04, MSE(pi3): 6.827e-03\n",
      "Epoch 27600, Train loss: 6.791e+03, Test loss: 2.110e+05, MSE(e): 5.927e-04, MSE(pi1): 2.262e-02, MSE(pi2): 3.491e-04, MSE(pi3): 6.378e-03\n",
      "Epoch 27700, Train loss: 5.796e+03, Test loss: 2.133e+05, MSE(e): 4.914e-04, MSE(pi1): 2.439e-02, MSE(pi2): 3.070e-04, MSE(pi3): 6.381e-03\n",
      "Epoch 27800, Train loss: 5.735e+03, Test loss: 2.116e+05, MSE(e): 4.885e-04, MSE(pi1): 2.138e-02, MSE(pi2): 3.046e-04, MSE(pi3): 6.357e-03\n",
      "Epoch 27900, Train loss: 5.714e+03, Test loss: 2.096e+05, MSE(e): 4.823e-04, MSE(pi1): 2.710e-02, MSE(pi2): 3.014e-04, MSE(pi3): 6.198e-03\n",
      "Epoch 28000, Train loss: 5.611e+03, Test loss: 2.091e+05, MSE(e): 4.764e-04, MSE(pi1): 2.158e-02, MSE(pi2): 2.976e-04, MSE(pi3): 6.308e-03\n",
      "Epoch 28100, Train loss: 5.640e+03, Test loss: 2.076e+05, MSE(e): 4.789e-04, MSE(pi1): 2.334e-02, MSE(pi2): 2.986e-04, MSE(pi3): 6.176e-03\n",
      "Epoch 28200, Train loss: 5.528e+03, Test loss: 2.071e+05, MSE(e): 4.682e-04, MSE(pi1): 2.159e-02, MSE(pi2): 2.925e-04, MSE(pi3): 6.303e-03\n",
      "Epoch 28300, Train loss: 5.568e+03, Test loss: 2.067e+05, MSE(e): 4.688e-04, MSE(pi1): 2.273e-02, MSE(pi2): 2.920e-04, MSE(pi3): 6.526e-03\n",
      "Epoch 28400, Train loss: 5.808e+03, Test loss: 2.061e+05, MSE(e): 4.965e-04, MSE(pi1): 2.285e-02, MSE(pi2): 3.036e-04, MSE(pi3): 6.148e-03\n",
      "Epoch 28500, Train loss: 5.988e+03, Test loss: 2.000e+05, MSE(e): 4.678e-04, MSE(pi1): 7.261e-02, MSE(pi2): 2.932e-04, MSE(pi3): 5.837e-03\n",
      "Epoch 28600, Train loss: 5.342e+03, Test loss: 2.025e+05, MSE(e): 4.502e-04, MSE(pi1): 2.134e-02, MSE(pi2): 2.814e-04, MSE(pi3): 6.264e-03\n",
      "Epoch 28700, Train loss: 6.936e+03, Test loss: 2.013e+05, MSE(e): 6.076e-04, MSE(pi1): 1.920e-02, MSE(pi2): 3.458e-04, MSE(pi3): 6.675e-03\n",
      "Epoch 28800, Train loss: 5.282e+03, Test loss: 2.017e+05, MSE(e): 4.427e-04, MSE(pi1): 2.114e-02, MSE(pi2): 2.768e-04, MSE(pi3): 6.442e-03\n",
      "Epoch 28900, Train loss: 5.213e+03, Test loss: 1.993e+05, MSE(e): 4.370e-04, MSE(pi1): 2.144e-02, MSE(pi2): 2.731e-04, MSE(pi3): 6.282e-03\n",
      "Epoch 29000, Train loss: 5.174e+03, Test loss: 1.978e+05, MSE(e): 4.333e-04, MSE(pi1): 2.195e-02, MSE(pi2): 2.710e-04, MSE(pi3): 6.210e-03\n",
      "Epoch 29100, Train loss: 5.668e+03, Test loss: 2.027e+05, MSE(e): 4.569e-04, MSE(pi1): 4.287e-02, MSE(pi2): 2.810e-04, MSE(pi3): 6.698e-03\n",
      "Epoch 29200, Train loss: 5.152e+03, Test loss: 1.962e+05, MSE(e): 4.313e-04, MSE(pi1): 2.037e-02, MSE(pi2): 2.680e-04, MSE(pi3): 6.355e-03\n",
      "Epoch 29300, Train loss: 5.560e+03, Test loss: 1.966e+05, MSE(e): 4.669e-04, MSE(pi1): 2.843e-02, MSE(pi2): 2.844e-04, MSE(pi3): 6.059e-03\n",
      "Epoch 29400, Train loss: 5.608e+03, Test loss: 2.007e+05, MSE(e): 4.645e-04, MSE(pi1): 2.881e-02, MSE(pi2): 2.857e-04, MSE(pi3): 6.746e-03\n",
      "Epoch 29500, Train loss: 5.023e+03, Test loss: 1.941e+05, MSE(e): 4.184e-04, MSE(pi1): 2.149e-02, MSE(pi2): 2.610e-04, MSE(pi3): 6.239e-03\n",
      "Epoch 29600, Train loss: 5.111e+03, Test loss: 1.903e+05, MSE(e): 4.248e-04, MSE(pi1): 2.544e-02, MSE(pi2): 2.644e-04, MSE(pi3): 6.090e-03\n",
      "Epoch 29700, Train loss: 5.312e+03, Test loss: 1.926e+05, MSE(e): 4.376e-04, MSE(pi1): 2.835e-02, MSE(pi2): 2.668e-04, MSE(pi3): 6.522e-03\n",
      "Epoch 29800, Train loss: 4.922e+03, Test loss: 1.918e+05, MSE(e): 4.088e-04, MSE(pi1): 2.166e-02, MSE(pi2): 2.551e-04, MSE(pi3): 6.171e-03\n",
      "Epoch 29900, Train loss: 4.838e+03, Test loss: 1.900e+05, MSE(e): 4.009e-04, MSE(pi1): 2.054e-02, MSE(pi2): 2.505e-04, MSE(pi3): 6.241e-03\n",
      "Epoch 30000, Train loss: 4.803e+03, Test loss: 1.896e+05, MSE(e): 3.976e-04, MSE(pi1): 1.984e-02, MSE(pi2): 2.485e-04, MSE(pi3): 6.281e-03\n",
      "Epoch 30100, Train loss: 4.782e+03, Test loss: 1.890e+05, MSE(e): 3.955e-04, MSE(pi1): 2.001e-02, MSE(pi2): 2.472e-04, MSE(pi3): 6.263e-03\n",
      "Epoch 30200, Train loss: 5.736e+03, Test loss: 1.905e+05, MSE(e): 4.859e-04, MSE(pi1): 2.834e-02, MSE(pi2): 2.879e-04, MSE(pi3): 5.928e-03\n",
      "Epoch 30300, Train loss: 4.769e+03, Test loss: 1.878e+05, MSE(e): 3.945e-04, MSE(pi1): 2.027e-02, MSE(pi2): 2.457e-04, MSE(pi3): 6.218e-03\n",
      "Epoch 30400, Train loss: 4.679e+03, Test loss: 1.863e+05, MSE(e): 3.851e-04, MSE(pi1): 1.982e-02, MSE(pi2): 2.407e-04, MSE(pi3): 6.295e-03\n",
      "Epoch 30500, Train loss: 5.098e+03, Test loss: 1.852e+05, MSE(e): 4.271e-04, MSE(pi1): 1.833e-02, MSE(pi2): 2.567e-04, MSE(pi3): 6.434e-03\n",
      "Epoch 30600, Train loss: 4.903e+03, Test loss: 1.883e+05, MSE(e): 3.843e-04, MSE(pi1): 3.887e-02, MSE(pi2): 2.400e-04, MSE(pi3): 6.712e-03\n",
      "Epoch 30700, Train loss: 4.603e+03, Test loss: 1.847e+05, MSE(e): 3.782e-04, MSE(pi1): 1.970e-02, MSE(pi2): 2.362e-04, MSE(pi3): 6.237e-03\n",
      "Epoch 30800, Train loss: 4.594e+03, Test loss: 1.829e+05, MSE(e): 3.761e-04, MSE(pi1): 2.162e-02, MSE(pi2): 2.347e-04, MSE(pi3): 6.173e-03\n",
      "Epoch 30900, Train loss: 4.844e+03, Test loss: 1.848e+05, MSE(e): 3.909e-04, MSE(pi1): 2.935e-02, MSE(pi2): 2.398e-04, MSE(pi3): 6.411e-03\n",
      "Epoch 31000, Train loss: 4.523e+03, Test loss: 1.819e+05, MSE(e): 3.703e-04, MSE(pi1): 1.997e-02, MSE(pi2): 2.315e-04, MSE(pi3): 6.198e-03\n",
      "Epoch 31100, Train loss: 4.540e+03, Test loss: 1.817e+05, MSE(e): 3.718e-04, MSE(pi1): 2.080e-02, MSE(pi2): 2.317e-04, MSE(pi3): 6.141e-03\n",
      "Epoch 31200, Train loss: 4.726e+03, Test loss: 1.817e+05, MSE(e): 3.650e-04, MSE(pi1): 4.423e-02, MSE(pi2): 2.269e-04, MSE(pi3): 6.332e-03\n",
      "Epoch 31300, Train loss: 5.730e+03, Test loss: 1.801e+05, MSE(e): 4.905e-04, MSE(pi1): 1.674e-02, MSE(pi2): 2.785e-04, MSE(pi3): 6.568e-03\n",
      "Epoch 31400, Train loss: 8.438e+03, Test loss: 1.847e+05, MSE(e): 7.565e-04, MSE(pi1): 2.998e-02, MSE(pi2): 3.987e-04, MSE(pi3): 5.729e-03\n",
      "Epoch 31500, Train loss: 4.368e+03, Test loss: 1.801e+05, MSE(e): 3.551e-04, MSE(pi1): 1.881e-02, MSE(pi2): 2.219e-04, MSE(pi3): 6.280e-03\n",
      "Epoch 31600, Train loss: 4.482e+03, Test loss: 1.790e+05, MSE(e): 3.666e-04, MSE(pi1): 2.020e-02, MSE(pi2): 2.270e-04, MSE(pi3): 6.136e-03\n",
      "Epoch 31700, Train loss: 4.414e+03, Test loss: 1.796e+05, MSE(e): 3.516e-04, MSE(pi1): 2.659e-02, MSE(pi2): 2.194e-04, MSE(pi3): 6.310e-03\n",
      "Epoch 31800, Train loss: 4.296e+03, Test loss: 1.775e+05, MSE(e): 3.482e-04, MSE(pi1): 1.929e-02, MSE(pi2): 2.176e-04, MSE(pi3): 6.208e-03\n",
      "Epoch 31900, Train loss: 5.565e+03, Test loss: 1.760e+05, MSE(e): 4.745e-04, MSE(pi1): 1.702e-02, MSE(pi2): 2.685e-04, MSE(pi3): 6.501e-03\n",
      "Epoch 32000, Train loss: 4.291e+03, Test loss: 1.753e+05, MSE(e): 3.455e-04, MSE(pi1): 2.275e-02, MSE(pi2): 2.161e-04, MSE(pi3): 6.083e-03\n",
      "Epoch 32100, Train loss: 4.230e+03, Test loss: 1.757e+05, MSE(e): 3.414e-04, MSE(pi1): 1.870e-02, MSE(pi2): 2.129e-04, MSE(pi3): 6.286e-03\n",
      "Epoch 32200, Train loss: 4.193e+03, Test loss: 1.753e+05, MSE(e): 3.382e-04, MSE(pi1): 1.843e-02, MSE(pi2): 2.113e-04, MSE(pi3): 6.259e-03\n",
      "Epoch 32300, Train loss: 4.217e+03, Test loss: 1.753e+05, MSE(e): 3.390e-04, MSE(pi1): 1.874e-02, MSE(pi2): 2.113e-04, MSE(pi3): 6.391e-03\n",
      "Epoch 32400, Train loss: 4.414e+03, Test loss: 1.746e+05, MSE(e): 3.569e-04, MSE(pi1): 1.942e-02, MSE(pi2): 2.180e-04, MSE(pi3): 6.507e-03\n",
      "Epoch 32500, Train loss: 4.127e+03, Test loss: 1.738e+05, MSE(e): 3.315e-04, MSE(pi1): 1.826e-02, MSE(pi2): 2.070e-04, MSE(pi3): 6.290e-03\n",
      "Epoch 32600, Train loss: 4.129e+03, Test loss: 1.727e+05, MSE(e): 3.321e-04, MSE(pi1): 1.789e-02, MSE(pi2): 2.066e-04, MSE(pi3): 6.290e-03\n",
      "Epoch 32700, Train loss: 5.858e+03, Test loss: 1.736e+05, MSE(e): 4.937e-04, MSE(pi1): 2.213e-02, MSE(pi2): 2.782e-04, MSE(pi3): 6.993e-03\n",
      "Epoch 32800, Train loss: 4.057e+03, Test loss: 1.720e+05, MSE(e): 3.251e-04, MSE(pi1): 1.819e-02, MSE(pi2): 2.030e-04, MSE(pi3): 6.241e-03\n",
      "Epoch 32900, Train loss: 4.839e+03, Test loss: 1.722e+05, MSE(e): 3.976e-04, MSE(pi1): 1.952e-02, MSE(pi2): 2.338e-04, MSE(pi3): 6.674e-03\n",
      "Epoch 33000, Train loss: 4.034e+03, Test loss: 1.718e+05, MSE(e): 3.222e-04, MSE(pi1): 1.820e-02, MSE(pi2): 2.010e-04, MSE(pi3): 6.306e-03\n",
      "Epoch 33100, Train loss: 4.041e+03, Test loss: 1.706e+05, MSE(e): 3.192e-04, MSE(pi1): 2.232e-02, MSE(pi2): 1.992e-04, MSE(pi3): 6.251e-03\n",
      "Epoch 33200, Train loss: 3.975e+03, Test loss: 1.700e+05, MSE(e): 3.170e-04, MSE(pi1): 1.771e-02, MSE(pi2): 1.978e-04, MSE(pi3): 6.272e-03\n",
      "Epoch 33300, Train loss: 5.251e+03, Test loss: 1.759e+05, MSE(e): 4.219e-04, MSE(pi1): 2.919e-02, MSE(pi2): 2.657e-04, MSE(pi3): 7.396e-03\n",
      "Epoch 33400, Train loss: 3.933e+03, Test loss: 1.691e+05, MSE(e): 3.130e-04, MSE(pi1): 1.790e-02, MSE(pi2): 1.954e-04, MSE(pi3): 6.242e-03\n",
      "Epoch 33500, Train loss: 3.931e+03, Test loss: 1.689e+05, MSE(e): 3.128e-04, MSE(pi1): 1.811e-02, MSE(pi2): 1.951e-04, MSE(pi3): 6.211e-03\n",
      "Epoch 33600, Train loss: 3.893e+03, Test loss: 1.681e+05, MSE(e): 3.091e-04, MSE(pi1): 1.780e-02, MSE(pi2): 1.930e-04, MSE(pi3): 6.237e-03\n",
      "Epoch 33700, Train loss: 4.099e+03, Test loss: 1.674e+05, MSE(e): 3.292e-04, MSE(pi1): 1.673e-02, MSE(pi2): 2.005e-04, MSE(pi3): 6.394e-03\n",
      "Epoch 33800, Train loss: 4.156e+03, Test loss: 1.675e+05, MSE(e): 3.311e-04, MSE(pi1): 2.040e-02, MSE(pi2): 2.008e-04, MSE(pi3): 6.403e-03\n",
      "Epoch 33900, Train loss: 3.835e+03, Test loss: 1.668e+05, MSE(e): 3.035e-04, MSE(pi1): 1.761e-02, MSE(pi2): 1.894e-04, MSE(pi3): 6.238e-03\n",
      "Epoch 34000, Train loss: 3.836e+03, Test loss: 1.665e+05, MSE(e): 3.036e-04, MSE(pi1): 1.819e-02, MSE(pi2): 1.894e-04, MSE(pi3): 6.177e-03\n",
      "Epoch 34100, Train loss: 3.801e+03, Test loss: 1.657e+05, MSE(e): 3.001e-04, MSE(pi1): 1.795e-02, MSE(pi2): 1.873e-04, MSE(pi3): 6.200e-03\n",
      "Epoch 34200, Train loss: 3.783e+03, Test loss: 1.653e+05, MSE(e): 2.983e-04, MSE(pi1): 1.793e-02, MSE(pi2): 1.862e-04, MSE(pi3): 6.200e-03\n",
      "Epoch 34300, Train loss: 3.838e+03, Test loss: 1.629e+05, MSE(e): 2.996e-04, MSE(pi1): 2.394e-02, MSE(pi2): 1.873e-04, MSE(pi3): 6.026e-03\n",
      "Epoch 34400, Train loss: 8.285e+03, Test loss: 1.692e+05, MSE(e): 7.108e-04, MSE(pi1): 6.373e-02, MSE(pi2): 3.900e-04, MSE(pi3): 5.401e-03\n",
      "Epoch 34500, Train loss: 3.725e+03, Test loss: 1.640e+05, MSE(e): 2.928e-04, MSE(pi1): 1.738e-02, MSE(pi2): 1.826e-04, MSE(pi3): 6.230e-03\n",
      "Epoch 34600, Train loss: 4.160e+03, Test loss: 1.659e+05, MSE(e): 3.236e-04, MSE(pi1): 2.798e-02, MSE(pi2): 1.955e-04, MSE(pi3): 6.442e-03\n",
      "Epoch 34700, Train loss: 3.690e+03, Test loss: 1.632e+05, MSE(e): 2.894e-04, MSE(pi1): 1.726e-02, MSE(pi2): 1.805e-04, MSE(pi3): 6.232e-03\n",
      "Epoch 34800, Train loss: 3.813e+03, Test loss: 1.611e+05, MSE(e): 3.012e-04, MSE(pi1): 1.775e-02, MSE(pi2): 1.849e-04, MSE(pi3): 6.239e-03\n",
      "Epoch 34900, Train loss: 3.687e+03, Test loss: 1.622e+05, MSE(e): 2.882e-04, MSE(pi1): 1.776e-02, MSE(pi2): 1.791e-04, MSE(pi3): 6.278e-03\n",
      "Epoch 35000, Train loss: 3.643e+03, Test loss: 1.619e+05, MSE(e): 2.845e-04, MSE(pi1): 1.760e-02, MSE(pi2): 1.774e-04, MSE(pi3): 6.213e-03\n",
      "Epoch 35100, Train loss: 3.825e+03, Test loss: 1.613e+05, MSE(e): 2.967e-04, MSE(pi1): 2.071e-02, MSE(pi2): 1.825e-04, MSE(pi3): 6.509e-03\n",
      "Epoch 35200, Train loss: 3.673e+03, Test loss: 1.619e+05, MSE(e): 2.875e-04, MSE(pi1): 1.767e-02, MSE(pi2): 1.783e-04, MSE(pi3): 6.211e-03\n",
      "Epoch 35300, Train loss: 3.659e+03, Test loss: 1.594e+05, MSE(e): 2.808e-04, MSE(pi1): 2.419e-02, MSE(pi2): 1.750e-04, MSE(pi3): 6.089e-03\n",
      "Epoch 35400, Train loss: 3.638e+03, Test loss: 1.592e+05, MSE(e): 2.839e-04, MSE(pi1): 1.771e-02, MSE(pi2): 1.752e-04, MSE(pi3): 6.220e-03\n",
      "Epoch 35500, Train loss: 3.556e+03, Test loss: 1.599e+05, MSE(e): 2.764e-04, MSE(pi1): 1.699e-02, MSE(pi2): 1.723e-04, MSE(pi3): 6.221e-03\n",
      "Epoch 35600, Train loss: 3.540e+03, Test loss: 1.595e+05, MSE(e): 2.748e-04, MSE(pi1): 1.700e-02, MSE(pi2): 1.713e-04, MSE(pi3): 6.218e-03\n",
      "Epoch 35700, Train loss: 3.525e+03, Test loss: 1.592e+05, MSE(e): 2.733e-04, MSE(pi1): 1.682e-02, MSE(pi2): 1.704e-04, MSE(pi3): 6.234e-03\n",
      "Epoch 35800, Train loss: 3.511e+03, Test loss: 1.590e+05, MSE(e): 2.720e-04, MSE(pi1): 1.669e-02, MSE(pi2): 1.695e-04, MSE(pi3): 6.239e-03\n",
      "Epoch 35900, Train loss: 4.156e+03, Test loss: 1.574e+05, MSE(e): 3.345e-04, MSE(pi1): 2.202e-02, MSE(pi2): 1.995e-04, MSE(pi3): 5.906e-03\n",
      "Epoch 36000, Train loss: 3.477e+03, Test loss: 1.580e+05, MSE(e): 2.687e-04, MSE(pi1): 1.669e-02, MSE(pi2): 1.675e-04, MSE(pi3): 6.231e-03\n",
      "Epoch 36100, Train loss: 3.500e+03, Test loss: 1.578e+05, MSE(e): 2.709e-04, MSE(pi1): 1.795e-02, MSE(pi2): 1.688e-04, MSE(pi3): 6.112e-03\n",
      "Epoch 36200, Train loss: 3.584e+03, Test loss: 1.575e+05, MSE(e): 2.682e-04, MSE(pi1): 2.836e-02, MSE(pi2): 1.666e-04, MSE(pi3): 6.179e-03\n",
      "Epoch 36300, Train loss: 3.433e+03, Test loss: 1.569e+05, MSE(e): 2.644e-04, MSE(pi1): 1.663e-02, MSE(pi2): 1.648e-04, MSE(pi3): 6.224e-03\n",
      "Epoch 36400, Train loss: 3.790e+03, Test loss: 1.545e+05, MSE(e): 2.930e-04, MSE(pi1): 2.232e-02, MSE(pi2): 1.764e-04, MSE(pi3): 6.373e-03\n",
      "Epoch 36500, Train loss: 3.516e+03, Test loss: 1.555e+05, MSE(e): 2.654e-04, MSE(pi1): 2.316e-02, MSE(pi2): 1.642e-04, MSE(pi3): 6.296e-03\n",
      "Epoch 36600, Train loss: 3.388e+03, Test loss: 1.557e+05, MSE(e): 2.601e-04, MSE(pi1): 1.654e-02, MSE(pi2): 1.620e-04, MSE(pi3): 6.220e-03\n",
      "Epoch 36700, Train loss: 3.574e+03, Test loss: 1.561e+05, MSE(e): 2.768e-04, MSE(pi1): 1.500e-02, MSE(pi2): 1.696e-04, MSE(pi3): 6.556e-03\n",
      "Epoch 36800, Train loss: 3.365e+03, Test loss: 1.550e+05, MSE(e): 2.573e-04, MSE(pi1): 1.694e-02, MSE(pi2): 1.603e-04, MSE(pi3): 6.225e-03\n",
      "Epoch 36900, Train loss: 3.365e+03, Test loss: 1.550e+05, MSE(e): 2.577e-04, MSE(pi1): 1.660e-02, MSE(pi2): 1.603e-04, MSE(pi3): 6.214e-03\n",
      "Epoch 37000, Train loss: 3.370e+03, Test loss: 1.551e+05, MSE(e): 2.554e-04, MSE(pi1): 1.795e-02, MSE(pi2): 1.590e-04, MSE(pi3): 6.369e-03\n",
      "Epoch 37100, Train loss: 3.319e+03, Test loss: 1.540e+05, MSE(e): 2.533e-04, MSE(pi1): 1.629e-02, MSE(pi2): 1.577e-04, MSE(pi3): 6.228e-03\n",
      "Epoch 37200, Train loss: 3.334e+03, Test loss: 1.535e+05, MSE(e): 2.542e-04, MSE(pi1): 1.735e-02, MSE(pi2): 1.583e-04, MSE(pi3): 6.183e-03\n",
      "Epoch 37300, Train loss: 3.364e+03, Test loss: 1.537e+05, MSE(e): 2.574e-04, MSE(pi1): 1.605e-02, MSE(pi2): 1.584e-04, MSE(pi3): 6.297e-03\n",
      "Epoch 37400, Train loss: 3.300e+03, Test loss: 1.529e+05, MSE(e): 2.514e-04, MSE(pi1): 1.727e-02, MSE(pi2): 1.564e-04, MSE(pi3): 6.138e-03\n",
      "Epoch 37500, Train loss: 3.341e+03, Test loss: 1.523e+05, MSE(e): 2.506e-04, MSE(pi1): 2.073e-02, MSE(pi2): 1.551e-04, MSE(pi3): 6.269e-03\n",
      "Epoch 37600, Train loss: 3.370e+03, Test loss: 1.509e+05, MSE(e): 2.494e-04, MSE(pi1): 2.749e-02, MSE(pi2): 1.550e-04, MSE(pi3): 6.007e-03\n",
      "Epoch 37700, Train loss: 3.289e+03, Test loss: 1.515e+05, MSE(e): 2.502e-04, MSE(pi1): 1.597e-02, MSE(pi2): 1.544e-04, MSE(pi3): 6.276e-03\n",
      "Epoch 37800, Train loss: 3.291e+03, Test loss: 1.523e+05, MSE(e): 2.500e-04, MSE(pi1): 1.684e-02, MSE(pi2): 1.546e-04, MSE(pi3): 6.222e-03\n",
      "Epoch 37900, Train loss: 3.356e+03, Test loss: 1.511e+05, MSE(e): 2.510e-04, MSE(pi1): 2.378e-02, MSE(pi2): 1.554e-04, MSE(pi3): 6.077e-03\n",
      "Epoch 38000, Train loss: 3.348e+03, Test loss: 1.501e+05, MSE(e): 2.557e-04, MSE(pi1): 1.680e-02, MSE(pi2): 1.556e-04, MSE(pi3): 6.227e-03\n",
      "Epoch 38100, Train loss: 3.352e+03, Test loss: 1.521e+05, MSE(e): 2.569e-04, MSE(pi1): 1.646e-02, MSE(pi2): 1.570e-04, MSE(pi3): 6.182e-03\n",
      "Epoch 38200, Train loss: 3.285e+03, Test loss: 1.494e+05, MSE(e): 2.419e-04, MSE(pi1): 2.601e-02, MSE(pi2): 1.506e-04, MSE(pi3): 6.057e-03\n",
      "Epoch 38300, Train loss: 3.170e+03, Test loss: 1.496e+05, MSE(e): 2.388e-04, MSE(pi1): 1.578e-02, MSE(pi2): 1.482e-04, MSE(pi3): 6.236e-03\n",
      "Epoch 38400, Train loss: 3.238e+03, Test loss: 1.492e+05, MSE(e): 2.374e-04, MSE(pi1): 2.421e-02, MSE(pi2): 1.474e-04, MSE(pi3): 6.226e-03\n",
      "Epoch 38500, Train loss: 3.145e+03, Test loss: 1.495e+05, MSE(e): 2.359e-04, MSE(pi1): 1.571e-02, MSE(pi2): 1.467e-04, MSE(pi3): 6.291e-03\n",
      "Epoch 38600, Train loss: 3.219e+03, Test loss: 1.496e+05, MSE(e): 2.439e-04, MSE(pi1): 1.671e-02, MSE(pi2): 1.503e-04, MSE(pi3): 6.132e-03\n",
      "Epoch 38700, Train loss: 3.112e+03, Test loss: 1.483e+05, MSE(e): 2.331e-04, MSE(pi1): 1.617e-02, MSE(pi2): 1.449e-04, MSE(pi3): 6.191e-03\n",
      "Epoch 38800, Train loss: 8.111e+03, Test loss: 1.489e+05, MSE(e): 7.204e-04, MSE(pi1): 2.066e-02, MSE(pi2): 3.491e-04, MSE(pi3): 7.005e-03\n",
      "Epoch 38900, Train loss: 3.350e+03, Test loss: 1.483e+05, MSE(e): 2.328e-04, MSE(pi1): 3.949e-02, MSE(pi2): 1.438e-04, MSE(pi3): 6.265e-03\n",
      "Epoch 39000, Train loss: 3.181e+03, Test loss: 1.477e+05, MSE(e): 2.378e-04, MSE(pi1): 2.001e-02, MSE(pi2): 1.473e-04, MSE(pi3): 6.022e-03\n",
      "Epoch 39100, Train loss: 3.897e+03, Test loss: 1.470e+05, MSE(e): 3.021e-04, MSE(pi1): 2.801e-02, MSE(pi2): 1.767e-04, MSE(pi3): 5.950e-03\n",
      "Epoch 39200, Train loss: 3.070e+03, Test loss: 1.465e+05, MSE(e): 2.287e-04, MSE(pi1): 1.602e-02, MSE(pi2): 1.417e-04, MSE(pi3): 6.229e-03\n",
      "Epoch 39300, Train loss: 3.039e+03, Test loss: 1.466e+05, MSE(e): 2.261e-04, MSE(pi1): 1.567e-02, MSE(pi2): 1.406e-04, MSE(pi3): 6.213e-03\n",
      "Epoch 39400, Train loss: 3.916e+03, Test loss: 1.460e+05, MSE(e): 3.091e-04, MSE(pi1): 2.140e-02, MSE(pi2): 1.756e-04, MSE(pi3): 6.104e-03\n",
      "Epoch 39500, Train loss: 3.021e+03, Test loss: 1.460e+05, MSE(e): 2.239e-04, MSE(pi1): 1.595e-02, MSE(pi2): 1.392e-04, MSE(pi3): 6.218e-03\n",
      "Epoch 39600, Train loss: 3.026e+03, Test loss: 1.455e+05, MSE(e): 2.249e-04, MSE(pi1): 1.523e-02, MSE(pi2): 1.391e-04, MSE(pi3): 6.250e-03\n",
      "Epoch 39700, Train loss: 3.023e+03, Test loss: 1.449e+05, MSE(e): 2.223e-04, MSE(pi1): 1.906e-02, MSE(pi2): 1.382e-04, MSE(pi3): 6.095e-03\n",
      "Epoch 39800, Train loss: 2.985e+03, Test loss: 1.448e+05, MSE(e): 2.207e-04, MSE(pi1): 1.551e-02, MSE(pi2): 1.371e-04, MSE(pi3): 6.229e-03\n",
      "Epoch 39900, Train loss: 3.201e+03, Test loss: 1.478e+05, MSE(e): 2.399e-04, MSE(pi1): 1.531e-02, MSE(pi2): 1.492e-04, MSE(pi3): 6.497e-03\n",
      "Epoch 40000, Train loss: 2.968e+03, Test loss: 1.448e+05, MSE(e): 2.188e-04, MSE(pi1): 1.548e-02, MSE(pi2): 1.359e-04, MSE(pi3): 6.251e-03\n",
      "Epoch 40100, Train loss: 3.000e+03, Test loss: 1.434e+05, MSE(e): 2.213e-04, MSE(pi1): 1.843e-02, MSE(pi2): 1.380e-04, MSE(pi3): 6.019e-03\n",
      "Epoch 40200, Train loss: 4.668e+03, Test loss: 1.462e+05, MSE(e): 3.859e-04, MSE(pi1): 2.273e-02, MSE(pi2): 2.102e-04, MSE(pi3): 5.814e-03\n",
      "Epoch 40300, Train loss: 2.928e+03, Test loss: 1.435e+05, MSE(e): 2.153e-04, MSE(pi1): 1.549e-02, MSE(pi2): 1.337e-04, MSE(pi3): 6.198e-03\n",
      "Epoch 40400, Train loss: 3.138e+03, Test loss: 1.422e+05, MSE(e): 2.320e-04, MSE(pi1): 2.020e-02, MSE(pi2): 1.393e-04, MSE(pi3): 6.149e-03\n",
      "Epoch 40500, Train loss: 2.907e+03, Test loss: 1.429e+05, MSE(e): 2.133e-04, MSE(pi1): 1.545e-02, MSE(pi2): 1.324e-04, MSE(pi3): 6.196e-03\n",
      "Epoch 40600, Train loss: 2.939e+03, Test loss: 1.431e+05, MSE(e): 2.145e-04, MSE(pi1): 1.545e-02, MSE(pi2): 1.333e-04, MSE(pi3): 6.392e-03\n",
      "Epoch 40700, Train loss: 2.896e+03, Test loss: 1.424e+05, MSE(e): 2.115e-04, MSE(pi1): 1.631e-02, MSE(pi2): 1.313e-04, MSE(pi3): 6.184e-03\n",
      "Epoch 40800, Train loss: 2.891e+03, Test loss: 1.420e+05, MSE(e): 2.117e-04, MSE(pi1): 1.496e-02, MSE(pi2): 1.309e-04, MSE(pi3): 6.247e-03\n",
      "Epoch 40900, Train loss: 3.155e+03, Test loss: 1.427e+05, MSE(e): 2.191e-04, MSE(pi1): 3.544e-02, MSE(pi2): 1.343e-04, MSE(pi3): 6.092e-03\n",
      "Epoch 41000, Train loss: 2.903e+03, Test loss: 1.410e+05, MSE(e): 2.092e-04, MSE(pi1): 2.034e-02, MSE(pi2): 1.296e-04, MSE(pi3): 6.082e-03\n",
      "Epoch 41100, Train loss: 7.599e+03, Test loss: 1.414e+05, MSE(e): 6.740e-04, MSE(pi1): 2.107e-02, MSE(pi2): 3.173e-04, MSE(pi3): 6.479e-03\n",
      "Epoch 41200, Train loss: 2.835e+03, Test loss: 1.409e+05, MSE(e): 2.063e-04, MSE(pi1): 1.528e-02, MSE(pi2): 1.280e-04, MSE(pi3): 6.194e-03\n",
      "Epoch 41300, Train loss: 2.981e+03, Test loss: 1.402e+05, MSE(e): 2.207e-04, MSE(pi1): 1.464e-02, MSE(pi2): 1.332e-04, MSE(pi3): 6.278e-03\n",
      "Epoch 41400, Train loss: 2.835e+03, Test loss: 1.413e+05, MSE(e): 2.063e-04, MSE(pi1): 1.526e-02, MSE(pi2): 1.278e-04, MSE(pi3): 6.190e-03\n",
      "Epoch 41500, Train loss: 2.806e+03, Test loss: 1.400e+05, MSE(e): 2.034e-04, MSE(pi1): 1.523e-02, MSE(pi2): 1.262e-04, MSE(pi3): 6.191e-03\n",
      "Epoch 41600, Train loss: 2.799e+03, Test loss: 1.399e+05, MSE(e): 2.025e-04, MSE(pi1): 1.535e-02, MSE(pi2): 1.256e-04, MSE(pi3): 6.203e-03\n",
      "Epoch 41700, Train loss: 2.791e+03, Test loss: 1.396e+05, MSE(e): 2.018e-04, MSE(pi1): 1.555e-02, MSE(pi2): 1.252e-04, MSE(pi3): 6.172e-03\n",
      "Epoch 41800, Train loss: 3.974e+03, Test loss: 1.388e+05, MSE(e): 3.173e-04, MSE(pi1): 1.544e-02, MSE(pi2): 1.712e-04, MSE(pi3): 6.459e-03\n",
      "Epoch 41900, Train loss: 2.997e+03, Test loss: 1.408e+05, MSE(e): 2.058e-04, MSE(pi1): 2.741e-02, MSE(pi2): 1.278e-04, MSE(pi3): 6.654e-03\n",
      "Epoch 42000, Train loss: 3.274e+03, Test loss: 1.385e+05, MSE(e): 2.478e-04, MSE(pi1): 1.912e-02, MSE(pi2): 1.452e-04, MSE(pi3): 6.045e-03\n",
      "Epoch 42100, Train loss: 2.872e+03, Test loss: 1.366e+05, MSE(e): 2.041e-04, MSE(pi1): 2.336e-02, MSE(pi2): 1.273e-04, MSE(pi3): 5.967e-03\n",
      "Epoch 42200, Train loss: 2.741e+03, Test loss: 1.382e+05, MSE(e): 1.970e-04, MSE(pi1): 1.496e-02, MSE(pi2): 1.220e-04, MSE(pi3): 6.217e-03\n",
      "Epoch 42300, Train loss: 2.779e+03, Test loss: 1.373e+05, MSE(e): 2.006e-04, MSE(pi1): 1.469e-02, MSE(pi2): 1.231e-04, MSE(pi3): 6.254e-03\n",
      "Epoch 42400, Train loss: 2.746e+03, Test loss: 1.375e+05, MSE(e): 1.976e-04, MSE(pi1): 1.459e-02, MSE(pi2): 1.217e-04, MSE(pi3): 6.240e-03\n",
      "Epoch 42500, Train loss: 3.295e+03, Test loss: 1.391e+05, MSE(e): 2.522e-04, MSE(pi1): 1.687e-02, MSE(pi2): 1.460e-04, MSE(pi3): 6.036e-03\n",
      "Epoch 42600, Train loss: 2.730e+03, Test loss: 1.365e+05, MSE(e): 1.943e-04, MSE(pi1): 1.785e-02, MSE(pi2): 1.204e-04, MSE(pi3): 6.079e-03\n",
      "Epoch 42700, Train loss: 2.699e+03, Test loss: 1.370e+05, MSE(e): 1.931e-04, MSE(pi1): 1.515e-02, MSE(pi2): 1.196e-04, MSE(pi3): 6.170e-03\n",
      "Epoch 42800, Train loss: 5.378e+03, Test loss: 1.362e+05, MSE(e): 4.588e-04, MSE(pi1): 1.249e-02, MSE(pi2): 2.290e-04, MSE(pi3): 6.652e-03\n",
      "Epoch 42900, Train loss: 2.697e+03, Test loss: 1.364e+05, MSE(e): 1.924e-04, MSE(pi1): 1.456e-02, MSE(pi2): 1.187e-04, MSE(pi3): 6.272e-03\n",
      "Epoch 43000, Train loss: 2.666e+03, Test loss: 1.362e+05, MSE(e): 1.898e-04, MSE(pi1): 1.484e-02, MSE(pi2): 1.176e-04, MSE(pi3): 6.196e-03\n",
      "Epoch 43100, Train loss: 2.660e+03, Test loss: 1.358e+05, MSE(e): 1.891e-04, MSE(pi1): 1.501e-02, MSE(pi2): 1.170e-04, MSE(pi3): 6.194e-03\n",
      "Epoch 43200, Train loss: 4.930e+03, Test loss: 1.312e+05, MSE(e): 4.154e-04, MSE(pi1): 1.272e-02, MSE(pi2): 2.090e-04, MSE(pi3): 6.486e-03\n",
      "Epoch 43300, Train loss: 2.896e+03, Test loss: 1.361e+05, MSE(e): 1.891e-04, MSE(pi1): 3.818e-02, MSE(pi2): 1.162e-04, MSE(pi3): 6.224e-03\n",
      "Epoch 43400, Train loss: 2.633e+03, Test loss: 1.351e+05, MSE(e): 1.866e-04, MSE(pi1): 1.465e-02, MSE(pi2): 1.154e-04, MSE(pi3): 6.204e-03\n",
      "Epoch 43500, Train loss: 2.623e+03, Test loss: 1.349e+05, MSE(e): 1.856e-04, MSE(pi1): 1.486e-02, MSE(pi2): 1.149e-04, MSE(pi3): 6.189e-03\n",
      "Epoch 43600, Train loss: 2.615e+03, Test loss: 1.348e+05, MSE(e): 1.848e-04, MSE(pi1): 1.484e-02, MSE(pi2): 1.144e-04, MSE(pi3): 6.182e-03\n",
      "Epoch 43700, Train loss: 3.653e+03, Test loss: 1.318e+05, MSE(e): 2.422e-04, MSE(pi1): 6.787e-02, MSE(pi2): 1.572e-04, MSE(pi3): 5.522e-03\n",
      "Epoch 43800, Train loss: 2.849e+03, Test loss: 1.352e+05, MSE(e): 2.076e-04, MSE(pi1): 1.704e-02, MSE(pi2): 1.248e-04, MSE(pi3): 6.025e-03\n",
      "Epoch 43900, Train loss: 3.957e+03, Test loss: 1.331e+05, MSE(e): 3.174e-04, MSE(pi1): 1.308e-02, MSE(pi2): 1.680e-04, MSE(pi3): 6.514e-03\n",
      "Epoch 44000, Train loss: 2.581e+03, Test loss: 1.336e+05, MSE(e): 1.815e-04, MSE(pi1): 1.492e-02, MSE(pi2): 1.123e-04, MSE(pi3): 6.165e-03\n",
      "Epoch 44100, Train loss: 2.583e+03, Test loss: 1.336e+05, MSE(e): 1.815e-04, MSE(pi1): 1.421e-02, MSE(pi2): 1.120e-04, MSE(pi3): 6.260e-03\n",
      "Epoch 44200, Train loss: 2.599e+03, Test loss: 1.324e+05, MSE(e): 1.832e-04, MSE(pi1): 1.465e-02, MSE(pi2): 1.124e-04, MSE(pi3): 6.210e-03\n",
      "Epoch 44300, Train loss: 2.665e+03, Test loss: 1.336e+05, MSE(e): 1.884e-04, MSE(pi1): 1.784e-02, MSE(pi2): 1.156e-04, MSE(pi3): 6.031e-03\n",
      "Epoch 44400, Train loss: 2.548e+03, Test loss: 1.327e+05, MSE(e): 1.784e-04, MSE(pi1): 1.452e-02, MSE(pi2): 1.102e-04, MSE(pi3): 6.193e-03\n",
      "Epoch 44500, Train loss: 2.546e+03, Test loss: 1.324e+05, MSE(e): 1.776e-04, MSE(pi1): 1.496e-02, MSE(pi2): 1.097e-04, MSE(pi3): 6.198e-03\n",
      "Epoch 44600, Train loss: 3.255e+03, Test loss: 1.319e+05, MSE(e): 2.360e-04, MSE(pi1): 2.829e-02, MSE(pi2): 1.307e-04, MSE(pi3): 6.116e-03\n",
      "Epoch 44700, Train loss: 2.524e+03, Test loss: 1.320e+05, MSE(e): 1.760e-04, MSE(pi1): 1.466e-02, MSE(pi2): 1.088e-04, MSE(pi3): 6.173e-03\n",
      "Epoch 44800, Train loss: 2.575e+03, Test loss: 1.319e+05, MSE(e): 1.808e-04, MSE(pi1): 1.612e-02, MSE(pi2): 1.114e-04, MSE(pi3): 6.059e-03\n",
      "Epoch 44900, Train loss: 2.512e+03, Test loss: 1.316e+05, MSE(e): 1.745e-04, MSE(pi1): 1.486e-02, MSE(pi2): 1.078e-04, MSE(pi3): 6.186e-03\n",
      "Epoch 45000, Train loss: 2.511e+03, Test loss: 1.314e+05, MSE(e): 1.747e-04, MSE(pi1): 1.401e-02, MSE(pi2): 1.077e-04, MSE(pi3): 6.236e-03\n",
      "Epoch 45100, Train loss: 2.533e+03, Test loss: 1.309e+05, MSE(e): 1.765e-04, MSE(pi1): 1.432e-02, MSE(pi2): 1.080e-04, MSE(pi3): 6.246e-03\n",
      "Epoch 45200, Train loss: 2.985e+03, Test loss: 1.330e+05, MSE(e): 2.094e-04, MSE(pi1): 3.100e-02, MSE(pi2): 1.259e-04, MSE(pi3): 5.800e-03\n",
      "Epoch 45300, Train loss: 2.485e+03, Test loss: 1.309e+05, MSE(e): 1.716e-04, MSE(pi1): 1.494e-02, MSE(pi2): 1.060e-04, MSE(pi3): 6.194e-03\n",
      "Epoch 45400, Train loss: 2.471e+03, Test loss: 1.306e+05, MSE(e): 1.708e-04, MSE(pi1): 1.426e-02, MSE(pi2): 1.055e-04, MSE(pi3): 6.203e-03\n",
      "Epoch 45500, Train loss: 2.488e+03, Test loss: 1.300e+05, MSE(e): 1.725e-04, MSE(pi1): 1.408e-02, MSE(pi2): 1.058e-04, MSE(pi3): 6.221e-03\n",
      "Epoch 45600, Train loss: 2.997e+03, Test loss: 1.318e+05, MSE(e): 2.232e-04, MSE(pi1): 1.615e-02, MSE(pi2): 1.283e-04, MSE(pi3): 6.034e-03\n",
      "Epoch 45700, Train loss: 2.453e+03, Test loss: 1.299e+05, MSE(e): 1.686e-04, MSE(pi1): 1.463e-02, MSE(pi2): 1.041e-04, MSE(pi3): 6.207e-03\n",
      "Epoch 45800, Train loss: 2.443e+03, Test loss: 1.294e+05, MSE(e): 1.681e-04, MSE(pi1): 1.468e-02, MSE(pi2): 1.039e-04, MSE(pi3): 6.154e-03\n",
      "Epoch 45900, Train loss: 2.594e+03, Test loss: 1.273e+05, MSE(e): 1.759e-04, MSE(pi1): 2.404e-02, MSE(pi2): 1.084e-04, MSE(pi3): 5.944e-03\n",
      "Epoch 46000, Train loss: 2.510e+03, Test loss: 1.298e+05, MSE(e): 1.749e-04, MSE(pi1): 1.513e-02, MSE(pi2): 1.068e-04, MSE(pi3): 6.100e-03\n",
      "Epoch 46100, Train loss: 2.470e+03, Test loss: 1.294e+05, MSE(e): 1.679e-04, MSE(pi1): 1.573e-02, MSE(pi2): 1.033e-04, MSE(pi3): 6.339e-03\n",
      "Epoch 46200, Train loss: 2.431e+03, Test loss: 1.283e+05, MSE(e): 1.664e-04, MSE(pi1): 1.564e-02, MSE(pi2): 1.028e-04, MSE(pi3): 6.104e-03\n",
      "Epoch 46300, Train loss: 4.341e+03, Test loss: 1.288e+05, MSE(e): 3.237e-04, MSE(pi1): 3.917e-02, MSE(pi2): 1.757e-04, MSE(pi3): 7.121e-03\n",
      "Epoch 46400, Train loss: 2.397e+03, Test loss: 1.283e+05, MSE(e): 1.636e-04, MSE(pi1): 1.432e-02, MSE(pi2): 1.010e-04, MSE(pi3): 6.174e-03\n",
      "Epoch 46500, Train loss: 2.522e+03, Test loss: 1.296e+05, MSE(e): 1.723e-04, MSE(pi1): 1.472e-02, MSE(pi2): 1.069e-04, MSE(pi3): 6.515e-03\n",
      "Epoch 46600, Train loss: 2.607e+03, Test loss: 1.287e+05, MSE(e): 1.833e-04, MSE(pi1): 1.784e-02, MSE(pi2): 1.113e-04, MSE(pi3): 5.958e-03\n",
      "Epoch 46700, Train loss: 2.376e+03, Test loss: 1.277e+05, MSE(e): 1.616e-04, MSE(pi1): 1.426e-02, MSE(pi2): 9.965e-05, MSE(pi3): 6.176e-03\n",
      "Epoch 46800, Train loss: 2.497e+03, Test loss: 1.287e+05, MSE(e): 1.700e-04, MSE(pi1): 1.725e-02, MSE(pi2): 1.031e-04, MSE(pi3): 6.247e-03\n",
      "Epoch 46900, Train loss: 4.263e+03, Test loss: 1.337e+05, MSE(e): 3.452e-04, MSE(pi1): 2.239e-02, MSE(pi2): 1.797e-04, MSE(pi3): 5.871e-03\n",
      "Epoch 47000, Train loss: 2.871e+03, Test loss: 1.257e+05, MSE(e): 1.748e-04, MSE(pi1): 5.519e-02, MSE(pi2): 1.098e-04, MSE(pi3): 5.718e-03\n",
      "Epoch 47100, Train loss: 2.365e+03, Test loss: 1.272e+05, MSE(e): 1.593e-04, MSE(pi1): 1.550e-02, MSE(pi2): 9.817e-05, MSE(pi3): 6.174e-03\n",
      "Epoch 47200, Train loss: 2.697e+03, Test loss: 1.269e+05, MSE(e): 1.827e-04, MSE(pi1): 2.869e-02, MSE(pi2): 1.117e-04, MSE(pi3): 5.834e-03\n",
      "Epoch 47300, Train loss: 2.451e+03, Test loss: 1.269e+05, MSE(e): 1.587e-04, MSE(pi1): 2.412e-02, MSE(pi2): 9.744e-05, MSE(pi3): 6.224e-03\n",
      "Epoch 47400, Train loss: 2.345e+03, Test loss: 1.267e+05, MSE(e): 1.584e-04, MSE(pi1): 1.461e-02, MSE(pi2): 9.752e-05, MSE(pi3): 6.148e-03\n",
      "Epoch 47500, Train loss: 2.322e+03, Test loss: 1.260e+05, MSE(e): 1.563e-04, MSE(pi1): 1.430e-02, MSE(pi2): 9.630e-05, MSE(pi3): 6.158e-03\n",
      "Epoch 47600, Train loss: 2.381e+03, Test loss: 1.268e+05, MSE(e): 1.621e-04, MSE(pi1): 1.436e-02, MSE(pi2): 9.897e-05, MSE(pi3): 6.156e-03\n",
      "Epoch 47700, Train loss: 2.612e+03, Test loss: 1.263e+05, MSE(e): 1.840e-04, MSE(pi1): 1.754e-02, MSE(pi2): 1.094e-04, MSE(pi3): 5.966e-03\n",
      "Epoch 47800, Train loss: 2.312e+03, Test loss: 1.256e+05, MSE(e): 1.547e-04, MSE(pi1): 1.425e-02, MSE(pi2): 9.530e-05, MSE(pi3): 6.217e-03\n",
      "Epoch 47900, Train loss: 2.344e+03, Test loss: 1.261e+05, MSE(e): 1.567e-04, MSE(pi1): 1.550e-02, MSE(pi2): 9.610e-05, MSE(pi3): 6.214e-03\n",
      "Epoch 48000, Train loss: 2.385e+03, Test loss: 1.243e+05, MSE(e): 1.599e-04, MSE(pi1): 1.645e-02, MSE(pi2): 9.656e-05, MSE(pi3): 6.213e-03\n",
      "Epoch 48100, Train loss: 2.294e+03, Test loss: 1.246e+05, MSE(e): 1.529e-04, MSE(pi1): 1.557e-02, MSE(pi2): 9.430e-05, MSE(pi3): 6.086e-03\n",
      "Epoch 48200, Train loss: 2.277e+03, Test loss: 1.248e+05, MSE(e): 1.519e-04, MSE(pi1): 1.410e-02, MSE(pi2): 9.348e-05, MSE(pi3): 6.169e-03\n",
      "Epoch 48300, Train loss: 2.394e+03, Test loss: 1.234e+05, MSE(e): 1.605e-04, MSE(pi1): 1.789e-02, MSE(pi2): 9.634e-05, MSE(pi3): 6.099e-03\n",
      "Epoch 48400, Train loss: 2.301e+03, Test loss: 1.247e+05, MSE(e): 1.543e-04, MSE(pi1): 1.473e-02, MSE(pi2): 9.466e-05, MSE(pi3): 6.106e-03\n",
      "Epoch 48500, Train loss: 2.403e+03, Test loss: 1.234e+05, MSE(e): 1.644e-04, MSE(pi1): 1.344e-02, MSE(pi2): 9.764e-05, MSE(pi3): 6.246e-03\n",
      "Epoch 48600, Train loss: 2.845e+03, Test loss: 1.273e+05, MSE(e): 2.078e-04, MSE(pi1): 1.675e-02, MSE(pi2): 1.180e-04, MSE(pi3): 5.997e-03\n",
      "Epoch 48700, Train loss: 2.284e+03, Test loss: 1.231e+05, MSE(e): 1.499e-04, MSE(pi1): 1.817e-02, MSE(pi2): 9.244e-05, MSE(pi3): 6.031e-03\n",
      "Epoch 48800, Train loss: 2.881e+03, Test loss: 1.223e+05, MSE(e): 2.106e-04, MSE(pi1): 1.480e-02, MSE(pi2): 1.153e-04, MSE(pi3): 6.267e-03\n",
      "Epoch 48900, Train loss: 2.658e+03, Test loss: 1.218e+05, MSE(e): 1.843e-04, MSE(pi1): 2.423e-02, MSE(pi2): 1.184e-04, MSE(pi3): 5.732e-03\n",
      "Epoch 49000, Train loss: 2.238e+03, Test loss: 1.234e+05, MSE(e): 1.482e-04, MSE(pi1): 1.416e-02, MSE(pi2): 9.112e-05, MSE(pi3): 6.144e-03\n",
      "Epoch 49100, Train loss: 2.227e+03, Test loss: 1.233e+05, MSE(e): 1.469e-04, MSE(pi1): 1.407e-02, MSE(pi2): 9.036e-05, MSE(pi3): 6.172e-03\n",
      "Epoch 49200, Train loss: 2.218e+03, Test loss: 1.231e+05, MSE(e): 1.461e-04, MSE(pi1): 1.385e-02, MSE(pi2): 8.985e-05, MSE(pi3): 6.188e-03\n",
      "Epoch 49300, Train loss: 2.640e+03, Test loss: 1.224e+05, MSE(e): 1.812e-04, MSE(pi1): 1.769e-02, MSE(pi2): 1.047e-04, MSE(pi3): 6.512e-03\n",
      "Epoch 49400, Train loss: 2.773e+03, Test loss: 1.203e+05, MSE(e): 1.856e-04, MSE(pi1): 3.522e-02, MSE(pi2): 1.174e-04, MSE(pi3): 5.653e-03\n",
      "Epoch 49500, Train loss: 2.672e+03, Test loss: 1.209e+05, MSE(e): 1.875e-04, MSE(pi1): 1.609e-02, MSE(pi2): 1.055e-04, MSE(pi3): 6.360e-03\n",
      "Epoch 49600, Train loss: 3.098e+03, Test loss: 1.259e+05, MSE(e): 2.007e-04, MSE(pi1): 3.715e-02, MSE(pi2): 1.265e-04, MSE(pi3): 7.193e-03\n",
      "Epoch 49700, Train loss: 2.942e+03, Test loss: 1.208e+05, MSE(e): 2.106e-04, MSE(pi1): 1.941e-02, MSE(pi2): 1.147e-04, MSE(pi3): 6.410e-03\n",
      "Epoch 49800, Train loss: 2.192e+03, Test loss: 1.213e+05, MSE(e): 1.430e-04, MSE(pi1): 1.513e-02, MSE(pi2): 8.783e-05, MSE(pi3): 6.104e-03\n",
      "Epoch 49900, Train loss: 2.175e+03, Test loss: 1.216e+05, MSE(e): 1.420e-04, MSE(pi1): 1.383e-02, MSE(pi2): 8.728e-05, MSE(pi3): 6.163e-03\n",
      "Epoch 50000, Train loss: 2.243e+03, Test loss: 1.212e+05, MSE(e): 1.479e-04, MSE(pi1): 1.402e-02, MSE(pi2): 8.931e-05, MSE(pi3): 6.236e-03\n",
      "Epoch 50100, Train loss: 2.163e+03, Test loss: 1.212e+05, MSE(e): 1.409e-04, MSE(pi1): 1.379e-02, MSE(pi2): 8.658e-05, MSE(pi3): 6.162e-03\n",
      "Epoch 50200, Train loss: 2.158e+03, Test loss: 1.209e+05, MSE(e): 1.404e-04, MSE(pi1): 1.389e-02, MSE(pi2): 8.626e-05, MSE(pi3): 6.152e-03\n",
      "Epoch 50300, Train loss: 2.281e+03, Test loss: 1.213e+05, MSE(e): 1.517e-04, MSE(pi1): 1.308e-02, MSE(pi2): 9.067e-05, MSE(pi3): 6.338e-03\n",
      "Epoch 50400, Train loss: 2.162e+03, Test loss: 1.209e+05, MSE(e): 1.394e-04, MSE(pi1): 1.499e-02, MSE(pi2): 8.556e-05, MSE(pi3): 6.183e-03\n",
      "Epoch 50500, Train loss: 2.145e+03, Test loss: 1.204e+05, MSE(e): 1.391e-04, MSE(pi1): 1.364e-02, MSE(pi2): 8.527e-05, MSE(pi3): 6.174e-03\n",
      "Epoch 50600, Train loss: 2.145e+03, Test loss: 1.208e+05, MSE(e): 1.392e-04, MSE(pi1): 1.371e-02, MSE(pi2): 8.544e-05, MSE(pi3): 6.164e-03\n",
      "Epoch 50700, Train loss: 2.135e+03, Test loss: 1.204e+05, MSE(e): 1.380e-04, MSE(pi1): 1.414e-02, MSE(pi2): 8.481e-05, MSE(pi3): 6.135e-03\n",
      "Epoch 50800, Train loss: 3.035e+03, Test loss: 1.193e+05, MSE(e): 2.227e-04, MSE(pi1): 1.551e-02, MSE(pi2): 1.199e-04, MSE(pi3): 6.523e-03\n",
      "Epoch 50900, Train loss: 2.132e+03, Test loss: 1.199e+05, MSE(e): 1.374e-04, MSE(pi1): 1.478e-02, MSE(pi2): 8.441e-05, MSE(pi3): 6.106e-03\n",
      "Epoch 51000, Train loss: 2.116e+03, Test loss: 1.198e+05, MSE(e): 1.363e-04, MSE(pi1): 1.388e-02, MSE(pi2): 8.369e-05, MSE(pi3): 6.145e-03\n",
      "Epoch 51100, Train loss: 2.110e+03, Test loss: 1.196e+05, MSE(e): 1.357e-04, MSE(pi1): 1.370e-02, MSE(pi2): 8.332e-05, MSE(pi3): 6.159e-03\n",
      "Epoch 51200, Train loss: 2.108e+03, Test loss: 1.194e+05, MSE(e): 1.353e-04, MSE(pi1): 1.349e-02, MSE(pi2): 8.295e-05, MSE(pi3): 6.195e-03\n",
      "Epoch 51300, Train loss: 2.819e+03, Test loss: 1.181e+05, MSE(e): 2.009e-04, MSE(pi1): 1.872e-02, MSE(pi2): 1.077e-04, MSE(pi3): 6.224e-03\n",
      "Epoch 51400, Train loss: 2.923e+03, Test loss: 1.240e+05, MSE(e): 1.757e-04, MSE(pi1): 4.537e-02, MSE(pi2): 1.121e-04, MSE(pi3): 7.125e-03\n",
      "Epoch 51500, Train loss: 2.119e+03, Test loss: 1.188e+05, MSE(e): 1.353e-04, MSE(pi1): 1.460e-02, MSE(pi2): 8.245e-05, MSE(pi3): 6.199e-03\n",
      "Epoch 51600, Train loss: 2.493e+03, Test loss: 1.195e+05, MSE(e): 1.738e-04, MSE(pi1): 1.592e-02, MSE(pi2): 1.006e-04, MSE(pi3): 5.962e-03\n",
      "Epoch 51700, Train loss: 2.127e+03, Test loss: 1.187e+05, MSE(e): 1.340e-04, MSE(pi1): 1.796e-02, MSE(pi2): 8.238e-05, MSE(pi3): 6.070e-03\n",
      "Epoch 51800, Train loss: 3.876e+03, Test loss: 1.284e+05, MSE(e): 2.947e-04, MSE(pi1): 2.587e-02, MSE(pi2): 1.611e-04, MSE(pi3): 6.699e-03\n",
      "Epoch 51900, Train loss: 2.576e+03, Test loss: 1.194e+05, MSE(e): 1.398e-04, MSE(pi1): 5.603e-02, MSE(pi2): 8.364e-05, MSE(pi3): 6.178e-03\n",
      "Epoch 52000, Train loss: 2.064e+03, Test loss: 1.181e+05, MSE(e): 1.312e-04, MSE(pi1): 1.350e-02, MSE(pi2): 8.047e-05, MSE(pi3): 6.164e-03\n",
      "Epoch 52100, Train loss: 2.078e+03, Test loss: 1.183e+05, MSE(e): 1.310e-04, MSE(pi1): 1.418e-02, MSE(pi2): 8.031e-05, MSE(pi3): 6.253e-03\n",
      "Epoch 52200, Train loss: 4.456e+03, Test loss: 1.272e+05, MSE(e): 3.646e-04, MSE(pi1): 1.945e-02, MSE(pi2): 1.798e-04, MSE(pi3): 6.151e-03\n",
      "Epoch 52300, Train loss: 2.050e+03, Test loss: 1.176e+05, MSE(e): 1.298e-04, MSE(pi1): 1.364e-02, MSE(pi2): 7.958e-05, MSE(pi3): 6.156e-03\n",
      "Epoch 52400, Train loss: 2.045e+03, Test loss: 1.177e+05, MSE(e): 1.294e-04, MSE(pi1): 1.355e-02, MSE(pi2): 7.934e-05, MSE(pi3): 6.157e-03\n",
      "Epoch 52500, Train loss: 2.076e+03, Test loss: 1.176e+05, MSE(e): 1.295e-04, MSE(pi1): 1.500e-02, MSE(pi2): 7.927e-05, MSE(pi3): 6.311e-03\n",
      "Epoch 52600, Train loss: 2.041e+03, Test loss: 1.173e+05, MSE(e): 1.285e-04, MSE(pi1): 1.405e-02, MSE(pi2): 7.871e-05, MSE(pi3): 6.155e-03\n",
      "Epoch 52700, Train loss: 2.153e+03, Test loss: 1.185e+05, MSE(e): 1.398e-04, MSE(pi1): 1.430e-02, MSE(pi2): 8.382e-05, MSE(pi3): 6.124e-03\n",
      "Epoch 52800, Train loss: 2.435e+03, Test loss: 1.165e+05, MSE(e): 1.657e-04, MSE(pi1): 1.331e-02, MSE(pi2): 9.394e-05, MSE(pi3): 6.445e-03\n",
      "Epoch 52900, Train loss: 4.969e+03, Test loss: 1.164e+05, MSE(e): 4.193e-04, MSE(pi1): 1.021e-02, MSE(pi2): 2.000e-04, MSE(pi3): 6.732e-03\n",
      "Epoch 53000, Train loss: 2.516e+03, Test loss: 1.200e+05, MSE(e): 1.531e-04, MSE(pi1): 2.995e-02, MSE(pi2): 9.651e-05, MSE(pi3): 6.857e-03\n",
      "Epoch 53100, Train loss: 2.064e+03, Test loss: 1.158e+05, MSE(e): 1.313e-04, MSE(pi1): 1.299e-02, MSE(pi2): 7.905e-05, MSE(pi3): 6.207e-03\n",
      "Epoch 53200, Train loss: 2.161e+03, Test loss: 1.166e+05, MSE(e): 1.401e-04, MSE(pi1): 1.679e-02, MSE(pi2): 8.675e-05, MSE(pi3): 5.923e-03\n",
      "Epoch 53300, Train loss: 2.017e+03, Test loss: 1.165e+05, MSE(e): 1.254e-04, MSE(pi1): 1.430e-02, MSE(pi2): 7.680e-05, MSE(pi3): 6.193e-03\n",
      "Epoch 53400, Train loss: 3.372e+03, Test loss: 1.227e+05, MSE(e): 2.528e-04, MSE(pi1): 2.087e-02, MSE(pi2): 1.339e-04, MSE(pi3): 6.345e-03\n",
      "Epoch 53500, Train loss: 2.352e+03, Test loss: 1.172e+05, MSE(e): 1.307e-04, MSE(pi1): 4.331e-02, MSE(pi2): 7.883e-05, MSE(pi3): 6.120e-03\n",
      "Epoch 53600, Train loss: 1.990e+03, Test loss: 1.156e+05, MSE(e): 1.240e-04, MSE(pi1): 1.338e-02, MSE(pi2): 7.589e-05, MSE(pi3): 6.157e-03\n",
      "Epoch 53700, Train loss: 2.194e+03, Test loss: 1.152e+05, MSE(e): 1.442e-04, MSE(pi1): 1.231e-02, MSE(pi2): 8.357e-05, MSE(pi3): 6.290e-03\n",
      "Epoch 53800, Train loss: 4.183e+03, Test loss: 1.163e+05, MSE(e): 3.109e-04, MSE(pi1): 5.229e-02, MSE(pi2): 1.744e-04, MSE(pi3): 5.511e-03\n",
      "Epoch 53900, Train loss: 1.980e+03, Test loss: 1.150e+05, MSE(e): 1.230e-04, MSE(pi1): 1.320e-02, MSE(pi2): 7.514e-05, MSE(pi3): 6.172e-03\n",
      "Epoch 54000, Train loss: 1.973e+03, Test loss: 1.150e+05, MSE(e): 1.224e-04, MSE(pi1): 1.346e-02, MSE(pi2): 7.484e-05, MSE(pi3): 6.147e-03\n",
      "Epoch 54100, Train loss: 2.428e+03, Test loss: 1.150e+05, MSE(e): 1.612e-04, MSE(pi1): 1.602e-02, MSE(pi2): 9.265e-05, MSE(pi3): 6.553e-03\n",
      "Epoch 54200, Train loss: 2.113e+03, Test loss: 1.152e+05, MSE(e): 1.358e-04, MSE(pi1): 1.534e-02, MSE(pi2): 8.142e-05, MSE(pi3): 6.010e-03\n",
      "Epoch 54300, Train loss: 4.042e+03, Test loss: 1.104e+05, MSE(e): 3.206e-04, MSE(pi1): 2.397e-02, MSE(pi2): 1.586e-04, MSE(pi3): 5.966e-03\n",
      "Epoch 54400, Train loss: 1.955e+03, Test loss: 1.146e+05, MSE(e): 1.206e-04, MSE(pi1): 1.335e-02, MSE(pi2): 7.385e-05, MSE(pi3): 6.149e-03\n",
      "Epoch 54500, Train loss: 1.950e+03, Test loss: 1.145e+05, MSE(e): 1.202e-04, MSE(pi1): 1.323e-02, MSE(pi2): 7.353e-05, MSE(pi3): 6.160e-03\n",
      "Epoch 54600, Train loss: 1.964e+03, Test loss: 1.146e+05, MSE(e): 1.201e-04, MSE(pi1): 1.523e-02, MSE(pi2): 7.340e-05, MSE(pi3): 6.112e-03\n",
      "Epoch 54700, Train loss: 2.106e+03, Test loss: 1.163e+05, MSE(e): 1.346e-04, MSE(pi1): 1.515e-02, MSE(pi2): 8.026e-05, MSE(pi3): 6.082e-03\n",
      "Epoch 54800, Train loss: 3.093e+03, Test loss: 1.123e+05, MSE(e): 2.198e-04, MSE(pi1): 2.466e-02, MSE(pi2): 1.135e-04, MSE(pi3): 6.481e-03\n",
      "Epoch 54900, Train loss: 1.934e+03, Test loss: 1.138e+05, MSE(e): 1.186e-04, MSE(pi1): 1.317e-02, MSE(pi2): 7.250e-05, MSE(pi3): 6.163e-03\n",
      "Epoch 55000, Train loss: 2.007e+03, Test loss: 1.134e+05, MSE(e): 1.258e-04, MSE(pi1): 1.243e-02, MSE(pi2): 7.507e-05, MSE(pi3): 6.253e-03\n",
      "Epoch 55100, Train loss: 1.964e+03, Test loss: 1.133e+05, MSE(e): 1.188e-04, MSE(pi1): 1.727e-02, MSE(pi2): 7.277e-05, MSE(pi3): 6.031e-03\n",
      "Epoch 55200, Train loss: 1.926e+03, Test loss: 1.137e+05, MSE(e): 1.177e-04, MSE(pi1): 1.330e-02, MSE(pi2): 7.197e-05, MSE(pi3): 6.161e-03\n",
      "Epoch 55300, Train loss: 2.006e+03, Test loss: 1.130e+05, MSE(e): 1.212e-04, MSE(pi1): 2.029e-02, MSE(pi2): 7.474e-05, MSE(pi3): 5.913e-03\n",
      "Epoch 55400, Train loss: 1.919e+03, Test loss: 1.128e+05, MSE(e): 1.167e-04, MSE(pi1): 1.396e-02, MSE(pi2): 7.141e-05, MSE(pi3): 6.123e-03\n",
      "Epoch 55500, Train loss: 1.910e+03, Test loss: 1.130e+05, MSE(e): 1.162e-04, MSE(pi1): 1.331e-02, MSE(pi2): 7.108e-05, MSE(pi3): 6.142e-03\n",
      "Epoch 55600, Train loss: 1.908e+03, Test loss: 1.129e+05, MSE(e): 1.160e-04, MSE(pi1): 1.350e-02, MSE(pi2): 7.096e-05, MSE(pi3): 6.126e-03\n",
      "Epoch 55700, Train loss: 1.924e+03, Test loss: 1.131e+05, MSE(e): 1.175e-04, MSE(pi1): 1.385e-02, MSE(pi2): 7.176e-05, MSE(pi3): 6.096e-03\n",
      "Epoch 55800, Train loss: 2.066e+03, Test loss: 1.144e+05, MSE(e): 1.312e-04, MSE(pi1): 1.510e-02, MSE(pi2): 7.805e-05, MSE(pi3): 6.026e-03\n",
      "Epoch 55900, Train loss: 1.962e+03, Test loss: 1.115e+05, MSE(e): 1.199e-04, MSE(pi1): 1.540e-02, MSE(pi2): 7.188e-05, MSE(pi3): 6.091e-03\n",
      "Epoch 56000, Train loss: 1.943e+03, Test loss: 1.124e+05, MSE(e): 1.167e-04, MSE(pi1): 1.710e-02, MSE(pi2): 7.147e-05, MSE(pi3): 6.050e-03\n",
      "Epoch 56100, Train loss: 1.887e+03, Test loss: 1.120e+05, MSE(e): 1.140e-04, MSE(pi1): 1.328e-02, MSE(pi2): 6.968e-05, MSE(pi3): 6.138e-03\n",
      "Epoch 56200, Train loss: 1.915e+03, Test loss: 1.126e+05, MSE(e): 1.150e-04, MSE(pi1): 1.427e-02, MSE(pi2): 6.992e-05, MSE(pi3): 6.225e-03\n",
      "Epoch 56300, Train loss: 1.886e+03, Test loss: 1.121e+05, MSE(e): 1.138e-04, MSE(pi1): 1.307e-02, MSE(pi2): 6.951e-05, MSE(pi3): 6.173e-03\n",
      "Epoch 56400, Train loss: 3.117e+03, Test loss: 1.181e+05, MSE(e): 2.303e-04, MSE(pi1): 1.719e-02, MSE(pi2): 1.230e-04, MSE(pi3): 6.418e-03\n",
      "Epoch 56500, Train loss: 1.889e+03, Test loss: 1.119e+05, MSE(e): 1.139e-04, MSE(pi1): 1.392e-02, MSE(pi2): 6.953e-05, MSE(pi3): 6.113e-03\n",
      "Epoch 56600, Train loss: 1.889e+03, Test loss: 1.113e+05, MSE(e): 1.127e-04, MSE(pi1): 1.555e-02, MSE(pi2): 6.881e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 56700, Train loss: 2.094e+03, Test loss: 1.112e+05, MSE(e): 1.332e-04, MSE(pi1): 1.582e-02, MSE(pi2): 7.846e-05, MSE(pi3): 6.031e-03\n",
      "Epoch 56800, Train loss: 1.862e+03, Test loss: 1.111e+05, MSE(e): 1.115e-04, MSE(pi1): 1.333e-02, MSE(pi2): 6.802e-05, MSE(pi3): 6.142e-03\n",
      "Epoch 56900, Train loss: 1.867e+03, Test loss: 1.116e+05, MSE(e): 1.121e-04, MSE(pi1): 1.354e-02, MSE(pi2): 6.845e-05, MSE(pi3): 6.112e-03\n",
      "Epoch 57000, Train loss: 1.876e+03, Test loss: 1.109e+05, MSE(e): 1.115e-04, MSE(pi1): 1.561e-02, MSE(pi2): 6.831e-05, MSE(pi3): 6.044e-03\n",
      "Epoch 57100, Train loss: 1.864e+03, Test loss: 1.113e+05, MSE(e): 1.109e-04, MSE(pi1): 1.320e-02, MSE(pi2): 6.765e-05, MSE(pi3): 6.234e-03\n",
      "Epoch 57200, Train loss: 1.852e+03, Test loss: 1.112e+05, MSE(e): 1.104e-04, MSE(pi1): 1.310e-02, MSE(pi2): 6.739e-05, MSE(pi3): 6.171e-03\n",
      "Epoch 57300, Train loss: 1.922e+03, Test loss: 1.104e+05, MSE(e): 1.173e-04, MSE(pi1): 1.270e-02, MSE(pi2): 6.955e-05, MSE(pi3): 6.225e-03\n",
      "Epoch 57400, Train loss: 1.867e+03, Test loss: 1.111e+05, MSE(e): 1.104e-04, MSE(pi1): 1.344e-02, MSE(pi2): 6.733e-05, MSE(pi3): 6.293e-03\n",
      "Epoch 57500, Train loss: 1.878e+03, Test loss: 1.099e+05, MSE(e): 1.129e-04, MSE(pi1): 1.290e-02, MSE(pi2): 6.778e-05, MSE(pi3): 6.198e-03\n",
      "Epoch 57600, Train loss: 1.832e+03, Test loss: 1.104e+05, MSE(e): 1.087e-04, MSE(pi1): 1.311e-02, MSE(pi2): 6.638e-05, MSE(pi3): 6.140e-03\n",
      "Epoch 57700, Train loss: 2.026e+03, Test loss: 1.099e+05, MSE(e): 1.118e-04, MSE(pi1): 3.194e-02, MSE(pi2): 6.859e-05, MSE(pi3): 5.884e-03\n",
      "Epoch 57800, Train loss: 3.205e+03, Test loss: 1.148e+05, MSE(e): 2.320e-04, MSE(pi1): 3.135e-02, MSE(pi2): 1.247e-04, MSE(pi3): 5.712e-03\n",
      "Epoch 57900, Train loss: 1.841e+03, Test loss: 1.100e+05, MSE(e): 1.079e-04, MSE(pi1): 1.480e-02, MSE(pi2): 6.569e-05, MSE(pi3): 6.141e-03\n",
      "Epoch 58000, Train loss: 2.200e+03, Test loss: 1.106e+05, MSE(e): 1.362e-04, MSE(pi1): 2.203e-02, MSE(pi2): 7.554e-05, MSE(pi3): 6.175e-03\n",
      "Epoch 58100, Train loss: 1.814e+03, Test loss: 1.097e+05, MSE(e): 1.070e-04, MSE(pi1): 1.298e-02, MSE(pi2): 6.524e-05, MSE(pi3): 6.148e-03\n",
      "Epoch 58200, Train loss: 2.089e+03, Test loss: 1.122e+05, MSE(e): 1.342e-04, MSE(pi1): 1.315e-02, MSE(pi2): 7.755e-05, MSE(pi3): 6.154e-03\n",
      "Epoch 58300, Train loss: 1.808e+03, Test loss: 1.101e+05, MSE(e): 1.064e-04, MSE(pi1): 1.308e-02, MSE(pi2): 6.485e-05, MSE(pi3): 6.140e-03\n",
      "Epoch 58400, Train loss: 1.841e+03, Test loss: 1.099e+05, MSE(e): 1.070e-04, MSE(pi1): 1.473e-02, MSE(pi2): 6.520e-05, MSE(pi3): 6.232e-03\n",
      "Epoch 58500, Train loss: 1.908e+03, Test loss: 1.106e+05, MSE(e): 1.164e-04, MSE(pi1): 1.356e-02, MSE(pi2): 6.948e-05, MSE(pi3): 6.086e-03\n",
      "Epoch 58600, Train loss: 1.890e+03, Test loss: 1.092e+05, MSE(e): 1.062e-04, MSE(pi1): 2.192e-02, MSE(pi2): 6.459e-05, MSE(pi3): 6.086e-03\n",
      "Epoch 58700, Train loss: 3.703e+03, Test loss: 1.100e+05, MSE(e): 2.633e-04, MSE(pi1): 3.292e-02, MSE(pi2): 1.478e-04, MSE(pi3): 7.410e-03\n",
      "Epoch 58800, Train loss: 2.122e+03, Test loss: 1.075e+05, MSE(e): 1.340e-04, MSE(pi1): 1.539e-02, MSE(pi2): 7.530e-05, MSE(pi3): 6.281e-03\n",
      "Epoch 58900, Train loss: 2.192e+03, Test loss: 1.072e+05, MSE(e): 1.445e-04, MSE(pi1): 1.181e-02, MSE(pi2): 7.919e-05, MSE(pi3): 6.286e-03\n",
      "Epoch 59000, Train loss: 1.961e+03, Test loss: 1.077e+05, MSE(e): 1.141e-04, MSE(pi1): 2.358e-02, MSE(pi2): 7.137e-05, MSE(pi3): 5.838e-03\n",
      "Epoch 59100, Train loss: 1.787e+03, Test loss: 1.082e+05, MSE(e): 1.043e-04, MSE(pi1): 1.294e-02, MSE(pi2): 6.332e-05, MSE(pi3): 6.148e-03\n",
      "Epoch 59200, Train loss: 1.784e+03, Test loss: 1.087e+05, MSE(e): 1.040e-04, MSE(pi1): 1.290e-02, MSE(pi2): 6.337e-05, MSE(pi3): 6.151e-03\n",
      "Epoch 59300, Train loss: 2.124e+03, Test loss: 1.085e+05, MSE(e): 1.059e-04, MSE(pi1): 4.362e-02, MSE(pi2): 6.324e-05, MSE(pi3): 6.291e-03\n",
      "Epoch 59400, Train loss: 1.909e+03, Test loss: 1.091e+05, MSE(e): 1.118e-04, MSE(pi1): 1.964e-02, MSE(pi2): 6.768e-05, MSE(pi3): 5.945e-03\n",
      "Epoch 59500, Train loss: 2.281e+03, Test loss: 1.089e+05, MSE(e): 1.523e-04, MSE(pi1): 1.654e-02, MSE(pi2): 8.552e-05, MSE(pi3): 5.924e-03\n",
      "Epoch 59600, Train loss: 2.537e+03, Test loss: 1.065e+05, MSE(e): 1.599e-04, MSE(pi1): 3.800e-02, MSE(pi2): 1.052e-04, MSE(pi3): 5.578e-03\n",
      "Epoch 59700, Train loss: 1.766e+03, Test loss: 1.075e+05, MSE(e): 1.020e-04, MSE(pi1): 1.337e-02, MSE(pi2): 6.221e-05, MSE(pi3): 6.123e-03\n",
      "Epoch 59800, Train loss: 1.774e+03, Test loss: 1.071e+05, MSE(e): 1.029e-04, MSE(pi1): 1.306e-02, MSE(pi2): 6.225e-05, MSE(pi3): 6.139e-03\n",
      "Epoch 59900, Train loss: 2.036e+03, Test loss: 1.066e+05, MSE(e): 1.264e-04, MSE(pi1): 1.402e-02, MSE(pi2): 7.146e-05, MSE(pi3): 6.322e-03\n",
      "Epoch 60000, Train loss: 2.581e+03, Test loss: 1.065e+05, MSE(e): 1.689e-04, MSE(pi1): 3.403e-02, MSE(pi2): 1.107e-04, MSE(pi3): 5.520e-03\n",
      "Epoch 60100, Train loss: 1.796e+03, Test loss: 1.068e+05, MSE(e): 1.052e-04, MSE(pi1): 1.224e-02, MSE(pi2): 6.287e-05, MSE(pi3): 6.221e-03\n",
      "Epoch 60200, Train loss: 1.783e+03, Test loss: 1.072e+05, MSE(e): 1.036e-04, MSE(pi1): 1.252e-02, MSE(pi2): 6.218e-05, MSE(pi3): 6.224e-03\n",
      "Epoch 60300, Train loss: 1.836e+03, Test loss: 1.082e+05, MSE(e): 1.082e-04, MSE(pi1): 1.466e-02, MSE(pi2): 6.493e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 60400, Train loss: 1.785e+03, Test loss: 1.067e+05, MSE(e): 1.032e-04, MSE(pi1): 1.495e-02, MSE(pi2): 6.349e-05, MSE(pi3): 6.029e-03\n",
      "Epoch 60500, Train loss: 2.025e+03, Test loss: 1.071e+05, MSE(e): 1.263e-04, MSE(pi1): 1.626e-02, MSE(pi2): 7.306e-05, MSE(pi3): 5.994e-03\n",
      "Epoch 60600, Train loss: 1.735e+03, Test loss: 1.067e+05, MSE(e): 9.920e-05, MSE(pi1): 1.290e-02, MSE(pi2): 6.040e-05, MSE(pi3): 6.135e-03\n",
      "Epoch 60700, Train loss: 2.305e+03, Test loss: 1.044e+05, MSE(e): 1.556e-04, MSE(pi1): 1.201e-02, MSE(pi2): 8.257e-05, MSE(pi3): 6.287e-03\n",
      "Epoch 60800, Train loss: 1.729e+03, Test loss: 1.066e+05, MSE(e): 9.866e-05, MSE(pi1): 1.274e-02, MSE(pi2): 6.007e-05, MSE(pi3): 6.149e-03\n",
      "Epoch 60900, Train loss: 1.767e+03, Test loss: 1.061e+05, MSE(e): 9.956e-05, MSE(pi1): 1.660e-02, MSE(pi2): 6.024e-05, MSE(pi3): 6.055e-03\n",
      "Epoch 61000, Train loss: 1.837e+03, Test loss: 1.061e+05, MSE(e): 1.085e-04, MSE(pi1): 1.216e-02, MSE(pi2): 6.378e-05, MSE(pi3): 6.303e-03\n",
      "Epoch 61100, Train loss: 2.064e+03, Test loss: 1.051e+05, MSE(e): 1.310e-04, MSE(pi1): 1.170e-02, MSE(pi2): 7.298e-05, MSE(pi3): 6.375e-03\n",
      "Epoch 61200, Train loss: 1.792e+03, Test loss: 1.057e+05, MSE(e): 9.940e-05, MSE(pi1): 2.003e-02, MSE(pi2): 6.053e-05, MSE(pi3): 5.982e-03\n",
      "Epoch 61300, Train loss: 1.902e+03, Test loss: 1.055e+05, MSE(e): 1.142e-04, MSE(pi1): 1.611e-02, MSE(pi2): 6.815e-05, MSE(pi3): 5.982e-03\n",
      "Epoch 61400, Train loss: 1.784e+03, Test loss: 1.061e+05, MSE(e): 9.978e-05, MSE(pi1): 1.786e-02, MSE(pi2): 6.047e-05, MSE(pi3): 6.077e-03\n",
      "Epoch 61500, Train loss: 1.719e+03, Test loss: 1.055e+05, MSE(e): 9.772e-05, MSE(pi1): 1.239e-02, MSE(pi2): 5.906e-05, MSE(pi3): 6.181e-03\n",
      "Epoch 61600, Train loss: 1.777e+03, Test loss: 1.052e+05, MSE(e): 9.846e-05, MSE(pi1): 1.956e-02, MSE(pi2): 6.027e-05, MSE(pi3): 5.966e-03\n",
      "Epoch 61700, Train loss: 1.804e+03, Test loss: 1.054e+05, MSE(e): 1.038e-04, MSE(pi1): 1.345e-02, MSE(pi2): 6.161e-05, MSE(pi3): 6.316e-03\n",
      "Epoch 61800, Train loss: 2.347e+03, Test loss: 1.083e+05, MSE(e): 1.582e-04, MSE(pi1): 1.753e-02, MSE(pi2): 8.709e-05, MSE(pi3): 5.893e-03\n",
      "Epoch 61900, Train loss: 1.698e+03, Test loss: 1.052e+05, MSE(e): 9.566e-05, MSE(pi1): 1.289e-02, MSE(pi2): 5.823e-05, MSE(pi3): 6.126e-03\n",
      "Epoch 62000, Train loss: 1.695e+03, Test loss: 1.050e+05, MSE(e): 9.529e-05, MSE(pi1): 1.266e-02, MSE(pi2): 5.794e-05, MSE(pi3): 6.153e-03\n",
      "Epoch 62100, Train loss: 1.711e+03, Test loss: 1.058e+05, MSE(e): 9.664e-05, MSE(pi1): 1.266e-02, MSE(pi2): 5.865e-05, MSE(pi3): 6.180e-03\n",
      "Epoch 62200, Train loss: 1.698e+03, Test loss: 1.053e+05, MSE(e): 9.562e-05, MSE(pi1): 1.276e-02, MSE(pi2): 5.812e-05, MSE(pi3): 6.141e-03\n",
      "Epoch 62300, Train loss: 1.802e+03, Test loss: 1.053e+05, MSE(e): 9.569e-05, MSE(pi1): 2.353e-02, MSE(pi2): 5.792e-05, MSE(pi3): 6.098e-03\n",
      "Epoch 62400, Train loss: 1.706e+03, Test loss: 1.049e+05, MSE(e): 9.590e-05, MSE(pi1): 1.210e-02, MSE(pi2): 5.797e-05, MSE(pi3): 6.254e-03\n",
      "Epoch 62500, Train loss: 1.693e+03, Test loss: 1.046e+05, MSE(e): 9.508e-05, MSE(pi1): 1.320e-02, MSE(pi2): 5.783e-05, MSE(pi3): 6.098e-03\n",
      "Epoch 62600, Train loss: 1.782e+03, Test loss: 1.060e+05, MSE(e): 1.040e-04, MSE(pi1): 1.292e-02, MSE(pi2): 6.176e-05, MSE(pi3): 6.126e-03\n",
      "Epoch 62700, Train loss: 1.719e+03, Test loss: 1.048e+05, MSE(e): 9.465e-05, MSE(pi1): 1.579e-02, MSE(pi2): 5.736e-05, MSE(pi3): 6.148e-03\n",
      "Epoch 62800, Train loss: 1.685e+03, Test loss: 1.046e+05, MSE(e): 9.427e-05, MSE(pi1): 1.197e-02, MSE(pi2): 5.734e-05, MSE(pi3): 6.230e-03\n",
      "Epoch 62900, Train loss: 1.679e+03, Test loss: 1.047e+05, MSE(e): 9.377e-05, MSE(pi1): 1.267e-02, MSE(pi2): 5.696e-05, MSE(pi3): 6.146e-03\n",
      "Epoch 63000, Train loss: 1.863e+03, Test loss: 1.056e+05, MSE(e): 1.035e-04, MSE(pi1): 1.759e-02, MSE(pi2): 6.398e-05, MSE(pi3): 6.522e-03\n",
      "Epoch 63100, Train loss: 4.927e+03, Test loss: 1.010e+05, MSE(e): 4.082e-04, MSE(pi1): 2.332e-02, MSE(pi2): 1.840e-04, MSE(pi3): 6.118e-03\n",
      "Epoch 63200, Train loss: 1.674e+03, Test loss: 1.037e+05, MSE(e): 9.246e-05, MSE(pi1): 1.344e-02, MSE(pi2): 5.604e-05, MSE(pi3): 6.146e-03\n",
      "Epoch 63300, Train loss: 1.685e+03, Test loss: 1.036e+05, MSE(e): 9.424e-05, MSE(pi1): 1.168e-02, MSE(pi2): 5.689e-05, MSE(pi3): 6.258e-03\n",
      "Epoch 63400, Train loss: 1.659e+03, Test loss: 1.038e+05, MSE(e): 9.168e-05, MSE(pi1): 1.276e-02, MSE(pi2): 5.572e-05, MSE(pi3): 6.141e-03\n",
      "Epoch 63500, Train loss: 1.656e+03, Test loss: 1.035e+05, MSE(e): 9.160e-05, MSE(pi1): 1.281e-02, MSE(pi2): 5.559e-05, MSE(pi3): 6.123e-03\n",
      "Epoch 63600, Train loss: 1.659e+03, Test loss: 1.034e+05, MSE(e): 9.175e-05, MSE(pi1): 1.332e-02, MSE(pi2): 5.587e-05, MSE(pi3): 6.082e-03\n",
      "Epoch 63700, Train loss: 1.661e+03, Test loss: 1.032e+05, MSE(e): 9.196e-05, MSE(pi1): 1.227e-02, MSE(pi2): 5.548e-05, MSE(pi3): 6.185e-03\n",
      "Epoch 63800, Train loss: 1.795e+03, Test loss: 1.032e+05, MSE(e): 1.030e-04, MSE(pi1): 1.779e-02, MSE(pi2): 6.341e-05, MSE(pi3): 5.874e-03\n",
      "Epoch 63900, Train loss: 1.645e+03, Test loss: 1.031e+05, MSE(e): 9.047e-05, MSE(pi1): 1.260e-02, MSE(pi2): 5.495e-05, MSE(pi3): 6.145e-03\n",
      "Epoch 64000, Train loss: 1.658e+03, Test loss: 1.035e+05, MSE(e): 9.140e-05, MSE(pi1): 1.288e-02, MSE(pi2): 5.542e-05, MSE(pi3): 6.155e-03\n",
      "Epoch 64100, Train loss: 1.716e+03, Test loss: 1.035e+05, MSE(e): 9.392e-05, MSE(pi1): 1.653e-02, MSE(pi2): 5.650e-05, MSE(pi3): 6.119e-03\n",
      "Epoch 64200, Train loss: 7.053e+03, Test loss: 1.131e+05, MSE(e): 6.275e-04, MSE(pi1): 2.151e-02, MSE(pi2): 2.868e-04, MSE(pi3): 5.632e-03\n",
      "Epoch 64300, Train loss: 1.673e+03, Test loss: 1.029e+05, MSE(e): 8.971e-05, MSE(pi1): 1.590e-02, MSE(pi2): 5.432e-05, MSE(pi3): 6.165e-03\n",
      "Epoch 64400, Train loss: 1.689e+03, Test loss: 1.026e+05, MSE(e): 9.377e-05, MSE(pi1): 1.402e-02, MSE(pi2): 5.556e-05, MSE(pi3): 6.114e-03\n",
      "Epoch 64500, Train loss: 2.713e+03, Test loss: 1.039e+05, MSE(e): 1.926e-04, MSE(pi1): 2.044e-02, MSE(pi2): 1.011e-04, MSE(pi3): 5.829e-03\n",
      "Epoch 64600, Train loss: 1.835e+03, Test loss: 1.045e+05, MSE(e): 1.058e-04, MSE(pi1): 1.319e-02, MSE(pi2): 6.438e-05, MSE(pi3): 6.455e-03\n",
      "Epoch 64700, Train loss: 1.656e+03, Test loss: 1.030e+05, MSE(e): 9.145e-05, MSE(pi1): 1.315e-02, MSE(pi2): 5.528e-05, MSE(pi3): 6.102e-03\n",
      "Epoch 64800, Train loss: 1.711e+03, Test loss: 1.012e+05, MSE(e): 9.389e-05, MSE(pi1): 1.455e-02, MSE(pi2): 5.553e-05, MSE(pi3): 6.268e-03\n",
      "Epoch 64900, Train loss: 1.781e+03, Test loss: 1.038e+05, MSE(e): 1.019e-04, MSE(pi1): 1.467e-02, MSE(pi2): 5.949e-05, MSE(pi3): 6.151e-03\n",
      "Epoch 65000, Train loss: 2.459e+03, Test loss: 1.056e+05, MSE(e): 1.285e-04, MSE(pi1): 4.615e-02, MSE(pi2): 8.174e-05, MSE(pi3): 7.123e-03\n",
      "Epoch 65100, Train loss: 1.651e+03, Test loss: 1.015e+05, MSE(e): 9.070e-05, MSE(pi1): 1.259e-02, MSE(pi2): 5.413e-05, MSE(pi3): 6.180e-03\n",
      "Epoch 65200, Train loss: 1.632e+03, Test loss: 1.016e+05, MSE(e): 8.904e-05, MSE(pi1): 1.232e-02, MSE(pi2): 5.347e-05, MSE(pi3): 6.181e-03\n",
      "Epoch 65300, Train loss: 1.748e+03, Test loss: 1.008e+05, MSE(e): 1.004e-04, MSE(pi1): 1.273e-02, MSE(pi2): 5.769e-05, MSE(pi3): 6.165e-03\n",
      "Epoch 65400, Train loss: 1.769e+03, Test loss: 1.039e+05, MSE(e): 1.007e-04, MSE(pi1): 1.267e-02, MSE(pi2): 6.019e-05, MSE(pi3): 6.351e-03\n",
      "Epoch 65500, Train loss: 4.935e+03, Test loss: 9.967e+04, MSE(e): 4.180e-04, MSE(pi1): 1.087e-02, MSE(pi2): 1.872e-04, MSE(pi3): 6.456e-03\n",
      "Epoch 65600, Train loss: 1.603e+03, Test loss: 1.015e+05, MSE(e): 8.644e-05, MSE(pi1): 1.252e-02, MSE(pi2): 5.242e-05, MSE(pi3): 6.135e-03\n",
      "Epoch 65700, Train loss: 1.608e+03, Test loss: 1.014e+05, MSE(e): 8.642e-05, MSE(pi1): 1.288e-02, MSE(pi2): 5.241e-05, MSE(pi3): 6.151e-03\n",
      "Epoch 65800, Train loss: 1.983e+03, Test loss: 1.004e+05, MSE(e): 1.235e-04, MSE(pi1): 1.129e-02, MSE(pi2): 6.689e-05, MSE(pi3): 6.357e-03\n",
      "Epoch 65900, Train loss: 1.596e+03, Test loss: 1.012e+05, MSE(e): 8.575e-05, MSE(pi1): 1.243e-02, MSE(pi2): 5.200e-05, MSE(pi3): 6.143e-03\n",
      "Epoch 66000, Train loss: 1.646e+03, Test loss: 1.016e+05, MSE(e): 9.070e-05, MSE(pi1): 1.315e-02, MSE(pi2): 5.453e-05, MSE(pi3): 6.073e-03\n",
      "Epoch 66100, Train loss: 1.596e+03, Test loss: 1.012e+05, MSE(e): 8.545e-05, MSE(pi1): 1.246e-02, MSE(pi2): 5.180e-05, MSE(pi3): 6.172e-03\n",
      "Epoch 66200, Train loss: 1.682e+03, Test loss: 1.018e+05, MSE(e): 9.255e-05, MSE(pi1): 1.403e-02, MSE(pi2): 5.491e-05, MSE(pi3): 6.165e-03\n",
      "Epoch 66300, Train loss: 1.975e+03, Test loss: 9.976e+04, MSE(e): 1.218e-04, MSE(pi1): 1.256e-02, MSE(pi2): 6.585e-05, MSE(pi3): 6.316e-03\n",
      "Epoch 66400, Train loss: 1.627e+03, Test loss: 1.004e+05, MSE(e): 8.839e-05, MSE(pi1): 1.185e-02, MSE(pi2): 5.267e-05, MSE(pi3): 6.242e-03\n",
      "Epoch 66500, Train loss: 1.921e+03, Test loss: 1.009e+05, MSE(e): 8.703e-05, MSE(pi1): 4.326e-02, MSE(pi2): 5.164e-05, MSE(pi3): 6.184e-03\n",
      "Epoch 66600, Train loss: 1.797e+03, Test loss: 1.013e+05, MSE(e): 9.847e-05, MSE(pi1): 1.546e-02, MSE(pi2): 6.049e-05, MSE(pi3): 6.576e-03\n",
      "Epoch 66700, Train loss: 1.726e+03, Test loss: 1.008e+05, MSE(e): 8.689e-05, MSE(pi1): 2.334e-02, MSE(pi2): 5.166e-05, MSE(pi3): 6.238e-03\n",
      "Epoch 66800, Train loss: 1.577e+03, Test loss: 1.005e+05, MSE(e): 8.391e-05, MSE(pi1): 1.250e-02, MSE(pi2): 5.091e-05, MSE(pi3): 6.130e-03\n",
      "Epoch 66900, Train loss: 4.027e+03, Test loss: 1.085e+05, MSE(e): 3.253e-04, MSE(pi1): 2.013e-02, MSE(pi2): 1.574e-04, MSE(pi3): 5.722e-03\n",
      "Epoch 67000, Train loss: 1.863e+03, Test loss: 1.005e+05, MSE(e): 8.584e-05, MSE(pi1): 3.913e-02, MSE(pi2): 5.120e-05, MSE(pi3): 6.133e-03\n",
      "Epoch 67100, Train loss: 1.774e+03, Test loss: 1.016e+05, MSE(e): 9.283e-05, MSE(pi1): 1.885e-02, MSE(pi2): 5.720e-05, MSE(pi3): 6.572e-03\n",
      "Epoch 67200, Train loss: 1.605e+03, Test loss: 9.928e+04, MSE(e): 8.615e-05, MSE(pi1): 1.356e-02, MSE(pi2): 5.158e-05, MSE(pi3): 6.082e-03\n",
      "Epoch 67300, Train loss: 1.604e+03, Test loss: 9.952e+04, MSE(e): 8.622e-05, MSE(pi1): 1.203e-02, MSE(pi2): 5.130e-05, MSE(pi3): 6.214e-03\n",
      "Epoch 67400, Train loss: 1.658e+03, Test loss: 9.906e+04, MSE(e): 8.627e-05, MSE(pi1): 2.014e-02, MSE(pi2): 5.278e-05, MSE(pi3): 5.935e-03\n",
      "Epoch 67500, Train loss: 1.600e+03, Test loss: 9.859e+04, MSE(e): 8.527e-05, MSE(pi1): 1.350e-02, MSE(pi2): 5.153e-05, MSE(pi3): 6.124e-03\n",
      "Epoch 67600, Train loss: 1.562e+03, Test loss: 9.953e+04, MSE(e): 8.236e-05, MSE(pi1): 1.269e-02, MSE(pi2): 4.988e-05, MSE(pi3): 6.112e-03\n",
      "Epoch 67700, Train loss: 1.561e+03, Test loss: 9.943e+04, MSE(e): 8.237e-05, MSE(pi1): 1.228e-02, MSE(pi2): 4.970e-05, MSE(pi3): 6.148e-03\n",
      "Epoch 67800, Train loss: 3.082e+03, Test loss: 9.719e+04, MSE(e): 2.338e-04, MSE(pi1): 1.041e-02, MSE(pi2): 1.109e-04, MSE(pi3): 6.396e-03\n",
      "Epoch 67900, Train loss: 1.557e+03, Test loss: 9.940e+04, MSE(e): 8.162e-05, MSE(pi1): 1.292e-02, MSE(pi2): 4.946e-05, MSE(pi3): 6.114e-03\n",
      "Epoch 68000, Train loss: 1.608e+03, Test loss: 9.995e+04, MSE(e): 8.536e-05, MSE(pi1): 1.491e-02, MSE(pi2): 5.155e-05, MSE(pi3): 6.049e-03\n",
      "Epoch 68100, Train loss: 1.590e+03, Test loss: 9.962e+04, MSE(e): 8.310e-05, MSE(pi1): 1.480e-02, MSE(pi2): 5.016e-05, MSE(pi3): 6.112e-03\n",
      "Epoch 68200, Train loss: 1.943e+03, Test loss: 9.739e+04, MSE(e): 1.019e-04, MSE(pi1): 3.502e-02, MSE(pi2): 6.399e-05, MSE(pi3): 5.733e-03\n",
      "Epoch 68300, Train loss: 1.565e+03, Test loss: 9.942e+04, MSE(e): 8.263e-05, MSE(pi1): 1.226e-02, MSE(pi2): 4.988e-05, MSE(pi3): 6.158e-03\n",
      "Epoch 68400, Train loss: 1.599e+03, Test loss: 9.819e+04, MSE(e): 8.607e-05, MSE(pi1): 1.205e-02, MSE(pi2): 5.067e-05, MSE(pi3): 6.175e-03\n",
      "Epoch 68500, Train loss: 1.634e+03, Test loss: 9.744e+04, MSE(e): 8.815e-05, MSE(pi1): 1.486e-02, MSE(pi2): 5.209e-05, MSE(pi3): 6.034e-03\n",
      "Epoch 68600, Train loss: 2.472e+03, Test loss: 9.847e+04, MSE(e): 1.436e-04, MSE(pi1): 3.856e-02, MSE(pi2): 7.373e-05, MSE(pi3): 6.498e-03\n",
      "Epoch 68700, Train loss: 1.537e+03, Test loss: 9.864e+04, MSE(e): 7.998e-05, MSE(pi1): 1.236e-02, MSE(pi2): 4.840e-05, MSE(pi3): 6.133e-03\n",
      "Epoch 68800, Train loss: 1.597e+03, Test loss: 9.865e+04, MSE(e): 8.348e-05, MSE(pi1): 1.445e-02, MSE(pi2): 4.997e-05, MSE(pi3): 6.172e-03\n",
      "Epoch 68900, Train loss: 1.541e+03, Test loss: 9.859e+04, MSE(e): 7.963e-05, MSE(pi1): 1.299e-02, MSE(pi2): 4.816e-05, MSE(pi3): 6.147e-03\n",
      "Epoch 69000, Train loss: 1.531e+03, Test loss: 9.849e+04, MSE(e): 7.940e-05, MSE(pi1): 1.228e-02, MSE(pi2): 4.803e-05, MSE(pi3): 6.140e-03\n",
      "Epoch 69100, Train loss: 1.541e+03, Test loss: 9.800e+04, MSE(e): 8.034e-05, MSE(pi1): 1.215e-02, MSE(pi2): 4.820e-05, MSE(pi3): 6.162e-03\n",
      "Epoch 69200, Train loss: 1.662e+03, Test loss: 9.753e+04, MSE(e): 9.096e-05, MSE(pi1): 1.262e-02, MSE(pi2): 5.230e-05, MSE(pi3): 6.265e-03\n",
      "Epoch 69300, Train loss: 1.574e+03, Test loss: 9.754e+04, MSE(e): 8.357e-05, MSE(pi1): 1.179e-02, MSE(pi2): 4.933e-05, MSE(pi3): 6.203e-03\n",
      "Epoch 69400, Train loss: 1.577e+03, Test loss: 9.774e+04, MSE(e): 8.034e-05, MSE(pi1): 1.633e-02, MSE(pi2): 4.819e-05, MSE(pi3): 6.098e-03\n",
      "Epoch 69500, Train loss: 2.354e+03, Test loss: 9.695e+04, MSE(e): 1.425e-04, MSE(pi1): 3.353e-02, MSE(pi2): 7.510e-05, MSE(pi3): 5.940e-03\n",
      "Epoch 69600, Train loss: 1.519e+03, Test loss: 9.796e+04, MSE(e): 7.824e-05, MSE(pi1): 1.229e-02, MSE(pi2): 4.736e-05, MSE(pi3): 6.134e-03\n",
      "Epoch 69700, Train loss: 1.531e+03, Test loss: 9.771e+04, MSE(e): 7.913e-05, MSE(pi1): 1.321e-02, MSE(pi2): 4.799e-05, MSE(pi3): 6.072e-03\n",
      "Epoch 69800, Train loss: 1.598e+03, Test loss: 9.809e+04, MSE(e): 7.849e-05, MSE(pi1): 1.968e-02, MSE(pi2): 4.718e-05, MSE(pi3): 6.162e-03\n",
      "Epoch 69900, Train loss: 1.644e+03, Test loss: 9.675e+04, MSE(e): 8.337e-05, MSE(pi1): 2.112e-02, MSE(pi2): 4.904e-05, MSE(pi3): 5.989e-03\n",
      "Epoch 70000, Train loss: 2.772e+03, Test loss: 1.012e+05, MSE(e): 1.647e-04, MSE(pi1): 5.445e-02, MSE(pi2): 8.879e-05, MSE(pi3): 5.797e-03\n",
      "Epoch 70100, Train loss: 1.509e+03, Test loss: 9.755e+04, MSE(e): 7.733e-05, MSE(pi1): 1.217e-02, MSE(pi2): 4.679e-05, MSE(pi3): 6.144e-03\n",
      "Epoch 70200, Train loss: 1.515e+03, Test loss: 9.710e+04, MSE(e): 7.781e-05, MSE(pi1): 1.290e-02, MSE(pi2): 4.722e-05, MSE(pi3): 6.075e-03\n",
      "Epoch 70300, Train loss: 3.353e+03, Test loss: 1.048e+05, MSE(e): 2.558e-04, MSE(pi1): 2.080e-02, MSE(pi2): 1.237e-04, MSE(pi3): 5.874e-03\n",
      "Epoch 70400, Train loss: 1.504e+03, Test loss: 9.734e+04, MSE(e): 7.682e-05, MSE(pi1): 1.220e-02, MSE(pi2): 4.649e-05, MSE(pi3): 6.140e-03\n",
      "Epoch 70500, Train loss: 1.530e+03, Test loss: 9.697e+04, MSE(e): 7.893e-05, MSE(pi1): 1.233e-02, MSE(pi2): 4.708e-05, MSE(pi3): 6.170e-03\n",
      "Epoch 70600, Train loss: 1.761e+03, Test loss: 9.696e+04, MSE(e): 1.001e-04, MSE(pi1): 1.263e-02, MSE(pi2): 5.572e-05, MSE(pi3): 6.340e-03\n",
      "Epoch 70700, Train loss: 1.498e+03, Test loss: 9.702e+04, MSE(e): 7.625e-05, MSE(pi1): 1.219e-02, MSE(pi2): 4.611e-05, MSE(pi3): 6.139e-03\n",
      "Epoch 70800, Train loss: 1.505e+03, Test loss: 9.674e+04, MSE(e): 7.647e-05, MSE(pi1): 1.229e-02, MSE(pi2): 4.607e-05, MSE(pi3): 6.177e-03\n",
      "Epoch 70900, Train loss: 1.525e+03, Test loss: 9.801e+04, MSE(e): 7.643e-05, MSE(pi1): 1.383e-02, MSE(pi2): 4.614e-05, MSE(pi3): 6.222e-03\n",
      "Epoch 71000, Train loss: 1.493e+03, Test loss: 9.679e+04, MSE(e): 7.572e-05, MSE(pi1): 1.216e-02, MSE(pi2): 4.579e-05, MSE(pi3): 6.140e-03\n",
      "Epoch 71100, Train loss: 1.539e+03, Test loss: 9.652e+04, MSE(e): 7.680e-05, MSE(pi1): 1.662e-02, MSE(pi2): 4.657e-05, MSE(pi3): 6.049e-03\n",
      "Epoch 71200, Train loss: 1.539e+03, Test loss: 9.651e+04, MSE(e): 7.751e-05, MSE(pi1): 1.432e-02, MSE(pi2): 4.619e-05, MSE(pi3): 6.209e-03\n",
      "Epoch 71300, Train loss: 1.488e+03, Test loss: 9.651e+04, MSE(e): 7.521e-05, MSE(pi1): 1.216e-02, MSE(pi2): 4.546e-05, MSE(pi3): 6.139e-03\n",
      "Epoch 71400, Train loss: 1.694e+03, Test loss: 9.807e+04, MSE(e): 8.869e-05, MSE(pi1): 1.509e-02, MSE(pi2): 5.500e-05, MSE(pi3): 6.563e-03\n",
      "Epoch 71500, Train loss: 2.042e+03, Test loss: 9.476e+04, MSE(e): 1.292e-04, MSE(pi1): 1.101e-02, MSE(pi2): 6.728e-05, MSE(pi3): 6.400e-03\n",
      "Epoch 71600, Train loss: 1.483e+03, Test loss: 9.629e+04, MSE(e): 7.475e-05, MSE(pi1): 1.231e-02, MSE(pi2): 4.523e-05, MSE(pi3): 6.122e-03\n",
      "Epoch 71700, Train loss: 1.493e+03, Test loss: 9.670e+04, MSE(e): 7.567e-05, MSE(pi1): 1.161e-02, MSE(pi2): 4.576e-05, MSE(pi3): 6.197e-03\n",
      "Epoch 71800, Train loss: 1.497e+03, Test loss: 9.633e+04, MSE(e): 7.499e-05, MSE(pi1): 1.368e-02, MSE(pi2): 4.541e-05, MSE(pi3): 6.099e-03\n",
      "Epoch 71900, Train loss: 1.478e+03, Test loss: 9.617e+04, MSE(e): 7.427e-05, MSE(pi1): 1.222e-02, MSE(pi2): 4.493e-05, MSE(pi3): 6.129e-03\n",
      "Epoch 72000, Train loss: 1.510e+03, Test loss: 9.633e+04, MSE(e): 7.465e-05, MSE(pi1): 1.343e-02, MSE(pi2): 4.503e-05, MSE(pi3): 6.289e-03\n",
      "Epoch 72100, Train loss: 1.523e+03, Test loss: 9.514e+04, MSE(e): 7.828e-05, MSE(pi1): 1.380e-02, MSE(pi2): 4.718e-05, MSE(pi3): 6.026e-03\n",
      "Epoch 72200, Train loss: 1.816e+03, Test loss: 9.842e+04, MSE(e): 1.005e-04, MSE(pi1): 1.715e-02, MSE(pi2): 5.738e-05, MSE(pi3): 6.390e-03\n",
      "Epoch 72300, Train loss: 2.920e+03, Test loss: 9.404e+04, MSE(e): 2.171e-04, MSE(pi1): 9.877e-03, MSE(pi2): 1.033e-04, MSE(pi3): 6.502e-03\n",
      "Epoch 72400, Train loss: 1.472e+03, Test loss: 9.551e+04, MSE(e): 7.349e-05, MSE(pi1): 1.261e-02, MSE(pi2): 4.439e-05, MSE(pi3): 6.107e-03\n",
      "Epoch 72500, Train loss: 1.489e+03, Test loss: 9.551e+04, MSE(e): 7.408e-05, MSE(pi1): 1.244e-02, MSE(pi2): 4.469e-05, MSE(pi3): 6.241e-03\n",
      "Epoch 72600, Train loss: 3.214e+03, Test loss: 9.381e+04, MSE(e): 2.385e-04, MSE(pi1): 1.827e-02, MSE(pi2): 1.111e-04, MSE(pi3): 6.465e-03\n",
      "Epoch 72700, Train loss: 1.463e+03, Test loss: 9.541e+04, MSE(e): 7.287e-05, MSE(pi1): 1.214e-02, MSE(pi2): 4.403e-05, MSE(pi3): 6.133e-03\n",
      "Epoch 72800, Train loss: 1.473e+03, Test loss: 9.500e+04, MSE(e): 7.297e-05, MSE(pi1): 1.357e-02, MSE(pi2): 4.416e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 72900, Train loss: 1.598e+03, Test loss: 9.443e+04, MSE(e): 8.264e-05, MSE(pi1): 1.478e-02, MSE(pi2): 4.754e-05, MSE(pi3): 6.237e-03\n",
      "Epoch 73000, Train loss: 1.459e+03, Test loss: 9.514e+04, MSE(e): 7.240e-05, MSE(pi1): 1.216e-02, MSE(pi2): 4.373e-05, MSE(pi3): 6.130e-03\n",
      "Epoch 73100, Train loss: 5.936e+03, Test loss: 1.058e+05, MSE(e): 5.157e-04, MSE(pi1): 1.566e-02, MSE(pi2): 2.350e-04, MSE(pi3): 6.214e-03\n",
      "Epoch 73200, Train loss: 1.456e+03, Test loss: 9.509e+04, MSE(e): 7.210e-05, MSE(pi1): 1.217e-02, MSE(pi2): 4.357e-05, MSE(pi3): 6.132e-03\n",
      "Epoch 73300, Train loss: 1.462e+03, Test loss: 9.531e+04, MSE(e): 7.267e-05, MSE(pi1): 1.220e-02, MSE(pi2): 4.389e-05, MSE(pi3): 6.128e-03\n",
      "Epoch 73400, Train loss: 3.324e+03, Test loss: 9.227e+04, MSE(e): 2.283e-04, MSE(pi1): 4.735e-02, MSE(pi2): 1.158e-04, MSE(pi3): 5.680e-03\n",
      "Epoch 73500, Train loss: 1.464e+03, Test loss: 9.467e+04, MSE(e): 7.179e-05, MSE(pi1): 1.329e-02, MSE(pi2): 4.330e-05, MSE(pi3): 6.136e-03\n",
      "Epoch 73600, Train loss: 1.546e+03, Test loss: 9.421e+04, MSE(e): 7.929e-05, MSE(pi1): 1.231e-02, MSE(pi2): 4.625e-05, MSE(pi3): 6.303e-03\n",
      "Epoch 73700, Train loss: 1.448e+03, Test loss: 9.464e+04, MSE(e): 7.132e-05, MSE(pi1): 1.211e-02, MSE(pi2): 4.304e-05, MSE(pi3): 6.133e-03\n",
      "Epoch 73800, Train loss: 1.451e+03, Test loss: 9.479e+04, MSE(e): 7.158e-05, MSE(pi1): 1.208e-02, MSE(pi2): 4.324e-05, MSE(pi3): 6.140e-03\n",
      "Epoch 73900, Train loss: 1.472e+03, Test loss: 9.467e+04, MSE(e): 7.131e-05, MSE(pi1): 1.428e-02, MSE(pi2): 4.300e-05, MSE(pi3): 6.158e-03\n",
      "Epoch 74000, Train loss: 1.529e+03, Test loss: 9.495e+04, MSE(e): 7.948e-05, MSE(pi1): 1.291e-02, MSE(pi2): 4.703e-05, MSE(pi3): 6.052e-03\n",
      "Epoch 74100, Train loss: 1.455e+03, Test loss: 9.463e+04, MSE(e): 7.118e-05, MSE(pi1): 1.199e-02, MSE(pi2): 4.295e-05, MSE(pi3): 6.230e-03\n",
      "Epoch 74200, Train loss: 1.449e+03, Test loss: 9.407e+04, MSE(e): 7.145e-05, MSE(pi1): 1.182e-02, MSE(pi2): 4.279e-05, MSE(pi3): 6.161e-03\n",
      "Epoch 74300, Train loss: 2.278e+03, Test loss: 9.178e+04, MSE(e): 1.509e-04, MSE(pi1): 1.558e-02, MSE(pi2): 7.407e-05, MSE(pi3): 6.131e-03\n",
      "Epoch 74400, Train loss: 3.433e+03, Test loss: 9.292e+04, MSE(e): 2.680e-04, MSE(pi1): 9.488e-03, MSE(pi2): 1.239e-04, MSE(pi3): 6.573e-03\n",
      "Epoch 74500, Train loss: 2.953e+03, Test loss: 9.234e+04, MSE(e): 2.076e-04, MSE(pi1): 1.656e-02, MSE(pi2): 1.079e-04, MSE(pi3): 7.109e-03\n",
      "Epoch 74600, Train loss: 1.530e+03, Test loss: 9.458e+04, MSE(e): 7.928e-05, MSE(pi1): 1.106e-02, MSE(pi2): 4.578e-05, MSE(pi3): 6.261e-03\n",
      "Epoch 74700, Train loss: 1.434e+03, Test loss: 9.375e+04, MSE(e): 6.997e-05, MSE(pi1): 1.193e-02, MSE(pi2): 4.211e-05, MSE(pi3): 6.146e-03\n",
      "Epoch 74800, Train loss: 1.444e+03, Test loss: 9.393e+04, MSE(e): 6.999e-05, MSE(pi1): 1.364e-02, MSE(pi2): 4.232e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 74900, Train loss: 2.578e+03, Test loss: 9.142e+04, MSE(e): 1.519e-04, MSE(pi1): 4.729e-02, MSE(pi2): 7.461e-05, MSE(pi3): 5.868e-03\n",
      "Epoch 75000, Train loss: 1.549e+03, Test loss: 9.416e+04, MSE(e): 7.107e-05, MSE(pi1): 2.312e-02, MSE(pi2): 4.268e-05, MSE(pi3): 6.075e-03\n",
      "Epoch 75100, Train loss: 1.430e+03, Test loss: 9.340e+04, MSE(e): 6.958e-05, MSE(pi1): 1.196e-02, MSE(pi2): 4.180e-05, MSE(pi3): 6.141e-03\n",
      "Epoch 75200, Train loss: 1.621e+03, Test loss: 9.443e+04, MSE(e): 7.578e-05, MSE(pi1): 2.187e-02, MSE(pi2): 4.579e-05, MSE(pi3): 6.448e-03\n",
      "Epoch 75300, Train loss: 1.431e+03, Test loss: 9.397e+04, MSE(e): 6.973e-05, MSE(pi1): 1.222e-02, MSE(pi2): 4.209e-05, MSE(pi3): 6.113e-03\n",
      "Epoch 75400, Train loss: 1.503e+03, Test loss: 9.251e+04, MSE(e): 7.540e-05, MSE(pi1): 1.379e-02, MSE(pi2): 4.366e-05, MSE(pi3): 6.105e-03\n",
      "Epoch 75500, Train loss: 1.422e+03, Test loss: 9.274e+04, MSE(e): 6.882e-05, MSE(pi1): 1.216e-02, MSE(pi2): 4.140e-05, MSE(pi3): 6.126e-03\n",
      "Epoch 75600, Train loss: 1.588e+03, Test loss: 9.517e+04, MSE(e): 8.486e-05, MSE(pi1): 1.336e-02, MSE(pi2): 4.887e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 75700, Train loss: 1.493e+03, Test loss: 9.392e+04, MSE(e): 7.138e-05, MSE(pi1): 1.435e-02, MSE(pi2): 4.318e-05, MSE(pi3): 6.357e-03\n",
      "Epoch 75800, Train loss: 1.437e+03, Test loss: 9.297e+04, MSE(e): 6.970e-05, MSE(pi1): 1.176e-02, MSE(pi2): 4.164e-05, MSE(pi3): 6.224e-03\n",
      "Epoch 75900, Train loss: 1.800e+03, Test loss: 9.551e+04, MSE(e): 7.690e-05, MSE(pi1): 3.781e-02, MSE(pi2): 4.587e-05, MSE(pi3): 6.528e-03\n",
      "Epoch 76000, Train loss: 1.436e+03, Test loss: 9.233e+04, MSE(e): 6.936e-05, MSE(pi1): 1.385e-02, MSE(pi2): 4.185e-05, MSE(pi3): 6.036e-03\n",
      "Epoch 76100, Train loss: 1.497e+03, Test loss: 9.331e+04, MSE(e): 7.505e-05, MSE(pi1): 1.111e-02, MSE(pi2): 4.477e-05, MSE(pi3): 6.356e-03\n",
      "Epoch 76200, Train loss: 1.948e+03, Test loss: 9.338e+04, MSE(e): 1.188e-04, MSE(pi1): 1.693e-02, MSE(pi2): 6.419e-05, MSE(pi3): 5.906e-03\n",
      "Epoch 76300, Train loss: 1.695e+03, Test loss: 9.297e+04, MSE(e): 6.970e-05, MSE(pi1): 3.841e-02, MSE(pi2): 4.117e-05, MSE(pi3): 6.134e-03\n",
      "Epoch 76400, Train loss: 1.522e+03, Test loss: 9.146e+04, MSE(e): 7.512e-05, MSE(pi1): 1.675e-02, MSE(pi2): 4.331e-05, MSE(pi3): 6.033e-03\n",
      "Epoch 76500, Train loss: 1.513e+03, Test loss: 9.234e+04, MSE(e): 6.912e-05, MSE(pi1): 2.169e-02, MSE(pi2): 4.172e-05, MSE(pi3): 6.052e-03\n",
      "Epoch 76600, Train loss: 1.404e+03, Test loss: 9.259e+04, MSE(e): 6.709e-05, MSE(pi1): 1.220e-02, MSE(pi2): 4.051e-05, MSE(pi3): 6.111e-03\n",
      "Epoch 76700, Train loss: 1.455e+03, Test loss: 9.306e+04, MSE(e): 7.208e-05, MSE(pi1): 1.287e-02, MSE(pi2): 4.306e-05, MSE(pi3): 6.052e-03\n",
      "Epoch 76800, Train loss: 1.401e+03, Test loss: 9.241e+04, MSE(e): 6.676e-05, MSE(pi1): 1.201e-02, MSE(pi2): 4.027e-05, MSE(pi3): 6.131e-03\n",
      "Epoch 76900, Train loss: 1.411e+03, Test loss: 9.222e+04, MSE(e): 6.776e-05, MSE(pi1): 1.161e-02, MSE(pi2): 4.046e-05, MSE(pi3): 6.171e-03\n",
      "Epoch 77000, Train loss: 1.398e+03, Test loss: 9.231e+04, MSE(e): 6.651e-05, MSE(pi1): 1.181e-02, MSE(pi2): 4.008e-05, MSE(pi3): 6.152e-03\n",
      "Epoch 77100, Train loss: 1.698e+03, Test loss: 9.136e+04, MSE(e): 9.154e-05, MSE(pi1): 1.870e-02, MSE(pi2): 5.154e-05, MSE(pi3): 5.957e-03\n",
      "Epoch 77200, Train loss: 1.395e+03, Test loss: 9.211e+04, MSE(e): 6.622e-05, MSE(pi1): 1.197e-02, MSE(pi2): 3.993e-05, MSE(pi3): 6.130e-03\n",
      "Epoch 77300, Train loss: 1.576e+03, Test loss: 9.129e+04, MSE(e): 8.400e-05, MSE(pi1): 1.119e-02, MSE(pi2): 4.662e-05, MSE(pi3): 6.236e-03\n",
      "Epoch 77400, Train loss: 1.397e+03, Test loss: 9.219e+04, MSE(e): 6.645e-05, MSE(pi1): 1.219e-02, MSE(pi2): 4.012e-05, MSE(pi3): 6.107e-03\n",
      "Epoch 77500, Train loss: 1.606e+03, Test loss: 9.244e+04, MSE(e): 6.781e-05, MSE(pi1): 3.062e-02, MSE(pi2): 4.021e-05, MSE(pi3): 6.218e-03\n",
      "Epoch 77600, Train loss: 1.917e+03, Test loss: 8.962e+04, MSE(e): 1.178e-04, MSE(pi1): 1.231e-02, MSE(pi2): 6.001e-05, MSE(pi3): 6.160e-03\n",
      "Epoch 77700, Train loss: 1.464e+03, Test loss: 9.106e+04, MSE(e): 6.933e-05, MSE(pi1): 1.557e-02, MSE(pi2): 4.071e-05, MSE(pi3): 6.154e-03\n",
      "Epoch 77800, Train loss: 1.408e+03, Test loss: 9.136e+04, MSE(e): 6.720e-05, MSE(pi1): 1.207e-02, MSE(pi2): 3.991e-05, MSE(pi3): 6.155e-03\n",
      "Epoch 77900, Train loss: 1.395e+03, Test loss: 9.157e+04, MSE(e): 6.585e-05, MSE(pi1): 1.310e-02, MSE(pi2): 3.987e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 78000, Train loss: 1.475e+03, Test loss: 9.182e+04, MSE(e): 6.587e-05, MSE(pi1): 2.018e-02, MSE(pi2): 3.935e-05, MSE(pi3): 6.149e-03\n",
      "Epoch 78100, Train loss: 1.387e+03, Test loss: 9.138e+04, MSE(e): 6.543e-05, MSE(pi1): 1.165e-02, MSE(pi2): 3.925e-05, MSE(pi3): 6.164e-03\n",
      "Epoch 78200, Train loss: 1.415e+03, Test loss: 9.141e+04, MSE(e): 6.778e-05, MSE(pi1): 1.134e-02, MSE(pi2): 4.019e-05, MSE(pi3): 6.234e-03\n",
      "Epoch 78300, Train loss: 1.453e+03, Test loss: 9.068e+04, MSE(e): 7.081e-05, MSE(pi1): 1.249e-02, MSE(pi2): 4.108e-05, MSE(pi3): 6.204e-03\n",
      "Epoch 78400, Train loss: 1.380e+03, Test loss: 9.135e+04, MSE(e): 6.471e-05, MSE(pi1): 1.199e-02, MSE(pi2): 3.904e-05, MSE(pi3): 6.124e-03\n",
      "Epoch 78500, Train loss: 1.388e+03, Test loss: 9.097e+04, MSE(e): 6.500e-05, MSE(pi1): 1.274e-02, MSE(pi2): 3.893e-05, MSE(pi3): 6.107e-03\n",
      "Epoch 78600, Train loss: 1.376e+03, Test loss: 9.109e+04, MSE(e): 6.442e-05, MSE(pi1): 1.183e-02, MSE(pi2): 3.878e-05, MSE(pi3): 6.140e-03\n",
      "Epoch 78700, Train loss: 1.383e+03, Test loss: 9.144e+04, MSE(e): 6.489e-05, MSE(pi1): 1.173e-02, MSE(pi2): 3.910e-05, MSE(pi3): 6.163e-03\n",
      "Epoch 78800, Train loss: 1.376e+03, Test loss: 9.087e+04, MSE(e): 6.440e-05, MSE(pi1): 1.185e-02, MSE(pi2): 3.866e-05, MSE(pi3): 6.137e-03\n",
      "Epoch 78900, Train loss: 1.379e+03, Test loss: 9.112e+04, MSE(e): 6.441e-05, MSE(pi1): 1.235e-02, MSE(pi2): 3.889e-05, MSE(pi3): 6.113e-03\n",
      "Epoch 79000, Train loss: 1.394e+03, Test loss: 9.091e+04, MSE(e): 6.408e-05, MSE(pi1): 1.402e-02, MSE(pi2): 3.851e-05, MSE(pi3): 6.133e-03\n",
      "Epoch 79100, Train loss: 1.726e+03, Test loss: 9.277e+04, MSE(e): 9.907e-05, MSE(pi1): 1.362e-02, MSE(pi2): 5.443e-05, MSE(pi3): 5.993e-03\n",
      "Epoch 79200, Train loss: 1.390e+03, Test loss: 9.114e+04, MSE(e): 6.423e-05, MSE(pi1): 1.262e-02, MSE(pi2): 3.867e-05, MSE(pi3): 6.211e-03\n",
      "Epoch 79300, Train loss: 1.377e+03, Test loss: 9.056e+04, MSE(e): 6.445e-05, MSE(pi1): 1.158e-02, MSE(pi2): 3.849e-05, MSE(pi3): 6.169e-03\n",
      "Epoch 79400, Train loss: 2.812e+03, Test loss: 8.773e+04, MSE(e): 2.005e-04, MSE(pi1): 1.988e-02, MSE(pi2): 9.309e-05, MSE(pi3): 6.080e-03\n",
      "Epoch 79500, Train loss: 7.914e+03, Test loss: 1.022e+05, MSE(e): 6.997e-04, MSE(pi1): 3.773e-02, MSE(pi2): 3.238e-04, MSE(pi3): 5.400e-03\n",
      "Epoch 79600, Train loss: 1.365e+03, Test loss: 9.051e+04, MSE(e): 6.316e-05, MSE(pi1): 1.196e-02, MSE(pi2): 3.804e-05, MSE(pi3): 6.133e-03\n",
      "Epoch 79700, Train loss: 2.850e+03, Test loss: 9.902e+04, MSE(e): 1.731e-04, MSE(pi1): 4.378e-02, MSE(pi2): 9.907e-05, MSE(pi3): 6.816e-03\n",
      "Epoch 79800, Train loss: 1.361e+03, Test loss: 9.040e+04, MSE(e): 6.289e-05, MSE(pi1): 1.179e-02, MSE(pi2): 3.788e-05, MSE(pi3): 6.139e-03\n",
      "Epoch 79900, Train loss: 1.435e+03, Test loss: 9.083e+04, MSE(e): 6.823e-05, MSE(pi1): 1.509e-02, MSE(pi2): 4.085e-05, MSE(pi3): 6.016e-03\n",
      "Epoch 80000, Train loss: 1.358e+03, Test loss: 9.025e+04, MSE(e): 6.265e-05, MSE(pi1): 1.185e-02, MSE(pi2): 3.774e-05, MSE(pi3): 6.131e-03\n",
      "Epoch 80100, Train loss: 1.420e+03, Test loss: 9.163e+04, MSE(e): 6.585e-05, MSE(pi1): 1.306e-02, MSE(pi2): 3.965e-05, MSE(pi3): 6.312e-03\n",
      "Epoch 80200, Train loss: 1.779e+03, Test loss: 8.855e+04, MSE(e): 1.043e-04, MSE(pi1): 1.055e-02, MSE(pi2): 5.409e-05, MSE(pi3): 6.301e-03\n",
      "Epoch 80300, Train loss: 1.355e+03, Test loss: 8.999e+04, MSE(e): 6.235e-05, MSE(pi1): 1.180e-02, MSE(pi2): 3.750e-05, MSE(pi3): 6.136e-03\n",
      "Epoch 80400, Train loss: 1.498e+03, Test loss: 8.901e+04, MSE(e): 7.562e-05, MSE(pi1): 1.243e-02, MSE(pi2): 4.218e-05, MSE(pi3): 6.175e-03\n",
      "Epoch 80500, Train loss: 1.354e+03, Test loss: 8.959e+04, MSE(e): 6.224e-05, MSE(pi1): 1.196e-02, MSE(pi2): 3.739e-05, MSE(pi3): 6.124e-03\n",
      "Epoch 80600, Train loss: 2.768e+03, Test loss: 8.829e+04, MSE(e): 1.873e-04, MSE(pi1): 2.723e-02, MSE(pi2): 8.447e-05, MSE(pi3): 6.233e-03\n",
      "Epoch 80700, Train loss: 1.350e+03, Test loss: 8.976e+04, MSE(e): 6.184e-05, MSE(pi1): 1.197e-02, MSE(pi2): 3.726e-05, MSE(pi3): 6.117e-03\n",
      "Epoch 80800, Train loss: 1.350e+03, Test loss: 8.971e+04, MSE(e): 6.177e-05, MSE(pi1): 1.221e-02, MSE(pi2): 3.722e-05, MSE(pi3): 6.102e-03\n",
      "Epoch 80900, Train loss: 1.444e+03, Test loss: 8.904e+04, MSE(e): 7.099e-05, MSE(pi1): 1.095e-02, MSE(pi2): 4.058e-05, MSE(pi3): 6.243e-03\n",
      "Epoch 81000, Train loss: 1.471e+03, Test loss: 8.986e+04, MSE(e): 7.375e-05, MSE(pi1): 1.274e-02, MSE(pi2): 4.279e-05, MSE(pi3): 6.061e-03\n",
      "Epoch 81100, Train loss: 1.431e+03, Test loss: 8.888e+04, MSE(e): 6.542e-05, MSE(pi1): 1.853e-02, MSE(pi2): 4.011e-05, MSE(pi3): 5.918e-03\n",
      "Epoch 81200, Train loss: 1.351e+03, Test loss: 8.976e+04, MSE(e): 6.152e-05, MSE(pi1): 1.165e-02, MSE(pi2): 3.704e-05, MSE(pi3): 6.192e-03\n",
      "Epoch 81300, Train loss: 1.360e+03, Test loss: 9.004e+04, MSE(e): 6.202e-05, MSE(pi1): 1.344e-02, MSE(pi2): 3.757e-05, MSE(pi3): 6.052e-03\n",
      "Epoch 81400, Train loss: 2.781e+03, Test loss: 9.143e+04, MSE(e): 2.012e-04, MSE(pi1): 1.943e-02, MSE(pi2): 1.022e-04, MSE(pi3): 5.750e-03\n",
      "Epoch 81500, Train loss: 1.342e+03, Test loss: 8.921e+04, MSE(e): 6.098e-05, MSE(pi1): 1.225e-02, MSE(pi2): 3.677e-05, MSE(pi3): 6.096e-03\n",
      "Epoch 81600, Train loss: 2.692e+03, Test loss: 9.375e+04, MSE(e): 1.954e-04, MSE(pi1): 1.518e-02, MSE(pi2): 9.567e-05, MSE(pi3): 5.859e-03\n",
      "Epoch 81700, Train loss: 1.398e+03, Test loss: 8.825e+04, MSE(e): 6.584e-05, MSE(pi1): 1.274e-02, MSE(pi2): 3.818e-05, MSE(pi3): 6.117e-03\n",
      "Epoch 81800, Train loss: 1.373e+03, Test loss: 8.893e+04, MSE(e): 6.309e-05, MSE(pi1): 1.440e-02, MSE(pi2): 3.852e-05, MSE(pi3): 5.977e-03\n",
      "Epoch 81900, Train loss: 1.365e+03, Test loss: 8.850e+04, MSE(e): 6.329e-05, MSE(pi1): 1.147e-02, MSE(pi2): 3.727e-05, MSE(pi3): 6.171e-03\n",
      "Epoch 82000, Train loss: 1.495e+03, Test loss: 8.925e+04, MSE(e): 6.883e-05, MSE(pi1): 1.804e-02, MSE(pi2): 3.973e-05, MSE(pi3): 6.266e-03\n",
      "Epoch 82100, Train loss: 4.555e+03, Test loss: 8.729e+04, MSE(e): 3.755e-04, MSE(pi1): 1.408e-02, MSE(pi2): 1.653e-04, MSE(pi3): 6.587e-03\n",
      "Epoch 82200, Train loss: 1.332e+03, Test loss: 8.885e+04, MSE(e): 6.010e-05, MSE(pi1): 1.183e-02, MSE(pi2): 3.619e-05, MSE(pi3): 6.126e-03\n",
      "Epoch 82300, Train loss: 1.386e+03, Test loss: 8.941e+04, MSE(e): 6.495e-05, MSE(pi1): 1.361e-02, MSE(pi2): 3.903e-05, MSE(pi3): 6.000e-03\n",
      "Epoch 82400, Train loss: 1.330e+03, Test loss: 8.874e+04, MSE(e): 5.990e-05, MSE(pi1): 1.190e-02, MSE(pi2): 3.607e-05, MSE(pi3): 6.123e-03\n",
      "Epoch 82500, Train loss: 1.387e+03, Test loss: 8.972e+04, MSE(e): 6.550e-05, MSE(pi1): 1.161e-02, MSE(pi2): 3.896e-05, MSE(pi3): 6.156e-03\n",
      "Epoch 82600, Train loss: 1.557e+03, Test loss: 9.019e+04, MSE(e): 8.243e-05, MSE(pi1): 1.287e-02, MSE(pi2): 4.640e-05, MSE(pi3): 6.036e-03\n",
      "Epoch 82700, Train loss: 1.342e+03, Test loss: 8.848e+04, MSE(e): 6.051e-05, MSE(pi1): 1.318e-02, MSE(pi2): 3.637e-05, MSE(pi3): 6.054e-03\n",
      "Epoch 82800, Train loss: 1.460e+03, Test loss: 8.829e+04, MSE(e): 7.089e-05, MSE(pi1): 1.506e-02, MSE(pi2): 4.166e-05, MSE(pi3): 6.007e-03\n",
      "Epoch 82900, Train loss: 1.876e+03, Test loss: 9.184e+04, MSE(e): 1.137e-04, MSE(pi1): 1.239e-02, MSE(pi2): 5.974e-05, MSE(pi3): 6.146e-03\n",
      "Epoch 83000, Train loss: 1.378e+03, Test loss: 8.815e+04, MSE(e): 6.404e-05, MSE(pi1): 1.235e-02, MSE(pi2): 3.793e-05, MSE(pi3): 6.140e-03\n",
      "Epoch 83100, Train loss: 1.790e+03, Test loss: 9.098e+04, MSE(e): 7.613e-05, MSE(pi1): 3.511e-02, MSE(pi2): 4.755e-05, MSE(pi3): 6.770e-03\n",
      "Epoch 83200, Train loss: 1.497e+03, Test loss: 8.700e+04, MSE(e): 7.468e-05, MSE(pi1): 1.376e-02, MSE(pi2): 4.099e-05, MSE(pi3): 6.122e-03\n",
      "Epoch 83300, Train loss: 1.326e+03, Test loss: 8.836e+04, MSE(e): 5.932e-05, MSE(pi1): 1.234e-02, MSE(pi2): 3.580e-05, MSE(pi3): 6.091e-03\n",
      "Epoch 83400, Train loss: 1.319e+03, Test loss: 8.802e+04, MSE(e): 5.884e-05, MSE(pi1): 1.177e-02, MSE(pi2): 3.537e-05, MSE(pi3): 6.128e-03\n",
      "Epoch 83500, Train loss: 1.321e+03, Test loss: 8.794e+04, MSE(e): 5.885e-05, MSE(pi1): 1.174e-02, MSE(pi2): 3.542e-05, MSE(pi3): 6.148e-03\n",
      "Epoch 83600, Train loss: 1.353e+03, Test loss: 8.844e+04, MSE(e): 6.071e-05, MSE(pi1): 1.165e-02, MSE(pi2): 3.650e-05, MSE(pi3): 6.292e-03\n",
      "Epoch 83700, Train loss: 1.763e+03, Test loss: 9.111e+04, MSE(e): 9.418e-05, MSE(pi1): 2.181e-02, MSE(pi2): 5.126e-05, MSE(pi3): 6.031e-03\n",
      "Epoch 83800, Train loss: 1.315e+03, Test loss: 8.786e+04, MSE(e): 5.841e-05, MSE(pi1): 1.170e-02, MSE(pi2): 3.511e-05, MSE(pi3): 6.134e-03\n",
      "Epoch 83900, Train loss: 1.357e+03, Test loss: 8.675e+04, MSE(e): 6.258e-05, MSE(pi1): 1.142e-02, MSE(pi2): 3.648e-05, MSE(pi3): 6.170e-03\n",
      "Epoch 84000, Train loss: 1.312e+03, Test loss: 8.777e+04, MSE(e): 5.818e-05, MSE(pi1): 1.178e-02, MSE(pi2): 3.500e-05, MSE(pi3): 6.125e-03\n",
      "Epoch 84100, Train loss: 1.316e+03, Test loss: 8.779e+04, MSE(e): 5.812e-05, MSE(pi1): 1.210e-02, MSE(pi2): 3.496e-05, MSE(pi3): 6.133e-03\n",
      "Epoch 84200, Train loss: 1.317e+03, Test loss: 8.804e+04, MSE(e): 5.855e-05, MSE(pi1): 1.171e-02, MSE(pi2): 3.523e-05, MSE(pi3): 6.139e-03\n",
      "Epoch 84300, Train loss: 1.324e+03, Test loss: 8.784e+04, MSE(e): 5.897e-05, MSE(pi1): 1.150e-02, MSE(pi2): 3.543e-05, MSE(pi3): 6.197e-03\n",
      "Epoch 84400, Train loss: 1.310e+03, Test loss: 8.742e+04, MSE(e): 5.796e-05, MSE(pi1): 1.157e-02, MSE(pi2): 3.475e-05, MSE(pi3): 6.147e-03\n",
      "Epoch 84500, Train loss: 1.308e+03, Test loss: 8.728e+04, MSE(e): 5.770e-05, MSE(pi1): 1.187e-02, MSE(pi2): 3.475e-05, MSE(pi3): 6.119e-03\n",
      "Epoch 84600, Train loss: 1.731e+03, Test loss: 9.098e+04, MSE(e): 8.703e-05, MSE(pi1): 2.029e-02, MSE(pi2): 5.185e-05, MSE(pi3): 6.581e-03\n",
      "Epoch 84700, Train loss: 1.305e+03, Test loss: 8.745e+04, MSE(e): 5.747e-05, MSE(pi1): 1.163e-02, MSE(pi2): 3.456e-05, MSE(pi3): 6.141e-03\n",
      "Epoch 84800, Train loss: 1.305e+03, Test loss: 8.728e+04, MSE(e): 5.737e-05, MSE(pi1): 1.164e-02, MSE(pi2): 3.451e-05, MSE(pi3): 6.149e-03\n",
      "Epoch 84900, Train loss: 1.404e+03, Test loss: 8.781e+04, MSE(e): 6.664e-05, MSE(pi1): 1.370e-02, MSE(pi2): 3.928e-05, MSE(pi3): 6.007e-03\n",
      "Epoch 85000, Train loss: 2.090e+03, Test loss: 8.575e+04, MSE(e): 1.345e-04, MSE(pi1): 1.028e-02, MSE(pi2): 6.578e-05, MSE(pi3): 6.413e-03\n",
      "Epoch 85100, Train loss: 5.021e+03, Test loss: 9.673e+04, MSE(e): 4.179e-04, MSE(pi1): 2.873e-02, MSE(pi2): 1.964e-04, MSE(pi3): 5.550e-03\n",
      "Epoch 85200, Train loss: 1.336e+03, Test loss: 8.785e+04, MSE(e): 5.881e-05, MSE(pi1): 1.232e-02, MSE(pi2): 3.539e-05, MSE(pi3): 6.251e-03\n",
      "Epoch 85300, Train loss: 1.352e+03, Test loss: 8.798e+04, MSE(e): 6.215e-05, MSE(pi1): 1.200e-02, MSE(pi2): 3.677e-05, MSE(pi3): 6.103e-03\n",
      "Epoch 85400, Train loss: 1.316e+03, Test loss: 8.662e+04, MSE(e): 5.851e-05, MSE(pi1): 1.136e-02, MSE(pi2): 3.463e-05, MSE(pi3): 6.171e-03\n",
      "Epoch 85500, Train loss: 1.321e+03, Test loss: 8.641e+04, MSE(e): 5.830e-05, MSE(pi1): 1.325e-02, MSE(pi2): 3.474e-05, MSE(pi3): 6.058e-03\n",
      "Epoch 85600, Train loss: 1.987e+03, Test loss: 8.604e+04, MSE(e): 8.986e-05, MSE(pi1): 5.300e-02, MSE(pi2): 5.960e-05, MSE(pi3): 5.585e-03\n",
      "Epoch 85700, Train loss: 1.344e+03, Test loss: 8.589e+04, MSE(e): 5.869e-05, MSE(pi1): 1.541e-02, MSE(pi2): 3.463e-05, MSE(pi3): 6.034e-03\n",
      "Epoch 85800, Train loss: 1.306e+03, Test loss: 8.689e+04, MSE(e): 5.647e-05, MSE(pi1): 1.257e-02, MSE(pi2): 3.390e-05, MSE(pi3): 6.154e-03\n",
      "Epoch 85900, Train loss: 2.382e+03, Test loss: 8.527e+04, MSE(e): 1.627e-04, MSE(pi1): 1.009e-02, MSE(pi2): 7.832e-05, MSE(pi3): 6.540e-03\n",
      "Epoch 86000, Train loss: 3.307e+03, Test loss: 8.390e+04, MSE(e): 2.562e-04, MSE(pi1): 1.197e-02, MSE(pi2): 1.144e-04, MSE(pi3): 6.250e-03\n",
      "Epoch 86100, Train loss: 1.292e+03, Test loss: 8.661e+04, MSE(e): 5.619e-05, MSE(pi1): 1.199e-02, MSE(pi2): 3.386e-05, MSE(pi3): 6.100e-03\n",
      "Epoch 86200, Train loss: 1.294e+03, Test loss: 8.632e+04, MSE(e): 5.626e-05, MSE(pi1): 1.188e-02, MSE(pi2): 3.369e-05, MSE(pi3): 6.123e-03\n",
      "Epoch 86300, Train loss: 1.400e+03, Test loss: 8.576e+04, MSE(e): 6.665e-05, MSE(pi1): 1.076e-02, MSE(pi2): 3.770e-05, MSE(pi3): 6.258e-03\n",
      "Epoch 86400, Train loss: 1.877e+03, Test loss: 8.464e+04, MSE(e): 1.144e-04, MSE(pi1): 1.032e-02, MSE(pi2): 5.667e-05, MSE(pi3): 6.298e-03\n",
      "Epoch 86500, Train loss: 1.288e+03, Test loss: 8.626e+04, MSE(e): 5.582e-05, MSE(pi1): 1.158e-02, MSE(pi2): 3.347e-05, MSE(pi3): 6.140e-03\n",
      "Epoch 86600, Train loss: 1.387e+03, Test loss: 8.600e+04, MSE(e): 5.734e-05, MSE(pi1): 2.128e-02, MSE(pi2): 3.391e-05, MSE(pi3): 6.011e-03\n",
      "Epoch 86700, Train loss: 1.309e+03, Test loss: 8.689e+04, MSE(e): 5.780e-05, MSE(pi1): 1.248e-02, MSE(pi2): 3.470e-05, MSE(pi3): 6.064e-03\n",
      "Epoch 86800, Train loss: 1.723e+03, Test loss: 8.476e+04, MSE(e): 8.604e-05, MSE(pi1): 2.373e-02, MSE(pi2): 4.515e-05, MSE(pi3): 6.257e-03\n",
      "Epoch 86900, Train loss: 1.311e+03, Test loss: 8.636e+04, MSE(e): 5.611e-05, MSE(pi1): 1.254e-02, MSE(pi2): 3.368e-05, MSE(pi3): 6.242e-03\n",
      "Epoch 87000, Train loss: 1.285e+03, Test loss: 8.608e+04, MSE(e): 5.551e-05, MSE(pi1): 1.154e-02, MSE(pi2): 3.321e-05, MSE(pi3): 6.145e-03\n",
      "Epoch 87100, Train loss: 1.297e+03, Test loss: 8.558e+04, MSE(e): 5.669e-05, MSE(pi1): 1.155e-02, MSE(pi2): 3.357e-05, MSE(pi3): 6.142e-03\n",
      "Epoch 87200, Train loss: 1.547e+03, Test loss: 8.703e+04, MSE(e): 5.813e-05, MSE(pi1): 3.338e-02, MSE(pi2): 3.422e-05, MSE(pi3): 6.318e-03\n",
      "Epoch 87300, Train loss: 1.315e+03, Test loss: 8.429e+04, MSE(e): 5.808e-05, MSE(pi1): 1.344e-02, MSE(pi2): 3.536e-05, MSE(pi3): 5.994e-03\n",
      "Epoch 87400, Train loss: 1.410e+03, Test loss: 8.648e+04, MSE(e): 5.734e-05, MSE(pi1): 2.248e-02, MSE(pi2): 3.420e-05, MSE(pi3): 6.116e-03\n",
      "Epoch 87500, Train loss: 1.278e+03, Test loss: 8.629e+04, MSE(e): 5.483e-05, MSE(pi1): 1.173e-02, MSE(pi2): 3.300e-05, MSE(pi3): 6.119e-03\n",
      "Epoch 87600, Train loss: 1.712e+03, Test loss: 8.809e+04, MSE(e): 8.550e-05, MSE(pi1): 2.601e-02, MSE(pi2): 4.829e-05, MSE(pi3): 5.971e-03\n",
      "Epoch 87700, Train loss: 1.275e+03, Test loss: 8.572e+04, MSE(e): 5.457e-05, MSE(pi1): 1.162e-02, MSE(pi2): 3.282e-05, MSE(pi3): 6.130e-03\n",
      "Epoch 87800, Train loss: 1.286e+03, Test loss: 8.535e+04, MSE(e): 5.531e-05, MSE(pi1): 1.227e-02, MSE(pi2): 3.294e-05, MSE(pi3): 6.107e-03\n",
      "Epoch 87900, Train loss: 1.279e+03, Test loss: 8.534e+04, MSE(e): 5.487e-05, MSE(pi1): 1.184e-02, MSE(pi2): 3.279e-05, MSE(pi3): 6.115e-03\n",
      "Epoch 88000, Train loss: 1.295e+03, Test loss: 8.550e+04, MSE(e): 5.647e-05, MSE(pi1): 1.120e-02, MSE(pi2): 3.329e-05, MSE(pi3): 6.181e-03\n",
      "Epoch 88100, Train loss: 1.539e+03, Test loss: 8.557e+04, MSE(e): 7.966e-05, MSE(pi1): 1.626e-02, MSE(pi2): 4.901e-05, MSE(pi3): 5.801e-03\n",
      "Epoch 88200, Train loss: 4.051e+03, Test loss: 9.289e+04, MSE(e): 3.298e-04, MSE(pi1): 1.785e-02, MSE(pi2): 1.521e-04, MSE(pi3): 5.746e-03\n",
      "Epoch 88300, Train loss: 1.310e+03, Test loss: 8.555e+04, MSE(e): 5.575e-05, MSE(pi1): 1.230e-02, MSE(pi2): 3.345e-05, MSE(pi3): 6.293e-03\n",
      "Epoch 88400, Train loss: 1.569e+03, Test loss: 8.561e+04, MSE(e): 5.703e-05, MSE(pi1): 3.895e-02, MSE(pi2): 3.355e-05, MSE(pi3): 6.096e-03\n",
      "Epoch 88500, Train loss: 1.312e+03, Test loss: 8.467e+04, MSE(e): 5.730e-05, MSE(pi1): 1.342e-02, MSE(pi2): 3.378e-05, MSE(pi3): 6.049e-03\n",
      "Epoch 88600, Train loss: 1.310e+03, Test loss: 8.513e+04, MSE(e): 5.696e-05, MSE(pi1): 1.134e-02, MSE(pi2): 3.370e-05, MSE(pi3): 6.265e-03\n",
      "Epoch 88700, Train loss: 1.276e+03, Test loss: 8.490e+04, MSE(e): 5.466e-05, MSE(pi1): 1.129e-02, MSE(pi2): 3.249e-05, MSE(pi3): 6.164e-03\n",
      "Epoch 88800, Train loss: 1.293e+03, Test loss: 8.567e+04, MSE(e): 5.633e-05, MSE(pi1): 1.239e-02, MSE(pi2): 3.376e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 88900, Train loss: 1.538e+03, Test loss: 8.438e+04, MSE(e): 7.934e-05, MSE(pi1): 1.223e-02, MSE(pi2): 4.180e-05, MSE(pi3): 6.224e-03\n",
      "Epoch 89000, Train loss: 1.586e+03, Test loss: 8.758e+04, MSE(e): 8.222e-05, MSE(pi1): 1.146e-02, MSE(pi2): 5.158e-05, MSE(pi3): 6.493e-03\n",
      "Epoch 89100, Train loss: 1.263e+03, Test loss: 8.513e+04, MSE(e): 5.336e-05, MSE(pi1): 1.142e-02, MSE(pi2): 3.207e-05, MSE(pi3): 6.154e-03\n",
      "Epoch 89200, Train loss: 1.329e+03, Test loss: 8.534e+04, MSE(e): 5.801e-05, MSE(pi1): 1.153e-02, MSE(pi2): 3.527e-05, MSE(pi3): 6.341e-03\n",
      "Epoch 89300, Train loss: 1.721e+03, Test loss: 8.356e+04, MSE(e): 8.607e-05, MSE(pi1): 2.960e-02, MSE(pi2): 5.680e-05, MSE(pi3): 5.644e-03\n",
      "Epoch 89400, Train loss: 1.264e+03, Test loss: 8.484e+04, MSE(e): 5.308e-05, MSE(pi1): 1.206e-02, MSE(pi2): 3.191e-05, MSE(pi3): 6.122e-03\n",
      "Epoch 89500, Train loss: 1.259e+03, Test loss: 8.481e+04, MSE(e): 5.305e-05, MSE(pi1): 1.173e-02, MSE(pi2): 3.192e-05, MSE(pi3): 6.115e-03\n",
      "Epoch 89600, Train loss: 1.292e+03, Test loss: 8.433e+04, MSE(e): 5.397e-05, MSE(pi1): 1.519e-02, MSE(pi2): 3.256e-05, MSE(pi3): 6.001e-03\n",
      "Epoch 89700, Train loss: 1.257e+03, Test loss: 8.472e+04, MSE(e): 5.281e-05, MSE(pi1): 1.158e-02, MSE(pi2): 3.176e-05, MSE(pi3): 6.130e-03\n",
      "Epoch 89800, Train loss: 1.322e+03, Test loss: 8.511e+04, MSE(e): 5.879e-05, MSE(pi1): 1.262e-02, MSE(pi2): 3.463e-05, MSE(pi3): 6.082e-03\n",
      "Epoch 89900, Train loss: 1.384e+03, Test loss: 8.539e+04, MSE(e): 6.453e-05, MSE(pi1): 1.002e-02, MSE(pi2): 3.967e-05, MSE(pi3): 6.389e-03\n",
      "Epoch 90000, Train loss: 1.289e+03, Test loss: 8.407e+04, MSE(e): 5.587e-05, MSE(pi1): 1.109e-02, MSE(pi2): 3.267e-05, MSE(pi3): 6.197e-03\n",
      "Epoch 90100, Train loss: 1.260e+03, Test loss: 8.417e+04, MSE(e): 5.317e-05, MSE(pi1): 1.149e-02, MSE(pi2): 3.166e-05, MSE(pi3): 6.138e-03\n",
      "Epoch 90200, Train loss: 1.254e+03, Test loss: 8.452e+04, MSE(e): 5.248e-05, MSE(pi1): 1.185e-02, MSE(pi2): 3.159e-05, MSE(pi3): 6.103e-03\n",
      "Epoch 90300, Train loss: 1.280e+03, Test loss: 8.425e+04, MSE(e): 5.257e-05, MSE(pi1): 1.424e-02, MSE(pi2): 3.144e-05, MSE(pi3): 6.123e-03\n",
      "Epoch 90400, Train loss: 2.383e+03, Test loss: 9.062e+04, MSE(e): 1.588e-04, MSE(pi1): 1.885e-02, MSE(pi2): 7.640e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 90500, Train loss: 1.250e+03, Test loss: 8.434e+04, MSE(e): 5.211e-05, MSE(pi1): 1.154e-02, MSE(pi2): 3.131e-05, MSE(pi3): 6.130e-03\n",
      "Epoch 90600, Train loss: 1.413e+03, Test loss: 8.302e+04, MSE(e): 6.763e-05, MSE(pi1): 1.305e-02, MSE(pi2): 3.763e-05, MSE(pi3): 6.059e-03\n",
      "Epoch 90700, Train loss: 1.334e+03, Test loss: 8.483e+04, MSE(e): 6.020e-05, MSE(pi1): 1.304e-02, MSE(pi2): 3.542e-05, MSE(pi3): 6.019e-03\n",
      "Epoch 90800, Train loss: 1.806e+03, Test loss: 8.680e+04, MSE(e): 9.216e-05, MSE(pi1): 2.304e-02, MSE(pi2): 5.097e-05, MSE(pi3): 6.537e-03\n",
      "Epoch 90900, Train loss: 2.341e+03, Test loss: 8.274e+04, MSE(e): 1.573e-04, MSE(pi1): 1.200e-02, MSE(pi2): 7.421e-05, MSE(pi3): 6.474e-03\n",
      "Epoch 91000, Train loss: 1.360e+03, Test loss: 8.333e+04, MSE(e): 6.137e-05, MSE(pi1): 1.199e-02, MSE(pi2): 3.448e-05, MSE(pi3): 6.260e-03\n",
      "Epoch 91100, Train loss: 2.213e+03, Test loss: 8.472e+04, MSE(e): 1.198e-04, MSE(pi1): 3.140e-02, MSE(pi2): 6.798e-05, MSE(pi3): 7.007e-03\n",
      "Epoch 91200, Train loss: 1.292e+03, Test loss: 8.485e+04, MSE(e): 5.357e-05, MSE(pi1): 1.256e-02, MSE(pi2): 3.232e-05, MSE(pi3): 6.305e-03\n",
      "Epoch 91300, Train loss: 2.016e+03, Test loss: 8.110e+04, MSE(e): 1.230e-04, MSE(pi1): 1.887e-02, MSE(pi2): 6.120e-05, MSE(pi3): 5.963e-03\n",
      "Epoch 91400, Train loss: 1.357e+03, Test loss: 8.298e+04, MSE(e): 6.003e-05, MSE(pi1): 1.355e-02, MSE(pi2): 3.396e-05, MSE(pi3): 6.211e-03\n",
      "Epoch 91500, Train loss: 1.242e+03, Test loss: 8.387e+04, MSE(e): 5.134e-05, MSE(pi1): 1.147e-02, MSE(pi2): 3.086e-05, MSE(pi3): 6.136e-03\n",
      "Epoch 91600, Train loss: 1.457e+03, Test loss: 8.301e+04, MSE(e): 7.188e-05, MSE(pi1): 1.201e-02, MSE(pi2): 3.824e-05, MSE(pi3): 6.185e-03\n",
      "Epoch 91700, Train loss: 1.307e+03, Test loss: 8.413e+04, MSE(e): 5.204e-05, MSE(pi1): 1.786e-02, MSE(pi2): 3.119e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 91800, Train loss: 1.246e+03, Test loss: 8.319e+04, MSE(e): 5.177e-05, MSE(pi1): 1.178e-02, MSE(pi2): 3.094e-05, MSE(pi3): 6.109e-03\n",
      "Epoch 91900, Train loss: 1.879e+03, Test loss: 8.221e+04, MSE(e): 1.029e-04, MSE(pi1): 2.583e-02, MSE(pi2): 5.182e-05, MSE(pi3): 5.915e-03\n",
      "Epoch 92000, Train loss: 1.416e+03, Test loss: 8.227e+04, MSE(e): 6.818e-05, MSE(pi1): 1.108e-02, MSE(pi2): 3.710e-05, MSE(pi3): 6.229e-03\n",
      "Epoch 92100, Train loss: 1.237e+03, Test loss: 8.343e+04, MSE(e): 5.086e-05, MSE(pi1): 1.142e-02, MSE(pi2): 3.050e-05, MSE(pi3): 6.138e-03\n",
      "Epoch 92200, Train loss: 1.237e+03, Test loss: 8.327e+04, MSE(e): 5.076e-05, MSE(pi1): 1.171e-02, MSE(pi2): 3.052e-05, MSE(pi3): 6.118e-03\n",
      "Epoch 92300, Train loss: 1.241e+03, Test loss: 8.312e+04, MSE(e): 5.119e-05, MSE(pi1): 1.131e-02, MSE(pi2): 3.052e-05, MSE(pi3): 6.164e-03\n",
      "Epoch 92400, Train loss: 1.301e+03, Test loss: 8.375e+04, MSE(e): 5.184e-05, MSE(pi1): 1.753e-02, MSE(pi2): 3.106e-05, MSE(pi3): 6.077e-03\n",
      "Epoch 92500, Train loss: 1.300e+03, Test loss: 8.257e+04, MSE(e): 5.709e-05, MSE(pi1): 1.093e-02, MSE(pi2): 3.263e-05, MSE(pi3): 6.195e-03\n",
      "Epoch 92600, Train loss: 1.479e+03, Test loss: 8.286e+04, MSE(e): 7.176e-05, MSE(pi1): 1.139e-02, MSE(pi2): 4.018e-05, MSE(pi3): 6.473e-03\n",
      "Epoch 92700, Train loss: 1.475e+03, Test loss: 8.164e+04, MSE(e): 7.420e-05, MSE(pi1): 1.159e-02, MSE(pi2): 3.914e-05, MSE(pi3): 6.168e-03\n",
      "Epoch 92800, Train loss: 2.300e+03, Test loss: 8.251e+04, MSE(e): 1.491e-04, MSE(pi1): 1.291e-02, MSE(pi2): 7.618e-05, MSE(pi3): 6.796e-03\n",
      "Epoch 92900, Train loss: 1.556e+03, Test loss: 8.466e+04, MSE(e): 8.203e-05, MSE(pi1): 1.403e-02, MSE(pi2): 4.498e-05, MSE(pi3): 5.957e-03\n",
      "Epoch 93000, Train loss: 2.302e+03, Test loss: 8.162e+04, MSE(e): 1.562e-04, MSE(pi1): 1.085e-02, MSE(pi2): 7.203e-05, MSE(pi3): 6.313e-03\n",
      "Epoch 93100, Train loss: 1.233e+03, Test loss: 8.322e+04, MSE(e): 5.015e-05, MSE(pi1): 1.235e-02, MSE(pi2): 3.012e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 93200, Train loss: 1.736e+03, Test loss: 8.491e+04, MSE(e): 9.781e-05, MSE(pi1): 1.332e-02, MSE(pi2): 5.182e-05, MSE(pi3): 6.247e-03\n",
      "Epoch 93300, Train loss: 1.229e+03, Test loss: 8.275e+04, MSE(e): 5.011e-05, MSE(pi1): 1.141e-02, MSE(pi2): 2.996e-05, MSE(pi3): 6.136e-03\n",
      "Epoch 93400, Train loss: 1.533e+03, Test loss: 8.447e+04, MSE(e): 5.842e-05, MSE(pi1): 2.869e-02, MSE(pi2): 3.557e-05, MSE(pi3): 6.617e-03\n",
      "Epoch 93500, Train loss: 3.357e+03, Test loss: 8.013e+04, MSE(e): 2.544e-04, MSE(pi1): 2.040e-02, MSE(pi2): 1.123e-04, MSE(pi3): 6.090e-03\n",
      "Epoch 93600, Train loss: 2.347e+03, Test loss: 8.110e+04, MSE(e): 1.563e-04, MSE(pi1): 1.322e-02, MSE(pi2): 7.259e-05, MSE(pi3): 6.515e-03\n",
      "Epoch 93700, Train loss: 1.223e+03, Test loss: 8.270e+04, MSE(e): 4.958e-05, MSE(pi1): 1.141e-02, MSE(pi2): 2.975e-05, MSE(pi3): 6.135e-03\n",
      "Epoch 93800, Train loss: 1.461e+03, Test loss: 8.453e+04, MSE(e): 7.325e-05, MSE(pi1): 1.256e-02, MSE(pi2): 4.057e-05, MSE(pi3): 6.024e-03\n",
      "Epoch 93900, Train loss: 1.303e+03, Test loss: 8.211e+04, MSE(e): 5.631e-05, MSE(pi1): 1.176e-02, MSE(pi2): 3.217e-05, MSE(pi3): 6.219e-03\n",
      "Epoch 94000, Train loss: 1.239e+03, Test loss: 8.192e+04, MSE(e): 5.100e-05, MSE(pi1): 1.229e-02, MSE(pi2): 3.088e-05, MSE(pi3): 6.062e-03\n",
      "Epoch 94100, Train loss: 1.242e+03, Test loss: 8.198e+04, MSE(e): 5.075e-05, MSE(pi1): 1.270e-02, MSE(pi2): 3.009e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 94200, Train loss: 1.229e+03, Test loss: 8.220e+04, MSE(e): 5.015e-05, MSE(pi1): 1.134e-02, MSE(pi2): 2.975e-05, MSE(pi3): 6.143e-03\n",
      "Epoch 94300, Train loss: 1.482e+03, Test loss: 8.088e+04, MSE(e): 7.527e-05, MSE(pi1): 1.105e-02, MSE(pi2): 3.934e-05, MSE(pi3): 6.192e-03\n",
      "Epoch 94400, Train loss: 1.256e+03, Test loss: 8.262e+04, MSE(e): 4.940e-05, MSE(pi1): 1.486e-02, MSE(pi2): 2.955e-05, MSE(pi3): 6.138e-03\n",
      "Epoch 94500, Train loss: 1.698e+03, Test loss: 8.463e+04, MSE(e): 7.918e-05, MSE(pi1): 3.295e-02, MSE(pi2): 4.462e-05, MSE(pi3): 5.771e-03\n",
      "Epoch 94600, Train loss: 1.327e+03, Test loss: 8.162e+04, MSE(e): 5.808e-05, MSE(pi1): 1.245e-02, MSE(pi2): 3.252e-05, MSE(pi3): 6.220e-03\n",
      "Epoch 94700, Train loss: 1.220e+03, Test loss: 8.208e+04, MSE(e): 4.924e-05, MSE(pi1): 1.129e-02, MSE(pi2): 2.937e-05, MSE(pi3): 6.146e-03\n",
      "Epoch 94800, Train loss: 1.591e+03, Test loss: 8.259e+04, MSE(e): 5.206e-05, MSE(pi1): 4.542e-02, MSE(pi2): 3.015e-05, MSE(pi3): 6.159e-03\n",
      "Epoch 94900, Train loss: 1.262e+03, Test loss: 8.172e+04, MSE(e): 5.330e-05, MSE(pi1): 1.143e-02, MSE(pi2): 3.073e-05, MSE(pi3): 6.143e-03\n",
      "Epoch 95000, Train loss: 1.298e+03, Test loss: 8.242e+04, MSE(e): 5.378e-05, MSE(pi1): 1.653e-02, MSE(pi2): 3.268e-05, MSE(pi3): 5.945e-03\n",
      "Epoch 95100, Train loss: 1.253e+03, Test loss: 8.251e+04, MSE(e): 5.026e-05, MSE(pi1): 1.343e-02, MSE(pi2): 2.995e-05, MSE(pi3): 6.160e-03\n",
      "Epoch 95200, Train loss: 4.281e+03, Test loss: 7.875e+04, MSE(e): 3.401e-04, MSE(pi1): 2.799e-02, MSE(pi2): 1.478e-04, MSE(pi3): 6.002e-03\n",
      "Epoch 95300, Train loss: 1.212e+03, Test loss: 8.193e+04, MSE(e): 4.844e-05, MSE(pi1): 1.141e-02, MSE(pi2): 2.903e-05, MSE(pi3): 6.135e-03\n",
      "Epoch 95400, Train loss: 1.216e+03, Test loss: 8.181e+04, MSE(e): 4.884e-05, MSE(pi1): 1.124e-02, MSE(pi2): 2.909e-05, MSE(pi3): 6.152e-03\n",
      "Epoch 95500, Train loss: 5.653e+03, Test loss: 8.080e+04, MSE(e): 4.729e-04, MSE(pi1): 2.153e-02, MSE(pi2): 2.101e-04, MSE(pi3): 7.087e-03\n",
      "Epoch 95600, Train loss: 1.295e+03, Test loss: 8.168e+04, MSE(e): 5.032e-05, MSE(pi1): 1.876e-02, MSE(pi2): 3.031e-05, MSE(pi3): 6.045e-03\n",
      "Epoch 95700, Train loss: 1.423e+03, Test loss: 8.046e+04, MSE(e): 6.523e-05, MSE(pi1): 1.765e-02, MSE(pi2): 3.656e-05, MSE(pi3): 5.940e-03\n",
      "Epoch 95800, Train loss: 1.258e+03, Test loss: 8.238e+04, MSE(e): 5.300e-05, MSE(pi1): 1.236e-02, MSE(pi2): 3.147e-05, MSE(pi3): 6.045e-03\n",
      "Epoch 95900, Train loss: 1.245e+03, Test loss: 8.131e+04, MSE(e): 5.174e-05, MSE(pi1): 1.090e-02, MSE(pi2): 3.004e-05, MSE(pi3): 6.189e-03\n",
      "Epoch 96000, Train loss: 1.388e+03, Test loss: 8.493e+04, MSE(e): 6.558e-05, MSE(pi1): 1.131e-02, MSE(pi2): 3.726e-05, MSE(pi3): 6.189e-03\n",
      "Epoch 96100, Train loss: 1.222e+03, Test loss: 8.142e+04, MSE(e): 4.835e-05, MSE(pi1): 1.350e-02, MSE(pi2): 2.918e-05, MSE(pi3): 6.031e-03\n",
      "Epoch 96200, Train loss: 1.209e+03, Test loss: 8.176e+04, MSE(e): 4.812e-05, MSE(pi1): 1.113e-02, MSE(pi2): 2.872e-05, MSE(pi3): 6.163e-03\n",
      "Epoch 96300, Train loss: 1.783e+03, Test loss: 8.489e+04, MSE(e): 8.965e-05, MSE(pi1): 2.830e-02, MSE(pi2): 4.726e-05, MSE(pi3): 6.036e-03\n",
      "Epoch 96400, Train loss: 1.204e+03, Test loss: 8.147e+04, MSE(e): 4.773e-05, MSE(pi1): 1.175e-02, MSE(pi2): 2.872e-05, MSE(pi3): 6.096e-03\n",
      "Epoch 96500, Train loss: 1.206e+03, Test loss: 8.170e+04, MSE(e): 4.786e-05, MSE(pi1): 1.123e-02, MSE(pi2): 2.875e-05, MSE(pi3): 6.153e-03\n",
      "Epoch 96600, Train loss: 1.485e+03, Test loss: 7.993e+04, MSE(e): 7.277e-05, MSE(pi1): 1.448e-02, MSE(pi2): 3.764e-05, MSE(pi3): 6.123e-03\n",
      "Epoch 96700, Train loss: 1.202e+03, Test loss: 8.138e+04, MSE(e): 4.741e-05, MSE(pi1): 1.143e-02, MSE(pi2): 2.845e-05, MSE(pi3): 6.132e-03\n",
      "Epoch 96800, Train loss: 1.249e+03, Test loss: 8.164e+04, MSE(e): 5.094e-05, MSE(pi1): 1.389e-02, MSE(pi2): 3.052e-05, MSE(pi3): 6.011e-03\n",
      "Epoch 96900, Train loss: 1.359e+03, Test loss: 8.239e+04, MSE(e): 6.298e-05, MSE(pi1): 1.282e-02, MSE(pi2): 3.589e-05, MSE(pi3): 6.009e-03\n",
      "Epoch 97000, Train loss: 1.266e+03, Test loss: 8.152e+04, MSE(e): 5.189e-05, MSE(pi1): 1.511e-02, MSE(pi2): 3.170e-05, MSE(pi3): 5.964e-03\n",
      "Epoch 97100, Train loss: 1.572e+03, Test loss: 8.294e+04, MSE(e): 7.007e-05, MSE(pi1): 1.980e-02, MSE(pi2): 4.467e-05, MSE(pi3): 6.733e-03\n",
      "Epoch 97200, Train loss: 1.201e+03, Test loss: 8.136e+04, MSE(e): 4.726e-05, MSE(pi1): 1.123e-02, MSE(pi2): 2.838e-05, MSE(pi3): 6.162e-03\n",
      "Epoch 97300, Train loss: 1.199e+03, Test loss: 8.102e+04, MSE(e): 4.716e-05, MSE(pi1): 1.153e-02, MSE(pi2): 2.821e-05, MSE(pi3): 6.118e-03\n",
      "Epoch 97400, Train loss: 1.199e+03, Test loss: 8.104e+04, MSE(e): 4.718e-05, MSE(pi1): 1.115e-02, MSE(pi2): 2.819e-05, MSE(pi3): 6.160e-03\n",
      "Epoch 97500, Train loss: 1.409e+03, Test loss: 8.309e+04, MSE(e): 6.346e-05, MSE(pi1): 1.342e-02, MSE(pi2): 3.728e-05, MSE(pi3): 6.397e-03\n",
      "Epoch 97600, Train loss: 1.196e+03, Test loss: 8.087e+04, MSE(e): 4.687e-05, MSE(pi1): 1.139e-02, MSE(pi2): 2.807e-05, MSE(pi3): 6.131e-03\n",
      "Epoch 97700, Train loss: 1.195e+03, Test loss: 8.099e+04, MSE(e): 4.682e-05, MSE(pi1): 1.144e-02, MSE(pi2): 2.814e-05, MSE(pi3): 6.122e-03\n",
      "Epoch 97800, Train loss: 1.469e+03, Test loss: 7.961e+04, MSE(e): 7.397e-05, MSE(pi1): 1.104e-02, MSE(pi2): 3.838e-05, MSE(pi3): 6.186e-03\n",
      "Epoch 97900, Train loss: 1.322e+03, Test loss: 8.210e+04, MSE(e): 5.943e-05, MSE(pi1): 1.240e-02, MSE(pi2): 3.405e-05, MSE(pi3): 6.038e-03\n",
      "Epoch 98000, Train loss: 1.718e+03, Test loss: 7.885e+04, MSE(e): 9.817e-05, MSE(pi1): 1.209e-02, MSE(pi2): 4.804e-05, MSE(pi3): 6.154e-03\n",
      "Epoch 98100, Train loss: 1.193e+03, Test loss: 8.078e+04, MSE(e): 4.660e-05, MSE(pi1): 1.116e-02, MSE(pi2): 2.788e-05, MSE(pi3): 6.157e-03\n",
      "Epoch 98200, Train loss: 1.199e+03, Test loss: 8.103e+04, MSE(e): 4.715e-05, MSE(pi1): 1.185e-02, MSE(pi2): 2.835e-05, MSE(pi3): 6.088e-03\n",
      "Epoch 98300, Train loss: 1.197e+03, Test loss: 8.052e+04, MSE(e): 4.703e-05, MSE(pi1): 1.112e-02, MSE(pi2): 2.795e-05, MSE(pi3): 6.157e-03\n",
      "Epoch 98400, Train loss: 1.200e+03, Test loss: 8.127e+04, MSE(e): 4.667e-05, MSE(pi1): 1.143e-02, MSE(pi2): 2.801e-05, MSE(pi3): 6.189e-03\n",
      "Epoch 98500, Train loss: 1.438e+03, Test loss: 7.922e+04, MSE(e): 7.045e-05, MSE(pi1): 9.923e-03, MSE(pi2): 3.809e-05, MSE(pi3): 6.341e-03\n",
      "Epoch 98600, Train loss: 1.194e+03, Test loss: 8.046e+04, MSE(e): 4.635e-05, MSE(pi1): 1.171e-02, MSE(pi2): 2.769e-05, MSE(pi3): 6.133e-03\n",
      "Epoch 98700, Train loss: 1.189e+03, Test loss: 8.060e+04, MSE(e): 4.618e-05, MSE(pi1): 1.136e-02, MSE(pi2): 2.775e-05, MSE(pi3): 6.132e-03\n",
      "Epoch 98800, Train loss: 1.258e+03, Test loss: 8.165e+04, MSE(e): 5.265e-05, MSE(pi1): 1.161e-02, MSE(pi2): 3.073e-05, MSE(pi3): 6.153e-03\n",
      "Epoch 98900, Train loss: 1.310e+03, Test loss: 7.967e+04, MSE(e): 5.701e-05, MSE(pi1): 1.173e-02, MSE(pi2): 3.177e-05, MSE(pi3): 6.230e-03\n",
      "Epoch 99000, Train loss: 1.613e+03, Test loss: 7.945e+04, MSE(e): 7.160e-05, MSE(pi1): 3.174e-02, MSE(pi2): 4.073e-05, MSE(pi3): 5.792e-03\n",
      "Epoch 99100, Train loss: 1.320e+03, Test loss: 7.990e+04, MSE(e): 4.756e-05, MSE(pi1): 2.304e-02, MSE(pi2): 2.825e-05, MSE(pi3): 6.138e-03\n",
      "Epoch 99200, Train loss: 1.186e+03, Test loss: 8.039e+04, MSE(e): 4.598e-05, MSE(pi1): 1.154e-02, MSE(pi2): 2.766e-05, MSE(pi3): 6.110e-03\n",
      "Epoch 99300, Train loss: 3.759e+03, Test loss: 7.869e+04, MSE(e): 3.011e-04, MSE(pi1): 9.000e-03, MSE(pi2): 1.318e-04, MSE(pi3): 6.571e-03\n",
      "Epoch 99400, Train loss: 1.270e+03, Test loss: 7.932e+04, MSE(e): 5.393e-05, MSE(pi1): 1.124e-02, MSE(pi2): 3.033e-05, MSE(pi3): 6.184e-03\n",
      "Epoch 99500, Train loss: 1.332e+03, Test loss: 8.045e+04, MSE(e): 4.681e-05, MSE(pi1): 2.483e-02, MSE(pi2): 2.754e-05, MSE(pi3): 6.156e-03\n",
      "Epoch 99600, Train loss: 1.383e+03, Test loss: 7.979e+04, MSE(e): 6.408e-05, MSE(pi1): 1.091e-02, MSE(pi2): 3.481e-05, MSE(pi3): 6.335e-03\n",
      "Epoch 99700, Train loss: 1.299e+03, Test loss: 7.987e+04, MSE(e): 4.794e-05, MSE(pi1): 2.120e-02, MSE(pi2): 2.893e-05, MSE(pi3): 6.079e-03\n",
      "Epoch 99800, Train loss: 1.184e+03, Test loss: 8.010e+04, MSE(e): 4.556e-05, MSE(pi1): 1.106e-02, MSE(pi2): 2.727e-05, MSE(pi3): 6.175e-03\n",
      "Epoch 99900, Train loss: 1.185e+03, Test loss: 8.025e+04, MSE(e): 4.574e-05, MSE(pi1): 1.124e-02, MSE(pi2): 2.746e-05, MSE(pi3): 6.147e-03\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_epoch = n_epochs-1\n",
    "# n_epochs = 20000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 5\n",
    "\n",
    "# second_lr = 3e-4\n",
    "\n",
    "# train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
