{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Own library imports\n",
    "from vecopsciml.utils import TensOps\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "\n",
    "# Function from this project\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "# Import model\n",
    "from architectures.pgnniv_baseline import PGNNIVBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder successfully created at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning\n",
      "Folder successfully created at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning/baseline\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear/sigmoid_nonlinear.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning')\n",
    "\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning/baseline')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_TRANSFERLEARNING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear/sigmoid_nonlinear.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 800\n",
      "Validation dataset length: 200\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X_train, y_train, K_train, f_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 1.363e+09, Test loss: 9.983e+08, MSE(e): 1.115e+02, MSE(pi1): 2.419e+04, MSE(pi2): 4.739e+01, MSE(pi3): 5.451e+01\n",
      "Epoch 100, Train loss: 1.522e+07, Test loss: 1.479e+07, MSE(e): 1.478e+00, MSE(pi1): 2.177e+01, MSE(pi2): 9.969e-01, MSE(pi3): 2.217e+00\n",
      "Epoch 200, Train loss: 1.465e+07, Test loss: 1.400e+07, MSE(e): 1.431e+00, MSE(pi1): 1.956e+01, MSE(pi2): 9.813e-01, MSE(pi3): 1.493e+00\n",
      "Epoch 300, Train loss: 1.456e+07, Test loss: 1.384e+07, MSE(e): 1.426e+00, MSE(pi1): 1.810e+01, MSE(pi2): 9.799e-01, MSE(pi3): 1.219e+00\n",
      "Epoch 400, Train loss: 1.453e+07, Test loss: 1.376e+07, MSE(e): 1.424e+00, MSE(pi1): 1.702e+01, MSE(pi2): 9.790e-01, MSE(pi3): 1.150e+00\n",
      "Epoch 500, Train loss: 1.445e+07, Test loss: 1.366e+07, MSE(e): 1.421e+00, MSE(pi1): 1.416e+01, MSE(pi2): 9.771e-01, MSE(pi3): 9.428e-01\n",
      "Epoch 600, Train loss: 9.112e+06, Test loss: 8.543e+06, MSE(e): 9.028e-01, MSE(pi1): 4.032e+00, MSE(pi2): 6.174e-01, MSE(pi3): 4.255e-01\n",
      "Epoch 700, Train loss: 5.788e+06, Test loss: 5.789e+06, MSE(e): 5.697e-01, MSE(pi1): 6.539e+00, MSE(pi2): 3.879e-01, MSE(pi3): 2.541e-01\n",
      "Epoch 800, Train loss: 5.734e+06, Test loss: 5.707e+06, MSE(e): 5.643e-01, MSE(pi1): 6.608e+00, MSE(pi2): 3.841e-01, MSE(pi3): 2.511e-01\n",
      "Epoch 900, Train loss: 5.643e+06, Test loss: 5.584e+06, MSE(e): 5.570e-01, MSE(pi1): 4.995e+00, MSE(pi2): 3.800e-01, MSE(pi3): 2.228e-01\n",
      "Epoch 1000, Train loss: 5.568e+06, Test loss: 5.506e+06, MSE(e): 5.496e-01, MSE(pi1): 4.996e+00, MSE(pi2): 3.749e-01, MSE(pi3): 2.193e-01\n",
      "Epoch 1100, Train loss: 2.923e+05, Test loss: 3.796e+05, MSE(e): 2.625e-02, MSE(pi1): 2.621e+00, MSE(pi2): 1.494e-02, MSE(pi3): 3.610e-02\n",
      "Epoch 1200, Train loss: 1.363e+05, Test loss: 2.134e+05, MSE(e): 9.656e-03, MSE(pi1): 3.462e+00, MSE(pi2): 5.538e-03, MSE(pi3): 5.096e-02\n",
      "Epoch 1300, Train loss: 7.800e+04, Test loss: 1.322e+05, MSE(e): 4.955e-03, MSE(pi1): 2.450e+00, MSE(pi2): 2.964e-03, MSE(pi3): 3.941e-02\n",
      "Epoch 1400, Train loss: 8.688e+04, Test loss: 1.417e+05, MSE(e): 6.021e-03, MSE(pi1): 2.353e+00, MSE(pi2): 3.354e-03, MSE(pi3): 3.133e-02\n",
      "Epoch 1500, Train loss: 8.540e+04, Test loss: 1.395e+05, MSE(e): 5.041e-03, MSE(pi1): 3.027e+00, MSE(pi2): 2.800e-03, MSE(pi3): 4.721e-02\n",
      "Epoch 1600, Train loss: 6.062e+04, Test loss: 1.078e+05, MSE(e): 3.694e-03, MSE(pi1): 2.094e+00, MSE(pi2): 2.013e-03, MSE(pi3): 2.740e-02\n",
      "Epoch 1700, Train loss: 5.149e+04, Test loss: 9.390e+04, MSE(e): 2.797e-03, MSE(pi1): 2.039e+00, MSE(pi2): 1.426e-03, MSE(pi3): 3.137e-02\n",
      "Epoch 1800, Train loss: 4.160e+04, Test loss: 7.775e+04, MSE(e): 1.926e-03, MSE(pi1): 1.972e+00, MSE(pi2): 1.003e-03, MSE(pi3): 2.614e-02\n",
      "Epoch 1900, Train loss: 4.463e+04, Test loss: 7.910e+04, MSE(e): 2.516e-03, MSE(pi1): 1.770e+00, MSE(pi2): 1.255e-03, MSE(pi3): 1.768e-02\n",
      "Epoch 2000, Train loss: 3.638e+04, Test loss: 7.145e+04, MSE(e): 1.972e-03, MSE(pi1): 1.501e+00, MSE(pi2): 1.020e-03, MSE(pi3): 1.657e-02\n",
      "Epoch 2100, Train loss: 5.207e+04, Test loss: 1.051e+05, MSE(e): 3.473e-03, MSE(pi1): 1.537e+00, MSE(pi2): 1.685e-03, MSE(pi3): 1.962e-02\n",
      "Epoch 2200, Train loss: 7.658e+04, Test loss: 8.208e+04, MSE(e): 5.783e-03, MSE(pi1): 1.600e+00, MSE(pi2): 2.979e-03, MSE(pi3): 2.747e-02\n",
      "Epoch 2300, Train loss: 3.592e+04, Test loss: 6.796e+04, MSE(e): 1.767e-03, MSE(pi1): 1.607e+00, MSE(pi2): 8.755e-04, MSE(pi3): 2.174e-02\n",
      "Epoch 2400, Train loss: 4.847e+04, Test loss: 1.056e+05, MSE(e): 2.986e-03, MSE(pi1): 1.656e+00, MSE(pi2): 1.424e-03, MSE(pi3): 2.050e-02\n",
      "Epoch 2500, Train loss: 3.392e+04, Test loss: 7.038e+04, MSE(e): 1.564e-03, MSE(pi1): 1.614e+00, MSE(pi2): 7.508e-04, MSE(pi3): 2.134e-02\n",
      "Epoch 2600, Train loss: 4.997e+04, Test loss: 1.135e+05, MSE(e): 3.260e-03, MSE(pi1): 1.525e+00, MSE(pi2): 1.588e-03, MSE(pi3): 2.108e-02\n",
      "Epoch 2700, Train loss: 2.586e+04, Test loss: 4.776e+04, MSE(e): 9.404e-04, MSE(pi1): 1.464e+00, MSE(pi2): 4.802e-04, MSE(pi3): 1.817e-02\n",
      "Epoch 2800, Train loss: 3.538e+04, Test loss: 7.948e+04, MSE(e): 1.916e-03, MSE(pi1): 1.439e+00, MSE(pi2): 9.099e-04, MSE(pi3): 1.828e-02\n",
      "Epoch 2900, Train loss: 4.259e+04, Test loss: 8.931e+04, MSE(e): 2.241e-03, MSE(pi1): 1.771e+00, MSE(pi2): 1.012e-03, MSE(pi3): 2.482e-02\n",
      "Epoch 3000, Train loss: 8.242e+04, Test loss: 2.295e+05, MSE(e): 6.499e-03, MSE(pi1): 1.574e+00, MSE(pi2): 3.161e-03, MSE(pi3): 1.689e-02\n",
      "Epoch 3100, Train loss: 3.163e+04, Test loss: 4.220e+04, MSE(e): 1.802e-03, MSE(pi1): 1.204e+00, MSE(pi2): 8.659e-04, MSE(pi3): 1.573e-02\n",
      "Epoch 3200, Train loss: 2.828e+04, Test loss: 4.647e+04, MSE(e): 1.153e-03, MSE(pi1): 1.517e+00, MSE(pi2): 6.486e-04, MSE(pi3): 1.582e-02\n",
      "Epoch 3300, Train loss: 3.502e+04, Test loss: 7.182e+04, MSE(e): 1.590e-03, MSE(pi1): 1.709e+00, MSE(pi2): 7.581e-04, MSE(pi3): 2.030e-02\n",
      "Epoch 3400, Train loss: 2.619e+04, Test loss: 4.669e+04, MSE(e): 1.325e-03, MSE(pi1): 1.126e+00, MSE(pi2): 7.438e-04, MSE(pi3): 1.675e-02\n",
      "Epoch 3500, Train loss: 3.294e+04, Test loss: 5.370e+04, MSE(e): 1.546e-03, MSE(pi1): 1.542e+00, MSE(pi2): 7.722e-04, MSE(pi3): 2.052e-02\n",
      "Epoch 3600, Train loss: 4.269e+04, Test loss: 8.847e+04, MSE(e): 2.550e-03, MSE(pi1): 1.510e+00, MSE(pi2): 1.357e-03, MSE(pi3): 2.090e-02\n",
      "Epoch 3700, Train loss: 4.439e+04, Test loss: 5.816e+04, MSE(e): 2.841e-03, MSE(pi1): 1.407e+00, MSE(pi2): 1.490e-03, MSE(pi3): 1.907e-02\n",
      "Epoch 3800, Train loss: 3.274e+04, Test loss: 6.497e+04, MSE(e): 2.418e-03, MSE(pi1): 7.265e-01, MSE(pi2): 1.187e-03, MSE(pi3): 1.287e-02\n",
      "Epoch 3900, Train loss: 2.284e+04, Test loss: 4.506e+04, MSE(e): 7.391e-04, MSE(pi1): 1.368e+00, MSE(pi2): 3.699e-04, MSE(pi3): 1.772e-02\n",
      "Epoch 4000, Train loss: 2.000e+04, Test loss: 4.038e+04, MSE(e): 6.660e-04, MSE(pi1): 1.175e+00, MSE(pi2): 3.340e-04, MSE(pi3): 1.588e-02\n",
      "Epoch 4100, Train loss: 3.622e+04, Test loss: 9.471e+04, MSE(e): 2.417e-03, MSE(pi1): 1.071e+00, MSE(pi2): 1.106e-03, MSE(pi3): 1.345e-02\n",
      "Epoch 4200, Train loss: 3.707e+04, Test loss: 7.380e+04, MSE(e): 1.433e-03, MSE(pi1): 1.984e+00, MSE(pi2): 7.098e-04, MSE(pi3): 2.904e-02\n",
      "Epoch 4300, Train loss: 2.544e+04, Test loss: 4.724e+04, MSE(e): 1.057e-03, MSE(pi1): 1.318e+00, MSE(pi2): 5.858e-04, MSE(pi3): 1.689e-02\n",
      "Epoch 4400, Train loss: 2.340e+04, Test loss: 4.766e+04, MSE(e): 7.733e-04, MSE(pi1): 1.390e+00, MSE(pi2): 3.750e-04, MSE(pi3): 1.763e-02\n",
      "Epoch 4500, Train loss: 2.262e+04, Test loss: 4.350e+04, MSE(e): 8.296e-04, MSE(pi1): 1.263e+00, MSE(pi2): 4.452e-04, MSE(pi3): 1.699e-02\n",
      "Epoch 4600, Train loss: 3.827e+04, Test loss: 5.789e+04, MSE(e): 2.283e-03, MSE(pi1): 1.366e+00, MSE(pi2): 1.051e-03, MSE(pi3): 1.769e-02\n",
      "Epoch 4700, Train loss: 3.709e+04, Test loss: 6.517e+04, MSE(e): 1.867e-03, MSE(pi1): 1.622e+00, MSE(pi2): 1.153e-03, MSE(pi3): 2.194e-02\n",
      "Epoch 4800, Train loss: 4.470e+04, Test loss: 9.972e+04, MSE(e): 2.551e-03, MSE(pi1): 1.680e+00, MSE(pi2): 1.126e-03, MSE(pi3): 2.394e-02\n",
      "Epoch 4900, Train loss: 1.969e+04, Test loss: 3.828e+04, MSE(e): 7.285e-04, MSE(pi1): 1.101e+00, MSE(pi2): 4.056e-04, MSE(pi3): 1.394e-02\n",
      "Epoch 5000, Train loss: 3.954e+04, Test loss: 8.301e+04, MSE(e): 2.158e-03, MSE(pi1): 1.589e+00, MSE(pi2): 1.259e-03, MSE(pi3): 2.060e-02\n",
      "Epoch 5100, Train loss: 1.736e+04, Test loss: 3.245e+04, MSE(e): 7.742e-04, MSE(pi1): 8.409e-01, MSE(pi2): 3.659e-04, MSE(pi3): 1.206e-02\n",
      "Epoch 5200, Train loss: 2.814e+04, Test loss: 5.297e+04, MSE(e): 1.445e-03, MSE(pi1): 1.207e+00, MSE(pi2): 7.083e-04, MSE(pi3): 1.617e-02\n",
      "Epoch 5300, Train loss: 2.056e+04, Test loss: 4.056e+04, MSE(e): 7.306e-04, MSE(pi1): 1.171e+00, MSE(pi2): 3.823e-04, MSE(pi3): 1.544e-02\n",
      "Epoch 5400, Train loss: 5.003e+04, Test loss: 1.206e+05, MSE(e): 4.018e-03, MSE(pi1): 8.509e-01, MSE(pi2): 1.851e-03, MSE(pi3): 1.335e-02\n",
      "Epoch 5500, Train loss: 2.618e+04, Test loss: 3.730e+04, MSE(e): 1.300e-03, MSE(pi1): 1.169e+00, MSE(pi2): 6.412e-04, MSE(pi3): 1.489e-02\n",
      "Epoch 5600, Train loss: 1.577e+04, Test loss: 3.278e+04, MSE(e): 5.056e-04, MSE(pi1): 9.411e-01, MSE(pi2): 2.386e-04, MSE(pi3): 1.305e-02\n",
      "Epoch 5700, Train loss: 3.141e+04, Test loss: 3.481e+04, MSE(e): 1.966e-03, MSE(pi1): 1.033e+00, MSE(pi2): 1.003e-03, MSE(pi3): 1.414e-02\n",
      "Epoch 5800, Train loss: 1.102e+05, Test loss: 1.208e+05, MSE(e): 9.269e-03, MSE(pi1): 1.542e+00, MSE(pi2): 4.472e-03, MSE(pi3): 2.055e-02\n",
      "Epoch 5900, Train loss: 2.036e+04, Test loss: 4.001e+04, MSE(e): 1.022e-03, MSE(pi1): 8.828e-01, MSE(pi2): 5.045e-04, MSE(pi3): 1.312e-02\n",
      "Epoch 6000, Train loss: 2.445e+04, Test loss: 4.109e+04, MSE(e): 1.345e-03, MSE(pi1): 9.619e-01, MSE(pi2): 6.205e-04, MSE(pi3): 1.379e-02\n",
      "Epoch 6100, Train loss: 1.247e+04, Test loss: 2.773e+04, MSE(e): 5.950e-04, MSE(pi1): 5.511e-01, MSE(pi2): 2.995e-04, MSE(pi3): 1.012e-02\n",
      "Epoch 6200, Train loss: 2.404e+04, Test loss: 5.656e+04, MSE(e): 1.219e-03, MSE(pi1): 1.044e+00, MSE(pi2): 5.780e-04, MSE(pi3): 1.413e-02\n",
      "Epoch 6300, Train loss: 3.395e+04, Test loss: 4.079e+04, MSE(e): 2.354e-03, MSE(pi1): 9.079e-01, MSE(pi2): 1.122e-03, MSE(pi3): 1.339e-02\n",
      "Epoch 6400, Train loss: 2.538e+04, Test loss: 4.264e+04, MSE(e): 1.100e-03, MSE(pi1): 1.276e+00, MSE(pi2): 5.311e-04, MSE(pi3): 1.627e-02\n",
      "Epoch 6500, Train loss: 1.339e+04, Test loss: 2.581e+04, MSE(e): 4.537e-04, MSE(pi1): 7.679e-01, MSE(pi2): 2.073e-04, MSE(pi3): 1.177e-02\n",
      "Epoch 6600, Train loss: 2.672e+04, Test loss: 4.662e+04, MSE(e): 1.032e-03, MSE(pi1): 1.440e+00, MSE(pi2): 5.157e-04, MSE(pi3): 2.006e-02\n",
      "Epoch 6700, Train loss: 3.938e+04, Test loss: 6.456e+04, MSE(e): 1.957e-03, MSE(pi1): 1.753e+00, MSE(pi2): 8.443e-04, MSE(pi3): 2.284e-02\n",
      "Epoch 6800, Train loss: 2.662e+04, Test loss: 5.273e+04, MSE(e): 1.826e-03, MSE(pi1): 7.245e-01, MSE(pi2): 8.527e-04, MSE(pi3): 1.118e-02\n",
      "Epoch 6900, Train loss: 2.522e+04, Test loss: 5.740e+04, MSE(e): 1.068e-03, MSE(pi1): 1.286e+00, MSE(pi2): 4.674e-04, MSE(pi3): 1.673e-02\n",
      "Epoch 7000, Train loss: 1.158e+04, Test loss: 2.515e+04, MSE(e): 4.153e-04, MSE(pi1): 6.350e-01, MSE(pi2): 1.855e-04, MSE(pi3): 1.073e-02\n",
      "Epoch 7100, Train loss: 1.530e+04, Test loss: 3.194e+04, MSE(e): 3.940e-04, MSE(pi1): 9.995e-01, MSE(pi2): 1.712e-04, MSE(pi3): 1.365e-02\n",
      "Epoch 7200, Train loss: 4.961e+04, Test loss: 3.989e+04, MSE(e): 4.015e-03, MSE(pi1): 8.239e-01, MSE(pi2): 1.979e-03, MSE(pi3): 1.219e-02\n",
      "Epoch 7300, Train loss: 1.808e+04, Test loss: 4.068e+04, MSE(e): 9.551e-04, MSE(pi1): 7.397e-01, MSE(pi2): 4.367e-04, MSE(pi3): 1.129e-02\n",
      "Epoch 7400, Train loss: 2.478e+04, Test loss: 3.174e+04, MSE(e): 1.781e-03, MSE(pi1): 5.860e-01, MSE(pi2): 9.143e-04, MSE(pi3): 1.109e-02\n",
      "Epoch 7500, Train loss: 1.682e+04, Test loss: 3.936e+04, MSE(e): 9.307e-04, MSE(pi1): 6.411e-01, MSE(pi2): 4.610e-04, MSE(pi3): 1.099e-02\n",
      "Epoch 7600, Train loss: 1.574e+04, Test loss: 3.104e+04, MSE(e): 7.262e-04, MSE(pi1): 7.373e-01, MSE(pi2): 3.357e-04, MSE(pi3): 1.100e-02\n",
      "Epoch 7700, Train loss: 1.295e+04, Test loss: 2.251e+04, MSE(e): 8.290e-04, MSE(pi1): 3.706e-01, MSE(pi2): 4.396e-04, MSE(pi3): 9.518e-03\n",
      "Epoch 7800, Train loss: 1.184e+04, Test loss: 2.951e+04, MSE(e): 6.789e-04, MSE(pi1): 4.095e-01, MSE(pi2): 3.177e-04, MSE(pi3): 9.561e-03\n",
      "Epoch 7900, Train loss: 3.453e+04, Test loss: 4.822e+04, MSE(e): 2.638e-03, MSE(pi1): 6.964e-01, MSE(pi2): 1.281e-03, MSE(pi3): 1.184e-02\n",
      "Epoch 8000, Train loss: 2.030e+04, Test loss: 3.890e+04, MSE(e): 9.996e-04, MSE(pi1): 9.084e-01, MSE(pi2): 5.168e-04, MSE(pi3): 1.219e-02\n",
      "Epoch 8100, Train loss: 1.497e+04, Test loss: 3.102e+04, MSE(e): 5.382e-04, MSE(pi1): 8.347e-01, MSE(pi2): 2.421e-04, MSE(pi3): 1.239e-02\n",
      "Epoch 8200, Train loss: 1.562e+04, Test loss: 2.130e+04, MSE(e): 1.050e-03, MSE(pi1): 4.156e-01, MSE(pi2): 5.293e-04, MSE(pi3): 9.702e-03\n",
      "Epoch 8300, Train loss: 2.617e+04, Test loss: 4.495e+04, MSE(e): 1.822e-03, MSE(pi1): 6.817e-01, MSE(pi2): 8.119e-04, MSE(pi3): 1.125e-02\n",
      "Epoch 8400, Train loss: 1.076e+04, Test loss: 2.179e+04, MSE(e): 3.667e-04, MSE(pi1): 6.058e-01, MSE(pi2): 1.809e-04, MSE(pi3): 1.032e-02\n",
      "Epoch 8500, Train loss: 1.569e+04, Test loss: 3.724e+04, MSE(e): 6.021e-04, MSE(pi1): 8.433e-01, MSE(pi2): 2.621e-04, MSE(pi3): 1.237e-02\n",
      "Epoch 8600, Train loss: 1.408e+04, Test loss: 2.647e+04, MSE(e): 4.238e-04, MSE(pi1): 8.599e-01, MSE(pi2): 1.869e-04, MSE(pi3): 1.242e-02\n",
      "Epoch 8700, Train loss: 1.969e+04, Test loss: 3.741e+04, MSE(e): 1.253e-03, MSE(pi1): 6.087e-01, MSE(pi2): 5.792e-04, MSE(pi3): 1.065e-02\n",
      "Epoch 8800, Train loss: 2.109e+04, Test loss: 4.841e+04, MSE(e): 1.358e-03, MSE(pi1): 6.430e-01, MSE(pi2): 6.297e-04, MSE(pi3): 1.075e-02\n",
      "Epoch 8900, Train loss: 1.248e+04, Test loss: 3.100e+04, MSE(e): 5.698e-04, MSE(pi1): 5.795e-01, MSE(pi2): 2.598e-04, MSE(pi3): 9.824e-03\n",
      "Epoch 9000, Train loss: 1.663e+04, Test loss: 3.351e+04, MSE(e): 5.671e-04, MSE(pi1): 9.623e-01, MSE(pi2): 2.314e-04, MSE(pi3): 1.335e-02\n",
      "Epoch 9100, Train loss: 2.229e+04, Test loss: 4.093e+04, MSE(e): 1.483e-03, MSE(pi1): 6.381e-01, MSE(pi2): 7.982e-04, MSE(pi3): 1.078e-02\n",
      "Epoch 9200, Train loss: 1.329e+04, Test loss: 2.630e+04, MSE(e): 4.308e-04, MSE(pi1): 7.823e-01, MSE(pi2): 1.838e-04, MSE(pi3): 1.163e-02\n",
      "Epoch 9300, Train loss: 1.577e+04, Test loss: 3.788e+04, MSE(e): 6.820e-04, MSE(pi1): 7.722e-01, MSE(pi2): 3.025e-04, MSE(pi3): 1.227e-02\n",
      "Epoch 9400, Train loss: 2.313e+04, Test loss: 5.000e+04, MSE(e): 1.333e-03, MSE(pi1): 8.554e-01, MSE(pi2): 5.903e-04, MSE(pi3): 1.247e-02\n",
      "Epoch 9500, Train loss: 2.051e+04, Test loss: 4.961e+04, MSE(e): 5.478e-04, MSE(pi1): 1.324e+00, MSE(pi2): 2.201e-04, MSE(pi3): 1.792e-02\n",
      "Epoch 9600, Train loss: 2.050e+04, Test loss: 4.119e+04, MSE(e): 1.451e-03, MSE(pi1): 4.993e-01, MSE(pi2): 6.488e-04, MSE(pi3): 9.940e-03\n",
      "Epoch 9700, Train loss: 1.364e+04, Test loss: 2.905e+04, MSE(e): 6.026e-04, MSE(pi1): 6.522e-01, MSE(pi2): 2.879e-04, MSE(pi3): 1.093e-02\n",
      "Epoch 9800, Train loss: 1.976e+04, Test loss: 2.931e+04, MSE(e): 9.617e-04, MSE(pi1): 8.851e-01, MSE(pi2): 4.401e-04, MSE(pi3): 1.286e-02\n",
      "Epoch 9900, Train loss: 1.587e+04, Test loss: 2.644e+04, MSE(e): 5.132e-04, MSE(pi1): 9.451e-01, MSE(pi2): 2.293e-04, MSE(pi3): 1.285e-02\n",
      "\n",
      "Training process finished after 10000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 10000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_epoch = n_epochs-1\n",
    "# n_epochs = 20000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 5\n",
    "\n",
    "# second_lr = 3e-4\n",
    "\n",
    "# train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
