{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import GPUtil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from model.baseline_model import BaselineNonlinearModel\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from vecopsciml.operators.zero_order import Mx, My"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/transfer_learning/results/non_linear\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/transfer_learning/results/non_linear/baseline\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/non_linear_100_0/non_linear_100_0.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/non_linear')\n",
    "MODEL_RESULTS_PATH = os.path.join(ROOT_PATH, r'transfer_learning/results/non_linear/baseline')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear_100_0/non_linear_100_0.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data splitting in train/test\n",
    "X = torch.tensor(dataset['X_train'], dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(dataset['y_train'], dtype=torch.float32).unsqueeze(1)\n",
    "K = torch.tensor(dataset['k_train'], dtype=torch.float32).unsqueeze(1)\n",
    "f = torch.tensor(dataset['f_train'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X, y, K, f, test_size=0.3, random_state=42)\n",
    "\n",
    "# Data processing and adequacy with our TensOps library\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "# Loading and processing validation data\n",
    "X_val = torch.tensor(dataset['X_val'], dtype=torch.float32).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 1.348e+09, Test loss: 1.459e+09, MSE(e): 9.300e+01, MSE(pi1): 4.113e+04, MSE(pi2): 3.929e+01, MSE(pi3): 6.284e+01\n",
      "Epoch 100, Train loss: 2.997e+07, Test loss: 3.594e+07, MSE(e): 2.990e+00, MSE(pi1): 3.821e+00, MSE(pi2): 1.378e+00, MSE(pi3): 2.929e-01\n",
      "Epoch 200, Train loss: 1.994e+07, Test loss: 2.314e+07, MSE(e): 1.982e+00, MSE(pi1): 9.573e+00, MSE(pi2): 9.543e-01, MSE(pi3): 2.768e-01\n",
      "Epoch 300, Train loss: 7.217e+06, Test loss: 8.507e+06, MSE(e): 7.094e-01, MSE(pi1): 9.458e+00, MSE(pi2): 4.449e-01, MSE(pi3): 2.746e-01\n",
      "Epoch 400, Train loss: 5.814e+06, Test loss: 6.681e+06, MSE(e): 5.728e-01, MSE(pi1): 5.957e+00, MSE(pi2): 3.840e-01, MSE(pi3): 2.600e-01\n",
      "Epoch 500, Train loss: 5.294e+06, Test loss: 6.027e+06, MSE(e): 5.224e-01, MSE(pi1): 4.379e+00, MSE(pi2): 3.598e-01, MSE(pi3): 2.501e-01\n",
      "Epoch 600, Train loss: 5.011e+06, Test loss: 5.629e+06, MSE(e): 4.950e-01, MSE(pi1): 3.630e+00, MSE(pi2): 3.461e-01, MSE(pi3): 2.434e-01\n",
      "Epoch 700, Train loss: 4.844e+06, Test loss: 5.385e+06, MSE(e): 4.788e-01, MSE(pi1): 3.229e+00, MSE(pi2): 3.377e-01, MSE(pi3): 2.385e-01\n",
      "Epoch 800, Train loss: 4.740e+06, Test loss: 5.234e+06, MSE(e): 4.686e-01, MSE(pi1): 2.998e+00, MSE(pi2): 3.323e-01, MSE(pi3): 2.345e-01\n",
      "Epoch 900, Train loss: 4.670e+06, Test loss: 5.125e+06, MSE(e): 4.618e-01, MSE(pi1): 2.863e+00, MSE(pi2): 3.286e-01, MSE(pi3): 2.313e-01\n",
      "Epoch 1000, Train loss: 4.641e+06, Test loss: 5.036e+06, MSE(e): 4.590e-01, MSE(pi1): 2.784e+00, MSE(pi2): 3.270e-01, MSE(pi3): 2.287e-01\n",
      "Epoch 1100, Train loss: 4.587e+06, Test loss: 4.991e+06, MSE(e): 4.537e-01, MSE(pi1): 2.722e+00, MSE(pi2): 3.243e-01, MSE(pi3): 2.260e-01\n",
      "Epoch 1200, Train loss: 4.565e+06, Test loss: 4.949e+06, MSE(e): 4.516e-01, MSE(pi1): 2.681e+00, MSE(pi2): 3.233e-01, MSE(pi3): 2.238e-01\n",
      "Epoch 1300, Train loss: 4.540e+06, Test loss: 4.932e+06, MSE(e): 4.491e-01, MSE(pi1): 2.645e+00, MSE(pi2): 3.220e-01, MSE(pi3): 2.215e-01\n",
      "Epoch 1400, Train loss: 4.529e+06, Test loss: 4.921e+06, MSE(e): 4.480e-01, MSE(pi1): 2.614e+00, MSE(pi2): 3.212e-01, MSE(pi3): 2.194e-01\n",
      "Epoch 1500, Train loss: 4.507e+06, Test loss: 4.915e+06, MSE(e): 4.459e-01, MSE(pi1): 2.587e+00, MSE(pi2): 3.200e-01, MSE(pi3): 2.175e-01\n",
      "Epoch 1600, Train loss: 4.491e+06, Test loss: 4.919e+06, MSE(e): 4.444e-01, MSE(pi1): 2.562e+00, MSE(pi2): 3.189e-01, MSE(pi3): 2.157e-01\n",
      "Epoch 1700, Train loss: 4.475e+06, Test loss: 4.933e+06, MSE(e): 4.428e-01, MSE(pi1): 2.542e+00, MSE(pi2): 3.177e-01, MSE(pi3): 2.141e-01\n",
      "Epoch 1800, Train loss: 4.458e+06, Test loss: 4.951e+06, MSE(e): 4.411e-01, MSE(pi1): 2.527e+00, MSE(pi2): 3.163e-01, MSE(pi3): 2.127e-01\n",
      "Epoch 1900, Train loss: 4.440e+06, Test loss: 4.978e+06, MSE(e): 4.393e-01, MSE(pi1): 2.517e+00, MSE(pi2): 3.148e-01, MSE(pi3): 2.114e-01\n",
      "Epoch 2000, Train loss: 4.420e+06, Test loss: 5.013e+06, MSE(e): 4.374e-01, MSE(pi1): 2.512e+00, MSE(pi2): 3.132e-01, MSE(pi3): 2.103e-01\n",
      "Epoch 2100, Train loss: 4.400e+06, Test loss: 5.051e+06, MSE(e): 4.354e-01, MSE(pi1): 2.509e+00, MSE(pi2): 3.115e-01, MSE(pi3): 2.095e-01\n",
      "Epoch 2200, Train loss: 4.379e+06, Test loss: 5.096e+06, MSE(e): 4.333e-01, MSE(pi1): 2.507e+00, MSE(pi2): 3.098e-01, MSE(pi3): 2.087e-01\n",
      "Epoch 2300, Train loss: 4.358e+06, Test loss: 5.146e+06, MSE(e): 4.312e-01, MSE(pi1): 2.502e+00, MSE(pi2): 3.080e-01, MSE(pi3): 2.080e-01\n",
      "Epoch 2400, Train loss: 4.337e+06, Test loss: 5.198e+06, MSE(e): 4.291e-01, MSE(pi1): 2.495e+00, MSE(pi2): 3.064e-01, MSE(pi3): 2.073e-01\n",
      "Epoch 2500, Train loss: 4.316e+06, Test loss: 5.251e+06, MSE(e): 4.270e-01, MSE(pi1): 2.485e+00, MSE(pi2): 3.047e-01, MSE(pi3): 2.067e-01\n",
      "Epoch 2600, Train loss: 4.296e+06, Test loss: 5.304e+06, MSE(e): 4.251e-01, MSE(pi1): 2.472e+00, MSE(pi2): 3.032e-01, MSE(pi3): 2.059e-01\n",
      "Epoch 2700, Train loss: 4.278e+06, Test loss: 5.355e+06, MSE(e): 4.232e-01, MSE(pi1): 2.456e+00, MSE(pi2): 3.016e-01, MSE(pi3): 2.051e-01\n",
      "Epoch 2800, Train loss: 4.258e+06, Test loss: 5.403e+06, MSE(e): 4.213e-01, MSE(pi1): 2.437e+00, MSE(pi2): 3.002e-01, MSE(pi3): 2.043e-01\n",
      "Epoch 2900, Train loss: 4.233e+06, Test loss: 5.448e+06, MSE(e): 4.188e-01, MSE(pi1): 2.415e+00, MSE(pi2): 2.982e-01, MSE(pi3): 2.034e-01\n",
      "Epoch 3000, Train loss: 4.142e+06, Test loss: 5.418e+06, MSE(e): 4.098e-01, MSE(pi1): 2.391e+00, MSE(pi2): 2.918e-01, MSE(pi3): 2.024e-01\n",
      "Epoch 3100, Train loss: 2.926e+06, Test loss: 4.000e+06, MSE(e): 2.880e-01, MSE(pi1): 2.571e+00, MSE(pi2): 2.024e-01, MSE(pi3): 1.999e-01\n",
      "Epoch 3200, Train loss: 1.954e+06, Test loss: 2.725e+06, MSE(e): 1.909e-01, MSE(pi1): 2.542e+00, MSE(pi2): 1.378e-01, MSE(pi3): 1.997e-01\n",
      "Epoch 3300, Train loss: 1.758e+06, Test loss: 2.436e+06, MSE(e): 1.713e-01, MSE(pi1): 2.431e+00, MSE(pi2): 1.264e-01, MSE(pi3): 1.981e-01\n",
      "Epoch 3400, Train loss: 1.668e+06, Test loss: 2.278e+06, MSE(e): 1.625e-01, MSE(pi1): 2.357e+00, MSE(pi2): 1.210e-01, MSE(pi3): 1.954e-01\n",
      "Epoch 3500, Train loss: 1.642e+06, Test loss: 2.242e+06, MSE(e): 1.600e-01, MSE(pi1): 2.295e+00, MSE(pi2): 1.195e-01, MSE(pi3): 1.926e-01\n",
      "Epoch 3600, Train loss: 1.626e+06, Test loss: 2.217e+06, MSE(e): 1.584e-01, MSE(pi1): 2.243e+00, MSE(pi2): 1.185e-01, MSE(pi3): 1.902e-01\n",
      "Epoch 3700, Train loss: 1.610e+06, Test loss: 2.195e+06, MSE(e): 1.569e-01, MSE(pi1): 2.203e+00, MSE(pi2): 1.173e-01, MSE(pi3): 1.883e-01\n",
      "Epoch 3800, Train loss: 1.577e+06, Test loss: 2.168e+06, MSE(e): 1.537e-01, MSE(pi1): 2.172e+00, MSE(pi2): 1.148e-01, MSE(pi3): 1.867e-01\n",
      "Epoch 3900, Train loss: 1.249e+06, Test loss: 1.853e+06, MSE(e): 1.207e-01, MSE(pi1): 2.331e+00, MSE(pi2): 8.784e-02, MSE(pi3): 1.834e-01\n",
      "Epoch 4000, Train loss: 3.715e+05, Test loss: 8.735e+05, MSE(e): 3.249e-02, MSE(pi1): 2.764e+00, MSE(pi2): 1.889e-02, MSE(pi3): 1.891e-01\n",
      "Epoch 4100, Train loss: 1.942e+05, Test loss: 4.531e+05, MSE(e): 1.508e-02, MSE(pi1): 2.410e+00, MSE(pi2): 9.706e-03, MSE(pi3): 1.921e-01\n",
      "Epoch 4200, Train loss: 1.401e+05, Test loss: 3.356e+05, MSE(e): 9.846e-03, MSE(pi1): 2.278e+00, MSE(pi2): 6.658e-03, MSE(pi3): 1.885e-01\n",
      "Epoch 4300, Train loss: 1.100e+05, Test loss: 2.750e+05, MSE(e): 7.009e-03, MSE(pi1): 2.147e+00, MSE(pi2): 5.109e-03, MSE(pi3): 1.839e-01\n",
      "Epoch 4400, Train loss: 9.354e+04, Test loss: 2.404e+05, MSE(e): 5.530e-03, MSE(pi1): 2.023e+00, MSE(pi2): 4.197e-03, MSE(pi3): 1.801e-01\n",
      "Epoch 4500, Train loss: 8.289e+04, Test loss: 2.190e+05, MSE(e): 4.604e-03, MSE(pi1): 1.910e+00, MSE(pi2): 3.695e-03, MSE(pi3): 1.775e-01\n",
      "Epoch 4600, Train loss: 7.923e+04, Test loss: 2.056e+05, MSE(e): 4.347e-03, MSE(pi1): 1.816e+00, MSE(pi2): 3.645e-03, MSE(pi3): 1.761e-01\n",
      "Epoch 4700, Train loss: 7.167e+04, Test loss: 1.947e+05, MSE(e): 3.671e-03, MSE(pi1): 1.743e+00, MSE(pi2): 3.121e-03, MSE(pi3): 1.752e-01\n",
      "Epoch 4800, Train loss: 6.832e+04, Test loss: 1.869e+05, MSE(e): 3.400e-03, MSE(pi1): 1.683e+00, MSE(pi2): 2.945e-03, MSE(pi3): 1.749e-01\n",
      "Epoch 4900, Train loss: 6.664e+04, Test loss: 1.848e+05, MSE(e): 3.285e-03, MSE(pi1): 1.631e+00, MSE(pi2): 2.943e-03, MSE(pi3): 1.748e-01\n",
      "Epoch 5000, Train loss: 6.401e+04, Test loss: 1.772e+05, MSE(e): 3.056e-03, MSE(pi1): 1.595e+00, MSE(pi2): 2.712e-03, MSE(pi3): 1.749e-01\n",
      "Epoch 5100, Train loss: 6.249e+04, Test loss: 1.734e+05, MSE(e): 2.936e-03, MSE(pi1): 1.560e+00, MSE(pi2): 2.636e-03, MSE(pi3): 1.753e-01\n",
      "Epoch 5200, Train loss: 6.124e+04, Test loss: 1.702e+05, MSE(e): 2.838e-03, MSE(pi1): 1.530e+00, MSE(pi2): 2.569e-03, MSE(pi3): 1.757e-01\n",
      "Epoch 5300, Train loss: 6.103e+04, Test loss: 1.684e+05, MSE(e): 2.834e-03, MSE(pi1): 1.509e+00, MSE(pi2): 2.461e-03, MSE(pi3): 1.760e-01\n",
      "Epoch 5400, Train loss: 5.940e+04, Test loss: 1.662e+05, MSE(e): 2.696e-03, MSE(pi1): 1.482e+00, MSE(pi2): 2.472e-03, MSE(pi3): 1.763e-01\n",
      "Epoch 5500, Train loss: 5.863e+04, Test loss: 1.641e+05, MSE(e): 2.637e-03, MSE(pi1): 1.461e+00, MSE(pi2): 2.427e-03, MSE(pi3): 1.765e-01\n",
      "Epoch 5600, Train loss: 5.803e+04, Test loss: 1.634e+05, MSE(e): 2.594e-03, MSE(pi1): 1.444e+00, MSE(pi2): 2.412e-03, MSE(pi3): 1.764e-01\n",
      "Epoch 5700, Train loss: 5.739e+04, Test loss: 1.614e+05, MSE(e): 2.547e-03, MSE(pi1): 1.427e+00, MSE(pi2): 2.367e-03, MSE(pi3): 1.765e-01\n",
      "Epoch 5800, Train loss: 9.237e+04, Test loss: 2.212e+05, MSE(e): 6.012e-03, MSE(pi1): 1.458e+00, MSE(pi2): 3.243e-03, MSE(pi3): 1.766e-01\n",
      "Epoch 5900, Train loss: 5.635e+04, Test loss: 1.589e+05, MSE(e): 2.475e-03, MSE(pi1): 1.399e+00, MSE(pi2): 2.311e-03, MSE(pi3): 1.760e-01\n",
      "Epoch 6000, Train loss: 5.583e+04, Test loss: 1.572e+05, MSE(e): 2.440e-03, MSE(pi1): 1.384e+00, MSE(pi2): 2.291e-03, MSE(pi3): 1.758e-01\n",
      "Epoch 6100, Train loss: 7.515e+04, Test loss: 1.598e+05, MSE(e): 4.344e-03, MSE(pi1): 1.415e+00, MSE(pi2): 2.709e-03, MSE(pi3): 1.755e-01\n",
      "Epoch 6200, Train loss: 5.491e+04, Test loss: 1.552e+05, MSE(e): 2.384e-03, MSE(pi1): 1.360e+00, MSE(pi2): 2.250e-03, MSE(pi3): 1.747e-01\n",
      "Epoch 6300, Train loss: 5.441e+04, Test loss: 1.534e+05, MSE(e): 2.355e-03, MSE(pi1): 1.346e+00, MSE(pi2): 2.229e-03, MSE(pi3): 1.740e-01\n",
      "Epoch 6400, Train loss: 1.405e+05, Test loss: 1.681e+05, MSE(e): 1.087e-02, MSE(pi1): 1.443e+00, MSE(pi2): 5.021e-03, MSE(pi3): 1.739e-01\n",
      "Epoch 6500, Train loss: 5.346e+04, Test loss: 1.516e+05, MSE(e): 2.307e-03, MSE(pi1): 1.321e+00, MSE(pi2): 2.197e-03, MSE(pi3): 1.718e-01\n",
      "Epoch 6600, Train loss: 5.290e+04, Test loss: 1.498e+05, MSE(e): 2.280e-03, MSE(pi1): 1.306e+00, MSE(pi2): 2.173e-03, MSE(pi3): 1.705e-01\n",
      "Epoch 6700, Train loss: 5.265e+04, Test loss: 1.491e+05, MSE(e): 2.291e-03, MSE(pi1): 1.287e+00, MSE(pi2): 2.228e-03, MSE(pi3): 1.687e-01\n",
      "Epoch 6800, Train loss: 5.169e+04, Test loss: 1.475e+05, MSE(e): 2.233e-03, MSE(pi1): 1.273e+00, MSE(pi2): 2.130e-03, MSE(pi3): 1.663e-01\n",
      "Epoch 6900, Train loss: 5.091e+04, Test loss: 1.458e+05, MSE(e): 2.205e-03, MSE(pi1): 1.251e+00, MSE(pi2): 2.116e-03, MSE(pi3): 1.635e-01\n",
      "Epoch 7000, Train loss: 8.139e+04, Test loss: 2.063e+05, MSE(e): 5.322e-03, MSE(pi1): 1.223e+00, MSE(pi2): 3.987e-03, MSE(pi3): 1.593e-01\n",
      "Epoch 7100, Train loss: 4.901e+04, Test loss: 1.435e+05, MSE(e): 2.154e-03, MSE(pi1): 1.195e+00, MSE(pi2): 2.073e-03, MSE(pi3): 1.552e-01\n",
      "Epoch 7200, Train loss: 4.772e+04, Test loss: 1.414e+05, MSE(e): 2.123e-03, MSE(pi1): 1.153e+00, MSE(pi2): 2.053e-03, MSE(pi3): 1.497e-01\n",
      "Epoch 7300, Train loss: 4.629e+04, Test loss: 1.395e+05, MSE(e): 2.098e-03, MSE(pi1): 1.101e+00, MSE(pi2): 2.053e-03, MSE(pi3): 1.430e-01\n",
      "Epoch 7400, Train loss: 4.459e+04, Test loss: 1.380e+05, MSE(e): 2.062e-03, MSE(pi1): 1.043e+00, MSE(pi2): 1.998e-03, MSE(pi3): 1.354e-01\n",
      "Epoch 7500, Train loss: 4.268e+04, Test loss: 1.351e+05, MSE(e): 2.026e-03, MSE(pi1): 9.713e-01, MSE(pi2): 1.981e-03, MSE(pi3): 1.271e-01\n",
      "Epoch 7600, Train loss: 4.067e+04, Test loss: 1.323e+05, MSE(e): 1.991e-03, MSE(pi1): 8.957e-01, MSE(pi2): 1.957e-03, MSE(pi3): 1.180e-01\n",
      "Epoch 7700, Train loss: 3.864e+04, Test loss: 1.313e+05, MSE(e): 1.963e-03, MSE(pi1): 8.203e-01, MSE(pi2): 1.927e-03, MSE(pi3): 1.081e-01\n",
      "Epoch 7800, Train loss: 3.646e+04, Test loss: 1.282e+05, MSE(e): 1.929e-03, MSE(pi1): 7.433e-01, MSE(pi2): 1.908e-03, MSE(pi3): 9.738e-02\n",
      "Epoch 7900, Train loss: 1.006e+05, Test loss: 2.108e+05, MSE(e): 8.509e-03, MSE(pi1): 7.054e-01, MSE(pi2): 4.592e-03, MSE(pi3): 8.492e-02\n",
      "Epoch 8000, Train loss: 3.222e+04, Test loss: 1.233e+05, MSE(e): 1.885e-03, MSE(pi1): 5.941e-01, MSE(pi2): 1.870e-03, MSE(pi3): 7.425e-02\n",
      "Epoch 8100, Train loss: 1.099e+05, Test loss: 1.830e+05, MSE(e): 9.804e-03, MSE(pi1): 5.364e-01, MSE(pi2): 5.283e-03, MSE(pi3): 6.440e-02\n",
      "Epoch 8200, Train loss: 2.869e+04, Test loss: 1.203e+05, MSE(e): 1.863e-03, MSE(pi1): 4.638e-01, MSE(pi2): 1.842e-03, MSE(pi3): 5.422e-02\n",
      "Epoch 8300, Train loss: 2.724e+04, Test loss: 1.182e+05, MSE(e): 1.847e-03, MSE(pi1): 4.101e-01, MSE(pi2): 1.827e-03, MSE(pi3): 4.667e-02\n",
      "Epoch 8400, Train loss: 2.608e+04, Test loss: 1.172e+05, MSE(e): 1.840e-03, MSE(pi1): 3.626e-01, MSE(pi2): 1.810e-03, MSE(pi3): 4.057e-02\n",
      "Epoch 8500, Train loss: 2.495e+04, Test loss: 1.181e+05, MSE(e): 1.818e-03, MSE(pi1): 3.227e-01, MSE(pi2): 1.794e-03, MSE(pi3): 3.538e-02\n",
      "Epoch 8600, Train loss: 2.395e+04, Test loss: 1.168e+05, MSE(e): 1.796e-03, MSE(pi1): 2.883e-01, MSE(pi2): 1.775e-03, MSE(pi3): 3.102e-02\n",
      "Epoch 8700, Train loss: 2.308e+04, Test loss: 1.157e+05, MSE(e): 1.774e-03, MSE(pi1): 2.602e-01, MSE(pi2): 1.753e-03, MSE(pi3): 2.731e-02\n",
      "Epoch 8800, Train loss: 6.760e+04, Test loss: 1.426e+05, MSE(e): 6.257e-03, MSE(pi1): 2.582e-01, MSE(pi2): 3.748e-03, MSE(pi3): 2.448e-02\n",
      "Epoch 8900, Train loss: 2.165e+04, Test loss: 1.158e+05, MSE(e): 1.730e-03, MSE(pi1): 2.191e-01, MSE(pi2): 1.708e-03, MSE(pi3): 2.149e-02\n",
      "Epoch 9000, Train loss: 2.100e+04, Test loss: 1.149e+05, MSE(e): 1.705e-03, MSE(pi1): 2.027e-01, MSE(pi2): 1.683e-03, MSE(pi3): 1.921e-02\n",
      "Epoch 9100, Train loss: 3.596e+04, Test loss: 1.269e+05, MSE(e): 3.230e-03, MSE(pi1): 1.974e-01, MSE(pi2): 2.392e-03, MSE(pi3): 1.676e-02\n",
      "Epoch 9200, Train loss: 2.018e+04, Test loss: 1.160e+05, MSE(e): 1.666e-03, MSE(pi1): 1.903e-01, MSE(pi2): 1.625e-03, MSE(pi3): 1.615e-02\n",
      "Epoch 9300, Train loss: 1.965e+04, Test loss: 1.160e+05, MSE(e): 1.629e-03, MSE(pi1): 1.706e-01, MSE(pi2): 1.600e-03, MSE(pi3): 1.645e-02\n",
      "Epoch 9400, Train loss: 2.412e+04, Test loss: 1.227e+05, MSE(e): 1.929e-03, MSE(pi1): 3.523e-01, MSE(pi2): 1.706e-03, MSE(pi3): 1.306e-02\n",
      "Epoch 9500, Train loss: 1.888e+04, Test loss: 1.173e+05, MSE(e): 1.580e-03, MSE(pi1): 1.829e-01, MSE(pi2): 1.536e-03, MSE(pi3): 1.241e-02\n",
      "Epoch 9600, Train loss: 1.895e+04, Test loss: 1.197e+05, MSE(e): 1.624e-03, MSE(pi1): 1.505e-01, MSE(pi2): 1.525e-03, MSE(pi3): 1.200e-02\n",
      "Epoch 9700, Train loss: 2.001e+04, Test loss: 1.200e+05, MSE(e): 1.725e-03, MSE(pi1): 1.651e-01, MSE(pi2): 1.567e-03, MSE(pi3): 1.110e-02\n",
      "Epoch 9800, Train loss: 1.757e+04, Test loss: 1.203e+05, MSE(e): 1.493e-03, MSE(pi1): 1.573e-01, MSE(pi2): 1.429e-03, MSE(pi3): 1.068e-02\n",
      "Epoch 9900, Train loss: 3.063e+04, Test loss: 1.407e+05, MSE(e): 2.777e-03, MSE(pi1): 1.833e-01, MSE(pi2): 1.967e-03, MSE(pi3): 1.023e-02\n",
      "Epoch 10000, Train loss: 1.697e+04, Test loss: 1.194e+05, MSE(e): 1.472e-03, MSE(pi1): 1.376e-01, MSE(pi2): 1.382e-03, MSE(pi3): 8.742e-03\n",
      "Epoch 10100, Train loss: 3.872e+04, Test loss: 1.541e+05, MSE(e): 3.535e-03, MSE(pi1): 2.638e-01, MSE(pi2): 2.519e-03, MSE(pi3): 7.284e-03\n",
      "Epoch 10200, Train loss: 1.943e+04, Test loss: 1.316e+05, MSE(e): 1.596e-03, MSE(pi1): 2.502e-01, MSE(pi2): 1.375e-03, MSE(pi3): 9.645e-03\n",
      "Epoch 10300, Train loss: 2.226e+04, Test loss: 1.369e+05, MSE(e): 1.510e-03, MSE(pi1): 6.572e-01, MSE(pi2): 1.276e-03, MSE(pi3): 5.875e-03\n",
      "Epoch 10400, Train loss: 1.601e+04, Test loss: 1.265e+05, MSE(e): 1.327e-03, MSE(pi1): 1.707e-01, MSE(pi2): 1.211e-03, MSE(pi3): 1.025e-02\n",
      "Epoch 10500, Train loss: 1.696e+04, Test loss: 1.333e+05, MSE(e): 1.454e-03, MSE(pi1): 1.753e-01, MSE(pi2): 1.255e-03, MSE(pi3): 6.676e-03\n",
      "Epoch 10600, Train loss: 1.660e+04, Test loss: 1.263e+05, MSE(e): 1.465e-03, MSE(pi1): 1.375e-01, MSE(pi2): 1.264e-03, MSE(pi3): 5.787e-03\n",
      "Epoch 10700, Train loss: 1.394e+04, Test loss: 1.265e+05, MSE(e): 1.203e-03, MSE(pi1): 1.210e-01, MSE(pi2): 1.107e-03, MSE(pi3): 6.937e-03\n",
      "Epoch 10800, Train loss: 1.561e+04, Test loss: 1.285e+05, MSE(e): 1.302e-03, MSE(pi1): 2.129e-01, MSE(pi2): 1.165e-03, MSE(pi3): 4.627e-03\n",
      "Epoch 10900, Train loss: 2.109e+04, Test loss: 1.458e+05, MSE(e): 1.896e-03, MSE(pi1): 1.500e-01, MSE(pi2): 1.405e-03, MSE(pi3): 6.208e-03\n",
      "Epoch 11000, Train loss: 1.239e+04, Test loss: 1.317e+05, MSE(e): 1.089e-03, MSE(pi1): 1.050e-01, MSE(pi2): 9.975e-04, MSE(pi3): 4.511e-03\n",
      "Epoch 11100, Train loss: 1.293e+04, Test loss: 1.350e+05, MSE(e): 1.093e-03, MSE(pi1): 1.303e-01, MSE(pi2): 9.794e-04, MSE(pi3): 6.997e-03\n",
      "Epoch 11200, Train loss: 1.231e+04, Test loss: 1.417e+05, MSE(e): 1.077e-03, MSE(pi1): 1.041e-01, MSE(pi2): 9.631e-04, MSE(pi3): 4.985e-03\n",
      "Epoch 11300, Train loss: 1.463e+04, Test loss: 1.371e+05, MSE(e): 1.107e-03, MSE(pi1): 3.083e-01, MSE(pi2): 9.459e-04, MSE(pi3): 4.737e-03\n",
      "Epoch 11400, Train loss: 1.696e+04, Test loss: 1.470e+05, MSE(e): 1.225e-03, MSE(pi1): 2.872e-01, MSE(pi2): 1.017e-03, MSE(pi3): 1.842e-02\n",
      "Epoch 11500, Train loss: 1.075e+04, Test loss: 1.405e+05, MSE(e): 9.600e-04, MSE(pi1): 7.780e-02, MSE(pi2): 8.616e-04, MSE(pi3): 3.710e-03\n",
      "Epoch 11600, Train loss: 1.200e+04, Test loss: 1.407e+05, MSE(e): 1.037e-03, MSE(pi1): 1.141e-01, MSE(pi2): 8.881e-04, MSE(pi3): 4.926e-03\n",
      "Epoch 11700, Train loss: 2.682e+04, Test loss: 1.497e+05, MSE(e): 2.489e-03, MSE(pi1): 1.547e-01, MSE(pi2): 1.627e-03, MSE(pi3): 3.803e-03\n",
      "Epoch 11800, Train loss: 2.115e+04, Test loss: 1.634e+05, MSE(e): 1.300e-03, MSE(pi1): 7.867e-01, MSE(pi2): 8.795e-04, MSE(pi3): 2.774e-03\n",
      "Epoch 11900, Train loss: 1.187e+04, Test loss: 1.517e+05, MSE(e): 1.058e-03, MSE(pi1): 8.471e-02, MSE(pi2): 8.542e-04, MSE(pi3): 4.406e-03\n",
      "Epoch 12000, Train loss: 1.309e+04, Test loss: 1.501e+05, MSE(e): 1.147e-03, MSE(pi1): 1.158e-01, MSE(pi2): 9.337e-04, MSE(pi3): 4.581e-03\n",
      "Epoch 12100, Train loss: 1.320e+04, Test loss: 1.527e+05, MSE(e): 1.170e-03, MSE(pi1): 1.014e-01, MSE(pi2): 8.685e-04, MSE(pi3): 4.907e-03\n",
      "Epoch 12200, Train loss: 9.854e+03, Test loss: 1.536e+05, MSE(e): 8.548e-04, MSE(pi1): 8.855e-02, MSE(pi2): 7.330e-04, MSE(pi3): 4.200e-03\n",
      "Epoch 12300, Train loss: 1.290e+04, Test loss: 1.662e+05, MSE(e): 8.793e-04, MSE(pi1): 3.687e-01, MSE(pi2): 6.992e-04, MSE(pi3): 4.177e-03\n",
      "Epoch 12400, Train loss: 1.588e+04, Test loss: 1.628e+05, MSE(e): 1.460e-03, MSE(pi1): 9.227e-02, MSE(pi2): 1.032e-03, MSE(pi3): 3.508e-03\n",
      "Epoch 12500, Train loss: 8.913e+03, Test loss: 1.607e+05, MSE(e): 7.590e-04, MSE(pi1): 9.931e-02, MSE(pi2): 6.554e-04, MSE(pi3): 3.289e-03\n",
      "Epoch 12600, Train loss: 9.564e+03, Test loss: 1.616e+05, MSE(e): 7.852e-04, MSE(pi1): 1.377e-01, MSE(pi2): 6.513e-04, MSE(pi3): 3.342e-03\n",
      "Epoch 12700, Train loss: 9.180e+03, Test loss: 1.652e+05, MSE(e): 7.555e-04, MSE(pi1): 1.142e-01, MSE(pi2): 6.311e-04, MSE(pi3): 4.824e-03\n",
      "Epoch 12800, Train loss: 1.375e+04, Test loss: 1.723e+05, MSE(e): 9.588e-04, MSE(pi1): 3.375e-01, MSE(pi2): 7.186e-04, MSE(pi3): 7.858e-03\n",
      "Epoch 12900, Train loss: 1.162e+04, Test loss: 1.751e+05, MSE(e): 7.830e-04, MSE(pi1): 3.562e-01, MSE(pi2): 6.143e-04, MSE(pi3): 2.317e-03\n",
      "Epoch 13000, Train loss: 1.053e+04, Test loss: 1.700e+05, MSE(e): 9.334e-04, MSE(pi1): 8.681e-02, MSE(pi2): 7.006e-04, MSE(pi3): 3.290e-03\n",
      "Epoch 13100, Train loss: 9.702e+03, Test loss: 1.758e+05, MSE(e): 8.290e-04, MSE(pi1): 9.518e-02, MSE(pi2): 6.914e-04, MSE(pi3): 4.596e-03\n",
      "Epoch 13200, Train loss: 9.578e+03, Test loss: 1.723e+05, MSE(e): 8.608e-04, MSE(pi1): 6.435e-02, MSE(pi2): 6.489e-04, MSE(pi3): 3.260e-03\n",
      "Epoch 13300, Train loss: 6.618e+04, Test loss: 2.257e+05, MSE(e): 5.820e-03, MSE(pi1): 6.669e-01, MSE(pi2): 2.514e-03, MSE(pi3): 1.307e-02\n",
      "Epoch 13400, Train loss: 7.873e+03, Test loss: 1.780e+05, MSE(e): 6.262e-04, MSE(pi1): 1.286e-01, MSE(pi2): 5.211e-04, MSE(pi3): 3.247e-03\n",
      "Epoch 13500, Train loss: 8.468e+03, Test loss: 1.818e+05, MSE(e): 6.592e-04, MSE(pi1): 1.184e-01, MSE(pi2): 5.280e-04, MSE(pi3): 6.910e-03\n",
      "Epoch 13600, Train loss: 2.157e+04, Test loss: 2.015e+05, MSE(e): 9.570e-04, MSE(pi1): 1.152e+00, MSE(pi2): 5.870e-04, MSE(pi3): 4.771e-03\n",
      "Epoch 13700, Train loss: 6.886e+03, Test loss: 1.874e+05, MSE(e): 5.872e-04, MSE(pi1): 7.981e-02, MSE(pi2): 4.883e-04, MSE(pi3): 2.150e-03\n",
      "Epoch 13800, Train loss: 7.786e+03, Test loss: 1.899e+05, MSE(e): 5.804e-04, MSE(pi1): 1.056e-01, MSE(pi2): 4.905e-04, MSE(pi3): 9.249e-03\n",
      "Epoch 13900, Train loss: 8.994e+03, Test loss: 1.863e+05, MSE(e): 8.123e-04, MSE(pi1): 5.915e-02, MSE(pi2): 5.815e-04, MSE(pi3): 2.784e-03\n",
      "Epoch 14000, Train loss: 1.079e+04, Test loss: 1.855e+05, MSE(e): 8.728e-04, MSE(pi1): 1.304e-01, MSE(pi2): 6.929e-04, MSE(pi3): 7.572e-03\n",
      "Epoch 14100, Train loss: 8.112e+03, Test loss: 1.929e+05, MSE(e): 6.160e-04, MSE(pi1): 1.626e-01, MSE(pi2): 4.754e-04, MSE(pi3): 3.248e-03\n",
      "Epoch 14200, Train loss: 1.246e+04, Test loss: 2.100e+05, MSE(e): 1.078e-03, MSE(pi1): 1.179e-01, MSE(pi2): 6.925e-04, MSE(pi3): 4.967e-03\n",
      "Epoch 14300, Train loss: 7.883e+03, Test loss: 1.981e+05, MSE(e): 6.744e-04, MSE(pi1): 8.408e-02, MSE(pi2): 4.930e-04, MSE(pi3): 2.977e-03\n",
      "Epoch 14400, Train loss: 6.819e+03, Test loss: 1.965e+05, MSE(e): 5.906e-04, MSE(pi1): 6.548e-02, MSE(pi2): 4.618e-04, MSE(pi3): 2.577e-03\n",
      "Epoch 14500, Train loss: 1.397e+04, Test loss: 2.159e+05, MSE(e): 1.190e-03, MSE(pi1): 1.623e-01, MSE(pi2): 7.290e-04, MSE(pi3): 4.441e-03\n",
      "Epoch 14600, Train loss: 2.655e+04, Test loss: 2.282e+05, MSE(e): 1.080e-03, MSE(pi1): 1.533e+00, MSE(pi2): 5.429e-04, MSE(pi3): 4.228e-03\n",
      "Epoch 14700, Train loss: 1.353e+04, Test loss: 1.935e+05, MSE(e): 1.177e-03, MSE(pi1): 1.570e-01, MSE(pi2): 8.405e-04, MSE(pi3): 1.946e-03\n",
      "Epoch 14800, Train loss: 1.020e+04, Test loss: 2.018e+05, MSE(e): 8.863e-04, MSE(pi1): 9.432e-02, MSE(pi2): 5.581e-04, MSE(pi3): 3.935e-03\n",
      "Epoch 14900, Train loss: 6.574e+03, Test loss: 2.037e+05, MSE(e): 5.392e-04, MSE(pi1): 9.336e-02, MSE(pi2): 4.205e-04, MSE(pi3): 2.481e-03\n",
      "Epoch 15000, Train loss: 6.820e+03, Test loss: 2.032e+05, MSE(e): 5.054e-04, MSE(pi1): 1.574e-01, MSE(pi2): 4.024e-04, MSE(pi3): 1.917e-03\n",
      "Epoch 15100, Train loss: 5.911e+03, Test loss: 2.072e+05, MSE(e): 4.608e-04, MSE(pi1): 7.597e-02, MSE(pi2): 3.739e-04, MSE(pi3): 5.426e-03\n",
      "Epoch 15200, Train loss: 2.585e+04, Test loss: 2.221e+05, MSE(e): 2.498e-03, MSE(pi1): 5.401e-02, MSE(pi2): 1.350e-03, MSE(pi3): 3.308e-03\n",
      "Epoch 15300, Train loss: 8.535e+03, Test loss: 2.178e+05, MSE(e): 7.234e-04, MSE(pi1): 1.004e-01, MSE(pi2): 4.818e-04, MSE(pi3): 2.974e-03\n",
      "Epoch 15400, Train loss: 4.383e+04, Test loss: 2.647e+05, MSE(e): 4.098e-03, MSE(pi1): 2.416e-01, MSE(pi2): 2.167e-03, MSE(pi3): 4.335e-03\n",
      "Epoch 15500, Train loss: 6.531e+03, Test loss: 2.182e+05, MSE(e): 5.841e-04, MSE(pi1): 4.439e-02, MSE(pi2): 4.430e-04, MSE(pi3): 2.458e-03\n",
      "Epoch 15600, Train loss: 3.438e+04, Test loss: 2.637e+05, MSE(e): 3.250e-03, MSE(pi1): 1.379e-01, MSE(pi2): 1.658e-03, MSE(pi3): 4.942e-03\n",
      "Epoch 15700, Train loss: 1.130e+04, Test loss: 2.217e+05, MSE(e): 9.972e-04, MSE(pi1): 7.820e-02, MSE(pi2): 6.517e-04, MSE(pi3): 5.460e-03\n",
      "Epoch 15800, Train loss: 4.692e+03, Test loss: 2.117e+05, MSE(e): 3.915e-04, MSE(pi1): 5.407e-02, MSE(pi2): 3.288e-04, MSE(pi3): 2.355e-03\n",
      "Epoch 15900, Train loss: 7.529e+03, Test loss: 2.213e+05, MSE(e): 6.434e-04, MSE(pi1): 8.767e-02, MSE(pi2): 4.371e-04, MSE(pi3): 2.184e-03\n",
      "Epoch 16000, Train loss: 6.780e+03, Test loss: 2.244e+05, MSE(e): 5.182e-04, MSE(pi1): 1.237e-01, MSE(pi2): 3.933e-04, MSE(pi3): 3.597e-03\n",
      "Epoch 16100, Train loss: 5.726e+03, Test loss: 2.147e+05, MSE(e): 5.111e-04, MSE(pi1): 4.465e-02, MSE(pi2): 3.872e-04, MSE(pi3): 1.688e-03\n",
      "Epoch 16200, Train loss: 6.224e+03, Test loss: 2.116e+05, MSE(e): 5.253e-04, MSE(pi1): 6.093e-02, MSE(pi2): 4.320e-04, MSE(pi3): 3.609e-03\n",
      "Epoch 16300, Train loss: 7.308e+03, Test loss: 2.227e+05, MSE(e): 5.749e-04, MSE(pi1): 9.485e-02, MSE(pi2): 4.410e-04, MSE(pi3): 6.098e-03\n",
      "Epoch 16400, Train loss: 6.553e+03, Test loss: 2.261e+05, MSE(e): 4.685e-04, MSE(pi1): 1.245e-01, MSE(pi2): 3.453e-04, MSE(pi3): 6.223e-03\n",
      "Epoch 16500, Train loss: 4.516e+03, Test loss: 2.217e+05, MSE(e): 3.648e-04, MSE(pi1): 6.970e-02, MSE(pi2): 3.001e-04, MSE(pi3): 1.707e-03\n",
      "Epoch 16600, Train loss: 1.696e+04, Test loss: 2.212e+05, MSE(e): 1.537e-03, MSE(pi1): 1.077e-01, MSE(pi2): 8.740e-04, MSE(pi3): 5.199e-03\n",
      "Epoch 16700, Train loss: 7.232e+03, Test loss: 2.303e+05, MSE(e): 4.550e-04, MSE(pi1): 1.957e-01, MSE(pi2): 3.324e-04, MSE(pi3): 7.242e-03\n",
      "Epoch 16800, Train loss: 1.035e+04, Test loss: 2.483e+05, MSE(e): 9.235e-04, MSE(pi1): 8.625e-02, MSE(pi2): 5.408e-04, MSE(pi3): 2.480e-03\n",
      "Epoch 16900, Train loss: 5.148e+03, Test loss: 2.217e+05, MSE(e): 4.137e-04, MSE(pi1): 6.472e-02, MSE(pi2): 3.187e-04, MSE(pi3): 3.639e-03\n",
      "Epoch 17000, Train loss: 6.724e+03, Test loss: 2.242e+05, MSE(e): 5.500e-04, MSE(pi1): 7.082e-02, MSE(pi2): 4.042e-04, MSE(pi3): 5.148e-03\n",
      "Epoch 17100, Train loss: 1.752e+04, Test loss: 2.274e+05, MSE(e): 7.338e-04, MSE(pi1): 9.934e-01, MSE(pi2): 4.276e-04, MSE(pi3): 2.502e-03\n",
      "Epoch 17200, Train loss: 4.797e+03, Test loss: 2.225e+05, MSE(e): 4.058e-04, MSE(pi1): 5.488e-02, MSE(pi2): 3.142e-04, MSE(pi3): 1.897e-03\n",
      "Epoch 17300, Train loss: 7.461e+03, Test loss: 2.285e+05, MSE(e): 4.318e-04, MSE(pi1): 1.279e-01, MSE(pi2): 3.257e-04, MSE(pi3): 1.864e-02\n",
      "Epoch 17400, Train loss: 6.583e+03, Test loss: 2.271e+05, MSE(e): 5.219e-04, MSE(pi1): 8.190e-02, MSE(pi2): 3.747e-04, MSE(pi3): 5.446e-03\n",
      "Epoch 17500, Train loss: 4.802e+03, Test loss: 2.265e+05, MSE(e): 3.827e-04, MSE(pi1): 8.376e-02, MSE(pi2): 3.010e-04, MSE(pi3): 1.364e-03\n",
      "Epoch 17600, Train loss: 5.167e+03, Test loss: 2.391e+05, MSE(e): 4.474e-04, MSE(pi1): 5.066e-02, MSE(pi2): 3.328e-04, MSE(pi3): 1.865e-03\n",
      "Epoch 17700, Train loss: 5.508e+03, Test loss: 2.330e+05, MSE(e): 3.590e-04, MSE(pi1): 1.325e-01, MSE(pi2): 2.703e-04, MSE(pi3): 5.926e-03\n",
      "Epoch 17800, Train loss: 4.562e+03, Test loss: 2.281e+05, MSE(e): 3.992e-04, MSE(pi1): 3.774e-02, MSE(pi2): 3.085e-04, MSE(pi3): 1.920e-03\n",
      "Epoch 17900, Train loss: 4.549e+03, Test loss: 2.358e+05, MSE(e): 3.305e-04, MSE(pi1): 1.075e-01, MSE(pi2): 2.621e-04, MSE(pi3): 1.684e-03\n",
      "Epoch 18000, Train loss: 3.710e+03, Test loss: 2.331e+05, MSE(e): 3.001e-04, MSE(pi1): 5.453e-02, MSE(pi2): 2.506e-04, MSE(pi3): 1.635e-03\n",
      "Epoch 18100, Train loss: 8.458e+03, Test loss: 2.383e+05, MSE(e): 4.931e-04, MSE(pi1): 2.183e-01, MSE(pi2): 3.863e-04, MSE(pi3): 1.344e-02\n",
      "Epoch 18200, Train loss: 3.055e+04, Test loss: 2.508e+05, MSE(e): 2.979e-03, MSE(pi1): 5.929e-02, MSE(pi2): 1.589e-03, MSE(pi3): 1.609e-03\n",
      "Epoch 18300, Train loss: 1.211e+04, Test loss: 2.374e+05, MSE(e): 7.534e-04, MSE(pi1): 4.437e-01, MSE(pi2): 4.966e-04, MSE(pi3): 1.338e-03\n",
      "Epoch 18400, Train loss: 1.779e+04, Test loss: 2.389e+05, MSE(e): 1.666e-03, MSE(pi1): 8.795e-02, MSE(pi2): 9.512e-04, MSE(pi3): 2.558e-03\n",
      "Epoch 18500, Train loss: 6.092e+03, Test loss: 2.354e+05, MSE(e): 4.102e-04, MSE(pi1): 1.092e-01, MSE(pi2): 3.237e-04, MSE(pi3): 8.980e-03\n",
      "Epoch 18600, Train loss: 4.344e+04, Test loss: 3.131e+05, MSE(e): 4.188e-03, MSE(pi1): 1.075e-01, MSE(pi2): 2.160e-03, MSE(pi3): 4.836e-03\n",
      "Epoch 18700, Train loss: 3.560e+03, Test loss: 2.395e+05, MSE(e): 2.825e-04, MSE(pi1): 5.287e-02, MSE(pi2): 2.325e-04, MSE(pi3): 2.058e-03\n",
      "Epoch 18800, Train loss: 2.684e+04, Test loss: 2.982e+05, MSE(e): 2.403e-03, MSE(pi1): 1.742e-01, MSE(pi2): 1.199e-03, MSE(pi3): 1.068e-02\n",
      "Epoch 18900, Train loss: 3.228e+03, Test loss: 2.400e+05, MSE(e): 2.703e-04, MSE(pi1): 2.994e-02, MSE(pi2): 2.283e-04, MSE(pi3): 2.248e-03\n",
      "Epoch 19000, Train loss: 3.610e+03, Test loss: 2.432e+05, MSE(e): 2.755e-04, MSE(pi1): 6.903e-02, MSE(pi2): 2.277e-04, MSE(pi3): 1.640e-03\n",
      "Epoch 19100, Train loss: 5.195e+03, Test loss: 2.383e+05, MSE(e): 3.923e-04, MSE(pi1): 1.136e-01, MSE(pi2): 2.991e-04, MSE(pi3): 1.353e-03\n",
      "Epoch 19200, Train loss: 7.539e+03, Test loss: 2.369e+05, MSE(e): 5.995e-04, MSE(pi1): 1.128e-01, MSE(pi2): 4.219e-04, MSE(pi3): 4.167e-03\n",
      "Epoch 19300, Train loss: 4.318e+03, Test loss: 2.446e+05, MSE(e): 3.222e-04, MSE(pi1): 7.882e-02, MSE(pi2): 2.550e-04, MSE(pi3): 3.074e-03\n",
      "Epoch 19400, Train loss: 4.945e+03, Test loss: 2.486e+05, MSE(e): 3.833e-04, MSE(pi1): 8.842e-02, MSE(pi2): 2.895e-04, MSE(pi3): 2.265e-03\n",
      "Epoch 19500, Train loss: 9.255e+03, Test loss: 2.531e+05, MSE(e): 4.423e-04, MSE(pi1): 4.636e-01, MSE(pi2): 2.772e-04, MSE(pi3): 1.955e-03\n",
      "Epoch 19600, Train loss: 6.470e+03, Test loss: 2.589e+05, MSE(e): 5.670e-04, MSE(pi1): 6.333e-02, MSE(pi2): 3.485e-04, MSE(pi3): 1.659e-03\n",
      "Epoch 19700, Train loss: 4.973e+03, Test loss: 2.471e+05, MSE(e): 3.097e-04, MSE(pi1): 1.081e-01, MSE(pi2): 2.273e-04, MSE(pi3): 7.958e-03\n",
      "Epoch 19800, Train loss: 3.117e+03, Test loss: 2.482e+05, MSE(e): 2.542e-04, MSE(pi1): 3.181e-02, MSE(pi2): 2.125e-04, MSE(pi3): 2.570e-03\n",
      "Epoch 19900, Train loss: 5.288e+03, Test loss: 2.563e+05, MSE(e): 4.463e-04, MSE(pi1): 4.835e-02, MSE(pi2): 3.339e-04, MSE(pi3): 3.410e-03\n",
      "\n",
      "Training process finished after 20000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = BaselineNonlinearModel(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 20000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 18000.\n",
      "Epoch 18000, Train loss: 3.640e+03, Test loss: 2.332e+05, MSE(e): 2.989e-04, MSE(pi1): 4.944e-02, MSE(pi2): 2.503e-04, MSE(pi3): 1.570e-03\n",
      "Epoch 18100, Train loss: 3.271e+03, Test loss: 2.336e+05, MSE(e): 2.888e-04, MSE(pi1): 2.300e-02, MSE(pi2): 2.466e-04, MSE(pi3): 1.533e-03\n",
      "Epoch 18200, Train loss: 3.265e+03, Test loss: 2.335e+05, MSE(e): 2.883e-04, MSE(pi1): 2.301e-02, MSE(pi2): 2.462e-04, MSE(pi3): 1.519e-03\n",
      "Epoch 18300, Train loss: 3.259e+03, Test loss: 2.333e+05, MSE(e): 2.878e-04, MSE(pi1): 2.299e-02, MSE(pi2): 2.458e-04, MSE(pi3): 1.513e-03\n",
      "Epoch 18400, Train loss: 3.253e+03, Test loss: 2.332e+05, MSE(e): 2.873e-04, MSE(pi1): 2.294e-02, MSE(pi2): 2.454e-04, MSE(pi3): 1.509e-03\n",
      "Epoch 18500, Train loss: 3.247e+03, Test loss: 2.331e+05, MSE(e): 2.868e-04, MSE(pi1): 2.288e-02, MSE(pi2): 2.450e-04, MSE(pi3): 1.507e-03\n",
      "Epoch 18600, Train loss: 3.241e+03, Test loss: 2.330e+05, MSE(e): 2.862e-04, MSE(pi1): 2.281e-02, MSE(pi2): 2.446e-04, MSE(pi3): 1.504e-03\n",
      "Epoch 18700, Train loss: 3.235e+03, Test loss: 2.328e+05, MSE(e): 2.857e-04, MSE(pi1): 2.274e-02, MSE(pi2): 2.442e-04, MSE(pi3): 1.501e-03\n",
      "Epoch 18800, Train loss: 3.228e+03, Test loss: 2.327e+05, MSE(e): 2.851e-04, MSE(pi1): 2.267e-02, MSE(pi2): 2.437e-04, MSE(pi3): 1.499e-03\n",
      "Epoch 18900, Train loss: 3.221e+03, Test loss: 2.326e+05, MSE(e): 2.845e-04, MSE(pi1): 2.259e-02, MSE(pi2): 2.433e-04, MSE(pi3): 1.496e-03\n",
      "Epoch 19000, Train loss: 3.214e+03, Test loss: 2.325e+05, MSE(e): 2.839e-04, MSE(pi1): 2.251e-02, MSE(pi2): 2.428e-04, MSE(pi3): 1.493e-03\n",
      "Epoch 19100, Train loss: 3.207e+03, Test loss: 2.323e+05, MSE(e): 2.833e-04, MSE(pi1): 2.243e-02, MSE(pi2): 2.423e-04, MSE(pi3): 1.490e-03\n",
      "Epoch 19200, Train loss: 3.199e+03, Test loss: 2.322e+05, MSE(e): 2.827e-04, MSE(pi1): 2.234e-02, MSE(pi2): 2.418e-04, MSE(pi3): 1.487e-03\n",
      "Epoch 19300, Train loss: 3.191e+03, Test loss: 2.321e+05, MSE(e): 2.820e-04, MSE(pi1): 2.226e-02, MSE(pi2): 2.412e-04, MSE(pi3): 1.484e-03\n",
      "Epoch 19400, Train loss: 3.183e+03, Test loss: 2.319e+05, MSE(e): 2.813e-04, MSE(pi1): 2.216e-02, MSE(pi2): 2.407e-04, MSE(pi3): 1.481e-03\n",
      "Epoch 19500, Train loss: 3.174e+03, Test loss: 2.318e+05, MSE(e): 2.806e-04, MSE(pi1): 2.207e-02, MSE(pi2): 2.401e-04, MSE(pi3): 1.478e-03\n",
      "Epoch 19600, Train loss: 3.165e+03, Test loss: 2.316e+05, MSE(e): 2.798e-04, MSE(pi1): 2.197e-02, MSE(pi2): 2.395e-04, MSE(pi3): 1.475e-03\n",
      "Epoch 19700, Train loss: 3.156e+03, Test loss: 2.315e+05, MSE(e): 2.790e-04, MSE(pi1): 2.186e-02, MSE(pi2): 2.389e-04, MSE(pi3): 1.471e-03\n",
      "Epoch 19800, Train loss: 3.147e+03, Test loss: 2.313e+05, MSE(e): 2.782e-04, MSE(pi1): 2.176e-02, MSE(pi2): 2.382e-04, MSE(pi3): 1.468e-03\n",
      "Epoch 19900, Train loss: 3.137e+03, Test loss: 2.311e+05, MSE(e): 2.774e-04, MSE(pi1): 2.165e-02, MSE(pi2): 2.376e-04, MSE(pi3): 1.464e-03\n",
      "Epoch 20000, Train loss: 3.127e+03, Test loss: 2.310e+05, MSE(e): 2.765e-04, MSE(pi1): 2.154e-02, MSE(pi2): 2.369e-04, MSE(pi3): 1.461e-03\n",
      "Epoch 20100, Train loss: 3.116e+03, Test loss: 2.308e+05, MSE(e): 2.756e-04, MSE(pi1): 2.142e-02, MSE(pi2): 2.361e-04, MSE(pi3): 1.457e-03\n",
      "Epoch 20200, Train loss: 3.105e+03, Test loss: 2.306e+05, MSE(e): 2.746e-04, MSE(pi1): 2.130e-02, MSE(pi2): 2.354e-04, MSE(pi3): 1.454e-03\n",
      "Epoch 20300, Train loss: 3.093e+03, Test loss: 2.304e+05, MSE(e): 2.736e-04, MSE(pi1): 2.118e-02, MSE(pi2): 2.346e-04, MSE(pi3): 1.450e-03\n",
      "Epoch 20400, Train loss: 3.081e+03, Test loss: 2.303e+05, MSE(e): 2.726e-04, MSE(pi1): 2.106e-02, MSE(pi2): 2.337e-04, MSE(pi3): 1.446e-03\n",
      "Epoch 20500, Train loss: 3.069e+03, Test loss: 2.301e+05, MSE(e): 2.715e-04, MSE(pi1): 2.093e-02, MSE(pi2): 2.329e-04, MSE(pi3): 1.442e-03\n",
      "Epoch 20600, Train loss: 3.056e+03, Test loss: 2.299e+05, MSE(e): 2.704e-04, MSE(pi1): 2.079e-02, MSE(pi2): 2.320e-04, MSE(pi3): 1.439e-03\n",
      "Epoch 20700, Train loss: 3.043e+03, Test loss: 2.297e+05, MSE(e): 2.693e-04, MSE(pi1): 2.066e-02, MSE(pi2): 2.311e-04, MSE(pi3): 1.435e-03\n",
      "Epoch 20800, Train loss: 3.029e+03, Test loss: 2.295e+05, MSE(e): 2.681e-04, MSE(pi1): 2.052e-02, MSE(pi2): 2.301e-04, MSE(pi3): 1.431e-03\n",
      "Epoch 20900, Train loss: 3.015e+03, Test loss: 2.293e+05, MSE(e): 2.669e-04, MSE(pi1): 2.038e-02, MSE(pi2): 2.291e-04, MSE(pi3): 1.427e-03\n",
      "Epoch 21000, Train loss: 3.001e+03, Test loss: 2.291e+05, MSE(e): 2.656e-04, MSE(pi1): 2.023e-02, MSE(pi2): 2.281e-04, MSE(pi3): 1.422e-03\n",
      "Epoch 21100, Train loss: 2.986e+03, Test loss: 2.289e+05, MSE(e): 2.643e-04, MSE(pi1): 2.008e-02, MSE(pi2): 2.270e-04, MSE(pi3): 1.418e-03\n",
      "Epoch 21200, Train loss: 2.970e+03, Test loss: 2.286e+05, MSE(e): 2.629e-04, MSE(pi1): 1.993e-02, MSE(pi2): 2.259e-04, MSE(pi3): 1.414e-03\n",
      "Epoch 21300, Train loss: 2.954e+03, Test loss: 2.284e+05, MSE(e): 2.615e-04, MSE(pi1): 1.977e-02, MSE(pi2): 2.247e-04, MSE(pi3): 1.410e-03\n",
      "Epoch 21400, Train loss: 2.937e+03, Test loss: 2.282e+05, MSE(e): 2.600e-04, MSE(pi1): 1.961e-02, MSE(pi2): 2.235e-04, MSE(pi3): 1.405e-03\n",
      "Epoch 21500, Train loss: 2.920e+03, Test loss: 2.280e+05, MSE(e): 2.585e-04, MSE(pi1): 1.945e-02, MSE(pi2): 2.222e-04, MSE(pi3): 1.401e-03\n",
      "Epoch 21600, Train loss: 2.902e+03, Test loss: 2.277e+05, MSE(e): 2.569e-04, MSE(pi1): 1.928e-02, MSE(pi2): 2.209e-04, MSE(pi3): 1.397e-03\n",
      "Epoch 21700, Train loss: 2.883e+03, Test loss: 2.275e+05, MSE(e): 2.553e-04, MSE(pi1): 1.911e-02, MSE(pi2): 2.196e-04, MSE(pi3): 1.392e-03\n",
      "Epoch 21800, Train loss: 2.864e+03, Test loss: 2.272e+05, MSE(e): 2.536e-04, MSE(pi1): 1.894e-02, MSE(pi2): 2.182e-04, MSE(pi3): 1.388e-03\n",
      "Epoch 21900, Train loss: 2.845e+03, Test loss: 2.270e+05, MSE(e): 2.519e-04, MSE(pi1): 1.876e-02, MSE(pi2): 2.167e-04, MSE(pi3): 1.383e-03\n",
      "Epoch 22000, Train loss: 2.824e+03, Test loss: 2.267e+05, MSE(e): 2.501e-04, MSE(pi1): 1.858e-02, MSE(pi2): 2.152e-04, MSE(pi3): 1.378e-03\n",
      "Epoch 22100, Train loss: 2.804e+03, Test loss: 2.265e+05, MSE(e): 2.482e-04, MSE(pi1): 1.840e-02, MSE(pi2): 2.137e-04, MSE(pi3): 1.374e-03\n",
      "Epoch 22200, Train loss: 2.782e+03, Test loss: 2.262e+05, MSE(e): 2.463e-04, MSE(pi1): 1.822e-02, MSE(pi2): 2.121e-04, MSE(pi3): 1.369e-03\n",
      "Epoch 22300, Train loss: 2.760e+03, Test loss: 2.259e+05, MSE(e): 2.443e-04, MSE(pi1): 1.803e-02, MSE(pi2): 2.104e-04, MSE(pi3): 1.364e-03\n",
      "Epoch 22400, Train loss: 2.738e+03, Test loss: 2.256e+05, MSE(e): 2.423e-04, MSE(pi1): 1.784e-02, MSE(pi2): 2.087e-04, MSE(pi3): 1.359e-03\n",
      "Epoch 22500, Train loss: 2.714e+03, Test loss: 2.253e+05, MSE(e): 2.402e-04, MSE(pi1): 1.765e-02, MSE(pi2): 2.070e-04, MSE(pi3): 1.355e-03\n",
      "Epoch 22600, Train loss: 2.696e+03, Test loss: 2.250e+05, MSE(e): 2.383e-04, MSE(pi1): 1.746e-02, MSE(pi2): 2.053e-04, MSE(pi3): 1.375e-03\n",
      "Epoch 22700, Train loss: 2.668e+03, Test loss: 2.248e+05, MSE(e): 2.360e-04, MSE(pi1): 1.726e-02, MSE(pi2): 2.034e-04, MSE(pi3): 1.349e-03\n",
      "Epoch 22800, Train loss: 2.666e+03, Test loss: 2.246e+05, MSE(e): 2.345e-04, MSE(pi1): 1.822e-02, MSE(pi2): 2.017e-04, MSE(pi3): 1.377e-03\n",
      "Epoch 22900, Train loss: 2.629e+03, Test loss: 2.245e+05, MSE(e): 2.326e-04, MSE(pi1): 1.694e-02, MSE(pi2): 2.001e-04, MSE(pi3): 1.339e-03\n",
      "Epoch 23000, Train loss: 2.601e+03, Test loss: 2.240e+05, MSE(e): 2.300e-04, MSE(pi1): 1.674e-02, MSE(pi2): 1.982e-04, MSE(pi3): 1.335e-03\n",
      "Epoch 23100, Train loss: 2.694e+03, Test loss: 2.224e+05, MSE(e): 2.390e-04, MSE(pi1): 1.727e-02, MSE(pi2): 2.022e-04, MSE(pi3): 1.306e-03\n",
      "Epoch 23200, Train loss: 2.599e+03, Test loss: 2.238e+05, MSE(e): 2.276e-04, MSE(pi1): 1.859e-02, MSE(pi2): 1.952e-04, MSE(pi3): 1.367e-03\n",
      "Epoch 23300, Train loss: 2.540e+03, Test loss: 2.233e+05, MSE(e): 2.242e-04, MSE(pi1): 1.661e-02, MSE(pi2): 1.932e-04, MSE(pi3): 1.323e-03\n",
      "Epoch 23400, Train loss: 2.518e+03, Test loss: 2.231e+05, MSE(e): 2.226e-04, MSE(pi1): 1.610e-02, MSE(pi2): 1.917e-04, MSE(pi3): 1.316e-03\n",
      "Epoch 23500, Train loss: 2.525e+03, Test loss: 2.228e+05, MSE(e): 2.210e-04, MSE(pi1): 1.870e-02, MSE(pi2): 1.901e-04, MSE(pi3): 1.279e-03\n",
      "Epoch 23600, Train loss: 2.474e+03, Test loss: 2.224e+05, MSE(e): 2.185e-04, MSE(pi1): 1.580e-02, MSE(pi2): 1.884e-04, MSE(pi3): 1.306e-03\n",
      "Epoch 23700, Train loss: 2.459e+03, Test loss: 2.224e+05, MSE(e): 2.171e-04, MSE(pi1): 1.566e-02, MSE(pi2): 1.870e-04, MSE(pi3): 1.307e-03\n",
      "Epoch 23800, Train loss: 2.463e+03, Test loss: 2.217e+05, MSE(e): 2.174e-04, MSE(pi1): 1.605e-02, MSE(pi2): 1.868e-04, MSE(pi3): 1.279e-03\n",
      "Epoch 23900, Train loss: 2.419e+03, Test loss: 2.217e+05, MSE(e): 2.134e-04, MSE(pi1): 1.541e-02, MSE(pi2): 1.839e-04, MSE(pi3): 1.309e-03\n",
      "Epoch 24000, Train loss: 2.399e+03, Test loss: 2.215e+05, MSE(e): 2.117e-04, MSE(pi1): 1.523e-02, MSE(pi2): 1.825e-04, MSE(pi3): 1.294e-03\n",
      "Epoch 24100, Train loss: 2.589e+03, Test loss: 2.234e+05, MSE(e): 2.304e-04, MSE(pi1): 1.519e-02, MSE(pi2): 1.903e-04, MSE(pi3): 1.323e-03\n",
      "Epoch 24200, Train loss: 2.532e+03, Test loss: 2.194e+05, MSE(e): 2.239e-04, MSE(pi1): 1.595e-02, MSE(pi2): 1.920e-04, MSE(pi3): 1.336e-03\n",
      "Epoch 24300, Train loss: 2.635e+03, Test loss: 2.223e+05, MSE(e): 2.346e-04, MSE(pi1): 1.543e-02, MSE(pi2): 1.909e-04, MSE(pi3): 1.337e-03\n",
      "Epoch 24400, Train loss: 2.548e+03, Test loss: 2.206e+05, MSE(e): 2.104e-04, MSE(pi1): 3.132e-02, MSE(pi2): 1.780e-04, MSE(pi3): 1.302e-03\n",
      "Epoch 24500, Train loss: 2.311e+03, Test loss: 2.203e+05, MSE(e): 2.036e-04, MSE(pi1): 1.468e-02, MSE(pi2): 1.755e-04, MSE(pi3): 1.275e-03\n",
      "Epoch 24600, Train loss: 2.294e+03, Test loss: 2.200e+05, MSE(e): 2.021e-04, MSE(pi1): 1.457e-02, MSE(pi2): 1.743e-04, MSE(pi3): 1.271e-03\n",
      "Epoch 24700, Train loss: 2.281e+03, Test loss: 2.195e+05, MSE(e): 2.010e-04, MSE(pi1): 1.449e-02, MSE(pi2): 1.733e-04, MSE(pi3): 1.266e-03\n",
      "Epoch 24800, Train loss: 2.525e+03, Test loss: 2.179e+05, MSE(e): 2.222e-04, MSE(pi1): 1.800e-02, MSE(pi2): 1.833e-04, MSE(pi3): 1.229e-03\n",
      "Epoch 24900, Train loss: 2.265e+03, Test loss: 2.198e+05, MSE(e): 1.995e-04, MSE(pi1): 1.433e-02, MSE(pi2): 1.712e-04, MSE(pi3): 1.264e-03\n",
      "Epoch 25000, Train loss: 2.395e+03, Test loss: 2.180e+05, MSE(e): 2.108e-04, MSE(pi1): 1.645e-02, MSE(pi2): 1.763e-04, MSE(pi3): 1.227e-03\n",
      "Epoch 25100, Train loss: 2.291e+03, Test loss: 2.182e+05, MSE(e): 1.990e-04, MSE(pi1): 1.710e-02, MSE(pi2): 1.699e-04, MSE(pi3): 1.304e-03\n",
      "Epoch 25200, Train loss: 2.204e+03, Test loss: 2.190e+05, MSE(e): 1.938e-04, MSE(pi1): 1.386e-02, MSE(pi2): 1.668e-04, MSE(pi3): 1.265e-03\n",
      "Epoch 25300, Train loss: 2.186e+03, Test loss: 2.184e+05, MSE(e): 1.921e-04, MSE(pi1): 1.392e-02, MSE(pi2): 1.655e-04, MSE(pi3): 1.256e-03\n",
      "Epoch 25400, Train loss: 2.179e+03, Test loss: 2.182e+05, MSE(e): 1.916e-04, MSE(pi1): 1.382e-02, MSE(pi2): 1.647e-04, MSE(pi3): 1.253e-03\n",
      "Epoch 25500, Train loss: 2.172e+03, Test loss: 2.186e+05, MSE(e): 1.904e-04, MSE(pi1): 1.440e-02, MSE(pi2): 1.633e-04, MSE(pi3): 1.240e-03\n",
      "Epoch 25600, Train loss: 2.140e+03, Test loss: 2.178e+05, MSE(e): 1.879e-04, MSE(pi1): 1.370e-02, MSE(pi2): 1.619e-04, MSE(pi3): 1.239e-03\n",
      "Epoch 25700, Train loss: 2.284e+03, Test loss: 2.193e+05, MSE(e): 1.969e-04, MSE(pi1): 1.832e-02, MSE(pi2): 1.652e-04, MSE(pi3): 1.324e-03\n",
      "Epoch 25800, Train loss: 2.125e+03, Test loss: 2.170e+05, MSE(e): 1.866e-04, MSE(pi1): 1.333e-02, MSE(pi2): 1.604e-04, MSE(pi3): 1.252e-03\n",
      "Epoch 25900, Train loss: 2.144e+03, Test loss: 2.172e+05, MSE(e): 1.860e-04, MSE(pi1): 1.577e-02, MSE(pi2): 1.591e-04, MSE(pi3): 1.264e-03\n",
      "Epoch 26000, Train loss: 2.084e+03, Test loss: 2.170e+05, MSE(e): 1.828e-04, MSE(pi1): 1.320e-02, MSE(pi2): 1.574e-04, MSE(pi3): 1.238e-03\n",
      "Epoch 26100, Train loss: 2.115e+03, Test loss: 2.159e+05, MSE(e): 1.860e-04, MSE(pi1): 1.331e-02, MSE(pi2): 1.587e-04, MSE(pi3): 1.219e-03\n",
      "Epoch 26200, Train loss: 2.284e+03, Test loss: 2.161e+05, MSE(e): 1.940e-04, MSE(pi1): 2.122e-02, MSE(pi2): 1.613e-04, MSE(pi3): 1.318e-03\n",
      "Epoch 26300, Train loss: 2.044e+03, Test loss: 2.162e+05, MSE(e): 1.791e-04, MSE(pi1): 1.291e-02, MSE(pi2): 1.542e-04, MSE(pi3): 1.239e-03\n",
      "Epoch 26400, Train loss: 2.037e+03, Test loss: 2.158e+05, MSE(e): 1.782e-04, MSE(pi1): 1.332e-02, MSE(pi2): 1.533e-04, MSE(pi3): 1.224e-03\n",
      "Epoch 26500, Train loss: 2.038e+03, Test loss: 2.163e+05, MSE(e): 1.786e-04, MSE(pi1): 1.277e-02, MSE(pi2): 1.529e-04, MSE(pi3): 1.234e-03\n",
      "Epoch 26600, Train loss: 2.015e+03, Test loss: 2.160e+05, MSE(e): 1.762e-04, MSE(pi1): 1.270e-02, MSE(pi2): 1.513e-04, MSE(pi3): 1.258e-03\n",
      "Epoch 26700, Train loss: 1.992e+03, Test loss: 2.154e+05, MSE(e): 1.744e-04, MSE(pi1): 1.258e-02, MSE(pi2): 1.501e-04, MSE(pi3): 1.230e-03\n",
      "Epoch 26800, Train loss: 2.012e+03, Test loss: 2.150e+05, MSE(e): 1.759e-04, MSE(pi1): 1.306e-02, MSE(pi2): 1.506e-04, MSE(pi3): 1.224e-03\n",
      "Epoch 26900, Train loss: 2.069e+03, Test loss: 2.137e+05, MSE(e): 1.820e-04, MSE(pi1): 1.294e-02, MSE(pi2): 1.531e-04, MSE(pi3): 1.201e-03\n",
      "Epoch 27000, Train loss: 2.075e+03, Test loss: 2.148e+05, MSE(e): 1.791e-04, MSE(pi1): 1.558e-02, MSE(pi2): 1.509e-04, MSE(pi3): 1.286e-03\n",
      "Epoch 27100, Train loss: 1.998e+03, Test loss: 2.137e+05, MSE(e): 1.744e-04, MSE(pi1): 1.342e-02, MSE(pi2): 1.485e-04, MSE(pi3): 1.203e-03\n",
      "Epoch 27200, Train loss: 2.094e+03, Test loss: 2.131e+05, MSE(e): 1.843e-04, MSE(pi1): 1.292e-02, MSE(pi2): 1.524e-04, MSE(pi3): 1.215e-03\n",
      "Epoch 27300, Train loss: 1.967e+03, Test loss: 2.137e+05, MSE(e): 1.691e-04, MSE(pi1): 1.580e-02, MSE(pi2): 1.449e-04, MSE(pi3): 1.176e-03\n",
      "Epoch 27400, Train loss: 2.226e+03, Test loss: 2.160e+05, MSE(e): 1.910e-04, MSE(pi1): 1.978e-02, MSE(pi2): 1.530e-04, MSE(pi3): 1.180e-03\n",
      "Epoch 27500, Train loss: 1.908e+03, Test loss: 2.135e+05, MSE(e): 1.665e-04, MSE(pi1): 1.199e-02, MSE(pi2): 1.428e-04, MSE(pi3): 1.226e-03\n",
      "Epoch 27600, Train loss: 1.911e+03, Test loss: 2.136e+05, MSE(e): 1.654e-04, MSE(pi1): 1.318e-02, MSE(pi2): 1.417e-04, MSE(pi3): 1.249e-03\n",
      "Epoch 27700, Train loss: 1.928e+03, Test loss: 2.138e+05, MSE(e): 1.659e-04, MSE(pi1): 1.411e-02, MSE(pi2): 1.414e-04, MSE(pi3): 1.275e-03\n",
      "Epoch 27800, Train loss: 1.868e+03, Test loss: 2.130e+05, MSE(e): 1.625e-04, MSE(pi1): 1.205e-02, MSE(pi2): 1.397e-04, MSE(pi3): 1.222e-03\n",
      "Epoch 27900, Train loss: 1.933e+03, Test loss: 2.138e+05, MSE(e): 1.657e-04, MSE(pi1): 1.524e-02, MSE(pi2): 1.404e-04, MSE(pi3): 1.235e-03\n",
      "Epoch 28000, Train loss: 1.842e+03, Test loss: 2.123e+05, MSE(e): 1.605e-04, MSE(pi1): 1.185e-02, MSE(pi2): 1.381e-04, MSE(pi3): 1.193e-03\n",
      "Epoch 28100, Train loss: 1.842e+03, Test loss: 2.127e+05, MSE(e): 1.604e-04, MSE(pi1): 1.174e-02, MSE(pi2): 1.375e-04, MSE(pi3): 1.204e-03\n",
      "Epoch 28200, Train loss: 1.830e+03, Test loss: 2.123e+05, MSE(e): 1.586e-04, MSE(pi1): 1.219e-02, MSE(pi2): 1.362e-04, MSE(pi3): 1.221e-03\n",
      "Epoch 28300, Train loss: 1.833e+03, Test loss: 2.126e+05, MSE(e): 1.593e-04, MSE(pi1): 1.192e-02, MSE(pi2): 1.361e-04, MSE(pi3): 1.206e-03\n",
      "Epoch 28400, Train loss: 1.806e+03, Test loss: 2.117e+05, MSE(e): 1.571e-04, MSE(pi1): 1.159e-02, MSE(pi2): 1.348e-04, MSE(pi3): 1.197e-03\n",
      "Epoch 28500, Train loss: 1.812e+03, Test loss: 2.122e+05, MSE(e): 1.569e-04, MSE(pi1): 1.184e-02, MSE(pi2): 1.343e-04, MSE(pi3): 1.236e-03\n",
      "Epoch 28600, Train loss: 1.778e+03, Test loss: 2.113e+05, MSE(e): 1.545e-04, MSE(pi1): 1.136e-02, MSE(pi2): 1.329e-04, MSE(pi3): 1.196e-03\n",
      "Epoch 28700, Train loss: 1.772e+03, Test loss: 2.111e+05, MSE(e): 1.538e-04, MSE(pi1): 1.143e-02, MSE(pi2): 1.322e-04, MSE(pi3): 1.198e-03\n",
      "Epoch 28800, Train loss: 1.779e+03, Test loss: 2.116e+05, MSE(e): 1.541e-04, MSE(pi1): 1.191e-02, MSE(pi2): 1.320e-04, MSE(pi3): 1.195e-03\n",
      "Epoch 28900, Train loss: 1.754e+03, Test loss: 2.105e+05, MSE(e): 1.520e-04, MSE(pi1): 1.156e-02, MSE(pi2): 1.308e-04, MSE(pi3): 1.180e-03\n",
      "Epoch 29000, Train loss: 1.738e+03, Test loss: 2.106e+05, MSE(e): 1.508e-04, MSE(pi1): 1.120e-02, MSE(pi2): 1.297e-04, MSE(pi3): 1.183e-03\n",
      "Epoch 29100, Train loss: 1.914e+03, Test loss: 2.111e+05, MSE(e): 1.624e-04, MSE(pi1): 1.653e-02, MSE(pi2): 1.347e-04, MSE(pi3): 1.244e-03\n",
      "Epoch 29200, Train loss: 1.727e+03, Test loss: 2.106e+05, MSE(e): 1.497e-04, MSE(pi1): 1.120e-02, MSE(pi2): 1.284e-04, MSE(pi3): 1.179e-03\n",
      "Epoch 29300, Train loss: 1.735e+03, Test loss: 2.106e+05, MSE(e): 1.496e-04, MSE(pi1): 1.152e-02, MSE(pi2): 1.280e-04, MSE(pi3): 1.231e-03\n",
      "Epoch 29400, Train loss: 2.063e+03, Test loss: 2.118e+05, MSE(e): 1.779e-04, MSE(pi1): 1.687e-02, MSE(pi2): 1.398e-04, MSE(pi3): 1.156e-03\n",
      "Epoch 29500, Train loss: 1.690e+03, Test loss: 2.096e+05, MSE(e): 1.464e-04, MSE(pi1): 1.089e-02, MSE(pi2): 1.260e-04, MSE(pi3): 1.176e-03\n",
      "Epoch 29600, Train loss: 1.682e+03, Test loss: 2.094e+05, MSE(e): 1.455e-04, MSE(pi1): 1.089e-02, MSE(pi2): 1.253e-04, MSE(pi3): 1.174e-03\n",
      "Epoch 29700, Train loss: 1.695e+03, Test loss: 2.096e+05, MSE(e): 1.466e-04, MSE(pi1): 1.090e-02, MSE(pi2): 1.255e-04, MSE(pi3): 1.204e-03\n",
      "Epoch 29800, Train loss: 1.674e+03, Test loss: 2.090e+05, MSE(e): 1.441e-04, MSE(pi1): 1.168e-02, MSE(pi2): 1.239e-04, MSE(pi3): 1.157e-03\n",
      "Epoch 29900, Train loss: 1.655e+03, Test loss: 2.089e+05, MSE(e): 1.431e-04, MSE(pi1): 1.078e-02, MSE(pi2): 1.231e-04, MSE(pi3): 1.167e-03\n",
      "Epoch 30000, Train loss: 1.646e+03, Test loss: 2.086e+05, MSE(e): 1.423e-04, MSE(pi1): 1.065e-02, MSE(pi2): 1.225e-04, MSE(pi3): 1.167e-03\n",
      "Epoch 30100, Train loss: 1.640e+03, Test loss: 2.085e+05, MSE(e): 1.415e-04, MSE(pi1): 1.096e-02, MSE(pi2): 1.217e-04, MSE(pi3): 1.159e-03\n",
      "Epoch 30200, Train loss: 1.701e+03, Test loss: 2.089e+05, MSE(e): 1.463e-04, MSE(pi1): 1.166e-02, MSE(pi2): 1.234e-04, MSE(pi3): 1.219e-03\n",
      "Epoch 30300, Train loss: 1.652e+03, Test loss: 2.081e+05, MSE(e): 1.406e-04, MSE(pi1): 1.287e-02, MSE(pi2): 1.206e-04, MSE(pi3): 1.167e-03\n",
      "Epoch 30400, Train loss: 1.794e+03, Test loss: 2.067e+05, MSE(e): 1.548e-04, MSE(pi1): 1.319e-02, MSE(pi2): 1.272e-04, MSE(pi3): 1.140e-03\n",
      "Epoch 30500, Train loss: 1.633e+03, Test loss: 2.079e+05, MSE(e): 1.410e-04, MSE(pi1): 1.066e-02, MSE(pi2): 1.204e-04, MSE(pi3): 1.156e-03\n",
      "Epoch 30600, Train loss: 1.664e+03, Test loss: 2.086e+05, MSE(e): 1.410e-04, MSE(pi1): 1.306e-02, MSE(pi2): 1.201e-04, MSE(pi3): 1.236e-03\n",
      "Epoch 30700, Train loss: 1.782e+03, Test loss: 2.089e+05, MSE(e): 1.510e-04, MSE(pi1): 1.448e-02, MSE(pi2): 1.236e-04, MSE(pi3): 1.271e-03\n",
      "Epoch 30800, Train loss: 1.629e+03, Test loss: 2.081e+05, MSE(e): 1.408e-04, MSE(pi1): 1.031e-02, MSE(pi2): 1.191e-04, MSE(pi3): 1.175e-03\n",
      "Epoch 30900, Train loss: 1.579e+03, Test loss: 2.074e+05, MSE(e): 1.359e-04, MSE(pi1): 1.026e-02, MSE(pi2): 1.167e-04, MSE(pi3): 1.177e-03\n",
      "Epoch 31000, Train loss: 1.641e+03, Test loss: 2.075e+05, MSE(e): 1.365e-04, MSE(pi1): 1.582e-02, MSE(pi2): 1.165e-04, MSE(pi3): 1.179e-03\n",
      "Epoch 31100, Train loss: 1.578e+03, Test loss: 2.075e+05, MSE(e): 1.360e-04, MSE(pi1): 1.009e-02, MSE(pi2): 1.161e-04, MSE(pi3): 1.168e-03\n",
      "Epoch 31200, Train loss: 1.550e+03, Test loss: 2.070e+05, MSE(e): 1.333e-04, MSE(pi1): 1.001e-02, MSE(pi2): 1.147e-04, MSE(pi3): 1.168e-03\n",
      "Epoch 31300, Train loss: 1.691e+03, Test loss: 2.053e+05, MSE(e): 1.468e-04, MSE(pi1): 1.106e-02, MSE(pi2): 1.213e-04, MSE(pi3): 1.124e-03\n",
      "Epoch 31400, Train loss: 1.547e+03, Test loss: 2.071e+05, MSE(e): 1.324e-04, MSE(pi1): 1.058e-02, MSE(pi2): 1.136e-04, MSE(pi3): 1.162e-03\n",
      "Epoch 31500, Train loss: 1.553e+03, Test loss: 2.057e+05, MSE(e): 1.333e-04, MSE(pi1): 1.028e-02, MSE(pi2): 1.139e-04, MSE(pi3): 1.171e-03\n",
      "Epoch 31600, Train loss: 1.539e+03, Test loss: 2.066e+05, MSE(e): 1.311e-04, MSE(pi1): 1.086e-02, MSE(pi2): 1.124e-04, MSE(pi3): 1.186e-03\n",
      "Epoch 31700, Train loss: 1.926e+03, Test loss: 2.050e+05, MSE(e): 1.659e-04, MSE(pi1): 1.535e-02, MSE(pi2): 1.299e-04, MSE(pi3): 1.138e-03\n",
      "Epoch 31800, Train loss: 1.541e+03, Test loss: 2.051e+05, MSE(e): 1.315e-04, MSE(pi1): 1.131e-02, MSE(pi2): 1.126e-04, MSE(pi3): 1.130e-03\n",
      "Epoch 31900, Train loss: 1.504e+03, Test loss: 2.058e+05, MSE(e): 1.288e-04, MSE(pi1): 1.025e-02, MSE(pi2): 1.107e-04, MSE(pi3): 1.138e-03\n",
      "Epoch 32000, Train loss: 1.527e+03, Test loss: 2.064e+05, MSE(e): 1.313e-04, MSE(pi1): 9.802e-03, MSE(pi2): 1.113e-04, MSE(pi3): 1.164e-03\n",
      "Epoch 32100, Train loss: 1.696e+03, Test loss: 2.049e+05, MSE(e): 1.419e-04, MSE(pi1): 1.572e-02, MSE(pi2): 1.158e-04, MSE(pi3): 1.199e-03\n",
      "Epoch 32200, Train loss: 1.521e+03, Test loss: 2.059e+05, MSE(e): 1.282e-04, MSE(pi1): 1.229e-02, MSE(pi2): 1.100e-04, MSE(pi3): 1.157e-03\n",
      "Epoch 32300, Train loss: 1.565e+03, Test loss: 2.059e+05, MSE(e): 1.347e-04, MSE(pi1): 1.007e-02, MSE(pi2): 1.120e-04, MSE(pi3): 1.163e-03\n",
      "Epoch 32400, Train loss: 1.496e+03, Test loss: 2.050e+05, MSE(e): 1.257e-04, MSE(pi1): 1.203e-02, MSE(pi2): 1.077e-04, MSE(pi3): 1.189e-03\n",
      "Epoch 32500, Train loss: 1.452e+03, Test loss: 2.051e+05, MSE(e): 1.242e-04, MSE(pi1): 9.568e-03, MSE(pi2): 1.070e-04, MSE(pi3): 1.144e-03\n",
      "Epoch 32600, Train loss: 1.457e+03, Test loss: 2.051e+05, MSE(e): 1.243e-04, MSE(pi1): 1.013e-02, MSE(pi2): 1.068e-04, MSE(pi3): 1.124e-03\n",
      "Epoch 32700, Train loss: 1.478e+03, Test loss: 2.049e+05, MSE(e): 1.240e-04, MSE(pi1): 1.192e-02, MSE(pi2): 1.061e-04, MSE(pi3): 1.191e-03\n",
      "Epoch 32800, Train loss: 1.439e+03, Test loss: 2.050e+05, MSE(e): 1.230e-04, MSE(pi1): 9.431e-03, MSE(pi2): 1.057e-04, MSE(pi3): 1.143e-03\n",
      "Epoch 32900, Train loss: 1.442e+03, Test loss: 2.042e+05, MSE(e): 1.226e-04, MSE(pi1): 1.021e-02, MSE(pi2): 1.056e-04, MSE(pi3): 1.142e-03\n",
      "Epoch 33000, Train loss: 1.463e+03, Test loss: 2.044e+05, MSE(e): 1.222e-04, MSE(pi1): 1.261e-02, MSE(pi2): 1.048e-04, MSE(pi3): 1.142e-03\n",
      "Epoch 33100, Train loss: 1.411e+03, Test loss: 2.045e+05, MSE(e): 1.204e-04, MSE(pi1): 9.308e-03, MSE(pi2): 1.039e-04, MSE(pi3): 1.139e-03\n",
      "Epoch 33200, Train loss: 1.409e+03, Test loss: 2.041e+05, MSE(e): 1.202e-04, MSE(pi1): 9.297e-03, MSE(pi2): 1.036e-04, MSE(pi3): 1.139e-03\n",
      "Epoch 33300, Train loss: 1.962e+03, Test loss: 2.066e+05, MSE(e): 1.737e-04, MSE(pi1): 1.035e-02, MSE(pi2): 1.280e-04, MSE(pi3): 1.207e-03\n",
      "Epoch 33400, Train loss: 1.392e+03, Test loss: 2.043e+05, MSE(e): 1.186e-04, MSE(pi1): 9.205e-03, MSE(pi2): 1.024e-04, MSE(pi3): 1.135e-03\n",
      "Epoch 33500, Train loss: 1.390e+03, Test loss: 2.040e+05, MSE(e): 1.184e-04, MSE(pi1): 9.229e-03, MSE(pi2): 1.021e-04, MSE(pi3): 1.134e-03\n",
      "Epoch 33600, Train loss: 1.385e+03, Test loss: 2.041e+05, MSE(e): 1.176e-04, MSE(pi1): 9.542e-03, MSE(pi2): 1.014e-04, MSE(pi3): 1.133e-03\n",
      "Epoch 33700, Train loss: 1.405e+03, Test loss: 2.046e+05, MSE(e): 1.197e-04, MSE(pi1): 9.324e-03, MSE(pi2): 1.025e-04, MSE(pi3): 1.138e-03\n",
      "Epoch 33800, Train loss: 1.425e+03, Test loss: 2.042e+05, MSE(e): 1.181e-04, MSE(pi1): 1.280e-02, MSE(pi2): 1.008e-04, MSE(pi3): 1.157e-03\n",
      "Epoch 33900, Train loss: 1.375e+03, Test loss: 2.040e+05, MSE(e): 1.161e-04, MSE(pi1): 9.595e-03, MSE(pi2): 9.999e-05, MSE(pi3): 1.174e-03\n",
      "Epoch 34000, Train loss: 1.372e+03, Test loss: 2.041e+05, MSE(e): 1.168e-04, MSE(pi1): 9.109e-03, MSE(pi2): 1.001e-04, MSE(pi3): 1.130e-03\n",
      "Epoch 34100, Train loss: 1.382e+03, Test loss: 2.049e+05, MSE(e): 1.176e-04, MSE(pi1): 8.942e-03, MSE(pi2): 1.005e-04, MSE(pi3): 1.162e-03\n",
      "Epoch 34200, Train loss: 1.450e+03, Test loss: 2.029e+05, MSE(e): 1.247e-04, MSE(pi1): 9.153e-03, MSE(pi2): 1.038e-04, MSE(pi3): 1.115e-03\n",
      "Epoch 34300, Train loss: 1.430e+03, Test loss: 2.047e+05, MSE(e): 1.224e-04, MSE(pi1): 9.298e-03, MSE(pi2): 1.018e-04, MSE(pi3): 1.129e-03\n",
      "Epoch 34400, Train loss: 1.336e+03, Test loss: 2.036e+05, MSE(e): 1.134e-04, MSE(pi1): 8.909e-03, MSE(pi2): 9.780e-05, MSE(pi3): 1.127e-03\n",
      "Epoch 34500, Train loss: 1.330e+03, Test loss: 2.040e+05, MSE(e): 1.128e-04, MSE(pi1): 8.888e-03, MSE(pi2): 9.733e-05, MSE(pi3): 1.126e-03\n",
      "Epoch 34600, Train loss: 1.330e+03, Test loss: 2.038e+05, MSE(e): 1.121e-04, MSE(pi1): 9.757e-03, MSE(pi2): 9.678e-05, MSE(pi3): 1.115e-03\n",
      "Epoch 34700, Train loss: 1.348e+03, Test loss: 2.035e+05, MSE(e): 1.145e-04, MSE(pi1): 8.932e-03, MSE(pi2): 9.802e-05, MSE(pi3): 1.132e-03\n",
      "Epoch 34800, Train loss: 1.332e+03, Test loss: 2.044e+05, MSE(e): 1.131e-04, MSE(pi1): 8.722e-03, MSE(pi2): 9.685e-05, MSE(pi3): 1.145e-03\n",
      "Epoch 34900, Train loss: 1.956e+03, Test loss: 2.016e+05, MSE(e): 1.679e-04, MSE(pi1): 1.686e-02, MSE(pi2): 1.233e-04, MSE(pi3): 1.088e-03\n",
      "Epoch 35000, Train loss: 1.305e+03, Test loss: 2.037e+05, MSE(e): 1.105e-04, MSE(pi1): 8.743e-03, MSE(pi2): 9.536e-05, MSE(pi3): 1.122e-03\n",
      "Epoch 35100, Train loss: 1.348e+03, Test loss: 2.043e+05, MSE(e): 1.136e-04, MSE(pi1): 1.024e-02, MSE(pi2): 9.613e-05, MSE(pi3): 1.098e-03\n",
      "Epoch 35200, Train loss: 1.324e+03, Test loss: 2.029e+05, MSE(e): 1.121e-04, MSE(pi1): 9.352e-03, MSE(pi2): 9.635e-05, MSE(pi3): 1.094e-03\n",
      "Epoch 35300, Train loss: 1.296e+03, Test loss: 2.040e+05, MSE(e): 1.090e-04, MSE(pi1): 9.541e-03, MSE(pi2): 9.390e-05, MSE(pi3): 1.107e-03\n",
      "Epoch 35400, Train loss: 1.278e+03, Test loss: 2.034e+05, MSE(e): 1.079e-04, MSE(pi1): 8.597e-03, MSE(pi2): 9.339e-05, MSE(pi3): 1.121e-03\n",
      "Epoch 35500, Train loss: 1.278e+03, Test loss: 2.033e+05, MSE(e): 1.078e-04, MSE(pi1): 8.890e-03, MSE(pi2): 9.329e-05, MSE(pi3): 1.103e-03\n",
      "Epoch 35600, Train loss: 1.308e+03, Test loss: 2.039e+05, MSE(e): 1.080e-04, MSE(pi1): 1.109e-02, MSE(pi2): 9.277e-05, MSE(pi3): 1.166e-03\n",
      "Epoch 35700, Train loss: 1.261e+03, Test loss: 2.037e+05, MSE(e): 1.064e-04, MSE(pi1): 8.477e-03, MSE(pi2): 9.208e-05, MSE(pi3): 1.119e-03\n",
      "Epoch 35800, Train loss: 1.263e+03, Test loss: 2.034e+05, MSE(e): 1.065e-04, MSE(pi1): 8.697e-03, MSE(pi2): 9.204e-05, MSE(pi3): 1.106e-03\n",
      "Epoch 35900, Train loss: 1.255e+03, Test loss: 2.036e+05, MSE(e): 1.055e-04, MSE(pi1): 8.649e-03, MSE(pi2): 9.131e-05, MSE(pi3): 1.130e-03\n",
      "Epoch 36000, Train loss: 1.245e+03, Test loss: 2.036e+05, MSE(e): 1.049e-04, MSE(pi1): 8.397e-03, MSE(pi2): 9.088e-05, MSE(pi3): 1.116e-03\n",
      "Epoch 36100, Train loss: 1.331e+03, Test loss: 2.052e+05, MSE(e): 1.109e-04, MSE(pi1): 1.036e-02, MSE(pi2): 9.408e-05, MSE(pi3): 1.176e-03\n",
      "Epoch 36200, Train loss: 1.235e+03, Test loss: 2.036e+05, MSE(e): 1.040e-04, MSE(pi1): 8.351e-03, MSE(pi2): 9.013e-05, MSE(pi3): 1.113e-03\n",
      "Epoch 36300, Train loss: 1.230e+03, Test loss: 2.035e+05, MSE(e): 1.035e-04, MSE(pi1): 8.367e-03, MSE(pi2): 8.978e-05, MSE(pi3): 1.110e-03\n",
      "Epoch 36400, Train loss: 1.240e+03, Test loss: 2.038e+05, MSE(e): 1.045e-04, MSE(pi1): 8.400e-03, MSE(pi2): 8.996e-05, MSE(pi3): 1.112e-03\n",
      "Epoch 36500, Train loss: 1.243e+03, Test loss: 2.035e+05, MSE(e): 1.031e-04, MSE(pi1): 1.020e-02, MSE(pi2): 8.910e-05, MSE(pi3): 1.103e-03\n",
      "Epoch 36600, Train loss: 1.252e+03, Test loss: 2.031e+05, MSE(e): 1.058e-04, MSE(pi1): 8.471e-03, MSE(pi2): 9.051e-05, MSE(pi3): 1.098e-03\n",
      "Epoch 36700, Train loss: 1.345e+03, Test loss: 2.024e+05, MSE(e): 1.147e-04, MSE(pi1): 8.951e-03, MSE(pi2): 9.474e-05, MSE(pi3): 1.082e-03\n",
      "Epoch 36800, Train loss: 1.331e+03, Test loss: 2.054e+05, MSE(e): 1.123e-04, MSE(pi1): 9.704e-03, MSE(pi2): 9.317e-05, MSE(pi3): 1.109e-03\n",
      "Epoch 36900, Train loss: 1.203e+03, Test loss: 2.036e+05, MSE(e): 1.008e-04, MSE(pi1): 8.344e-03, MSE(pi2): 8.749e-05, MSE(pi3): 1.111e-03\n",
      "Epoch 37000, Train loss: 1.196e+03, Test loss: 2.035e+05, MSE(e): 1.003e-04, MSE(pi1): 8.112e-03, MSE(pi2): 8.713e-05, MSE(pi3): 1.113e-03\n",
      "Epoch 37100, Train loss: 1.191e+03, Test loss: 2.035e+05, MSE(e): 9.991e-05, MSE(pi1): 8.142e-03, MSE(pi2): 8.677e-05, MSE(pi3): 1.108e-03\n",
      "Epoch 37200, Train loss: 1.358e+03, Test loss: 2.041e+05, MSE(e): 1.118e-04, MSE(pi1): 1.306e-02, MSE(pi2): 9.258e-05, MSE(pi3): 1.094e-03\n",
      "Epoch 37300, Train loss: 1.202e+03, Test loss: 2.040e+05, MSE(e): 1.010e-04, MSE(pi1): 8.064e-03, MSE(pi2): 8.680e-05, MSE(pi3): 1.112e-03\n",
      "Epoch 37400, Train loss: 1.223e+03, Test loss: 2.031e+05, MSE(e): 1.029e-04, MSE(pi1): 8.482e-03, MSE(pi2): 8.809e-05, MSE(pi3): 1.086e-03\n",
      "Epoch 37500, Train loss: 1.186e+03, Test loss: 2.030e+05, MSE(e): 9.944e-05, MSE(pi1): 8.189e-03, MSE(pi2): 8.606e-05, MSE(pi3): 1.100e-03\n",
      "Epoch 37600, Train loss: 1.188e+03, Test loss: 2.033e+05, MSE(e): 9.882e-05, MSE(pi1): 8.816e-03, MSE(pi2): 8.566e-05, MSE(pi3): 1.114e-03\n",
      "Epoch 37700, Train loss: 1.206e+03, Test loss: 2.032e+05, MSE(e): 1.005e-04, MSE(pi1): 8.910e-03, MSE(pi2): 8.653e-05, MSE(pi3): 1.121e-03\n",
      "Epoch 37800, Train loss: 1.185e+03, Test loss: 2.029e+05, MSE(e): 9.915e-05, MSE(pi1): 8.455e-03, MSE(pi2): 8.568e-05, MSE(pi3): 1.086e-03\n",
      "Epoch 37900, Train loss: 1.255e+03, Test loss: 2.022e+05, MSE(e): 1.060e-04, MSE(pi1): 8.715e-03, MSE(pi2): 8.907e-05, MSE(pi3): 1.076e-03\n",
      "Epoch 38000, Train loss: 1.169e+03, Test loss: 2.036e+05, MSE(e): 9.741e-05, MSE(pi1): 8.494e-03, MSE(pi2): 8.404e-05, MSE(pi3): 1.100e-03\n",
      "Epoch 38100, Train loss: 1.166e+03, Test loss: 2.038e+05, MSE(e): 9.754e-05, MSE(pi1): 7.884e-03, MSE(pi2): 8.402e-05, MSE(pi3): 1.114e-03\n",
      "Epoch 38200, Train loss: 1.224e+03, Test loss: 2.040e+05, MSE(e): 1.026e-04, MSE(pi1): 8.796e-03, MSE(pi2): 8.590e-05, MSE(pi3): 1.105e-03\n",
      "Epoch 38300, Train loss: 1.241e+03, Test loss: 2.037e+05, MSE(e): 9.852e-05, MSE(pi1): 1.472e-02, MSE(pi2): 8.336e-05, MSE(pi3): 1.087e-03\n",
      "Epoch 38400, Train loss: 1.135e+03, Test loss: 2.031e+05, MSE(e): 9.465e-05, MSE(pi1): 7.769e-03, MSE(pi2): 8.239e-05, MSE(pi3): 1.106e-03\n",
      "Epoch 38500, Train loss: 1.148e+03, Test loss: 2.031e+05, MSE(e): 9.470e-05, MSE(pi1): 8.856e-03, MSE(pi2): 8.212e-05, MSE(pi3): 1.128e-03\n",
      "Epoch 38600, Train loss: 1.134e+03, Test loss: 2.028e+05, MSE(e): 9.391e-05, MSE(pi1): 8.637e-03, MSE(pi2): 8.175e-05, MSE(pi3): 1.082e-03\n",
      "Epoch 38700, Train loss: 1.141e+03, Test loss: 2.034e+05, MSE(e): 9.518e-05, MSE(pi1): 7.762e-03, MSE(pi2): 8.207e-05, MSE(pi3): 1.113e-03\n",
      "Epoch 38800, Train loss: 1.234e+03, Test loss: 2.027e+05, MSE(e): 1.015e-04, MSE(pi1): 1.063e-02, MSE(pi2): 8.634e-05, MSE(pi3): 1.126e-03\n",
      "Epoch 38900, Train loss: 1.124e+03, Test loss: 2.030e+05, MSE(e): 9.320e-05, MSE(pi1): 8.022e-03, MSE(pi2): 8.095e-05, MSE(pi3): 1.121e-03\n",
      "Epoch 39000, Train loss: 1.129e+03, Test loss: 2.032e+05, MSE(e): 9.409e-05, MSE(pi1): 7.634e-03, MSE(pi2): 8.118e-05, MSE(pi3): 1.114e-03\n",
      "Epoch 39100, Train loss: 1.116e+03, Test loss: 2.026e+05, MSE(e): 9.233e-05, MSE(pi1): 8.383e-03, MSE(pi2): 8.045e-05, MSE(pi3): 1.090e-03\n",
      "Epoch 39200, Train loss: 1.138e+03, Test loss: 2.023e+05, MSE(e): 9.436e-05, MSE(pi1): 8.258e-03, MSE(pi2): 8.125e-05, MSE(pi3): 1.120e-03\n",
      "Epoch 39300, Train loss: 1.183e+03, Test loss: 2.021e+05, MSE(e): 9.371e-05, MSE(pi1): 1.307e-02, MSE(pi2): 8.052e-05, MSE(pi3): 1.150e-03\n",
      "Epoch 39400, Train loss: 1.278e+03, Test loss: 2.038e+05, MSE(e): 1.085e-04, MSE(pi1): 7.886e-03, MSE(pi2): 8.709e-05, MSE(pi3): 1.135e-03\n",
      "Epoch 39500, Train loss: 1.102e+03, Test loss: 2.026e+05, MSE(e): 9.122e-05, MSE(pi1): 7.754e-03, MSE(pi2): 7.920e-05, MSE(pi3): 1.120e-03\n",
      "Epoch 39600, Train loss: 1.115e+03, Test loss: 2.025e+05, MSE(e): 9.107e-05, MSE(pi1): 9.083e-03, MSE(pi2): 7.915e-05, MSE(pi3): 1.130e-03\n",
      "Epoch 39700, Train loss: 1.299e+03, Test loss: 2.038e+05, MSE(e): 1.098e-04, MSE(pi1): 9.177e-03, MSE(pi2): 8.656e-05, MSE(pi3): 1.091e-03\n",
      "Epoch 39800, Train loss: 1.096e+03, Test loss: 2.015e+05, MSE(e): 9.049e-05, MSE(pi1): 8.196e-03, MSE(pi2): 7.868e-05, MSE(pi3): 1.090e-03\n",
      "Epoch 39900, Train loss: 1.104e+03, Test loss: 2.011e+05, MSE(e): 9.175e-05, MSE(pi1): 7.736e-03, MSE(pi2): 7.943e-05, MSE(pi3): 1.087e-03\n",
      "Epoch 40000, Train loss: 1.173e+03, Test loss: 2.015e+05, MSE(e): 9.486e-05, MSE(pi1): 1.063e-02, MSE(pi2): 7.991e-05, MSE(pi3): 1.179e-03\n",
      "Epoch 40100, Train loss: 1.067e+03, Test loss: 2.018e+05, MSE(e): 8.835e-05, MSE(pi1): 7.427e-03, MSE(pi2): 7.725e-05, MSE(pi3): 1.095e-03\n",
      "Epoch 40200, Train loss: 1.092e+03, Test loss: 2.012e+05, MSE(e): 9.018e-05, MSE(pi1): 8.120e-03, MSE(pi2): 7.798e-05, MSE(pi3): 1.091e-03\n",
      "Epoch 40300, Train loss: 1.060e+03, Test loss: 2.016e+05, MSE(e): 8.764e-05, MSE(pi1): 7.411e-03, MSE(pi2): 7.671e-05, MSE(pi3): 1.091e-03\n",
      "Epoch 40400, Train loss: 1.067e+03, Test loss: 2.011e+05, MSE(e): 8.832e-05, MSE(pi1): 7.572e-03, MSE(pi2): 7.704e-05, MSE(pi3): 1.083e-03\n",
      "Epoch 40500, Train loss: 1.066e+03, Test loss: 2.018e+05, MSE(e): 8.821e-05, MSE(pi1): 7.374e-03, MSE(pi2): 7.659e-05, MSE(pi3): 1.095e-03\n",
      "Epoch 40600, Train loss: 1.053e+03, Test loss: 2.010e+05, MSE(e): 8.704e-05, MSE(pi1): 7.381e-03, MSE(pi2): 7.614e-05, MSE(pi3): 1.087e-03\n",
      "Epoch 40700, Train loss: 1.145e+03, Test loss: 2.002e+05, MSE(e): 9.521e-05, MSE(pi1): 8.390e-03, MSE(pi2): 7.976e-05, MSE(pi3): 1.090e-03\n",
      "Epoch 40800, Train loss: 1.078e+03, Test loss: 2.009e+05, MSE(e): 8.788e-05, MSE(pi1): 8.982e-03, MSE(pi2): 7.629e-05, MSE(pi3): 1.097e-03\n",
      "Epoch 40900, Train loss: 1.059e+03, Test loss: 2.014e+05, MSE(e): 8.722e-05, MSE(pi1): 7.522e-03, MSE(pi2): 7.566e-05, MSE(pi3): 1.115e-03\n",
      "Epoch 41000, Train loss: 1.040e+03, Test loss: 2.009e+05, MSE(e): 8.563e-05, MSE(pi1): 7.338e-03, MSE(pi2): 7.500e-05, MSE(pi3): 1.098e-03\n",
      "Epoch 41100, Train loss: 1.036e+03, Test loss: 2.008e+05, MSE(e): 8.515e-05, MSE(pi1): 7.551e-03, MSE(pi2): 7.457e-05, MSE(pi3): 1.090e-03\n",
      "Epoch 41200, Train loss: 1.031e+03, Test loss: 2.007e+05, MSE(e): 8.479e-05, MSE(pi1): 7.287e-03, MSE(pi2): 7.432e-05, MSE(pi3): 1.099e-03\n",
      "Epoch 41300, Train loss: 1.025e+03, Test loss: 2.005e+05, MSE(e): 8.441e-05, MSE(pi1): 7.207e-03, MSE(pi2): 7.406e-05, MSE(pi3): 1.089e-03\n",
      "Epoch 41400, Train loss: 1.041e+03, Test loss: 2.002e+05, MSE(e): 8.497e-05, MSE(pi1): 8.445e-03, MSE(pi2): 7.432e-05, MSE(pi3): 1.067e-03\n",
      "Epoch 41500, Train loss: 1.135e+03, Test loss: 2.015e+05, MSE(e): 9.418e-05, MSE(pi1): 7.975e-03, MSE(pi2): 7.800e-05, MSE(pi3): 1.135e-03\n",
      "Epoch 41600, Train loss: 1.040e+03, Test loss: 1.998e+05, MSE(e): 8.573e-05, MSE(pi1): 7.375e-03, MSE(pi2): 7.446e-05, MSE(pi3): 1.084e-03\n",
      "Epoch 41700, Train loss: 1.100e+03, Test loss: 1.993e+05, MSE(e): 9.125e-05, MSE(pi1): 8.124e-03, MSE(pi2): 7.690e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 41800, Train loss: 1.013e+03, Test loss: 2.001e+05, MSE(e): 8.301e-05, MSE(pi1): 7.246e-03, MSE(pi2): 7.283e-05, MSE(pi3): 1.099e-03\n",
      "Epoch 41900, Train loss: 1.148e+03, Test loss: 1.985e+05, MSE(e): 9.333e-05, MSE(pi1): 1.034e-02, MSE(pi2): 7.792e-05, MSE(pi3): 1.117e-03\n",
      "Epoch 42000, Train loss: 1.033e+03, Test loss: 1.997e+05, MSE(e): 8.466e-05, MSE(pi1): 7.805e-03, MSE(pi2): 7.365e-05, MSE(pi3): 1.080e-03\n",
      "Epoch 42100, Train loss: 1.005e+03, Test loss: 1.995e+05, MSE(e): 8.215e-05, MSE(pi1): 7.671e-03, MSE(pi2): 7.218e-05, MSE(pi3): 1.070e-03\n",
      "Epoch 42200, Train loss: 9.969e+02, Test loss: 1.996e+05, MSE(e): 8.177e-05, MSE(pi1): 7.059e-03, MSE(pi2): 7.186e-05, MSE(pi3): 1.085e-03\n",
      "Epoch 42300, Train loss: 1.001e+03, Test loss: 1.992e+05, MSE(e): 8.178e-05, MSE(pi1): 7.320e-03, MSE(pi2): 7.177e-05, MSE(pi3): 1.095e-03\n",
      "Epoch 42400, Train loss: 1.012e+03, Test loss: 1.991e+05, MSE(e): 8.300e-05, MSE(pi1): 7.355e-03, MSE(pi2): 7.246e-05, MSE(pi3): 1.084e-03\n",
      "Epoch 42500, Train loss: 1.014e+03, Test loss: 1.988e+05, MSE(e): 8.193e-05, MSE(pi1): 8.996e-03, MSE(pi2): 7.156e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 42600, Train loss: 9.866e+02, Test loss: 1.992e+05, MSE(e): 8.069e-05, MSE(pi1): 7.218e-03, MSE(pi2): 7.101e-05, MSE(pi3): 1.074e-03\n",
      "Epoch 42700, Train loss: 9.838e+02, Test loss: 1.989e+05, MSE(e): 8.054e-05, MSE(pi1): 6.985e-03, MSE(pi2): 7.084e-05, MSE(pi3): 1.085e-03\n",
      "Epoch 42800, Train loss: 9.801e+02, Test loss: 1.988e+05, MSE(e): 8.014e-05, MSE(pi1): 6.990e-03, MSE(pi2): 7.054e-05, MSE(pi3): 1.088e-03\n",
      "Epoch 42900, Train loss: 9.758e+02, Test loss: 1.987e+05, MSE(e): 7.976e-05, MSE(pi1): 6.983e-03, MSE(pi2): 7.025e-05, MSE(pi3): 1.083e-03\n",
      "Epoch 43000, Train loss: 1.185e+03, Test loss: 2.004e+05, MSE(e): 9.808e-05, MSE(pi1): 9.051e-03, MSE(pi2): 7.840e-05, MSE(pi3): 1.134e-03\n",
      "Epoch 43100, Train loss: 1.026e+03, Test loss: 1.983e+05, MSE(e): 8.144e-05, MSE(pi1): 1.057e-02, MSE(pi2): 7.094e-05, MSE(pi3): 1.060e-03\n",
      "Epoch 43200, Train loss: 9.729e+02, Test loss: 1.987e+05, MSE(e): 7.951e-05, MSE(pi1): 6.875e-03, MSE(pi2): 6.976e-05, MSE(pi3): 1.090e-03\n",
      "Epoch 43300, Train loss: 9.766e+02, Test loss: 1.985e+05, MSE(e): 7.987e-05, MSE(pi1): 6.901e-03, MSE(pi2): 6.979e-05, MSE(pi3): 1.088e-03\n",
      "Epoch 43400, Train loss: 1.096e+03, Test loss: 1.995e+05, MSE(e): 8.669e-05, MSE(pi1): 1.131e-02, MSE(pi2): 7.325e-05, MSE(pi3): 1.158e-03\n",
      "Epoch 43500, Train loss: 9.849e+02, Test loss: 1.979e+05, MSE(e): 7.883e-05, MSE(pi1): 9.134e-03, MSE(pi2): 6.899e-05, MSE(pi3): 1.052e-03\n",
      "Epoch 43600, Train loss: 9.757e+02, Test loss: 1.976e+05, MSE(e): 7.970e-05, MSE(pi1): 7.162e-03, MSE(pi2): 6.976e-05, MSE(pi3): 1.071e-03\n",
      "Epoch 43700, Train loss: 1.012e+03, Test loss: 1.988e+05, MSE(e): 8.230e-05, MSE(pi1): 7.818e-03, MSE(pi2): 7.060e-05, MSE(pi3): 1.105e-03\n",
      "Epoch 43800, Train loss: 9.537e+02, Test loss: 1.975e+05, MSE(e): 7.770e-05, MSE(pi1): 6.882e-03, MSE(pi2): 6.853e-05, MSE(pi3): 1.078e-03\n",
      "Epoch 43900, Train loss: 9.486e+02, Test loss: 1.974e+05, MSE(e): 7.726e-05, MSE(pi1): 6.850e-03, MSE(pi2): 6.822e-05, MSE(pi3): 1.074e-03\n",
      "Epoch 44000, Train loss: 9.484e+02, Test loss: 1.973e+05, MSE(e): 7.717e-05, MSE(pi1): 6.823e-03, MSE(pi2): 6.808e-05, MSE(pi3): 1.084e-03\n",
      "Epoch 44100, Train loss: 9.415e+02, Test loss: 1.974e+05, MSE(e): 7.660e-05, MSE(pi1): 6.722e-03, MSE(pi2): 6.764e-05, MSE(pi3): 1.083e-03\n",
      "Epoch 44200, Train loss: 9.922e+02, Test loss: 1.969e+05, MSE(e): 7.803e-05, MSE(pi1): 1.017e-02, MSE(pi2): 6.827e-05, MSE(pi3): 1.102e-03\n",
      "Epoch 44300, Train loss: 9.385e+02, Test loss: 1.971e+05, MSE(e): 7.631e-05, MSE(pi1): 6.697e-03, MSE(pi2): 6.732e-05, MSE(pi3): 1.084e-03\n",
      "Epoch 44400, Train loss: 9.419e+02, Test loss: 1.973e+05, MSE(e): 7.660e-05, MSE(pi1): 6.693e-03, MSE(pi2): 6.730e-05, MSE(pi3): 1.089e-03\n",
      "Epoch 44500, Train loss: 9.853e+02, Test loss: 1.964e+05, MSE(e): 7.809e-05, MSE(pi1): 9.235e-03, MSE(pi2): 6.765e-05, MSE(pi3): 1.120e-03\n",
      "Epoch 44600, Train loss: 9.488e+02, Test loss: 1.968e+05, MSE(e): 7.628e-05, MSE(pi1): 7.674e-03, MSE(pi2): 6.692e-05, MSE(pi3): 1.091e-03\n",
      "Epoch 44700, Train loss: 9.263e+02, Test loss: 1.965e+05, MSE(e): 7.513e-05, MSE(pi1): 6.786e-03, MSE(pi2): 6.650e-05, MSE(pi3): 1.071e-03\n",
      "Epoch 44800, Train loss: 9.266e+02, Test loss: 1.967e+05, MSE(e): 7.506e-05, MSE(pi1): 6.772e-03, MSE(pi2): 6.628e-05, MSE(pi3): 1.081e-03\n",
      "Epoch 44900, Train loss: 9.288e+02, Test loss: 1.966e+05, MSE(e): 7.492e-05, MSE(pi1): 7.427e-03, MSE(pi2): 6.607e-05, MSE(pi3): 1.052e-03\n",
      "Epoch 45000, Train loss: 1.030e+03, Test loss: 1.960e+05, MSE(e): 8.038e-05, MSE(pi1): 1.162e-02, MSE(pi2): 6.911e-05, MSE(pi3): 1.095e-03\n",
      "Epoch 45100, Train loss: 9.176e+02, Test loss: 1.960e+05, MSE(e): 7.427e-05, MSE(pi1): 6.649e-03, MSE(pi2): 6.575e-05, MSE(pi3): 1.083e-03\n",
      "Epoch 45200, Train loss: 9.248e+02, Test loss: 1.961e+05, MSE(e): 7.425e-05, MSE(pi1): 7.269e-03, MSE(pi2): 6.563e-05, MSE(pi3): 1.095e-03\n",
      "Epoch 45300, Train loss: 9.140e+02, Test loss: 1.958e+05, MSE(e): 7.392e-05, MSE(pi1): 6.607e-03, MSE(pi2): 6.546e-05, MSE(pi3): 1.087e-03\n",
      "Epoch 45400, Train loss: 9.090e+02, Test loss: 1.959e+05, MSE(e): 7.354e-05, MSE(pi1): 6.542e-03, MSE(pi2): 6.510e-05, MSE(pi3): 1.081e-03\n",
      "Epoch 45500, Train loss: 1.025e+03, Test loss: 1.968e+05, MSE(e): 8.505e-05, MSE(pi1): 6.560e-03, MSE(pi2): 6.989e-05, MSE(pi3): 1.093e-03\n",
      "Epoch 45600, Train loss: 9.720e+02, Test loss: 1.956e+05, MSE(e): 7.599e-05, MSE(pi1): 1.065e-02, MSE(pi2): 6.604e-05, MSE(pi3): 1.056e-03\n",
      "Epoch 45700, Train loss: 9.187e+02, Test loss: 1.958e+05, MSE(e): 7.443e-05, MSE(pi1): 6.542e-03, MSE(pi2): 6.517e-05, MSE(pi3): 1.089e-03\n",
      "Epoch 45800, Train loss: 9.149e+02, Test loss: 1.958e+05, MSE(e): 7.417e-05, MSE(pi1): 6.515e-03, MSE(pi2): 6.499e-05, MSE(pi3): 1.080e-03\n",
      "Epoch 45900, Train loss: 9.907e+02, Test loss: 1.965e+05, MSE(e): 7.799e-05, MSE(pi1): 1.011e-02, MSE(pi2): 6.723e-05, MSE(pi3): 1.096e-03\n",
      "Epoch 46000, Train loss: 9.164e+02, Test loss: 1.951e+05, MSE(e): 7.259e-05, MSE(pi1): 7.944e-03, MSE(pi2): 6.405e-05, MSE(pi3): 1.110e-03\n",
      "Epoch 46100, Train loss: 8.906e+02, Test loss: 1.949e+05, MSE(e): 7.183e-05, MSE(pi1): 6.520e-03, MSE(pi2): 6.380e-05, MSE(pi3): 1.071e-03\n",
      "Epoch 46200, Train loss: 8.954e+02, Test loss: 1.947e+05, MSE(e): 7.184e-05, MSE(pi1): 7.083e-03, MSE(pi2): 6.375e-05, MSE(pi3): 1.061e-03\n",
      "Epoch 46300, Train loss: 9.134e+02, Test loss: 1.948e+05, MSE(e): 7.203e-05, MSE(pi1): 8.188e-03, MSE(pi2): 6.353e-05, MSE(pi3): 1.112e-03\n",
      "Epoch 46400, Train loss: 8.861e+02, Test loss: 1.942e+05, MSE(e): 7.140e-05, MSE(pi1): 6.486e-03, MSE(pi2): 6.343e-05, MSE(pi3): 1.072e-03\n",
      "Epoch 46500, Train loss: 8.870e+02, Test loss: 1.944e+05, MSE(e): 7.123e-05, MSE(pi1): 6.792e-03, MSE(pi2): 6.326e-05, MSE(pi3): 1.067e-03\n",
      "Epoch 46600, Train loss: 8.792e+02, Test loss: 1.943e+05, MSE(e): 7.077e-05, MSE(pi1): 6.428e-03, MSE(pi2): 6.294e-05, MSE(pi3): 1.072e-03\n",
      "Epoch 46700, Train loss: 8.788e+02, Test loss: 1.943e+05, MSE(e): 7.062e-05, MSE(pi1): 6.554e-03, MSE(pi2): 6.275e-05, MSE(pi3): 1.071e-03\n",
      "Epoch 46800, Train loss: 9.061e+02, Test loss: 1.939e+05, MSE(e): 7.337e-05, MSE(pi1): 6.436e-03, MSE(pi2): 6.398e-05, MSE(pi3): 1.080e-03\n",
      "Epoch 46900, Train loss: 8.995e+02, Test loss: 1.939e+05, MSE(e): 7.068e-05, MSE(pi1): 8.717e-03, MSE(pi2): 6.256e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 47000, Train loss: 8.887e+02, Test loss: 1.940e+05, MSE(e): 7.154e-05, MSE(pi1): 6.642e-03, MSE(pi2): 6.282e-05, MSE(pi3): 1.069e-03\n",
      "Epoch 47100, Train loss: 8.798e+02, Test loss: 1.941e+05, MSE(e): 7.074e-05, MSE(pi1): 6.604e-03, MSE(pi2): 6.235e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 47200, Train loss: 8.664e+02, Test loss: 1.936e+05, MSE(e): 6.954e-05, MSE(pi1): 6.407e-03, MSE(pi2): 6.193e-05, MSE(pi3): 1.069e-03\n",
      "Epoch 47300, Train loss: 8.687e+02, Test loss: 1.929e+05, MSE(e): 6.964e-05, MSE(pi1): 6.443e-03, MSE(pi2): 6.199e-05, MSE(pi3): 1.078e-03\n",
      "Epoch 47400, Train loss: 9.166e+02, Test loss: 1.930e+05, MSE(e): 7.267e-05, MSE(pi1): 8.137e-03, MSE(pi2): 6.423e-05, MSE(pi3): 1.084e-03\n",
      "Epoch 47500, Train loss: 8.656e+02, Test loss: 1.932e+05, MSE(e): 6.953e-05, MSE(pi1): 6.371e-03, MSE(pi2): 6.177e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 47600, Train loss: 9.014e+02, Test loss: 1.927e+05, MSE(e): 7.236e-05, MSE(pi1): 7.115e-03, MSE(pi2): 6.410e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 47700, Train loss: 8.557e+02, Test loss: 1.930e+05, MSE(e): 6.857e-05, MSE(pi1): 6.320e-03, MSE(pi2): 6.115e-05, MSE(pi3): 1.067e-03\n",
      "Epoch 47800, Train loss: 8.818e+02, Test loss: 1.928e+05, MSE(e): 7.112e-05, MSE(pi1): 6.348e-03, MSE(pi2): 6.253e-05, MSE(pi3): 1.070e-03\n",
      "Epoch 47900, Train loss: 9.126e+02, Test loss: 1.936e+05, MSE(e): 7.097e-05, MSE(pi1): 9.329e-03, MSE(pi2): 6.158e-05, MSE(pi3): 1.096e-03\n",
      "Epoch 48000, Train loss: 8.674e+02, Test loss: 1.925e+05, MSE(e): 6.846e-05, MSE(pi1): 7.817e-03, MSE(pi2): 6.084e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 48100, Train loss: 8.543e+02, Test loss: 1.926e+05, MSE(e): 6.806e-05, MSE(pi1): 6.646e-03, MSE(pi2): 6.062e-05, MSE(pi3): 1.071e-03\n",
      "Epoch 48200, Train loss: 8.529e+02, Test loss: 1.927e+05, MSE(e): 6.771e-05, MSE(pi1): 7.001e-03, MSE(pi2): 6.035e-05, MSE(pi3): 1.058e-03\n",
      "Epoch 48300, Train loss: 8.489e+02, Test loss: 1.921e+05, MSE(e): 6.770e-05, MSE(pi1): 6.580e-03, MSE(pi2): 6.041e-05, MSE(pi3): 1.060e-03\n",
      "Epoch 48400, Train loss: 9.267e+02, Test loss: 1.933e+05, MSE(e): 7.473e-05, MSE(pi1): 7.041e-03, MSE(pi2): 6.351e-05, MSE(pi3): 1.090e-03\n",
      "Epoch 48500, Train loss: 9.332e+02, Test loss: 1.932e+05, MSE(e): 7.618e-05, MSE(pi1): 6.180e-03, MSE(pi2): 6.376e-05, MSE(pi3): 1.096e-03\n",
      "Epoch 48600, Train loss: 9.231e+02, Test loss: 1.933e+05, MSE(e): 7.514e-05, MSE(pi1): 6.246e-03, MSE(pi2): 6.304e-05, MSE(pi3): 1.092e-03\n",
      "Epoch 48700, Train loss: 8.446e+02, Test loss: 1.924e+05, MSE(e): 6.745e-05, MSE(pi1): 6.178e-03, MSE(pi2): 5.980e-05, MSE(pi3): 1.082e-03\n",
      "Epoch 48800, Train loss: 8.794e+02, Test loss: 1.919e+05, MSE(e): 6.774e-05, MSE(pi1): 9.061e-03, MSE(pi2): 5.978e-05, MSE(pi3): 1.113e-03\n",
      "Epoch 48900, Train loss: 8.313e+02, Test loss: 1.918e+05, MSE(e): 6.626e-05, MSE(pi1): 6.223e-03, MSE(pi2): 5.921e-05, MSE(pi3): 1.064e-03\n",
      "Epoch 49000, Train loss: 8.311e+02, Test loss: 1.917e+05, MSE(e): 6.625e-05, MSE(pi1): 6.154e-03, MSE(pi2): 5.917e-05, MSE(pi3): 1.070e-03\n",
      "Epoch 49100, Train loss: 8.341e+02, Test loss: 1.915e+05, MSE(e): 6.608e-05, MSE(pi1): 6.512e-03, MSE(pi2): 5.896e-05, MSE(pi3): 1.081e-03\n",
      "Epoch 49200, Train loss: 8.255e+02, Test loss: 1.915e+05, MSE(e): 6.574e-05, MSE(pi1): 6.113e-03, MSE(pi2): 5.878e-05, MSE(pi3): 1.070e-03\n",
      "Epoch 49300, Train loss: 8.462e+02, Test loss: 1.918e+05, MSE(e): 6.778e-05, MSE(pi1): 6.058e-03, MSE(pi2): 5.949e-05, MSE(pi3): 1.077e-03\n",
      "Epoch 49400, Train loss: 8.218e+02, Test loss: 1.912e+05, MSE(e): 6.539e-05, MSE(pi1): 6.168e-03, MSE(pi2): 5.853e-05, MSE(pi3): 1.062e-03\n",
      "Epoch 49500, Train loss: 8.507e+02, Test loss: 1.909e+05, MSE(e): 6.697e-05, MSE(pi1): 7.039e-03, MSE(pi2): 5.906e-05, MSE(pi3): 1.105e-03\n",
      "Epoch 49600, Train loss: 8.212e+02, Test loss: 1.910e+05, MSE(e): 6.533e-05, MSE(pi1): 6.119e-03, MSE(pi2): 5.844e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 49700, Train loss: 8.184e+02, Test loss: 1.909e+05, MSE(e): 6.489e-05, MSE(pi1): 6.388e-03, MSE(pi2): 5.809e-05, MSE(pi3): 1.056e-03\n",
      "Epoch 49800, Train loss: 8.534e+02, Test loss: 1.903e+05, MSE(e): 6.767e-05, MSE(pi1): 6.983e-03, MSE(pi2): 5.930e-05, MSE(pi3): 1.067e-03\n",
      "Epoch 49900, Train loss: 9.858e+02, Test loss: 1.897e+05, MSE(e): 8.103e-05, MSE(pi1): 7.158e-03, MSE(pi2): 6.607e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 50000, Train loss: 8.618e+02, Test loss: 1.903e+05, MSE(e): 6.605e-05, MSE(pi1): 8.933e-03, MSE(pi2): 5.819e-05, MSE(pi3): 1.119e-03\n",
      "Epoch 50100, Train loss: 8.530e+02, Test loss: 1.907e+05, MSE(e): 6.802e-05, MSE(pi1): 6.641e-03, MSE(pi2): 5.956e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 50200, Train loss: 8.896e+02, Test loss: 1.906e+05, MSE(e): 6.612e-05, MSE(pi1): 1.168e-02, MSE(pi2): 5.805e-05, MSE(pi3): 1.115e-03\n",
      "Epoch 50300, Train loss: 8.076e+02, Test loss: 1.903e+05, MSE(e): 6.406e-05, MSE(pi1): 6.046e-03, MSE(pi2): 5.740e-05, MSE(pi3): 1.064e-03\n",
      "Epoch 50400, Train loss: 8.078e+02, Test loss: 1.902e+05, MSE(e): 6.385e-05, MSE(pi1): 6.334e-03, MSE(pi2): 5.714e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 50500, Train loss: 8.045e+02, Test loss: 1.901e+05, MSE(e): 6.361e-05, MSE(pi1): 6.275e-03, MSE(pi2): 5.695e-05, MSE(pi3): 1.056e-03\n",
      "Epoch 50600, Train loss: 8.022e+02, Test loss: 1.898e+05, MSE(e): 6.356e-05, MSE(pi1): 6.046e-03, MSE(pi2): 5.696e-05, MSE(pi3): 1.062e-03\n",
      "Epoch 50700, Train loss: 8.645e+02, Test loss: 1.899e+05, MSE(e): 6.484e-05, MSE(pi1): 1.128e-02, MSE(pi2): 5.706e-05, MSE(pi3): 1.033e-03\n",
      "Epoch 50800, Train loss: 8.114e+02, Test loss: 1.896e+05, MSE(e): 6.339e-05, MSE(pi1): 7.119e-03, MSE(pi2): 5.668e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 50900, Train loss: 8.394e+02, Test loss: 1.899e+05, MSE(e): 6.702e-05, MSE(pi1): 5.984e-03, MSE(pi2): 5.818e-05, MSE(pi3): 1.092e-03\n",
      "Epoch 51000, Train loss: 8.610e+02, Test loss: 1.893e+05, MSE(e): 6.803e-05, MSE(pi1): 7.363e-03, MSE(pi2): 5.872e-05, MSE(pi3): 1.070e-03\n",
      "Epoch 51100, Train loss: 8.036e+02, Test loss: 1.897e+05, MSE(e): 6.335e-05, MSE(pi1): 6.156e-03, MSE(pi2): 5.664e-05, MSE(pi3): 1.085e-03\n",
      "Epoch 51200, Train loss: 1.049e+03, Test loss: 1.884e+05, MSE(e): 8.682e-05, MSE(pi1): 7.561e-03, MSE(pi2): 6.793e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 51300, Train loss: 8.153e+02, Test loss: 1.900e+05, MSE(e): 6.458e-05, MSE(pi1): 5.893e-03, MSE(pi2): 5.682e-05, MSE(pi3): 1.105e-03\n",
      "Epoch 51400, Train loss: 8.687e+02, Test loss: 1.883e+05, MSE(e): 6.867e-05, MSE(pi1): 7.385e-03, MSE(pi2): 5.928e-05, MSE(pi3): 1.081e-03\n",
      "Epoch 51500, Train loss: 7.862e+02, Test loss: 1.890e+05, MSE(e): 6.199e-05, MSE(pi1): 6.108e-03, MSE(pi2): 5.570e-05, MSE(pi3): 1.052e-03\n",
      "Epoch 51600, Train loss: 7.844e+02, Test loss: 1.890e+05, MSE(e): 6.176e-05, MSE(pi1): 5.961e-03, MSE(pi2): 5.549e-05, MSE(pi3): 1.071e-03\n",
      "Epoch 51700, Train loss: 7.886e+02, Test loss: 1.888e+05, MSE(e): 6.205e-05, MSE(pi1): 6.010e-03, MSE(pi2): 5.567e-05, MSE(pi3): 1.079e-03\n",
      "Epoch 51800, Train loss: 7.816e+02, Test loss: 1.889e+05, MSE(e): 6.157e-05, MSE(pi1): 5.935e-03, MSE(pi2): 5.525e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 51900, Train loss: 7.825e+02, Test loss: 1.890e+05, MSE(e): 6.168e-05, MSE(pi1): 5.892e-03, MSE(pi2): 5.526e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 52000, Train loss: 7.853e+02, Test loss: 1.890e+05, MSE(e): 6.197e-05, MSE(pi1): 5.885e-03, MSE(pi2): 5.523e-05, MSE(pi3): 1.067e-03\n",
      "Epoch 52100, Train loss: 7.908e+02, Test loss: 1.885e+05, MSE(e): 6.153e-05, MSE(pi1): 6.670e-03, MSE(pi2): 5.503e-05, MSE(pi3): 1.088e-03\n",
      "Epoch 52200, Train loss: 7.809e+02, Test loss: 1.887e+05, MSE(e): 6.157e-05, MSE(pi1): 5.830e-03, MSE(pi2): 5.501e-05, MSE(pi3): 1.069e-03\n",
      "Epoch 52300, Train loss: 8.512e+02, Test loss: 1.880e+05, MSE(e): 6.402e-05, MSE(pi1): 1.069e-02, MSE(pi2): 5.628e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 52400, Train loss: 7.699e+02, Test loss: 1.882e+05, MSE(e): 6.052e-05, MSE(pi1): 5.840e-03, MSE(pi2): 5.449e-05, MSE(pi3): 1.062e-03\n",
      "Epoch 52500, Train loss: 7.750e+02, Test loss: 1.879e+05, MSE(e): 6.100e-05, MSE(pi1): 5.782e-03, MSE(pi2): 5.471e-05, MSE(pi3): 1.071e-03\n",
      "Epoch 52600, Train loss: 7.713e+02, Test loss: 1.884e+05, MSE(e): 6.059e-05, MSE(pi1): 5.973e-03, MSE(pi2): 5.430e-05, MSE(pi3): 1.056e-03\n",
      "Epoch 52700, Train loss: 9.733e+02, Test loss: 1.866e+05, MSE(e): 8.044e-05, MSE(pi1): 6.575e-03, MSE(pi2): 6.393e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 52800, Train loss: 1.135e+03, Test loss: 1.860e+05, MSE(e): 9.615e-05, MSE(pi1): 7.062e-03, MSE(pi2): 7.155e-05, MSE(pi3): 1.024e-03\n",
      "Epoch 52900, Train loss: 8.077e+02, Test loss: 1.884e+05, MSE(e): 6.410e-05, MSE(pi1): 6.069e-03, MSE(pi2): 5.574e-05, MSE(pi3): 1.060e-03\n",
      "Epoch 53000, Train loss: 8.605e+02, Test loss: 1.885e+05, MSE(e): 6.927e-05, MSE(pi1): 5.904e-03, MSE(pi2): 5.759e-05, MSE(pi3): 1.087e-03\n",
      "Epoch 53100, Train loss: 7.850e+02, Test loss: 1.873e+05, MSE(e): 6.096e-05, MSE(pi1): 7.101e-03, MSE(pi2): 5.403e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 53200, Train loss: 7.666e+02, Test loss: 1.879e+05, MSE(e): 6.019e-05, MSE(pi1): 5.866e-03, MSE(pi2): 5.376e-05, MSE(pi3): 1.060e-03\n",
      "Epoch 53300, Train loss: 7.834e+02, Test loss: 1.870e+05, MSE(e): 6.041e-05, MSE(pi1): 7.448e-03, MSE(pi2): 5.411e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 53400, Train loss: 7.779e+02, Test loss: 1.878e+05, MSE(e): 6.138e-05, MSE(pi1): 5.764e-03, MSE(pi2): 5.414e-05, MSE(pi3): 1.064e-03\n",
      "Epoch 53500, Train loss: 8.378e+02, Test loss: 1.863e+05, MSE(e): 6.704e-05, MSE(pi1): 6.412e-03, MSE(pi2): 5.731e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 53600, Train loss: 8.016e+02, Test loss: 1.861e+05, MSE(e): 6.357e-05, MSE(pi1): 5.974e-03, MSE(pi2): 5.573e-05, MSE(pi3): 1.061e-03\n",
      "Epoch 53700, Train loss: 7.499e+02, Test loss: 1.870e+05, MSE(e): 5.866e-05, MSE(pi1): 5.740e-03, MSE(pi2): 5.294e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 53800, Train loss: 7.523e+02, Test loss: 1.867e+05, MSE(e): 5.890e-05, MSE(pi1): 5.757e-03, MSE(pi2): 5.315e-05, MSE(pi3): 1.056e-03\n",
      "Epoch 53900, Train loss: 7.501e+02, Test loss: 1.869e+05, MSE(e): 5.847e-05, MSE(pi1): 5.920e-03, MSE(pi2): 5.275e-05, MSE(pi3): 1.061e-03\n",
      "Epoch 54000, Train loss: 7.661e+02, Test loss: 1.865e+05, MSE(e): 6.029e-05, MSE(pi1): 5.782e-03, MSE(pi2): 5.368e-05, MSE(pi3): 1.053e-03\n",
      "Epoch 54100, Train loss: 7.578e+02, Test loss: 1.865e+05, MSE(e): 5.877e-05, MSE(pi1): 6.394e-03, MSE(pi2): 5.278e-05, MSE(pi3): 1.061e-03\n",
      "Epoch 54200, Train loss: 7.452e+02, Test loss: 1.865e+05, MSE(e): 5.812e-05, MSE(pi1): 5.944e-03, MSE(pi2): 5.247e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 54300, Train loss: 7.640e+02, Test loss: 1.867e+05, MSE(e): 5.902e-05, MSE(pi1): 6.540e-03, MSE(pi2): 5.290e-05, MSE(pi3): 1.083e-03\n",
      "Epoch 54400, Train loss: 7.532e+02, Test loss: 1.862e+05, MSE(e): 5.843e-05, MSE(pi1): 6.387e-03, MSE(pi2): 5.267e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 54500, Train loss: 7.415e+02, Test loss: 1.864e+05, MSE(e): 5.772e-05, MSE(pi1): 5.803e-03, MSE(pi2): 5.213e-05, MSE(pi3): 1.062e-03\n",
      "Epoch 54600, Train loss: 7.382e+02, Test loss: 1.861e+05, MSE(e): 5.756e-05, MSE(pi1): 5.701e-03, MSE(pi2): 5.203e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 54700, Train loss: 7.484e+02, Test loss: 1.859e+05, MSE(e): 5.840e-05, MSE(pi1): 5.926e-03, MSE(pi2): 5.243e-05, MSE(pi3): 1.051e-03\n",
      "Epoch 54800, Train loss: 7.361e+02, Test loss: 1.860e+05, MSE(e): 5.726e-05, MSE(pi1): 5.744e-03, MSE(pi2): 5.175e-05, MSE(pi3): 1.060e-03\n",
      "Epoch 54900, Train loss: 7.379e+02, Test loss: 1.858e+05, MSE(e): 5.753e-05, MSE(pi1): 5.668e-03, MSE(pi2): 5.186e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 55000, Train loss: 7.392e+02, Test loss: 1.857e+05, MSE(e): 5.769e-05, MSE(pi1): 5.682e-03, MSE(pi2): 5.206e-05, MSE(pi3): 1.054e-03\n",
      "Epoch 55100, Train loss: 7.448e+02, Test loss: 1.863e+05, MSE(e): 5.813e-05, MSE(pi1): 5.615e-03, MSE(pi2): 5.192e-05, MSE(pi3): 1.073e-03\n",
      "Epoch 55200, Train loss: 7.612e+02, Test loss: 1.856e+05, MSE(e): 5.918e-05, MSE(pi1): 6.353e-03, MSE(pi2): 5.279e-05, MSE(pi3): 1.058e-03\n",
      "Epoch 55300, Train loss: 7.299e+02, Test loss: 1.856e+05, MSE(e): 5.662e-05, MSE(pi1): 5.647e-03, MSE(pi2): 5.119e-05, MSE(pi3): 1.072e-03\n",
      "Epoch 55400, Train loss: 7.379e+02, Test loss: 1.853e+05, MSE(e): 5.717e-05, MSE(pi1): 6.038e-03, MSE(pi2): 5.143e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 55500, Train loss: 7.255e+02, Test loss: 1.856e+05, MSE(e): 5.636e-05, MSE(pi1): 5.654e-03, MSE(pi2): 5.101e-05, MSE(pi3): 1.053e-03\n",
      "Epoch 55600, Train loss: 8.358e+02, Test loss: 1.860e+05, MSE(e): 6.691e-05, MSE(pi1): 5.850e-03, MSE(pi2): 5.544e-05, MSE(pi3): 1.081e-03\n",
      "Epoch 55700, Train loss: 7.510e+02, Test loss: 1.856e+05, MSE(e): 5.805e-05, MSE(pi1): 6.723e-03, MSE(pi2): 5.151e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 55800, Train loss: 7.954e+02, Test loss: 1.847e+05, MSE(e): 5.894e-05, MSE(pi1): 9.943e-03, MSE(pi2): 5.202e-05, MSE(pi3): 1.065e-03\n",
      "Epoch 55900, Train loss: 7.247e+02, Test loss: 1.854e+05, MSE(e): 5.607e-05, MSE(pi1): 5.759e-03, MSE(pi2): 5.061e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 56000, Train loss: 7.240e+02, Test loss: 1.852e+05, MSE(e): 5.584e-05, MSE(pi1): 5.847e-03, MSE(pi2): 5.048e-05, MSE(pi3): 1.071e-03\n",
      "Epoch 56100, Train loss: 7.529e+02, Test loss: 1.849e+05, MSE(e): 5.755e-05, MSE(pi1): 6.993e-03, MSE(pi2): 5.129e-05, MSE(pi3): 1.074e-03\n",
      "Epoch 56200, Train loss: 7.193e+02, Test loss: 1.850e+05, MSE(e): 5.567e-05, MSE(pi1): 5.621e-03, MSE(pi2): 5.030e-05, MSE(pi3): 1.064e-03\n",
      "Epoch 56300, Train loss: 7.153e+02, Test loss: 1.848e+05, MSE(e): 5.539e-05, MSE(pi1): 5.601e-03, MSE(pi2): 5.020e-05, MSE(pi3): 1.053e-03\n",
      "Epoch 56400, Train loss: 7.148e+02, Test loss: 1.849e+05, MSE(e): 5.530e-05, MSE(pi1): 5.553e-03, MSE(pi2): 5.006e-05, MSE(pi3): 1.062e-03\n",
      "Epoch 56500, Train loss: 7.173e+02, Test loss: 1.848e+05, MSE(e): 5.557e-05, MSE(pi1): 5.622e-03, MSE(pi2): 5.012e-05, MSE(pi3): 1.054e-03\n",
      "Epoch 56600, Train loss: 7.129e+02, Test loss: 1.848e+05, MSE(e): 5.514e-05, MSE(pi1): 5.550e-03, MSE(pi2): 4.987e-05, MSE(pi3): 1.060e-03\n",
      "Epoch 56700, Train loss: 7.097e+02, Test loss: 1.846e+05, MSE(e): 5.487e-05, MSE(pi1): 5.525e-03, MSE(pi2): 4.974e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 56800, Train loss: 7.392e+02, Test loss: 1.840e+05, MSE(e): 5.764e-05, MSE(pi1): 5.829e-03, MSE(pi2): 5.119e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 56900, Train loss: 7.246e+02, Test loss: 1.848e+05, MSE(e): 5.629e-05, MSE(pi1): 5.639e-03, MSE(pi2): 5.013e-05, MSE(pi3): 1.053e-03\n",
      "Epoch 57000, Train loss: 9.040e+02, Test loss: 1.857e+05, MSE(e): 7.315e-05, MSE(pi1): 6.316e-03, MSE(pi2): 5.723e-05, MSE(pi3): 1.092e-03\n",
      "Epoch 57100, Train loss: 7.142e+02, Test loss: 1.845e+05, MSE(e): 5.516e-05, MSE(pi1): 5.653e-03, MSE(pi2): 4.959e-05, MSE(pi3): 1.060e-03\n",
      "Epoch 57200, Train loss: 7.461e+02, Test loss: 1.844e+05, MSE(e): 5.617e-05, MSE(pi1): 7.718e-03, MSE(pi2): 5.034e-05, MSE(pi3): 1.072e-03\n",
      "Epoch 57300, Train loss: 7.157e+02, Test loss: 1.846e+05, MSE(e): 5.546e-05, MSE(pi1): 5.463e-03, MSE(pi2): 4.963e-05, MSE(pi3): 1.064e-03\n",
      "Epoch 57400, Train loss: 7.203e+02, Test loss: 1.837e+05, MSE(e): 5.580e-05, MSE(pi1): 5.804e-03, MSE(pi2): 5.003e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 57500, Train loss: 1.129e+03, Test loss: 1.822e+05, MSE(e): 9.560e-05, MSE(pi1): 6.821e-03, MSE(pi2): 6.774e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 57600, Train loss: 7.385e+02, Test loss: 1.840e+05, MSE(e): 5.508e-05, MSE(pi1): 8.290e-03, MSE(pi2): 4.926e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 57700, Train loss: 6.987e+02, Test loss: 1.840e+05, MSE(e): 5.384e-05, MSE(pi1): 5.458e-03, MSE(pi2): 4.880e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 57800, Train loss: 6.976e+02, Test loss: 1.838e+05, MSE(e): 5.365e-05, MSE(pi1): 5.514e-03, MSE(pi2): 4.870e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 57900, Train loss: 6.955e+02, Test loss: 1.838e+05, MSE(e): 5.353e-05, MSE(pi1): 5.445e-03, MSE(pi2): 4.860e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 58000, Train loss: 7.271e+02, Test loss: 1.835e+05, MSE(e): 5.571e-05, MSE(pi1): 6.617e-03, MSE(pi2): 4.981e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 58100, Train loss: 1.184e+03, Test loss: 1.823e+05, MSE(e): 9.369e-05, MSE(pi1): 1.343e-02, MSE(pi2): 6.567e-05, MSE(pi3): 1.125e-03\n",
      "Epoch 58200, Train loss: 7.305e+02, Test loss: 1.834e+05, MSE(e): 5.403e-05, MSE(pi1): 8.447e-03, MSE(pi2): 4.858e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 58300, Train loss: 6.942e+02, Test loss: 1.836e+05, MSE(e): 5.344e-05, MSE(pi1): 5.415e-03, MSE(pi2): 4.835e-05, MSE(pi3): 1.056e-03\n",
      "Epoch 58400, Train loss: 7.113e+02, Test loss: 1.835e+05, MSE(e): 5.346e-05, MSE(pi1): 6.772e-03, MSE(pi2): 4.822e-05, MSE(pi3): 1.089e-03\n",
      "Epoch 58500, Train loss: 6.893e+02, Test loss: 1.832e+05, MSE(e): 5.295e-05, MSE(pi1): 5.507e-03, MSE(pi2): 4.814e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 58600, Train loss: 7.023e+02, Test loss: 1.835e+05, MSE(e): 5.350e-05, MSE(pi1): 5.948e-03, MSE(pi2): 4.832e-05, MSE(pi3): 1.078e-03\n",
      "Epoch 58700, Train loss: 6.863e+02, Test loss: 1.831e+05, MSE(e): 5.269e-05, MSE(pi1): 5.426e-03, MSE(pi2): 4.792e-05, MSE(pi3): 1.051e-03\n",
      "Epoch 58800, Train loss: 7.541e+02, Test loss: 1.832e+05, MSE(e): 5.389e-05, MSE(pi1): 1.135e-02, MSE(pi2): 4.806e-05, MSE(pi3): 1.016e-03\n",
      "Epoch 58900, Train loss: 7.064e+02, Test loss: 1.826e+05, MSE(e): 5.408e-05, MSE(pi1): 6.207e-03, MSE(pi2): 4.876e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 59000, Train loss: 7.119e+02, Test loss: 1.832e+05, MSE(e): 5.404e-05, MSE(pi1): 6.296e-03, MSE(pi2): 4.876e-05, MSE(pi3): 1.085e-03\n",
      "Epoch 59100, Train loss: 7.974e+02, Test loss: 1.819e+05, MSE(e): 5.968e-05, MSE(pi1): 9.987e-03, MSE(pi2): 5.139e-05, MSE(pi3): 1.006e-03\n",
      "Epoch 59200, Train loss: 7.103e+02, Test loss: 1.824e+05, MSE(e): 5.469e-05, MSE(pi1): 5.942e-03, MSE(pi2): 4.916e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 59300, Train loss: 8.193e+02, Test loss: 1.814e+05, MSE(e): 6.560e-05, MSE(pi1): 5.878e-03, MSE(pi2): 5.354e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 59400, Train loss: 6.948e+02, Test loss: 1.823e+05, MSE(e): 5.292e-05, MSE(pi1): 6.082e-03, MSE(pi2): 4.788e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 59500, Train loss: 6.998e+02, Test loss: 1.829e+05, MSE(e): 5.383e-05, MSE(pi1): 5.557e-03, MSE(pi2): 4.861e-05, MSE(pi3): 1.058e-03\n",
      "Epoch 59600, Train loss: 7.146e+02, Test loss: 1.826e+05, MSE(e): 5.256e-05, MSE(pi1): 7.904e-03, MSE(pi2): 4.720e-05, MSE(pi3): 1.099e-03\n",
      "Epoch 59700, Train loss: 6.771e+02, Test loss: 1.826e+05, MSE(e): 5.179e-05, MSE(pi1): 5.339e-03, MSE(pi2): 4.703e-05, MSE(pi3): 1.058e-03\n",
      "Epoch 59800, Train loss: 7.375e+02, Test loss: 1.824e+05, MSE(e): 5.282e-05, MSE(pi1): 1.027e-02, MSE(pi2): 4.717e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 59900, Train loss: 6.796e+02, Test loss: 1.827e+05, MSE(e): 5.204e-05, MSE(pi1): 5.387e-03, MSE(pi2): 4.728e-05, MSE(pi3): 1.053e-03\n",
      "Epoch 60000, Train loss: 7.339e+02, Test loss: 1.819e+05, MSE(e): 5.511e-05, MSE(pi1): 7.744e-03, MSE(pi2): 4.852e-05, MSE(pi3): 1.053e-03\n",
      "Epoch 60100, Train loss: 6.758e+02, Test loss: 1.824e+05, MSE(e): 5.149e-05, MSE(pi1): 5.549e-03, MSE(pi2): 4.671e-05, MSE(pi3): 1.054e-03\n",
      "Epoch 60200, Train loss: 6.925e+02, Test loss: 1.819e+05, MSE(e): 5.232e-05, MSE(pi1): 5.743e-03, MSE(pi2): 4.705e-05, MSE(pi3): 1.118e-03\n",
      "Epoch 60300, Train loss: 9.621e+02, Test loss: 1.839e+05, MSE(e): 7.916e-05, MSE(pi1): 6.080e-03, MSE(pi2): 5.840e-05, MSE(pi3): 1.096e-03\n",
      "Epoch 60400, Train loss: 7.244e+02, Test loss: 1.816e+05, MSE(e): 5.563e-05, MSE(pi1): 6.521e-03, MSE(pi2): 4.865e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 60500, Train loss: 7.246e+02, Test loss: 1.832e+05, MSE(e): 5.568e-05, MSE(pi1): 6.010e-03, MSE(pi2): 4.869e-05, MSE(pi3): 1.076e-03\n",
      "Epoch 60600, Train loss: 6.669e+02, Test loss: 1.818e+05, MSE(e): 5.083e-05, MSE(pi1): 5.402e-03, MSE(pi2): 4.633e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 60700, Train loss: 6.646e+02, Test loss: 1.818e+05, MSE(e): 5.065e-05, MSE(pi1): 5.301e-03, MSE(pi2): 4.618e-05, MSE(pi3): 1.051e-03\n",
      "Epoch 60800, Train loss: 6.693e+02, Test loss: 1.822e+05, MSE(e): 5.093e-05, MSE(pi1): 5.524e-03, MSE(pi2): 4.625e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 60900, Train loss: 7.382e+02, Test loss: 1.820e+05, MSE(e): 5.203e-05, MSE(pi1): 1.058e-02, MSE(pi2): 4.626e-05, MSE(pi3): 1.122e-03\n",
      "Epoch 61000, Train loss: 6.784e+02, Test loss: 1.816e+05, MSE(e): 5.197e-05, MSE(pi1): 5.279e-03, MSE(pi2): 4.669e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 61100, Train loss: 8.042e+02, Test loss: 1.823e+05, MSE(e): 6.320e-05, MSE(pi1): 6.631e-03, MSE(pi2): 5.080e-05, MSE(pi3): 1.058e-03\n",
      "Epoch 61200, Train loss: 6.616e+02, Test loss: 1.814e+05, MSE(e): 5.034e-05, MSE(pi1): 5.370e-03, MSE(pi2): 4.588e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 61300, Train loss: 7.412e+02, Test loss: 1.815e+05, MSE(e): 5.279e-05, MSE(pi1): 9.999e-03, MSE(pi2): 4.641e-05, MSE(pi3): 1.133e-03\n",
      "Epoch 61400, Train loss: 6.756e+02, Test loss: 1.815e+05, MSE(e): 5.113e-05, MSE(pi1): 5.964e-03, MSE(pi2): 4.599e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 61500, Train loss: 6.843e+02, Test loss: 1.820e+05, MSE(e): 5.261e-05, MSE(pi1): 5.275e-03, MSE(pi2): 4.653e-05, MSE(pi3): 1.054e-03\n",
      "Epoch 61600, Train loss: 6.822e+02, Test loss: 1.818e+05, MSE(e): 5.205e-05, MSE(pi1): 5.485e-03, MSE(pi2): 4.633e-05, MSE(pi3): 1.068e-03\n",
      "Epoch 61700, Train loss: 6.645e+02, Test loss: 1.811e+05, MSE(e): 5.062e-05, MSE(pi1): 5.387e-03, MSE(pi2): 4.588e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 61800, Train loss: 8.318e+02, Test loss: 1.803e+05, MSE(e): 6.701e-05, MSE(pi1): 5.893e-03, MSE(pi2): 5.366e-05, MSE(pi3): 1.027e-03\n",
      "Epoch 61900, Train loss: 6.617e+02, Test loss: 1.810e+05, MSE(e): 5.041e-05, MSE(pi1): 5.329e-03, MSE(pi2): 4.572e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 62000, Train loss: 6.822e+02, Test loss: 1.807e+05, MSE(e): 5.245e-05, MSE(pi1): 5.334e-03, MSE(pi2): 4.673e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 62100, Train loss: 6.635e+02, Test loss: 1.809e+05, MSE(e): 4.977e-05, MSE(pi1): 6.280e-03, MSE(pi2): 4.529e-05, MSE(pi3): 1.030e-03\n",
      "Epoch 62200, Train loss: 6.655e+02, Test loss: 1.817e+05, MSE(e): 5.078e-05, MSE(pi1): 5.268e-03, MSE(pi2): 4.595e-05, MSE(pi3): 1.050e-03\n",
      "Epoch 62300, Train loss: 6.497e+02, Test loss: 1.809e+05, MSE(e): 4.919e-05, MSE(pi1): 5.260e-03, MSE(pi2): 4.491e-05, MSE(pi3): 1.052e-03\n",
      "Epoch 62400, Train loss: 6.510e+02, Test loss: 1.807e+05, MSE(e): 4.930e-05, MSE(pi1): 5.352e-03, MSE(pi2): 4.500e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 62500, Train loss: 6.471e+02, Test loss: 1.808e+05, MSE(e): 4.898e-05, MSE(pi1): 5.210e-03, MSE(pi2): 4.473e-05, MSE(pi3): 1.051e-03\n",
      "Epoch 62600, Train loss: 6.470e+02, Test loss: 1.808e+05, MSE(e): 4.897e-05, MSE(pi1): 5.232e-03, MSE(pi2): 4.469e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 62700, Train loss: 6.487e+02, Test loss: 1.805e+05, MSE(e): 4.915e-05, MSE(pi1): 5.298e-03, MSE(pi2): 4.482e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 62800, Train loss: 6.480e+02, Test loss: 1.806e+05, MSE(e): 4.901e-05, MSE(pi1): 5.263e-03, MSE(pi2): 4.469e-05, MSE(pi3): 1.052e-03\n",
      "Epoch 62900, Train loss: 7.042e+02, Test loss: 1.816e+05, MSE(e): 5.427e-05, MSE(pi1): 5.388e-03, MSE(pi2): 4.674e-05, MSE(pi3): 1.075e-03\n",
      "Epoch 63000, Train loss: 8.668e+02, Test loss: 1.794e+05, MSE(e): 6.842e-05, MSE(pi1): 8.131e-03, MSE(pi2): 5.409e-05, MSE(pi3): 1.012e-03\n",
      "Epoch 63100, Train loss: 7.520e+02, Test loss: 1.816e+05, MSE(e): 5.868e-05, MSE(pi1): 5.363e-03, MSE(pi2): 4.869e-05, MSE(pi3): 1.115e-03\n",
      "Epoch 63200, Train loss: 8.385e+02, Test loss: 1.792e+05, MSE(e): 6.663e-05, MSE(pi1): 7.140e-03, MSE(pi2): 5.309e-05, MSE(pi3): 1.008e-03\n",
      "Epoch 63300, Train loss: 6.477e+02, Test loss: 1.805e+05, MSE(e): 4.874e-05, MSE(pi1): 5.424e-03, MSE(pi2): 4.446e-05, MSE(pi3): 1.060e-03\n",
      "Epoch 63400, Train loss: 6.424e+02, Test loss: 1.802e+05, MSE(e): 4.857e-05, MSE(pi1): 5.200e-03, MSE(pi2): 4.430e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 63500, Train loss: 6.383e+02, Test loss: 1.802e+05, MSE(e): 4.813e-05, MSE(pi1): 5.220e-03, MSE(pi2): 4.401e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 63600, Train loss: 6.423e+02, Test loss: 1.807e+05, MSE(e): 4.843e-05, MSE(pi1): 5.327e-03, MSE(pi2): 4.404e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 63700, Train loss: 6.615e+02, Test loss: 1.804e+05, MSE(e): 4.902e-05, MSE(pi1): 6.379e-03, MSE(pi2): 4.429e-05, MSE(pi3): 1.075e-03\n",
      "Epoch 63800, Train loss: 6.371e+02, Test loss: 1.801e+05, MSE(e): 4.797e-05, MSE(pi1): 5.157e-03, MSE(pi2): 4.387e-05, MSE(pi3): 1.058e-03\n",
      "Epoch 63900, Train loss: 6.420e+02, Test loss: 1.804e+05, MSE(e): 4.848e-05, MSE(pi1): 5.076e-03, MSE(pi2): 4.395e-05, MSE(pi3): 1.064e-03\n",
      "Epoch 64000, Train loss: 9.509e+02, Test loss: 1.788e+05, MSE(e): 6.508e-05, MSE(pi1): 2.030e-02, MSE(pi2): 5.203e-05, MSE(pi3): 9.700e-04\n",
      "Epoch 64100, Train loss: 6.322e+02, Test loss: 1.800e+05, MSE(e): 4.760e-05, MSE(pi1): 5.156e-03, MSE(pi2): 4.356e-05, MSE(pi3): 1.046e-03\n",
      "Epoch 64200, Train loss: 7.635e+02, Test loss: 1.804e+05, MSE(e): 5.638e-05, MSE(pi1): 9.541e-03, MSE(pi2): 4.792e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 64300, Train loss: 6.308e+02, Test loss: 1.798e+05, MSE(e): 4.745e-05, MSE(pi1): 5.205e-03, MSE(pi2): 4.344e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 64400, Train loss: 6.297e+02, Test loss: 1.798e+05, MSE(e): 4.736e-05, MSE(pi1): 5.145e-03, MSE(pi2): 4.337e-05, MSE(pi3): 1.046e-03\n",
      "Epoch 64500, Train loss: 6.389e+02, Test loss: 1.798e+05, MSE(e): 4.760e-05, MSE(pi1): 5.840e-03, MSE(pi2): 4.337e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 64600, Train loss: 6.942e+02, Test loss: 1.796e+05, MSE(e): 5.075e-05, MSE(pi1): 8.039e-03, MSE(pi2): 4.464e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 64700, Train loss: 6.273e+02, Test loss: 1.798e+05, MSE(e): 4.714e-05, MSE(pi1): 5.127e-03, MSE(pi2): 4.316e-05, MSE(pi3): 1.046e-03\n",
      "Epoch 64800, Train loss: 6.332e+02, Test loss: 1.799e+05, MSE(e): 4.765e-05, MSE(pi1): 5.102e-03, MSE(pi2): 4.338e-05, MSE(pi3): 1.056e-03\n",
      "Epoch 64900, Train loss: 6.292e+02, Test loss: 1.796e+05, MSE(e): 4.708e-05, MSE(pi1): 5.412e-03, MSE(pi2): 4.304e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 65000, Train loss: 6.259e+02, Test loss: 1.796e+05, MSE(e): 4.698e-05, MSE(pi1): 5.074e-03, MSE(pi2): 4.295e-05, MSE(pi3): 1.053e-03\n",
      "Epoch 65100, Train loss: 6.238e+02, Test loss: 1.794e+05, MSE(e): 4.681e-05, MSE(pi1): 5.114e-03, MSE(pi2): 4.289e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 65200, Train loss: 6.315e+02, Test loss: 1.791e+05, MSE(e): 4.754e-05, MSE(pi1): 5.198e-03, MSE(pi2): 4.327e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 65300, Train loss: 7.254e+02, Test loss: 1.797e+05, MSE(e): 4.895e-05, MSE(pi1): 1.277e-02, MSE(pi2): 4.321e-05, MSE(pi3): 1.082e-03\n",
      "Epoch 65400, Train loss: 6.217e+02, Test loss: 1.794e+05, MSE(e): 4.661e-05, MSE(pi1): 5.052e-03, MSE(pi2): 4.268e-05, MSE(pi3): 1.051e-03\n",
      "Epoch 65500, Train loss: 6.417e+02, Test loss: 1.788e+05, MSE(e): 4.800e-05, MSE(pi1): 5.544e-03, MSE(pi2): 4.338e-05, MSE(pi3): 1.062e-03\n",
      "Epoch 65600, Train loss: 6.528e+02, Test loss: 1.785e+05, MSE(e): 4.943e-05, MSE(pi1): 5.218e-03, MSE(pi2): 4.395e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 65700, Train loss: 6.194e+02, Test loss: 1.791e+05, MSE(e): 4.634e-05, MSE(pi1): 5.144e-03, MSE(pi2): 4.247e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 65800, Train loss: 6.186e+02, Test loss: 1.790e+05, MSE(e): 4.631e-05, MSE(pi1): 5.088e-03, MSE(pi2): 4.245e-05, MSE(pi3): 1.046e-03\n",
      "Epoch 65900, Train loss: 6.242e+02, Test loss: 1.786e+05, MSE(e): 4.686e-05, MSE(pi1): 5.137e-03, MSE(pi2): 4.274e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 66000, Train loss: 6.276e+02, Test loss: 1.791e+05, MSE(e): 4.696e-05, MSE(pi1): 5.383e-03, MSE(pi2): 4.286e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 66100, Train loss: 6.473e+02, Test loss: 1.790e+05, MSE(e): 4.669e-05, MSE(pi1): 7.210e-03, MSE(pi2): 4.227e-05, MSE(pi3): 1.083e-03\n",
      "Epoch 66200, Train loss: 6.785e+02, Test loss: 1.806e+05, MSE(e): 5.088e-05, MSE(pi1): 6.245e-03, MSE(pi2): 4.452e-05, MSE(pi3): 1.072e-03\n",
      "Epoch 66300, Train loss: 6.138e+02, Test loss: 1.789e+05, MSE(e): 4.587e-05, MSE(pi1): 5.067e-03, MSE(pi2): 4.207e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 66400, Train loss: 6.161e+02, Test loss: 1.786e+05, MSE(e): 4.608e-05, MSE(pi1): 5.046e-03, MSE(pi2): 4.219e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 66500, Train loss: 6.123e+02, Test loss: 1.788e+05, MSE(e): 4.573e-05, MSE(pi1): 5.047e-03, MSE(pi2): 4.193e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 66600, Train loss: 7.036e+02, Test loss: 1.796e+05, MSE(e): 5.452e-05, MSE(pi1): 5.335e-03, MSE(pi2): 4.543e-05, MSE(pi3): 1.050e-03\n",
      "Epoch 66700, Train loss: 6.139e+02, Test loss: 1.788e+05, MSE(e): 4.585e-05, MSE(pi1): 5.067e-03, MSE(pi2): 4.191e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 66800, Train loss: 6.184e+02, Test loss: 1.785e+05, MSE(e): 4.601e-05, MSE(pi1): 5.388e-03, MSE(pi2): 4.200e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 66900, Train loss: 6.105e+02, Test loss: 1.786e+05, MSE(e): 4.550e-05, MSE(pi1): 5.119e-03, MSE(pi2): 4.175e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 67000, Train loss: 6.558e+02, Test loss: 1.780e+05, MSE(e): 4.912e-05, MSE(pi1): 6.311e-03, MSE(pi2): 4.354e-05, MSE(pi3): 1.015e-03\n",
      "Epoch 67100, Train loss: 8.096e+02, Test loss: 1.804e+05, MSE(e): 6.406e-05, MSE(pi1): 6.136e-03, MSE(pi2): 4.959e-05, MSE(pi3): 1.076e-03\n",
      "Epoch 67200, Train loss: 6.786e+02, Test loss: 1.796e+05, MSE(e): 5.204e-05, MSE(pi1): 5.025e-03, MSE(pi2): 4.443e-05, MSE(pi3): 1.079e-03\n",
      "Epoch 67300, Train loss: 6.613e+02, Test loss: 1.790e+05, MSE(e): 5.047e-05, MSE(pi1): 5.230e-03, MSE(pi2): 4.391e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 67400, Train loss: 6.220e+02, Test loss: 1.779e+05, MSE(e): 4.664e-05, MSE(pi1): 5.263e-03, MSE(pi2): 4.228e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 67500, Train loss: 6.913e+02, Test loss: 1.782e+05, MSE(e): 5.014e-05, MSE(pi1): 8.381e-03, MSE(pi2): 4.356e-05, MSE(pi3): 1.061e-03\n",
      "Epoch 67600, Train loss: 6.584e+02, Test loss: 1.791e+05, MSE(e): 5.015e-05, MSE(pi1): 5.053e-03, MSE(pi2): 4.337e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 67700, Train loss: 6.123e+02, Test loss: 1.782e+05, MSE(e): 4.518e-05, MSE(pi1): 5.593e-03, MSE(pi2): 4.134e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 67800, Train loss: 6.080e+02, Test loss: 1.784e+05, MSE(e): 4.498e-05, MSE(pi1): 5.255e-03, MSE(pi2): 4.119e-05, MSE(pi3): 1.056e-03\n",
      "Epoch 67900, Train loss: 6.076e+02, Test loss: 1.784e+05, MSE(e): 4.528e-05, MSE(pi1): 4.982e-03, MSE(pi2): 4.124e-05, MSE(pi3): 1.050e-03\n",
      "Epoch 68000, Train loss: 6.008e+02, Test loss: 1.782e+05, MSE(e): 4.463e-05, MSE(pi1): 5.006e-03, MSE(pi2): 4.098e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 68100, Train loss: 6.002e+02, Test loss: 1.781e+05, MSE(e): 4.457e-05, MSE(pi1): 5.035e-03, MSE(pi2): 4.094e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 68200, Train loss: 5.995e+02, Test loss: 1.781e+05, MSE(e): 4.449e-05, MSE(pi1): 5.019e-03, MSE(pi2): 4.086e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 68300, Train loss: 5.991e+02, Test loss: 1.781e+05, MSE(e): 4.448e-05, MSE(pi1): 4.965e-03, MSE(pi2): 4.081e-05, MSE(pi3): 1.046e-03\n",
      "Epoch 68400, Train loss: 6.220e+02, Test loss: 1.778e+05, MSE(e): 4.671e-05, MSE(pi1): 5.051e-03, MSE(pi2): 4.212e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 68500, Train loss: 6.156e+02, Test loss: 1.783e+05, MSE(e): 4.611e-05, MSE(pi1): 4.910e-03, MSE(pi2): 4.142e-05, MSE(pi3): 1.054e-03\n",
      "Epoch 68600, Train loss: 5.981e+02, Test loss: 1.778e+05, MSE(e): 4.425e-05, MSE(pi1): 5.137e-03, MSE(pi2): 4.063e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 68700, Train loss: 5.961e+02, Test loss: 1.778e+05, MSE(e): 4.419e-05, MSE(pi1): 5.017e-03, MSE(pi2): 4.062e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 68800, Train loss: 9.087e+02, Test loss: 1.769e+05, MSE(e): 7.399e-05, MSE(pi1): 6.759e-03, MSE(pi2): 5.487e-05, MSE(pi3): 1.012e-03\n",
      "Epoch 68900, Train loss: 6.855e+02, Test loss: 1.780e+05, MSE(e): 4.604e-05, MSE(pi1): 1.164e-02, MSE(pi2): 4.075e-05, MSE(pi3): 1.087e-03\n",
      "Epoch 69000, Train loss: 5.950e+02, Test loss: 1.780e+05, MSE(e): 4.408e-05, MSE(pi1): 4.989e-03, MSE(pi2): 4.044e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 69100, Train loss: 6.889e+02, Test loss: 1.767e+05, MSE(e): 5.262e-05, MSE(pi1): 6.109e-03, MSE(pi2): 4.470e-05, MSE(pi3): 1.015e-03\n",
      "Epoch 69200, Train loss: 6.861e+02, Test loss: 1.781e+05, MSE(e): 5.220e-05, MSE(pi1): 5.814e-03, MSE(pi2): 4.338e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 69300, Train loss: 1.084e+03, Test loss: 1.801e+05, MSE(e): 9.158e-05, MSE(pi1): 5.381e-03, MSE(pi2): 6.083e-05, MSE(pi3): 1.141e-03\n",
      "Epoch 69400, Train loss: 6.069e+02, Test loss: 1.778e+05, MSE(e): 4.436e-05, MSE(pi1): 6.218e-03, MSE(pi2): 4.024e-05, MSE(pi3): 1.010e-03\n",
      "Epoch 69500, Train loss: 5.899e+02, Test loss: 1.774e+05, MSE(e): 4.362e-05, MSE(pi1): 4.966e-03, MSE(pi2): 4.012e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 69600, Train loss: 5.894e+02, Test loss: 1.775e+05, MSE(e): 4.353e-05, MSE(pi1): 5.043e-03, MSE(pi2): 4.003e-05, MSE(pi3): 1.037e-03\n",
      "Epoch 69700, Train loss: 5.890e+02, Test loss: 1.775e+05, MSE(e): 4.352e-05, MSE(pi1): 4.963e-03, MSE(pi2): 4.002e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 69800, Train loss: 5.887e+02, Test loss: 1.772e+05, MSE(e): 4.343e-05, MSE(pi1): 4.969e-03, MSE(pi2): 3.993e-05, MSE(pi3): 1.046e-03\n",
      "Epoch 69900, Train loss: 5.953e+02, Test loss: 1.771e+05, MSE(e): 4.395e-05, MSE(pi1): 5.230e-03, MSE(pi2): 4.032e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 70000, Train loss: 5.908e+02, Test loss: 1.771e+05, MSE(e): 4.356e-05, MSE(pi1): 5.077e-03, MSE(pi2): 3.997e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 70100, Train loss: 5.893e+02, Test loss: 1.772e+05, MSE(e): 4.349e-05, MSE(pi1): 4.956e-03, MSE(pi2): 3.990e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 70200, Train loss: 6.026e+02, Test loss: 1.772e+05, MSE(e): 4.348e-05, MSE(pi1): 6.578e-03, MSE(pi2): 3.977e-05, MSE(pi3): 1.020e-03\n",
      "Epoch 70300, Train loss: 5.920e+02, Test loss: 1.772e+05, MSE(e): 4.375e-05, MSE(pi1): 4.968e-03, MSE(pi2): 3.994e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 70400, Train loss: 6.118e+02, Test loss: 1.775e+05, MSE(e): 4.444e-05, MSE(pi1): 6.368e-03, MSE(pi2): 4.046e-05, MSE(pi3): 1.037e-03\n",
      "Epoch 70500, Train loss: 5.848e+02, Test loss: 1.770e+05, MSE(e): 4.313e-05, MSE(pi1): 4.909e-03, MSE(pi2): 3.964e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 70600, Train loss: 6.068e+02, Test loss: 1.775e+05, MSE(e): 4.528e-05, MSE(pi1): 4.898e-03, MSE(pi2): 4.037e-05, MSE(pi3): 1.050e-03\n",
      "Epoch 70700, Train loss: 8.653e+02, Test loss: 1.760e+05, MSE(e): 6.286e-05, MSE(pi1): 1.275e-02, MSE(pi2): 5.405e-05, MSE(pi3): 1.092e-03\n",
      "Epoch 70800, Train loss: 7.092e+02, Test loss: 1.778e+05, MSE(e): 5.547e-05, MSE(pi1): 4.780e-03, MSE(pi2): 4.452e-05, MSE(pi3): 1.067e-03\n",
      "Epoch 70900, Train loss: 5.807e+02, Test loss: 1.769e+05, MSE(e): 4.269e-05, MSE(pi1): 4.873e-03, MSE(pi2): 3.928e-05, MSE(pi3): 1.050e-03\n",
      "Epoch 71000, Train loss: 8.516e+02, Test loss: 1.792e+05, MSE(e): 6.815e-05, MSE(pi1): 6.004e-03, MSE(pi2): 5.043e-05, MSE(pi3): 1.100e-03\n",
      "Epoch 71100, Train loss: 6.176e+02, Test loss: 1.774e+05, MSE(e): 4.453e-05, MSE(pi1): 6.646e-03, MSE(pi2): 4.013e-05, MSE(pi3): 1.058e-03\n",
      "Epoch 71200, Train loss: 5.863e+02, Test loss: 1.770e+05, MSE(e): 4.322e-05, MSE(pi1): 4.925e-03, MSE(pi2): 3.936e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 71300, Train loss: 5.887e+02, Test loss: 1.770e+05, MSE(e): 4.318e-05, MSE(pi1): 5.309e-03, MSE(pi2): 3.957e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 71400, Train loss: 5.774e+02, Test loss: 1.767e+05, MSE(e): 4.244e-05, MSE(pi1): 4.885e-03, MSE(pi2): 3.907e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 71500, Train loss: 6.005e+02, Test loss: 1.764e+05, MSE(e): 4.452e-05, MSE(pi1): 5.166e-03, MSE(pi2): 4.008e-05, MSE(pi3): 1.036e-03\n",
      "Epoch 71600, Train loss: 6.276e+02, Test loss: 1.765e+05, MSE(e): 4.417e-05, MSE(pi1): 8.478e-03, MSE(pi2): 3.984e-05, MSE(pi3): 1.011e-03\n",
      "Epoch 71700, Train loss: 5.834e+02, Test loss: 1.769e+05, MSE(e): 4.291e-05, MSE(pi1): 4.956e-03, MSE(pi2): 3.909e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 71800, Train loss: 5.786e+02, Test loss: 1.765e+05, MSE(e): 4.241e-05, MSE(pi1): 5.038e-03, MSE(pi2): 3.901e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 71900, Train loss: 6.292e+02, Test loss: 1.761e+05, MSE(e): 4.424e-05, MSE(pi1): 8.274e-03, MSE(pi2): 3.975e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 72000, Train loss: 5.729e+02, Test loss: 1.766e+05, MSE(e): 4.199e-05, MSE(pi1): 4.795e-03, MSE(pi2): 3.868e-05, MSE(pi3): 1.050e-03\n",
      "Epoch 72100, Train loss: 5.751e+02, Test loss: 1.766e+05, MSE(e): 4.200e-05, MSE(pi1): 5.115e-03, MSE(pi2): 3.864e-05, MSE(pi3): 1.039e-03\n",
      "Epoch 72200, Train loss: 6.940e+02, Test loss: 1.765e+05, MSE(e): 4.888e-05, MSE(pi1): 9.937e-03, MSE(pi2): 4.315e-05, MSE(pi3): 1.058e-03\n",
      "Epoch 72300, Train loss: 6.076e+02, Test loss: 1.758e+05, MSE(e): 4.456e-05, MSE(pi1): 6.150e-03, MSE(pi2): 4.001e-05, MSE(pi3): 1.005e-03\n",
      "Epoch 72400, Train loss: 5.735e+02, Test loss: 1.764e+05, MSE(e): 4.182e-05, MSE(pi1): 5.128e-03, MSE(pi2): 3.850e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 72500, Train loss: 5.694e+02, Test loss: 1.764e+05, MSE(e): 4.169e-05, MSE(pi1): 4.847e-03, MSE(pi2): 3.842e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 72600, Train loss: 5.736e+02, Test loss: 1.765e+05, MSE(e): 4.189e-05, MSE(pi1): 5.080e-03, MSE(pi2): 3.843e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 72700, Train loss: 5.695e+02, Test loss: 1.763e+05, MSE(e): 4.170e-05, MSE(pi1): 4.844e-03, MSE(pi2): 3.841e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 72800, Train loss: 5.736e+02, Test loss: 1.766e+05, MSE(e): 4.204e-05, MSE(pi1): 4.900e-03, MSE(pi2): 3.841e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 72900, Train loss: 5.792e+02, Test loss: 1.763e+05, MSE(e): 4.182e-05, MSE(pi1): 5.823e-03, MSE(pi2): 3.827e-05, MSE(pi3): 1.027e-03\n",
      "Epoch 73000, Train loss: 5.683e+02, Test loss: 1.763e+05, MSE(e): 4.152e-05, MSE(pi1): 4.834e-03, MSE(pi2): 3.818e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 73100, Train loss: 5.763e+02, Test loss: 1.763e+05, MSE(e): 4.153e-05, MSE(pi1): 5.690e-03, MSE(pi2): 3.811e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 73200, Train loss: 5.677e+02, Test loss: 1.761e+05, MSE(e): 4.149e-05, MSE(pi1): 4.937e-03, MSE(pi2): 3.820e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 73300, Train loss: 5.656e+02, Test loss: 1.762e+05, MSE(e): 4.131e-05, MSE(pi1): 4.856e-03, MSE(pi2): 3.802e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 73400, Train loss: 5.775e+02, Test loss: 1.757e+05, MSE(e): 4.249e-05, MSE(pi1): 4.899e-03, MSE(pi2): 3.866e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 73500, Train loss: 7.344e+02, Test loss: 1.759e+05, MSE(e): 5.175e-05, MSE(pi1): 1.102e-02, MSE(pi2): 4.497e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 73600, Train loss: 5.770e+02, Test loss: 1.759e+05, MSE(e): 4.134e-05, MSE(pi1): 6.074e-03, MSE(pi2): 3.789e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 73700, Train loss: 5.723e+02, Test loss: 1.759e+05, MSE(e): 4.140e-05, MSE(pi1): 5.468e-03, MSE(pi2): 3.795e-05, MSE(pi3): 1.036e-03\n",
      "Epoch 73800, Train loss: 5.617e+02, Test loss: 1.759e+05, MSE(e): 4.095e-05, MSE(pi1): 4.862e-03, MSE(pi2): 3.778e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 73900, Train loss: 6.458e+02, Test loss: 1.767e+05, MSE(e): 4.856e-05, MSE(pi1): 5.290e-03, MSE(pi2): 4.097e-05, MSE(pi3): 1.072e-03\n",
      "Epoch 74000, Train loss: 6.308e+02, Test loss: 1.770e+05, MSE(e): 4.511e-05, MSE(pi1): 6.725e-03, MSE(pi2): 3.958e-05, MSE(pi3): 1.124e-03\n",
      "Epoch 74100, Train loss: 8.856e+02, Test loss: 1.774e+05, MSE(e): 7.273e-05, MSE(pi1): 4.946e-03, MSE(pi2): 5.123e-05, MSE(pi3): 1.088e-03\n",
      "Epoch 74200, Train loss: 5.881e+02, Test loss: 1.754e+05, MSE(e): 4.297e-05, MSE(pi1): 5.579e-03, MSE(pi2): 3.866e-05, MSE(pi3): 1.026e-03\n",
      "Epoch 74300, Train loss: 5.624e+02, Test loss: 1.757e+05, MSE(e): 4.075e-05, MSE(pi1): 5.001e-03, MSE(pi2): 3.752e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 74400, Train loss: 5.596e+02, Test loss: 1.756e+05, MSE(e): 4.076e-05, MSE(pi1): 4.862e-03, MSE(pi2): 3.758e-05, MSE(pi3): 1.033e-03\n",
      "Epoch 74500, Train loss: 1.304e+03, Test loss: 1.741e+05, MSE(e): 1.118e-04, MSE(pi1): 8.705e-03, MSE(pi2): 7.103e-05, MSE(pi3): 9.920e-04\n",
      "Epoch 74600, Train loss: 5.603e+02, Test loss: 1.757e+05, MSE(e): 4.053e-05, MSE(pi1): 5.214e-03, MSE(pi2): 3.734e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 74700, Train loss: 5.609e+02, Test loss: 1.758e+05, MSE(e): 4.081e-05, MSE(pi1): 4.876e-03, MSE(pi2): 3.744e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 74800, Train loss: 5.592e+02, Test loss: 1.756e+05, MSE(e): 4.057e-05, MSE(pi1): 4.969e-03, MSE(pi2): 3.738e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 74900, Train loss: 5.845e+02, Test loss: 1.762e+05, MSE(e): 4.320e-05, MSE(pi1): 4.836e-03, MSE(pi2): 3.829e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 75000, Train loss: 5.733e+02, Test loss: 1.759e+05, MSE(e): 4.118e-05, MSE(pi1): 5.914e-03, MSE(pi2): 3.734e-05, MSE(pi3): 1.023e-03\n",
      "Epoch 75100, Train loss: 9.453e+02, Test loss: 1.744e+05, MSE(e): 7.809e-05, MSE(pi1): 5.943e-03, MSE(pi2): 5.577e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 75200, Train loss: 5.540e+02, Test loss: 1.756e+05, MSE(e): 4.022e-05, MSE(pi1): 4.776e-03, MSE(pi2): 3.705e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 75300, Train loss: 5.523e+02, Test loss: 1.754e+05, MSE(e): 4.008e-05, MSE(pi1): 4.776e-03, MSE(pi2): 3.701e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 75400, Train loss: 5.542e+02, Test loss: 1.753e+05, MSE(e): 4.024e-05, MSE(pi1): 4.769e-03, MSE(pi2): 3.710e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 75500, Train loss: 5.709e+02, Test loss: 1.760e+05, MSE(e): 4.160e-05, MSE(pi1): 5.013e-03, MSE(pi2): 3.766e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 75600, Train loss: 5.536e+02, Test loss: 1.752e+05, MSE(e): 4.018e-05, MSE(pi1): 4.855e-03, MSE(pi2): 3.703e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 75700, Train loss: 6.018e+02, Test loss: 1.752e+05, MSE(e): 4.115e-05, MSE(pi1): 9.008e-03, MSE(pi2): 3.699e-05, MSE(pi3): 1.001e-03\n",
      "Epoch 75800, Train loss: 5.778e+02, Test loss: 1.759e+05, MSE(e): 4.232e-05, MSE(pi1): 4.840e-03, MSE(pi2): 3.793e-05, MSE(pi3): 1.061e-03\n",
      "Epoch 75900, Train loss: 5.598e+02, Test loss: 1.749e+05, MSE(e): 4.057e-05, MSE(pi1): 4.950e-03, MSE(pi2): 3.714e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 76000, Train loss: 5.851e+02, Test loss: 1.751e+05, MSE(e): 4.122e-05, MSE(pi1): 7.179e-03, MSE(pi2): 3.744e-05, MSE(pi3): 1.010e-03\n",
      "Epoch 76100, Train loss: 5.801e+02, Test loss: 1.746e+05, MSE(e): 4.261e-05, MSE(pi1): 5.188e-03, MSE(pi2): 3.817e-05, MSE(pi3): 1.021e-03\n",
      "Epoch 76200, Train loss: 5.717e+02, Test loss: 1.748e+05, MSE(e): 4.170e-05, MSE(pi1): 4.929e-03, MSE(pi2): 3.761e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 76300, Train loss: 1.037e+03, Test loss: 1.731e+05, MSE(e): 8.303e-05, MSE(pi1): 1.036e-02, MSE(pi2): 5.648e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 76400, Train loss: 5.604e+02, Test loss: 1.753e+05, MSE(e): 3.978e-05, MSE(pi1): 6.023e-03, MSE(pi2): 3.650e-05, MSE(pi3): 1.023e-03\n",
      "Epoch 76500, Train loss: 5.803e+02, Test loss: 1.750e+05, MSE(e): 4.031e-05, MSE(pi1): 7.143e-03, MSE(pi2): 3.670e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 76600, Train loss: 5.464e+02, Test loss: 1.750e+05, MSE(e): 3.945e-05, MSE(pi1): 4.767e-03, MSE(pi2): 3.642e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 76700, Train loss: 7.299e+02, Test loss: 1.739e+05, MSE(e): 5.613e-05, MSE(pi1): 6.813e-03, MSE(pi2): 4.452e-05, MSE(pi3): 1.005e-03\n",
      "Epoch 76800, Train loss: 5.879e+02, Test loss: 1.747e+05, MSE(e): 4.184e-05, MSE(pi1): 6.768e-03, MSE(pi2): 3.751e-05, MSE(pi3): 1.018e-03\n",
      "Epoch 76900, Train loss: 6.396e+02, Test loss: 1.759e+05, MSE(e): 4.490e-05, MSE(pi1): 7.576e-03, MSE(pi2): 3.969e-05, MSE(pi3): 1.147e-03\n",
      "Epoch 77000, Train loss: 5.445e+02, Test loss: 1.748e+05, MSE(e): 3.935e-05, MSE(pi1): 4.752e-03, MSE(pi2): 3.632e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 77100, Train loss: 5.442e+02, Test loss: 1.749e+05, MSE(e): 3.923e-05, MSE(pi1): 4.819e-03, MSE(pi2): 3.620e-05, MSE(pi3): 1.037e-03\n",
      "Epoch 77200, Train loss: 5.859e+02, Test loss: 1.745e+05, MSE(e): 4.334e-05, MSE(pi1): 5.043e-03, MSE(pi2): 3.825e-05, MSE(pi3): 1.021e-03\n",
      "Epoch 77300, Train loss: 6.545e+02, Test loss: 1.761e+05, MSE(e): 4.785e-05, MSE(pi1): 7.045e-03, MSE(pi2): 3.922e-05, MSE(pi3): 1.054e-03\n",
      "Epoch 77400, Train loss: 5.404e+02, Test loss: 1.748e+05, MSE(e): 3.895e-05, MSE(pi1): 4.694e-03, MSE(pi2): 3.599e-05, MSE(pi3): 1.038e-03\n",
      "Epoch 77500, Train loss: 5.548e+02, Test loss: 1.751e+05, MSE(e): 4.001e-05, MSE(pi1): 4.741e-03, MSE(pi2): 3.674e-05, MSE(pi3): 1.073e-03\n",
      "Epoch 77600, Train loss: 5.691e+02, Test loss: 1.741e+05, MSE(e): 4.157e-05, MSE(pi1): 5.092e-03, MSE(pi2): 3.760e-05, MSE(pi3): 1.024e-03\n",
      "Epoch 77700, Train loss: 5.476e+02, Test loss: 1.748e+05, MSE(e): 3.905e-05, MSE(pi1): 5.124e-03, MSE(pi2): 3.591e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 77800, Train loss: 5.385e+02, Test loss: 1.747e+05, MSE(e): 3.877e-05, MSE(pi1): 4.732e-03, MSE(pi2): 3.581e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 77900, Train loss: 5.388e+02, Test loss: 1.745e+05, MSE(e): 3.880e-05, MSE(pi1): 4.731e-03, MSE(pi2): 3.587e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 78000, Train loss: 5.799e+02, Test loss: 1.753e+05, MSE(e): 4.276e-05, MSE(pi1): 4.859e-03, MSE(pi2): 3.731e-05, MSE(pi3): 1.037e-03\n",
      "Epoch 78100, Train loss: 5.383e+02, Test loss: 1.746e+05, MSE(e): 3.871e-05, MSE(pi1): 4.678e-03, MSE(pi2): 3.572e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 78200, Train loss: 5.424e+02, Test loss: 1.742e+05, MSE(e): 3.914e-05, MSE(pi1): 4.772e-03, MSE(pi2): 3.599e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 78300, Train loss: 6.370e+02, Test loss: 1.740e+05, MSE(e): 4.243e-05, MSE(pi1): 1.092e-02, MSE(pi2): 3.732e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 78400, Train loss: 6.331e+02, Test loss: 1.756e+05, MSE(e): 4.804e-05, MSE(pi1): 4.680e-03, MSE(pi2): 3.957e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 78500, Train loss: 8.097e+02, Test loss: 1.730e+05, MSE(e): 6.529e-05, MSE(pi1): 5.361e-03, MSE(pi2): 4.739e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 78600, Train loss: 6.275e+02, Test loss: 1.741e+05, MSE(e): 4.679e-05, MSE(pi1): 5.696e-03, MSE(pi2): 3.973e-05, MSE(pi3): 1.026e-03\n",
      "Epoch 78700, Train loss: 6.156e+02, Test loss: 1.742e+05, MSE(e): 4.300e-05, MSE(pi1): 8.599e-03, MSE(pi2): 3.868e-05, MSE(pi3): 9.962e-04\n",
      "Epoch 78800, Train loss: 5.400e+02, Test loss: 1.740e+05, MSE(e): 3.890e-05, MSE(pi1): 4.779e-03, MSE(pi2): 3.582e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 78900, Train loss: 6.289e+02, Test loss: 1.748e+05, MSE(e): 4.748e-05, MSE(pi1): 4.947e-03, MSE(pi2): 3.896e-05, MSE(pi3): 1.046e-03\n",
      "Epoch 79000, Train loss: 7.732e+02, Test loss: 1.755e+05, MSE(e): 6.138e-05, MSE(pi1): 4.960e-03, MSE(pi2): 4.501e-05, MSE(pi3): 1.098e-03\n",
      "Epoch 79100, Train loss: 5.412e+02, Test loss: 1.743e+05, MSE(e): 3.861e-05, MSE(pi1): 5.191e-03, MSE(pi2): 3.545e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 79200, Train loss: 5.307e+02, Test loss: 1.743e+05, MSE(e): 3.804e-05, MSE(pi1): 4.652e-03, MSE(pi2): 3.520e-05, MSE(pi3): 1.037e-03\n",
      "Epoch 79300, Train loss: 5.418e+02, Test loss: 1.746e+05, MSE(e): 3.893e-05, MSE(pi1): 4.769e-03, MSE(pi2): 3.547e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 79400, Train loss: 5.775e+02, Test loss: 1.740e+05, MSE(e): 4.025e-05, MSE(pi1): 6.710e-03, MSE(pi2): 3.657e-05, MSE(pi3): 1.079e-03\n",
      "Epoch 79500, Train loss: 5.293e+02, Test loss: 1.742e+05, MSE(e): 3.791e-05, MSE(pi1): 4.683e-03, MSE(pi2): 3.509e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 79600, Train loss: 5.559e+02, Test loss: 1.744e+05, MSE(e): 4.024e-05, MSE(pi1): 4.821e-03, MSE(pi2): 3.604e-05, MSE(pi3): 1.052e-03\n",
      "Epoch 79700, Train loss: 5.292e+02, Test loss: 1.741e+05, MSE(e): 3.783e-05, MSE(pi1): 4.668e-03, MSE(pi2): 3.499e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 79800, Train loss: 5.336e+02, Test loss: 1.745e+05, MSE(e): 3.834e-05, MSE(pi1): 4.595e-03, MSE(pi2): 3.512e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 79900, Train loss: 5.271e+02, Test loss: 1.741e+05, MSE(e): 3.771e-05, MSE(pi1): 4.635e-03, MSE(pi2): 3.489e-05, MSE(pi3): 1.036e-03\n",
      "Epoch 80000, Train loss: 5.280e+02, Test loss: 1.742e+05, MSE(e): 3.772e-05, MSE(pi1): 4.739e-03, MSE(pi2): 3.485e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 80100, Train loss: 5.278e+02, Test loss: 1.740e+05, MSE(e): 3.768e-05, MSE(pi1): 4.810e-03, MSE(pi2): 3.487e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 80200, Train loss: 5.470e+02, Test loss: 1.739e+05, MSE(e): 3.967e-05, MSE(pi1): 4.739e-03, MSE(pi2): 3.586e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 80300, Train loss: 5.314e+02, Test loss: 1.741e+05, MSE(e): 3.768e-05, MSE(pi1): 5.356e-03, MSE(pi2): 3.474e-05, MSE(pi3): 1.010e-03\n",
      "Epoch 80400, Train loss: 5.247e+02, Test loss: 1.739e+05, MSE(e): 3.747e-05, MSE(pi1): 4.638e-03, MSE(pi2): 3.470e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 80500, Train loss: 5.845e+02, Test loss: 1.747e+05, MSE(e): 4.310e-05, MSE(pi1): 4.767e-03, MSE(pi2): 3.704e-05, MSE(pi3): 1.058e-03\n",
      "Epoch 80600, Train loss: 5.379e+02, Test loss: 1.736e+05, MSE(e): 3.872e-05, MSE(pi1): 4.832e-03, MSE(pi2): 3.533e-05, MSE(pi3): 1.024e-03\n",
      "Epoch 80700, Train loss: 5.294e+02, Test loss: 1.734e+05, MSE(e): 3.794e-05, MSE(pi1): 4.688e-03, MSE(pi2): 3.497e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 80800, Train loss: 5.911e+02, Test loss: 1.731e+05, MSE(e): 4.408e-05, MSE(pi1): 4.790e-03, MSE(pi2): 3.785e-05, MSE(pi3): 1.024e-03\n",
      "Epoch 80900, Train loss: 5.309e+02, Test loss: 1.735e+05, MSE(e): 3.804e-05, MSE(pi1): 4.706e-03, MSE(pi2): 3.493e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 81000, Train loss: 6.068e+02, Test loss: 1.732e+05, MSE(e): 4.328e-05, MSE(pi1): 6.808e-03, MSE(pi2): 3.693e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 81100, Train loss: 5.450e+02, Test loss: 1.738e+05, MSE(e): 3.769e-05, MSE(pi1): 6.392e-03, MSE(pi2): 3.454e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 81200, Train loss: 5.615e+02, Test loss: 1.737e+05, MSE(e): 3.791e-05, MSE(pi1): 8.177e-03, MSE(pi2): 3.454e-05, MSE(pi3): 1.006e-03\n",
      "Epoch 81300, Train loss: 5.264e+02, Test loss: 1.736e+05, MSE(e): 3.741e-05, MSE(pi1): 4.874e-03, MSE(pi2): 3.455e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 81400, Train loss: 5.607e+02, Test loss: 1.731e+05, MSE(e): 4.074e-05, MSE(pi1): 5.199e-03, MSE(pi2): 3.655e-05, MSE(pi3): 1.012e-03\n",
      "Epoch 81500, Train loss: 5.252e+02, Test loss: 1.734e+05, MSE(e): 3.745e-05, MSE(pi1): 4.665e-03, MSE(pi2): 3.454e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 81600, Train loss: 5.667e+02, Test loss: 1.745e+05, MSE(e): 4.162e-05, MSE(pi1): 4.553e-03, MSE(pi2): 3.608e-05, MSE(pi3): 1.050e-03\n",
      "Epoch 81700, Train loss: 5.202e+02, Test loss: 1.734e+05, MSE(e): 3.704e-05, MSE(pi1): 4.734e-03, MSE(pi2): 3.428e-05, MSE(pi3): 1.025e-03\n",
      "Epoch 81800, Train loss: 5.197e+02, Test loss: 1.736e+05, MSE(e): 3.697e-05, MSE(pi1): 4.600e-03, MSE(pi2): 3.420e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 81900, Train loss: 5.398e+02, Test loss: 1.741e+05, MSE(e): 3.900e-05, MSE(pi1): 4.509e-03, MSE(pi2): 3.491e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 82000, Train loss: 5.194e+02, Test loss: 1.735e+05, MSE(e): 3.686e-05, MSE(pi1): 4.810e-03, MSE(pi2): 3.411e-05, MSE(pi3): 1.027e-03\n",
      "Epoch 82100, Train loss: 5.535e+02, Test loss: 1.742e+05, MSE(e): 3.987e-05, MSE(pi1): 4.913e-03, MSE(pi2): 3.529e-05, MSE(pi3): 1.056e-03\n",
      "Epoch 82200, Train loss: 5.540e+02, Test loss: 1.735e+05, MSE(e): 3.903e-05, MSE(pi1): 6.027e-03, MSE(pi2): 3.546e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 82300, Train loss: 6.164e+02, Test loss: 1.724e+05, MSE(e): 4.418e-05, MSE(pi1): 6.683e-03, MSE(pi2): 3.688e-05, MSE(pi3): 1.077e-03\n",
      "Epoch 82400, Train loss: 5.284e+02, Test loss: 1.733e+05, MSE(e): 3.708e-05, MSE(pi1): 5.438e-03, MSE(pi2): 3.409e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 82500, Train loss: 5.150e+02, Test loss: 1.733e+05, MSE(e): 3.657e-05, MSE(pi1): 4.609e-03, MSE(pi2): 3.390e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 82600, Train loss: 5.169e+02, Test loss: 1.734e+05, MSE(e): 3.662e-05, MSE(pi1): 4.596e-03, MSE(pi2): 3.387e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 82700, Train loss: 7.682e+02, Test loss: 1.721e+05, MSE(e): 5.761e-05, MSE(pi1): 8.892e-03, MSE(pi2): 4.296e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 82800, Train loss: 5.224e+02, Test loss: 1.734e+05, MSE(e): 3.665e-05, MSE(pi1): 5.035e-03, MSE(pi2): 3.378e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 82900, Train loss: 5.754e+02, Test loss: 1.742e+05, MSE(e): 4.245e-05, MSE(pi1): 4.559e-03, MSE(pi2): 3.625e-05, MSE(pi3): 1.053e-03\n",
      "Epoch 83000, Train loss: 5.715e+02, Test loss: 1.732e+05, MSE(e): 3.756e-05, MSE(pi1): 9.090e-03, MSE(pi2): 3.392e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 83100, Train loss: 5.123e+02, Test loss: 1.732e+05, MSE(e): 3.628e-05, MSE(pi1): 4.550e-03, MSE(pi2): 3.362e-05, MSE(pi3): 1.039e-03\n",
      "Epoch 83200, Train loss: 5.187e+02, Test loss: 1.731e+05, MSE(e): 3.682e-05, MSE(pi1): 4.704e-03, MSE(pi2): 3.388e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 83300, Train loss: 5.197e+02, Test loss: 1.729e+05, MSE(e): 3.704e-05, MSE(pi1): 4.635e-03, MSE(pi2): 3.401e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 83400, Train loss: 6.255e+02, Test loss: 1.724e+05, MSE(e): 4.646e-05, MSE(pi1): 5.675e-03, MSE(pi2): 3.797e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 83500, Train loss: 9.841e+02, Test loss: 1.718e+05, MSE(e): 8.078e-05, MSE(pi1): 7.661e-03, MSE(pi2): 5.454e-05, MSE(pi3): 9.957e-04\n",
      "Epoch 83600, Train loss: 5.256e+02, Test loss: 1.732e+05, MSE(e): 3.645e-05, MSE(pi1): 5.535e-03, MSE(pi2): 3.352e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 83700, Train loss: 5.089e+02, Test loss: 1.731e+05, MSE(e): 3.599e-05, MSE(pi1): 4.590e-03, MSE(pi2): 3.337e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 83800, Train loss: 5.086e+02, Test loss: 1.730e+05, MSE(e): 3.597e-05, MSE(pi1): 4.569e-03, MSE(pi2): 3.336e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 83900, Train loss: 5.517e+02, Test loss: 1.725e+05, MSE(e): 3.937e-05, MSE(pi1): 5.470e-03, MSE(pi2): 3.499e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 84000, Train loss: 5.942e+02, Test loss: 1.723e+05, MSE(e): 4.252e-05, MSE(pi1): 5.907e-03, MSE(pi2): 3.609e-05, MSE(pi3): 1.099e-03\n",
      "Epoch 84100, Train loss: 5.113e+02, Test loss: 1.731e+05, MSE(e): 3.610e-05, MSE(pi1): 4.628e-03, MSE(pi2): 3.328e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 84200, Train loss: 5.072e+02, Test loss: 1.730e+05, MSE(e): 3.580e-05, MSE(pi1): 4.547e-03, MSE(pi2): 3.316e-05, MSE(pi3): 1.037e-03\n",
      "Epoch 84300, Train loss: 5.368e+02, Test loss: 1.737e+05, MSE(e): 3.874e-05, MSE(pi1): 4.471e-03, MSE(pi2): 3.438e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 84400, Train loss: 5.128e+02, Test loss: 1.732e+05, MSE(e): 3.636e-05, MSE(pi1): 4.501e-03, MSE(pi2): 3.332e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 84500, Train loss: 5.310e+02, Test loss: 1.733e+05, MSE(e): 3.660e-05, MSE(pi1): 6.077e-03, MSE(pi2): 3.328e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 84600, Train loss: 5.129e+02, Test loss: 1.726e+05, MSE(e): 3.639e-05, MSE(pi1): 4.641e-03, MSE(pi2): 3.347e-05, MSE(pi3): 1.026e-03\n",
      "Epoch 84700, Train loss: 5.461e+02, Test loss: 1.730e+05, MSE(e): 3.872e-05, MSE(pi1): 5.496e-03, MSE(pi2): 3.468e-05, MSE(pi3): 1.039e-03\n",
      "Epoch 84800, Train loss: 5.387e+02, Test loss: 1.730e+05, MSE(e): 3.728e-05, MSE(pi1): 6.515e-03, MSE(pi2): 3.371e-05, MSE(pi3): 1.007e-03\n",
      "Epoch 84900, Train loss: 5.036e+02, Test loss: 1.728e+05, MSE(e): 3.547e-05, MSE(pi1): 4.567e-03, MSE(pi2): 3.290e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 85000, Train loss: 8.909e+02, Test loss: 1.756e+05, MSE(e): 6.771e-05, MSE(pi1): 9.634e-03, MSE(pi2): 4.718e-05, MSE(pi3): 1.174e-03\n",
      "Epoch 85100, Train loss: 5.024e+02, Test loss: 1.727e+05, MSE(e): 3.539e-05, MSE(pi1): 4.508e-03, MSE(pi2): 3.283e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 85200, Train loss: 5.027e+02, Test loss: 1.727e+05, MSE(e): 3.536e-05, MSE(pi1): 4.560e-03, MSE(pi2): 3.279e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 85300, Train loss: 5.066e+02, Test loss: 1.727e+05, MSE(e): 3.549e-05, MSE(pi1): 4.837e-03, MSE(pi2): 3.282e-05, MSE(pi3): 1.033e-03\n",
      "Epoch 85400, Train loss: 5.288e+02, Test loss: 1.731e+05, MSE(e): 3.755e-05, MSE(pi1): 5.163e-03, MSE(pi2): 3.350e-05, MSE(pi3): 1.017e-03\n",
      "Epoch 85500, Train loss: 1.147e+03, Test loss: 1.708e+05, MSE(e): 9.353e-05, MSE(pi1): 1.108e-02, MSE(pi2): 5.923e-05, MSE(pi3): 1.009e-03\n",
      "Epoch 85600, Train loss: 5.030e+02, Test loss: 1.726e+05, MSE(e): 3.528e-05, MSE(pi1): 4.711e-03, MSE(pi2): 3.267e-05, MSE(pi3): 1.030e-03\n",
      "Epoch 85700, Train loss: 5.005e+02, Test loss: 1.726e+05, MSE(e): 3.515e-05, MSE(pi1): 4.524e-03, MSE(pi2): 3.261e-05, MSE(pi3): 1.037e-03\n",
      "Epoch 85800, Train loss: 5.268e+02, Test loss: 1.731e+05, MSE(e): 3.779e-05, MSE(pi1): 4.455e-03, MSE(pi2): 3.365e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 85900, Train loss: 5.098e+02, Test loss: 1.726e+05, MSE(e): 3.551e-05, MSE(pi1): 5.001e-03, MSE(pi2): 3.271e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 86000, Train loss: 5.001e+02, Test loss: 1.724e+05, MSE(e): 3.517e-05, MSE(pi1): 4.524e-03, MSE(pi2): 3.260e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 86100, Train loss: 5.202e+02, Test loss: 1.724e+05, MSE(e): 3.553e-05, MSE(pi1): 6.337e-03, MSE(pi2): 3.259e-05, MSE(pi3): 1.016e-03\n",
      "Epoch 86200, Train loss: 5.923e+02, Test loss: 1.721e+05, MSE(e): 4.370e-05, MSE(pi1): 4.903e-03, MSE(pi2): 3.796e-05, MSE(pi3): 1.063e-03\n",
      "Epoch 86300, Train loss: 4.973e+02, Test loss: 1.725e+05, MSE(e): 3.490e-05, MSE(pi1): 4.502e-03, MSE(pi2): 3.239e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 86400, Train loss: 5.208e+02, Test loss: 1.729e+05, MSE(e): 3.713e-05, MSE(pi1): 4.456e-03, MSE(pi2): 3.322e-05, MSE(pi3): 1.049e-03\n",
      "Epoch 86500, Train loss: 5.134e+02, Test loss: 1.721e+05, MSE(e): 3.638e-05, MSE(pi1): 4.697e-03, MSE(pi2): 3.313e-05, MSE(pi3): 1.026e-03\n",
      "Epoch 86600, Train loss: 5.193e+02, Test loss: 1.728e+05, MSE(e): 3.617e-05, MSE(pi1): 5.216e-03, MSE(pi2): 3.278e-05, MSE(pi3): 1.054e-03\n",
      "Epoch 86700, Train loss: 5.152e+02, Test loss: 1.721e+05, MSE(e): 3.659e-05, MSE(pi1): 4.712e-03, MSE(pi2): 3.323e-05, MSE(pi3): 1.021e-03\n",
      "Epoch 86800, Train loss: 5.646e+02, Test loss: 1.718e+05, MSE(e): 3.826e-05, MSE(pi1): 8.137e-03, MSE(pi2): 3.390e-05, MSE(pi3): 1.006e-03\n",
      "Epoch 86900, Train loss: 4.948e+02, Test loss: 1.723e+05, MSE(e): 3.466e-05, MSE(pi1): 4.499e-03, MSE(pi2): 3.218e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 87000, Train loss: 5.028e+02, Test loss: 1.726e+05, MSE(e): 3.544e-05, MSE(pi1): 4.436e-03, MSE(pi2): 3.242e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 87100, Train loss: 5.563e+02, Test loss: 1.721e+05, MSE(e): 3.809e-05, MSE(pi1): 7.349e-03, MSE(pi2): 3.378e-05, MSE(pi3): 1.018e-03\n",
      "Epoch 87200, Train loss: 4.951e+02, Test loss: 1.723e+05, MSE(e): 3.470e-05, MSE(pi1): 4.491e-03, MSE(pi2): 3.211e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 87300, Train loss: 4.934e+02, Test loss: 1.722e+05, MSE(e): 3.452e-05, MSE(pi1): 4.468e-03, MSE(pi2): 3.206e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 87400, Train loss: 4.934e+02, Test loss: 1.721e+05, MSE(e): 3.452e-05, MSE(pi1): 4.514e-03, MSE(pi2): 3.206e-05, MSE(pi3): 1.030e-03\n",
      "Epoch 87500, Train loss: 4.934e+02, Test loss: 1.722e+05, MSE(e): 3.453e-05, MSE(pi1): 4.471e-03, MSE(pi2): 3.203e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 87600, Train loss: 5.295e+02, Test loss: 1.716e+05, MSE(e): 3.811e-05, MSE(pi1): 4.543e-03, MSE(pi2): 3.379e-05, MSE(pi3): 1.030e-03\n",
      "Epoch 87700, Train loss: 5.087e+02, Test loss: 1.725e+05, MSE(e): 3.599e-05, MSE(pi1): 4.478e-03, MSE(pi2): 3.251e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 87800, Train loss: 5.795e+02, Test loss: 1.734e+05, MSE(e): 4.244e-05, MSE(pi1): 4.970e-03, MSE(pi2): 3.511e-05, MSE(pi3): 1.053e-03\n",
      "Epoch 87900, Train loss: 5.439e+02, Test loss: 1.715e+05, MSE(e): 3.944e-05, MSE(pi1): 4.736e-03, MSE(pi2): 3.439e-05, MSE(pi3): 1.021e-03\n",
      "Epoch 88000, Train loss: 5.337e+02, Test loss: 1.713e+05, MSE(e): 3.777e-05, MSE(pi1): 5.460e-03, MSE(pi2): 3.433e-05, MSE(pi3): 1.014e-03\n",
      "Epoch 88100, Train loss: 6.151e+02, Test loss: 1.725e+05, MSE(e): 3.728e-05, MSE(pi1): 1.341e-02, MSE(pi2): 3.249e-05, MSE(pi3): 1.081e-03\n",
      "Epoch 88200, Train loss: 4.913e+02, Test loss: 1.719e+05, MSE(e): 3.424e-05, MSE(pi1): 4.497e-03, MSE(pi2): 3.176e-05, MSE(pi3): 1.039e-03\n",
      "Epoch 88300, Train loss: 4.899e+02, Test loss: 1.719e+05, MSE(e): 3.417e-05, MSE(pi1): 4.540e-03, MSE(pi2): 3.174e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 88400, Train loss: 1.278e+03, Test loss: 1.704e+05, MSE(e): 1.105e-04, MSE(pi1): 7.357e-03, MSE(pi2): 6.645e-05, MSE(pi3): 9.939e-04\n",
      "Epoch 88500, Train loss: 4.881e+02, Test loss: 1.719e+05, MSE(e): 3.404e-05, MSE(pi1): 4.445e-03, MSE(pi2): 3.162e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 88600, Train loss: 5.040e+02, Test loss: 1.718e+05, MSE(e): 3.547e-05, MSE(pi1): 4.538e-03, MSE(pi2): 3.238e-05, MSE(pi3): 1.039e-03\n",
      "Epoch 88700, Train loss: 4.923e+02, Test loss: 1.720e+05, MSE(e): 3.412e-05, MSE(pi1): 4.708e-03, MSE(pi2): 3.158e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 88800, Train loss: 4.872e+02, Test loss: 1.719e+05, MSE(e): 3.393e-05, MSE(pi1): 4.503e-03, MSE(pi2): 3.153e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 88900, Train loss: 5.862e+02, Test loss: 1.727e+05, MSE(e): 4.258e-05, MSE(pi1): 5.206e-03, MSE(pi2): 3.517e-05, MSE(pi3): 1.083e-03\n",
      "Epoch 89000, Train loss: 4.894e+02, Test loss: 1.716e+05, MSE(e): 3.411e-05, MSE(pi1): 4.476e-03, MSE(pi2): 3.160e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 89100, Train loss: 4.876e+02, Test loss: 1.717e+05, MSE(e): 3.399e-05, MSE(pi1): 4.498e-03, MSE(pi2): 3.154e-05, MSE(pi3): 1.026e-03\n",
      "Epoch 89200, Train loss: 4.880e+02, Test loss: 1.715e+05, MSE(e): 3.399e-05, MSE(pi1): 4.464e-03, MSE(pi2): 3.152e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 89300, Train loss: 4.888e+02, Test loss: 1.716e+05, MSE(e): 3.396e-05, MSE(pi1): 4.525e-03, MSE(pi2): 3.148e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 89400, Train loss: 4.851e+02, Test loss: 1.720e+05, MSE(e): 3.375e-05, MSE(pi1): 4.439e-03, MSE(pi2): 3.133e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 89500, Train loss: 5.040e+02, Test loss: 1.711e+05, MSE(e): 3.535e-05, MSE(pi1): 4.884e-03, MSE(pi2): 3.219e-05, MSE(pi3): 1.017e-03\n",
      "Epoch 89600, Train loss: 4.895e+02, Test loss: 1.719e+05, MSE(e): 3.399e-05, MSE(pi1): 4.501e-03, MSE(pi2): 3.140e-05, MSE(pi3): 1.046e-03\n",
      "Epoch 89700, Train loss: 5.634e+02, Test loss: 1.707e+05, MSE(e): 4.150e-05, MSE(pi1): 4.672e-03, MSE(pi2): 3.503e-05, MSE(pi3): 1.016e-03\n",
      "Epoch 89800, Train loss: 5.135e+02, Test loss: 1.717e+05, MSE(e): 3.414e-05, MSE(pi1): 7.150e-03, MSE(pi2): 3.126e-05, MSE(pi3): 1.006e-03\n",
      "Epoch 89900, Train loss: 6.933e+02, Test loss: 1.702e+05, MSE(e): 5.399e-05, MSE(pi1): 5.327e-03, MSE(pi2): 4.095e-05, MSE(pi3): 1.000e-03\n",
      "Epoch 90000, Train loss: 5.084e+02, Test loss: 1.718e+05, MSE(e): 3.424e-05, MSE(pi1): 5.813e-03, MSE(pi2): 3.130e-05, MSE(pi3): 1.079e-03\n",
      "Epoch 90100, Train loss: 4.822e+02, Test loss: 1.715e+05, MSE(e): 3.348e-05, MSE(pi1): 4.441e-03, MSE(pi2): 3.112e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 90200, Train loss: 4.823e+02, Test loss: 1.716e+05, MSE(e): 3.346e-05, MSE(pi1): 4.425e-03, MSE(pi2): 3.106e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 90300, Train loss: 6.206e+02, Test loss: 1.728e+05, MSE(e): 4.675e-05, MSE(pi1): 4.835e-03, MSE(pi2): 3.655e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 90400, Train loss: 7.296e+02, Test loss: 1.706e+05, MSE(e): 5.008e-05, MSE(pi1): 1.232e-02, MSE(pi2): 3.767e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 90500, Train loss: 5.857e+02, Test loss: 1.705e+05, MSE(e): 4.375e-05, MSE(pi1): 4.655e-03, MSE(pi2): 3.591e-05, MSE(pi3): 1.016e-03\n",
      "Epoch 90600, Train loss: 6.331e+02, Test loss: 1.705e+05, MSE(e): 4.567e-05, MSE(pi1): 7.605e-03, MSE(pi2): 3.638e-05, MSE(pi3): 1.002e-03\n",
      "Epoch 90700, Train loss: 4.867e+02, Test loss: 1.712e+05, MSE(e): 3.378e-05, MSE(pi1): 4.675e-03, MSE(pi2): 3.121e-05, MSE(pi3): 1.021e-03\n",
      "Epoch 90800, Train loss: 4.928e+02, Test loss: 1.711e+05, MSE(e): 3.387e-05, MSE(pi1): 4.975e-03, MSE(pi2): 3.118e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 90900, Train loss: 4.790e+02, Test loss: 1.714e+05, MSE(e): 3.316e-05, MSE(pi1): 4.449e-03, MSE(pi2): 3.083e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 91000, Train loss: 6.281e+02, Test loss: 1.727e+05, MSE(e): 4.710e-05, MSE(pi1): 5.028e-03, MSE(pi2): 3.701e-05, MSE(pi3): 1.068e-03\n",
      "Epoch 91100, Train loss: 6.022e+02, Test loss: 1.719e+05, MSE(e): 3.753e-05, MSE(pi1): 1.209e-02, MSE(pi2): 3.313e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 91200, Train loss: 4.778e+02, Test loss: 1.713e+05, MSE(e): 3.307e-05, MSE(pi1): 4.402e-03, MSE(pi2): 3.075e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 91300, Train loss: 4.774e+02, Test loss: 1.713e+05, MSE(e): 3.302e-05, MSE(pi1): 4.397e-03, MSE(pi2): 3.069e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 91400, Train loss: 4.852e+02, Test loss: 1.717e+05, MSE(e): 3.377e-05, MSE(pi1): 4.265e-03, MSE(pi2): 3.089e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 91500, Train loss: 4.848e+02, Test loss: 1.710e+05, MSE(e): 3.362e-05, MSE(pi1): 4.564e-03, MSE(pi2): 3.101e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 91600, Train loss: 5.406e+02, Test loss: 1.712e+05, MSE(e): 3.419e-05, MSE(pi1): 9.878e-03, MSE(pi2): 3.083e-05, MSE(pi3): 9.993e-04\n",
      "Epoch 91700, Train loss: 4.812e+02, Test loss: 1.709e+05, MSE(e): 3.341e-05, MSE(pi1): 4.442e-03, MSE(pi2): 3.088e-05, MSE(pi3): 1.026e-03\n",
      "Epoch 91800, Train loss: 4.963e+02, Test loss: 1.717e+05, MSE(e): 3.469e-05, MSE(pi1): 4.119e-03, MSE(pi2): 3.124e-05, MSE(pi3): 1.082e-03\n",
      "Epoch 91900, Train loss: 4.776e+02, Test loss: 1.710e+05, MSE(e): 3.296e-05, MSE(pi1): 4.452e-03, MSE(pi2): 3.061e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 92000, Train loss: 4.800e+02, Test loss: 1.714e+05, MSE(e): 3.310e-05, MSE(pi1): 4.473e-03, MSE(pi2): 3.060e-05, MSE(pi3): 1.042e-03\n",
      "Epoch 92100, Train loss: 5.540e+02, Test loss: 1.718e+05, MSE(e): 3.567e-05, MSE(pi1): 9.086e-03, MSE(pi2): 3.138e-05, MSE(pi3): 1.065e-03\n",
      "Epoch 92200, Train loss: 4.739e+02, Test loss: 1.711e+05, MSE(e): 3.270e-05, MSE(pi1): 4.391e-03, MSE(pi2): 3.042e-05, MSE(pi3): 1.030e-03\n",
      "Epoch 92300, Train loss: 4.834e+02, Test loss: 1.708e+05, MSE(e): 3.353e-05, MSE(pi1): 4.485e-03, MSE(pi2): 3.093e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 92400, Train loss: 5.267e+02, Test loss: 1.716e+05, MSE(e): 3.539e-05, MSE(pi1): 6.313e-03, MSE(pi2): 3.140e-05, MSE(pi3): 1.097e-03\n",
      "Epoch 92500, Train loss: 4.804e+02, Test loss: 1.712e+05, MSE(e): 3.315e-05, MSE(pi1): 4.607e-03, MSE(pi2): 3.045e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 92600, Train loss: 4.951e+02, Test loss: 1.705e+05, MSE(e): 3.380e-05, MSE(pi1): 5.455e-03, MSE(pi2): 3.092e-05, MSE(pi3): 1.025e-03\n",
      "Epoch 92700, Train loss: 5.700e+02, Test loss: 1.721e+05, MSE(e): 4.169e-05, MSE(pi1): 4.605e-03, MSE(pi2): 3.448e-05, MSE(pi3): 1.071e-03\n",
      "Epoch 92800, Train loss: 4.873e+02, Test loss: 1.714e+05, MSE(e): 3.401e-05, MSE(pi1): 4.355e-03, MSE(pi2): 3.079e-05, MSE(pi3): 1.037e-03\n",
      "Epoch 92900, Train loss: 4.941e+02, Test loss: 1.704e+05, MSE(e): 3.466e-05, MSE(pi1): 4.469e-03, MSE(pi2): 3.182e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 93000, Train loss: 4.752e+02, Test loss: 1.707e+05, MSE(e): 3.275e-05, MSE(pi1): 4.390e-03, MSE(pi2): 3.034e-05, MSE(pi3): 1.037e-03\n",
      "Epoch 93100, Train loss: 4.722e+02, Test loss: 1.708e+05, MSE(e): 3.254e-05, MSE(pi1): 4.364e-03, MSE(pi2): 3.023e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 93200, Train loss: 4.736e+02, Test loss: 1.710e+05, MSE(e): 3.256e-05, MSE(pi1): 4.516e-03, MSE(pi2): 3.013e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 93300, Train loss: 6.228e+02, Test loss: 1.695e+05, MSE(e): 4.661e-05, MSE(pi1): 5.718e-03, MSE(pi2): 3.697e-05, MSE(pi3): 9.952e-04\n",
      "Epoch 93400, Train loss: 5.078e+02, Test loss: 1.708e+05, MSE(e): 3.329e-05, MSE(pi1): 7.349e-03, MSE(pi2): 3.016e-05, MSE(pi3): 1.013e-03\n",
      "Epoch 93500, Train loss: 5.240e+02, Test loss: 1.715e+05, MSE(e): 3.625e-05, MSE(pi1): 5.807e-03, MSE(pi2): 3.187e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 93600, Train loss: 5.511e+02, Test loss: 1.713e+05, MSE(e): 3.930e-05, MSE(pi1): 5.584e-03, MSE(pi2): 3.257e-05, MSE(pi3): 1.022e-03\n",
      "Epoch 93700, Train loss: 5.054e+02, Test loss: 1.704e+05, MSE(e): 3.579e-05, MSE(pi1): 4.475e-03, MSE(pi2): 3.174e-05, MSE(pi3): 1.027e-03\n",
      "Epoch 93800, Train loss: 5.908e+02, Test loss: 1.699e+05, MSE(e): 3.728e-05, MSE(pi1): 1.111e-02, MSE(pi2): 3.160e-05, MSE(pi3): 1.069e-03\n",
      "Epoch 93900, Train loss: 5.406e+02, Test loss: 1.701e+05, MSE(e): 3.915e-05, MSE(pi1): 4.746e-03, MSE(pi2): 3.334e-05, MSE(pi3): 1.016e-03\n",
      "Epoch 94000, Train loss: 6.129e+02, Test loss: 1.725e+05, MSE(e): 4.598e-05, MSE(pi1): 4.307e-03, MSE(pi2): 3.857e-05, MSE(pi3): 1.101e-03\n",
      "Epoch 94100, Train loss: 5.181e+02, Test loss: 1.717e+05, MSE(e): 3.626e-05, MSE(pi1): 5.357e-03, MSE(pi2): 3.123e-05, MSE(pi3): 1.018e-03\n",
      "Epoch 94200, Train loss: 4.818e+02, Test loss: 1.710e+05, MSE(e): 3.281e-05, MSE(pi1): 4.802e-03, MSE(pi2): 3.010e-05, MSE(pi3): 1.057e-03\n",
      "Epoch 94300, Train loss: 4.823e+02, Test loss: 1.708e+05, MSE(e): 3.348e-05, MSE(pi1): 4.311e-03, MSE(pi2): 3.036e-05, MSE(pi3): 1.044e-03\n",
      "Epoch 94400, Train loss: 4.948e+02, Test loss: 1.708e+05, MSE(e): 3.429e-05, MSE(pi1): 5.021e-03, MSE(pi2): 3.065e-05, MSE(pi3): 1.016e-03\n",
      "Epoch 94500, Train loss: 4.840e+02, Test loss: 1.702e+05, MSE(e): 3.372e-05, MSE(pi1): 4.466e-03, MSE(pi2): 3.065e-05, MSE(pi3): 1.021e-03\n",
      "Epoch 94600, Train loss: 7.193e+02, Test loss: 1.719e+05, MSE(e): 5.644e-05, MSE(pi1): 4.679e-03, MSE(pi2): 4.030e-05, MSE(pi3): 1.080e-03\n",
      "Epoch 94700, Train loss: 6.309e+02, Test loss: 1.693e+05, MSE(e): 4.805e-05, MSE(pi1): 4.754e-03, MSE(pi2): 3.705e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 94800, Train loss: 5.437e+02, Test loss: 1.699e+05, MSE(e): 3.733e-05, MSE(pi1): 6.445e-03, MSE(pi2): 3.186e-05, MSE(pi3): 1.059e-03\n",
      "Epoch 94900, Train loss: 4.751e+02, Test loss: 1.701e+05, MSE(e): 3.271e-05, MSE(pi1): 4.539e-03, MSE(pi2): 3.007e-05, MSE(pi3): 1.026e-03\n",
      "Epoch 95000, Train loss: 5.561e+02, Test loss: 1.712e+05, MSE(e): 4.092e-05, MSE(pi1): 4.182e-03, MSE(pi2): 3.324e-05, MSE(pi3): 1.051e-03\n",
      "Epoch 95100, Train loss: 4.725e+02, Test loss: 1.704e+05, MSE(e): 3.250e-05, MSE(pi1): 4.439e-03, MSE(pi2): 3.007e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 95200, Train loss: 4.981e+02, Test loss: 1.702e+05, MSE(e): 3.473e-05, MSE(pi1): 4.992e-03, MSE(pi2): 3.110e-05, MSE(pi3): 1.009e-03\n",
      "Epoch 95300, Train loss: 5.120e+02, Test loss: 1.699e+05, MSE(e): 3.379e-05, MSE(pi1): 7.461e-03, MSE(pi2): 3.054e-05, MSE(pi3): 9.945e-04\n",
      "Epoch 95400, Train loss: 4.654e+02, Test loss: 1.704e+05, MSE(e): 3.187e-05, MSE(pi1): 4.302e-03, MSE(pi2): 2.961e-05, MSE(pi3): 1.036e-03\n",
      "Epoch 95500, Train loss: 4.634e+02, Test loss: 1.703e+05, MSE(e): 3.166e-05, MSE(pi1): 4.438e-03, MSE(pi2): 2.946e-05, MSE(pi3): 1.024e-03\n",
      "Epoch 95600, Train loss: 6.868e+02, Test loss: 1.698e+05, MSE(e): 4.856e-05, MSE(pi1): 9.165e-03, MSE(pi2): 3.676e-05, MSE(pi3): 1.096e-03\n",
      "Epoch 95700, Train loss: 4.668e+02, Test loss: 1.701e+05, MSE(e): 3.205e-05, MSE(pi1): 4.345e-03, MSE(pi2): 2.967e-05, MSE(pi3): 1.028e-03\n",
      "Epoch 95800, Train loss: 4.652e+02, Test loss: 1.704e+05, MSE(e): 3.181e-05, MSE(pi1): 4.386e-03, MSE(pi2): 2.954e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 95900, Train loss: 6.488e+02, Test loss: 1.721e+05, MSE(e): 4.964e-05, MSE(pi1): 4.690e-03, MSE(pi2): 3.680e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 96000, Train loss: 5.119e+02, Test loss: 1.705e+05, MSE(e): 3.478e-05, MSE(pi1): 6.198e-03, MSE(pi2): 3.051e-05, MSE(pi3): 1.021e-03\n",
      "Epoch 96100, Train loss: 4.625e+02, Test loss: 1.701e+05, MSE(e): 3.158e-05, MSE(pi1): 4.342e-03, MSE(pi2): 2.935e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 96200, Train loss: 4.671e+02, Test loss: 1.703e+05, MSE(e): 3.188e-05, MSE(pi1): 4.542e-03, MSE(pi2): 2.934e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 96300, Train loss: 4.651e+02, Test loss: 1.702e+05, MSE(e): 3.189e-05, MSE(pi1): 4.318e-03, MSE(pi2): 2.937e-05, MSE(pi3): 1.030e-03\n",
      "Epoch 96400, Train loss: 5.629e+02, Test loss: 1.692e+05, MSE(e): 4.074e-05, MSE(pi1): 5.513e-03, MSE(pi2): 3.375e-05, MSE(pi3): 1.003e-03\n",
      "Epoch 96500, Train loss: 8.420e+02, Test loss: 1.728e+05, MSE(e): 6.586e-05, MSE(pi1): 8.042e-03, MSE(pi2): 4.403e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 96600, Train loss: 4.600e+02, Test loss: 1.695e+05, MSE(e): 3.139e-05, MSE(pi1): 4.324e-03, MSE(pi2): 2.920e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 96700, Train loss: 5.593e+02, Test loss: 1.693e+05, MSE(e): 3.685e-05, MSE(pi1): 8.599e-03, MSE(pi2): 3.120e-05, MSE(pi3): 1.048e-03\n",
      "Epoch 96800, Train loss: 8.493e+02, Test loss: 1.725e+05, MSE(e): 6.916e-05, MSE(pi1): 5.316e-03, MSE(pi2): 4.482e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 96900, Train loss: 5.166e+02, Test loss: 1.693e+05, MSE(e): 3.637e-05, MSE(pi1): 5.111e-03, MSE(pi2): 3.155e-05, MSE(pi3): 1.018e-03\n",
      "Epoch 97000, Train loss: 4.840e+02, Test loss: 1.694e+05, MSE(e): 3.356e-05, MSE(pi1): 4.815e-03, MSE(pi2): 3.072e-05, MSE(pi3): 1.002e-03\n",
      "Epoch 97100, Train loss: 4.576e+02, Test loss: 1.700e+05, MSE(e): 3.111e-05, MSE(pi1): 4.363e-03, MSE(pi2): 2.896e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 97200, Train loss: 4.690e+02, Test loss: 1.703e+05, MSE(e): 3.208e-05, MSE(pi1): 4.365e-03, MSE(pi2): 2.931e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 97300, Train loss: 5.340e+02, Test loss: 1.695e+05, MSE(e): 3.799e-05, MSE(pi1): 4.851e-03, MSE(pi2): 3.387e-05, MSE(pi3): 1.056e-03\n",
      "Epoch 97400, Train loss: 4.572e+02, Test loss: 1.699e+05, MSE(e): 3.103e-05, MSE(pi1): 4.446e-03, MSE(pi2): 2.887e-05, MSE(pi3): 1.023e-03\n",
      "Epoch 97500, Train loss: 4.568e+02, Test loss: 1.698e+05, MSE(e): 3.102e-05, MSE(pi1): 4.299e-03, MSE(pi2): 2.888e-05, MSE(pi3): 1.035e-03\n",
      "Epoch 97600, Train loss: 4.558e+02, Test loss: 1.698e+05, MSE(e): 3.096e-05, MSE(pi1): 4.364e-03, MSE(pi2): 2.884e-05, MSE(pi3): 1.025e-03\n",
      "Epoch 97700, Train loss: 4.848e+02, Test loss: 1.693e+05, MSE(e): 3.362e-05, MSE(pi1): 4.781e-03, MSE(pi2): 3.034e-05, MSE(pi3): 1.007e-03\n",
      "Epoch 97800, Train loss: 4.597e+02, Test loss: 1.702e+05, MSE(e): 3.137e-05, MSE(pi1): 4.264e-03, MSE(pi2): 2.892e-05, MSE(pi3): 1.033e-03\n",
      "Epoch 97900, Train loss: 4.876e+02, Test loss: 1.698e+05, MSE(e): 3.205e-05, MSE(pi1): 6.156e-03, MSE(pi2): 2.912e-05, MSE(pi3): 1.055e-03\n",
      "Epoch 98000, Train loss: 4.593e+02, Test loss: 1.700e+05, MSE(e): 3.134e-05, MSE(pi1): 4.297e-03, MSE(pi2): 2.900e-05, MSE(pi3): 1.029e-03\n",
      "Epoch 98100, Train loss: 4.931e+02, Test loss: 1.701e+05, MSE(e): 3.259e-05, MSE(pi1): 6.241e-03, MSE(pi2): 2.953e-05, MSE(pi3): 1.047e-03\n",
      "Epoch 98200, Train loss: 4.689e+02, Test loss: 1.694e+05, MSE(e): 3.203e-05, MSE(pi1): 4.717e-03, MSE(pi2): 2.935e-05, MSE(pi3): 1.013e-03\n",
      "Epoch 98300, Train loss: 4.876e+02, Test loss: 1.704e+05, MSE(e): 3.346e-05, MSE(pi1): 4.630e-03, MSE(pi2): 2.991e-05, MSE(pi3): 1.066e-03\n",
      "Epoch 98400, Train loss: 4.906e+02, Test loss: 1.704e+05, MSE(e): 3.442e-05, MSE(pi1): 4.206e-03, MSE(pi2): 3.010e-05, MSE(pi3): 1.043e-03\n",
      "Epoch 98500, Train loss: 4.757e+02, Test loss: 1.696e+05, MSE(e): 3.298e-05, MSE(pi1): 4.285e-03, MSE(pi2): 3.011e-05, MSE(pi3): 1.031e-03\n",
      "Epoch 98600, Train loss: 4.664e+02, Test loss: 1.693e+05, MSE(e): 3.173e-05, MSE(pi1): 4.670e-03, MSE(pi2): 2.911e-05, MSE(pi3): 1.023e-03\n",
      "Epoch 98700, Train loss: 4.596e+02, Test loss: 1.698e+05, MSE(e): 3.122e-05, MSE(pi1): 4.326e-03, MSE(pi2): 2.873e-05, MSE(pi3): 1.041e-03\n",
      "Epoch 98800, Train loss: 4.521e+02, Test loss: 1.696e+05, MSE(e): 3.064e-05, MSE(pi1): 4.253e-03, MSE(pi2): 2.853e-05, MSE(pi3): 1.032e-03\n",
      "Epoch 98900, Train loss: 4.534e+02, Test loss: 1.697e+05, MSE(e): 3.077e-05, MSE(pi1): 4.237e-03, MSE(pi2): 2.852e-05, MSE(pi3): 1.033e-03\n",
      "Epoch 99000, Train loss: 4.984e+02, Test loss: 1.691e+05, MSE(e): 3.246e-05, MSE(pi1): 7.031e-03, MSE(pi2): 2.927e-05, MSE(pi3): 1.034e-03\n",
      "Epoch 99100, Train loss: 4.639e+02, Test loss: 1.695e+05, MSE(e): 3.079e-05, MSE(pi1): 5.503e-03, MSE(pi2): 2.842e-05, MSE(pi3): 1.010e-03\n",
      "Epoch 99200, Train loss: 4.512e+02, Test loss: 1.694e+05, MSE(e): 3.056e-05, MSE(pi1): 4.304e-03, MSE(pi2): 2.846e-05, MSE(pi3): 1.026e-03\n",
      "Epoch 99300, Train loss: 4.604e+02, Test loss: 1.695e+05, MSE(e): 3.070e-05, MSE(pi1): 4.998e-03, MSE(pi2): 2.846e-05, MSE(pi3): 1.033e-03\n",
      "Epoch 99400, Train loss: 4.503e+02, Test loss: 1.694e+05, MSE(e): 3.044e-05, MSE(pi1): 4.262e-03, MSE(pi2): 2.835e-05, MSE(pi3): 1.033e-03\n",
      "Epoch 99500, Train loss: 4.797e+02, Test loss: 1.700e+05, MSE(e): 3.336e-05, MSE(pi1): 4.210e-03, MSE(pi2): 2.945e-05, MSE(pi3): 1.040e-03\n",
      "Epoch 99600, Train loss: 4.719e+02, Test loss: 1.688e+05, MSE(e): 3.246e-05, MSE(pi1): 4.272e-03, MSE(pi2): 2.970e-05, MSE(pi3): 1.045e-03\n",
      "Epoch 99700, Train loss: 4.947e+02, Test loss: 1.690e+05, MSE(e): 3.271e-05, MSE(pi1): 6.709e-03, MSE(pi2): 2.947e-05, MSE(pi3): 1.005e-03\n",
      "Epoch 99800, Train loss: 4.483e+02, Test loss: 1.693e+05, MSE(e): 3.030e-05, MSE(pi1): 4.263e-03, MSE(pi2): 2.824e-05, MSE(pi3): 1.027e-03\n",
      "Epoch 99900, Train loss: 4.529e+02, Test loss: 1.696e+05, MSE(e): 3.073e-05, MSE(pi1): 4.227e-03, MSE(pi2): 2.835e-05, MSE(pi3): 1.032e-03\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = 18000\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "second_lr = 3e-4\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
