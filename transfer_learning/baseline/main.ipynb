{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Own library imports\n",
    "from vecopsciml.utils import TensOps\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "\n",
    "# Function from this project\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "# Import model\n",
    "from architectures.pgnniv_baseline import PGNNIVBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning/baseline\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear/sigmoid_nonlinear.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning')\n",
    "\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning/baseline')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_TRANSFERLEARNING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear/sigmoid_nonlinear.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data splitting in train/test\n",
    "X = torch.tensor(dataset['X_train'], dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(dataset['y_train'], dtype=torch.float32).unsqueeze(1)\n",
    "K = torch.tensor(dataset['k_train'], dtype=torch.float32).unsqueeze(1)\n",
    "f = torch.tensor(dataset['f_train'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X, y, K, f, test_size=0.3, random_state=42)\n",
    "\n",
    "# Data processing and adequacy with our TensOps library\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "# Loading and processing validation data\n",
    "X_val = torch.tensor(dataset['X_val'], dtype=torch.float32).unsqueeze(1)\n",
    "y_val = TensOps(torch.tensor(dataset['y_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val'], dtype=torch.float32, requires_grad=True).unsqueeze(1), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 6.968e+08, Test loss: 8.965e+08, MSE(e): 6.961e+01, MSE(pi1): 4.383e+01, MSE(pi2): 2.977e+01, MSE(pi3): 1.933e+00\n",
      "Epoch 100, Train loss: 1.254e+07, Test loss: 1.425e+07, MSE(e): 1.235e+00, MSE(pi1): 1.119e+01, MSE(pi2): 8.481e-01, MSE(pi3): 8.273e-01\n",
      "Epoch 200, Train loss: 1.243e+07, Test loss: 1.374e+07, MSE(e): 1.235e+00, MSE(pi1): 3.436e+00, MSE(pi2): 8.455e-01, MSE(pi3): 4.016e-01\n",
      "Epoch 300, Train loss: 1.238e+07, Test loss: 1.376e+07, MSE(e): 1.230e+00, MSE(pi1): 3.707e+00, MSE(pi2): 8.444e-01, MSE(pi3): 4.182e-01\n",
      "Epoch 400, Train loss: 1.235e+07, Test loss: 1.363e+07, MSE(e): 1.227e+00, MSE(pi1): 3.631e+00, MSE(pi2): 8.439e-01, MSE(pi3): 3.773e-01\n",
      "Epoch 500, Train loss: 1.235e+07, Test loss: 1.361e+07, MSE(e): 1.227e+00, MSE(pi1): 3.635e+00, MSE(pi2): 8.444e-01, MSE(pi3): 4.427e-01\n",
      "Epoch 600, Train loss: 1.234e+07, Test loss: 1.349e+07, MSE(e): 1.227e+00, MSE(pi1): 3.589e+00, MSE(pi2): 8.422e-01, MSE(pi3): 3.808e-01\n",
      "Epoch 700, Train loss: 4.546e+06, Test loss: 6.113e+06, MSE(e): 4.500e-01, MSE(pi1): 2.886e+00, MSE(pi2): 3.069e-01, MSE(pi3): 1.693e-01\n",
      "Epoch 800, Train loss: 4.327e+06, Test loss: 5.836e+06, MSE(e): 4.275e-01, MSE(pi1): 3.289e+00, MSE(pi2): 2.924e-01, MSE(pi3): 1.886e-01\n",
      "Epoch 900, Train loss: 4.265e+06, Test loss: 5.655e+06, MSE(e): 4.211e-01, MSE(pi1): 3.559e+00, MSE(pi2): 2.878e-01, MSE(pi3): 1.839e-01\n",
      "Epoch 1000, Train loss: 9.756e+04, Test loss: 2.627e+05, MSE(e): 8.331e-03, MSE(pi1): 7.825e-01, MSE(pi2): 5.078e-03, MSE(pi3): 6.427e-02\n",
      "Epoch 1100, Train loss: 4.962e+04, Test loss: 1.494e+05, MSE(e): 3.746e-03, MSE(pi1): 7.112e-01, MSE(pi2): 2.297e-03, MSE(pi3): 5.049e-02\n",
      "Epoch 1200, Train loss: 4.650e+04, Test loss: 1.235e+05, MSE(e): 3.602e-03, MSE(pi1): 6.140e-01, MSE(pi2): 2.000e-03, MSE(pi3): 4.334e-02\n",
      "Epoch 1300, Train loss: 4.521e+04, Test loss: 1.250e+05, MSE(e): 3.247e-03, MSE(pi1): 7.067e-01, MSE(pi2): 1.912e-03, MSE(pi3): 5.676e-02\n",
      "Epoch 1400, Train loss: 4.055e+04, Test loss: 9.769e+04, MSE(e): 2.873e-03, MSE(pi1): 7.907e-01, MSE(pi2): 1.602e-03, MSE(pi3): 3.906e-02\n",
      "Epoch 1500, Train loss: 3.947e+04, Test loss: 9.149e+04, MSE(e): 3.060e-03, MSE(pi1): 5.285e-01, MSE(pi2): 1.915e-03, MSE(pi3): 3.577e-02\n",
      "Epoch 1600, Train loss: 2.823e+04, Test loss: 8.946e+04, MSE(e): 1.955e-03, MSE(pi1): 2.827e-01, MSE(pi2): 1.028e-03, MSE(pi3): 5.859e-02\n",
      "Epoch 1700, Train loss: 3.440e+04, Test loss: 9.988e+04, MSE(e): 2.219e-03, MSE(pi1): 6.805e-01, MSE(pi2): 1.109e-03, MSE(pi3): 5.395e-02\n",
      "Epoch 1800, Train loss: 3.214e+04, Test loss: 8.806e+04, MSE(e): 2.230e-03, MSE(pi1): 6.844e-01, MSE(pi2): 1.074e-03, MSE(pi3): 2.989e-02\n",
      "Epoch 1900, Train loss: 2.951e+04, Test loss: 1.894e+05, MSE(e): 1.776e-03, MSE(pi1): 9.103e-01, MSE(pi2): 9.254e-04, MSE(pi3): 2.647e-02\n",
      "Epoch 2000, Train loss: 2.662e+04, Test loss: 8.012e+04, MSE(e): 1.335e-03, MSE(pi1): 1.064e+00, MSE(pi2): 6.406e-04, MSE(pi3): 2.626e-02\n",
      "Epoch 2100, Train loss: 1.736e+04, Test loss: 7.187e+04, MSE(e): 1.171e-03, MSE(pi1): 2.258e-01, MSE(pi2): 5.801e-04, MSE(pi3): 3.390e-02\n",
      "Epoch 2200, Train loss: 7.183e+04, Test loss: 8.966e+04, MSE(e): 6.241e-03, MSE(pi1): 3.626e-01, MSE(pi2): 2.595e-03, MSE(pi3): 5.787e-02\n",
      "Epoch 2300, Train loss: 2.074e+04, Test loss: 7.601e+04, MSE(e): 1.530e-03, MSE(pi1): 3.434e-01, MSE(pi2): 8.837e-04, MSE(pi3): 2.011e-02\n",
      "Epoch 2400, Train loss: 1.897e+04, Test loss: 7.761e+04, MSE(e): 1.169e-03, MSE(pi1): 4.657e-01, MSE(pi2): 5.159e-04, MSE(pi3): 2.621e-02\n",
      "Epoch 2500, Train loss: 6.968e+04, Test loss: 7.057e+04, MSE(e): 5.707e-03, MSE(pi1): 5.635e-01, MSE(pi2): 2.719e-03, MSE(pi3): 6.976e-02\n",
      "Epoch 2600, Train loss: 2.764e+04, Test loss: 1.131e+05, MSE(e): 1.774e-03, MSE(pi1): 8.043e-01, MSE(pi2): 7.862e-04, MSE(pi3): 1.859e-02\n",
      "Epoch 2700, Train loss: 1.858e+04, Test loss: 7.104e+04, MSE(e): 1.235e-03, MSE(pi1): 4.240e-01, MSE(pi2): 7.018e-04, MSE(pi3): 1.993e-02\n",
      "Epoch 2800, Train loss: 4.241e+04, Test loss: 8.464e+04, MSE(e): 3.286e-03, MSE(pi1): 5.886e-01, MSE(pi2): 1.505e-03, MSE(pi3): 3.658e-02\n",
      "Epoch 2900, Train loss: 4.107e+04, Test loss: 6.976e+04, MSE(e): 3.528e-03, MSE(pi1): 4.343e-01, MSE(pi2): 1.854e-03, MSE(pi3): 1.446e-02\n",
      "Epoch 3000, Train loss: 1.109e+04, Test loss: 6.671e+04, MSE(e): 5.596e-04, MSE(pi1): 3.618e-01, MSE(pi2): 3.064e-04, MSE(pi3): 1.874e-02\n",
      "Epoch 3100, Train loss: 5.496e+04, Test loss: 9.661e+04, MSE(e): 4.922e-03, MSE(pi1): 4.826e-01, MSE(pi2): 2.559e-03, MSE(pi3): 9.095e-03\n",
      "Epoch 3200, Train loss: 4.573e+04, Test loss: 7.742e+04, MSE(e): 4.012e-03, MSE(pi1): 4.201e-01, MSE(pi2): 1.943e-03, MSE(pi3): 1.408e-02\n",
      "Epoch 3300, Train loss: 1.027e+04, Test loss: 6.283e+04, MSE(e): 4.611e-04, MSE(pi1): 3.082e-01, MSE(pi2): 2.307e-04, MSE(pi3): 2.579e-02\n",
      "Epoch 3400, Train loss: 9.562e+03, Test loss: 5.175e+04, MSE(e): 5.229e-04, MSE(pi1): 3.021e-01, MSE(pi2): 2.590e-04, MSE(pi3): 1.312e-02\n",
      "Epoch 3500, Train loss: 3.762e+04, Test loss: 7.605e+04, MSE(e): 3.126e-03, MSE(pi1): 5.596e-01, MSE(pi2): 1.733e-03, MSE(pi3): 7.674e-03\n",
      "Epoch 3600, Train loss: 1.118e+04, Test loss: 4.626e+04, MSE(e): 7.902e-04, MSE(pi1): 2.580e-01, MSE(pi2): 3.559e-04, MSE(pi3): 6.956e-03\n",
      "Epoch 3700, Train loss: 7.951e+04, Test loss: 6.520e+04, MSE(e): 7.229e-03, MSE(pi1): 6.390e-01, MSE(pi2): 3.474e-03, MSE(pi3): 8.306e-03\n",
      "Epoch 3800, Train loss: 6.277e+04, Test loss: 6.262e+04, MSE(e): 5.657e-03, MSE(pi1): 5.120e-01, MSE(pi2): 2.663e-03, MSE(pi3): 1.078e-02\n",
      "Epoch 3900, Train loss: 2.921e+04, Test loss: 8.336e+04, MSE(e): 2.219e-03, MSE(pi1): 4.219e-01, MSE(pi2): 1.111e-03, MSE(pi3): 2.802e-02\n",
      "Epoch 4000, Train loss: 8.800e+04, Test loss: 5.245e+04, MSE(e): 8.371e-03, MSE(pi1): 3.565e-01, MSE(pi2): 4.033e-03, MSE(pi3): 7.173e-03\n",
      "Epoch 4100, Train loss: 2.915e+04, Test loss: 5.393e+04, MSE(e): 2.515e-03, MSE(pi1): 3.108e-01, MSE(pi2): 1.311e-03, MSE(pi3): 8.874e-03\n",
      "Epoch 4200, Train loss: 3.112e+04, Test loss: 5.179e+04, MSE(e): 2.747e-03, MSE(pi1): 2.172e-01, MSE(pi2): 1.257e-03, MSE(pi3): 1.481e-02\n",
      "Epoch 4300, Train loss: 4.656e+04, Test loss: 8.852e+04, MSE(e): 4.066e-03, MSE(pi1): 4.976e-01, MSE(pi2): 2.026e-03, MSE(pi3): 9.198e-03\n",
      "Epoch 4400, Train loss: 1.436e+04, Test loss: 9.457e+04, MSE(e): 1.085e-03, MSE(pi1): 2.029e-01, MSE(pi2): 5.792e-04, MSE(pi3): 1.486e-02\n",
      "Epoch 4500, Train loss: 5.460e+04, Test loss: 4.869e+04, MSE(e): 5.023e-03, MSE(pi1): 3.373e-01, MSE(pi2): 2.360e-03, MSE(pi3): 1.001e-02\n",
      "Epoch 4600, Train loss: 8.844e+03, Test loss: 5.388e+04, MSE(e): 3.847e-04, MSE(pi1): 3.130e-01, MSE(pi2): 1.740e-04, MSE(pi3): 1.867e-02\n",
      "Epoch 4700, Train loss: 1.076e+04, Test loss: 5.633e+04, MSE(e): 6.240e-04, MSE(pi1): 2.815e-01, MSE(pi2): 2.718e-04, MSE(pi3): 1.701e-02\n",
      "Epoch 4800, Train loss: 8.009e+03, Test loss: 5.288e+04, MSE(e): 3.258e-04, MSE(pi1): 3.044e-01, MSE(pi2): 1.701e-04, MSE(pi3): 1.706e-02\n",
      "Epoch 4900, Train loss: 1.583e+04, Test loss: 5.344e+04, MSE(e): 1.263e-03, MSE(pi1): 1.760e-01, MSE(pi2): 5.930e-04, MSE(pi3): 1.442e-02\n",
      "Epoch 5000, Train loss: 1.132e+04, Test loss: 5.412e+04, MSE(e): 6.548e-04, MSE(pi1): 3.173e-01, MSE(pi2): 3.465e-04, MSE(pi3): 1.603e-02\n",
      "Epoch 5100, Train loss: 9.930e+03, Test loss: 4.668e+04, MSE(e): 5.079e-04, MSE(pi1): 2.960e-01, MSE(pi2): 2.314e-04, MSE(pi3): 1.890e-02\n",
      "Epoch 5200, Train loss: 1.073e+04, Test loss: 4.170e+04, MSE(e): 6.081e-04, MSE(pi1): 2.933e-01, MSE(pi2): 2.560e-04, MSE(pi3): 1.720e-02\n",
      "Epoch 5300, Train loss: 6.307e+03, Test loss: 4.338e+04, MSE(e): 2.764e-04, MSE(pi1): 1.840e-01, MSE(pi2): 1.379e-04, MSE(pi3): 1.703e-02\n",
      "Epoch 5400, Train loss: 4.406e+04, Test loss: 5.798e+04, MSE(e): 3.820e-03, MSE(pi1): 3.743e-01, MSE(pi2): 1.466e-03, MSE(pi3): 2.115e-02\n",
      "Epoch 5500, Train loss: 1.922e+04, Test loss: 4.513e+04, MSE(e): 1.566e-03, MSE(pi1): 2.695e-01, MSE(pi2): 8.441e-04, MSE(pi3): 8.651e-03\n",
      "Epoch 5600, Train loss: 9.468e+03, Test loss: 4.203e+04, MSE(e): 6.420e-04, MSE(pi1): 1.466e-01, MSE(pi2): 2.875e-04, MSE(pi3): 1.582e-02\n",
      "Epoch 5700, Train loss: 6.531e+03, Test loss: 3.826e+04, MSE(e): 3.098e-04, MSE(pi1): 2.130e-01, MSE(pi2): 1.507e-04, MSE(pi3): 1.303e-02\n",
      "Epoch 5800, Train loss: 3.967e+04, Test loss: 1.157e+05, MSE(e): 3.602e-03, MSE(pi1): 2.939e-01, MSE(pi2): 1.732e-03, MSE(pi3): 7.142e-03\n",
      "Epoch 5900, Train loss: 8.740e+03, Test loss: 4.002e+04, MSE(e): 4.026e-04, MSE(pi1): 3.706e-01, MSE(pi2): 1.796e-04, MSE(pi3): 1.008e-02\n",
      "Epoch 6000, Train loss: 7.053e+03, Test loss: 4.626e+04, MSE(e): 3.014e-04, MSE(pi1): 2.668e-01, MSE(pi2): 1.533e-04, MSE(pi3): 1.371e-02\n",
      "Epoch 6100, Train loss: 8.654e+03, Test loss: 5.265e+04, MSE(e): 3.089e-04, MSE(pi1): 3.455e-01, MSE(pi2): 1.670e-04, MSE(pi3): 2.111e-02\n",
      "Epoch 6200, Train loss: 9.139e+03, Test loss: 4.752e+04, MSE(e): 6.237e-04, MSE(pi1): 1.654e-01, MSE(pi2): 3.812e-04, MSE(pi3): 1.248e-02\n",
      "Epoch 6300, Train loss: 1.022e+04, Test loss: 3.617e+04, MSE(e): 7.563e-04, MSE(pi1): 1.047e-01, MSE(pi2): 3.655e-04, MSE(pi3): 1.612e-02\n",
      "Epoch 6400, Train loss: 1.342e+04, Test loss: 4.316e+04, MSE(e): 9.791e-04, MSE(pi1): 1.844e-01, MSE(pi2): 5.568e-04, MSE(pi3): 1.782e-02\n",
      "Epoch 6500, Train loss: 8.821e+03, Test loss: 3.759e+04, MSE(e): 6.089e-04, MSE(pi1): 1.792e-01, MSE(pi2): 3.531e-04, MSE(pi3): 9.405e-03\n",
      "Epoch 6600, Train loss: 7.707e+03, Test loss: 4.395e+04, MSE(e): 4.411e-04, MSE(pi1): 2.008e-01, MSE(pi2): 2.572e-04, MSE(pi3): 1.288e-02\n",
      "Epoch 6700, Train loss: 7.155e+03, Test loss: 4.513e+04, MSE(e): 4.285e-04, MSE(pi1): 1.334e-01, MSE(pi2): 2.146e-04, MSE(pi3): 1.536e-02\n",
      "Epoch 6800, Train loss: 5.059e+03, Test loss: 3.424e+04, MSE(e): 2.129e-04, MSE(pi1): 1.668e-01, MSE(pi2): 1.120e-04, MSE(pi3): 1.263e-02\n",
      "Epoch 6900, Train loss: 8.443e+03, Test loss: 3.996e+04, MSE(e): 4.032e-04, MSE(pi1): 3.388e-01, MSE(pi2): 2.475e-04, MSE(pi3): 1.024e-02\n",
      "Epoch 7000, Train loss: 2.442e+04, Test loss: 6.286e+04, MSE(e): 2.047e-03, MSE(pi1): 3.259e-01, MSE(pi2): 1.103e-03, MSE(pi3): 6.904e-03\n",
      "Epoch 7100, Train loss: 8.005e+03, Test loss: 3.306e+04, MSE(e): 5.165e-04, MSE(pi1): 2.062e-01, MSE(pi2): 2.936e-04, MSE(pi3): 7.780e-03\n",
      "Epoch 7200, Train loss: 9.442e+03, Test loss: 4.829e+04, MSE(e): 5.211e-04, MSE(pi1): 3.066e-01, MSE(pi2): 2.928e-04, MSE(pi3): 1.165e-02\n",
      "Epoch 7300, Train loss: 1.012e+04, Test loss: 3.558e+04, MSE(e): 8.496e-04, MSE(pi1): 7.283e-02, MSE(pi2): 4.636e-04, MSE(pi3): 8.993e-03\n",
      "Epoch 7400, Train loss: 8.062e+03, Test loss: 3.901e+04, MSE(e): 5.523e-04, MSE(pi1): 1.454e-01, MSE(pi2): 2.960e-04, MSE(pi3): 1.084e-02\n",
      "Epoch 7500, Train loss: 5.048e+03, Test loss: 3.658e+04, MSE(e): 2.837e-04, MSE(pi1): 8.443e-02, MSE(pi2): 1.379e-04, MSE(pi3): 1.367e-02\n",
      "Epoch 7600, Train loss: 6.406e+03, Test loss: 3.382e+04, MSE(e): 2.945e-04, MSE(pi1): 2.225e-01, MSE(pi2): 1.547e-04, MSE(pi3): 1.235e-02\n",
      "Epoch 7700, Train loss: 5.247e+03, Test loss: 4.025e+04, MSE(e): 2.292e-04, MSE(pi1): 1.728e-01, MSE(pi2): 1.254e-04, MSE(pi3): 1.227e-02\n",
      "Epoch 7800, Train loss: 5.683e+03, Test loss: 4.316e+04, MSE(e): 3.029e-04, MSE(pi1): 1.391e-01, MSE(pi2): 1.723e-04, MSE(pi3): 1.262e-02\n",
      "Epoch 7900, Train loss: 9.315e+03, Test loss: 5.498e+04, MSE(e): 6.067e-04, MSE(pi1): 1.851e-01, MSE(pi2): 3.694e-04, MSE(pi3): 1.397e-02\n",
      "Epoch 8000, Train loss: 5.962e+03, Test loss: 3.774e+04, MSE(e): 2.717e-04, MSE(pi1): 2.129e-01, MSE(pi2): 1.679e-04, MSE(pi3): 1.116e-02\n",
      "Epoch 8100, Train loss: 6.565e+03, Test loss: 4.267e+04, MSE(e): 3.013e-04, MSE(pi1): 2.120e-01, MSE(pi2): 1.516e-04, MSE(pi3): 1.432e-02\n",
      "Epoch 8200, Train loss: 4.808e+03, Test loss: 3.461e+04, MSE(e): 2.278e-04, MSE(pi1): 1.677e-01, MSE(pi2): 1.389e-04, MSE(pi3): 8.531e-03\n",
      "Epoch 8300, Train loss: 7.198e+03, Test loss: 3.645e+04, MSE(e): 3.425e-04, MSE(pi1): 2.904e-01, MSE(pi2): 1.959e-04, MSE(pi3): 8.692e-03\n",
      "Epoch 8400, Train loss: 4.044e+03, Test loss: 3.091e+04, MSE(e): 1.933e-04, MSE(pi1): 1.015e-01, MSE(pi2): 9.994e-05, MSE(pi3): 1.097e-02\n",
      "Epoch 8500, Train loss: 5.374e+03, Test loss: 3.505e+04, MSE(e): 2.386e-04, MSE(pi1): 1.937e-01, MSE(pi2): 1.465e-04, MSE(pi3): 1.050e-02\n",
      "Epoch 8600, Train loss: 9.202e+03, Test loss: 4.596e+04, MSE(e): 4.027e-04, MSE(pi1): 3.785e-01, MSE(pi2): 2.186e-04, MSE(pi3): 1.389e-02\n",
      "Epoch 8700, Train loss: 5.453e+03, Test loss: 4.211e+04, MSE(e): 2.028e-04, MSE(pi1): 2.329e-01, MSE(pi2): 1.217e-04, MSE(pi3): 1.095e-02\n",
      "Epoch 8800, Train loss: 8.018e+03, Test loss: 3.862e+04, MSE(e): 5.106e-04, MSE(pi1): 1.752e-01, MSE(pi2): 2.402e-04, MSE(pi3): 1.160e-02\n",
      "Epoch 8900, Train loss: 6.944e+03, Test loss: 3.293e+04, MSE(e): 4.258e-04, MSE(pi1): 1.668e-01, MSE(pi2): 2.189e-04, MSE(pi3): 1.018e-02\n",
      "Epoch 9000, Train loss: 4.466e+03, Test loss: 3.478e+04, MSE(e): 2.072e-04, MSE(pi1): 1.332e-01, MSE(pi2): 1.080e-04, MSE(pi3): 1.062e-02\n",
      "Epoch 9100, Train loss: 6.348e+03, Test loss: 3.172e+04, MSE(e): 3.520e-04, MSE(pi1): 1.729e-01, MSE(pi2): 1.926e-04, MSE(pi3): 1.098e-02\n",
      "Epoch 9200, Train loss: 7.586e+03, Test loss: 3.505e+04, MSE(e): 5.107e-04, MSE(pi1): 1.603e-01, MSE(pi2): 2.612e-04, MSE(pi3): 8.762e-03\n",
      "Epoch 9300, Train loss: 8.999e+03, Test loss: 3.799e+04, MSE(e): 7.038e-04, MSE(pi1): 1.142e-01, MSE(pi2): 3.724e-04, MSE(pi3): 8.182e-03\n",
      "Epoch 9400, Train loss: 9.995e+03, Test loss: 5.442e+04, MSE(e): 5.296e-04, MSE(pi1): 3.026e-01, MSE(pi2): 2.831e-04, MSE(pi3): 1.673e-02\n",
      "Epoch 9500, Train loss: 7.612e+03, Test loss: 4.178e+04, MSE(e): 5.192e-04, MSE(pi1): 1.483e-01, MSE(pi2): 2.761e-04, MSE(pi3): 9.366e-03\n",
      "Epoch 9600, Train loss: 7.694e+03, Test loss: 4.943e+04, MSE(e): 3.540e-04, MSE(pi1): 2.961e-01, MSE(pi2): 1.940e-04, MSE(pi3): 1.194e-02\n",
      "Epoch 9700, Train loss: 8.942e+03, Test loss: 3.413e+04, MSE(e): 6.782e-04, MSE(pi1): 1.305e-01, MSE(pi2): 3.423e-04, MSE(pi3): 8.545e-03\n",
      "Epoch 9800, Train loss: 7.993e+03, Test loss: 4.000e+04, MSE(e): 5.918e-04, MSE(pi1): 1.035e-01, MSE(pi2): 2.639e-04, MSE(pi3): 1.040e-02\n",
      "Epoch 9900, Train loss: 6.551e+03, Test loss: 3.111e+04, MSE(e): 4.361e-04, MSE(pi1): 1.411e-01, MSE(pi2): 2.349e-04, MSE(pi3): 7.782e-03\n",
      "Epoch 10000, Train loss: 5.561e+03, Test loss: 2.947e+04, MSE(e): 2.753e-04, MSE(pi1): 1.700e-01, MSE(pi2): 1.621e-04, MSE(pi3): 1.107e-02\n",
      "Epoch 10100, Train loss: 5.445e+04, Test loss: 4.468e+04, MSE(e): 5.226e-03, MSE(pi1): 1.501e-01, MSE(pi2): 2.465e-03, MSE(pi3): 6.839e-03\n",
      "Epoch 10200, Train loss: 4.996e+03, Test loss: 3.010e+04, MSE(e): 2.358e-04, MSE(pi1): 1.866e-01, MSE(pi2): 1.326e-04, MSE(pi3): 7.714e-03\n",
      "Epoch 10300, Train loss: 1.696e+04, Test loss: 3.483e+04, MSE(e): 1.532e-03, MSE(pi1): 6.959e-02, MSE(pi2): 7.282e-04, MSE(pi3): 9.377e-03\n",
      "Epoch 10400, Train loss: 1.823e+04, Test loss: 3.745e+04, MSE(e): 1.492e-03, MSE(pi1): 2.014e-01, MSE(pi2): 5.869e-04, MSE(pi3): 1.296e-02\n",
      "Epoch 10500, Train loss: 4.245e+03, Test loss: 3.000e+04, MSE(e): 2.066e-04, MSE(pi1): 1.410e-01, MSE(pi2): 1.128e-04, MSE(pi3): 7.684e-03\n",
      "Epoch 10600, Train loss: 8.234e+03, Test loss: 5.027e+04, MSE(e): 4.995e-04, MSE(pi1): 2.076e-01, MSE(pi2): 2.793e-04, MSE(pi3): 1.162e-02\n",
      "Epoch 10700, Train loss: 5.685e+03, Test loss: 4.469e+04, MSE(e): 3.189e-04, MSE(pi1): 1.872e-01, MSE(pi2): 1.802e-04, MSE(pi3): 6.234e-03\n",
      "Epoch 10800, Train loss: 1.651e+04, Test loss: 3.018e+04, MSE(e): 1.435e-03, MSE(pi1): 8.624e-02, MSE(pi2): 5.699e-04, MSE(pi3): 1.301e-02\n",
      "Epoch 10900, Train loss: 1.807e+04, Test loss: 3.279e+04, MSE(e): 1.594e-03, MSE(pi1): 9.891e-02, MSE(pi2): 6.339e-04, MSE(pi3): 1.144e-02\n",
      "Epoch 11000, Train loss: 4.419e+03, Test loss: 2.574e+04, MSE(e): 2.321e-04, MSE(pi1): 1.222e-01, MSE(pi2): 1.167e-04, MSE(pi3): 8.768e-03\n",
      "Epoch 11100, Train loss: 2.195e+04, Test loss: 3.544e+04, MSE(e): 1.915e-03, MSE(pi1): 1.547e-01, MSE(pi2): 7.534e-04, MSE(pi3): 1.249e-02\n",
      "Epoch 11200, Train loss: 1.067e+04, Test loss: 3.343e+04, MSE(e): 7.988e-04, MSE(pi1): 1.325e-01, MSE(pi2): 3.240e-04, MSE(pi3): 1.354e-02\n",
      "Epoch 11300, Train loss: 5.920e+03, Test loss: 5.142e+04, MSE(e): 3.526e-04, MSE(pi1): 1.754e-01, MSE(pi2): 1.991e-04, MSE(pi3): 6.400e-03\n",
      "Epoch 11400, Train loss: 4.821e+03, Test loss: 3.105e+04, MSE(e): 2.480e-04, MSE(pi1): 1.603e-01, MSE(pi2): 1.411e-04, MSE(pi3): 7.377e-03\n",
      "Epoch 11500, Train loss: 5.245e+03, Test loss: 2.690e+04, MSE(e): 3.090e-04, MSE(pi1): 1.262e-01, MSE(pi2): 1.284e-04, MSE(pi3): 8.935e-03\n",
      "Epoch 11600, Train loss: 5.481e+03, Test loss: 2.992e+04, MSE(e): 2.485e-04, MSE(pi1): 2.156e-01, MSE(pi2): 1.132e-04, MSE(pi3): 8.394e-03\n",
      "Epoch 11700, Train loss: 4.610e+03, Test loss: 2.817e+04, MSE(e): 2.875e-04, MSE(pi1): 9.201e-02, MSE(pi2): 1.589e-04, MSE(pi3): 8.147e-03\n",
      "Epoch 11800, Train loss: 4.032e+03, Test loss: 3.079e+04, MSE(e): 1.793e-04, MSE(pi1): 1.330e-01, MSE(pi2): 7.874e-05, MSE(pi3): 9.085e-03\n",
      "Epoch 11900, Train loss: 4.912e+03, Test loss: 2.882e+04, MSE(e): 2.569e-04, MSE(pi1): 1.493e-01, MSE(pi2): 1.025e-04, MSE(pi3): 8.501e-03\n",
      "Epoch 12000, Train loss: 4.963e+03, Test loss: 2.783e+04, MSE(e): 3.032e-04, MSE(pi1): 7.193e-02, MSE(pi2): 1.327e-04, MSE(pi3): 1.211e-02\n",
      "Epoch 12100, Train loss: 3.569e+03, Test loss: 2.708e+04, MSE(e): 1.723e-04, MSE(pi1): 8.291e-02, MSE(pi2): 8.317e-05, MSE(pi3): 1.017e-02\n",
      "Epoch 12200, Train loss: 3.407e+03, Test loss: 2.363e+04, MSE(e): 2.059e-04, MSE(pi1): 4.558e-02, MSE(pi2): 9.449e-05, MSE(pi3): 8.918e-03\n",
      "Epoch 12300, Train loss: 2.100e+04, Test loss: 3.325e+04, MSE(e): 1.754e-03, MSE(pi1): 2.299e-01, MSE(pi2): 7.789e-04, MSE(pi3): 1.165e-02\n",
      "Epoch 12400, Train loss: 4.363e+03, Test loss: 3.023e+04, MSE(e): 2.303e-04, MSE(pi1): 1.189e-01, MSE(pi2): 1.258e-04, MSE(pi3): 8.716e-03\n",
      "Epoch 12500, Train loss: 4.117e+03, Test loss: 3.071e+04, MSE(e): 2.101e-04, MSE(pi1): 1.130e-01, MSE(pi2): 1.263e-04, MSE(pi3): 8.865e-03\n",
      "Epoch 12600, Train loss: 3.623e+03, Test loss: 2.753e+04, MSE(e): 1.615e-04, MSE(pi1): 1.206e-01, MSE(pi2): 6.805e-05, MSE(pi3): 8.013e-03\n",
      "Epoch 12700, Train loss: 8.526e+03, Test loss: 2.459e+04, MSE(e): 6.772e-04, MSE(pi1): 1.083e-01, MSE(pi2): 3.491e-04, MSE(pi3): 6.712e-03\n",
      "Epoch 12800, Train loss: 7.486e+03, Test loss: 2.712e+04, MSE(e): 5.258e-04, MSE(pi1): 1.170e-01, MSE(pi2): 2.278e-04, MSE(pi3): 1.058e-02\n",
      "Epoch 12900, Train loss: 9.098e+03, Test loss: 3.104e+04, MSE(e): 6.388e-04, MSE(pi1): 2.113e-01, MSE(pi2): 3.700e-04, MSE(pi3): 5.962e-03\n",
      "Epoch 13000, Train loss: 7.387e+03, Test loss: 3.014e+04, MSE(e): 5.246e-04, MSE(pi1): 9.696e-02, MSE(pi2): 2.307e-04, MSE(pi3): 1.171e-02\n",
      "Epoch 13100, Train loss: 6.132e+03, Test loss: 3.822e+04, MSE(e): 4.246e-04, MSE(pi1): 9.622e-02, MSE(pi2): 1.900e-04, MSE(pi3): 9.236e-03\n",
      "Epoch 13200, Train loss: 1.057e+04, Test loss: 2.957e+04, MSE(e): 7.926e-04, MSE(pi1): 2.096e-01, MSE(pi2): 4.529e-04, MSE(pi3): 5.429e-03\n",
      "Epoch 13300, Train loss: 4.164e+03, Test loss: 2.493e+04, MSE(e): 2.280e-04, MSE(pi1): 9.601e-02, MSE(pi2): 9.761e-05, MSE(pi3): 9.239e-03\n",
      "Epoch 13400, Train loss: 2.845e+04, Test loss: 3.077e+04, MSE(e): 2.666e-03, MSE(pi1): 1.197e-01, MSE(pi2): 1.238e-03, MSE(pi3): 5.909e-03\n",
      "Epoch 13500, Train loss: 3.514e+03, Test loss: 2.779e+04, MSE(e): 1.556e-04, MSE(pi1): 1.078e-01, MSE(pi2): 8.596e-05, MSE(pi3): 8.790e-03\n",
      "Epoch 13600, Train loss: 2.753e+04, Test loss: 2.798e+04, MSE(e): 2.539e-03, MSE(pi1): 1.640e-01, MSE(pi2): 1.282e-03, MSE(pi3): 4.984e-03\n",
      "Epoch 13700, Train loss: 5.436e+04, Test loss: 2.891e+04, MSE(e): 5.123e-03, MSE(pi1): 2.618e-01, MSE(pi2): 2.382e-03, MSE(pi3): 5.104e-03\n",
      "Epoch 13800, Train loss: 4.517e+03, Test loss: 2.727e+04, MSE(e): 2.831e-04, MSE(pi1): 7.360e-02, MSE(pi2): 1.095e-04, MSE(pi3): 9.502e-03\n",
      "Epoch 13900, Train loss: 1.133e+04, Test loss: 6.630e+04, MSE(e): 9.675e-04, MSE(pi1): 1.007e-01, MSE(pi2): 5.444e-04, MSE(pi3): 6.480e-03\n",
      "Epoch 14000, Train loss: 4.705e+03, Test loss: 3.145e+04, MSE(e): 2.102e-04, MSE(pi1): 1.455e-01, MSE(pi2): 9.664e-05, MSE(pi3): 1.148e-02\n",
      "Epoch 14100, Train loss: 3.195e+03, Test loss: 2.514e+04, MSE(e): 1.703e-04, MSE(pi1): 6.054e-02, MSE(pi2): 7.515e-05, MSE(pi3): 8.868e-03\n",
      "Epoch 14200, Train loss: 2.346e+04, Test loss: 2.875e+04, MSE(e): 2.130e-03, MSE(pi1): 1.592e-01, MSE(pi2): 1.074e-03, MSE(pi3): 5.688e-03\n",
      "Epoch 14300, Train loss: 2.822e+03, Test loss: 2.367e+04, MSE(e): 1.400e-04, MSE(pi1): 6.853e-02, MSE(pi2): 6.690e-05, MSE(pi3): 7.371e-03\n",
      "Epoch 14400, Train loss: 3.229e+03, Test loss: 2.537e+04, MSE(e): 1.505e-04, MSE(pi1): 9.553e-02, MSE(pi2): 8.014e-05, MSE(pi3): 7.687e-03\n",
      "Epoch 14500, Train loss: 3.926e+03, Test loss: 2.756e+04, MSE(e): 1.731e-04, MSE(pi1): 1.343e-01, MSE(pi2): 8.007e-05, MSE(pi3): 8.517e-03\n",
      "Epoch 14600, Train loss: 1.595e+04, Test loss: 4.511e+04, MSE(e): 1.406e-03, MSE(pi1): 8.742e-02, MSE(pi2): 6.111e-04, MSE(pi3): 1.017e-02\n",
      "Epoch 14700, Train loss: 4.074e+03, Test loss: 2.286e+04, MSE(e): 2.491e-04, MSE(pi1): 9.438e-02, MSE(pi2): 1.381e-04, MSE(pi3): 6.392e-03\n",
      "Epoch 14800, Train loss: 3.733e+03, Test loss: 2.528e+04, MSE(e): 1.760e-04, MSE(pi1): 1.278e-01, MSE(pi2): 1.033e-04, MSE(pi3): 6.939e-03\n",
      "Epoch 14900, Train loss: 1.673e+04, Test loss: 3.002e+04, MSE(e): 1.541e-03, MSE(pi1): 7.266e-02, MSE(pi2): 7.104e-04, MSE(pi3): 5.930e-03\n",
      "Epoch 15000, Train loss: 3.033e+03, Test loss: 2.531e+04, MSE(e): 1.295e-04, MSE(pi1): 9.743e-02, MSE(pi2): 6.977e-05, MSE(pi3): 7.638e-03\n",
      "Epoch 15100, Train loss: 3.301e+03, Test loss: 2.224e+04, MSE(e): 1.996e-04, MSE(pi1): 6.656e-02, MSE(pi2): 1.199e-04, MSE(pi3): 6.392e-03\n",
      "Epoch 15200, Train loss: 3.039e+03, Test loss: 2.903e+04, MSE(e): 1.707e-04, MSE(pi1): 3.729e-02, MSE(pi2): 8.075e-05, MSE(pi3): 9.582e-03\n",
      "Epoch 15300, Train loss: 5.450e+03, Test loss: 2.879e+04, MSE(e): 3.338e-04, MSE(pi1): 1.271e-01, MSE(pi2): 1.596e-04, MSE(pi3): 8.406e-03\n",
      "Epoch 15400, Train loss: 8.256e+03, Test loss: 2.864e+04, MSE(e): 5.750e-04, MSE(pi1): 1.824e-01, MSE(pi2): 3.130e-04, MSE(pi3): 6.819e-03\n",
      "Epoch 15500, Train loss: 5.756e+03, Test loss: 2.893e+04, MSE(e): 4.052e-04, MSE(pi1): 8.723e-02, MSE(pi2): 2.019e-04, MSE(pi3): 8.316e-03\n",
      "Epoch 15600, Train loss: 2.691e+03, Test loss: 2.355e+04, MSE(e): 1.238e-04, MSE(pi1): 6.986e-02, MSE(pi2): 6.815e-05, MSE(pi3): 7.538e-03\n",
      "Epoch 15700, Train loss: 4.358e+04, Test loss: 5.069e+04, MSE(e): 4.023e-03, MSE(pi1): 2.831e-01, MSE(pi2): 1.903e-03, MSE(pi3): 5.105e-03\n",
      "Epoch 15800, Train loss: 6.237e+03, Test loss: 2.505e+04, MSE(e): 4.044e-04, MSE(pi1): 1.506e-01, MSE(pi2): 2.038e-04, MSE(pi3): 6.875e-03\n",
      "Epoch 15900, Train loss: 1.856e+04, Test loss: 2.072e+04, MSE(e): 1.708e-03, MSE(pi1): 8.946e-02, MSE(pi2): 8.006e-04, MSE(pi3): 5.878e-03\n",
      "Epoch 16000, Train loss: 3.605e+03, Test loss: 2.884e+04, MSE(e): 1.723e-04, MSE(pi1): 1.009e-01, MSE(pi2): 8.872e-05, MSE(pi3): 8.725e-03\n",
      "Epoch 16100, Train loss: 2.842e+03, Test loss: 2.310e+04, MSE(e): 1.495e-04, MSE(pi1): 6.201e-02, MSE(pi2): 9.009e-05, MSE(pi3): 7.262e-03\n",
      "Epoch 16200, Train loss: 4.174e+03, Test loss: 2.360e+04, MSE(e): 2.641e-04, MSE(pi1): 8.271e-02, MSE(pi2): 1.017e-04, MSE(pi3): 7.066e-03\n",
      "Epoch 16300, Train loss: 7.548e+03, Test loss: 2.412e+04, MSE(e): 6.097e-04, MSE(pi1): 5.360e-02, MSE(pi2): 2.608e-04, MSE(pi3): 9.143e-03\n",
      "Epoch 16400, Train loss: 3.666e+03, Test loss: 3.330e+04, MSE(e): 1.490e-04, MSE(pi1): 1.402e-01, MSE(pi2): 7.779e-05, MSE(pi3): 7.739e-03\n",
      "Epoch 16500, Train loss: 3.925e+03, Test loss: 2.945e+04, MSE(e): 1.870e-04, MSE(pi1): 1.037e-01, MSE(pi2): 8.408e-05, MSE(pi3): 1.017e-02\n",
      "Epoch 16600, Train loss: 6.672e+03, Test loss: 2.536e+04, MSE(e): 5.332e-04, MSE(pi1): 5.153e-02, MSE(pi2): 2.133e-04, MSE(pi3): 8.253e-03\n",
      "Epoch 16700, Train loss: 3.671e+03, Test loss: 2.658e+04, MSE(e): 1.722e-04, MSE(pi1): 1.019e-01, MSE(pi2): 8.249e-05, MSE(pi3): 9.296e-03\n",
      "Epoch 16800, Train loss: 3.013e+03, Test loss: 2.475e+04, MSE(e): 1.351e-04, MSE(pi1): 8.223e-02, MSE(pi2): 6.557e-05, MSE(pi3): 8.398e-03\n",
      "Epoch 16900, Train loss: 2.839e+03, Test loss: 2.220e+04, MSE(e): 1.866e-04, MSE(pi1): 2.832e-02, MSE(pi2): 1.120e-04, MSE(pi3): 6.896e-03\n",
      "Epoch 17000, Train loss: 8.107e+03, Test loss: 3.223e+04, MSE(e): 5.884e-04, MSE(pi1): 1.384e-01, MSE(pi2): 2.103e-04, MSE(pi3): 8.392e-03\n",
      "Epoch 17100, Train loss: 3.985e+03, Test loss: 3.119e+04, MSE(e): 2.353e-04, MSE(pi1): 8.908e-02, MSE(pi2): 1.131e-04, MSE(pi3): 7.414e-03\n",
      "Epoch 17200, Train loss: 5.727e+03, Test loss: 2.265e+04, MSE(e): 4.207e-04, MSE(pi1): 8.020e-02, MSE(pi2): 2.032e-04, MSE(pi3): 7.176e-03\n",
      "Epoch 17300, Train loss: 6.067e+03, Test loss: 2.985e+04, MSE(e): 3.735e-04, MSE(pi1): 1.378e-01, MSE(pi2): 1.830e-04, MSE(pi3): 9.548e-03\n",
      "Epoch 17400, Train loss: 3.750e+03, Test loss: 3.110e+04, MSE(e): 2.042e-04, MSE(pi1): 9.660e-02, MSE(pi2): 8.782e-05, MSE(pi3): 7.416e-03\n",
      "Epoch 17500, Train loss: 3.086e+03, Test loss: 2.489e+04, MSE(e): 1.358e-04, MSE(pi1): 1.052e-01, MSE(pi2): 6.995e-05, MSE(pi3): 6.757e-03\n",
      "Epoch 17600, Train loss: 7.605e+03, Test loss: 2.478e+04, MSE(e): 5.898e-04, MSE(pi1): 9.758e-02, MSE(pi2): 2.725e-04, MSE(pi3): 7.313e-03\n",
      "Epoch 17700, Train loss: 6.536e+03, Test loss: 2.521e+04, MSE(e): 4.785e-04, MSE(pi1): 1.135e-01, MSE(pi2): 2.369e-04, MSE(pi3): 6.154e-03\n",
      "Epoch 17800, Train loss: 7.811e+03, Test loss: 2.800e+04, MSE(e): 5.424e-04, MSE(pi1): 1.534e-01, MSE(pi2): 2.474e-04, MSE(pi3): 8.533e-03\n",
      "Epoch 17900, Train loss: 5.963e+03, Test loss: 2.395e+04, MSE(e): 4.593e-04, MSE(pi1): 6.511e-02, MSE(pi2): 2.175e-04, MSE(pi3): 7.192e-03\n",
      "Epoch 18000, Train loss: 5.792e+03, Test loss: 2.550e+04, MSE(e): 4.315e-04, MSE(pi1): 8.730e-02, MSE(pi2): 2.386e-04, MSE(pi3): 6.033e-03\n",
      "Epoch 18100, Train loss: 2.863e+03, Test loss: 2.692e+04, MSE(e): 1.116e-04, MSE(pi1): 1.058e-01, MSE(pi2): 5.768e-05, MSE(pi3): 6.889e-03\n",
      "Epoch 18200, Train loss: 3.709e+03, Test loss: 3.357e+04, MSE(e): 1.845e-04, MSE(pi1): 9.977e-02, MSE(pi2): 1.113e-04, MSE(pi3): 8.662e-03\n",
      "Epoch 18300, Train loss: 3.051e+03, Test loss: 2.426e+04, MSE(e): 1.564e-04, MSE(pi1): 7.211e-02, MSE(pi2): 8.708e-05, MSE(pi3): 7.658e-03\n",
      "Epoch 18400, Train loss: 4.119e+03, Test loss: 2.430e+04, MSE(e): 2.437e-04, MSE(pi1): 9.253e-02, MSE(pi2): 1.232e-04, MSE(pi3): 7.561e-03\n",
      "Epoch 18500, Train loss: 4.180e+03, Test loss: 2.515e+04, MSE(e): 2.580e-04, MSE(pi1): 9.805e-02, MSE(pi2): 1.425e-04, MSE(pi3): 6.194e-03\n",
      "Epoch 18600, Train loss: 5.598e+03, Test loss: 2.554e+04, MSE(e): 4.339e-04, MSE(pi1): 6.487e-02, MSE(pi2): 2.080e-04, MSE(pi3): 6.098e-03\n",
      "Epoch 18700, Train loss: 6.235e+03, Test loss: 2.548e+04, MSE(e): 4.815e-04, MSE(pi1): 6.608e-02, MSE(pi2): 2.312e-04, MSE(pi3): 7.589e-03\n",
      "Epoch 18800, Train loss: 7.734e+03, Test loss: 2.534e+04, MSE(e): 6.031e-04, MSE(pi1): 9.708e-02, MSE(pi2): 2.626e-04, MSE(pi3): 7.318e-03\n",
      "Epoch 18900, Train loss: 6.521e+03, Test loss: 2.566e+04, MSE(e): 5.224e-04, MSE(pi1): 5.931e-02, MSE(pi2): 2.534e-04, MSE(pi3): 7.042e-03\n",
      "Epoch 19000, Train loss: 6.565e+03, Test loss: 3.637e+04, MSE(e): 5.110e-04, MSE(pi1): 5.659e-02, MSE(pi2): 2.795e-04, MSE(pi3): 8.887e-03\n",
      "Epoch 19100, Train loss: 2.271e+04, Test loss: 4.587e+04, MSE(e): 2.021e-03, MSE(pi1): 2.001e-01, MSE(pi2): 9.925e-04, MSE(pi3): 5.002e-03\n",
      "Epoch 19200, Train loss: 2.852e+03, Test loss: 2.593e+04, MSE(e): 1.306e-04, MSE(pi1): 8.345e-02, MSE(pi2): 7.679e-05, MSE(pi3): 7.112e-03\n",
      "Epoch 19300, Train loss: 3.811e+03, Test loss: 2.646e+04, MSE(e): 1.579e-04, MSE(pi1): 1.316e-01, MSE(pi2): 8.132e-05, MSE(pi3): 9.155e-03\n",
      "Epoch 19400, Train loss: 2.604e+03, Test loss: 2.717e+04, MSE(e): 1.192e-04, MSE(pi1): 6.374e-02, MSE(pi2): 5.998e-05, MSE(pi3): 7.738e-03\n",
      "Epoch 19500, Train loss: 1.206e+04, Test loss: 4.419e+04, MSE(e): 9.960e-04, MSE(pi1): 1.593e-01, MSE(pi2): 5.760e-04, MSE(pi3): 5.116e-03\n",
      "Epoch 19600, Train loss: 3.636e+03, Test loss: 2.437e+04, MSE(e): 1.897e-04, MSE(pi1): 8.892e-02, MSE(pi2): 9.799e-05, MSE(pi3): 8.498e-03\n",
      "Epoch 19700, Train loss: 3.643e+03, Test loss: 2.328e+04, MSE(e): 1.671e-04, MSE(pi1): 1.316e-01, MSE(pi2): 7.334e-05, MSE(pi3): 6.570e-03\n",
      "Epoch 19800, Train loss: 4.311e+03, Test loss: 2.861e+04, MSE(e): 2.396e-04, MSE(pi1): 1.089e-01, MSE(pi2): 1.150e-04, MSE(pi3): 8.263e-03\n",
      "Epoch 19900, Train loss: 3.500e+04, Test loss: 2.718e+04, MSE(e): 3.332e-03, MSE(pi1): 1.143e-01, MSE(pi2): 1.542e-03, MSE(pi3): 5.298e-03\n",
      "Epoch 20000, Train loss: 4.114e+03, Test loss: 2.350e+04, MSE(e): 2.605e-04, MSE(pi1): 6.551e-02, MSE(pi2): 1.148e-04, MSE(pi3): 8.534e-03\n",
      "Epoch 20100, Train loss: 1.335e+04, Test loss: 2.799e+04, MSE(e): 1.152e-03, MSE(pi1): 8.225e-02, MSE(pi2): 4.757e-04, MSE(pi3): 1.004e-02\n",
      "Epoch 20200, Train loss: 1.504e+04, Test loss: 3.245e+04, MSE(e): 1.272e-03, MSE(pi1): 1.294e-01, MSE(pi2): 5.641e-04, MSE(pi3): 1.020e-02\n",
      "Epoch 20300, Train loss: 3.471e+03, Test loss: 2.358e+04, MSE(e): 2.247e-04, MSE(pi1): 5.212e-02, MSE(pi2): 1.050e-04, MSE(pi3): 7.031e-03\n",
      "Epoch 20400, Train loss: 6.483e+03, Test loss: 2.937e+04, MSE(e): 4.637e-04, MSE(pi1): 1.246e-01, MSE(pi2): 2.678e-04, MSE(pi3): 5.998e-03\n",
      "Epoch 20500, Train loss: 4.701e+03, Test loss: 2.442e+04, MSE(e): 2.734e-04, MSE(pi1): 1.305e-01, MSE(pi2): 1.012e-04, MSE(pi3): 6.625e-03\n",
      "Epoch 20600, Train loss: 8.078e+03, Test loss: 5.112e+04, MSE(e): 6.124e-04, MSE(pi1): 1.423e-01, MSE(pi2): 3.256e-04, MSE(pi3): 5.303e-03\n",
      "Epoch 20700, Train loss: 3.204e+03, Test loss: 2.091e+04, MSE(e): 1.966e-04, MSE(pi1): 5.389e-02, MSE(pi2): 7.847e-05, MSE(pi3): 6.991e-03\n",
      "Epoch 20800, Train loss: 2.756e+03, Test loss: 2.159e+04, MSE(e): 1.190e-04, MSE(pi1): 9.893e-02, MSE(pi2): 7.399e-05, MSE(pi3): 5.767e-03\n",
      "Epoch 20900, Train loss: 7.888e+03, Test loss: 2.761e+04, MSE(e): 5.758e-04, MSE(pi1): 1.584e-01, MSE(pi2): 3.246e-04, MSE(pi3): 5.464e-03\n",
      "Epoch 21000, Train loss: 3.796e+03, Test loss: 2.610e+04, MSE(e): 1.729e-04, MSE(pi1): 1.469e-01, MSE(pi2): 1.012e-04, MSE(pi3): 5.972e-03\n",
      "Epoch 21100, Train loss: 5.807e+03, Test loss: 2.203e+04, MSE(e): 4.286e-04, MSE(pi1): 8.124e-02, MSE(pi2): 1.958e-04, MSE(pi3): 7.086e-03\n",
      "Epoch 21200, Train loss: 4.884e+03, Test loss: 2.676e+04, MSE(e): 3.457e-04, MSE(pi1): 6.007e-02, MSE(pi2): 1.738e-04, MSE(pi3): 8.252e-03\n",
      "Epoch 21300, Train loss: 6.541e+03, Test loss: 2.842e+04, MSE(e): 5.060e-04, MSE(pi1): 8.863e-02, MSE(pi2): 2.651e-04, MSE(pi3): 5.942e-03\n",
      "Epoch 21400, Train loss: 3.519e+03, Test loss: 2.533e+04, MSE(e): 2.253e-04, MSE(pi1): 5.992e-02, MSE(pi2): 1.334e-04, MSE(pi3): 6.661e-03\n",
      "Epoch 21500, Train loss: 4.560e+03, Test loss: 2.974e+04, MSE(e): 2.026e-04, MSE(pi1): 1.643e-01, MSE(pi2): 8.998e-05, MSE(pi3): 8.897e-03\n",
      "Epoch 21600, Train loss: 2.689e+03, Test loss: 2.218e+04, MSE(e): 1.397e-04, MSE(pi1): 6.463e-02, MSE(pi2): 8.719e-05, MSE(pi3): 6.462e-03\n",
      "Epoch 21700, Train loss: 5.754e+03, Test loss: 2.546e+04, MSE(e): 4.096e-04, MSE(pi1): 1.067e-01, MSE(pi2): 2.210e-04, MSE(pi3): 5.906e-03\n",
      "Epoch 21800, Train loss: 6.016e+03, Test loss: 2.556e+04, MSE(e): 4.532e-04, MSE(pi1): 9.241e-02, MSE(pi2): 2.392e-04, MSE(pi3): 5.593e-03\n",
      "Epoch 21900, Train loss: 2.801e+03, Test loss: 2.010e+04, MSE(e): 1.547e-04, MSE(pi1): 6.124e-02, MSE(pi2): 8.643e-05, MSE(pi3): 6.417e-03\n",
      "Epoch 22000, Train loss: 3.183e+03, Test loss: 2.333e+04, MSE(e): 1.455e-04, MSE(pi1): 9.686e-02, MSE(pi2): 7.777e-05, MSE(pi3): 7.595e-03\n",
      "Epoch 22100, Train loss: 4.366e+03, Test loss: 1.963e+04, MSE(e): 3.133e-04, MSE(pi1): 5.929e-02, MSE(pi2): 1.608e-04, MSE(pi3): 6.398e-03\n",
      "Epoch 22200, Train loss: 3.911e+03, Test loss: 1.986e+04, MSE(e): 2.635e-04, MSE(pi1): 6.904e-02, MSE(pi2): 1.377e-04, MSE(pi3): 5.860e-03\n",
      "Epoch 22300, Train loss: 7.654e+03, Test loss: 2.621e+04, MSE(e): 6.072e-04, MSE(pi1): 9.735e-02, MSE(pi2): 2.909e-04, MSE(pi3): 6.082e-03\n",
      "Epoch 22400, Train loss: 4.259e+03, Test loss: 2.515e+04, MSE(e): 2.739e-04, MSE(pi1): 8.125e-02, MSE(pi2): 1.530e-04, MSE(pi3): 7.074e-03\n",
      "Epoch 22500, Train loss: 3.131e+03, Test loss: 2.547e+04, MSE(e): 1.632e-04, MSE(pi1): 7.997e-02, MSE(pi2): 8.832e-05, MSE(pi3): 6.990e-03\n",
      "Epoch 22600, Train loss: 4.061e+03, Test loss: 2.321e+04, MSE(e): 2.988e-04, MSE(pi1): 4.568e-02, MSE(pi2): 1.700e-04, MSE(pi3): 6.160e-03\n",
      "Epoch 22700, Train loss: 8.043e+03, Test loss: 2.556e+04, MSE(e): 6.576e-04, MSE(pi1): 7.449e-02, MSE(pi2): 2.900e-04, MSE(pi3): 7.216e-03\n",
      "Epoch 22800, Train loss: 2.416e+03, Test loss: 2.240e+04, MSE(e): 1.151e-04, MSE(pi1): 6.453e-02, MSE(pi2): 6.761e-05, MSE(pi3): 6.200e-03\n",
      "Epoch 22900, Train loss: 2.681e+03, Test loss: 2.205e+04, MSE(e): 1.307e-04, MSE(pi1): 7.734e-02, MSE(pi2): 7.978e-05, MSE(pi3): 6.000e-03\n",
      "Epoch 23000, Train loss: 7.310e+03, Test loss: 2.750e+04, MSE(e): 5.230e-04, MSE(pi1): 1.415e-01, MSE(pi2): 2.524e-04, MSE(pi3): 6.652e-03\n",
      "Epoch 23100, Train loss: 6.680e+03, Test loss: 2.339e+04, MSE(e): 5.260e-04, MSE(pi1): 8.268e-02, MSE(pi2): 2.591e-04, MSE(pi3): 5.928e-03\n",
      "Epoch 23200, Train loss: 4.292e+03, Test loss: 2.461e+04, MSE(e): 2.100e-04, MSE(pi1): 1.443e-01, MSE(pi2): 1.011e-04, MSE(pi3): 7.477e-03\n",
      "Epoch 23300, Train loss: 4.440e+03, Test loss: 2.873e+04, MSE(e): 2.798e-04, MSE(pi1): 9.543e-02, MSE(pi2): 1.374e-04, MSE(pi3): 6.871e-03\n",
      "Epoch 23400, Train loss: 5.598e+03, Test loss: 2.490e+04, MSE(e): 4.166e-04, MSE(pi1): 7.431e-02, MSE(pi2): 1.953e-04, MSE(pi3): 6.887e-03\n",
      "Epoch 23500, Train loss: 7.655e+03, Test loss: 2.205e+04, MSE(e): 6.400e-04, MSE(pi1): 7.305e-02, MSE(pi2): 3.197e-04, MSE(pi3): 5.239e-03\n",
      "Epoch 23600, Train loss: 3.557e+03, Test loss: 2.159e+04, MSE(e): 2.418e-04, MSE(pi1): 4.446e-02, MSE(pi2): 1.363e-04, MSE(pi3): 6.951e-03\n",
      "Epoch 23700, Train loss: 3.145e+03, Test loss: 2.729e+04, MSE(e): 1.449e-04, MSE(pi1): 9.832e-02, MSE(pi2): 7.557e-05, MSE(pi3): 7.129e-03\n",
      "Epoch 23800, Train loss: 3.145e+03, Test loss: 2.578e+04, MSE(e): 1.421e-04, MSE(pi1): 1.122e-01, MSE(pi2): 8.981e-05, MSE(pi3): 6.023e-03\n",
      "Epoch 23900, Train loss: 6.357e+03, Test loss: 2.174e+04, MSE(e): 5.109e-04, MSE(pi1): 7.213e-02, MSE(pi2): 2.735e-04, MSE(pi3): 5.257e-03\n",
      "Epoch 24000, Train loss: 9.535e+03, Test loss: 2.496e+04, MSE(e): 8.102e-04, MSE(pi1): 8.937e-02, MSE(pi2): 4.048e-04, MSE(pi3): 5.390e-03\n",
      "Epoch 24100, Train loss: 7.706e+03, Test loss: 2.536e+04, MSE(e): 6.018e-04, MSE(pi1): 1.040e-01, MSE(pi2): 2.820e-04, MSE(pi3): 6.473e-03\n",
      "Epoch 24200, Train loss: 3.828e+03, Test loss: 2.475e+04, MSE(e): 2.305e-04, MSE(pi1): 8.648e-02, MSE(pi2): 1.309e-04, MSE(pi3): 6.581e-03\n",
      "Epoch 24300, Train loss: 2.674e+03, Test loss: 2.449e+04, MSE(e): 1.364e-04, MSE(pi1): 5.396e-02, MSE(pi2): 7.305e-05, MSE(pi3): 7.702e-03\n",
      "Epoch 24400, Train loss: 3.906e+03, Test loss: 2.457e+04, MSE(e): 2.583e-04, MSE(pi1): 5.688e-02, MSE(pi2): 1.339e-04, MSE(pi3): 7.545e-03\n",
      "Epoch 24500, Train loss: 3.502e+03, Test loss: 2.034e+04, MSE(e): 2.544e-04, MSE(pi1): 3.395e-02, MSE(pi2): 1.400e-04, MSE(pi3): 6.189e-03\n",
      "Epoch 24600, Train loss: 4.920e+03, Test loss: 2.385e+04, MSE(e): 3.595e-04, MSE(pi1): 5.871e-02, MSE(pi2): 1.657e-04, MSE(pi3): 7.381e-03\n",
      "Epoch 24700, Train loss: 6.984e+03, Test loss: 2.239e+04, MSE(e): 5.619e-04, MSE(pi1): 7.462e-02, MSE(pi2): 2.786e-04, MSE(pi3): 6.187e-03\n",
      "Epoch 24800, Train loss: 1.059e+04, Test loss: 2.362e+04, MSE(e): 9.097e-04, MSE(pi1): 9.770e-02, MSE(pi2): 4.563e-04, MSE(pi3): 5.137e-03\n",
      "Epoch 24900, Train loss: 9.244e+03, Test loss: 2.694e+04, MSE(e): 7.427e-04, MSE(pi1): 1.198e-01, MSE(pi2): 3.669e-04, MSE(pi3): 6.179e-03\n",
      "Epoch 25000, Train loss: 7.234e+03, Test loss: 1.976e+04, MSE(e): 5.910e-04, MSE(pi1): 7.826e-02, MSE(pi2): 2.906e-04, MSE(pi3): 5.413e-03\n",
      "Epoch 25100, Train loss: 8.786e+03, Test loss: 2.200e+04, MSE(e): 7.438e-04, MSE(pi1): 7.864e-02, MSE(pi2): 3.516e-04, MSE(pi3): 5.609e-03\n",
      "Epoch 25200, Train loss: 5.876e+03, Test loss: 2.156e+04, MSE(e): 4.862e-04, MSE(pi1): 3.717e-02, MSE(pi2): 2.357e-04, MSE(pi3): 6.420e-03\n",
      "Epoch 25300, Train loss: 3.618e+03, Test loss: 2.162e+04, MSE(e): 2.257e-04, MSE(pi1): 7.192e-02, MSE(pi2): 1.184e-04, MSE(pi3): 6.412e-03\n",
      "Epoch 25400, Train loss: 2.266e+03, Test loss: 2.150e+04, MSE(e): 1.110e-04, MSE(pi1): 3.959e-02, MSE(pi2): 5.811e-05, MSE(pi3): 7.602e-03\n",
      "Epoch 25500, Train loss: 4.190e+03, Test loss: 2.829e+04, MSE(e): 2.424e-04, MSE(pi1): 7.848e-02, MSE(pi2): 1.308e-04, MSE(pi3): 9.805e-03\n",
      "Epoch 25600, Train loss: 5.886e+03, Test loss: 2.157e+04, MSE(e): 4.396e-04, MSE(pi1): 8.832e-02, MSE(pi2): 2.185e-04, MSE(pi3): 6.062e-03\n",
      "Epoch 25700, Train loss: 6.192e+03, Test loss: 2.116e+04, MSE(e): 4.619e-04, MSE(pi1): 8.986e-02, MSE(pi2): 2.117e-04, MSE(pi3): 6.743e-03\n",
      "Epoch 25800, Train loss: 5.815e+03, Test loss: 1.941e+04, MSE(e): 4.576e-04, MSE(pi1): 6.922e-02, MSE(pi2): 2.350e-04, MSE(pi3): 5.463e-03\n",
      "Epoch 25900, Train loss: 3.341e+03, Test loss: 2.406e+04, MSE(e): 1.763e-04, MSE(pi1): 9.170e-02, MSE(pi2): 9.739e-05, MSE(pi3): 6.611e-03\n",
      "Epoch 26000, Train loss: 5.559e+03, Test loss: 2.141e+04, MSE(e): 4.084e-04, MSE(pi1): 8.633e-02, MSE(pi2): 2.164e-04, MSE(pi3): 6.109e-03\n",
      "Epoch 26100, Train loss: 1.121e+04, Test loss: 2.355e+04, MSE(e): 9.800e-04, MSE(pi1): 8.815e-02, MSE(pi2): 4.776e-04, MSE(pi3): 5.251e-03\n",
      "Epoch 26200, Train loss: 4.178e+03, Test loss: 2.170e+04, MSE(e): 2.516e-04, MSE(pi1): 1.051e-01, MSE(pi2): 1.319e-04, MSE(pi3): 6.109e-03\n",
      "Epoch 26300, Train loss: 4.344e+03, Test loss: 2.237e+04, MSE(e): 3.037e-04, MSE(pi1): 6.661e-02, MSE(pi2): 1.548e-04, MSE(pi3): 6.410e-03\n",
      "Epoch 26400, Train loss: 2.506e+03, Test loss: 2.266e+04, MSE(e): 1.367e-04, MSE(pi1): 5.104e-02, MSE(pi2): 7.615e-05, MSE(pi3): 6.293e-03\n",
      "Epoch 26500, Train loss: 6.580e+03, Test loss: 2.301e+04, MSE(e): 5.261e-04, MSE(pi1): 6.075e-02, MSE(pi2): 2.346e-04, MSE(pi3): 7.105e-03\n",
      "Epoch 26600, Train loss: 3.346e+03, Test loss: 2.348e+04, MSE(e): 2.113e-04, MSE(pi1): 4.607e-02, MSE(pi2): 1.021e-04, MSE(pi3): 7.720e-03\n",
      "Epoch 26700, Train loss: 5.091e+03, Test loss: 2.479e+04, MSE(e): 2.859e-04, MSE(pi1): 1.625e-01, MSE(pi2): 1.639e-04, MSE(pi3): 6.061e-03\n",
      "Epoch 26800, Train loss: 1.162e+04, Test loss: 1.942e+04, MSE(e): 1.035e-03, MSE(pi1): 7.115e-02, MSE(pi2): 4.751e-04, MSE(pi3): 5.621e-03\n",
      "Epoch 26900, Train loss: 2.932e+03, Test loss: 2.107e+04, MSE(e): 1.680e-04, MSE(pi1): 6.209e-02, MSE(pi2): 6.458e-05, MSE(pi3): 6.307e-03\n",
      "Epoch 27000, Train loss: 2.391e+03, Test loss: 1.902e+04, MSE(e): 1.290e-04, MSE(pi1): 3.966e-02, MSE(pi2): 6.084e-05, MSE(pi3): 7.044e-03\n",
      "Epoch 27100, Train loss: 3.493e+03, Test loss: 2.011e+04, MSE(e): 2.239e-04, MSE(pi1): 4.913e-02, MSE(pi2): 1.003e-04, MSE(pi3): 7.631e-03\n",
      "Epoch 27200, Train loss: 1.512e+04, Test loss: 2.719e+04, MSE(e): 1.372e-03, MSE(pi1): 6.721e-02, MSE(pi2): 5.629e-04, MSE(pi3): 7.260e-03\n",
      "Epoch 27300, Train loss: 6.811e+03, Test loss: 2.253e+04, MSE(e): 5.599e-04, MSE(pi1): 4.170e-02, MSE(pi2): 2.277e-04, MSE(pi3): 7.945e-03\n",
      "Epoch 27400, Train loss: 3.408e+03, Test loss: 2.207e+04, MSE(e): 1.909e-04, MSE(pi1): 7.687e-02, MSE(pi2): 8.000e-05, MSE(pi3): 7.308e-03\n",
      "Epoch 27500, Train loss: 1.863e+04, Test loss: 3.783e+04, MSE(e): 1.763e-03, MSE(pi1): 4.840e-02, MSE(pi2): 8.057e-04, MSE(pi3): 5.111e-03\n",
      "Epoch 27600, Train loss: 3.248e+03, Test loss: 1.991e+04, MSE(e): 2.329e-04, MSE(pi1): 1.690e-02, MSE(pi2): 1.019e-04, MSE(pi3): 7.499e-03\n",
      "Epoch 27700, Train loss: 1.357e+04, Test loss: 2.464e+04, MSE(e): 1.245e-03, MSE(pi1): 5.535e-02, MSE(pi2): 5.778e-04, MSE(pi3): 5.618e-03\n",
      "Epoch 27800, Train loss: 2.903e+03, Test loss: 2.289e+04, MSE(e): 1.475e-04, MSE(pi1): 6.504e-02, MSE(pi2): 6.305e-05, MSE(pi3): 7.778e-03\n",
      "Epoch 27900, Train loss: 3.764e+03, Test loss: 2.734e+04, MSE(e): 2.446e-04, MSE(pi1): 6.228e-02, MSE(pi2): 1.181e-04, MSE(pi3): 6.953e-03\n",
      "Epoch 28000, Train loss: 2.876e+03, Test loss: 1.872e+04, MSE(e): 1.768e-04, MSE(pi1): 4.021e-02, MSE(pi2): 7.337e-05, MSE(pi3): 7.064e-03\n",
      "Epoch 28100, Train loss: 3.479e+03, Test loss: 2.173e+04, MSE(e): 2.427e-04, MSE(pi1): 3.230e-02, MSE(pi2): 9.764e-05, MSE(pi3): 7.293e-03\n",
      "Epoch 28200, Train loss: 3.580e+03, Test loss: 2.133e+04, MSE(e): 2.454e-04, MSE(pi1): 4.631e-02, MSE(pi2): 9.284e-05, MSE(pi3): 6.626e-03\n",
      "Epoch 28300, Train loss: 1.166e+04, Test loss: 3.241e+04, MSE(e): 1.003e-03, MSE(pi1): 8.469e-02, MSE(pi2): 4.368e-04, MSE(pi3): 7.820e-03\n",
      "Epoch 28400, Train loss: 9.172e+03, Test loss: 2.316e+04, MSE(e): 7.510e-04, MSE(pi1): 7.036e-02, MSE(pi2): 3.790e-04, MSE(pi3): 9.575e-03\n",
      "Epoch 28500, Train loss: 1.071e+04, Test loss: 2.167e+04, MSE(e): 9.581e-04, MSE(pi1): 5.155e-02, MSE(pi2): 4.327e-04, MSE(pi3): 6.129e-03\n",
      "Epoch 28600, Train loss: 6.327e+03, Test loss: 2.392e+04, MSE(e): 5.126e-04, MSE(pi1): 5.704e-02, MSE(pi2): 2.757e-04, MSE(pi3): 6.303e-03\n",
      "Epoch 28700, Train loss: 1.013e+04, Test loss: 2.618e+04, MSE(e): 8.709e-04, MSE(pi1): 4.951e-02, MSE(pi2): 3.903e-04, MSE(pi3): 9.244e-03\n",
      "Epoch 28800, Train loss: 3.896e+03, Test loss: 3.714e+04, MSE(e): 2.676e-04, MSE(pi1): 6.887e-02, MSE(pi2): 1.369e-04, MSE(pi3): 5.314e-03\n",
      "Epoch 28900, Train loss: 2.363e+03, Test loss: 2.130e+04, MSE(e): 1.204e-04, MSE(pi1): 4.800e-02, MSE(pi2): 6.960e-05, MSE(pi3): 6.786e-03\n",
      "Epoch 29000, Train loss: 3.063e+03, Test loss: 2.523e+04, MSE(e): 1.489e-04, MSE(pi1): 7.611e-02, MSE(pi2): 6.017e-05, MSE(pi3): 8.135e-03\n",
      "Epoch 29100, Train loss: 2.125e+03, Test loss: 2.272e+04, MSE(e): 7.051e-05, MSE(pi1): 7.872e-02, MSE(pi2): 3.261e-05, MSE(pi3): 6.328e-03\n",
      "Epoch 29200, Train loss: 1.846e+04, Test loss: 2.450e+04, MSE(e): 1.703e-03, MSE(pi1): 9.368e-02, MSE(pi2): 8.251e-04, MSE(pi3): 4.939e-03\n",
      "Epoch 29300, Train loss: 2.975e+03, Test loss: 2.517e+04, MSE(e): 1.756e-04, MSE(pi1): 6.177e-02, MSE(pi2): 9.783e-05, MSE(pi3): 6.009e-03\n",
      "Epoch 29400, Train loss: 3.326e+03, Test loss: 2.573e+04, MSE(e): 1.896e-04, MSE(pi1): 8.292e-02, MSE(pi2): 1.051e-04, MSE(pi3): 6.006e-03\n",
      "Epoch 29500, Train loss: 3.394e+03, Test loss: 2.694e+04, MSE(e): 1.866e-04, MSE(pi1): 8.825e-02, MSE(pi2): 1.061e-04, MSE(pi3): 6.450e-03\n",
      "Epoch 29600, Train loss: 3.582e+03, Test loss: 2.352e+04, MSE(e): 2.011e-04, MSE(pi1): 9.181e-02, MSE(pi2): 9.693e-05, MSE(pi3): 6.522e-03\n",
      "Epoch 29700, Train loss: 2.372e+03, Test loss: 2.198e+04, MSE(e): 1.249e-04, MSE(pi1): 4.908e-02, MSE(pi2): 6.574e-05, MSE(pi3): 6.323e-03\n",
      "Epoch 29800, Train loss: 6.922e+03, Test loss: 2.666e+04, MSE(e): 4.957e-04, MSE(pi1): 1.405e-01, MSE(pi2): 2.495e-04, MSE(pi3): 5.601e-03\n",
      "Epoch 29900, Train loss: 6.937e+03, Test loss: 2.729e+04, MSE(e): 5.157e-04, MSE(pi1): 1.129e-01, MSE(pi2): 2.392e-04, MSE(pi3): 6.505e-03\n",
      "Epoch 30000, Train loss: 7.995e+03, Test loss: 2.510e+04, MSE(e): 6.343e-04, MSE(pi1): 1.118e-01, MSE(pi2): 3.132e-04, MSE(pi3): 5.340e-03\n",
      "Epoch 30100, Train loss: 5.365e+03, Test loss: 2.526e+04, MSE(e): 4.010e-04, MSE(pi1): 7.334e-02, MSE(pi2): 2.032e-04, MSE(pi3): 6.207e-03\n",
      "Epoch 30200, Train loss: 3.900e+03, Test loss: 2.528e+04, MSE(e): 2.359e-04, MSE(pi1): 8.401e-02, MSE(pi2): 1.207e-04, MSE(pi3): 7.005e-03\n",
      "Epoch 30300, Train loss: 3.221e+03, Test loss: 2.353e+04, MSE(e): 1.888e-04, MSE(pi1): 7.320e-02, MSE(pi2): 1.065e-04, MSE(pi3): 6.002e-03\n",
      "Epoch 30400, Train loss: 3.363e+03, Test loss: 2.427e+04, MSE(e): 2.071e-04, MSE(pi1): 5.044e-02, MSE(pi2): 1.074e-04, MSE(pi3): 7.873e-03\n",
      "Epoch 30500, Train loss: 3.494e+03, Test loss: 3.052e+04, MSE(e): 1.725e-04, MSE(pi1): 1.050e-01, MSE(pi2): 8.325e-05, MSE(pi3): 7.196e-03\n",
      "Epoch 30600, Train loss: 3.613e+03, Test loss: 2.846e+04, MSE(e): 1.735e-04, MSE(pi1): 1.313e-01, MSE(pi2): 1.057e-04, MSE(pi3): 5.662e-03\n",
      "Epoch 30700, Train loss: 4.783e+03, Test loss: 2.462e+04, MSE(e): 3.560e-04, MSE(pi1): 6.340e-02, MSE(pi2): 1.841e-04, MSE(pi3): 5.886e-03\n",
      "Epoch 30800, Train loss: 9.864e+03, Test loss: 2.891e+04, MSE(e): 8.569e-04, MSE(pi1): 7.469e-02, MSE(pi2): 4.107e-04, MSE(pi3): 5.479e-03\n",
      "Epoch 30900, Train loss: 4.158e+03, Test loss: 2.700e+04, MSE(e): 2.567e-04, MSE(pi1): 7.784e-02, MSE(pi2): 1.328e-04, MSE(pi3): 8.122e-03\n",
      "Epoch 31000, Train loss: 2.995e+03, Test loss: 2.548e+04, MSE(e): 1.740e-04, MSE(pi1): 4.933e-02, MSE(pi2): 8.540e-05, MSE(pi3): 7.613e-03\n",
      "Epoch 31100, Train loss: 6.383e+03, Test loss: 3.003e+04, MSE(e): 4.336e-04, MSE(pi1): 1.497e-01, MSE(pi2): 2.425e-04, MSE(pi3): 5.500e-03\n",
      "Epoch 31200, Train loss: 7.660e+03, Test loss: 2.352e+04, MSE(e): 6.554e-04, MSE(pi1): 5.578e-02, MSE(pi2): 3.269e-04, MSE(pi3): 5.481e-03\n",
      "Epoch 31300, Train loss: 3.518e+03, Test loss: 2.679e+04, MSE(e): 2.158e-04, MSE(pi1): 5.190e-02, MSE(pi2): 1.106e-04, MSE(pi3): 8.408e-03\n",
      "Epoch 31400, Train loss: 3.206e+03, Test loss: 2.802e+04, MSE(e): 1.602e-04, MSE(pi1): 9.714e-02, MSE(pi2): 7.897e-05, MSE(pi3): 6.326e-03\n",
      "Epoch 31500, Train loss: 6.221e+03, Test loss: 2.659e+04, MSE(e): 5.010e-04, MSE(pi1): 5.738e-02, MSE(pi2): 2.379e-04, MSE(pi3): 6.369e-03\n",
      "Epoch 31600, Train loss: 9.635e+03, Test loss: 2.597e+04, MSE(e): 8.304e-04, MSE(pi1): 7.891e-02, MSE(pi2): 3.857e-04, MSE(pi3): 5.417e-03\n",
      "Epoch 31700, Train loss: 5.854e+03, Test loss: 2.636e+04, MSE(e): 4.590e-04, MSE(pi1): 6.943e-02, MSE(pi2): 2.493e-04, MSE(pi3): 5.693e-03\n",
      "Epoch 31800, Train loss: 3.377e+03, Test loss: 2.470e+04, MSE(e): 2.106e-04, MSE(pi1): 4.834e-02, MSE(pi2): 1.196e-04, MSE(pi3): 7.871e-03\n",
      "Epoch 31900, Train loss: 2.602e+03, Test loss: 2.757e+04, MSE(e): 1.353e-04, MSE(pi1): 5.214e-02, MSE(pi2): 6.723e-05, MSE(pi3): 7.281e-03\n",
      "Epoch 32000, Train loss: 2.612e+03, Test loss: 2.773e+04, MSE(e): 1.060e-04, MSE(pi1): 8.057e-02, MSE(pi2): 5.917e-05, MSE(pi3): 7.460e-03\n",
      "Epoch 32100, Train loss: 4.597e+03, Test loss: 2.545e+04, MSE(e): 3.190e-04, MSE(pi1): 8.858e-02, MSE(pi2): 1.822e-04, MSE(pi3): 5.210e-03\n",
      "Epoch 32200, Train loss: 2.794e+03, Test loss: 2.596e+04, MSE(e): 1.413e-04, MSE(pi1): 7.059e-02, MSE(pi2): 7.647e-05, MSE(pi3): 6.747e-03\n",
      "Epoch 32300, Train loss: 8.162e+03, Test loss: 2.543e+04, MSE(e): 6.819e-04, MSE(pi1): 8.138e-02, MSE(pi2): 3.466e-04, MSE(pi3): 5.292e-03\n",
      "Epoch 32400, Train loss: 9.949e+03, Test loss: 2.939e+04, MSE(e): 7.931e-04, MSE(pi1): 1.499e-01, MSE(pi2): 3.948e-04, MSE(pi3): 5.184e-03\n",
      "Epoch 32500, Train loss: 7.569e+03, Test loss: 2.666e+04, MSE(e): 6.431e-04, MSE(pi1): 5.760e-02, MSE(pi2): 3.201e-04, MSE(pi3): 5.620e-03\n",
      "Epoch 32600, Train loss: 9.466e+03, Test loss: 3.077e+04, MSE(e): 7.805e-04, MSE(pi1): 1.116e-01, MSE(pi2): 3.907e-04, MSE(pi3): 5.442e-03\n",
      "Epoch 32700, Train loss: 4.672e+03, Test loss: 2.812e+04, MSE(e): 3.173e-04, MSE(pi1): 8.086e-02, MSE(pi2): 1.622e-04, MSE(pi3): 6.901e-03\n",
      "Epoch 32800, Train loss: 4.839e+03, Test loss: 2.867e+04, MSE(e): 3.208e-04, MSE(pi1): 8.654e-02, MSE(pi2): 1.572e-04, MSE(pi3): 7.651e-03\n",
      "Epoch 32900, Train loss: 5.391e+03, Test loss: 2.414e+04, MSE(e): 4.266e-04, MSE(pi1): 5.335e-02, MSE(pi2): 2.216e-04, MSE(pi3): 5.913e-03\n",
      "Epoch 33000, Train loss: 3.504e+03, Test loss: 2.376e+04, MSE(e): 2.346e-04, MSE(pi1): 4.511e-02, MSE(pi2): 1.285e-04, MSE(pi3): 7.075e-03\n",
      "Epoch 33100, Train loss: 3.922e+03, Test loss: 2.429e+04, MSE(e): 2.694e-04, MSE(pi1): 5.068e-02, MSE(pi2): 1.386e-04, MSE(pi3): 7.209e-03\n",
      "Epoch 33200, Train loss: 3.835e+03, Test loss: 2.492e+04, MSE(e): 2.442e-04, MSE(pi1): 6.932e-02, MSE(pi2): 1.328e-04, MSE(pi3): 6.998e-03\n",
      "Epoch 33300, Train loss: 3.504e+03, Test loss: 2.535e+04, MSE(e): 2.092e-04, MSE(pi1): 6.398e-02, MSE(pi2): 1.165e-04, MSE(pi3): 7.720e-03\n",
      "Epoch 33400, Train loss: 3.321e+03, Test loss: 2.385e+04, MSE(e): 2.162e-04, MSE(pi1): 4.418e-02, MSE(pi2): 1.211e-04, MSE(pi3): 7.167e-03\n",
      "Epoch 33500, Train loss: 4.163e+03, Test loss: 2.332e+04, MSE(e): 3.127e-04, MSE(pi1): 4.299e-02, MSE(pi2): 1.660e-04, MSE(pi3): 6.064e-03\n",
      "Epoch 33600, Train loss: 5.160e+03, Test loss: 2.550e+04, MSE(e): 3.897e-04, MSE(pi1): 6.653e-02, MSE(pi2): 2.101e-04, MSE(pi3): 5.970e-03\n",
      "Epoch 33700, Train loss: 6.244e+03, Test loss: 3.154e+04, MSE(e): 4.306e-04, MSE(pi1): 1.124e-01, MSE(pi2): 2.182e-04, MSE(pi3): 8.137e-03\n",
      "Epoch 33800, Train loss: 5.315e+03, Test loss: 2.489e+04, MSE(e): 4.030e-04, MSE(pi1): 6.592e-02, MSE(pi2): 1.972e-04, MSE(pi3): 6.260e-03\n",
      "Epoch 33900, Train loss: 7.034e+03, Test loss: 2.635e+04, MSE(e): 5.829e-04, MSE(pi1): 6.397e-02, MSE(pi2): 2.877e-04, MSE(pi3): 5.649e-03\n",
      "Epoch 34000, Train loss: 7.110e+03, Test loss: 2.778e+04, MSE(e): 5.743e-04, MSE(pi1): 7.287e-02, MSE(pi2): 2.714e-04, MSE(pi3): 6.386e-03\n",
      "Epoch 34100, Train loss: 1.048e+04, Test loss: 2.622e+04, MSE(e): 9.490e-04, MSE(pi1): 4.290e-02, MSE(pi2): 4.334e-04, MSE(pi3): 5.561e-03\n",
      "Epoch 34200, Train loss: 8.362e+03, Test loss: 2.985e+04, MSE(e): 7.100e-04, MSE(pi1): 6.980e-02, MSE(pi2): 3.596e-04, MSE(pi3): 5.631e-03\n",
      "Epoch 34300, Train loss: 8.676e+03, Test loss: 2.693e+04, MSE(e): 7.359e-04, MSE(pi1): 8.076e-02, MSE(pi2): 3.651e-04, MSE(pi3): 5.091e-03\n",
      "Epoch 34400, Train loss: 3.621e+03, Test loss: 2.616e+04, MSE(e): 2.289e-04, MSE(pi1): 7.449e-02, MSE(pi2): 1.235e-04, MSE(pi3): 5.873e-03\n",
      "Epoch 34500, Train loss: 2.629e+03, Test loss: 3.032e+04, MSE(e): 1.378e-04, MSE(pi1): 6.081e-02, MSE(pi2): 7.155e-05, MSE(pi3): 6.428e-03\n",
      "Epoch 34600, Train loss: 2.688e+03, Test loss: 3.003e+04, MSE(e): 1.346e-04, MSE(pi1): 6.128e-02, MSE(pi2): 6.856e-05, MSE(pi3): 7.289e-03\n",
      "Epoch 34700, Train loss: 3.436e+03, Test loss: 2.673e+04, MSE(e): 2.085e-04, MSE(pi1): 5.477e-02, MSE(pi2): 1.121e-04, MSE(pi3): 8.032e-03\n",
      "Epoch 34800, Train loss: 5.202e+03, Test loss: 2.700e+04, MSE(e): 3.955e-04, MSE(pi1): 6.488e-02, MSE(pi2): 2.041e-04, MSE(pi3): 5.983e-03\n",
      "Epoch 34900, Train loss: 8.246e+03, Test loss: 2.736e+04, MSE(e): 7.091e-04, MSE(pi1): 5.753e-02, MSE(pi2): 3.296e-04, MSE(pi3): 5.790e-03\n",
      "Epoch 35000, Train loss: 8.326e+03, Test loss: 2.807e+04, MSE(e): 7.066e-04, MSE(pi1): 7.462e-02, MSE(pi2): 3.610e-04, MSE(pi3): 5.130e-03\n",
      "Epoch 35100, Train loss: 2.907e+03, Test loss: 2.836e+04, MSE(e): 1.753e-04, MSE(pi1): 4.900e-02, MSE(pi2): 8.697e-05, MSE(pi3): 6.639e-03\n",
      "Epoch 35200, Train loss: 3.035e+03, Test loss: 2.915e+04, MSE(e): 1.639e-04, MSE(pi1): 7.051e-02, MSE(pi2): 7.547e-05, MSE(pi3): 6.909e-03\n",
      "Epoch 35300, Train loss: 3.333e+03, Test loss: 2.524e+04, MSE(e): 2.205e-04, MSE(pi1): 4.064e-02, MSE(pi2): 1.154e-04, MSE(pi3): 7.208e-03\n",
      "Epoch 35400, Train loss: 8.034e+03, Test loss: 2.982e+04, MSE(e): 6.849e-04, MSE(pi1): 6.389e-02, MSE(pi2): 3.391e-04, MSE(pi3): 5.462e-03\n",
      "Epoch 35500, Train loss: 8.325e+03, Test loss: 2.762e+04, MSE(e): 7.286e-04, MSE(pi1): 4.907e-02, MSE(pi2): 3.436e-04, MSE(pi3): 5.482e-03\n",
      "Epoch 35600, Train loss: 2.845e+03, Test loss: 2.893e+04, MSE(e): 1.611e-04, MSE(pi1): 5.446e-02, MSE(pi2): 7.723e-05, MSE(pi3): 6.898e-03\n",
      "Epoch 35700, Train loss: 3.523e+03, Test loss: 2.549e+04, MSE(e): 2.616e-04, MSE(pi1): 2.718e-02, MSE(pi2): 1.348e-04, MSE(pi3): 6.348e-03\n",
      "Epoch 35800, Train loss: 7.630e+03, Test loss: 3.001e+04, MSE(e): 6.495e-04, MSE(pi1): 5.211e-02, MSE(pi2): 3.053e-04, MSE(pi3): 6.137e-03\n",
      "Epoch 35900, Train loss: 6.518e+03, Test loss: 2.557e+04, MSE(e): 5.232e-04, MSE(pi1): 7.489e-02, MSE(pi2): 2.606e-04, MSE(pi3): 5.364e-03\n",
      "Epoch 36000, Train loss: 2.958e+03, Test loss: 2.951e+04, MSE(e): 1.678e-04, MSE(pi1): 5.569e-02, MSE(pi2): 7.973e-05, MSE(pi3): 7.237e-03\n",
      "Epoch 36100, Train loss: 6.803e+03, Test loss: 3.004e+04, MSE(e): 5.552e-04, MSE(pi1): 6.619e-02, MSE(pi2): 2.698e-04, MSE(pi3): 5.894e-03\n",
      "Epoch 36200, Train loss: 6.487e+03, Test loss: 2.700e+04, MSE(e): 5.474e-04, MSE(pi1): 4.977e-02, MSE(pi2): 2.764e-04, MSE(pi3): 5.150e-03\n",
      "Epoch 36300, Train loss: 2.767e+03, Test loss: 2.969e+04, MSE(e): 1.630e-04, MSE(pi1): 3.862e-02, MSE(pi2): 8.083e-05, MSE(pi3): 7.508e-03\n",
      "Epoch 36400, Train loss: 7.889e+03, Test loss: 3.029e+04, MSE(e): 6.674e-04, MSE(pi1): 6.858e-02, MSE(pi2): 3.304e-04, MSE(pi3): 5.296e-03\n",
      "Epoch 36500, Train loss: 4.492e+03, Test loss: 2.769e+04, MSE(e): 3.319e-04, MSE(pi1): 6.237e-02, MSE(pi2): 1.744e-04, MSE(pi3): 5.492e-03\n",
      "Epoch 36600, Train loss: 3.845e+03, Test loss: 2.693e+04, MSE(e): 2.721e-04, MSE(pi1): 4.269e-02, MSE(pi2): 1.438e-04, MSE(pi3): 6.970e-03\n",
      "Epoch 36700, Train loss: 6.713e+03, Test loss: 2.470e+04, MSE(e): 5.801e-04, MSE(pi1): 3.804e-02, MSE(pi2): 2.811e-04, MSE(pi3): 5.309e-03\n",
      "Epoch 36800, Train loss: 3.281e+03, Test loss: 3.141e+04, MSE(e): 1.805e-04, MSE(pi1): 7.941e-02, MSE(pi2): 8.952e-05, MSE(pi3): 6.826e-03\n",
      "Epoch 36900, Train loss: 8.535e+03, Test loss: 2.537e+04, MSE(e): 7.652e-04, MSE(pi1): 3.554e-02, MSE(pi2): 3.596e-04, MSE(pi3): 5.276e-03\n",
      "Epoch 37000, Train loss: 3.013e+03, Test loss: 2.899e+04, MSE(e): 1.891e-04, MSE(pi1): 3.627e-02, MSE(pi2): 9.181e-05, MSE(pi3): 7.592e-03\n",
      "Epoch 37100, Train loss: 9.811e+03, Test loss: 2.738e+04, MSE(e): 8.783e-04, MSE(pi1): 5.174e-02, MSE(pi2): 4.157e-04, MSE(pi3): 5.109e-03\n",
      "Epoch 37200, Train loss: 2.933e+03, Test loss: 2.954e+04, MSE(e): 1.792e-04, MSE(pi1): 4.566e-02, MSE(pi2): 8.662e-05, MSE(pi3): 6.844e-03\n",
      "Epoch 37300, Train loss: 1.019e+04, Test loss: 3.049e+04, MSE(e): 8.788e-04, MSE(pi1): 8.629e-02, MSE(pi2): 4.263e-04, MSE(pi3): 5.403e-03\n",
      "Epoch 37400, Train loss: 3.389e+03, Test loss: 2.871e+04, MSE(e): 2.209e-04, MSE(pi1): 4.563e-02, MSE(pi2): 1.172e-04, MSE(pi3): 7.237e-03\n",
      "Epoch 37500, Train loss: 6.372e+03, Test loss: 2.748e+04, MSE(e): 4.909e-04, MSE(pi1): 9.348e-02, MSE(pi2): 2.482e-04, MSE(pi3): 5.284e-03\n",
      "Epoch 37600, Train loss: 6.284e+03, Test loss: 2.850e+04, MSE(e): 5.046e-04, MSE(pi1): 6.792e-02, MSE(pi2): 2.536e-04, MSE(pi3): 5.588e-03\n",
      "Epoch 37700, Train loss: 2.968e+03, Test loss: 2.923e+04, MSE(e): 1.894e-04, MSE(pi1): 3.988e-02, MSE(pi2): 8.597e-05, MSE(pi3): 6.752e-03\n",
      "Epoch 37800, Train loss: 9.103e+03, Test loss: 2.847e+04, MSE(e): 8.033e-04, MSE(pi1): 5.324e-02, MSE(pi2): 3.795e-04, MSE(pi3): 5.367e-03\n",
      "Epoch 37900, Train loss: 3.914e+03, Test loss: 2.697e+04, MSE(e): 2.696e-04, MSE(pi1): 5.338e-02, MSE(pi2): 1.431e-04, MSE(pi3): 6.840e-03\n",
      "Epoch 38000, Train loss: 3.763e+03, Test loss: 2.905e+04, MSE(e): 2.601e-04, MSE(pi1): 5.751e-02, MSE(pi2): 1.293e-04, MSE(pi3): 5.869e-03\n",
      "Epoch 38100, Train loss: 8.585e+03, Test loss: 2.724e+04, MSE(e): 7.613e-04, MSE(pi1): 4.582e-02, MSE(pi2): 3.669e-04, MSE(pi3): 5.133e-03\n",
      "Epoch 38200, Train loss: 5.547e+03, Test loss: 2.890e+04, MSE(e): 4.284e-04, MSE(pi1): 6.722e-02, MSE(pi2): 2.125e-04, MSE(pi3): 5.907e-03\n",
      "Epoch 38300, Train loss: 2.974e+03, Test loss: 3.037e+04, MSE(e): 1.881e-04, MSE(pi1): 4.394e-02, MSE(pi2): 9.149e-05, MSE(pi3): 6.536e-03\n",
      "Epoch 38400, Train loss: 4.543e+03, Test loss: 2.860e+04, MSE(e): 3.353e-04, MSE(pi1): 6.436e-02, MSE(pi2): 1.753e-04, MSE(pi3): 5.465e-03\n",
      "Epoch 38500, Train loss: 1.039e+04, Test loss: 3.159e+04, MSE(e): 8.823e-04, MSE(pi1): 1.057e-01, MSE(pi2): 4.398e-04, MSE(pi3): 5.052e-03\n",
      "Epoch 38600, Train loss: 7.914e+03, Test loss: 3.218e+04, MSE(e): 6.479e-04, MSE(pi1): 8.199e-02, MSE(pi2): 2.979e-04, MSE(pi3): 6.153e-03\n",
      "Epoch 38700, Train loss: 4.811e+03, Test loss: 2.689e+04, MSE(e): 3.738e-04, MSE(pi1): 4.383e-02, MSE(pi2): 2.019e-04, MSE(pi3): 6.338e-03\n",
      "Epoch 38800, Train loss: 2.881e+03, Test loss: 2.869e+04, MSE(e): 1.780e-04, MSE(pi1): 3.674e-02, MSE(pi2): 9.092e-05, MSE(pi3): 7.332e-03\n",
      "Epoch 38900, Train loss: 3.326e+03, Test loss: 2.773e+04, MSE(e): 2.297e-04, MSE(pi1): 4.636e-02, MSE(pi2): 1.206e-04, MSE(pi3): 5.647e-03\n",
      "Epoch 39000, Train loss: 6.114e+03, Test loss: 2.871e+04, MSE(e): 5.038e-04, MSE(pi1): 4.919e-02, MSE(pi2): 2.336e-04, MSE(pi3): 5.845e-03\n",
      "Epoch 39100, Train loss: 6.741e+03, Test loss: 2.981e+04, MSE(e): 5.522e-04, MSE(pi1): 6.365e-02, MSE(pi2): 2.616e-04, MSE(pi3): 5.828e-03\n",
      "Epoch 39200, Train loss: 7.741e+03, Test loss: 2.716e+04, MSE(e): 6.801e-04, MSE(pi1): 4.031e-02, MSE(pi2): 3.228e-04, MSE(pi3): 5.371e-03\n",
      "Epoch 39300, Train loss: 8.005e+03, Test loss: 3.102e+04, MSE(e): 6.949e-04, MSE(pi1): 5.189e-02, MSE(pi2): 3.508e-04, MSE(pi3): 5.368e-03\n",
      "Epoch 39400, Train loss: 7.792e+03, Test loss: 2.919e+04, MSE(e): 6.653e-04, MSE(pi1): 5.663e-02, MSE(pi2): 3.037e-04, MSE(pi3): 5.728e-03\n",
      "Epoch 39500, Train loss: 6.583e+03, Test loss: 2.916e+04, MSE(e): 5.588e-04, MSE(pi1): 4.002e-02, MSE(pi2): 2.598e-04, MSE(pi3): 5.954e-03\n",
      "Epoch 39600, Train loss: 9.354e+03, Test loss: 3.370e+04, MSE(e): 7.743e-04, MSE(pi1): 1.047e-01, MSE(pi2): 3.802e-04, MSE(pi3): 5.631e-03\n",
      "Epoch 39700, Train loss: 9.573e+03, Test loss: 2.839e+04, MSE(e): 8.183e-04, MSE(pi1): 8.685e-02, MSE(pi2): 3.941e-04, MSE(pi3): 5.214e-03\n",
      "Epoch 39800, Train loss: 1.079e+04, Test loss: 2.832e+04, MSE(e): 9.645e-04, MSE(pi1): 6.643e-02, MSE(pi2): 4.740e-04, MSE(pi3): 4.835e-03\n",
      "Epoch 39900, Train loss: 6.437e+03, Test loss: 2.763e+04, MSE(e): 5.502e-04, MSE(pi1): 3.578e-02, MSE(pi2): 2.532e-04, MSE(pi3): 5.764e-03\n",
      "Epoch 40000, Train loss: 7.400e+03, Test loss: 3.542e+04, MSE(e): 5.773e-04, MSE(pi1): 1.037e-01, MSE(pi2): 2.900e-04, MSE(pi3): 5.899e-03\n",
      "Epoch 40100, Train loss: 7.251e+03, Test loss: 3.120e+04, MSE(e): 6.032e-04, MSE(pi1): 5.784e-02, MSE(pi2): 2.658e-04, MSE(pi3): 6.403e-03\n",
      "Epoch 40200, Train loss: 6.306e+03, Test loss: 3.050e+04, MSE(e): 4.850e-04, MSE(pi1): 9.007e-02, MSE(pi2): 2.406e-04, MSE(pi3): 5.550e-03\n",
      "Epoch 40300, Train loss: 4.534e+03, Test loss: 3.152e+04, MSE(e): 3.343e-04, MSE(pi1): 5.929e-02, MSE(pi2): 1.620e-04, MSE(pi3): 5.975e-03\n",
      "Epoch 40400, Train loss: 5.744e+03, Test loss: 3.201e+04, MSE(e): 4.508e-04, MSE(pi1): 6.236e-02, MSE(pi2): 2.175e-04, MSE(pi3): 6.115e-03\n",
      "Epoch 40500, Train loss: 4.424e+03, Test loss: 3.237e+04, MSE(e): 3.059e-04, MSE(pi1): 6.279e-02, MSE(pi2): 1.600e-04, MSE(pi3): 7.364e-03\n",
      "Epoch 40600, Train loss: 4.724e+03, Test loss: 3.281e+04, MSE(e): 3.262e-04, MSE(pi1): 7.120e-02, MSE(pi2): 1.452e-04, MSE(pi3): 7.499e-03\n",
      "Epoch 40700, Train loss: 9.923e+03, Test loss: 3.286e+04, MSE(e): 8.340e-04, MSE(pi1): 1.069e-01, MSE(pi2): 4.155e-04, MSE(pi3): 5.133e-03\n",
      "Epoch 40800, Train loss: 4.848e+03, Test loss: 3.054e+04, MSE(e): 3.670e-04, MSE(pi1): 5.003e-02, MSE(pi2): 1.717e-04, MSE(pi3): 6.778e-03\n",
      "Epoch 40900, Train loss: 5.907e+03, Test loss: 2.910e+04, MSE(e): 4.596e-04, MSE(pi1): 6.498e-02, MSE(pi2): 2.371e-04, MSE(pi3): 6.603e-03\n",
      "Epoch 41000, Train loss: 4.651e+03, Test loss: 3.183e+04, MSE(e): 3.402e-04, MSE(pi1): 5.215e-02, MSE(pi2): 1.620e-04, MSE(pi3): 7.274e-03\n",
      "Epoch 41100, Train loss: 5.446e+03, Test loss: 2.986e+04, MSE(e): 4.359e-04, MSE(pi1): 4.482e-02, MSE(pi2): 2.239e-04, MSE(pi3): 6.388e-03\n",
      "Epoch 41200, Train loss: 5.168e+03, Test loss: 3.460e+04, MSE(e): 3.810e-04, MSE(pi1): 6.990e-02, MSE(pi2): 1.927e-04, MSE(pi3): 6.583e-03\n",
      "Epoch 41300, Train loss: 5.039e+03, Test loss: 3.192e+04, MSE(e): 3.977e-04, MSE(pi1): 3.812e-02, MSE(pi2): 1.973e-04, MSE(pi3): 6.798e-03\n",
      "Epoch 41400, Train loss: 6.235e+03, Test loss: 2.777e+04, MSE(e): 5.293e-04, MSE(pi1): 3.585e-02, MSE(pi2): 2.420e-04, MSE(pi3): 5.830e-03\n",
      "Epoch 41500, Train loss: 5.228e+03, Test loss: 3.236e+04, MSE(e): 4.218e-04, MSE(pi1): 3.852e-02, MSE(pi2): 1.857e-04, MSE(pi3): 6.244e-03\n",
      "Epoch 41600, Train loss: 4.622e+03, Test loss: 3.703e+04, MSE(e): 2.707e-04, MSE(pi1): 1.251e-01, MSE(pi2): 1.051e-04, MSE(pi3): 6.636e-03\n",
      "Epoch 41700, Train loss: 2.738e+03, Test loss: 2.780e+04, MSE(e): 1.792e-04, MSE(pi1): 3.089e-02, MSE(pi2): 8.167e-05, MSE(pi3): 6.368e-03\n",
      "Epoch 41800, Train loss: 2.392e+03, Test loss: 2.833e+04, MSE(e): 1.093e-04, MSE(pi1): 6.689e-02, MSE(pi2): 6.021e-05, MSE(pi3): 6.292e-03\n",
      "Epoch 41900, Train loss: 8.170e+03, Test loss: 3.315e+04, MSE(e): 6.916e-04, MSE(pi1): 4.376e-02, MSE(pi2): 2.933e-04, MSE(pi3): 8.160e-03\n",
      "Epoch 42000, Train loss: 5.498e+03, Test loss: 3.632e+04, MSE(e): 4.371e-04, MSE(pi1): 2.999e-02, MSE(pi2): 1.936e-04, MSE(pi3): 8.261e-03\n",
      "Epoch 42100, Train loss: 2.838e+03, Test loss: 3.088e+04, MSE(e): 1.828e-04, MSE(pi1): 3.914e-02, MSE(pi2): 9.959e-05, MSE(pi3): 6.188e-03\n",
      "Epoch 42200, Train loss: 2.468e+03, Test loss: 3.085e+04, MSE(e): 1.196e-04, MSE(pi1): 6.762e-02, MSE(pi2): 6.577e-05, MSE(pi3): 5.956e-03\n",
      "Epoch 42300, Train loss: 5.538e+03, Test loss: 3.063e+04, MSE(e): 4.430e-04, MSE(pi1): 4.183e-02, MSE(pi2): 1.811e-04, MSE(pi3): 6.890e-03\n",
      "Epoch 42400, Train loss: 9.754e+03, Test loss: 3.902e+04, MSE(e): 8.220e-04, MSE(pi1): 8.104e-02, MSE(pi2): 3.255e-04, MSE(pi3): 7.230e-03\n",
      "Epoch 42500, Train loss: 5.019e+03, Test loss: 3.217e+04, MSE(e): 3.878e-04, MSE(pi1): 4.897e-02, MSE(pi2): 1.978e-04, MSE(pi3): 6.513e-03\n",
      "Epoch 42600, Train loss: 2.499e+03, Test loss: 2.935e+04, MSE(e): 1.628e-04, MSE(pi1): 2.875e-02, MSE(pi2): 9.910e-05, MSE(pi3): 5.831e-03\n",
      "Epoch 42700, Train loss: 5.178e+03, Test loss: 2.756e+04, MSE(e): 4.272e-04, MSE(pi1): 2.224e-02, MSE(pi2): 1.907e-04, MSE(pi3): 6.840e-03\n",
      "Epoch 42800, Train loss: 8.964e+03, Test loss: 4.124e+04, MSE(e): 7.340e-04, MSE(pi1): 7.901e-02, MSE(pi2): 2.986e-04, MSE(pi3): 8.340e-03\n",
      "Epoch 42900, Train loss: 2.333e+03, Test loss: 2.658e+04, MSE(e): 1.313e-04, MSE(pi1): 4.698e-02, MSE(pi2): 7.888e-05, MSE(pi3): 5.508e-03\n",
      "Epoch 43000, Train loss: 2.561e+03, Test loss: 3.001e+04, MSE(e): 1.353e-04, MSE(pi1): 5.226e-02, MSE(pi2): 6.504e-05, MSE(pi3): 6.853e-03\n",
      "Epoch 43100, Train loss: 1.154e+04, Test loss: 3.793e+04, MSE(e): 1.014e-03, MSE(pi1): 5.794e-02, MSE(pi2): 4.258e-04, MSE(pi3): 8.204e-03\n",
      "Epoch 43200, Train loss: 2.068e+03, Test loss: 2.475e+04, MSE(e): 1.121e-04, MSE(pi1): 3.439e-02, MSE(pi2): 6.232e-05, MSE(pi3): 6.027e-03\n",
      "Epoch 43300, Train loss: 4.898e+03, Test loss: 3.037e+04, MSE(e): 3.625e-04, MSE(pi1): 7.665e-02, MSE(pi2): 2.037e-04, MSE(pi3): 5.062e-03\n",
      "Epoch 43400, Train loss: 2.732e+03, Test loss: 2.780e+04, MSE(e): 1.548e-04, MSE(pi1): 5.470e-02, MSE(pi2): 7.260e-05, MSE(pi3): 6.375e-03\n",
      "Epoch 43500, Train loss: 5.045e+03, Test loss: 3.962e+04, MSE(e): 3.792e-04, MSE(pi1): 3.294e-02, MSE(pi2): 1.668e-04, MSE(pi3): 9.228e-03\n",
      "Epoch 43600, Train loss: 2.158e+03, Test loss: 2.519e+04, MSE(e): 1.161e-04, MSE(pi1): 4.397e-02, MSE(pi2): 6.734e-05, MSE(pi3): 5.570e-03\n",
      "Epoch 43700, Train loss: 3.105e+03, Test loss: 3.068e+04, MSE(e): 1.739e-04, MSE(pi1): 8.070e-02, MSE(pi2): 9.296e-05, MSE(pi3): 5.597e-03\n",
      "Epoch 43800, Train loss: 6.379e+03, Test loss: 2.964e+04, MSE(e): 5.114e-04, MSE(pi1): 6.202e-02, MSE(pi2): 2.028e-04, MSE(pi3): 6.448e-03\n",
      "Epoch 43900, Train loss: 2.669e+03, Test loss: 3.061e+04, MSE(e): 1.452e-04, MSE(pi1): 5.480e-02, MSE(pi2): 6.693e-05, MSE(pi3): 6.698e-03\n",
      "Epoch 44000, Train loss: 2.530e+03, Test loss: 2.432e+04, MSE(e): 1.603e-04, MSE(pi1): 3.596e-02, MSE(pi2): 8.536e-05, MSE(pi3): 5.673e-03\n",
      "Epoch 44100, Train loss: 5.752e+03, Test loss: 3.012e+04, MSE(e): 4.465e-04, MSE(pi1): 7.708e-02, MSE(pi2): 2.318e-04, MSE(pi3): 5.159e-03\n",
      "Epoch 44200, Train loss: 3.252e+03, Test loss: 2.684e+04, MSE(e): 2.323e-04, MSE(pi1): 2.560e-02, MSE(pi2): 1.261e-04, MSE(pi3): 6.722e-03\n",
      "Epoch 44300, Train loss: 7.141e+03, Test loss: 3.535e+04, MSE(e): 6.016e-04, MSE(pi1): 3.384e-02, MSE(pi2): 2.673e-04, MSE(pi3): 7.872e-03\n",
      "Epoch 44400, Train loss: 3.079e+03, Test loss: 3.449e+04, MSE(e): 1.939e-04, MSE(pi1): 2.990e-02, MSE(pi2): 8.675e-05, MSE(pi3): 8.407e-03\n",
      "Epoch 44500, Train loss: 1.836e+03, Test loss: 2.565e+04, MSE(e): 9.368e-05, MSE(pi1): 3.111e-02, MSE(pi2): 5.412e-05, MSE(pi3): 5.881e-03\n",
      "Epoch 44600, Train loss: 2.824e+03, Test loss: 2.437e+04, MSE(e): 2.101e-04, MSE(pi1): 1.634e-02, MSE(pi2): 1.114e-04, MSE(pi3): 5.587e-03\n",
      "Epoch 44700, Train loss: 5.012e+03, Test loss: 2.751e+04, MSE(e): 3.962e-04, MSE(pi1): 5.131e-02, MSE(pi2): 2.004e-04, MSE(pi3): 5.360e-03\n",
      "Epoch 44800, Train loss: 4.192e+03, Test loss: 3.335e+04, MSE(e): 2.830e-04, MSE(pi1): 7.415e-02, MSE(pi2): 1.361e-04, MSE(pi3): 6.206e-03\n",
      "Epoch 44900, Train loss: 4.143e+03, Test loss: 2.668e+04, MSE(e): 3.146e-04, MSE(pi1): 4.912e-02, MSE(pi2): 1.817e-04, MSE(pi3): 5.060e-03\n",
      "Epoch 45000, Train loss: 6.252e+03, Test loss: 3.053e+04, MSE(e): 4.863e-04, MSE(pi1): 8.491e-02, MSE(pi2): 2.382e-04, MSE(pi3): 5.400e-03\n",
      "Epoch 45100, Train loss: 2.710e+03, Test loss: 2.384e+04, MSE(e): 1.961e-04, MSE(pi1): 1.552e-02, MSE(pi2): 9.837e-05, MSE(pi3): 5.942e-03\n",
      "Epoch 45200, Train loss: 2.591e+03, Test loss: 2.462e+04, MSE(e): 1.623e-04, MSE(pi1): 3.799e-02, MSE(pi2): 8.702e-05, MSE(pi3): 5.881e-03\n",
      "Epoch 45300, Train loss: 6.285e+03, Test loss: 4.076e+04, MSE(e): 5.192e-04, MSE(pi1): 2.785e-02, MSE(pi2): 2.208e-04, MSE(pi3): 8.148e-03\n",
      "Epoch 45400, Train loss: 7.540e+03, Test loss: 3.817e+04, MSE(e): 6.201e-04, MSE(pi1): 5.404e-02, MSE(pi2): 2.428e-04, MSE(pi3): 7.982e-03\n",
      "Epoch 45500, Train loss: 3.700e+03, Test loss: 2.856e+04, MSE(e): 2.668e-04, MSE(pi1): 3.061e-02, MSE(pi2): 1.187e-04, MSE(pi3): 7.249e-03\n",
      "Epoch 45600, Train loss: 6.130e+03, Test loss: 3.047e+04, MSE(e): 4.947e-04, MSE(pi1): 6.112e-02, MSE(pi2): 2.358e-04, MSE(pi3): 5.713e-03\n",
      "Epoch 45700, Train loss: 5.206e+03, Test loss: 3.504e+04, MSE(e): 4.073e-04, MSE(pi1): 5.203e-02, MSE(pi2): 2.245e-04, MSE(pi3): 6.130e-03\n",
      "Epoch 45800, Train loss: 4.178e+03, Test loss: 3.063e+04, MSE(e): 2.976e-04, MSE(pi1): 4.814e-02, MSE(pi2): 1.243e-04, MSE(pi3): 7.208e-03\n",
      "Epoch 45900, Train loss: 2.651e+03, Test loss: 2.876e+04, MSE(e): 1.436e-04, MSE(pi1): 4.866e-02, MSE(pi2): 6.760e-05, MSE(pi3): 7.287e-03\n",
      "Epoch 46000, Train loss: 2.686e+03, Test loss: 2.769e+04, MSE(e): 1.582e-04, MSE(pi1): 5.253e-02, MSE(pi2): 9.056e-05, MSE(pi3): 5.788e-03\n",
      "Epoch 46100, Train loss: 8.758e+03, Test loss: 3.436e+04, MSE(e): 7.656e-04, MSE(pi1): 2.720e-02, MSE(pi2): 3.418e-04, MSE(pi3): 8.295e-03\n",
      "Epoch 46200, Train loss: 2.090e+03, Test loss: 2.913e+04, MSE(e): 1.257e-04, MSE(pi1): 2.605e-02, MSE(pi2): 6.269e-05, MSE(pi3): 5.732e-03\n",
      "Epoch 46300, Train loss: 2.411e+03, Test loss: 2.557e+04, MSE(e): 1.358e-04, MSE(pi1): 4.921e-02, MSE(pi2): 7.936e-05, MSE(pi3): 5.613e-03\n",
      "Epoch 46400, Train loss: 3.327e+03, Test loss: 3.101e+04, MSE(e): 2.008e-04, MSE(pi1): 6.887e-02, MSE(pi2): 8.363e-05, MSE(pi3): 6.308e-03\n",
      "Epoch 46500, Train loss: 4.544e+03, Test loss: 3.201e+04, MSE(e): 3.208e-04, MSE(pi1): 7.276e-02, MSE(pi2): 1.611e-04, MSE(pi3): 6.086e-03\n",
      "Epoch 46600, Train loss: 2.505e+03, Test loss: 2.882e+04, MSE(e): 1.453e-04, MSE(pi1): 3.737e-02, MSE(pi2): 7.246e-05, MSE(pi3): 6.785e-03\n",
      "Epoch 46700, Train loss: 5.086e+03, Test loss: 3.824e+04, MSE(e): 3.724e-04, MSE(pi1): 5.751e-02, MSE(pi2): 1.530e-04, MSE(pi3): 7.875e-03\n",
      "Epoch 46800, Train loss: 2.903e+03, Test loss: 2.918e+04, MSE(e): 1.945e-04, MSE(pi1): 4.239e-02, MSE(pi2): 1.045e-04, MSE(pi3): 5.332e-03\n",
      "Epoch 46900, Train loss: 4.854e+03, Test loss: 3.892e+04, MSE(e): 3.678e-04, MSE(pi1): 4.422e-02, MSE(pi2): 1.576e-04, MSE(pi3): 7.341e-03\n",
      "Epoch 47000, Train loss: 4.098e+03, Test loss: 3.020e+04, MSE(e): 2.970e-04, MSE(pi1): 6.234e-02, MSE(pi2): 1.630e-04, MSE(pi3): 5.039e-03\n",
      "Epoch 47100, Train loss: 3.027e+03, Test loss: 2.964e+04, MSE(e): 1.875e-04, MSE(pi1): 5.133e-02, MSE(pi2): 7.266e-05, MSE(pi3): 6.388e-03\n",
      "Epoch 47200, Train loss: 3.680e+03, Test loss: 3.285e+04, MSE(e): 2.642e-04, MSE(pi1): 3.771e-02, MSE(pi2): 1.354e-04, MSE(pi3): 6.608e-03\n",
      "Epoch 47300, Train loss: 2.903e+03, Test loss: 2.803e+04, MSE(e): 2.031e-04, MSE(pi1): 2.689e-02, MSE(pi2): 9.861e-05, MSE(pi3): 6.028e-03\n",
      "Epoch 47400, Train loss: 2.264e+03, Test loss: 2.893e+04, MSE(e): 1.147e-04, MSE(pi1): 4.392e-02, MSE(pi2): 5.855e-05, MSE(pi3): 6.782e-03\n",
      "Epoch 47500, Train loss: 3.199e+03, Test loss: 3.126e+04, MSE(e): 2.187e-04, MSE(pi1): 3.972e-02, MSE(pi2): 1.068e-04, MSE(pi3): 6.149e-03\n",
      "Epoch 47600, Train loss: 1.821e+03, Test loss: 2.881e+04, MSE(e): 6.652e-05, MSE(pi1): 6.040e-02, MSE(pi2): 3.999e-05, MSE(pi3): 5.516e-03\n",
      "Epoch 47700, Train loss: 2.668e+03, Test loss: 3.291e+04, MSE(e): 1.591e-04, MSE(pi1): 4.444e-02, MSE(pi2): 7.894e-05, MSE(pi3): 6.325e-03\n",
      "Epoch 47800, Train loss: 4.502e+03, Test loss: 3.154e+04, MSE(e): 2.861e-04, MSE(pi1): 8.020e-02, MSE(pi2): 1.341e-04, MSE(pi3): 8.381e-03\n",
      "Epoch 47900, Train loss: 3.361e+03, Test loss: 3.325e+04, MSE(e): 2.248e-04, MSE(pi1): 3.633e-02, MSE(pi2): 1.066e-04, MSE(pi3): 7.500e-03\n",
      "Epoch 48000, Train loss: 2.347e+03, Test loss: 2.849e+04, MSE(e): 1.232e-04, MSE(pi1): 4.320e-02, MSE(pi2): 5.935e-05, MSE(pi3): 6.828e-03\n",
      "Epoch 48100, Train loss: 3.190e+03, Test loss: 2.818e+04, MSE(e): 2.050e-04, MSE(pi1): 5.447e-02, MSE(pi2): 1.037e-04, MSE(pi3): 5.954e-03\n",
      "Epoch 48200, Train loss: 2.596e+03, Test loss: 2.745e+04, MSE(e): 1.657e-04, MSE(pi1): 3.810e-02, MSE(pi2): 9.100e-05, MSE(pi3): 5.580e-03\n",
      "Epoch 48300, Train loss: 5.039e+03, Test loss: 3.078e+04, MSE(e): 3.963e-04, MSE(pi1): 5.694e-02, MSE(pi2): 2.118e-04, MSE(pi3): 5.066e-03\n",
      "Epoch 48400, Train loss: 3.600e+03, Test loss: 3.537e+04, MSE(e): 2.189e-04, MSE(pi1): 6.869e-02, MSE(pi2): 1.095e-04, MSE(pi3): 7.241e-03\n",
      "Epoch 48500, Train loss: 2.176e+03, Test loss: 3.108e+04, MSE(e): 1.127e-04, MSE(pi1): 3.538e-02, MSE(pi2): 4.999e-05, MSE(pi3): 6.955e-03\n",
      "Epoch 48600, Train loss: 2.281e+03, Test loss: 3.096e+04, MSE(e): 1.246e-04, MSE(pi1): 2.895e-02, MSE(pi2): 6.028e-05, MSE(pi3): 7.447e-03\n",
      "Epoch 48700, Train loss: 2.851e+03, Test loss: 3.351e+04, MSE(e): 1.660e-04, MSE(pi1): 4.537e-02, MSE(pi2): 7.814e-05, MSE(pi3): 7.376e-03\n",
      "Epoch 48800, Train loss: 3.311e+03, Test loss: 3.592e+04, MSE(e): 1.832e-04, MSE(pi1): 7.471e-02, MSE(pi2): 8.355e-05, MSE(pi3): 7.310e-03\n",
      "Epoch 48900, Train loss: 4.372e+03, Test loss: 3.291e+04, MSE(e): 3.277e-04, MSE(pi1): 4.255e-02, MSE(pi2): 1.668e-04, MSE(pi3): 6.694e-03\n",
      "Epoch 49000, Train loss: 2.292e+03, Test loss: 3.089e+04, MSE(e): 1.245e-04, MSE(pi1): 3.398e-02, MSE(pi2): 5.910e-05, MSE(pi3): 7.076e-03\n",
      "Epoch 49100, Train loss: 8.576e+03, Test loss: 3.826e+04, MSE(e): 7.131e-04, MSE(pi1): 6.099e-02, MSE(pi2): 3.056e-04, MSE(pi3): 8.351e-03\n",
      "Epoch 49200, Train loss: 2.358e+03, Test loss: 3.315e+04, MSE(e): 1.413e-04, MSE(pi1): 2.596e-02, MSE(pi2): 6.636e-05, MSE(pi3): 6.849e-03\n",
      "Epoch 49300, Train loss: 2.286e+03, Test loss: 3.301e+04, MSE(e): 1.257e-04, MSE(pi1): 4.509e-02, MSE(pi2): 5.857e-05, MSE(pi3): 5.788e-03\n",
      "Epoch 49400, Train loss: 3.846e+03, Test loss: 3.391e+04, MSE(e): 2.506e-04, MSE(pi1): 6.852e-02, MSE(pi2): 1.245e-04, MSE(pi3): 6.550e-03\n",
      "Epoch 49500, Train loss: 2.231e+03, Test loss: 2.848e+04, MSE(e): 9.857e-05, MSE(pi1): 5.298e-02, MSE(pi2): 5.329e-05, MSE(pi3): 7.152e-03\n",
      "Epoch 49600, Train loss: 3.067e+03, Test loss: 2.818e+04, MSE(e): 1.691e-04, MSE(pi1): 7.707e-02, MSE(pi2): 8.930e-05, MSE(pi3): 6.049e-03\n",
      "Epoch 49700, Train loss: 9.798e+03, Test loss: 3.292e+04, MSE(e): 8.364e-04, MSE(pi1): 8.393e-02, MSE(pi2): 3.946e-04, MSE(pi3): 5.943e-03\n",
      "Epoch 49800, Train loss: 4.785e+03, Test loss: 2.744e+04, MSE(e): 3.921e-04, MSE(pi1): 2.672e-02, MSE(pi2): 1.949e-04, MSE(pi3): 5.968e-03\n",
      "Epoch 49900, Train loss: 2.058e+03, Test loss: 3.229e+04, MSE(e): 8.529e-05, MSE(pi1): 5.876e-02, MSE(pi2): 4.207e-05, MSE(pi3): 6.175e-03\n",
      "Epoch 50000, Train loss: 1.928e+03, Test loss: 3.003e+04, MSE(e): 8.681e-05, MSE(pi1): 3.641e-02, MSE(pi2): 4.018e-05, MSE(pi3): 6.960e-03\n",
      "Epoch 50100, Train loss: 2.503e+03, Test loss: 3.198e+04, MSE(e): 1.607e-04, MSE(pi1): 3.418e-02, MSE(pi2): 8.435e-05, MSE(pi3): 5.542e-03\n",
      "Epoch 50200, Train loss: 3.215e+03, Test loss: 3.593e+04, MSE(e): 2.028e-04, MSE(pi1): 6.129e-02, MSE(pi2): 9.190e-05, MSE(pi3): 5.745e-03\n",
      "Epoch 50300, Train loss: 2.140e+03, Test loss: 3.286e+04, MSE(e): 1.063e-04, MSE(pi1): 4.276e-02, MSE(pi2): 4.725e-05, MSE(pi3): 6.498e-03\n",
      "Epoch 50400, Train loss: 4.305e+03, Test loss: 3.730e+04, MSE(e): 2.551e-04, MSE(pi1): 1.077e-01, MSE(pi2): 1.264e-04, MSE(pi3): 6.777e-03\n",
      "Epoch 50500, Train loss: 4.711e+03, Test loss: 3.016e+04, MSE(e): 3.808e-04, MSE(pi1): 3.183e-02, MSE(pi2): 1.919e-04, MSE(pi3): 5.848e-03\n",
      "Epoch 50600, Train loss: 1.191e+04, Test loss: 2.917e+04, MSE(e): 1.100e-03, MSE(pi1): 4.077e-02, MSE(pi2): 5.250e-04, MSE(pi3): 5.035e-03\n",
      "Epoch 50700, Train loss: 5.178e+03, Test loss: 3.461e+04, MSE(e): 3.922e-04, MSE(pi1): 5.457e-02, MSE(pi2): 2.246e-04, MSE(pi3): 7.098e-03\n",
      "Epoch 50800, Train loss: 2.092e+03, Test loss: 3.004e+04, MSE(e): 1.205e-04, MSE(pi1): 2.227e-02, MSE(pi2): 5.088e-05, MSE(pi3): 6.642e-03\n",
      "Epoch 50900, Train loss: 3.877e+03, Test loss: 3.616e+04, MSE(e): 2.820e-04, MSE(pi1): 5.112e-02, MSE(pi2): 1.503e-04, MSE(pi3): 5.459e-03\n",
      "Epoch 51000, Train loss: 3.089e+03, Test loss: 3.379e+04, MSE(e): 1.800e-04, MSE(pi1): 5.599e-02, MSE(pi2): 7.720e-05, MSE(pi3): 7.294e-03\n",
      "Epoch 51100, Train loss: 1.454e+03, Test loss: 3.214e+04, MSE(e): 6.042e-05, MSE(pi1): 2.322e-02, MSE(pi2): 3.526e-05, MSE(pi3): 6.173e-03\n",
      "Epoch 51200, Train loss: 2.056e+03, Test loss: 3.059e+04, MSE(e): 9.786e-05, MSE(pi1): 3.918e-02, MSE(pi2): 5.732e-05, MSE(pi3): 6.856e-03\n",
      "Epoch 51300, Train loss: 3.809e+03, Test loss: 3.540e+04, MSE(e): 2.609e-04, MSE(pi1): 6.093e-02, MSE(pi2): 1.411e-04, MSE(pi3): 5.911e-03\n",
      "Epoch 51400, Train loss: 1.693e+03, Test loss: 3.152e+04, MSE(e): 8.748e-05, MSE(pi1): 1.469e-02, MSE(pi2): 3.837e-05, MSE(pi3): 6.712e-03\n",
      "Epoch 51500, Train loss: 2.143e+03, Test loss: 3.207e+04, MSE(e): 1.312e-04, MSE(pi1): 1.278e-02, MSE(pi2): 6.013e-05, MSE(pi3): 7.034e-03\n",
      "Epoch 51600, Train loss: 3.019e+03, Test loss: 3.399e+04, MSE(e): 2.168e-04, MSE(pi1): 1.452e-02, MSE(pi2): 1.284e-04, MSE(pi3): 7.053e-03\n",
      "Epoch 51700, Train loss: 3.495e+03, Test loss: 3.281e+04, MSE(e): 2.170e-04, MSE(pi1): 6.398e-02, MSE(pi2): 1.298e-04, MSE(pi3): 6.858e-03\n",
      "Epoch 51800, Train loss: 3.556e+03, Test loss: 2.839e+04, MSE(e): 2.698e-04, MSE(pi1): 2.995e-02, MSE(pi2): 1.403e-04, MSE(pi3): 5.587e-03\n",
      "Epoch 51900, Train loss: 2.799e+03, Test loss: 3.682e+04, MSE(e): 1.775e-04, MSE(pi1): 4.351e-02, MSE(pi2): 8.417e-05, MSE(pi3): 5.886e-03\n",
      "Epoch 52000, Train loss: 4.192e+03, Test loss: 3.790e+04, MSE(e): 3.211e-04, MSE(pi1): 3.871e-02, MSE(pi2): 1.537e-04, MSE(pi3): 5.941e-03\n",
      "Epoch 52100, Train loss: 2.930e+03, Test loss: 3.359e+04, MSE(e): 2.068e-04, MSE(pi1): 2.263e-02, MSE(pi2): 9.886e-05, MSE(pi3): 6.355e-03\n",
      "Epoch 52200, Train loss: 1.320e+03, Test loss: 3.241e+04, MSE(e): 5.003e-05, MSE(pi1): 2.288e-02, MSE(pi2): 2.800e-05, MSE(pi3): 5.912e-03\n",
      "Epoch 52300, Train loss: 6.114e+03, Test loss: 3.830e+04, MSE(e): 5.005e-04, MSE(pi1): 3.850e-02, MSE(pi2): 2.230e-04, MSE(pi3): 7.238e-03\n",
      "Epoch 52400, Train loss: 1.734e+03, Test loss: 3.319e+04, MSE(e): 6.687e-05, MSE(pi1): 5.028e-02, MSE(pi2): 3.714e-05, MSE(pi3): 5.622e-03\n",
      "Epoch 52500, Train loss: 7.862e+03, Test loss: 4.008e+04, MSE(e): 6.636e-04, MSE(pi1): 3.922e-02, MSE(pi2): 3.174e-04, MSE(pi3): 8.335e-03\n",
      "Epoch 52600, Train loss: 1.569e+03, Test loss: 3.239e+04, MSE(e): 7.576e-05, MSE(pi1): 1.719e-02, MSE(pi2): 3.461e-05, MSE(pi3): 6.392e-03\n",
      "Epoch 52700, Train loss: 1.848e+03, Test loss: 3.530e+04, MSE(e): 9.856e-05, MSE(pi1): 1.820e-02, MSE(pi2): 4.499e-05, MSE(pi3): 6.801e-03\n",
      "Epoch 52800, Train loss: 1.893e+03, Test loss: 3.536e+04, MSE(e): 1.082e-04, MSE(pi1): 1.721e-02, MSE(pi2): 4.732e-05, MSE(pi3): 6.389e-03\n",
      "Epoch 52900, Train loss: 1.620e+03, Test loss: 3.388e+04, MSE(e): 7.389e-05, MSE(pi1): 2.739e-02, MSE(pi2): 3.049e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 53000, Train loss: 3.155e+03, Test loss: 3.835e+04, MSE(e): 2.039e-04, MSE(pi1): 5.581e-02, MSE(pi2): 1.092e-04, MSE(pi3): 5.586e-03\n",
      "Epoch 53100, Train loss: 2.586e+03, Test loss: 3.618e+04, MSE(e): 1.745e-04, MSE(pi1): 2.237e-02, MSE(pi2): 7.066e-05, MSE(pi3): 6.166e-03\n",
      "Epoch 53200, Train loss: 2.848e+03, Test loss: 4.239e+04, MSE(e): 1.727e-04, MSE(pi1): 5.167e-02, MSE(pi2): 8.528e-05, MSE(pi3): 6.041e-03\n",
      "Epoch 53300, Train loss: 2.149e+03, Test loss: 3.963e+04, MSE(e): 8.115e-05, MSE(pi1): 6.006e-02, MSE(pi2): 3.296e-05, MSE(pi3): 7.370e-03\n",
      "Epoch 53400, Train loss: 3.554e+03, Test loss: 3.597e+04, MSE(e): 2.551e-04, MSE(pi1): 3.215e-02, MSE(pi2): 1.032e-04, MSE(pi3): 6.812e-03\n",
      "Epoch 53500, Train loss: 1.901e+03, Test loss: 3.613e+04, MSE(e): 1.088e-04, MSE(pi1): 1.300e-02, MSE(pi2): 4.883e-05, MSE(pi3): 6.830e-03\n",
      "Epoch 53600, Train loss: 3.003e+03, Test loss: 3.789e+04, MSE(e): 1.847e-04, MSE(pi1): 4.949e-02, MSE(pi2): 9.130e-05, MSE(pi3): 6.608e-03\n",
      "Epoch 53700, Train loss: 1.572e+03, Test loss: 3.683e+04, MSE(e): 6.330e-05, MSE(pi1): 2.590e-02, MSE(pi2): 3.283e-05, MSE(pi3): 6.804e-03\n",
      "Epoch 53800, Train loss: 2.080e+03, Test loss: 3.671e+04, MSE(e): 1.075e-04, MSE(pi1): 4.014e-02, MSE(pi2): 5.254e-05, MSE(pi3): 6.037e-03\n",
      "Epoch 53900, Train loss: 1.838e+03, Test loss: 3.672e+04, MSE(e): 9.468e-05, MSE(pi1): 2.790e-02, MSE(pi2): 3.798e-05, MSE(pi3): 6.120e-03\n",
      "Epoch 54000, Train loss: 1.751e+03, Test loss: 3.718e+04, MSE(e): 8.429e-05, MSE(pi1): 2.621e-02, MSE(pi2): 3.809e-05, MSE(pi3): 6.464e-03\n",
      "Epoch 54100, Train loss: 2.863e+03, Test loss: 4.040e+04, MSE(e): 1.824e-04, MSE(pi1): 3.816e-02, MSE(pi2): 7.234e-05, MSE(pi3): 6.578e-03\n",
      "Epoch 54200, Train loss: 1.822e+03, Test loss: 3.841e+04, MSE(e): 6.544e-05, MSE(pi1): 5.837e-02, MSE(pi2): 3.350e-05, MSE(pi3): 5.840e-03\n",
      "Epoch 54300, Train loss: 3.426e+03, Test loss: 4.104e+04, MSE(e): 2.516e-04, MSE(pi1): 1.755e-02, MSE(pi2): 1.243e-04, MSE(pi3): 7.339e-03\n",
      "Epoch 54400, Train loss: 2.591e+03, Test loss: 4.526e+04, MSE(e): 1.374e-04, MSE(pi1): 4.633e-02, MSE(pi2): 7.128e-05, MSE(pi3): 7.534e-03\n",
      "Epoch 54500, Train loss: 2.515e+03, Test loss: 3.940e+04, MSE(e): 1.558e-04, MSE(pi1): 3.577e-02, MSE(pi2): 9.289e-05, MSE(pi3): 5.993e-03\n",
      "Epoch 54600, Train loss: 2.409e+03, Test loss: 4.199e+04, MSE(e): 1.193e-04, MSE(pi1): 4.684e-02, MSE(pi2): 6.683e-05, MSE(pi3): 7.470e-03\n",
      "Epoch 54700, Train loss: 2.162e+03, Test loss: 4.452e+04, MSE(e): 1.009e-04, MSE(pi1): 4.799e-02, MSE(pi2): 4.881e-05, MSE(pi3): 6.735e-03\n",
      "Epoch 54800, Train loss: 1.519e+03, Test loss: 4.075e+04, MSE(e): 5.060e-05, MSE(pi1): 4.136e-02, MSE(pi2): 2.721e-05, MSE(pi3): 5.992e-03\n",
      "Epoch 54900, Train loss: 2.070e+03, Test loss: 4.087e+04, MSE(e): 1.007e-04, MSE(pi1): 4.308e-02, MSE(pi2): 4.064e-05, MSE(pi3): 6.319e-03\n",
      "Epoch 55000, Train loss: 1.837e+03, Test loss: 4.459e+04, MSE(e): 4.424e-05, MSE(pi1): 6.622e-02, MSE(pi2): 1.995e-05, MSE(pi3): 7.325e-03\n",
      "Epoch 55100, Train loss: 6.531e+03, Test loss: 6.086e+04, MSE(e): 5.670e-04, MSE(pi1): 3.115e-02, MSE(pi2): 2.831e-04, MSE(pi3): 5.493e-03\n",
      "Epoch 55200, Train loss: 2.363e+03, Test loss: 4.091e+04, MSE(e): 1.211e-04, MSE(pi1): 5.916e-02, MSE(pi2): 6.491e-05, MSE(pi3): 5.605e-03\n",
      "Epoch 55300, Train loss: 2.392e+03, Test loss: 4.553e+04, MSE(e): 1.308e-04, MSE(pi1): 4.184e-02, MSE(pi2): 5.718e-05, MSE(pi3): 6.646e-03\n",
      "Epoch 55400, Train loss: 6.336e+03, Test loss: 4.445e+04, MSE(e): 5.300e-04, MSE(pi1): 5.153e-02, MSE(pi2): 2.705e-04, MSE(pi3): 5.201e-03\n",
      "Epoch 55500, Train loss: 2.006e+03, Test loss: 4.299e+04, MSE(e): 9.524e-05, MSE(pi1): 4.260e-02, MSE(pi2): 3.686e-05, MSE(pi3): 6.279e-03\n",
      "Epoch 55600, Train loss: 3.328e+03, Test loss: 4.407e+04, MSE(e): 2.217e-04, MSE(pi1): 5.102e-02, MSE(pi2): 1.255e-04, MSE(pi3): 6.009e-03\n",
      "Epoch 55700, Train loss: 1.794e+03, Test loss: 4.732e+04, MSE(e): 6.299e-05, MSE(pi1): 3.680e-02, MSE(pi2): 2.670e-05, MSE(pi3): 7.962e-03\n",
      "Epoch 55800, Train loss: 1.804e+03, Test loss: 4.164e+04, MSE(e): 6.066e-05, MSE(pi1): 5.922e-02, MSE(pi2): 2.474e-05, MSE(pi3): 6.057e-03\n",
      "Epoch 55900, Train loss: 1.579e+03, Test loss: 4.062e+04, MSE(e): 6.739e-05, MSE(pi1): 3.231e-02, MSE(pi2): 2.818e-05, MSE(pi3): 5.816e-03\n",
      "Epoch 56000, Train loss: 2.481e+03, Test loss: 4.427e+04, MSE(e): 1.553e-04, MSE(pi1): 2.430e-02, MSE(pi2): 7.382e-05, MSE(pi3): 6.853e-03\n",
      "Epoch 56100, Train loss: 2.018e+03, Test loss: 4.935e+04, MSE(e): 9.549e-05, MSE(pi1): 4.339e-02, MSE(pi2): 4.834e-05, MSE(pi3): 6.287e-03\n",
      "Epoch 56200, Train loss: 1.828e+03, Test loss: 4.142e+04, MSE(e): 8.804e-05, MSE(pi1): 3.582e-02, MSE(pi2): 3.623e-05, MSE(pi3): 5.892e-03\n",
      "Epoch 56300, Train loss: 1.863e+03, Test loss: 4.475e+04, MSE(e): 6.450e-05, MSE(pi1): 6.118e-02, MSE(pi2): 2.656e-05, MSE(pi3): 6.066e-03\n",
      "Epoch 56400, Train loss: 1.080e+04, Test loss: 4.428e+04, MSE(e): 9.595e-04, MSE(pi1): 6.873e-02, MSE(pi2): 4.677e-04, MSE(pi3): 5.127e-03\n",
      "Epoch 56500, Train loss: 2.916e+03, Test loss: 4.775e+04, MSE(e): 1.715e-04, MSE(pi1): 6.494e-02, MSE(pi2): 9.810e-05, MSE(pi3): 5.513e-03\n",
      "Epoch 56600, Train loss: 1.856e+03, Test loss: 4.455e+04, MSE(e): 9.599e-05, MSE(pi1): 2.228e-02, MSE(pi2): 4.428e-05, MSE(pi3): 6.729e-03\n",
      "Epoch 56700, Train loss: 2.578e+03, Test loss: 5.039e+04, MSE(e): 1.041e-04, MSE(pi1): 8.626e-02, MSE(pi2): 4.974e-05, MSE(pi3): 6.743e-03\n",
      "Epoch 56800, Train loss: 4.197e+03, Test loss: 4.713e+04, MSE(e): 3.415e-04, MSE(pi1): 1.931e-02, MSE(pi2): 1.704e-04, MSE(pi3): 5.884e-03\n",
      "Epoch 56900, Train loss: 3.008e+03, Test loss: 5.248e+04, MSE(e): 1.927e-04, MSE(pi1): 3.616e-02, MSE(pi2): 8.557e-05, MSE(pi3): 7.189e-03\n",
      "Epoch 57000, Train loss: 1.974e+03, Test loss: 4.481e+04, MSE(e): 1.063e-04, MSE(pi1): 3.435e-02, MSE(pi2): 5.871e-05, MSE(pi3): 5.670e-03\n",
      "Epoch 57100, Train loss: 1.588e+03, Test loss: 4.413e+04, MSE(e): 6.609e-05, MSE(pi1): 3.474e-02, MSE(pi2): 3.760e-05, MSE(pi3): 5.801e-03\n",
      "Epoch 57200, Train loss: 6.163e+03, Test loss: 4.789e+04, MSE(e): 5.062e-04, MSE(pi1): 4.877e-02, MSE(pi2): 2.172e-04, MSE(pi3): 6.137e-03\n",
      "Epoch 57300, Train loss: 7.201e+03, Test loss: 5.427e+04, MSE(e): 5.777e-04, MSE(pi1): 6.462e-02, MSE(pi2): 2.526e-04, MSE(pi3): 7.780e-03\n",
      "Epoch 57400, Train loss: 4.097e+03, Test loss: 5.217e+04, MSE(e): 2.552e-04, MSE(pi1): 9.934e-02, MSE(pi2): 1.647e-04, MSE(pi3): 5.518e-03\n",
      "Epoch 57500, Train loss: 3.978e+03, Test loss: 5.156e+04, MSE(e): 2.288e-04, MSE(pi1): 1.105e-01, MSE(pi2): 1.106e-04, MSE(pi3): 5.847e-03\n",
      "Epoch 57600, Train loss: 2.054e+03, Test loss: 4.717e+04, MSE(e): 9.347e-05, MSE(pi1): 4.668e-02, MSE(pi2): 4.705e-05, MSE(pi3): 6.522e-03\n",
      "Epoch 57700, Train loss: 1.377e+03, Test loss: 4.966e+04, MSE(e): 4.010e-05, MSE(pi1): 2.221e-02, MSE(pi2): 2.019e-05, MSE(pi3): 7.536e-03\n",
      "Epoch 57800, Train loss: 1.434e+03, Test loss: 4.532e+04, MSE(e): 5.256e-05, MSE(pi1): 2.442e-02, MSE(pi2): 2.383e-05, MSE(pi3): 6.646e-03\n",
      "Epoch 57900, Train loss: 9.139e+03, Test loss: 5.075e+04, MSE(e): 7.795e-04, MSE(pi1): 6.545e-02, MSE(pi2): 3.691e-04, MSE(pi3): 6.887e-03\n",
      "Epoch 58000, Train loss: 2.019e+03, Test loss: 4.659e+04, MSE(e): 9.330e-05, MSE(pi1): 4.352e-02, MSE(pi2): 3.759e-05, MSE(pi3): 6.508e-03\n",
      "Epoch 58100, Train loss: 1.450e+03, Test loss: 4.705e+04, MSE(e): 4.818e-05, MSE(pi1): 3.982e-02, MSE(pi2): 2.770e-05, MSE(pi3): 5.700e-03\n",
      "Epoch 58200, Train loss: 9.260e+03, Test loss: 7.491e+04, MSE(e): 8.337e-04, MSE(pi1): 1.444e-02, MSE(pi2): 3.755e-04, MSE(pi3): 7.786e-03\n",
      "Epoch 58300, Train loss: 9.686e+03, Test loss: 5.876e+04, MSE(e): 8.347e-04, MSE(pi1): 4.826e-02, MSE(pi2): 3.812e-04, MSE(pi3): 8.557e-03\n",
      "Epoch 58400, Train loss: 1.780e+03, Test loss: 4.855e+04, MSE(e): 7.826e-05, MSE(pi1): 3.742e-02, MSE(pi2): 3.687e-05, MSE(pi3): 6.230e-03\n",
      "Epoch 58500, Train loss: 2.632e+03, Test loss: 5.196e+04, MSE(e): 1.614e-04, MSE(pi1): 3.705e-02, MSE(pi2): 7.395e-05, MSE(pi3): 6.475e-03\n",
      "Epoch 58600, Train loss: 2.049e+03, Test loss: 5.001e+04, MSE(e): 8.677e-05, MSE(pi1): 5.217e-02, MSE(pi2): 3.215e-05, MSE(pi3): 6.594e-03\n",
      "Epoch 58700, Train loss: 4.064e+03, Test loss: 5.047e+04, MSE(e): 2.824e-04, MSE(pi1): 5.600e-02, MSE(pi2): 1.349e-04, MSE(pi3): 6.791e-03\n",
      "Epoch 58800, Train loss: 3.550e+03, Test loss: 4.745e+04, MSE(e): 2.702e-04, MSE(pi1): 2.179e-02, MSE(pi2): 1.266e-04, MSE(pi3): 6.295e-03\n",
      "Epoch 58900, Train loss: 1.787e+03, Test loss: 5.120e+04, MSE(e): 4.406e-05, MSE(pi1): 6.578e-02, MSE(pi2): 2.117e-05, MSE(pi3): 6.883e-03\n",
      "Epoch 59000, Train loss: 2.144e+03, Test loss: 5.386e+04, MSE(e): 6.351e-05, MSE(pi1): 9.168e-02, MSE(pi2): 3.316e-05, MSE(pi3): 5.920e-03\n",
      "Epoch 59100, Train loss: 1.230e+03, Test loss: 4.809e+04, MSE(e): 4.292e-05, MSE(pi1): 1.988e-02, MSE(pi2): 2.076e-05, MSE(pi3): 6.014e-03\n",
      "Epoch 59200, Train loss: 1.699e+04, Test loss: 5.526e+04, MSE(e): 1.584e-03, MSE(pi1): 3.808e-02, MSE(pi2): 6.908e-04, MSE(pi3): 7.675e-03\n",
      "Epoch 59300, Train loss: 2.432e+03, Test loss: 5.013e+04, MSE(e): 1.107e-04, MSE(pi1): 7.423e-02, MSE(pi2): 4.543e-05, MSE(pi3): 5.828e-03\n",
      "Epoch 59400, Train loss: 2.770e+03, Test loss: 5.168e+04, MSE(e): 1.382e-04, MSE(pi1): 6.255e-02, MSE(pi2): 6.230e-05, MSE(pi3): 7.626e-03\n",
      "Epoch 59500, Train loss: 8.390e+03, Test loss: 4.940e+04, MSE(e): 7.600e-04, MSE(pi1): 2.366e-02, MSE(pi2): 3.745e-04, MSE(pi3): 5.534e-03\n",
      "Epoch 59600, Train loss: 1.622e+03, Test loss: 4.876e+04, MSE(e): 6.106e-05, MSE(pi1): 3.933e-02, MSE(pi2): 2.296e-05, MSE(pi3): 6.184e-03\n",
      "Epoch 59700, Train loss: 1.528e+03, Test loss: 4.629e+04, MSE(e): 4.868e-05, MSE(pi1): 3.963e-02, MSE(pi2): 2.603e-05, MSE(pi3): 6.451e-03\n",
      "Epoch 59800, Train loss: 1.492e+03, Test loss: 4.923e+04, MSE(e): 4.598e-05, MSE(pi1): 3.539e-02, MSE(pi2): 2.419e-05, MSE(pi3): 6.785e-03\n",
      "Epoch 59900, Train loss: 1.638e+03, Test loss: 4.762e+04, MSE(e): 7.140e-05, MSE(pi1): 3.043e-02, MSE(pi2): 2.860e-05, MSE(pi3): 6.196e-03\n",
      "Epoch 60000, Train loss: 1.204e+03, Test loss: 4.780e+04, MSE(e): 3.921e-05, MSE(pi1): 1.916e-02, MSE(pi2): 1.997e-05, MSE(pi3): 6.204e-03\n",
      "Epoch 60100, Train loss: 2.109e+03, Test loss: 5.468e+04, MSE(e): 1.205e-04, MSE(pi1): 2.439e-02, MSE(pi2): 5.868e-05, MSE(pi3): 6.600e-03\n",
      "Epoch 60200, Train loss: 4.214e+03, Test loss: 5.596e+04, MSE(e): 2.872e-04, MSE(pi1): 7.377e-02, MSE(pi2): 1.427e-04, MSE(pi3): 6.044e-03\n",
      "Epoch 60300, Train loss: 6.000e+03, Test loss: 5.110e+04, MSE(e): 4.991e-04, MSE(pi1): 4.257e-02, MSE(pi2): 2.374e-04, MSE(pi3): 5.838e-03\n",
      "Epoch 60400, Train loss: 1.517e+03, Test loss: 4.965e+04, MSE(e): 4.563e-05, MSE(pi1): 5.044e-02, MSE(pi2): 2.450e-05, MSE(pi3): 5.563e-03\n",
      "Epoch 60500, Train loss: 2.402e+03, Test loss: 5.287e+04, MSE(e): 1.496e-04, MSE(pi1): 2.552e-02, MSE(pi2): 8.252e-05, MSE(pi3): 6.505e-03\n",
      "Epoch 60600, Train loss: 6.568e+03, Test loss: 5.037e+04, MSE(e): 5.655e-04, MSE(pi1): 3.606e-02, MSE(pi2): 3.041e-04, MSE(pi3): 5.518e-03\n",
      "Epoch 60700, Train loss: 4.579e+03, Test loss: 5.293e+04, MSE(e): 3.214e-04, MSE(pi1): 7.456e-02, MSE(pi2): 1.724e-04, MSE(pi3): 6.193e-03\n",
      "Epoch 60800, Train loss: 2.569e+03, Test loss: 5.226e+04, MSE(e): 1.292e-04, MSE(pi1): 6.411e-02, MSE(pi2): 6.672e-05, MSE(pi3): 6.365e-03\n",
      "Epoch 60900, Train loss: 2.070e+03, Test loss: 5.042e+04, MSE(e): 5.844e-05, MSE(pi1): 8.195e-02, MSE(pi2): 2.862e-05, MSE(pi3): 6.660e-03\n",
      "Epoch 61000, Train loss: 1.457e+03, Test loss: 5.390e+04, MSE(e): 5.986e-05, MSE(pi1): 2.037e-02, MSE(pi2): 3.074e-05, MSE(pi3): 6.548e-03\n",
      "Epoch 61100, Train loss: 1.658e+03, Test loss: 5.143e+04, MSE(e): 5.662e-05, MSE(pi1): 3.463e-02, MSE(pi2): 2.789e-05, MSE(pi3): 7.456e-03\n",
      "Epoch 61200, Train loss: 2.531e+03, Test loss: 4.922e+04, MSE(e): 1.767e-04, MSE(pi1): 1.710e-02, MSE(pi2): 8.467e-05, MSE(pi3): 5.938e-03\n",
      "Epoch 61300, Train loss: 1.707e+03, Test loss: 5.050e+04, MSE(e): 6.083e-05, MSE(pi1): 4.288e-02, MSE(pi2): 3.274e-05, MSE(pi3): 6.701e-03\n",
      "Epoch 61400, Train loss: 2.099e+03, Test loss: 4.918e+04, MSE(e): 1.114e-04, MSE(pi1): 3.681e-02, MSE(pi2): 4.583e-05, MSE(pi3): 6.171e-03\n",
      "Epoch 61500, Train loss: 4.883e+03, Test loss: 5.522e+04, MSE(e): 3.736e-04, MSE(pi1): 5.693e-02, MSE(pi2): 2.328e-04, MSE(pi3): 5.777e-03\n",
      "Epoch 61600, Train loss: 2.032e+03, Test loss: 4.983e+04, MSE(e): 6.848e-05, MSE(pi1): 7.746e-02, MSE(pi2): 4.241e-05, MSE(pi3): 5.725e-03\n",
      "Epoch 61700, Train loss: 1.428e+04, Test loss: 5.763e+04, MSE(e): 1.331e-03, MSE(pi1): 1.671e-02, MSE(pi2): 5.783e-04, MSE(pi3): 8.025e-03\n",
      "Epoch 61800, Train loss: 2.383e+03, Test loss: 5.575e+04, MSE(e): 1.282e-04, MSE(pi1): 4.311e-02, MSE(pi2): 5.540e-05, MSE(pi3): 6.699e-03\n",
      "Epoch 61900, Train loss: 1.900e+03, Test loss: 5.440e+04, MSE(e): 9.495e-05, MSE(pi1): 2.765e-02, MSE(pi2): 4.450e-05, MSE(pi3): 6.743e-03\n",
      "Epoch 62000, Train loss: 7.232e+03, Test loss: 4.800e+04, MSE(e): 6.257e-04, MSE(pi1): 4.087e-02, MSE(pi2): 2.941e-04, MSE(pi3): 5.666e-03\n",
      "Epoch 62100, Train loss: 1.722e+03, Test loss: 4.758e+04, MSE(e): 7.906e-05, MSE(pi1): 3.050e-02, MSE(pi2): 3.518e-05, MSE(pi3): 6.268e-03\n",
      "Epoch 62200, Train loss: 2.704e+03, Test loss: 4.995e+04, MSE(e): 1.310e-04, MSE(pi1): 8.176e-02, MSE(pi2): 7.380e-05, MSE(pi3): 5.771e-03\n",
      "Epoch 62300, Train loss: 1.433e+03, Test loss: 4.699e+04, MSE(e): 4.962e-05, MSE(pi1): 3.176e-02, MSE(pi2): 2.556e-05, MSE(pi3): 6.190e-03\n",
      "Epoch 62400, Train loss: 2.126e+03, Test loss: 4.891e+04, MSE(e): 1.140e-04, MSE(pi1): 3.555e-02, MSE(pi2): 4.592e-05, MSE(pi3): 6.306e-03\n",
      "Epoch 62500, Train loss: 2.692e+03, Test loss: 4.878e+04, MSE(e): 1.808e-04, MSE(pi1): 2.357e-02, MSE(pi2): 7.786e-05, MSE(pi3): 6.481e-03\n",
      "Epoch 62600, Train loss: 2.301e+03, Test loss: 4.624e+04, MSE(e): 1.383e-04, MSE(pi1): 2.117e-02, MSE(pi2): 7.062e-05, MSE(pi3): 7.064e-03\n",
      "Epoch 62700, Train loss: 1.575e+03, Test loss: 4.678e+04, MSE(e): 8.029e-05, MSE(pi1): 1.494e-02, MSE(pi2): 4.777e-05, MSE(pi3): 6.226e-03\n",
      "Epoch 62800, Train loss: 1.997e+03, Test loss: 5.207e+04, MSE(e): 9.083e-05, MSE(pi1): 4.800e-02, MSE(pi2): 4.154e-05, MSE(pi3): 6.091e-03\n",
      "Epoch 62900, Train loss: 2.001e+03, Test loss: 4.937e+04, MSE(e): 6.762e-05, MSE(pi1): 7.419e-02, MSE(pi2): 2.510e-05, MSE(pi3): 5.830e-03\n",
      "Epoch 63000, Train loss: 2.080e+03, Test loss: 4.931e+04, MSE(e): 1.157e-04, MSE(pi1): 3.680e-02, MSE(pi2): 8.180e-05, MSE(pi3): 5.552e-03\n",
      "Epoch 63100, Train loss: 9.979e+03, Test loss: 5.326e+04, MSE(e): 9.006e-04, MSE(pi1): 2.423e-02, MSE(pi2): 4.058e-04, MSE(pi3): 7.302e-03\n",
      "Epoch 63200, Train loss: 2.102e+03, Test loss: 5.136e+04, MSE(e): 6.621e-05, MSE(pi1): 8.509e-02, MSE(pi2): 2.799e-05, MSE(pi3): 5.891e-03\n",
      "Epoch 63300, Train loss: 1.823e+03, Test loss: 5.004e+04, MSE(e): 7.338e-05, MSE(pi1): 4.713e-02, MSE(pi2): 2.736e-05, MSE(pi3): 6.180e-03\n",
      "Epoch 63400, Train loss: 1.795e+04, Test loss: 5.243e+04, MSE(e): 1.695e-03, MSE(pi1): 3.607e-02, MSE(pi2): 7.397e-04, MSE(pi3): 6.461e-03\n",
      "Epoch 63500, Train loss: 3.638e+03, Test loss: 4.982e+04, MSE(e): 2.729e-04, MSE(pi1): 2.609e-02, MSE(pi2): 1.270e-04, MSE(pi3): 6.476e-03\n",
      "Epoch 63600, Train loss: 6.330e+03, Test loss: 4.950e+04, MSE(e): 5.283e-04, MSE(pi1): 4.023e-02, MSE(pi2): 2.177e-04, MSE(pi3): 6.447e-03\n",
      "Epoch 63700, Train loss: 2.976e+03, Test loss: 5.528e+04, MSE(e): 1.838e-04, MSE(pi1): 3.422e-02, MSE(pi2): 1.015e-04, MSE(pi3): 7.950e-03\n",
      "Epoch 63800, Train loss: 1.060e+04, Test loss: 5.965e+04, MSE(e): 9.540e-04, MSE(pi1): 3.160e-02, MSE(pi2): 4.029e-04, MSE(pi3): 7.389e-03\n",
      "Epoch 63900, Train loss: 1.270e+03, Test loss: 4.698e+04, MSE(e): 3.970e-05, MSE(pi1): 2.445e-02, MSE(pi2): 1.795e-05, MSE(pi3): 6.286e-03\n",
      "Epoch 64000, Train loss: 2.536e+03, Test loss: 4.924e+04, MSE(e): 1.542e-04, MSE(pi1): 3.539e-02, MSE(pi2): 7.800e-05, MSE(pi3): 6.402e-03\n",
      "Epoch 64100, Train loss: 3.592e+03, Test loss: 4.812e+04, MSE(e): 2.578e-04, MSE(pi1): 3.510e-02, MSE(pi2): 1.108e-04, MSE(pi3): 6.632e-03\n",
      "Epoch 64200, Train loss: 2.126e+04, Test loss: 4.886e+04, MSE(e): 2.004e-03, MSE(pi1): 7.255e-02, MSE(pi2): 9.791e-04, MSE(pi3): 4.945e-03\n",
      "Epoch 64300, Train loss: 1.257e+04, Test loss: 5.497e+04, MSE(e): 1.115e-03, MSE(pi1): 5.286e-02, MSE(pi2): 4.990e-04, MSE(pi3): 8.853e-03\n",
      "Epoch 64400, Train loss: 1.732e+03, Test loss: 4.569e+04, MSE(e): 7.446e-05, MSE(pi1): 3.432e-02, MSE(pi2): 3.276e-05, MSE(pi3): 6.441e-03\n",
      "Epoch 64500, Train loss: 4.727e+03, Test loss: 4.805e+04, MSE(e): 3.794e-04, MSE(pi1): 3.247e-02, MSE(pi2): 1.788e-04, MSE(pi3): 6.079e-03\n",
      "Epoch 64600, Train loss: 1.354e+03, Test loss: 4.623e+04, MSE(e): 3.859e-05, MSE(pi1): 3.767e-02, MSE(pi2): 1.786e-05, MSE(pi3): 5.909e-03\n",
      "Epoch 64700, Train loss: 1.450e+03, Test loss: 4.473e+04, MSE(e): 6.934e-05, MSE(pi1): 1.674e-02, MSE(pi2): 4.174e-05, MSE(pi3): 5.888e-03\n",
      "Epoch 64800, Train loss: 1.338e+03, Test loss: 4.493e+04, MSE(e): 3.699e-05, MSE(pi1): 3.111e-02, MSE(pi2): 1.837e-05, MSE(pi3): 6.571e-03\n",
      "Epoch 64900, Train loss: 3.062e+03, Test loss: 4.619e+04, MSE(e): 2.174e-04, MSE(pi1): 2.434e-02, MSE(pi2): 1.217e-04, MSE(pi3): 6.443e-03\n",
      "Epoch 65000, Train loss: 2.564e+03, Test loss: 4.327e+04, MSE(e): 1.624e-04, MSE(pi1): 3.227e-02, MSE(pi2): 8.713e-05, MSE(pi3): 6.170e-03\n",
      "Epoch 65100, Train loss: 1.848e+03, Test loss: 4.345e+04, MSE(e): 1.041e-04, MSE(pi1): 1.397e-02, MSE(pi2): 5.625e-05, MSE(pi3): 6.668e-03\n",
      "Epoch 65200, Train loss: 1.177e+04, Test loss: 6.677e+04, MSE(e): 1.062e-03, MSE(pi1): 3.257e-02, MSE(pi2): 4.761e-04, MSE(pi3): 8.264e-03\n",
      "Epoch 65300, Train loss: 5.817e+03, Test loss: 5.143e+04, MSE(e): 4.552e-04, MSE(pi1): 6.039e-02, MSE(pi2): 2.656e-04, MSE(pi3): 6.606e-03\n",
      "Epoch 65400, Train loss: 1.359e+03, Test loss: 4.206e+04, MSE(e): 5.462e-05, MSE(pi1): 1.867e-02, MSE(pi2): 2.823e-05, MSE(pi3): 6.257e-03\n",
      "Epoch 65500, Train loss: 1.181e+04, Test loss: 6.005e+04, MSE(e): 1.085e-03, MSE(pi1): 3.723e-02, MSE(pi2): 5.108e-04, MSE(pi3): 5.836e-03\n",
      "Epoch 65600, Train loss: 2.038e+03, Test loss: 4.190e+04, MSE(e): 9.609e-05, MSE(pi1): 5.239e-02, MSE(pi2): 5.754e-05, MSE(pi3): 5.530e-03\n",
      "Epoch 65700, Train loss: 2.904e+03, Test loss: 4.424e+04, MSE(e): 1.931e-04, MSE(pi1): 3.243e-02, MSE(pi2): 9.395e-05, MSE(pi3): 6.489e-03\n",
      "Epoch 65800, Train loss: 2.645e+03, Test loss: 4.506e+04, MSE(e): 1.852e-04, MSE(pi1): 1.851e-02, MSE(pi2): 9.017e-05, MSE(pi3): 6.076e-03\n",
      "Epoch 65900, Train loss: 1.535e+03, Test loss: 4.237e+04, MSE(e): 6.508e-05, MSE(pi1): 2.937e-02, MSE(pi2): 3.748e-05, MSE(pi3): 5.903e-03\n",
      "Epoch 66000, Train loss: 1.858e+03, Test loss: 4.527e+04, MSE(e): 9.482e-05, MSE(pi1): 2.552e-02, MSE(pi2): 5.139e-05, MSE(pi3): 6.541e-03\n",
      "Epoch 66100, Train loss: 4.935e+03, Test loss: 4.860e+04, MSE(e): 3.456e-04, MSE(pi1): 9.542e-02, MSE(pi2): 1.863e-04, MSE(pi3): 5.241e-03\n",
      "Epoch 66200, Train loss: 2.152e+03, Test loss: 4.522e+04, MSE(e): 9.479e-05, MSE(pi1): 6.183e-02, MSE(pi2): 3.272e-05, MSE(pi3): 5.854e-03\n",
      "Epoch 66300, Train loss: 1.702e+03, Test loss: 4.290e+04, MSE(e): 7.437e-05, MSE(pi1): 2.868e-02, MSE(pi2): 3.445e-05, MSE(pi3): 6.713e-03\n",
      "Epoch 66400, Train loss: 1.661e+03, Test loss: 4.488e+04, MSE(e): 5.536e-05, MSE(pi1): 4.709e-02, MSE(pi2): 3.093e-05, MSE(pi3): 6.367e-03\n",
      "Epoch 66500, Train loss: 1.379e+03, Test loss: 4.191e+04, MSE(e): 5.218e-05, MSE(pi1): 1.828e-02, MSE(pi2): 2.679e-05, MSE(pi3): 6.747e-03\n",
      "Epoch 66600, Train loss: 2.600e+04, Test loss: 4.377e+04, MSE(e): 2.500e-03, MSE(pi1): 4.836e-02, MSE(pi2): 1.135e-03, MSE(pi3): 5.116e-03\n",
      "Epoch 66700, Train loss: 1.369e+03, Test loss: 4.179e+04, MSE(e): 5.415e-05, MSE(pi1): 2.326e-02, MSE(pi2): 2.798e-05, MSE(pi3): 5.953e-03\n",
      "Epoch 66800, Train loss: 4.262e+03, Test loss: 4.396e+04, MSE(e): 3.378e-04, MSE(pi1): 1.789e-02, MSE(pi2): 1.503e-04, MSE(pi3): 7.047e-03\n",
      "Epoch 66900, Train loss: 2.258e+03, Test loss: 4.270e+04, MSE(e): 1.216e-04, MSE(pi1): 4.123e-02, MSE(pi2): 6.728e-05, MSE(pi3): 6.298e-03\n",
      "Epoch 67000, Train loss: 4.763e+03, Test loss: 3.926e+04, MSE(e): 3.975e-04, MSE(pi1): 2.305e-02, MSE(pi2): 1.971e-04, MSE(pi3): 5.569e-03\n",
      "Epoch 67100, Train loss: 8.540e+03, Test loss: 4.871e+04, MSE(e): 7.310e-04, MSE(pi1): 4.475e-02, MSE(pi2): 3.295e-04, MSE(pi3): 7.819e-03\n",
      "Epoch 67200, Train loss: 2.032e+03, Test loss: 4.401e+04, MSE(e): 8.386e-05, MSE(pi1): 5.696e-02, MSE(pi2): 3.530e-05, MSE(pi3): 6.233e-03\n",
      "Epoch 67300, Train loss: 1.891e+03, Test loss: 4.131e+04, MSE(e): 8.224e-05, MSE(pi1): 3.770e-02, MSE(pi2): 3.888e-05, MSE(pi3): 6.915e-03\n",
      "Epoch 67400, Train loss: 1.758e+03, Test loss: 4.236e+04, MSE(e): 8.003e-05, MSE(pi1): 2.750e-02, MSE(pi2): 3.786e-05, MSE(pi3): 6.822e-03\n",
      "Epoch 67500, Train loss: 2.816e+03, Test loss: 4.614e+04, MSE(e): 1.937e-04, MSE(pi1): 2.147e-02, MSE(pi2): 9.085e-05, MSE(pi3): 6.642e-03\n",
      "Epoch 67600, Train loss: 1.526e+03, Test loss: 3.918e+04, MSE(e): 7.843e-05, MSE(pi1): 1.499e-02, MSE(pi2): 3.638e-05, MSE(pi3): 5.915e-03\n",
      "Epoch 67700, Train loss: 1.504e+03, Test loss: 4.087e+04, MSE(e): 4.382e-05, MSE(pi1): 4.231e-02, MSE(pi2): 1.812e-05, MSE(pi3): 6.428e-03\n",
      "Epoch 67800, Train loss: 1.492e+03, Test loss: 4.446e+04, MSE(e): 4.985e-05, MSE(pi1): 2.841e-02, MSE(pi2): 2.513e-05, MSE(pi3): 7.092e-03\n",
      "Epoch 67900, Train loss: 1.943e+03, Test loss: 4.174e+04, MSE(e): 8.436e-05, MSE(pi1): 4.837e-02, MSE(pi2): 4.546e-05, MSE(pi3): 6.160e-03\n",
      "Epoch 68000, Train loss: 1.603e+03, Test loss: 4.121e+04, MSE(e): 5.778e-05, MSE(pi1): 3.638e-02, MSE(pi2): 2.769e-05, MSE(pi3): 6.617e-03\n",
      "Epoch 68100, Train loss: 2.664e+03, Test loss: 4.761e+04, MSE(e): 1.549e-04, MSE(pi1): 5.228e-02, MSE(pi2): 8.465e-05, MSE(pi3): 5.920e-03\n",
      "Epoch 68200, Train loss: 1.803e+03, Test loss: 4.148e+04, MSE(e): 5.537e-05, MSE(pi1): 5.488e-02, MSE(pi2): 2.468e-05, MSE(pi3): 7.001e-03\n",
      "Epoch 68300, Train loss: 5.120e+03, Test loss: 4.413e+04, MSE(e): 4.272e-04, MSE(pi1): 2.651e-02, MSE(pi2): 2.195e-04, MSE(pi3): 5.826e-03\n",
      "Epoch 68400, Train loss: 2.748e+03, Test loss: 3.821e+04, MSE(e): 1.529e-04, MSE(pi1): 6.991e-02, MSE(pi2): 1.015e-04, MSE(pi3): 5.201e-03\n",
      "Epoch 68500, Train loss: 3.482e+03, Test loss: 5.345e+04, MSE(e): 2.586e-04, MSE(pi1): 2.748e-02, MSE(pi2): 1.474e-04, MSE(pi3): 6.204e-03\n",
      "Epoch 68600, Train loss: 3.874e+03, Test loss: 4.046e+04, MSE(e): 2.749e-04, MSE(pi1): 5.920e-02, MSE(pi2): 1.771e-04, MSE(pi3): 5.325e-03\n",
      "Epoch 68700, Train loss: 2.967e+03, Test loss: 4.060e+04, MSE(e): 1.935e-04, MSE(pi1): 3.575e-02, MSE(pi2): 8.883e-05, MSE(pi3): 6.744e-03\n",
      "Epoch 68800, Train loss: 1.463e+03, Test loss: 3.810e+04, MSE(e): 5.747e-05, MSE(pi1): 2.764e-02, MSE(pi2): 3.036e-05, MSE(pi3): 6.119e-03\n",
      "Epoch 68900, Train loss: 2.676e+03, Test loss: 4.060e+04, MSE(e): 1.779e-04, MSE(pi1): 2.991e-02, MSE(pi2): 6.923e-05, MSE(pi3): 5.979e-03\n",
      "Epoch 69000, Train loss: 8.005e+03, Test loss: 5.074e+04, MSE(e): 6.941e-04, MSE(pi1): 2.837e-02, MSE(pi2): 2.944e-04, MSE(pi3): 7.800e-03\n",
      "Epoch 69100, Train loss: 3.244e+03, Test loss: 3.977e+04, MSE(e): 2.139e-04, MSE(pi1): 3.483e-02, MSE(pi2): 1.153e-04, MSE(pi3): 7.567e-03\n",
      "Epoch 69200, Train loss: 1.363e+03, Test loss: 3.819e+04, MSE(e): 5.113e-05, MSE(pi1): 1.887e-02, MSE(pi2): 2.955e-05, MSE(pi3): 6.631e-03\n",
      "Epoch 69300, Train loss: 2.558e+03, Test loss: 4.334e+04, MSE(e): 1.361e-04, MSE(pi1): 5.301e-02, MSE(pi2): 6.030e-05, MSE(pi3): 6.670e-03\n",
      "Epoch 69400, Train loss: 1.300e+03, Test loss: 3.804e+04, MSE(e): 4.492e-05, MSE(pi1): 2.102e-02, MSE(pi2): 2.046e-05, MSE(pi3): 6.401e-03\n",
      "Epoch 69500, Train loss: 1.254e+03, Test loss: 3.891e+04, MSE(e): 3.306e-05, MSE(pi1): 2.877e-02, MSE(pi2): 1.407e-05, MSE(pi3): 6.359e-03\n",
      "Epoch 69600, Train loss: 1.649e+03, Test loss: 4.107e+04, MSE(e): 4.161e-05, MSE(pi1): 5.161e-02, MSE(pi2): 1.911e-05, MSE(pi3): 7.171e-03\n",
      "Epoch 69700, Train loss: 2.137e+03, Test loss: 3.909e+04, MSE(e): 1.175e-04, MSE(pi1): 3.361e-02, MSE(pi2): 5.619e-05, MSE(pi3): 6.257e-03\n",
      "Epoch 69800, Train loss: 3.047e+03, Test loss: 3.652e+04, MSE(e): 2.019e-04, MSE(pi1): 4.053e-02, MSE(pi2): 9.580e-05, MSE(pi3): 6.228e-03\n",
      "Epoch 69900, Train loss: 1.706e+03, Test loss: 3.799e+04, MSE(e): 8.460e-05, MSE(pi1): 2.416e-02, MSE(pi2): 3.408e-05, MSE(pi3): 6.184e-03\n",
      "Epoch 70000, Train loss: 1.449e+03, Test loss: 3.785e+04, MSE(e): 3.571e-05, MSE(pi1): 4.867e-02, MSE(pi2): 1.673e-05, MSE(pi3): 6.056e-03\n",
      "Epoch 70100, Train loss: 1.599e+03, Test loss: 3.702e+04, MSE(e): 6.868e-05, MSE(pi1): 2.277e-02, MSE(pi2): 3.277e-05, MSE(pi3): 6.848e-03\n",
      "Epoch 70200, Train loss: 1.478e+03, Test loss: 3.664e+04, MSE(e): 4.746e-05, MSE(pi1): 3.902e-02, MSE(pi2): 2.443e-05, MSE(pi3): 6.133e-03\n",
      "Epoch 70300, Train loss: 1.468e+03, Test loss: 3.521e+04, MSE(e): 6.679e-05, MSE(pi1): 2.253e-02, MSE(pi2): 3.749e-05, MSE(pi3): 5.748e-03\n",
      "Epoch 70400, Train loss: 1.135e+03, Test loss: 3.770e+04, MSE(e): 3.532e-05, MSE(pi1): 1.992e-02, MSE(pi2): 2.015e-05, MSE(pi3): 5.829e-03\n",
      "Epoch 70500, Train loss: 4.602e+03, Test loss: 3.894e+04, MSE(e): 3.513e-04, MSE(pi1): 3.547e-02, MSE(pi2): 1.504e-04, MSE(pi3): 7.347e-03\n",
      "Epoch 70600, Train loss: 1.735e+03, Test loss: 3.863e+04, MSE(e): 6.407e-05, MSE(pi1): 5.230e-02, MSE(pi2): 3.726e-05, MSE(pi3): 5.717e-03\n",
      "Epoch 70700, Train loss: 1.418e+03, Test loss: 3.699e+04, MSE(e): 4.436e-05, MSE(pi1): 3.654e-02, MSE(pi2): 2.540e-05, MSE(pi3): 6.090e-03\n",
      "Epoch 70800, Train loss: 2.283e+03, Test loss: 3.656e+04, MSE(e): 1.268e-04, MSE(pi1): 3.908e-02, MSE(pi2): 5.959e-05, MSE(pi3): 6.236e-03\n",
      "Epoch 70900, Train loss: 2.035e+03, Test loss: 3.640e+04, MSE(e): 1.123e-04, MSE(pi1): 2.896e-02, MSE(pi2): 6.849e-05, MSE(pi3): 6.232e-03\n",
      "Epoch 71000, Train loss: 1.598e+03, Test loss: 3.492e+04, MSE(e): 6.198e-05, MSE(pi1): 3.562e-02, MSE(pi2): 3.294e-05, MSE(pi3): 6.217e-03\n",
      "Epoch 71100, Train loss: 1.973e+03, Test loss: 3.698e+04, MSE(e): 1.112e-04, MSE(pi1): 2.176e-02, MSE(pi2): 6.580e-05, MSE(pi3): 6.434e-03\n",
      "Epoch 71200, Train loss: 4.227e+03, Test loss: 4.263e+04, MSE(e): 3.149e-04, MSE(pi1): 4.400e-02, MSE(pi2): 1.487e-04, MSE(pi3): 6.371e-03\n",
      "Epoch 71300, Train loss: 1.221e+03, Test loss: 3.611e+04, MSE(e): 4.373e-05, MSE(pi1): 1.617e-02, MSE(pi2): 2.189e-05, MSE(pi3): 6.224e-03\n",
      "Epoch 71400, Train loss: 1.857e+03, Test loss: 3.668e+04, MSE(e): 9.659e-05, MSE(pi1): 2.744e-02, MSE(pi2): 5.325e-05, MSE(pi3): 6.168e-03\n",
      "Epoch 71500, Train loss: 1.452e+03, Test loss: 3.553e+04, MSE(e): 3.231e-05, MSE(pi1): 4.720e-02, MSE(pi2): 1.688e-05, MSE(pi3): 6.566e-03\n",
      "Epoch 71600, Train loss: 1.830e+03, Test loss: 3.426e+04, MSE(e): 1.042e-04, MSE(pi1): 2.142e-02, MSE(pi2): 5.678e-05, MSE(pi3): 5.737e-03\n",
      "Epoch 71700, Train loss: 1.782e+03, Test loss: 3.516e+04, MSE(e): 6.997e-05, MSE(pi1): 4.623e-02, MSE(pi2): 3.698e-05, MSE(pi3): 6.200e-03\n",
      "Epoch 71800, Train loss: 1.323e+03, Test loss: 3.592e+04, MSE(e): 4.975e-05, MSE(pi1): 1.986e-02, MSE(pi2): 2.322e-05, MSE(pi3): 6.267e-03\n",
      "Epoch 71900, Train loss: 1.621e+03, Test loss: 3.704e+04, MSE(e): 6.386e-05, MSE(pi1): 3.043e-02, MSE(pi2): 2.957e-05, MSE(pi3): 6.783e-03\n",
      "Epoch 72000, Train loss: 1.157e+04, Test loss: 3.713e+04, MSE(e): 1.065e-03, MSE(pi1): 2.885e-02, MSE(pi2): 4.985e-04, MSE(pi3): 6.275e-03\n",
      "Epoch 72100, Train loss: 1.807e+03, Test loss: 3.340e+04, MSE(e): 1.006e-04, MSE(pi1): 2.423e-02, MSE(pi2): 5.552e-05, MSE(pi3): 5.588e-03\n",
      "Epoch 72200, Train loss: 1.375e+03, Test loss: 3.595e+04, MSE(e): 4.458e-05, MSE(pi1): 3.258e-02, MSE(pi2): 2.044e-05, MSE(pi3): 6.030e-03\n",
      "Epoch 72300, Train loss: 3.106e+03, Test loss: 4.268e+04, MSE(e): 2.072e-04, MSE(pi1): 4.708e-02, MSE(pi2): 1.167e-04, MSE(pi3): 5.634e-03\n",
      "Epoch 72400, Train loss: 4.039e+03, Test loss: 4.580e+04, MSE(e): 3.083e-04, MSE(pi1): 2.542e-02, MSE(pi2): 2.003e-04, MSE(pi3): 7.022e-03\n",
      "Epoch 72500, Train loss: 2.007e+03, Test loss: 3.762e+04, MSE(e): 9.040e-05, MSE(pi1): 4.774e-02, MSE(pi2): 3.567e-05, MSE(pi3): 6.254e-03\n",
      "Epoch 72600, Train loss: 1.676e+03, Test loss: 3.512e+04, MSE(e): 6.792e-05, MSE(pi1): 3.745e-02, MSE(pi2): 2.655e-05, MSE(pi3): 6.225e-03\n",
      "Epoch 72700, Train loss: 2.910e+03, Test loss: 3.772e+04, MSE(e): 1.692e-04, MSE(pi1): 6.469e-02, MSE(pi2): 9.311e-05, MSE(pi3): 5.701e-03\n",
      "Epoch 72800, Train loss: 1.349e+03, Test loss: 3.623e+04, MSE(e): 4.252e-05, MSE(pi1): 3.358e-02, MSE(pi2): 1.539e-05, MSE(pi3): 5.878e-03\n",
      "Epoch 72900, Train loss: 1.609e+03, Test loss: 3.503e+04, MSE(e): 9.081e-05, MSE(pi1): 1.165e-02, MSE(pi2): 5.172e-05, MSE(pi3): 5.844e-03\n",
      "Epoch 73000, Train loss: 1.254e+03, Test loss: 3.806e+04, MSE(e): 4.509e-05, MSE(pi1): 1.818e-02, MSE(pi2): 2.235e-05, MSE(pi3): 6.212e-03\n",
      "Epoch 73100, Train loss: 1.832e+03, Test loss: 4.164e+04, MSE(e): 9.230e-05, MSE(pi1): 2.281e-02, MSE(pi2): 4.879e-05, MSE(pi3): 6.810e-03\n",
      "Epoch 73200, Train loss: 1.705e+03, Test loss: 3.777e+04, MSE(e): 6.559e-05, MSE(pi1): 3.705e-02, MSE(pi2): 3.673e-05, MSE(pi3): 6.784e-03\n",
      "Epoch 73300, Train loss: 1.792e+03, Test loss: 3.371e+04, MSE(e): 9.605e-05, MSE(pi1): 2.431e-02, MSE(pi2): 4.478e-05, MSE(pi3): 5.880e-03\n",
      "Epoch 73400, Train loss: 1.221e+03, Test loss: 3.280e+04, MSE(e): 3.078e-05, MSE(pi1): 2.707e-02, MSE(pi2): 1.630e-05, MSE(pi3): 6.427e-03\n",
      "Epoch 73500, Train loss: 3.696e+03, Test loss: 5.907e+04, MSE(e): 2.856e-04, MSE(pi1): 2.706e-02, MSE(pi2): 1.559e-04, MSE(pi3): 5.691e-03\n",
      "Epoch 73600, Train loss: 6.087e+03, Test loss: 3.381e+04, MSE(e): 5.197e-04, MSE(pi1): 3.364e-02, MSE(pi2): 2.605e-04, MSE(pi3): 5.532e-03\n",
      "Epoch 73700, Train loss: 4.040e+03, Test loss: 3.806e+04, MSE(e): 2.901e-04, MSE(pi1): 4.163e-02, MSE(pi2): 1.889e-04, MSE(pi3): 7.229e-03\n",
      "Epoch 73800, Train loss: 1.384e+03, Test loss: 3.542e+04, MSE(e): 4.353e-05, MSE(pi1): 3.641e-02, MSE(pi2): 2.306e-05, MSE(pi3): 5.844e-03\n",
      "Epoch 73900, Train loss: 5.142e+03, Test loss: 4.321e+04, MSE(e): 3.960e-04, MSE(pi1): 6.918e-02, MSE(pi2): 2.496e-04, MSE(pi3): 4.903e-03\n",
      "Epoch 74000, Train loss: 3.149e+03, Test loss: 3.641e+04, MSE(e): 2.228e-04, MSE(pi1): 2.628e-02, MSE(pi2): 1.437e-04, MSE(pi3): 6.579e-03\n",
      "Epoch 74100, Train loss: 4.117e+03, Test loss: 4.180e+04, MSE(e): 3.284e-04, MSE(pi1): 1.456e-02, MSE(pi2): 1.395e-04, MSE(pi3): 6.869e-03\n",
      "Epoch 74200, Train loss: 1.319e+03, Test loss: 3.345e+04, MSE(e): 3.644e-05, MSE(pi1): 3.386e-02, MSE(pi2): 1.817e-05, MSE(pi3): 6.162e-03\n",
      "Epoch 74300, Train loss: 5.290e+03, Test loss: 3.947e+04, MSE(e): 4.250e-04, MSE(pi1): 3.224e-02, MSE(pi2): 2.307e-04, MSE(pi3): 7.181e-03\n",
      "Epoch 74400, Train loss: 2.158e+03, Test loss: 3.421e+04, MSE(e): 1.211e-04, MSE(pi1): 3.003e-02, MSE(pi2): 6.279e-05, MSE(pi3): 6.465e-03\n",
      "Epoch 74500, Train loss: 1.618e+03, Test loss: 3.372e+04, MSE(e): 6.664e-05, MSE(pi1): 2.572e-02, MSE(pi2): 3.085e-05, MSE(pi3): 6.941e-03\n",
      "Epoch 74600, Train loss: 1.859e+03, Test loss: 3.561e+04, MSE(e): 8.037e-05, MSE(pi1): 3.518e-02, MSE(pi2): 4.629e-05, MSE(pi3): 7.039e-03\n",
      "Epoch 74700, Train loss: 1.499e+03, Test loss: 3.408e+04, MSE(e): 3.955e-05, MSE(pi1): 5.003e-02, MSE(pi2): 1.436e-05, MSE(pi3): 6.035e-03\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 3\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from a checkpoint. Epoch 80.\n",
      "Epoch 80, Train loss: 1.255e+07, Test loss: 1.404e+07, MSE(e): 1.229e+00, MSE(pi1): 1.474e+01, MSE(pi2): 8.448e-01, MSE(pi3): 1.110e+00\n",
      "Epoch 90, Train loss: 1.254e+07, Test loss: 1.402e+07, MSE(e): 1.229e+00, MSE(pi1): 1.467e+01, MSE(pi2): 8.449e-01, MSE(pi3): 1.110e+00\n",
      "\n",
      "Training process finished after 100 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametros de entrenamiento\n",
    "start_epoch = n_epochs-1\n",
    "n_epochs = 150000\n",
    "\n",
    "batch_size = 64 \n",
    "n_checkpoints = 3\n",
    "\n",
    "second_lr = 3e-4\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE, new_lr=second_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
