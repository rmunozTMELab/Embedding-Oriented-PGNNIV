{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Own library imports\n",
    "from vecopsciml.utils import TensOps\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "\n",
    "# Function from this project\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop\n",
    "\n",
    "# Import model\n",
    "from architectures.pgnniv_baseline import PGNNIVBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_1000\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/transfer_learning_1000/baseline\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/sigmoid_nonlinear_1000/sigmoid_nonlinear_1000.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_1000')\n",
    "\n",
    "MODEL_RESULTS_TRANSFERLEARNING_PATH = os.path.join(ROOT_PATH, r'results/transfer_learning_1000/baseline')\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_TRANSFERLEARNING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/sigmoid_nonlinear_1000/sigmoid_nonlinear_1000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 800\n",
      "Validation dataset length: 200\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1)\n",
    "y_train = torch.Tensor(dataset['y_train']).unsqueeze(1)\n",
    "K_train = torch.tensor(dataset['k_train']).unsqueeze(1)\n",
    "f_train = torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, K_train, K_test, f_train, f_test = train_test_split(X_train, y_train, K_train, f_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to(DEVICE)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "y_train = TensOps(y_train.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "y_test = TensOps(y_test.requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "K_train = TensOps(K_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_test = TensOps(K_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "f_train = TensOps(f_train.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_test = TensOps(f_test.to(DEVICE), space_dimension=2, contravariance=0, covariance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = 10\n",
    "\n",
    "# Predictive network architecture\n",
    "input_shape = X_train[0].shape\n",
    "predictive_layers = [20, 10, n_modes, 10, 20]\n",
    "predictive_output = y_train.values[0].shape\n",
    "\n",
    "# Explanatory network architecture\n",
    "explanatory_input = Mx(My(y_train)).values[0].shape\n",
    "explanatory_layers = [10, 10]\n",
    "explanatory_output = Mx(My(f_train)).values[0].shape\n",
    "\n",
    "# Other parameters\n",
    "n_filters_explanatory = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 0, Train loss: 1.813e+09, Test loss: 1.734e+09, MSE(e): 1.269e+02, MSE(pi1): 5.348e+04, MSE(pi2): 5.575e+01, MSE(pi3): 8.897e+01\n",
      "Epoch 100, Train loss: 1.303e+08, Test loss: 1.481e+08, MSE(e): 1.295e+01, MSE(pi1): 3.229e+01, MSE(pi2): 5.663e+00, MSE(pi3): 4.971e+00\n",
      "Epoch 200, Train loss: 3.919e+07, Test loss: 4.608e+07, MSE(e): 3.755e+00, MSE(pi1): 1.167e+02, MSE(pi2): 1.921e+00, MSE(pi3): 4.660e+00\n",
      "Epoch 300, Train loss: 2.369e+07, Test loss: 2.687e+07, MSE(e): 2.281e+00, MSE(pi1): 4.940e+01, MSE(pi2): 1.326e+00, MSE(pi3): 3.919e+00\n",
      "Epoch 400, Train loss: 1.862e+07, Test loss: 1.981e+07, MSE(e): 1.799e+00, MSE(pi1): 2.926e+01, MSE(pi2): 1.130e+00, MSE(pi3): 3.355e+00\n",
      "Epoch 500, Train loss: 1.656e+07, Test loss: 1.681e+07, MSE(e): 1.603e+00, MSE(pi1): 2.328e+01, MSE(pi2): 1.050e+00, MSE(pi3): 2.916e+00\n",
      "Epoch 600, Train loss: 1.560e+07, Test loss: 1.542e+07, MSE(e): 1.512e+00, MSE(pi1): 2.205e+01, MSE(pi2): 1.013e+00, MSE(pi3): 2.521e+00\n",
      "Epoch 700, Train loss: 1.507e+07, Test loss: 1.469e+07, MSE(e): 1.466e+00, MSE(pi1): 2.130e+01, MSE(pi2): 9.947e-01, MSE(pi3): 2.036e+00\n",
      "Epoch 800, Train loss: 1.478e+07, Test loss: 1.426e+07, MSE(e): 1.443e+00, MSE(pi1): 1.946e+01, MSE(pi2): 9.863e-01, MSE(pi3): 1.522e+00\n",
      "Epoch 900, Train loss: 1.463e+07, Test loss: 1.401e+07, MSE(e): 1.433e+00, MSE(pi1): 1.786e+01, MSE(pi2): 9.823e-01, MSE(pi3): 1.246e+00\n",
      "Epoch 1000, Train loss: 1.456e+07, Test loss: 1.388e+07, MSE(e): 1.428e+00, MSE(pi1): 1.680e+01, MSE(pi2): 9.803e-01, MSE(pi3): 1.174e+00\n",
      "Epoch 1100, Train loss: 1.452e+07, Test loss: 1.380e+07, MSE(e): 1.425e+00, MSE(pi1): 1.589e+01, MSE(pi2): 9.791e-01, MSE(pi3): 1.128e+00\n",
      "Epoch 1200, Train loss: 1.448e+07, Test loss: 1.373e+07, MSE(e): 1.423e+00, MSE(pi1): 1.430e+01, MSE(pi2): 9.783e-01, MSE(pi3): 1.016e+00\n",
      "Epoch 1300, Train loss: 1.436e+07, Test loss: 1.360e+07, MSE(e): 1.421e+00, MSE(pi1): 8.679e+00, MSE(pi2): 9.771e-01, MSE(pi3): 6.310e-01\n",
      "Epoch 1400, Train loss: 1.429e+07, Test loss: 1.352e+07, MSE(e): 1.419e+00, MSE(pi1): 4.770e+00, MSE(pi2): 9.762e-01, MSE(pi3): 4.973e-01\n",
      "Epoch 1500, Train loss: 1.428e+07, Test loss: 1.350e+07, MSE(e): 1.419e+00, MSE(pi1): 4.175e+00, MSE(pi2): 9.758e-01, MSE(pi3): 4.896e-01\n",
      "Epoch 1600, Train loss: 1.427e+07, Test loss: 1.349e+07, MSE(e): 1.418e+00, MSE(pi1): 4.029e+00, MSE(pi2): 9.756e-01, MSE(pi3): 4.878e-01\n",
      "Epoch 1700, Train loss: 1.427e+07, Test loss: 1.348e+07, MSE(e): 1.418e+00, MSE(pi1): 3.971e+00, MSE(pi2): 9.754e-01, MSE(pi3): 4.868e-01\n",
      "Epoch 1800, Train loss: 1.426e+07, Test loss: 1.348e+07, MSE(e): 1.417e+00, MSE(pi1): 3.944e+00, MSE(pi2): 9.752e-01, MSE(pi3): 4.863e-01\n",
      "Epoch 1900, Train loss: 1.426e+07, Test loss: 1.347e+07, MSE(e): 1.417e+00, MSE(pi1): 3.924e+00, MSE(pi2): 9.749e-01, MSE(pi3): 4.860e-01\n",
      "Epoch 2000, Train loss: 1.425e+07, Test loss: 1.346e+07, MSE(e): 1.417e+00, MSE(pi1): 3.905e+00, MSE(pi2): 9.748e-01, MSE(pi3): 4.859e-01\n",
      "Epoch 2100, Train loss: 1.425e+07, Test loss: 1.346e+07, MSE(e): 1.416e+00, MSE(pi1): 3.895e+00, MSE(pi2): 9.746e-01, MSE(pi3): 4.859e-01\n",
      "Epoch 2200, Train loss: 1.425e+07, Test loss: 1.345e+07, MSE(e): 1.416e+00, MSE(pi1): 3.887e+00, MSE(pi2): 9.744e-01, MSE(pi3): 4.859e-01\n",
      "Epoch 2300, Train loss: 1.424e+07, Test loss: 1.344e+07, MSE(e): 1.416e+00, MSE(pi1): 3.879e+00, MSE(pi2): 9.742e-01, MSE(pi3): 4.860e-01\n",
      "Epoch 2400, Train loss: 1.424e+07, Test loss: 1.344e+07, MSE(e): 1.415e+00, MSE(pi1): 3.871e+00, MSE(pi2): 9.740e-01, MSE(pi3): 4.860e-01\n",
      "Epoch 2500, Train loss: 1.424e+07, Test loss: 1.343e+07, MSE(e): 1.415e+00, MSE(pi1): 3.861e+00, MSE(pi2): 9.737e-01, MSE(pi3): 4.861e-01\n",
      "Epoch 2600, Train loss: 1.423e+07, Test loss: 1.343e+07, MSE(e): 1.414e+00, MSE(pi1): 3.850e+00, MSE(pi2): 9.735e-01, MSE(pi3): 4.862e-01\n",
      "Epoch 2700, Train loss: 1.423e+07, Test loss: 1.342e+07, MSE(e): 1.414e+00, MSE(pi1): 3.838e+00, MSE(pi2): 9.732e-01, MSE(pi3): 4.863e-01\n",
      "Epoch 2800, Train loss: 1.422e+07, Test loss: 1.341e+07, MSE(e): 1.413e+00, MSE(pi1): 3.825e+00, MSE(pi2): 9.728e-01, MSE(pi3): 4.863e-01\n",
      "Epoch 2900, Train loss: 1.421e+07, Test loss: 1.340e+07, MSE(e): 1.412e+00, MSE(pi1): 3.812e+00, MSE(pi2): 9.721e-01, MSE(pi3): 4.863e-01\n",
      "Epoch 3000, Train loss: 1.418e+07, Test loss: 1.338e+07, MSE(e): 1.410e+00, MSE(pi1): 3.787e+00, MSE(pi2): 9.705e-01, MSE(pi3): 4.860e-01\n",
      "Epoch 3100, Train loss: 1.403e+07, Test loss: 1.323e+07, MSE(e): 1.394e+00, MSE(pi1): 3.793e+00, MSE(pi2): 9.613e-01, MSE(pi3): 4.839e-01\n",
      "Epoch 3200, Train loss: 9.587e+06, Test loss: 9.032e+06, MSE(e): 9.506e-01, MSE(pi1): 4.044e+00, MSE(pi2): 6.653e-01, MSE(pi3): 4.008e-01\n",
      "Epoch 3300, Train loss: 8.077e+06, Test loss: 7.740e+06, MSE(e): 8.028e-01, MSE(pi1): 2.016e+00, MSE(pi2): 5.536e-01, MSE(pi3): 2.773e-01\n",
      "Epoch 3400, Train loss: 7.151e+06, Test loss: 7.040e+06, MSE(e): 7.099e-01, MSE(pi1): 2.677e+00, MSE(pi2): 4.875e-01, MSE(pi3): 2.409e-01\n",
      "Epoch 3500, Train loss: 6.349e+06, Test loss: 6.394e+06, MSE(e): 6.292e-01, MSE(pi1): 3.433e+00, MSE(pi2): 4.295e-01, MSE(pi3): 2.185e-01\n",
      "Epoch 3600, Train loss: 5.956e+06, Test loss: 6.036e+06, MSE(e): 5.896e-01, MSE(pi1): 3.836e+00, MSE(pi2): 4.012e-01, MSE(pi3): 2.112e-01\n",
      "Epoch 3700, Train loss: 5.805e+06, Test loss: 5.860e+06, MSE(e): 5.744e-01, MSE(pi1): 3.964e+00, MSE(pi2): 3.909e-01, MSE(pi3): 2.090e-01\n",
      "Epoch 3800, Train loss: 5.745e+06, Test loss: 5.769e+06, MSE(e): 5.683e-01, MSE(pi1): 4.000e+00, MSE(pi2): 3.871e-01, MSE(pi3): 2.084e-01\n",
      "Epoch 3900, Train loss: 5.713e+06, Test loss: 5.716e+06, MSE(e): 5.652e-01, MSE(pi1): 3.993e+00, MSE(pi2): 3.853e-01, MSE(pi3): 2.080e-01\n",
      "Epoch 4000, Train loss: 5.692e+06, Test loss: 5.679e+06, MSE(e): 5.631e-01, MSE(pi1): 3.964e+00, MSE(pi2): 3.841e-01, MSE(pi3): 2.075e-01\n",
      "Epoch 4100, Train loss: 5.675e+06, Test loss: 5.651e+06, MSE(e): 5.614e-01, MSE(pi1): 3.938e+00, MSE(pi2): 3.831e-01, MSE(pi3): 2.070e-01\n",
      "Epoch 4200, Train loss: 5.659e+06, Test loss: 5.627e+06, MSE(e): 5.599e-01, MSE(pi1): 3.914e+00, MSE(pi2): 3.821e-01, MSE(pi3): 2.067e-01\n",
      "Epoch 4300, Train loss: 5.644e+06, Test loss: 5.605e+06, MSE(e): 5.584e-01, MSE(pi1): 3.893e+00, MSE(pi2): 3.812e-01, MSE(pi3): 2.063e-01\n",
      "Epoch 4400, Train loss: 5.629e+06, Test loss: 5.585e+06, MSE(e): 5.569e-01, MSE(pi1): 3.871e+00, MSE(pi2): 3.803e-01, MSE(pi3): 2.060e-01\n",
      "Epoch 4500, Train loss: 5.614e+06, Test loss: 5.565e+06, MSE(e): 5.555e-01, MSE(pi1): 3.849e+00, MSE(pi2): 3.794e-01, MSE(pi3): 2.057e-01\n",
      "Epoch 4600, Train loss: 5.598e+06, Test loss: 5.546e+06, MSE(e): 5.539e-01, MSE(pi1): 3.827e+00, MSE(pi2): 3.785e-01, MSE(pi3): 2.054e-01\n",
      "Epoch 4700, Train loss: 5.582e+06, Test loss: 5.526e+06, MSE(e): 5.523e-01, MSE(pi1): 3.810e+00, MSE(pi2): 3.774e-01, MSE(pi3): 2.051e-01\n",
      "Epoch 4800, Train loss: 5.564e+06, Test loss: 5.507e+06, MSE(e): 5.505e-01, MSE(pi1): 3.804e+00, MSE(pi2): 3.763e-01, MSE(pi3): 2.048e-01\n",
      "Epoch 4900, Train loss: 5.543e+06, Test loss: 5.486e+06, MSE(e): 5.485e-01, MSE(pi1): 3.811e+00, MSE(pi2): 3.750e-01, MSE(pi3): 2.046e-01\n",
      "Epoch 5000, Train loss: 5.519e+06, Test loss: 5.462e+06, MSE(e): 5.460e-01, MSE(pi1): 3.824e+00, MSE(pi2): 3.734e-01, MSE(pi3): 2.044e-01\n",
      "Epoch 5100, Train loss: 5.489e+06, Test loss: 5.436e+06, MSE(e): 5.430e-01, MSE(pi1): 3.852e+00, MSE(pi2): 3.714e-01, MSE(pi3): 2.042e-01\n",
      "Epoch 5200, Train loss: 5.443e+06, Test loss: 5.395e+06, MSE(e): 5.384e-01, MSE(pi1): 3.844e+00, MSE(pi2): 3.684e-01, MSE(pi3): 2.039e-01\n",
      "Epoch 5300, Train loss: 5.339e+06, Test loss: 5.300e+06, MSE(e): 5.280e-01, MSE(pi1): 3.861e+00, MSE(pi2): 3.615e-01, MSE(pi3): 2.032e-01\n",
      "Epoch 5400, Train loss: 4.263e+06, Test loss: 4.245e+06, MSE(e): 4.207e-01, MSE(pi1): 3.737e+00, MSE(pi2): 2.908e-01, MSE(pi3): 1.844e-01\n",
      "Epoch 5500, Train loss: 3.636e+05, Test loss: 4.073e+05, MSE(e): 3.463e-02, MSE(pi1): 1.357e+00, MSE(pi2): 2.344e-02, MSE(pi3): 3.695e-02\n",
      "Epoch 5600, Train loss: 2.050e+05, Test loss: 2.310e+05, MSE(e): 1.935e-02, MSE(pi1): 9.399e-01, MSE(pi2): 1.255e-02, MSE(pi3): 2.054e-02\n",
      "Epoch 5700, Train loss: 1.434e+05, Test loss: 1.628e+05, MSE(e): 1.341e-02, MSE(pi1): 7.590e-01, MSE(pi2): 8.596e-03, MSE(pi3): 1.650e-02\n",
      "Epoch 5800, Train loss: 1.056e+05, Test loss: 1.217e+05, MSE(e): 9.792e-03, MSE(pi1): 6.258e-01, MSE(pi2): 6.218e-03, MSE(pi3): 1.412e-02\n",
      "Epoch 5900, Train loss: 7.813e+04, Test loss: 9.329e+04, MSE(e): 7.146e-03, MSE(pi1): 5.415e-01, MSE(pi2): 4.533e-03, MSE(pi3): 1.253e-02\n",
      "Epoch 6000, Train loss: 6.018e+04, Test loss: 7.332e+04, MSE(e): 5.400e-03, MSE(pi1): 5.015e-01, MSE(pi2): 3.412e-03, MSE(pi3): 1.164e-02\n",
      "Epoch 6100, Train loss: 4.801e+04, Test loss: 5.860e+04, MSE(e): 4.240e-03, MSE(pi1): 4.517e-01, MSE(pi2): 2.645e-03, MSE(pi3): 1.086e-02\n",
      "Epoch 6200, Train loss: 3.972e+04, Test loss: 4.949e+04, MSE(e): 3.479e-03, MSE(pi1): 3.903e-01, MSE(pi2): 2.158e-03, MSE(pi3): 1.027e-02\n",
      "Epoch 6300, Train loss: 3.444e+04, Test loss: 4.341e+04, MSE(e): 3.000e-03, MSE(pi1): 3.449e-01, MSE(pi2): 1.858e-03, MSE(pi3): 9.912e-03\n",
      "Epoch 6400, Train loss: 3.054e+04, Test loss: 3.947e+04, MSE(e): 2.659e-03, MSE(pi1): 2.986e-01, MSE(pi2): 1.650e-03, MSE(pi3): 9.621e-03\n",
      "Epoch 6500, Train loss: 2.783e+04, Test loss: 3.830e+04, MSE(e): 2.411e-03, MSE(pi1): 2.764e-01, MSE(pi2): 1.503e-03, MSE(pi3): 9.479e-03\n",
      "Epoch 6600, Train loss: 2.529e+04, Test loss: 3.521e+04, MSE(e): 2.186e-03, MSE(pi1): 2.499e-01, MSE(pi2): 1.368e-03, MSE(pi3): 9.307e-03\n",
      "Epoch 6700, Train loss: 2.374e+04, Test loss: 3.511e+04, MSE(e): 2.051e-03, MSE(pi1): 2.310e-01, MSE(pi2): 1.279e-03, MSE(pi3): 9.211e-03\n",
      "Epoch 6800, Train loss: 2.161e+04, Test loss: 3.163e+04, MSE(e): 1.853e-03, MSE(pi1): 2.172e-01, MSE(pi2): 1.165e-03, MSE(pi3): 9.113e-03\n",
      "Epoch 6900, Train loss: 2.110e+04, Test loss: 3.325e+04, MSE(e): 1.814e-03, MSE(pi1): 2.050e-01, MSE(pi2): 1.124e-03, MSE(pi3): 9.078e-03\n",
      "Epoch 7000, Train loss: 1.882e+04, Test loss: 2.834e+04, MSE(e): 1.614e-03, MSE(pi1): 1.785e-01, MSE(pi2): 1.012e-03, MSE(pi3): 8.930e-03\n",
      "Epoch 7100, Train loss: 1.716e+04, Test loss: 2.607e+04, MSE(e): 1.469e-03, MSE(pi1): 1.597e-01, MSE(pi2): 9.274e-04, MSE(pi3): 8.788e-03\n",
      "Epoch 7200, Train loss: 1.594e+04, Test loss: 2.435e+04, MSE(e): 1.366e-03, MSE(pi1): 1.412e-01, MSE(pi2): 8.639e-04, MSE(pi3): 8.662e-03\n",
      "Epoch 7300, Train loss: 1.615e+04, Test loss: 2.409e+04, MSE(e): 1.403e-03, MSE(pi1): 1.252e-01, MSE(pi2): 8.650e-04, MSE(pi3): 8.607e-03\n",
      "Epoch 7400, Train loss: 1.894e+04, Test loss: 2.194e+04, MSE(e): 1.696e-03, MSE(pi1): 1.115e-01, MSE(pi2): 9.770e-04, MSE(pi3): 8.677e-03\n",
      "Epoch 7500, Train loss: 1.372e+04, Test loss: 2.157e+04, MSE(e): 1.150e-03, MSE(pi1): 1.365e-01, MSE(pi2): 7.280e-04, MSE(pi3): 8.521e-03\n",
      "Epoch 7600, Train loss: 1.286e+04, Test loss: 2.051e+04, MSE(e): 1.076e-03, MSE(pi1): 1.253e-01, MSE(pi2): 6.857e-04, MSE(pi3): 8.460e-03\n",
      "Epoch 7700, Train loss: 1.221e+04, Test loss: 1.963e+04, MSE(e): 1.023e-03, MSE(pi1): 1.140e-01, MSE(pi2): 6.519e-04, MSE(pi3): 8.412e-03\n",
      "Epoch 7800, Train loss: 1.189e+04, Test loss: 1.869e+04, MSE(e): 1.011e-03, MSE(pi1): 9.447e-02, MSE(pi2): 6.373e-04, MSE(pi3): 8.350e-03\n",
      "Epoch 7900, Train loss: 1.170e+04, Test loss: 2.013e+04, MSE(e): 9.782e-04, MSE(pi1): 1.083e-01, MSE(pi2): 6.156e-04, MSE(pi3): 8.351e-03\n",
      "Epoch 8000, Train loss: 1.088e+04, Test loss: 1.798e+04, MSE(e): 9.048e-04, MSE(pi1): 9.964e-02, MSE(pi2): 5.744e-04, MSE(pi3): 8.317e-03\n",
      "Epoch 8100, Train loss: 1.050e+04, Test loss: 1.735e+04, MSE(e): 8.607e-04, MSE(pi1): 1.064e-01, MSE(pi2): 5.478e-04, MSE(pi3): 8.314e-03\n",
      "Epoch 8200, Train loss: 1.065e+04, Test loss: 1.842e+04, MSE(e): 8.694e-04, MSE(pi1): 1.125e-01, MSE(pi2): 5.458e-04, MSE(pi3): 8.315e-03\n",
      "Epoch 8300, Train loss: 1.052e+04, Test loss: 1.826e+04, MSE(e): 8.256e-04, MSE(pi1): 1.426e-01, MSE(pi2): 5.175e-04, MSE(pi3): 8.383e-03\n",
      "Epoch 8400, Train loss: 1.028e+04, Test loss: 1.575e+04, MSE(e): 8.590e-04, MSE(pi1): 8.662e-02, MSE(pi2): 5.271e-04, MSE(pi3): 8.273e-03\n",
      "Epoch 8500, Train loss: 9.134e+03, Test loss: 1.525e+04, MSE(e): 7.389e-04, MSE(pi1): 9.225e-02, MSE(pi2): 4.698e-04, MSE(pi3): 8.224e-03\n",
      "Epoch 8600, Train loss: 8.740e+03, Test loss: 1.486e+04, MSE(e): 7.250e-04, MSE(pi1): 6.708e-02, MSE(pi2): 4.610e-04, MSE(pi3): 8.182e-03\n",
      "Epoch 8700, Train loss: 8.446e+03, Test loss: 1.433e+04, MSE(e): 7.072e-04, MSE(pi1): 5.604e-02, MSE(pi2): 4.460e-04, MSE(pi3): 8.136e-03\n",
      "Epoch 8800, Train loss: 8.747e+03, Test loss: 1.462e+04, MSE(e): 6.785e-04, MSE(pi1): 1.137e-01, MSE(pi2): 4.284e-04, MSE(pi3): 8.246e-03\n",
      "Epoch 8900, Train loss: 1.037e+04, Test loss: 1.621e+04, MSE(e): 9.004e-04, MSE(pi1): 5.459e-02, MSE(pi2): 5.200e-04, MSE(pi3): 8.182e-03\n",
      "Epoch 9000, Train loss: 7.626e+03, Test loss: 1.301e+04, MSE(e): 6.317e-04, MSE(pi1): 4.959e-02, MSE(pi2): 4.024e-04, MSE(pi3): 8.121e-03\n",
      "Epoch 9100, Train loss: 7.565e+03, Test loss: 1.280e+04, MSE(e): 6.067e-04, MSE(pi1): 6.840e-02, MSE(pi2): 3.867e-04, MSE(pi3): 8.140e-03\n",
      "Epoch 9200, Train loss: 9.065e+03, Test loss: 1.943e+04, MSE(e): 7.783e-04, MSE(pi1): 4.649e-02, MSE(pi2): 4.567e-04, MSE(pi3): 8.170e-03\n",
      "Epoch 9300, Train loss: 9.644e+03, Test loss: 1.331e+04, MSE(e): 8.276e-04, MSE(pi1): 5.528e-02, MSE(pi2): 4.726e-04, MSE(pi3): 8.150e-03\n",
      "Epoch 9400, Train loss: 7.334e+03, Test loss: 1.272e+04, MSE(e): 6.002e-04, MSE(pi1): 5.212e-02, MSE(pi2): 3.739e-04, MSE(pi3): 8.111e-03\n",
      "Epoch 9500, Train loss: 8.582e+03, Test loss: 1.589e+04, MSE(e): 7.336e-04, MSE(pi1): 4.328e-02, MSE(pi2): 4.298e-04, MSE(pi3): 8.128e-03\n",
      "Epoch 9600, Train loss: 6.758e+03, Test loss: 1.214e+04, MSE(e): 5.542e-04, MSE(pi1): 4.074e-02, MSE(pi2): 3.469e-04, MSE(pi3): 8.091e-03\n",
      "Epoch 9700, Train loss: 6.994e+03, Test loss: 1.220e+04, MSE(e): 5.400e-04, MSE(pi1): 7.786e-02, MSE(pi2): 3.387e-04, MSE(pi3): 8.150e-03\n",
      "Epoch 9800, Train loss: 9.329e+03, Test loss: 1.204e+04, MSE(e): 7.686e-04, MSE(pi1): 8.264e-02, MSE(pi2): 4.327e-04, MSE(pi3): 8.163e-03\n",
      "Epoch 9900, Train loss: 7.234e+03, Test loss: 1.256e+04, MSE(e): 4.984e-04, MSE(pi1): 1.422e-01, MSE(pi2): 3.121e-04, MSE(pi3): 8.267e-03\n",
      "Epoch 10000, Train loss: 6.394e+03, Test loss: 1.147e+04, MSE(e): 5.105e-04, MSE(pi1): 4.819e-02, MSE(pi2): 3.184e-04, MSE(pi3): 8.075e-03\n",
      "Epoch 10100, Train loss: 6.125e+03, Test loss: 1.061e+04, MSE(e): 4.719e-04, MSE(pi1): 5.958e-02, MSE(pi2): 2.991e-04, MSE(pi3): 8.102e-03\n",
      "Epoch 10200, Train loss: 5.800e+03, Test loss: 1.007e+04, MSE(e): 4.539e-04, MSE(pi1): 4.545e-02, MSE(pi2): 2.878e-04, MSE(pi3): 8.066e-03\n",
      "Epoch 10300, Train loss: 6.196e+03, Test loss: 1.108e+04, MSE(e): 4.856e-04, MSE(pi1): 5.298e-02, MSE(pi2): 3.019e-04, MSE(pi3): 8.096e-03\n",
      "Epoch 10400, Train loss: 5.823e+03, Test loss: 9.973e+03, MSE(e): 4.650e-04, MSE(pi1): 3.658e-02, MSE(pi2): 2.883e-04, MSE(pi3): 8.062e-03\n",
      "Epoch 10500, Train loss: 5.835e+03, Test loss: 1.015e+04, MSE(e): 4.308e-04, MSE(pi1): 7.119e-02, MSE(pi2): 2.720e-04, MSE(pi3): 8.144e-03\n",
      "Epoch 10600, Train loss: 5.929e+03, Test loss: 9.403e+03, MSE(e): 4.656e-04, MSE(pi1): 4.662e-02, MSE(pi2): 2.831e-04, MSE(pi3): 8.067e-03\n",
      "Epoch 10700, Train loss: 6.163e+03, Test loss: 1.146e+04, MSE(e): 4.776e-04, MSE(pi1): 5.755e-02, MSE(pi2): 2.910e-04, MSE(pi3): 8.112e-03\n",
      "Epoch 10800, Train loss: 5.278e+03, Test loss: 8.922e+03, MSE(e): 4.026e-04, MSE(pi1): 4.470e-02, MSE(pi2): 2.522e-04, MSE(pi3): 8.044e-03\n",
      "Epoch 10900, Train loss: 5.428e+03, Test loss: 9.462e+03, MSE(e): 4.062e-04, MSE(pi1): 5.583e-02, MSE(pi2): 2.555e-04, MSE(pi3): 8.073e-03\n",
      "Epoch 11000, Train loss: 5.318e+03, Test loss: 8.664e+03, MSE(e): 4.145e-04, MSE(pi1): 3.695e-02, MSE(pi2): 2.535e-04, MSE(pi3): 8.033e-03\n",
      "Epoch 11100, Train loss: 5.231e+03, Test loss: 9.127e+03, MSE(e): 3.752e-04, MSE(pi1): 6.699e-02, MSE(pi2): 2.355e-04, MSE(pi3): 8.085e-03\n",
      "Epoch 11200, Train loss: 4.965e+03, Test loss: 8.676e+03, MSE(e): 3.682e-04, MSE(pi1): 4.777e-02, MSE(pi2): 2.316e-04, MSE(pi3): 8.048e-03\n",
      "Epoch 11300, Train loss: 4.888e+03, Test loss: 8.398e+03, MSE(e): 3.677e-04, MSE(pi1): 4.084e-02, MSE(pi2): 2.317e-04, MSE(pi3): 8.025e-03\n",
      "Epoch 11400, Train loss: 5.305e+03, Test loss: 9.839e+03, MSE(e): 4.082e-04, MSE(pi1): 4.188e-02, MSE(pi2): 2.483e-04, MSE(pi3): 8.044e-03\n",
      "Epoch 11500, Train loss: 8.037e+03, Test loss: 1.039e+04, MSE(e): 6.696e-04, MSE(pi1): 5.267e-02, MSE(pi2): 3.586e-04, MSE(pi3): 8.133e-03\n",
      "Epoch 11600, Train loss: 5.497e+03, Test loss: 9.958e+03, MSE(e): 4.327e-04, MSE(pi1): 3.653e-02, MSE(pi2): 2.590e-04, MSE(pi3): 8.038e-03\n",
      "Epoch 11700, Train loss: 4.724e+03, Test loss: 7.938e+03, MSE(e): 3.537e-04, MSE(pi1): 3.828e-02, MSE(pi2): 2.173e-04, MSE(pi3): 8.034e-03\n",
      "Epoch 11800, Train loss: 4.740e+03, Test loss: 7.968e+03, MSE(e): 3.375e-04, MSE(pi1): 5.592e-02, MSE(pi2): 2.107e-04, MSE(pi3): 8.057e-03\n",
      "Epoch 11900, Train loss: 4.825e+03, Test loss: 8.305e+03, MSE(e): 3.335e-04, MSE(pi1): 6.819e-02, MSE(pi2): 2.051e-04, MSE(pi3): 8.075e-03\n",
      "Epoch 12000, Train loss: 4.366e+03, Test loss: 7.513e+03, MSE(e): 3.246e-04, MSE(pi1): 3.187e-02, MSE(pi2): 2.031e-04, MSE(pi3): 8.007e-03\n",
      "Epoch 12100, Train loss: 4.449e+03, Test loss: 7.840e+03, MSE(e): 3.180e-04, MSE(pi1): 4.654e-02, MSE(pi2): 1.991e-04, MSE(pi3): 8.039e-03\n",
      "Epoch 12200, Train loss: 4.583e+03, Test loss: 8.107e+03, MSE(e): 3.146e-04, MSE(pi1): 6.273e-02, MSE(pi2): 1.970e-04, MSE(pi3): 8.098e-03\n",
      "Epoch 12300, Train loss: 4.870e+03, Test loss: 8.631e+03, MSE(e): 3.154e-04, MSE(pi1): 9.039e-02, MSE(pi2): 1.925e-04, MSE(pi3): 8.119e-03\n",
      "Epoch 12400, Train loss: 4.497e+03, Test loss: 7.967e+03, MSE(e): 3.374e-04, MSE(pi1): 3.202e-02, MSE(pi2): 2.044e-04, MSE(pi3): 8.024e-03\n",
      "Epoch 12500, Train loss: 4.788e+03, Test loss: 1.013e+04, MSE(e): 3.647e-04, MSE(pi1): 3.397e-02, MSE(pi2): 2.182e-04, MSE(pi3): 8.015e-03\n",
      "Epoch 12600, Train loss: 4.032e+03, Test loss: 7.030e+03, MSE(e): 2.911e-04, MSE(pi1): 3.205e-02, MSE(pi2): 1.812e-04, MSE(pi3): 8.006e-03\n",
      "Epoch 12700, Train loss: 4.214e+03, Test loss: 7.502e+03, MSE(e): 3.159e-04, MSE(pi1): 2.552e-02, MSE(pi2): 1.903e-04, MSE(pi3): 7.999e-03\n",
      "Epoch 12800, Train loss: 3.945e+03, Test loss: 6.801e+03, MSE(e): 2.877e-04, MSE(pi1): 2.678e-02, MSE(pi2): 1.770e-04, MSE(pi3): 7.999e-03\n",
      "Epoch 12900, Train loss: 4.056e+03, Test loss: 6.840e+03, MSE(e): 2.864e-04, MSE(pi1): 3.908e-02, MSE(pi2): 1.753e-04, MSE(pi3): 8.012e-03\n",
      "Epoch 13000, Train loss: 4.154e+03, Test loss: 7.749e+03, MSE(e): 2.911e-04, MSE(pi1): 4.379e-02, MSE(pi2): 1.806e-04, MSE(pi3): 8.046e-03\n",
      "Epoch 13100, Train loss: 4.088e+03, Test loss: 6.824e+03, MSE(e): 2.935e-04, MSE(pi1): 3.512e-02, MSE(pi2): 1.773e-04, MSE(pi3): 8.007e-03\n",
      "Epoch 13200, Train loss: 4.051e+03, Test loss: 7.694e+03, MSE(e): 2.907e-04, MSE(pi1): 3.429e-02, MSE(pi2): 1.810e-04, MSE(pi3): 8.006e-03\n",
      "Epoch 13300, Train loss: 3.986e+03, Test loss: 6.873e+03, MSE(e): 2.696e-04, MSE(pi1): 4.870e-02, MSE(pi2): 1.648e-04, MSE(pi3): 8.032e-03\n",
      "Epoch 13400, Train loss: 4.398e+03, Test loss: 7.832e+03, MSE(e): 2.920e-04, MSE(pi1): 6.678e-02, MSE(pi2): 1.799e-04, MSE(pi3): 8.095e-03\n",
      "Epoch 13500, Train loss: 3.768e+03, Test loss: 6.774e+03, MSE(e): 2.630e-04, MSE(pi1): 3.356e-02, MSE(pi2): 1.625e-04, MSE(pi3): 8.016e-03\n",
      "Epoch 13600, Train loss: 6.556e+03, Test loss: 1.628e+04, MSE(e): 5.325e-04, MSE(pi1): 4.223e-02, MSE(pi2): 2.786e-04, MSE(pi3): 8.078e-03\n",
      "Epoch 13700, Train loss: 4.215e+03, Test loss: 7.313e+03, MSE(e): 2.738e-04, MSE(pi1): 6.690e-02, MSE(pi2): 1.636e-04, MSE(pi3): 8.082e-03\n",
      "Epoch 13800, Train loss: 3.761e+03, Test loss: 6.961e+03, MSE(e): 2.700e-04, MSE(pi1): 2.635e-02, MSE(pi2): 1.675e-04, MSE(pi3): 7.978e-03\n",
      "Epoch 13900, Train loss: 3.966e+03, Test loss: 6.929e+03, MSE(e): 2.696e-04, MSE(pi1): 4.656e-02, MSE(pi2): 1.608e-04, MSE(pi3): 8.039e-03\n",
      "Epoch 14000, Train loss: 3.745e+03, Test loss: 6.583e+03, MSE(e): 2.525e-04, MSE(pi1): 4.157e-02, MSE(pi2): 1.572e-04, MSE(pi3): 8.041e-03\n",
      "Epoch 14100, Train loss: 4.214e+03, Test loss: 7.083e+03, MSE(e): 2.759e-04, MSE(pi1): 6.467e-02, MSE(pi2): 1.605e-04, MSE(pi3): 8.087e-03\n",
      "Epoch 14200, Train loss: 3.718e+03, Test loss: 6.649e+03, MSE(e): 2.435e-04, MSE(pi1): 4.787e-02, MSE(pi2): 1.511e-04, MSE(pi3): 8.039e-03\n",
      "Epoch 14300, Train loss: 3.512e+03, Test loss: 5.893e+03, MSE(e): 2.464e-04, MSE(pi1): 2.505e-02, MSE(pi2): 1.496e-04, MSE(pi3): 7.983e-03\n",
      "Epoch 14400, Train loss: 3.873e+03, Test loss: 6.791e+03, MSE(e): 2.466e-04, MSE(pi1): 5.977e-02, MSE(pi2): 1.516e-04, MSE(pi3): 8.088e-03\n",
      "Epoch 14500, Train loss: 3.524e+03, Test loss: 5.729e+03, MSE(e): 2.474e-04, MSE(pi1): 2.496e-02, MSE(pi2): 1.486e-04, MSE(pi3): 8.005e-03\n",
      "Epoch 14600, Train loss: 4.021e+03, Test loss: 7.022e+03, MSE(e): 2.386e-04, MSE(pi1): 8.247e-02, MSE(pi2): 1.460e-04, MSE(pi3): 8.099e-03\n",
      "Epoch 14700, Train loss: 3.944e+03, Test loss: 7.283e+03, MSE(e): 2.623e-04, MSE(pi1): 5.136e-02, MSE(pi2): 1.571e-04, MSE(pi3): 8.074e-03\n",
      "Epoch 14800, Train loss: 6.631e+03, Test loss: 7.071e+03, MSE(e): 5.559e-04, MSE(pi1): 2.635e-02, MSE(pi2): 2.847e-04, MSE(pi3): 8.073e-03\n",
      "Epoch 14900, Train loss: 3.696e+03, Test loss: 6.736e+03, MSE(e): 2.378e-04, MSE(pi1): 5.153e-02, MSE(pi2): 1.458e-04, MSE(pi3): 8.030e-03\n",
      "Epoch 15000, Train loss: 3.598e+03, Test loss: 6.274e+03, MSE(e): 2.214e-04, MSE(pi1): 5.783e-02, MSE(pi2): 1.361e-04, MSE(pi3): 8.049e-03\n",
      "Epoch 15100, Train loss: 3.669e+03, Test loss: 6.509e+03, MSE(e): 2.289e-04, MSE(pi1): 5.737e-02, MSE(pi2): 1.405e-04, MSE(pi3): 8.056e-03\n",
      "Epoch 15200, Train loss: 3.477e+03, Test loss: 6.070e+03, MSE(e): 2.328e-04, MSE(pi1): 3.500e-02, MSE(pi2): 1.397e-04, MSE(pi3): 7.987e-03\n",
      "Epoch 15300, Train loss: 3.719e+03, Test loss: 6.485e+03, MSE(e): 2.325e-04, MSE(pi1): 5.880e-02, MSE(pi2): 1.409e-04, MSE(pi3): 8.064e-03\n",
      "Epoch 15400, Train loss: 8.195e+03, Test loss: 8.681e+03, MSE(e): 6.938e-04, MSE(pi1): 4.449e-02, MSE(pi2): 3.429e-04, MSE(pi3): 8.118e-03\n",
      "Epoch 15500, Train loss: 3.243e+03, Test loss: 5.713e+03, MSE(e): 2.123e-04, MSE(pi1): 3.193e-02, MSE(pi2): 1.306e-04, MSE(pi3): 8.003e-03\n",
      "Epoch 15600, Train loss: 3.632e+03, Test loss: 6.355e+03, MSE(e): 2.383e-04, MSE(pi1): 4.448e-02, MSE(pi2): 1.428e-04, MSE(pi3): 8.047e-03\n",
      "Epoch 15700, Train loss: 4.625e+03, Test loss: 6.315e+03, MSE(e): 3.431e-04, MSE(pi1): 3.941e-02, MSE(pi2): 1.863e-04, MSE(pi3): 7.999e-03\n",
      "Epoch 15800, Train loss: 3.302e+03, Test loss: 5.757e+03, MSE(e): 2.126e-04, MSE(pi1): 3.766e-02, MSE(pi2): 1.315e-04, MSE(pi3): 7.993e-03\n",
      "Epoch 15900, Train loss: 3.393e+03, Test loss: 5.791e+03, MSE(e): 2.112e-04, MSE(pi1): 4.774e-02, MSE(pi2): 1.272e-04, MSE(pi3): 8.028e-03\n",
      "Epoch 16000, Train loss: 3.729e+03, Test loss: 6.451e+03, MSE(e): 2.187e-04, MSE(pi1): 7.346e-02, MSE(pi2): 1.311e-04, MSE(pi3): 8.077e-03\n",
      "Epoch 16100, Train loss: 3.779e+03, Test loss: 8.399e+03, MSE(e): 2.624e-04, MSE(pi1): 3.546e-02, MSE(pi2): 1.507e-04, MSE(pi3): 8.004e-03\n",
      "Epoch 16200, Train loss: 3.747e+03, Test loss: 6.310e+03, MSE(e): 2.219e-04, MSE(pi1): 7.181e-02, MSE(pi2): 1.294e-04, MSE(pi3): 8.098e-03\n",
      "Epoch 16300, Train loss: 3.277e+03, Test loss: 5.794e+03, MSE(e): 2.121e-04, MSE(pi1): 3.582e-02, MSE(pi2): 1.299e-04, MSE(pi3): 7.979e-03\n",
      "Epoch 16400, Train loss: 6.858e+03, Test loss: 6.824e+03, MSE(e): 5.798e-04, MSE(pi1): 2.603e-02, MSE(pi2): 2.896e-04, MSE(pi3): 7.998e-03\n",
      "Epoch 16500, Train loss: 3.092e+03, Test loss: 5.397e+03, MSE(e): 1.967e-04, MSE(pi1): 3.256e-02, MSE(pi2): 1.196e-04, MSE(pi3): 7.989e-03\n",
      "Epoch 16600, Train loss: 3.117e+03, Test loss: 5.555e+03, MSE(e): 1.990e-04, MSE(pi1): 3.274e-02, MSE(pi2): 1.235e-04, MSE(pi3): 8.003e-03\n",
      "Epoch 16700, Train loss: 4.009e+03, Test loss: 5.775e+03, MSE(e): 2.779e-04, MSE(pi1): 4.298e-02, MSE(pi2): 1.568e-04, MSE(pi3): 7.998e-03\n",
      "Epoch 16800, Train loss: 3.055e+03, Test loss: 5.513e+03, MSE(e): 1.945e-04, MSE(pi1): 3.104e-02, MSE(pi2): 1.185e-04, MSE(pi3): 7.993e-03\n",
      "Epoch 16900, Train loss: 3.262e+03, Test loss: 5.903e+03, MSE(e): 1.961e-04, MSE(pi1): 4.951e-02, MSE(pi2): 1.206e-04, MSE(pi3): 8.060e-03\n",
      "Epoch 17000, Train loss: 3.539e+03, Test loss: 5.950e+03, MSE(e): 2.302e-04, MSE(pi1): 4.328e-02, MSE(pi2): 1.335e-04, MSE(pi3): 8.042e-03\n",
      "Epoch 17100, Train loss: 2.955e+03, Test loss: 5.297e+03, MSE(e): 1.823e-04, MSE(pi1): 3.325e-02, MSE(pi2): 1.121e-04, MSE(pi3): 7.994e-03\n",
      "Epoch 17200, Train loss: 3.012e+03, Test loss: 5.624e+03, MSE(e): 2.018e-04, MSE(pi1): 1.989e-02, MSE(pi2): 1.247e-04, MSE(pi3): 7.956e-03\n",
      "Epoch 17300, Train loss: 3.273e+03, Test loss: 5.483e+03, MSE(e): 2.180e-04, MSE(pi1): 2.932e-02, MSE(pi2): 1.295e-04, MSE(pi3): 7.993e-03\n",
      "Epoch 17400, Train loss: 3.194e+03, Test loss: 5.780e+03, MSE(e): 1.901e-04, MSE(pi1): 4.865e-02, MSE(pi2): 1.165e-04, MSE(pi3): 8.058e-03\n",
      "Epoch 17500, Train loss: 7.443e+03, Test loss: 7.568e+03, MSE(e): 5.698e-04, MSE(pi1): 9.212e-02, MSE(pi2): 2.780e-04, MSE(pi3): 8.236e-03\n",
      "Epoch 17600, Train loss: 3.060e+03, Test loss: 5.300e+03, MSE(e): 1.808e-04, MSE(pi1): 4.529e-02, MSE(pi2): 1.098e-04, MSE(pi3): 7.994e-03\n",
      "Epoch 17700, Train loss: 3.261e+03, Test loss: 5.843e+03, MSE(e): 1.887e-04, MSE(pi1): 5.696e-02, MSE(pi2): 1.142e-04, MSE(pi3): 8.041e-03\n",
      "Epoch 17800, Train loss: 4.418e+03, Test loss: 6.093e+03, MSE(e): 3.205e-04, MSE(pi1): 4.100e-02, MSE(pi2): 1.740e-04, MSE(pi3): 8.025e-03\n",
      "Epoch 17900, Train loss: 3.086e+03, Test loss: 5.436e+03, MSE(e): 1.790e-04, MSE(pi1): 4.938e-02, MSE(pi2): 1.081e-04, MSE(pi3): 8.021e-03\n",
      "Epoch 18000, Train loss: 3.129e+03, Test loss: 5.744e+03, MSE(e): 1.823e-04, MSE(pi1): 5.037e-02, MSE(pi2): 1.105e-04, MSE(pi3): 8.028e-03\n",
      "Epoch 18100, Train loss: 6.302e+03, Test loss: 9.270e+03, MSE(e): 5.075e-04, MSE(pi1): 4.157e-02, MSE(pi2): 2.528e-04, MSE(pi3): 8.105e-03\n",
      "Epoch 18200, Train loss: 2.958e+03, Test loss: 5.220e+03, MSE(e): 1.746e-04, MSE(pi1): 4.124e-02, MSE(pi2): 1.080e-04, MSE(pi3): 7.989e-03\n",
      "Epoch 18300, Train loss: 2.940e+03, Test loss: 5.202e+03, MSE(e): 1.858e-04, MSE(pi1): 2.852e-02, MSE(pi2): 1.140e-04, MSE(pi3): 7.973e-03\n",
      "Epoch 18400, Train loss: 3.055e+03, Test loss: 5.377e+03, MSE(e): 2.020e-04, MSE(pi1): 2.372e-02, MSE(pi2): 1.188e-04, MSE(pi3): 7.977e-03\n",
      "Epoch 18500, Train loss: 3.106e+03, Test loss: 5.639e+03, MSE(e): 1.717e-04, MSE(pi1): 5.856e-02, MSE(pi2): 1.032e-04, MSE(pi3): 8.033e-03\n",
      "Epoch 18600, Train loss: 3.967e+03, Test loss: 9.927e+03, MSE(e): 2.807e-04, MSE(pi1): 3.612e-02, MSE(pi2): 1.530e-04, MSE(pi3): 7.987e-03\n",
      "Epoch 18700, Train loss: 3.025e+03, Test loss: 5.223e+03, MSE(e): 1.716e-04, MSE(pi1): 5.025e-02, MSE(pi2): 1.028e-04, MSE(pi3): 8.055e-03\n",
      "Epoch 18800, Train loss: 3.043e+03, Test loss: 5.570e+03, MSE(e): 1.836e-04, MSE(pi1): 4.021e-02, MSE(pi2): 1.127e-04, MSE(pi3): 8.041e-03\n",
      "Epoch 18900, Train loss: 7.529e+03, Test loss: 1.733e+04, MSE(e): 6.531e-04, MSE(pi1): 1.940e-02, MSE(pi2): 3.119e-04, MSE(pi3): 8.038e-03\n",
      "Epoch 19000, Train loss: 2.946e+03, Test loss: 4.865e+03, MSE(e): 1.855e-04, MSE(pi1): 2.919e-02, MSE(pi2): 1.115e-04, MSE(pi3): 7.986e-03\n",
      "Epoch 19100, Train loss: 2.900e+03, Test loss: 5.245e+03, MSE(e): 1.727e-04, MSE(pi1): 3.703e-02, MSE(pi2): 1.063e-04, MSE(pi3): 8.024e-03\n",
      "Epoch 19200, Train loss: 3.527e+03, Test loss: 8.271e+03, MSE(e): 2.277e-04, MSE(pi1): 4.472e-02, MSE(pi2): 1.284e-04, MSE(pi3): 8.025e-03\n",
      "Epoch 19300, Train loss: 2.876e+03, Test loss: 5.022e+03, MSE(e): 1.645e-04, MSE(pi1): 4.292e-02, MSE(pi2): 1.007e-04, MSE(pi3): 8.021e-03\n",
      "Epoch 19400, Train loss: 2.810e+03, Test loss: 5.010e+03, MSE(e): 1.750e-04, MSE(pi1): 2.629e-02, MSE(pi2): 1.071e-04, MSE(pi3): 7.966e-03\n",
      "Epoch 19500, Train loss: 3.852e+03, Test loss: 9.972e+03, MSE(e): 2.805e-04, MSE(pi1): 2.502e-02, MSE(pi2): 1.494e-04, MSE(pi3): 7.968e-03\n",
      "Epoch 19600, Train loss: 2.933e+03, Test loss: 4.722e+03, MSE(e): 1.911e-04, MSE(pi1): 2.252e-02, MSE(pi2): 1.123e-04, MSE(pi3): 7.963e-03\n",
      "Epoch 19700, Train loss: 2.884e+03, Test loss: 5.170e+03, MSE(e): 1.726e-04, MSE(pi1): 3.607e-02, MSE(pi2): 1.061e-04, MSE(pi3): 7.978e-03\n",
      "Epoch 19800, Train loss: 3.054e+03, Test loss: 5.286e+03, MSE(e): 2.053e-04, MSE(pi1): 2.023e-02, MSE(pi2): 1.183e-04, MSE(pi3): 7.984e-03\n",
      "Epoch 19900, Train loss: 2.926e+03, Test loss: 5.133e+03, MSE(e): 1.687e-04, MSE(pi1): 4.403e-02, MSE(pi2): 1.018e-04, MSE(pi3): 7.978e-03\n",
      "Epoch 20000, Train loss: 2.800e+03, Test loss: 5.030e+03, MSE(e): 1.642e-04, MSE(pi1): 3.589e-02, MSE(pi2): 1.006e-04, MSE(pi3): 7.987e-03\n",
      "Epoch 20100, Train loss: 3.439e+03, Test loss: 6.253e+03, MSE(e): 1.912e-04, MSE(pi1): 7.201e-02, MSE(pi2): 1.110e-04, MSE(pi3): 8.070e-03\n",
      "Epoch 20200, Train loss: 2.884e+03, Test loss: 5.134e+03, MSE(e): 1.660e-04, MSE(pi1): 4.255e-02, MSE(pi2): 9.901e-05, MSE(pi3): 7.990e-03\n",
      "Epoch 20300, Train loss: 7.734e+03, Test loss: 6.376e+03, MSE(e): 6.025e-04, MSE(pi1): 8.799e-02, MSE(pi2): 2.874e-04, MSE(pi3): 8.291e-03\n",
      "Epoch 20400, Train loss: 2.612e+03, Test loss: 4.574e+03, MSE(e): 1.586e-04, MSE(pi1): 2.306e-02, MSE(pi2): 9.681e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 20500, Train loss: 2.550e+03, Test loss: 4.613e+03, MSE(e): 1.542e-04, MSE(pi1): 2.107e-02, MSE(pi2): 9.508e-05, MSE(pi3): 7.971e-03\n",
      "Epoch 20600, Train loss: 3.121e+03, Test loss: 5.116e+03, MSE(e): 1.939e-04, MSE(pi1): 3.834e-02, MSE(pi2): 1.130e-04, MSE(pi3): 7.988e-03\n",
      "Epoch 20700, Train loss: 2.654e+03, Test loss: 4.781e+03, MSE(e): 1.516e-04, MSE(pi1): 3.387e-02, MSE(pi2): 9.374e-05, MSE(pi3): 7.997e-03\n",
      "Epoch 20800, Train loss: 5.406e+03, Test loss: 1.173e+04, MSE(e): 4.258e-04, MSE(pi1): 3.438e-02, MSE(pi2): 2.096e-04, MSE(pi3): 8.042e-03\n",
      "Epoch 20900, Train loss: 2.964e+03, Test loss: 4.900e+03, MSE(e): 1.816e-04, MSE(pi1): 3.509e-02, MSE(pi2): 1.063e-04, MSE(pi3): 7.964e-03\n",
      "Epoch 21000, Train loss: 2.835e+03, Test loss: 5.119e+03, MSE(e): 1.518e-04, MSE(pi1): 5.141e-02, MSE(pi2): 9.158e-05, MSE(pi3): 8.026e-03\n",
      "Epoch 21100, Train loss: 2.756e+03, Test loss: 4.918e+03, MSE(e): 1.710e-04, MSE(pi1): 2.486e-02, MSE(pi2): 1.014e-04, MSE(pi3): 7.973e-03\n",
      "Epoch 21200, Train loss: 2.710e+03, Test loss: 4.877e+03, MSE(e): 1.546e-04, MSE(pi1): 3.649e-02, MSE(pi2): 9.320e-05, MSE(pi3): 7.990e-03\n",
      "Epoch 21300, Train loss: 7.484e+03, Test loss: 9.899e+03, MSE(e): 6.470e-04, MSE(pi1): 2.067e-02, MSE(pi2): 3.058e-04, MSE(pi3): 8.072e-03\n",
      "Epoch 21400, Train loss: 2.438e+03, Test loss: 4.345e+03, MSE(e): 1.466e-04, MSE(pi1): 1.769e-02, MSE(pi2): 9.117e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 21500, Train loss: 2.648e+03, Test loss: 4.802e+03, MSE(e): 1.481e-04, MSE(pi1): 3.675e-02, MSE(pi2): 9.047e-05, MSE(pi3): 7.995e-03\n",
      "Epoch 21600, Train loss: 6.814e+03, Test loss: 5.151e+03, MSE(e): 5.701e-04, MSE(pi1): 3.016e-02, MSE(pi2): 2.750e-04, MSE(pi3): 8.116e-03\n",
      "Epoch 21700, Train loss: 2.782e+03, Test loss: 4.804e+03, MSE(e): 1.537e-04, MSE(pi1): 4.431e-02, MSE(pi2): 9.359e-05, MSE(pi3): 8.022e-03\n",
      "Epoch 21800, Train loss: 2.773e+03, Test loss: 5.088e+03, MSE(e): 1.483e-04, MSE(pi1): 4.844e-02, MSE(pi2): 9.221e-05, MSE(pi3): 8.049e-03\n",
      "Epoch 21900, Train loss: 2.564e+03, Test loss: 4.302e+03, MSE(e): 1.525e-04, MSE(pi1): 2.424e-02, MSE(pi2): 9.248e-05, MSE(pi3): 7.967e-03\n",
      "Epoch 22000, Train loss: 2.694e+03, Test loss: 4.847e+03, MSE(e): 1.529e-04, MSE(pi1): 3.678e-02, MSE(pi2): 9.240e-05, MSE(pi3): 7.973e-03\n",
      "Epoch 22100, Train loss: 3.020e+03, Test loss: 5.330e+03, MSE(e): 1.852e-04, MSE(pi1): 3.662e-02, MSE(pi2): 1.048e-04, MSE(pi3): 8.010e-03\n",
      "Epoch 22200, Train loss: 2.565e+03, Test loss: 4.659e+03, MSE(e): 1.438e-04, MSE(pi1): 3.259e-02, MSE(pi2): 8.908e-05, MSE(pi3): 8.007e-03\n",
      "Epoch 22300, Train loss: 2.481e+03, Test loss: 4.499e+03, MSE(e): 1.396e-04, MSE(pi1): 2.863e-02, MSE(pi2): 8.630e-05, MSE(pi3): 7.981e-03\n",
      "Epoch 22400, Train loss: 3.192e+03, Test loss: 4.906e+03, MSE(e): 1.905e-04, MSE(pi1): 4.865e-02, MSE(pi2): 1.082e-04, MSE(pi3): 8.003e-03\n",
      "Epoch 22500, Train loss: 2.535e+03, Test loss: 4.561e+03, MSE(e): 1.482e-04, MSE(pi1): 2.535e-02, MSE(pi2): 9.158e-05, MSE(pi3): 7.993e-03\n",
      "Epoch 22600, Train loss: 2.526e+03, Test loss: 5.010e+03, MSE(e): 1.420e-04, MSE(pi1): 3.100e-02, MSE(pi2): 8.661e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 22700, Train loss: 2.672e+03, Test loss: 4.669e+03, MSE(e): 1.485e-04, MSE(pi1): 3.875e-02, MSE(pi2): 8.930e-05, MSE(pi3): 7.995e-03\n",
      "Epoch 22800, Train loss: 2.647e+03, Test loss: 4.822e+03, MSE(e): 1.377e-04, MSE(pi1): 4.681e-02, MSE(pi2): 8.340e-05, MSE(pi3): 8.016e-03\n",
      "Epoch 22900, Train loss: 2.558e+03, Test loss: 5.403e+03, MSE(e): 1.470e-04, MSE(pi1): 2.899e-02, MSE(pi2): 8.956e-05, MSE(pi3): 7.984e-03\n",
      "Epoch 23000, Train loss: 2.406e+03, Test loss: 4.198e+03, MSE(e): 1.404e-04, MSE(pi1): 2.059e-02, MSE(pi2): 8.628e-05, MSE(pi3): 7.962e-03\n",
      "Epoch 23100, Train loss: 2.826e+03, Test loss: 5.069e+03, MSE(e): 1.410e-04, MSE(pi1): 6.119e-02, MSE(pi2): 8.439e-05, MSE(pi3): 8.034e-03\n",
      "Epoch 23200, Train loss: 4.098e+03, Test loss: 5.444e+03, MSE(e): 2.777e-04, MSE(pi1): 5.165e-02, MSE(pi2): 1.479e-04, MSE(pi3): 8.050e-03\n",
      "Epoch 23300, Train loss: 2.318e+03, Test loss: 4.270e+03, MSE(e): 1.354e-04, MSE(pi1): 1.686e-02, MSE(pi2): 8.497e-05, MSE(pi3): 7.950e-03\n",
      "Epoch 23400, Train loss: 2.886e+03, Test loss: 6.357e+03, MSE(e): 1.684e-04, MSE(pi1): 4.022e-02, MSE(pi2): 9.721e-05, MSE(pi3): 8.001e-03\n",
      "Epoch 23500, Train loss: 2.346e+03, Test loss: 4.227e+03, MSE(e): 1.338e-04, MSE(pi1): 2.105e-02, MSE(pi2): 8.287e-05, MSE(pi3): 7.965e-03\n",
      "Epoch 23600, Train loss: 2.568e+03, Test loss: 4.634e+03, MSE(e): 1.370e-04, MSE(pi1): 3.981e-02, MSE(pi2): 8.356e-05, MSE(pi3): 8.001e-03\n",
      "Epoch 23700, Train loss: 4.638e+03, Test loss: 1.040e+04, MSE(e): 3.524e-04, MSE(pi1): 3.090e-02, MSE(pi2): 1.804e-04, MSE(pi3): 8.050e-03\n",
      "Epoch 23800, Train loss: 2.613e+03, Test loss: 4.423e+03, MSE(e): 1.569e-04, MSE(pi1): 2.467e-02, MSE(pi2): 9.317e-05, MSE(pi3): 7.968e-03\n",
      "Epoch 23900, Train loss: 2.706e+03, Test loss: 4.855e+03, MSE(e): 1.434e-04, MSE(pi1): 4.736e-02, MSE(pi2): 8.760e-05, MSE(pi3): 7.976e-03\n",
      "Epoch 24000, Train loss: 3.456e+03, Test loss: 6.381e+03, MSE(e): 2.335e-04, MSE(pi1): 3.195e-02, MSE(pi2): 1.253e-04, MSE(pi3): 8.011e-03\n",
      "Epoch 24100, Train loss: 2.286e+03, Test loss: 4.195e+03, MSE(e): 1.323e-04, MSE(pi1): 1.681e-02, MSE(pi2): 8.140e-05, MSE(pi3): 7.950e-03\n",
      "Epoch 24200, Train loss: 2.994e+03, Test loss: 7.433e+03, MSE(e): 2.028e-04, MSE(pi1): 1.711e-02, MSE(pi2): 1.097e-04, MSE(pi3): 7.943e-03\n",
      "Epoch 24300, Train loss: 2.648e+03, Test loss: 4.684e+03, MSE(e): 1.442e-04, MSE(pi1): 4.061e-02, MSE(pi2): 8.430e-05, MSE(pi3): 7.998e-03\n",
      "Epoch 24400, Train loss: 2.384e+03, Test loss: 4.281e+03, MSE(e): 1.232e-04, MSE(pi1): 3.538e-02, MSE(pi2): 7.382e-05, MSE(pi3): 7.983e-03\n",
      "Epoch 24500, Train loss: 3.188e+03, Test loss: 5.290e+03, MSE(e): 2.124e-04, MSE(pi1): 2.642e-02, MSE(pi2): 1.122e-04, MSE(pi3): 7.994e-03\n",
      "Epoch 24600, Train loss: 2.165e+03, Test loss: 3.843e+03, MSE(e): 1.078e-04, MSE(pi1): 2.918e-02, MSE(pi2): 6.384e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 24700, Train loss: 2.790e+03, Test loss: 3.699e+03, MSE(e): 1.844e-04, MSE(pi1): 1.479e-02, MSE(pi2): 9.762e-05, MSE(pi3): 7.976e-03\n",
      "Epoch 24800, Train loss: 2.280e+03, Test loss: 3.938e+03, MSE(e): 1.138e-04, MSE(pi1): 3.459e-02, MSE(pi2): 6.702e-05, MSE(pi3): 7.965e-03\n",
      "Epoch 24900, Train loss: 2.218e+03, Test loss: 4.025e+03, MSE(e): 1.116e-04, MSE(pi1): 3.048e-02, MSE(pi2): 6.547e-05, MSE(pi3): 7.967e-03\n",
      "Epoch 25000, Train loss: 4.841e+03, Test loss: 5.846e+03, MSE(e): 3.379e-04, MSE(pi1): 6.578e-02, MSE(pi2): 1.597e-04, MSE(pi3): 8.045e-03\n",
      "Epoch 25100, Train loss: 2.112e+03, Test loss: 3.644e+03, MSE(e): 1.074e-04, MSE(pi1): 2.425e-02, MSE(pi2): 6.413e-05, MSE(pi3): 7.953e-03\n",
      "Epoch 25200, Train loss: 2.661e+03, Test loss: 4.830e+03, MSE(e): 1.548e-04, MSE(pi1): 3.186e-02, MSE(pi2): 8.312e-05, MSE(pi3): 7.952e-03\n",
      "Epoch 25300, Train loss: 2.353e+03, Test loss: 4.050e+03, MSE(e): 1.045e-04, MSE(pi1): 5.099e-02, MSE(pi2): 6.113e-05, MSE(pi3): 7.979e-03\n",
      "Epoch 25400, Train loss: 2.403e+03, Test loss: 4.446e+03, MSE(e): 1.308e-04, MSE(pi1): 2.969e-02, MSE(pi2): 7.328e-05, MSE(pi3): 7.979e-03\n",
      "Epoch 25500, Train loss: 3.037e+03, Test loss: 4.059e+03, MSE(e): 1.930e-04, MSE(pi1): 3.044e-02, MSE(pi2): 1.002e-04, MSE(pi3): 8.019e-03\n",
      "Epoch 25600, Train loss: 2.315e+03, Test loss: 4.022e+03, MSE(e): 1.025e-04, MSE(pi1): 4.914e-02, MSE(pi2): 6.033e-05, MSE(pi3): 7.980e-03\n",
      "Epoch 25700, Train loss: 2.708e+03, Test loss: 4.667e+03, MSE(e): 1.418e-04, MSE(pi1): 4.885e-02, MSE(pi2): 7.750e-05, MSE(pi3): 8.016e-03\n",
      "Epoch 25800, Train loss: 3.172e+03, Test loss: 5.060e+03, MSE(e): 1.828e-04, MSE(pi1): 5.326e-02, MSE(pi2): 9.483e-05, MSE(pi3): 8.108e-03\n",
      "Epoch 25900, Train loss: 2.314e+03, Test loss: 4.069e+03, MSE(e): 1.089e-04, MSE(pi1): 4.236e-02, MSE(pi2): 6.378e-05, MSE(pi3): 8.014e-03\n",
      "Epoch 26000, Train loss: 3.196e+03, Test loss: 4.387e+03, MSE(e): 1.906e-04, MSE(pi1): 4.904e-02, MSE(pi2): 9.757e-05, MSE(pi3): 7.992e-03\n",
      "Epoch 26100, Train loss: 2.587e+03, Test loss: 5.812e+03, MSE(e): 1.505e-04, MSE(pi1): 2.849e-02, MSE(pi2): 8.291e-05, MSE(pi3): 7.968e-03\n",
      "Epoch 26200, Train loss: 1.961e+03, Test loss: 3.615e+03, MSE(e): 1.020e-04, MSE(pi1): 1.489e-02, MSE(pi2): 6.131e-05, MSE(pi3): 7.926e-03\n",
      "Epoch 26300, Train loss: 2.450e+03, Test loss: 4.215e+03, MSE(e): 1.265e-04, MSE(pi1): 3.840e-02, MSE(pi2): 7.085e-05, MSE(pi3): 8.007e-03\n",
      "Epoch 26400, Train loss: 5.000e+03, Test loss: 6.695e+03, MSE(e): 3.817e-04, MSE(pi1): 3.783e-02, MSE(pi2): 1.813e-04, MSE(pi3): 8.050e-03\n",
      "Epoch 26500, Train loss: 2.142e+03, Test loss: 3.793e+03, MSE(e): 9.508e-05, MSE(pi1): 3.925e-02, MSE(pi2): 5.659e-05, MSE(pi3): 7.990e-03\n",
      "Epoch 26600, Train loss: 3.560e+03, Test loss: 9.228e+03, MSE(e): 2.426e-04, MSE(pi1): 3.346e-02, MSE(pi2): 1.221e-04, MSE(pi3): 7.996e-03\n",
      "Epoch 26700, Train loss: 2.037e+03, Test loss: 3.661e+03, MSE(e): 9.667e-05, MSE(pi1): 2.758e-02, MSE(pi2): 5.700e-05, MSE(pi3): 7.947e-03\n",
      "Epoch 26800, Train loss: 2.635e+03, Test loss: 3.715e+03, MSE(e): 1.525e-04, MSE(pi1): 3.146e-02, MSE(pi2): 8.091e-05, MSE(pi3): 7.958e-03\n",
      "Epoch 26900, Train loss: 2.387e+03, Test loss: 4.696e+03, MSE(e): 1.119e-04, MSE(pi1): 4.703e-02, MSE(pi2): 6.279e-05, MSE(pi3): 7.977e-03\n",
      "Epoch 27000, Train loss: 2.205e+03, Test loss: 3.955e+03, MSE(e): 9.967e-05, MSE(pi1): 4.090e-02, MSE(pi2): 5.733e-05, MSE(pi3): 7.997e-03\n",
      "Epoch 27100, Train loss: 2.095e+03, Test loss: 3.679e+03, MSE(e): 1.026e-04, MSE(pi1): 2.724e-02, MSE(pi2): 5.942e-05, MSE(pi3): 7.961e-03\n",
      "Epoch 27200, Train loss: 1.919e+03, Test loss: 3.567e+03, MSE(e): 9.371e-05, MSE(pi1): 1.877e-02, MSE(pi2): 5.633e-05, MSE(pi3): 7.943e-03\n",
      "Epoch 27300, Train loss: 2.195e+03, Test loss: 3.540e+03, MSE(e): 1.220e-04, MSE(pi1): 1.816e-02, MSE(pi2): 6.761e-05, MSE(pi3): 7.941e-03\n",
      "Epoch 27400, Train loss: 2.213e+03, Test loss: 4.150e+03, MSE(e): 1.039e-04, MSE(pi1): 3.760e-02, MSE(pi2): 6.146e-05, MSE(pi3): 7.989e-03\n",
      "Epoch 27500, Train loss: 1.969e+03, Test loss: 3.459e+03, MSE(e): 1.037e-04, MSE(pi1): 1.378e-02, MSE(pi2): 5.983e-05, MSE(pi3): 7.945e-03\n",
      "Epoch 27600, Train loss: 2.194e+03, Test loss: 4.041e+03, MSE(e): 9.787e-05, MSE(pi1): 4.177e-02, MSE(pi2): 5.750e-05, MSE(pi3): 7.978e-03\n",
      "Epoch 27700, Train loss: 2.004e+03, Test loss: 3.598e+03, MSE(e): 9.352e-05, MSE(pi1): 2.734e-02, MSE(pi2): 5.567e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 27800, Train loss: 2.312e+03, Test loss: 3.515e+03, MSE(e): 1.339e-04, MSE(pi1): 1.763e-02, MSE(pi2): 7.210e-05, MSE(pi3): 7.964e-03\n",
      "Epoch 27900, Train loss: 2.151e+03, Test loss: 3.833e+03, MSE(e): 9.506e-05, MSE(pi1): 3.999e-02, MSE(pi2): 5.587e-05, MSE(pi3): 8.003e-03\n",
      "Epoch 28000, Train loss: 2.469e+03, Test loss: 3.606e+03, MSE(e): 1.473e-04, MSE(pi1): 2.042e-02, MSE(pi2): 7.799e-05, MSE(pi3): 7.914e-03\n",
      "Epoch 28100, Train loss: 2.576e+03, Test loss: 5.060e+03, MSE(e): 1.130e-04, MSE(pi1): 6.396e-02, MSE(pi2): 6.328e-05, MSE(pi3): 8.058e-03\n",
      "Epoch 28200, Train loss: 2.441e+03, Test loss: 4.203e+03, MSE(e): 1.169e-04, MSE(pi1): 4.707e-02, MSE(pi2): 6.391e-05, MSE(pi3): 8.011e-03\n",
      "Epoch 28300, Train loss: 3.166e+03, Test loss: 6.116e+03, MSE(e): 1.922e-04, MSE(pi1): 4.427e-02, MSE(pi2): 9.690e-05, MSE(pi3): 8.012e-03\n",
      "Epoch 28400, Train loss: 2.103e+03, Test loss: 3.822e+03, MSE(e): 9.142e-05, MSE(pi1): 3.922e-02, MSE(pi2): 5.279e-05, MSE(pi3): 7.966e-03\n",
      "Epoch 28500, Train loss: 5.286e+03, Test loss: 1.020e+04, MSE(e): 3.954e-04, MSE(pi1): 5.175e-02, MSE(pi2): 1.867e-04, MSE(pi3): 8.142e-03\n",
      "Epoch 28600, Train loss: 1.965e+03, Test loss: 3.602e+03, MSE(e): 9.022e-05, MSE(pi1): 2.692e-02, MSE(pi2): 5.362e-05, MSE(pi3): 7.937e-03\n",
      "Epoch 28700, Train loss: 2.025e+03, Test loss: 3.500e+03, MSE(e): 9.950e-05, MSE(pi1): 2.356e-02, MSE(pi2): 5.756e-05, MSE(pi3): 7.947e-03\n",
      "Epoch 28800, Train loss: 2.045e+03, Test loss: 3.379e+03, MSE(e): 1.123e-04, MSE(pi1): 1.279e-02, MSE(pi2): 6.298e-05, MSE(pi3): 7.934e-03\n",
      "Epoch 28900, Train loss: 4.541e+03, Test loss: 1.173e+04, MSE(e): 3.580e-04, MSE(pi1): 1.626e-02, MSE(pi2): 1.712e-04, MSE(pi3): 7.983e-03\n",
      "Epoch 29000, Train loss: 1.784e+03, Test loss: 3.325e+03, MSE(e): 8.250e-05, MSE(pi1): 1.652e-02, MSE(pi2): 4.974e-05, MSE(pi3): 7.938e-03\n",
      "Epoch 29100, Train loss: 1.836e+03, Test loss: 3.345e+03, MSE(e): 8.307e-05, MSE(pi1): 2.100e-02, MSE(pi2): 4.944e-05, MSE(pi3): 7.955e-03\n",
      "Epoch 29200, Train loss: 3.395e+03, Test loss: 4.642e+03, MSE(e): 2.324e-04, MSE(pi1): 2.747e-02, MSE(pi2): 1.132e-04, MSE(pi3): 7.959e-03\n",
      "Epoch 29300, Train loss: 2.200e+03, Test loss: 3.920e+03, MSE(e): 9.279e-05, MSE(pi1): 4.739e-02, MSE(pi2): 5.306e-05, MSE(pi3): 7.981e-03\n",
      "Epoch 29400, Train loss: 2.168e+03, Test loss: 3.932e+03, MSE(e): 1.029e-04, MSE(pi1): 3.400e-02, MSE(pi2): 5.853e-05, MSE(pi3): 7.988e-03\n",
      "Epoch 29500, Train loss: 3.264e+03, Test loss: 3.626e+03, MSE(e): 2.186e-04, MSE(pi1): 2.780e-02, MSE(pi2): 1.091e-04, MSE(pi3): 8.001e-03\n",
      "Epoch 29600, Train loss: 1.860e+03, Test loss: 3.633e+03, MSE(e): 8.808e-05, MSE(pi1): 1.859e-02, MSE(pi2): 5.304e-05, MSE(pi3): 7.937e-03\n",
      "Epoch 29700, Train loss: 2.046e+03, Test loss: 3.598e+03, MSE(e): 1.050e-04, MSE(pi1): 1.999e-02, MSE(pi2): 5.855e-05, MSE(pi3): 7.968e-03\n",
      "Epoch 29800, Train loss: 3.729e+03, Test loss: 8.528e+03, MSE(e): 2.061e-04, MSE(pi1): 8.543e-02, MSE(pi2): 9.978e-05, MSE(pi3): 8.132e-03\n",
      "Epoch 29900, Train loss: 2.434e+03, Test loss: 4.587e+03, MSE(e): 9.468e-05, MSE(pi1): 6.817e-02, MSE(pi2): 5.338e-05, MSE(pi3): 8.058e-03\n",
      "Epoch 30000, Train loss: 1.985e+03, Test loss: 3.593e+03, MSE(e): 8.556e-05, MSE(pi1): 3.313e-02, MSE(pi2): 5.015e-05, MSE(pi3): 7.978e-03\n",
      "Epoch 30100, Train loss: 2.282e+03, Test loss: 4.139e+03, MSE(e): 1.302e-04, MSE(pi1): 1.877e-02, MSE(pi2): 6.877e-05, MSE(pi3): 7.927e-03\n",
      "Epoch 30200, Train loss: 2.259e+03, Test loss: 4.034e+03, MSE(e): 9.083e-05, MSE(pi1): 5.487e-02, MSE(pi2): 5.321e-05, MSE(pi3): 8.022e-03\n",
      "Epoch 30300, Train loss: 3.069e+03, Test loss: 3.535e+03, MSE(e): 2.088e-04, MSE(pi1): 1.862e-02, MSE(pi2): 1.044e-04, MSE(pi3): 7.945e-03\n",
      "Epoch 30400, Train loss: 2.016e+03, Test loss: 3.529e+03, MSE(e): 9.002e-05, MSE(pi1): 3.178e-02, MSE(pi2): 5.259e-05, MSE(pi3): 7.979e-03\n",
      "Epoch 30500, Train loss: 2.232e+03, Test loss: 3.917e+03, MSE(e): 1.166e-04, MSE(pi1): 2.691e-02, MSE(pi2): 6.411e-05, MSE(pi3): 7.969e-03\n",
      "Epoch 30600, Train loss: 4.934e+03, Test loss: 3.668e+03, MSE(e): 3.850e-04, MSE(pi1): 2.749e-02, MSE(pi2): 1.827e-04, MSE(pi3): 8.092e-03\n",
      "Epoch 30700, Train loss: 2.295e+03, Test loss: 3.693e+03, MSE(e): 1.142e-04, MSE(pi1): 3.533e-02, MSE(pi2): 6.145e-05, MSE(pi3): 7.990e-03\n",
      "Epoch 30800, Train loss: 2.800e+03, Test loss: 6.344e+03, MSE(e): 1.596e-04, MSE(pi1): 4.061e-02, MSE(pi2): 8.263e-05, MSE(pi3): 7.976e-03\n",
      "Epoch 30900, Train loss: 1.771e+03, Test loss: 3.217e+03, MSE(e): 8.274e-05, MSE(pi1): 1.503e-02, MSE(pi2): 4.955e-05, MSE(pi3): 7.933e-03\n",
      "Epoch 31000, Train loss: 2.184e+03, Test loss: 3.728e+03, MSE(e): 1.085e-04, MSE(pi1): 3.011e-02, MSE(pi2): 5.822e-05, MSE(pi3): 7.978e-03\n",
      "Epoch 31100, Train loss: 2.413e+03, Test loss: 4.631e+03, MSE(e): 8.992e-05, MSE(pi1): 7.098e-02, MSE(pi2): 5.024e-05, MSE(pi3): 8.036e-03\n",
      "Epoch 31200, Train loss: 1.987e+03, Test loss: 3.475e+03, MSE(e): 8.572e-05, MSE(pi1): 3.334e-02, MSE(pi2): 4.955e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 31300, Train loss: 2.455e+03, Test loss: 3.549e+03, MSE(e): 1.339e-04, MSE(pi1): 3.205e-02, MSE(pi2): 7.094e-05, MSE(pi3): 7.958e-03\n",
      "Epoch 31400, Train loss: 3.576e+03, Test loss: 8.174e+03, MSE(e): 2.170e-04, MSE(pi1): 5.997e-02, MSE(pi2): 1.086e-04, MSE(pi3): 8.062e-03\n",
      "Epoch 31500, Train loss: 4.524e+03, Test loss: 5.306e+03, MSE(e): 3.538e-04, MSE(pi1): 1.856e-02, MSE(pi2): 1.664e-04, MSE(pi3): 8.003e-03\n",
      "Epoch 31600, Train loss: 2.064e+03, Test loss: 3.332e+03, MSE(e): 9.997e-05, MSE(pi1): 2.704e-02, MSE(pi2): 5.559e-05, MSE(pi3): 7.941e-03\n",
      "Epoch 31700, Train loss: 2.272e+03, Test loss: 3.961e+03, MSE(e): 1.216e-04, MSE(pi1): 2.582e-02, MSE(pi2): 6.516e-05, MSE(pi3): 7.973e-03\n",
      "Epoch 31800, Train loss: 2.034e+03, Test loss: 3.768e+03, MSE(e): 8.543e-05, MSE(pi1): 3.818e-02, MSE(pi2): 5.012e-05, MSE(pi3): 7.982e-03\n",
      "Epoch 31900, Train loss: 1.981e+03, Test loss: 3.454e+03, MSE(e): 8.022e-05, MSE(pi1): 3.779e-02, MSE(pi2): 4.684e-05, MSE(pi3): 8.008e-03\n",
      "Epoch 32000, Train loss: 2.215e+03, Test loss: 4.971e+03, MSE(e): 1.081e-04, MSE(pi1): 3.367e-02, MSE(pi2): 6.000e-05, MSE(pi3): 7.966e-03\n",
      "Epoch 32100, Train loss: 2.448e+03, Test loss: 3.818e+03, MSE(e): 1.162e-04, MSE(pi1): 4.852e-02, MSE(pi2): 6.307e-05, MSE(pi3): 8.010e-03\n",
      "Epoch 32200, Train loss: 1.904e+03, Test loss: 3.504e+03, MSE(e): 9.313e-05, MSE(pi1): 1.787e-02, MSE(pi2): 5.284e-05, MSE(pi3): 7.936e-03\n",
      "Epoch 32300, Train loss: 3.675e+03, Test loss: 9.074e+03, MSE(e): 2.368e-04, MSE(pi1): 5.024e-02, MSE(pi2): 1.190e-04, MSE(pi3): 8.044e-03\n",
      "Epoch 32400, Train loss: 2.447e+03, Test loss: 3.597e+03, MSE(e): 1.233e-04, MSE(pi1): 4.163e-02, MSE(pi2): 6.561e-05, MSE(pi3): 7.972e-03\n",
      "Epoch 32500, Train loss: 2.504e+03, Test loss: 6.214e+03, MSE(e): 1.417e-04, MSE(pi1): 2.913e-02, MSE(pi2): 7.509e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 32600, Train loss: 2.456e+03, Test loss: 4.553e+03, MSE(e): 1.013e-04, MSE(pi1): 6.408e-02, MSE(pi2): 5.302e-05, MSE(pi3): 8.023e-03\n",
      "Epoch 32700, Train loss: 2.486e+03, Test loss: 4.463e+03, MSE(e): 1.524e-04, MSE(pi1): 1.633e-02, MSE(pi2): 7.812e-05, MSE(pi3): 7.987e-03\n",
      "Epoch 32800, Train loss: 1.983e+03, Test loss: 3.766e+03, MSE(e): 7.963e-05, MSE(pi1): 3.888e-02, MSE(pi2): 4.524e-05, MSE(pi3): 7.978e-03\n",
      "Epoch 32900, Train loss: 2.150e+03, Test loss: 3.942e+03, MSE(e): 8.621e-05, MSE(pi1): 4.871e-02, MSE(pi2): 4.820e-05, MSE(pi3): 8.011e-03\n",
      "Epoch 33000, Train loss: 2.893e+03, Test loss: 4.188e+03, MSE(e): 1.872e-04, MSE(pi1): 2.237e-02, MSE(pi2): 9.436e-05, MSE(pi3): 7.968e-03\n",
      "Epoch 33100, Train loss: 1.881e+03, Test loss: 3.500e+03, MSE(e): 7.998e-05, MSE(pi1): 2.852e-02, MSE(pi2): 4.659e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 33200, Train loss: 1.807e+03, Test loss: 3.326e+03, MSE(e): 7.982e-05, MSE(pi1): 2.131e-02, MSE(pi2): 4.683e-05, MSE(pi3): 7.953e-03\n",
      "Epoch 33300, Train loss: 2.207e+03, Test loss: 4.087e+03, MSE(e): 8.528e-05, MSE(pi1): 5.533e-02, MSE(pi2): 4.837e-05, MSE(pi3): 8.013e-03\n",
      "Epoch 33400, Train loss: 2.325e+03, Test loss: 3.162e+03, MSE(e): 1.378e-04, MSE(pi1): 1.547e-02, MSE(pi2): 7.155e-05, MSE(pi3): 7.928e-03\n",
      "Epoch 33500, Train loss: 2.334e+03, Test loss: 5.232e+03, MSE(e): 1.069e-04, MSE(pi1): 4.631e-02, MSE(pi2): 5.842e-05, MSE(pi3): 8.013e-03\n",
      "Epoch 33600, Train loss: 1.880e+03, Test loss: 3.422e+03, MSE(e): 7.665e-05, MSE(pi1): 3.165e-02, MSE(pi2): 4.514e-05, MSE(pi3): 7.967e-03\n",
      "Epoch 33700, Train loss: 1.976e+03, Test loss: 3.653e+03, MSE(e): 8.368e-05, MSE(pi1): 3.416e-02, MSE(pi2): 4.969e-05, MSE(pi3): 7.971e-03\n",
      "Epoch 33800, Train loss: 2.314e+03, Test loss: 4.083e+03, MSE(e): 8.294e-05, MSE(pi1): 6.797e-02, MSE(pi2): 4.879e-05, MSE(pi3): 8.046e-03\n",
      "Epoch 33900, Train loss: 1.975e+03, Test loss: 3.457e+03, MSE(e): 8.303e-05, MSE(pi1): 3.466e-02, MSE(pi2): 4.689e-05, MSE(pi3): 7.981e-03\n",
      "Epoch 34000, Train loss: 4.404e+03, Test loss: 3.737e+03, MSE(e): 3.218e-04, MSE(pi1): 3.866e-02, MSE(pi2): 1.513e-04, MSE(pi3): 7.990e-03\n",
      "Epoch 34100, Train loss: 1.744e+03, Test loss: 3.017e+03, MSE(e): 8.152e-05, MSE(pi1): 1.360e-02, MSE(pi2): 4.719e-05, MSE(pi3): 7.930e-03\n",
      "Epoch 34200, Train loss: 2.338e+03, Test loss: 3.256e+03, MSE(e): 1.330e-04, MSE(pi1): 2.132e-02, MSE(pi2): 6.978e-05, MSE(pi3): 7.952e-03\n",
      "Epoch 34300, Train loss: 2.204e+03, Test loss: 4.034e+03, MSE(e): 7.960e-05, MSE(pi1): 6.047e-02, MSE(pi2): 4.511e-05, MSE(pi3): 8.033e-03\n",
      "Epoch 34400, Train loss: 2.065e+03, Test loss: 3.173e+03, MSE(e): 1.135e-04, MSE(pi1): 1.348e-02, MSE(pi2): 6.045e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 34500, Train loss: 1.827e+03, Test loss: 3.296e+03, MSE(e): 7.560e-05, MSE(pi1): 2.751e-02, MSE(pi2): 4.561e-05, MSE(pi3): 7.958e-03\n",
      "Epoch 34600, Train loss: 2.202e+03, Test loss: 3.961e+03, MSE(e): 1.093e-04, MSE(pi1): 3.107e-02, MSE(pi2): 5.850e-05, MSE(pi3): 7.985e-03\n",
      "Epoch 34700, Train loss: 3.305e+03, Test loss: 7.759e+03, MSE(e): 1.789e-04, MSE(pi1): 7.074e-02, MSE(pi2): 9.082e-05, MSE(pi3): 8.084e-03\n",
      "Epoch 34800, Train loss: 1.683e+03, Test loss: 3.020e+03, MSE(e): 7.577e-05, MSE(pi1): 1.335e-02, MSE(pi2): 4.422e-05, MSE(pi3): 7.920e-03\n",
      "Epoch 34900, Train loss: 1.958e+03, Test loss: 3.684e+03, MSE(e): 7.979e-05, MSE(pi1): 3.634e-02, MSE(pi2): 4.664e-05, MSE(pi3): 7.970e-03\n",
      "Epoch 35000, Train loss: 2.232e+03, Test loss: 4.030e+03, MSE(e): 8.769e-05, MSE(pi1): 5.519e-02, MSE(pi2): 4.842e-05, MSE(pi3): 8.036e-03\n",
      "Epoch 35100, Train loss: 2.237e+03, Test loss: 4.587e+03, MSE(e): 9.449e-05, MSE(pi1): 4.919e-02, MSE(pi2): 5.376e-05, MSE(pi3): 7.997e-03\n",
      "Epoch 35200, Train loss: 1.887e+03, Test loss: 3.322e+03, MSE(e): 8.164e-05, MSE(pi1): 2.759e-02, MSE(pi2): 4.681e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 35300, Train loss: 2.043e+03, Test loss: 3.420e+03, MSE(e): 1.034e-04, MSE(pi1): 2.135e-02, MSE(pi2): 5.676e-05, MSE(pi3): 7.957e-03\n",
      "Epoch 35400, Train loss: 1.890e+03, Test loss: 3.302e+03, MSE(e): 8.693e-05, MSE(pi1): 2.260e-02, MSE(pi2): 4.804e-05, MSE(pi3): 7.943e-03\n",
      "Epoch 35500, Train loss: 1.867e+03, Test loss: 3.439e+03, MSE(e): 8.652e-05, MSE(pi1): 2.063e-02, MSE(pi2): 4.828e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 35600, Train loss: 2.178e+03, Test loss: 3.435e+03, MSE(e): 1.172e-04, MSE(pi1): 2.088e-02, MSE(pi2): 6.189e-05, MSE(pi3): 7.971e-03\n",
      "Epoch 35700, Train loss: 1.856e+03, Test loss: 3.063e+03, MSE(e): 9.041e-05, MSE(pi1): 1.583e-02, MSE(pi2): 5.026e-05, MSE(pi3): 7.932e-03\n",
      "Epoch 35800, Train loss: 2.994e+03, Test loss: 3.337e+03, MSE(e): 1.848e-04, MSE(pi1): 3.445e-02, MSE(pi2): 9.134e-05, MSE(pi3): 8.014e-03\n",
      "Epoch 35900, Train loss: 2.044e+03, Test loss: 3.992e+03, MSE(e): 9.343e-05, MSE(pi1): 3.119e-02, MSE(pi2): 5.525e-05, MSE(pi3): 7.978e-03\n",
      "Epoch 36000, Train loss: 2.046e+03, Test loss: 3.363e+03, MSE(e): 8.845e-05, MSE(pi1): 3.630e-02, MSE(pi2): 4.884e-05, MSE(pi3): 7.985e-03\n",
      "Epoch 36100, Train loss: 1.886e+03, Test loss: 3.403e+03, MSE(e): 8.852e-05, MSE(pi1): 2.064e-02, MSE(pi2): 4.893e-05, MSE(pi3): 7.939e-03\n",
      "Epoch 36200, Train loss: 1.899e+03, Test loss: 3.396e+03, MSE(e): 7.475e-05, MSE(pi1): 3.548e-02, MSE(pi2): 4.395e-05, MSE(pi3): 7.965e-03\n",
      "Epoch 36300, Train loss: 1.933e+03, Test loss: 3.607e+03, MSE(e): 8.469e-05, MSE(pi1): 2.923e-02, MSE(pi2): 4.727e-05, MSE(pi3): 7.942e-03\n",
      "Epoch 36400, Train loss: 2.824e+03, Test loss: 4.486e+03, MSE(e): 1.834e-04, MSE(pi1): 1.923e-02, MSE(pi2): 9.266e-05, MSE(pi3): 7.973e-03\n",
      "Epoch 36500, Train loss: 2.247e+03, Test loss: 4.122e+03, MSE(e): 1.010e-04, MSE(pi1): 4.349e-02, MSE(pi2): 5.367e-05, MSE(pi3): 8.011e-03\n",
      "Epoch 36600, Train loss: 2.191e+03, Test loss: 3.036e+03, MSE(e): 1.227e-04, MSE(pi1): 1.719e-02, MSE(pi2): 6.431e-05, MSE(pi3): 7.920e-03\n",
      "Epoch 36700, Train loss: 1.897e+03, Test loss: 3.391e+03, MSE(e): 7.380e-05, MSE(pi1): 3.609e-02, MSE(pi2): 4.382e-05, MSE(pi3): 7.975e-03\n",
      "Epoch 36800, Train loss: 3.869e+03, Test loss: 4.785e+03, MSE(e): 2.817e-04, MSE(pi1): 2.522e-02, MSE(pi2): 1.332e-04, MSE(pi3): 7.997e-03\n",
      "Epoch 36900, Train loss: 2.477e+03, Test loss: 5.577e+03, MSE(e): 1.321e-04, MSE(pi1): 3.555e-02, MSE(pi2): 7.027e-05, MSE(pi3): 8.003e-03\n",
      "Epoch 37000, Train loss: 4.919e+03, Test loss: 4.425e+03, MSE(e): 3.565e-04, MSE(pi1): 5.437e-02, MSE(pi2): 1.666e-04, MSE(pi3): 8.109e-03\n",
      "Epoch 37100, Train loss: 1.936e+03, Test loss: 3.317e+03, MSE(e): 7.253e-05, MSE(pi1): 4.122e-02, MSE(pi2): 4.188e-05, MSE(pi3): 7.982e-03\n",
      "Epoch 37200, Train loss: 2.142e+03, Test loss: 4.573e+03, MSE(e): 1.079e-04, MSE(pi1): 2.654e-02, MSE(pi2): 5.718e-05, MSE(pi3): 7.981e-03\n",
      "Epoch 37300, Train loss: 1.995e+03, Test loss: 3.273e+03, MSE(e): 9.875e-05, MSE(pi1): 2.109e-02, MSE(pi2): 5.174e-05, MSE(pi3): 7.964e-03\n",
      "Epoch 37400, Train loss: 4.358e+03, Test loss: 6.302e+03, MSE(e): 3.238e-04, MSE(pi1): 3.185e-02, MSE(pi2): 1.526e-04, MSE(pi3): 8.020e-03\n",
      "Epoch 37500, Train loss: 1.796e+03, Test loss: 3.256e+03, MSE(e): 7.133e-05, MSE(pi1): 2.864e-02, MSE(pi2): 4.243e-05, MSE(pi3): 7.966e-03\n",
      "Epoch 37600, Train loss: 1.676e+03, Test loss: 2.995e+03, MSE(e): 6.891e-05, MSE(pi1): 1.923e-02, MSE(pi2): 4.019e-05, MSE(pi3): 7.943e-03\n",
      "Epoch 37700, Train loss: 1.796e+03, Test loss: 3.235e+03, MSE(e): 7.434e-05, MSE(pi1): 2.575e-02, MSE(pi2): 4.417e-05, MSE(pi3): 7.949e-03\n",
      "Epoch 37800, Train loss: 1.944e+03, Test loss: 3.940e+03, MSE(e): 8.354e-05, MSE(pi1): 3.131e-02, MSE(pi2): 4.789e-05, MSE(pi3): 7.958e-03\n",
      "Epoch 37900, Train loss: 1.713e+03, Test loss: 3.202e+03, MSE(e): 7.081e-05, MSE(pi1): 2.123e-02, MSE(pi2): 4.196e-05, MSE(pi3): 7.930e-03\n",
      "Epoch 38000, Train loss: 1.688e+03, Test loss: 3.098e+03, MSE(e): 6.702e-05, MSE(pi1): 2.239e-02, MSE(pi2): 3.887e-05, MSE(pi3): 7.937e-03\n",
      "Epoch 38100, Train loss: 1.789e+03, Test loss: 3.218e+03, MSE(e): 6.963e-05, MSE(pi1): 2.980e-02, MSE(pi2): 4.084e-05, MSE(pi3): 7.946e-03\n",
      "Epoch 38200, Train loss: 1.596e+03, Test loss: 2.970e+03, MSE(e): 6.854e-05, MSE(pi1): 1.182e-02, MSE(pi2): 4.128e-05, MSE(pi3): 7.923e-03\n",
      "Epoch 38300, Train loss: 4.068e+03, Test loss: 7.538e+03, MSE(e): 2.733e-04, MSE(pi1): 5.260e-02, MSE(pi2): 1.304e-04, MSE(pi3): 8.089e-03\n",
      "Epoch 38400, Train loss: 3.730e+03, Test loss: 9.392e+03, MSE(e): 2.359e-04, MSE(pi1): 5.664e-02, MSE(pi2): 1.141e-04, MSE(pi3): 8.048e-03\n",
      "Epoch 38500, Train loss: 1.671e+03, Test loss: 3.001e+03, MSE(e): 6.635e-05, MSE(pi1): 2.140e-02, MSE(pi2): 3.931e-05, MSE(pi3): 7.938e-03\n",
      "Epoch 38600, Train loss: 1.682e+03, Test loss: 3.275e+03, MSE(e): 6.923e-05, MSE(pi1): 1.967e-02, MSE(pi2): 3.964e-05, MSE(pi3): 7.934e-03\n",
      "Epoch 38700, Train loss: 1.923e+03, Test loss: 3.316e+03, MSE(e): 9.932e-05, MSE(pi1): 1.363e-02, MSE(pi2): 5.358e-05, MSE(pi3): 7.937e-03\n",
      "Epoch 38800, Train loss: 3.147e+03, Test loss: 5.064e+03, MSE(e): 1.383e-04, MSE(pi1): 9.523e-02, MSE(pi2): 6.746e-05, MSE(pi3): 8.123e-03\n",
      "Epoch 38900, Train loss: 2.779e+03, Test loss: 6.059e+03, MSE(e): 1.505e-04, MSE(pi1): 4.733e-02, MSE(pi2): 7.566e-05, MSE(pi3): 8.005e-03\n",
      "Epoch 39000, Train loss: 2.115e+03, Test loss: 3.527e+03, MSE(e): 1.031e-04, MSE(pi1): 2.868e-02, MSE(pi2): 5.354e-05, MSE(pi3): 7.972e-03\n",
      "Epoch 39100, Train loss: 1.850e+03, Test loss: 3.624e+03, MSE(e): 8.387e-05, MSE(pi1): 2.179e-02, MSE(pi2): 4.589e-05, MSE(pi3): 7.933e-03\n",
      "Epoch 39200, Train loss: 2.596e+03, Test loss: 3.013e+03, MSE(e): 1.575e-04, MSE(pi1): 2.281e-02, MSE(pi2): 7.878e-05, MSE(pi3): 7.937e-03\n",
      "Epoch 39300, Train loss: 2.086e+03, Test loss: 3.797e+03, MSE(e): 8.682e-05, MSE(pi1): 4.189e-02, MSE(pi2): 4.764e-05, MSE(pi3): 7.986e-03\n",
      "Epoch 39400, Train loss: 2.053e+03, Test loss: 3.154e+03, MSE(e): 1.118e-04, MSE(pi1): 1.432e-02, MSE(pi2): 5.863e-05, MSE(pi3): 7.915e-03\n",
      "Epoch 39500, Train loss: 1.774e+03, Test loss: 3.161e+03, MSE(e): 6.693e-05, MSE(pi1): 3.094e-02, MSE(pi2): 3.917e-05, MSE(pi3): 7.951e-03\n",
      "Epoch 39600, Train loss: 1.918e+03, Test loss: 3.612e+03, MSE(e): 9.167e-05, MSE(pi1): 2.062e-02, MSE(pi2): 4.966e-05, MSE(pi3): 7.949e-03\n",
      "Epoch 39700, Train loss: 4.876e+03, Test loss: 8.465e+03, MSE(e): 3.305e-04, MSE(pi1): 7.560e-02, MSE(pi2): 1.555e-04, MSE(pi3): 8.150e-03\n",
      "Epoch 39800, Train loss: 2.033e+03, Test loss: 3.283e+03, MSE(e): 1.066e-04, MSE(pi1): 1.709e-02, MSE(pi2): 5.633e-05, MSE(pi3): 7.958e-03\n",
      "Epoch 39900, Train loss: 1.729e+03, Test loss: 3.244e+03, MSE(e): 6.450e-05, MSE(pi1): 2.880e-02, MSE(pi2): 3.744e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 40000, Train loss: 2.422e+03, Test loss: 4.534e+03, MSE(e): 1.346e-04, MSE(pi1): 2.771e-02, MSE(pi2): 6.724e-05, MSE(pi3): 7.989e-03\n",
      "Epoch 40100, Train loss: 1.775e+03, Test loss: 3.251e+03, MSE(e): 6.368e-05, MSE(pi1): 3.422e-02, MSE(pi2): 3.641e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 40200, Train loss: 1.565e+03, Test loss: 2.995e+03, MSE(e): 6.272e-05, MSE(pi1): 1.467e-02, MSE(pi2): 3.707e-05, MSE(pi3): 7.916e-03\n",
      "Epoch 40300, Train loss: 1.692e+03, Test loss: 3.040e+03, MSE(e): 6.671e-05, MSE(pi1): 2.313e-02, MSE(pi2): 3.805e-05, MSE(pi3): 7.937e-03\n",
      "Epoch 40400, Train loss: 1.954e+03, Test loss: 3.406e+03, MSE(e): 8.567e-05, MSE(pi1): 3.008e-02, MSE(pi2): 4.712e-05, MSE(pi3): 7.968e-03\n",
      "Epoch 40500, Train loss: 3.662e+03, Test loss: 3.614e+03, MSE(e): 2.388e-04, MSE(pi1): 4.660e-02, MSE(pi2): 1.157e-04, MSE(pi3): 8.078e-03\n",
      "Epoch 40600, Train loss: 1.887e+03, Test loss: 3.199e+03, MSE(e): 6.618e-05, MSE(pi1): 4.269e-02, MSE(pi2): 3.712e-05, MSE(pi3): 7.987e-03\n",
      "Epoch 40700, Train loss: 1.858e+03, Test loss: 3.317e+03, MSE(e): 6.687e-05, MSE(pi1): 3.925e-02, MSE(pi2): 3.850e-05, MSE(pi3): 7.969e-03\n",
      "Epoch 40800, Train loss: 1.740e+03, Test loss: 3.211e+03, MSE(e): 6.420e-05, MSE(pi1): 3.012e-02, MSE(pi2): 3.778e-05, MSE(pi3): 7.969e-03\n",
      "Epoch 40900, Train loss: 1.737e+03, Test loss: 3.007e+03, MSE(e): 7.271e-05, MSE(pi1): 2.149e-02, MSE(pi2): 4.171e-05, MSE(pi3): 7.953e-03\n",
      "Epoch 41000, Train loss: 2.168e+03, Test loss: 3.460e+03, MSE(e): 9.811e-05, MSE(pi1): 3.873e-02, MSE(pi2): 5.144e-05, MSE(pi3): 7.997e-03\n",
      "Epoch 41100, Train loss: 2.364e+03, Test loss: 3.628e+03, MSE(e): 8.695e-05, MSE(pi1): 6.911e-02, MSE(pi2): 4.669e-05, MSE(pi3): 8.036e-03\n",
      "Epoch 41200, Train loss: 1.819e+03, Test loss: 3.487e+03, MSE(e): 6.796e-05, MSE(pi1): 3.430e-02, MSE(pi2): 3.849e-05, MSE(pi3): 7.963e-03\n",
      "Epoch 41300, Train loss: 1.702e+03, Test loss: 3.107e+03, MSE(e): 6.691e-05, MSE(pi1): 2.381e-02, MSE(pi2): 3.938e-05, MSE(pi3): 7.945e-03\n",
      "Epoch 41400, Train loss: 5.014e+03, Test loss: 5.992e+03, MSE(e): 3.588e-04, MSE(pi1): 6.129e-02, MSE(pi2): 1.709e-04, MSE(pi3): 8.130e-03\n",
      "Epoch 41500, Train loss: 2.166e+03, Test loss: 3.883e+03, MSE(e): 7.165e-05, MSE(pi1): 6.460e-02, MSE(pi2): 4.158e-05, MSE(pi3): 8.030e-03\n",
      "Epoch 41600, Train loss: 2.248e+03, Test loss: 4.028e+03, MSE(e): 8.649e-05, MSE(pi1): 5.806e-02, MSE(pi2): 4.678e-05, MSE(pi3): 8.023e-03\n",
      "Epoch 41700, Train loss: 1.694e+03, Test loss: 3.112e+03, MSE(e): 6.643e-05, MSE(pi1): 2.343e-02, MSE(pi2): 3.938e-05, MSE(pi3): 7.950e-03\n",
      "Epoch 41800, Train loss: 1.818e+03, Test loss: 3.281e+03, MSE(e): 6.533e-05, MSE(pi1): 3.679e-02, MSE(pi2): 3.875e-05, MSE(pi3): 7.972e-03\n",
      "Epoch 41900, Train loss: 1.795e+03, Test loss: 3.196e+03, MSE(e): 7.219e-05, MSE(pi1): 2.769e-02, MSE(pi2): 4.116e-05, MSE(pi3): 7.965e-03\n",
      "Epoch 42000, Train loss: 1.827e+03, Test loss: 3.109e+03, MSE(e): 7.535e-05, MSE(pi1): 2.784e-02, MSE(pi2): 4.226e-05, MSE(pi3): 7.947e-03\n",
      "Epoch 42100, Train loss: 2.555e+03, Test loss: 4.671e+03, MSE(e): 9.934e-05, MSE(pi1): 7.570e-02, MSE(pi2): 4.865e-05, MSE(pi3): 8.046e-03\n",
      "Epoch 42200, Train loss: 3.531e+03, Test loss: 8.513e+03, MSE(e): 2.156e-04, MSE(pi1): 5.703e-02, MSE(pi2): 1.048e-04, MSE(pi3): 8.052e-03\n",
      "Epoch 42300, Train loss: 2.591e+03, Test loss: 4.728e+03, MSE(e): 1.278e-04, MSE(pi1): 5.113e-02, MSE(pi2): 6.506e-05, MSE(pi3): 8.016e-03\n",
      "Epoch 42400, Train loss: 3.371e+03, Test loss: 4.863e+03, MSE(e): 2.322e-04, MSE(pi1): 2.506e-02, MSE(pi2): 1.110e-04, MSE(pi3): 7.983e-03\n",
      "Epoch 42500, Train loss: 2.237e+03, Test loss: 3.911e+03, MSE(e): 9.219e-05, MSE(pi1): 5.146e-02, MSE(pi2): 4.874e-05, MSE(pi3): 8.006e-03\n",
      "Epoch 42600, Train loss: 2.116e+03, Test loss: 3.707e+03, MSE(e): 8.361e-05, MSE(pi1): 4.803e-02, MSE(pi2): 4.590e-05, MSE(pi3): 7.997e-03\n",
      "Epoch 42700, Train loss: 3.550e+03, Test loss: 7.888e+03, MSE(e): 2.005e-04, MSE(pi1): 7.367e-02, MSE(pi2): 9.787e-05, MSE(pi3): 8.087e-03\n",
      "Epoch 42800, Train loss: 1.592e+03, Test loss: 2.835e+03, MSE(e): 6.784e-05, MSE(pi1): 1.208e-02, MSE(pi2): 4.018e-05, MSE(pi3): 7.926e-03\n",
      "Epoch 42900, Train loss: 3.636e+03, Test loss: 7.647e+03, MSE(e): 2.436e-04, MSE(pi1): 3.951e-02, MSE(pi2): 1.164e-04, MSE(pi3): 8.048e-03\n",
      "Epoch 43000, Train loss: 2.018e+03, Test loss: 3.227e+03, MSE(e): 9.060e-05, MSE(pi1): 3.153e-02, MSE(pi2): 4.847e-05, MSE(pi3): 7.969e-03\n",
      "Epoch 43100, Train loss: 5.344e+03, Test loss: 4.625e+03, MSE(e): 4.300e-04, MSE(pi1): 2.363e-02, MSE(pi2): 2.010e-04, MSE(pi3): 8.068e-03\n",
      "Epoch 43200, Train loss: 3.286e+03, Test loss: 3.640e+03, MSE(e): 1.930e-04, MSE(pi1): 5.476e-02, MSE(pi2): 9.640e-05, MSE(pi3): 8.081e-03\n",
      "Epoch 43300, Train loss: 1.997e+03, Test loss: 3.827e+03, MSE(e): 9.169e-05, MSE(pi1): 2.815e-02, MSE(pi2): 4.970e-05, MSE(pi3): 7.987e-03\n",
      "Epoch 43400, Train loss: 2.359e+03, Test loss: 4.568e+03, MSE(e): 1.223e-04, MSE(pi1): 3.372e-02, MSE(pi2): 6.191e-05, MSE(pi3): 7.987e-03\n",
      "Epoch 43500, Train loss: 2.730e+03, Test loss: 4.947e+03, MSE(e): 1.701e-04, MSE(pi1): 2.326e-02, MSE(pi2): 8.399e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 43600, Train loss: 2.554e+03, Test loss: 3.742e+03, MSE(e): 1.248e-04, MSE(pi1): 5.068e-02, MSE(pi2): 6.326e-05, MSE(pi3): 7.995e-03\n",
      "Epoch 43700, Train loss: 2.470e+03, Test loss: 4.373e+03, MSE(e): 1.292e-04, MSE(pi1): 3.760e-02, MSE(pi2): 6.500e-05, MSE(pi3): 8.019e-03\n",
      "Epoch 43800, Train loss: 2.433e+03, Test loss: 4.077e+03, MSE(e): 1.215e-04, MSE(pi1): 4.179e-02, MSE(pi2): 6.280e-05, MSE(pi3): 8.001e-03\n",
      "Epoch 43900, Train loss: 1.982e+03, Test loss: 3.676e+03, MSE(e): 8.032e-05, MSE(pi1): 3.810e-02, MSE(pi2): 4.333e-05, MSE(pi3): 7.982e-03\n",
      "Epoch 44000, Train loss: 1.672e+03, Test loss: 3.101e+03, MSE(e): 6.021e-05, MSE(pi1): 2.759e-02, MSE(pi2): 3.499e-05, MSE(pi3): 7.937e-03\n",
      "Epoch 44100, Train loss: 2.930e+03, Test loss: 5.858e+03, MSE(e): 1.496e-04, MSE(pi1): 6.276e-02, MSE(pi2): 7.141e-05, MSE(pi3): 8.062e-03\n",
      "Epoch 44200, Train loss: 2.235e+03, Test loss: 3.660e+03, MSE(e): 9.200e-05, MSE(pi1): 5.117e-02, MSE(pi2): 5.152e-05, MSE(pi3): 8.031e-03\n",
      "Epoch 44300, Train loss: 1.974e+03, Test loss: 3.280e+03, MSE(e): 8.142e-05, MSE(pi1): 3.625e-02, MSE(pi2): 4.428e-05, MSE(pi3): 7.970e-03\n",
      "Epoch 44400, Train loss: 2.407e+03, Test loss: 4.364e+03, MSE(e): 8.579e-05, MSE(pi1): 7.462e-02, MSE(pi2): 4.453e-05, MSE(pi3): 8.028e-03\n",
      "Epoch 44500, Train loss: 1.770e+03, Test loss: 3.129e+03, MSE(e): 6.945e-05, MSE(pi1): 2.785e-02, MSE(pi2): 4.054e-05, MSE(pi3): 7.967e-03\n",
      "Epoch 44600, Train loss: 2.836e+03, Test loss: 4.055e+03, MSE(e): 1.671e-04, MSE(pi1): 3.616e-02, MSE(pi2): 8.348e-05, MSE(pi3): 8.039e-03\n",
      "Epoch 44700, Train loss: 2.946e+03, Test loss: 5.812e+03, MSE(e): 1.460e-04, MSE(pi1): 6.775e-02, MSE(pi2): 7.235e-05, MSE(pi3): 8.092e-03\n",
      "Epoch 44800, Train loss: 2.203e+03, Test loss: 4.053e+03, MSE(e): 1.118e-04, MSE(pi1): 2.866e-02, MSE(pi2): 5.758e-05, MSE(pi3): 7.988e-03\n",
      "Epoch 44900, Train loss: 1.471e+03, Test loss: 2.720e+03, MSE(e): 5.597e-05, MSE(pi1): 1.199e-02, MSE(pi2): 3.357e-05, MSE(pi3): 7.910e-03\n",
      "Epoch 45000, Train loss: 1.754e+03, Test loss: 3.226e+03, MSE(e): 6.213e-05, MSE(pi1): 3.352e-02, MSE(pi2): 3.618e-05, MSE(pi3): 7.971e-03\n",
      "Epoch 45100, Train loss: 1.692e+03, Test loss: 3.013e+03, MSE(e): 7.438e-05, MSE(pi1): 1.535e-02, MSE(pi2): 4.233e-05, MSE(pi3): 7.946e-03\n",
      "Epoch 45200, Train loss: 1.667e+03, Test loss: 3.148e+03, MSE(e): 6.104e-05, MSE(pi1): 2.625e-02, MSE(pi2): 3.513e-05, MSE(pi3): 7.937e-03\n",
      "Epoch 45300, Train loss: 1.538e+03, Test loss: 2.761e+03, MSE(e): 5.976e-05, MSE(pi1): 1.479e-02, MSE(pi2): 3.568e-05, MSE(pi3): 7.928e-03\n",
      "Epoch 45400, Train loss: 2.151e+03, Test loss: 4.569e+03, MSE(e): 7.884e-05, MSE(pi1): 5.613e-02, MSE(pi2): 4.286e-05, MSE(pi3): 8.015e-03\n",
      "Epoch 45500, Train loss: 2.170e+03, Test loss: 4.279e+03, MSE(e): 9.915e-05, MSE(pi1): 3.796e-02, MSE(pi2): 5.480e-05, MSE(pi3): 7.993e-03\n",
      "Epoch 45600, Train loss: 2.388e+03, Test loss: 4.126e+03, MSE(e): 1.149e-04, MSE(pi1): 4.381e-02, MSE(pi2): 6.316e-05, MSE(pi3): 8.017e-03\n",
      "Epoch 45700, Train loss: 1.586e+03, Test loss: 2.837e+03, MSE(e): 5.810e-05, MSE(pi1): 2.106e-02, MSE(pi2): 3.455e-05, MSE(pi3): 7.941e-03\n",
      "Epoch 45800, Train loss: 2.076e+03, Test loss: 3.660e+03, MSE(e): 7.761e-05, MSE(pi1): 5.002e-02, MSE(pi2): 4.244e-05, MSE(pi3): 8.002e-03\n",
      "Epoch 45900, Train loss: 2.742e+03, Test loss: 3.263e+03, MSE(e): 1.608e-04, MSE(pi1): 3.334e-02, MSE(pi2): 7.942e-05, MSE(pi3): 7.999e-03\n",
      "Epoch 46000, Train loss: 1.799e+03, Test loss: 3.130e+03, MSE(e): 6.591e-05, MSE(pi1): 3.445e-02, MSE(pi2): 3.790e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 46100, Train loss: 2.512e+03, Test loss: 4.435e+03, MSE(e): 9.520e-05, MSE(pi1): 7.544e-02, MSE(pi2): 4.735e-05, MSE(pi3): 8.055e-03\n",
      "Epoch 46200, Train loss: 2.521e+03, Test loss: 6.218e+03, MSE(e): 1.438e-04, MSE(pi1): 2.882e-02, MSE(pi2): 7.267e-05, MSE(pi3): 7.951e-03\n",
      "Epoch 46300, Train loss: 1.856e+03, Test loss: 3.045e+03, MSE(e): 7.998e-05, MSE(pi1): 2.629e-02, MSE(pi2): 4.385e-05, MSE(pi3): 7.935e-03\n",
      "Epoch 46400, Train loss: 2.296e+03, Test loss: 5.730e+03, MSE(e): 1.297e-04, MSE(pi1): 2.034e-02, MSE(pi2): 6.805e-05, MSE(pi3): 7.952e-03\n",
      "Epoch 46500, Train loss: 2.063e+03, Test loss: 3.672e+03, MSE(e): 8.423e-05, MSE(pi1): 4.233e-02, MSE(pi2): 4.515e-05, MSE(pi3): 7.977e-03\n",
      "Epoch 46600, Train loss: 1.565e+03, Test loss: 2.753e+03, MSE(e): 5.720e-05, MSE(pi1): 1.990e-02, MSE(pi2): 3.421e-05, MSE(pi3): 7.935e-03\n",
      "Epoch 46700, Train loss: 1.685e+03, Test loss: 3.043e+03, MSE(e): 6.038e-05, MSE(pi1): 2.850e-02, MSE(pi2): 3.545e-05, MSE(pi3): 7.957e-03\n",
      "Epoch 46800, Train loss: 3.020e+03, Test loss: 3.440e+03, MSE(e): 1.924e-04, MSE(pi1): 2.945e-02, MSE(pi2): 9.576e-05, MSE(pi3): 8.019e-03\n",
      "Epoch 46900, Train loss: 1.648e+03, Test loss: 2.871e+03, MSE(e): 6.877e-05, MSE(pi1): 1.680e-02, MSE(pi2): 3.893e-05, MSE(pi3): 7.927e-03\n",
      "Epoch 47000, Train loss: 2.181e+03, Test loss: 3.960e+03, MSE(e): 6.328e-05, MSE(pi1): 7.439e-02, MSE(pi2): 3.463e-05, MSE(pi3): 8.045e-03\n",
      "Epoch 47100, Train loss: 1.968e+03, Test loss: 4.279e+03, MSE(e): 8.656e-05, MSE(pi1): 3.079e-02, MSE(pi2): 4.679e-05, MSE(pi3): 7.942e-03\n",
      "Epoch 47200, Train loss: 3.307e+03, Test loss: 6.144e+03, MSE(e): 1.973e-04, MSE(pi1): 5.302e-02, MSE(pi2): 9.259e-05, MSE(pi3): 8.036e-03\n",
      "Epoch 47300, Train loss: 1.502e+03, Test loss: 2.673e+03, MSE(e): 5.688e-05, MSE(pi1): 1.414e-02, MSE(pi2): 3.409e-05, MSE(pi3): 7.915e-03\n",
      "Epoch 47400, Train loss: 1.767e+03, Test loss: 3.142e+03, MSE(e): 6.540e-05, MSE(pi1): 3.177e-02, MSE(pi2): 3.714e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 47500, Train loss: 1.940e+03, Test loss: 4.194e+03, MSE(e): 9.622e-05, MSE(pi1): 1.834e-02, MSE(pi2): 5.538e-05, MSE(pi3): 7.941e-03\n",
      "Epoch 47600, Train loss: 1.599e+03, Test loss: 2.807e+03, MSE(e): 6.113e-05, MSE(pi1): 1.931e-02, MSE(pi2): 3.562e-05, MSE(pi3): 7.941e-03\n",
      "Epoch 47700, Train loss: 1.807e+03, Test loss: 3.142e+03, MSE(e): 5.910e-05, MSE(pi1): 4.173e-02, MSE(pi2): 3.377e-05, MSE(pi3): 7.986e-03\n",
      "Epoch 47800, Train loss: 2.922e+03, Test loss: 4.050e+03, MSE(e): 1.643e-04, MSE(pi1): 4.812e-02, MSE(pi2): 7.929e-05, MSE(pi3): 7.985e-03\n",
      "Epoch 47900, Train loss: 1.645e+03, Test loss: 3.202e+03, MSE(e): 6.398e-05, MSE(pi1): 2.123e-02, MSE(pi2): 3.697e-05, MSE(pi3): 7.931e-03\n",
      "Epoch 48000, Train loss: 1.894e+03, Test loss: 3.491e+03, MSE(e): 6.817e-05, MSE(pi1): 4.143e-02, MSE(pi2): 3.901e-05, MSE(pi3): 7.979e-03\n",
      "Epoch 48100, Train loss: 1.870e+03, Test loss: 3.187e+03, MSE(e): 6.390e-05, MSE(pi1): 4.320e-02, MSE(pi2): 3.725e-05, MSE(pi3): 7.988e-03\n",
      "Epoch 48200, Train loss: 2.145e+03, Test loss: 3.657e+03, MSE(e): 8.179e-05, MSE(pi1): 5.266e-02, MSE(pi2): 4.343e-05, MSE(pi3): 8.009e-03\n",
      "Epoch 48300, Train loss: 2.024e+03, Test loss: 3.234e+03, MSE(e): 9.064e-05, MSE(pi1): 3.211e-02, MSE(pi2): 4.920e-05, MSE(pi3): 7.968e-03\n",
      "Epoch 48400, Train loss: 1.885e+03, Test loss: 2.788e+03, MSE(e): 9.380e-05, MSE(pi1): 1.552e-02, MSE(pi2): 4.977e-05, MSE(pi3): 7.916e-03\n",
      "Epoch 48500, Train loss: 1.773e+03, Test loss: 3.111e+03, MSE(e): 5.970e-05, MSE(pi1): 3.778e-02, MSE(pi2): 3.418e-05, MSE(pi3): 7.977e-03\n",
      "Epoch 48600, Train loss: 2.986e+03, Test loss: 6.249e+03, MSE(e): 1.904e-04, MSE(pi1): 2.841e-02, MSE(pi2): 9.473e-05, MSE(pi3): 7.977e-03\n",
      "Epoch 48700, Train loss: 1.912e+03, Test loss: 3.310e+03, MSE(e): 6.431e-05, MSE(pi1): 4.714e-02, MSE(pi2): 3.661e-05, MSE(pi3): 7.975e-03\n",
      "Epoch 48800, Train loss: 1.601e+03, Test loss: 2.854e+03, MSE(e): 6.292e-05, MSE(pi1): 1.787e-02, MSE(pi2): 3.649e-05, MSE(pi3): 7.935e-03\n",
      "Epoch 48900, Train loss: 1.696e+03, Test loss: 2.894e+03, MSE(e): 6.598e-05, MSE(pi1): 2.402e-02, MSE(pi2): 3.687e-05, MSE(pi3): 7.963e-03\n",
      "Epoch 49000, Train loss: 1.765e+03, Test loss: 3.066e+03, MSE(e): 5.981e-05, MSE(pi1): 3.697e-02, MSE(pi2): 3.541e-05, MSE(pi3): 7.968e-03\n",
      "Epoch 49100, Train loss: 2.027e+03, Test loss: 3.598e+03, MSE(e): 6.318e-05, MSE(pi1): 5.940e-02, MSE(pi2): 3.556e-05, MSE(pi3): 8.007e-03\n",
      "Epoch 49200, Train loss: 1.635e+03, Test loss: 2.895e+03, MSE(e): 6.347e-05, MSE(pi1): 2.050e-02, MSE(pi2): 3.703e-05, MSE(pi3): 7.953e-03\n",
      "Epoch 49300, Train loss: 1.672e+03, Test loss: 2.762e+03, MSE(e): 5.679e-05, MSE(pi1): 3.093e-02, MSE(pi2): 3.320e-05, MSE(pi3): 7.946e-03\n",
      "Epoch 49400, Train loss: 2.967e+03, Test loss: 6.728e+03, MSE(e): 1.964e-04, MSE(pi1): 2.038e-02, MSE(pi2): 9.508e-05, MSE(pi3): 7.994e-03\n",
      "Epoch 49500, Train loss: 1.528e+03, Test loss: 2.764e+03, MSE(e): 5.543e-05, MSE(pi1): 1.803e-02, MSE(pi2): 3.202e-05, MSE(pi3): 7.932e-03\n",
      "Epoch 49600, Train loss: 2.023e+03, Test loss: 3.416e+03, MSE(e): 7.173e-05, MSE(pi1): 5.053e-02, MSE(pi2): 3.982e-05, MSE(pi3): 8.000e-03\n",
      "Epoch 49700, Train loss: 1.533e+03, Test loss: 2.742e+03, MSE(e): 5.621e-05, MSE(pi1): 1.777e-02, MSE(pi2): 3.365e-05, MSE(pi3): 7.930e-03\n",
      "Epoch 49800, Train loss: 1.775e+03, Test loss: 3.154e+03, MSE(e): 6.105e-05, MSE(pi1): 3.693e-02, MSE(pi2): 3.438e-05, MSE(pi3): 7.953e-03\n",
      "Epoch 49900, Train loss: 1.914e+03, Test loss: 3.191e+03, MSE(e): 8.964e-05, MSE(pi1): 2.206e-02, MSE(pi2): 4.718e-05, MSE(pi3): 7.965e-03\n",
      "Epoch 50000, Train loss: 2.387e+03, Test loss: 3.758e+03, MSE(e): 1.070e-04, MSE(pi1): 5.128e-02, MSE(pi2): 5.543e-05, MSE(pi3): 8.037e-03\n",
      "Epoch 50100, Train loss: 2.101e+03, Test loss: 3.469e+03, MSE(e): 1.062e-04, MSE(pi1): 2.419e-02, MSE(pi2): 5.549e-05, MSE(pi3): 7.969e-03\n",
      "Epoch 50200, Train loss: 1.626e+03, Test loss: 2.912e+03, MSE(e): 5.607e-05, MSE(pi1): 2.696e-02, MSE(pi2): 3.294e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 50300, Train loss: 1.669e+03, Test loss: 2.801e+03, MSE(e): 5.867e-05, MSE(pi1): 2.878e-02, MSE(pi2): 3.363e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 50400, Train loss: 2.006e+03, Test loss: 3.695e+03, MSE(e): 1.024e-04, MSE(pi1): 1.852e-02, MSE(pi2): 5.359e-05, MSE(pi3): 7.965e-03\n",
      "Epoch 50500, Train loss: 1.666e+03, Test loss: 2.666e+03, MSE(e): 6.344e-05, MSE(pi1): 2.374e-02, MSE(pi2): 3.668e-05, MSE(pi3): 7.943e-03\n",
      "Epoch 50600, Train loss: 1.659e+03, Test loss: 2.942e+03, MSE(e): 5.402e-05, MSE(pi1): 3.225e-02, MSE(pi2): 3.102e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 50700, Train loss: 2.438e+03, Test loss: 3.031e+03, MSE(e): 1.263e-04, MSE(pi1): 3.746e-02, MSE(pi2): 6.417e-05, MSE(pi3): 7.996e-03\n",
      "Epoch 50800, Train loss: 1.636e+03, Test loss: 2.735e+03, MSE(e): 6.288e-05, MSE(pi1): 2.137e-02, MSE(pi2): 3.625e-05, MSE(pi3): 7.936e-03\n",
      "Epoch 50900, Train loss: 2.105e+03, Test loss: 3.097e+03, MSE(e): 8.583e-05, MSE(pi1): 4.468e-02, MSE(pi2): 4.561e-05, MSE(pi3): 8.002e-03\n",
      "Epoch 51000, Train loss: 1.549e+03, Test loss: 2.599e+03, MSE(e): 5.836e-05, MSE(pi1): 1.735e-02, MSE(pi2): 3.385e-05, MSE(pi3): 7.923e-03\n",
      "Epoch 51100, Train loss: 1.680e+03, Test loss: 2.594e+03, MSE(e): 7.683e-05, MSE(pi1): 1.214e-02, MSE(pi2): 4.169e-05, MSE(pi3): 7.908e-03\n",
      "Epoch 51200, Train loss: 2.298e+03, Test loss: 3.260e+03, MSE(e): 1.081e-04, MSE(pi1): 4.191e-02, MSE(pi2): 5.562e-05, MSE(pi3): 7.971e-03\n",
      "Epoch 51300, Train loss: 4.024e+03, Test loss: 4.498e+03, MSE(e): 2.918e-04, MSE(pi1): 3.052e-02, MSE(pi2): 1.368e-04, MSE(pi3): 8.001e-03\n",
      "Epoch 51400, Train loss: 1.602e+03, Test loss: 2.821e+03, MSE(e): 5.780e-05, MSE(pi1): 2.308e-02, MSE(pi2): 3.475e-05, MSE(pi3): 7.937e-03\n",
      "Epoch 51500, Train loss: 1.699e+03, Test loss: 2.944e+03, MSE(e): 5.540e-05, MSE(pi1): 3.490e-02, MSE(pi2): 3.213e-05, MSE(pi3): 7.963e-03\n",
      "Epoch 51600, Train loss: 3.590e+03, Test loss: 6.608e+03, MSE(e): 1.987e-04, MSE(pi1): 7.901e-02, MSE(pi2): 9.263e-05, MSE(pi3): 8.122e-03\n",
      "Epoch 51700, Train loss: 2.110e+03, Test loss: 3.345e+03, MSE(e): 9.827e-05, MSE(pi1): 3.310e-02, MSE(pi2): 5.114e-05, MSE(pi3): 7.962e-03\n",
      "Epoch 51800, Train loss: 2.487e+03, Test loss: 5.684e+03, MSE(e): 1.491e-04, MSE(pi1): 2.005e-02, MSE(pi2): 7.522e-05, MSE(pi3): 7.950e-03\n",
      "Epoch 51900, Train loss: 2.031e+03, Test loss: 3.779e+03, MSE(e): 7.404e-05, MSE(pi1): 4.912e-02, MSE(pi2): 4.060e-05, MSE(pi3): 7.999e-03\n",
      "Epoch 52000, Train loss: 2.016e+03, Test loss: 3.781e+03, MSE(e): 6.633e-05, MSE(pi1): 5.527e-02, MSE(pi2): 3.481e-05, MSE(pi3): 7.999e-03\n",
      "Epoch 52100, Train loss: 2.364e+03, Test loss: 3.324e+03, MSE(e): 1.123e-04, MSE(pi1): 4.404e-02, MSE(pi2): 5.614e-05, MSE(pi3): 8.002e-03\n",
      "Epoch 52200, Train loss: 2.090e+03, Test loss: 2.942e+03, MSE(e): 9.242e-05, MSE(pi1): 3.675e-02, MSE(pi2): 4.772e-05, MSE(pi3): 7.983e-03\n",
      "Epoch 52300, Train loss: 2.704e+03, Test loss: 5.080e+03, MSE(e): 1.616e-04, MSE(pi1): 2.893e-02, MSE(pi2): 7.806e-05, MSE(pi3): 7.986e-03\n",
      "Epoch 52400, Train loss: 1.777e+03, Test loss: 3.517e+03, MSE(e): 7.049e-05, MSE(pi1): 2.789e-02, MSE(pi2): 3.888e-05, MSE(pi3): 7.934e-03\n",
      "Epoch 52500, Train loss: 2.172e+03, Test loss: 3.692e+03, MSE(e): 6.836e-05, MSE(pi1): 6.841e-02, MSE(pi2): 3.451e-05, MSE(pi3): 8.046e-03\n",
      "Epoch 52600, Train loss: 1.636e+03, Test loss: 2.677e+03, MSE(e): 5.834e-05, MSE(pi1): 2.573e-02, MSE(pi2): 3.232e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 52700, Train loss: 2.243e+03, Test loss: 4.709e+03, MSE(e): 1.151e-04, MSE(pi1): 2.952e-02, MSE(pi2): 5.567e-05, MSE(pi3): 7.966e-03\n",
      "Epoch 52800, Train loss: 1.819e+03, Test loss: 2.934e+03, MSE(e): 6.955e-05, MSE(pi1): 3.277e-02, MSE(pi2): 3.837e-05, MSE(pi3): 7.959e-03\n",
      "Epoch 52900, Train loss: 1.564e+03, Test loss: 2.920e+03, MSE(e): 5.808e-05, MSE(pi1): 1.909e-02, MSE(pi2): 3.119e-05, MSE(pi3): 7.922e-03\n",
      "Epoch 53000, Train loss: 1.873e+03, Test loss: 2.648e+03, MSE(e): 9.123e-05, MSE(pi1): 1.696e-02, MSE(pi2): 4.712e-05, MSE(pi3): 7.910e-03\n",
      "Epoch 53100, Train loss: 2.298e+03, Test loss: 4.428e+03, MSE(e): 1.100e-04, MSE(pi1): 4.007e-02, MSE(pi2): 5.626e-05, MSE(pi3): 7.974e-03\n",
      "Epoch 53200, Train loss: 1.578e+03, Test loss: 2.743e+03, MSE(e): 5.199e-05, MSE(pi1): 2.637e-02, MSE(pi2): 3.117e-05, MSE(pi3): 7.946e-03\n",
      "Epoch 53300, Train loss: 2.026e+03, Test loss: 3.951e+03, MSE(e): 1.085e-04, MSE(pi1): 1.469e-02, MSE(pi2): 5.363e-05, MSE(pi3): 7.942e-03\n",
      "Epoch 53400, Train loss: 1.806e+03, Test loss: 2.841e+03, MSE(e): 8.340e-05, MSE(pi1): 1.786e-02, MSE(pi2): 4.400e-05, MSE(pi3): 7.932e-03\n",
      "Epoch 53500, Train loss: 2.617e+03, Test loss: 5.776e+03, MSE(e): 1.356e-04, MSE(pi1): 4.589e-02, MSE(pi2): 6.525e-05, MSE(pi3): 8.021e-03\n",
      "Epoch 53600, Train loss: 3.011e+03, Test loss: 6.992e+03, MSE(e): 1.875e-04, MSE(pi1): 3.390e-02, MSE(pi2): 9.177e-05, MSE(pi3): 7.976e-03\n",
      "Epoch 53700, Train loss: 1.623e+03, Test loss: 3.572e+03, MSE(e): 6.971e-05, MSE(pi1): 1.339e-02, MSE(pi2): 3.941e-05, MSE(pi3): 7.916e-03\n",
      "Epoch 53800, Train loss: 1.883e+03, Test loss: 4.035e+03, MSE(e): 8.328e-05, MSE(pi1): 2.552e-02, MSE(pi2): 4.573e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 53900, Train loss: 1.604e+03, Test loss: 2.771e+03, MSE(e): 5.308e-05, MSE(pi1): 2.808e-02, MSE(pi2): 2.907e-05, MSE(pi3): 7.926e-03\n",
      "Epoch 54000, Train loss: 1.504e+03, Test loss: 2.579e+03, MSE(e): 5.057e-05, MSE(pi1): 2.053e-02, MSE(pi2): 3.038e-05, MSE(pi3): 7.927e-03\n",
      "Epoch 54100, Train loss: 1.927e+03, Test loss: 3.277e+03, MSE(e): 6.143e-05, MSE(pi1): 5.134e-02, MSE(pi2): 3.239e-05, MSE(pi3): 7.993e-03\n",
      "Epoch 54200, Train loss: 2.454e+03, Test loss: 6.135e+03, MSE(e): 1.350e-04, MSE(pi1): 3.075e-02, MSE(pi2): 6.856e-05, MSE(pi3): 7.963e-03\n",
      "Epoch 54300, Train loss: 4.008e+03, Test loss: 5.008e+03, MSE(e): 2.668e-04, MSE(pi1): 5.332e-02, MSE(pi2): 1.257e-04, MSE(pi3): 8.075e-03\n",
      "Epoch 54400, Train loss: 3.496e+03, Test loss: 4.998e+03, MSE(e): 2.330e-04, MSE(pi1): 3.631e-02, MSE(pi2): 1.126e-04, MSE(pi3): 8.028e-03\n",
      "Epoch 54500, Train loss: 1.709e+03, Test loss: 2.911e+03, MSE(e): 5.060e-05, MSE(pi1): 4.066e-02, MSE(pi2): 2.757e-05, MSE(pi3): 7.961e-03\n",
      "Epoch 54600, Train loss: 1.675e+03, Test loss: 2.548e+03, MSE(e): 7.494e-05, MSE(pi1): 1.338e-02, MSE(pi2): 4.040e-05, MSE(pi3): 7.921e-03\n",
      "Epoch 54700, Train loss: 1.564e+03, Test loss: 2.648e+03, MSE(e): 5.567e-05, MSE(pi1): 2.133e-02, MSE(pi2): 3.060e-05, MSE(pi3): 7.942e-03\n",
      "Epoch 54800, Train loss: 1.738e+03, Test loss: 3.860e+03, MSE(e): 8.216e-05, MSE(pi1): 1.246e-02, MSE(pi2): 4.596e-05, MSE(pi3): 7.921e-03\n",
      "Epoch 54900, Train loss: 2.478e+03, Test loss: 6.153e+03, MSE(e): 1.428e-04, MSE(pi1): 2.554e-02, MSE(pi2): 7.223e-05, MSE(pi3): 7.947e-03\n",
      "Epoch 55000, Train loss: 1.636e+03, Test loss: 2.958e+03, MSE(e): 4.917e-05, MSE(pi1): 3.484e-02, MSE(pi2): 2.763e-05, MSE(pi3): 7.959e-03\n",
      "Epoch 55100, Train loss: 1.492e+03, Test loss: 2.849e+03, MSE(e): 5.295e-05, MSE(pi1): 1.714e-02, MSE(pi2): 3.039e-05, MSE(pi3): 7.914e-03\n",
      "Epoch 55200, Train loss: 1.551e+03, Test loss: 2.837e+03, MSE(e): 5.369e-05, MSE(pi1): 2.202e-02, MSE(pi2): 3.168e-05, MSE(pi3): 7.938e-03\n",
      "Epoch 55300, Train loss: 2.287e+03, Test loss: 4.021e+03, MSE(e): 5.937e-05, MSE(pi1): 8.865e-02, MSE(pi2): 2.910e-05, MSE(pi3): 8.065e-03\n",
      "Epoch 55400, Train loss: 2.040e+03, Test loss: 2.861e+03, MSE(e): 9.570e-05, MSE(pi1): 2.869e-02, MSE(pi2): 4.869e-05, MSE(pi3): 7.959e-03\n",
      "Epoch 55500, Train loss: 1.447e+03, Test loss: 2.621e+03, MSE(e): 4.809e-05, MSE(pi1): 1.736e-02, MSE(pi2): 2.884e-05, MSE(pi3): 7.922e-03\n",
      "Epoch 55600, Train loss: 1.603e+03, Test loss: 3.296e+03, MSE(e): 6.500e-05, MSE(pi1): 1.602e-02, MSE(pi2): 3.701e-05, MSE(pi3): 7.925e-03\n",
      "Epoch 55700, Train loss: 2.232e+03, Test loss: 4.098e+03, MSE(e): 9.019e-05, MSE(pi1): 5.291e-02, MSE(pi2): 4.738e-05, MSE(pi3): 8.007e-03\n",
      "Epoch 55800, Train loss: 2.021e+03, Test loss: 3.830e+03, MSE(e): 7.979e-05, MSE(pi1): 4.231e-02, MSE(pi2): 4.109e-05, MSE(pi3): 7.997e-03\n",
      "Epoch 55900, Train loss: 2.249e+03, Test loss: 5.337e+03, MSE(e): 1.244e-04, MSE(pi1): 2.104e-02, MSE(pi2): 6.384e-05, MSE(pi3): 7.945e-03\n",
      "Epoch 56000, Train loss: 1.788e+03, Test loss: 3.065e+03, MSE(e): 5.411e-05, MSE(pi1): 4.511e-02, MSE(pi2): 2.889e-05, MSE(pi3): 7.961e-03\n",
      "Epoch 56100, Train loss: 2.864e+03, Test loss: 2.702e+03, MSE(e): 1.927e-04, MSE(pi1): 1.439e-02, MSE(pi2): 9.322e-05, MSE(pi3): 7.931e-03\n",
      "Epoch 56200, Train loss: 3.176e+03, Test loss: 3.030e+03, MSE(e): 2.021e-04, MSE(pi1): 3.509e-02, MSE(pi2): 9.822e-05, MSE(pi3): 8.034e-03\n",
      "Epoch 56300, Train loss: 2.009e+03, Test loss: 3.396e+03, MSE(e): 1.090e-04, MSE(pi1): 1.255e-02, MSE(pi2): 5.353e-05, MSE(pi3): 7.929e-03\n",
      "Epoch 56400, Train loss: 1.603e+03, Test loss: 3.115e+03, MSE(e): 5.995e-05, MSE(pi1): 2.102e-02, MSE(pi2): 3.321e-05, MSE(pi3): 7.931e-03\n",
      "Epoch 56500, Train loss: 1.513e+03, Test loss: 2.797e+03, MSE(e): 4.870e-05, MSE(pi1): 2.339e-02, MSE(pi2): 2.714e-05, MSE(pi3): 7.923e-03\n",
      "Epoch 56600, Train loss: 2.548e+03, Test loss: 3.890e+03, MSE(e): 1.585e-04, MSE(pi1): 1.683e-02, MSE(pi2): 7.670e-05, MSE(pi3): 7.946e-03\n",
      "Epoch 56700, Train loss: 1.545e+03, Test loss: 2.616e+03, MSE(e): 4.341e-05, MSE(pi1): 3.162e-02, MSE(pi2): 2.511e-05, MSE(pi3): 7.951e-03\n",
      "Epoch 56800, Train loss: 1.596e+03, Test loss: 3.119e+03, MSE(e): 5.987e-05, MSE(pi1): 2.039e-02, MSE(pi2): 3.464e-05, MSE(pi3): 7.932e-03\n",
      "Epoch 56900, Train loss: 1.974e+03, Test loss: 3.505e+03, MSE(e): 6.517e-05, MSE(pi1): 5.230e-02, MSE(pi2): 3.635e-05, MSE(pi3): 7.995e-03\n",
      "Epoch 57000, Train loss: 2.094e+03, Test loss: 3.291e+03, MSE(e): 7.556e-05, MSE(pi1): 5.394e-02, MSE(pi2): 3.827e-05, MSE(pi3): 7.995e-03\n",
      "Epoch 57100, Train loss: 2.146e+03, Test loss: 3.939e+03, MSE(e): 5.914e-05, MSE(pi1): 7.512e-02, MSE(pi2): 2.953e-05, MSE(pi3): 8.036e-03\n",
      "Epoch 57200, Train loss: 1.365e+03, Test loss: 2.540e+03, MSE(e): 4.311e-05, MSE(pi1): 1.435e-02, MSE(pi2): 2.502e-05, MSE(pi3): 7.903e-03\n",
      "Epoch 57300, Train loss: 1.590e+03, Test loss: 2.832e+03, MSE(e): 5.802e-05, MSE(pi1): 2.178e-02, MSE(pi2): 3.146e-05, MSE(pi3): 7.922e-03\n",
      "Epoch 57400, Train loss: 1.708e+03, Test loss: 2.609e+03, MSE(e): 6.904e-05, MSE(pi1): 2.232e-02, MSE(pi2): 3.716e-05, MSE(pi3): 7.942e-03\n",
      "Epoch 57500, Train loss: 1.865e+03, Test loss: 3.619e+03, MSE(e): 8.557e-05, MSE(pi1): 2.135e-02, MSE(pi2): 4.368e-05, MSE(pi3): 7.957e-03\n",
      "Epoch 57600, Train loss: 3.156e+03, Test loss: 6.702e+03, MSE(e): 1.885e-04, MSE(pi1): 4.704e-02, MSE(pi2): 9.202e-05, MSE(pi3): 8.012e-03\n",
      "Epoch 57700, Train loss: 1.677e+03, Test loss: 3.196e+03, MSE(e): 6.724e-05, MSE(pi1): 2.106e-02, MSE(pi2): 3.712e-05, MSE(pi3): 7.935e-03\n",
      "Epoch 57800, Train loss: 1.553e+03, Test loss: 2.867e+03, MSE(e): 5.512e-05, MSE(pi1): 2.091e-02, MSE(pi2): 2.956e-05, MSE(pi3): 7.931e-03\n",
      "Epoch 57900, Train loss: 1.804e+03, Test loss: 3.301e+03, MSE(e): 4.721e-05, MSE(pi1): 5.344e-02, MSE(pi2): 2.575e-05, MSE(pi3): 7.978e-03\n",
      "Epoch 58000, Train loss: 3.260e+03, Test loss: 4.893e+03, MSE(e): 2.017e-04, MSE(pi1): 4.405e-02, MSE(pi2): 9.790e-05, MSE(pi3): 8.024e-03\n",
      "Epoch 58100, Train loss: 1.682e+03, Test loss: 3.180e+03, MSE(e): 6.634e-05, MSE(pi1): 2.248e-02, MSE(pi2): 3.400e-05, MSE(pi3): 7.942e-03\n",
      "Epoch 58200, Train loss: 2.477e+03, Test loss: 5.322e+03, MSE(e): 1.455e-04, MSE(pi1): 2.268e-02, MSE(pi2): 7.291e-05, MSE(pi3): 7.952e-03\n",
      "Epoch 58300, Train loss: 2.227e+03, Test loss: 4.614e+03, MSE(e): 1.003e-04, MSE(pi1): 4.256e-02, MSE(pi2): 5.261e-05, MSE(pi3): 7.984e-03\n",
      "Epoch 58400, Train loss: 1.456e+03, Test loss: 2.682e+03, MSE(e): 4.374e-05, MSE(pi1): 2.258e-02, MSE(pi2): 2.500e-05, MSE(pi3): 7.924e-03\n",
      "Epoch 58500, Train loss: 1.507e+03, Test loss: 2.788e+03, MSE(e): 5.555e-05, MSE(pi1): 1.594e-02, MSE(pi2): 3.262e-05, MSE(pi3): 7.917e-03\n",
      "Epoch 58600, Train loss: 1.731e+03, Test loss: 2.945e+03, MSE(e): 4.673e-05, MSE(pi1): 4.657e-02, MSE(pi2): 2.664e-05, MSE(pi3): 7.978e-03\n",
      "Epoch 58700, Train loss: 1.293e+03, Test loss: 2.339e+03, MSE(e): 3.944e-05, MSE(pi1): 1.075e-02, MSE(pi2): 2.312e-05, MSE(pi3): 7.912e-03\n",
      "Epoch 58800, Train loss: 1.794e+03, Test loss: 3.085e+03, MSE(e): 5.465e-05, MSE(pi1): 4.480e-02, MSE(pi2): 3.007e-05, MSE(pi3): 7.992e-03\n",
      "Epoch 58900, Train loss: 1.575e+03, Test loss: 2.799e+03, MSE(e): 5.114e-05, MSE(pi1): 2.700e-02, MSE(pi2): 2.896e-05, MSE(pi3): 7.940e-03\n",
      "Epoch 59000, Train loss: 1.503e+03, Test loss: 2.970e+03, MSE(e): 5.221e-05, MSE(pi1): 1.886e-02, MSE(pi2): 2.944e-05, MSE(pi3): 7.919e-03\n",
      "Epoch 59100, Train loss: 1.815e+03, Test loss: 3.182e+03, MSE(e): 7.891e-05, MSE(pi1): 2.317e-02, MSE(pi2): 3.994e-05, MSE(pi3): 7.943e-03\n",
      "Epoch 59200, Train loss: 1.663e+03, Test loss: 3.042e+03, MSE(e): 5.705e-05, MSE(pi1): 2.976e-02, MSE(pi2): 2.975e-05, MSE(pi3): 7.949e-03\n",
      "Epoch 59300, Train loss: 1.790e+03, Test loss: 2.728e+03, MSE(e): 4.765e-05, MSE(pi1): 5.143e-02, MSE(pi2): 2.792e-05, MSE(pi3): 7.995e-03\n",
      "Epoch 59400, Train loss: 1.572e+03, Test loss: 2.575e+03, MSE(e): 5.499e-05, MSE(pi1): 2.307e-02, MSE(pi2): 2.980e-05, MSE(pi3): 7.915e-03\n",
      "Epoch 59500, Train loss: 1.650e+03, Test loss: 2.806e+03, MSE(e): 5.352e-05, MSE(pi1): 3.194e-02, MSE(pi2): 2.917e-05, MSE(pi3): 7.950e-03\n",
      "Epoch 59600, Train loss: 2.637e+03, Test loss: 4.061e+03, MSE(e): 9.635e-05, MSE(pi1): 8.686e-02, MSE(pi2): 4.571e-05, MSE(pi3): 8.053e-03\n",
      "Epoch 59700, Train loss: 1.594e+03, Test loss: 2.783e+03, MSE(e): 4.920e-05, MSE(pi1): 3.069e-02, MSE(pi2): 2.717e-05, MSE(pi3): 7.955e-03\n",
      "Epoch 59800, Train loss: 1.908e+03, Test loss: 2.560e+03, MSE(e): 8.693e-05, MSE(pi1): 2.452e-02, MSE(pi2): 4.536e-05, MSE(pi3): 7.936e-03\n",
      "Epoch 59900, Train loss: 1.807e+03, Test loss: 3.137e+03, MSE(e): 5.526e-05, MSE(pi1): 4.561e-02, MSE(pi2): 3.251e-05, MSE(pi3): 7.979e-03\n",
      "Epoch 60000, Train loss: 2.265e+03, Test loss: 4.017e+03, MSE(e): 1.206e-04, MSE(pi1): 2.617e-02, MSE(pi2): 5.982e-05, MSE(pi3): 7.972e-03\n",
      "Epoch 60100, Train loss: 3.307e+03, Test loss: 3.721e+03, MSE(e): 1.860e-04, MSE(pi1): 6.429e-02, MSE(pi2): 9.002e-05, MSE(pi3): 8.032e-03\n",
      "Epoch 60200, Train loss: 2.473e+03, Test loss: 2.494e+03, MSE(e): 1.552e-04, MSE(pi1): 1.298e-02, MSE(pi2): 7.508e-05, MSE(pi3): 7.920e-03\n",
      "Epoch 60300, Train loss: 1.450e+03, Test loss: 2.556e+03, MSE(e): 4.318e-05, MSE(pi1): 2.262e-02, MSE(pi2): 2.483e-05, MSE(pi3): 7.919e-03\n",
      "Epoch 60400, Train loss: 1.771e+03, Test loss: 3.475e+03, MSE(e): 6.672e-05, MSE(pi1): 3.110e-02, MSE(pi2): 3.556e-05, MSE(pi3): 7.931e-03\n",
      "Epoch 60500, Train loss: 1.505e+03, Test loss: 2.538e+03, MSE(e): 4.546e-05, MSE(pi1): 2.568e-02, MSE(pi2): 2.631e-05, MSE(pi3): 7.941e-03\n",
      "Epoch 60600, Train loss: 1.406e+03, Test loss: 2.711e+03, MSE(e): 4.827e-05, MSE(pi1): 1.321e-02, MSE(pi2): 2.831e-05, MSE(pi3): 7.911e-03\n",
      "Epoch 60700, Train loss: 3.399e+03, Test loss: 3.409e+03, MSE(e): 2.104e-04, MSE(pi1): 4.867e-02, MSE(pi2): 1.010e-04, MSE(pi3): 8.076e-03\n",
      "Epoch 60800, Train loss: 1.924e+03, Test loss: 3.033e+03, MSE(e): 7.871e-05, MSE(pi1): 3.392e-02, MSE(pi2): 3.993e-05, MSE(pi3): 7.980e-03\n",
      "Epoch 60900, Train loss: 1.507e+03, Test loss: 2.821e+03, MSE(e): 5.623e-05, MSE(pi1): 1.520e-02, MSE(pi2): 3.032e-05, MSE(pi3): 7.925e-03\n",
      "Epoch 61000, Train loss: 1.790e+03, Test loss: 3.504e+03, MSE(e): 5.402e-05, MSE(pi1): 4.517e-02, MSE(pi2): 2.871e-05, MSE(pi3): 7.976e-03\n",
      "Epoch 61100, Train loss: 1.599e+03, Test loss: 3.039e+03, MSE(e): 5.300e-05, MSE(pi1): 2.743e-02, MSE(pi2): 3.109e-05, MSE(pi3): 7.950e-03\n",
      "Epoch 61200, Train loss: 2.856e+03, Test loss: 4.266e+03, MSE(e): 1.681e-04, MSE(pi1): 3.764e-02, MSE(pi2): 7.963e-05, MSE(pi3): 7.979e-03\n",
      "Epoch 61300, Train loss: 1.987e+03, Test loss: 3.379e+03, MSE(e): 7.529e-05, MSE(pi1): 4.374e-02, MSE(pi2): 3.831e-05, MSE(pi3): 7.971e-03\n",
      "Epoch 61400, Train loss: 1.523e+03, Test loss: 2.821e+03, MSE(e): 4.767e-05, MSE(pi1): 2.523e-02, MSE(pi2): 2.730e-05, MSE(pi3): 7.939e-03\n",
      "Epoch 61500, Train loss: 1.344e+03, Test loss: 2.345e+03, MSE(e): 4.332e-05, MSE(pi1): 1.205e-02, MSE(pi2): 2.481e-05, MSE(pi3): 7.908e-03\n",
      "Epoch 61600, Train loss: 1.511e+03, Test loss: 2.434e+03, MSE(e): 5.176e-05, MSE(pi1): 2.014e-02, MSE(pi2): 2.919e-05, MSE(pi3): 7.922e-03\n",
      "Epoch 61700, Train loss: 1.720e+03, Test loss: 3.477e+03, MSE(e): 7.831e-05, MSE(pi1): 1.424e-02, MSE(pi2): 4.406e-05, MSE(pi3): 7.940e-03\n",
      "Epoch 61800, Train loss: 2.023e+03, Test loss: 2.695e+03, MSE(e): 9.399e-05, MSE(pi1): 2.852e-02, MSE(pi2): 4.794e-05, MSE(pi3): 7.982e-03\n",
      "Epoch 61900, Train loss: 1.494e+03, Test loss: 2.969e+03, MSE(e): 5.325e-05, MSE(pi1): 1.679e-02, MSE(pi2): 3.112e-05, MSE(pi3): 7.934e-03\n",
      "Epoch 62000, Train loss: 2.055e+03, Test loss: 4.554e+03, MSE(e): 9.201e-05, MSE(pi1): 3.381e-02, MSE(pi2): 4.790e-05, MSE(pi3): 7.962e-03\n",
      "Epoch 62100, Train loss: 2.176e+03, Test loss: 4.629e+03, MSE(e): 8.742e-05, MSE(pi1): 4.992e-02, MSE(pi2): 4.849e-05, MSE(pi3): 8.027e-03\n",
      "Epoch 62200, Train loss: 1.692e+03, Test loss: 3.613e+03, MSE(e): 7.200e-05, MSE(pi1): 1.785e-02, MSE(pi2): 3.899e-05, MSE(pi3): 7.934e-03\n",
      "Epoch 62300, Train loss: 2.258e+03, Test loss: 4.439e+03, MSE(e): 8.452e-05, MSE(pi1): 6.092e-02, MSE(pi2): 4.582e-05, MSE(pi3): 8.038e-03\n",
      "Epoch 62400, Train loss: 1.520e+03, Test loss: 2.503e+03, MSE(e): 5.442e-05, MSE(pi1): 1.840e-02, MSE(pi2): 2.993e-05, MSE(pi3): 7.922e-03\n",
      "Epoch 62500, Train loss: 1.778e+03, Test loss: 2.534e+03, MSE(e): 7.939e-05, MSE(pi1): 1.896e-02, MSE(pi2): 4.189e-05, MSE(pi3): 7.944e-03\n",
      "Epoch 62600, Train loss: 1.850e+03, Test loss: 2.734e+03, MSE(e): 7.723e-05, MSE(pi1): 2.848e-02, MSE(pi2): 3.979e-05, MSE(pi3): 7.934e-03\n",
      "Epoch 62700, Train loss: 1.828e+03, Test loss: 2.815e+03, MSE(e): 5.857e-05, MSE(pi1): 4.448e-02, MSE(pi2): 3.196e-05, MSE(pi3): 7.974e-03\n",
      "Epoch 62800, Train loss: 1.698e+03, Test loss: 3.548e+03, MSE(e): 7.014e-05, MSE(pi1): 2.035e-02, MSE(pi2): 3.762e-05, MSE(pi3): 7.927e-03\n",
      "Epoch 62900, Train loss: 1.321e+03, Test loss: 2.464e+03, MSE(e): 3.572e-05, MSE(pi1): 1.722e-02, MSE(pi2): 2.080e-05, MSE(pi3): 7.912e-03\n",
      "Epoch 63000, Train loss: 1.550e+03, Test loss: 3.227e+03, MSE(e): 5.393e-05, MSE(pi1): 2.179e-02, MSE(pi2): 3.003e-05, MSE(pi3): 7.926e-03\n",
      "Epoch 63100, Train loss: 2.941e+03, Test loss: 4.875e+03, MSE(e): 1.450e-04, MSE(pi1): 6.855e-02, MSE(pi2): 7.288e-05, MSE(pi3): 8.060e-03\n",
      "Epoch 63200, Train loss: 2.463e+03, Test loss: 4.049e+03, MSE(e): 8.075e-05, MSE(pi1): 8.475e-02, MSE(pi2): 3.959e-05, MSE(pi3): 8.084e-03\n",
      "Epoch 63300, Train loss: 2.530e+03, Test loss: 4.329e+03, MSE(e): 1.375e-04, MSE(pi1): 3.546e-02, MSE(pi2): 6.818e-05, MSE(pi3): 8.002e-03\n",
      "Epoch 63400, Train loss: 2.382e+03, Test loss: 5.279e+03, MSE(e): 1.343e-04, MSE(pi1): 2.425e-02, MSE(pi2): 6.779e-05, MSE(pi3): 7.958e-03\n",
      "Epoch 63500, Train loss: 1.700e+03, Test loss: 3.674e+03, MSE(e): 7.262e-05, MSE(pi1): 1.801e-02, MSE(pi2): 3.987e-05, MSE(pi3): 7.939e-03\n",
      "Epoch 63600, Train loss: 1.794e+03, Test loss: 3.693e+03, MSE(e): 7.520e-05, MSE(pi1): 2.466e-02, MSE(pi2): 4.237e-05, MSE(pi3): 7.951e-03\n",
      "Epoch 63700, Train loss: 2.216e+03, Test loss: 4.521e+03, MSE(e): 1.169e-04, MSE(pi1): 2.479e-02, MSE(pi2): 5.845e-05, MSE(pi3): 7.992e-03\n",
      "Epoch 63800, Train loss: 3.304e+03, Test loss: 5.094e+03, MSE(e): 2.316e-04, MSE(pi1): 1.897e-02, MSE(pi2): 1.123e-04, MSE(pi3): 7.990e-03\n",
      "Epoch 63900, Train loss: 1.679e+03, Test loss: 2.573e+03, MSE(e): 7.590e-05, MSE(pi1): 1.282e-02, MSE(pi2): 3.996e-05, MSE(pi3): 7.920e-03\n",
      "Epoch 64000, Train loss: 2.030e+03, Test loss: 2.444e+03, MSE(e): 1.052e-04, MSE(pi1): 1.863e-02, MSE(pi2): 5.228e-05, MSE(pi3): 7.922e-03\n",
      "Epoch 64100, Train loss: 3.015e+03, Test loss: 4.701e+03, MSE(e): 1.578e-04, MSE(pi1): 6.299e-02, MSE(pi2): 7.518e-05, MSE(pi3): 8.063e-03\n",
      "Epoch 64200, Train loss: 1.353e+03, Test loss: 2.521e+03, MSE(e): 4.071e-05, MSE(pi1): 1.549e-02, MSE(pi2): 2.324e-05, MSE(pi3): 7.909e-03\n",
      "Epoch 64300, Train loss: 1.954e+03, Test loss: 3.678e+03, MSE(e): 7.855e-05, MSE(pi1): 3.697e-02, MSE(pi2): 3.899e-05, MSE(pi3): 7.984e-03\n",
      "Epoch 64400, Train loss: 3.124e+03, Test loss: 3.224e+03, MSE(e): 2.021e-04, MSE(pi1): 2.999e-02, MSE(pi2): 9.978e-05, MSE(pi3): 8.034e-03\n",
      "Epoch 64500, Train loss: 1.757e+03, Test loss: 2.893e+03, MSE(e): 7.059e-05, MSE(pi1): 2.557e-02, MSE(pi2): 3.962e-05, MSE(pi3): 7.957e-03\n",
      "Epoch 64600, Train loss: 1.379e+03, Test loss: 2.581e+03, MSE(e): 4.134e-05, MSE(pi1): 1.747e-02, MSE(pi2): 2.402e-05, MSE(pi3): 7.909e-03\n",
      "Epoch 64700, Train loss: 2.404e+03, Test loss: 4.333e+03, MSE(e): 1.413e-04, MSE(pi1): 1.955e-02, MSE(pi2): 6.984e-05, MSE(pi3): 7.961e-03\n",
      "Epoch 64800, Train loss: 1.549e+03, Test loss: 2.949e+03, MSE(e): 3.911e-05, MSE(pi1): 3.622e-02, MSE(pi2): 2.165e-05, MSE(pi3): 7.951e-03\n",
      "Epoch 64900, Train loss: 2.735e+03, Test loss: 5.011e+03, MSE(e): 1.237e-04, MSE(pi1): 6.916e-02, MSE(pi2): 6.158e-05, MSE(pi3): 8.069e-03\n",
      "Epoch 65000, Train loss: 1.293e+03, Test loss: 2.446e+03, MSE(e): 3.775e-05, MSE(pi1): 1.256e-02, MSE(pi2): 2.214e-05, MSE(pi3): 7.900e-03\n",
      "Epoch 65100, Train loss: 2.991e+03, Test loss: 4.444e+03, MSE(e): 1.660e-04, MSE(pi1): 5.269e-02, MSE(pi2): 7.900e-05, MSE(pi3): 8.038e-03\n",
      "Epoch 65200, Train loss: 1.779e+03, Test loss: 3.876e+03, MSE(e): 6.516e-05, MSE(pi1): 3.325e-02, MSE(pi2): 3.408e-05, MSE(pi3): 7.950e-03\n",
      "Epoch 65300, Train loss: 2.746e+03, Test loss: 5.965e+03, MSE(e): 1.681e-04, MSE(pi1): 2.672e-02, MSE(pi2): 8.313e-05, MSE(pi3): 7.974e-03\n",
      "Epoch 65400, Train loss: 1.468e+03, Test loss: 2.560e+03, MSE(e): 4.612e-05, MSE(pi1): 2.131e-02, MSE(pi2): 2.746e-05, MSE(pi3): 7.938e-03\n",
      "Epoch 65500, Train loss: 1.638e+03, Test loss: 2.918e+03, MSE(e): 4.889e-05, MSE(pi1): 3.539e-02, MSE(pi2): 2.644e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 65600, Train loss: 1.476e+03, Test loss: 2.822e+03, MSE(e): 5.237e-05, MSE(pi1): 1.607e-02, MSE(pi2): 3.038e-05, MSE(pi3): 7.913e-03\n",
      "Epoch 65700, Train loss: 1.941e+03, Test loss: 2.542e+03, MSE(e): 9.234e-05, MSE(pi1): 2.245e-02, MSE(pi2): 4.609e-05, MSE(pi3): 7.934e-03\n",
      "Epoch 65800, Train loss: 4.063e+03, Test loss: 6.062e+03, MSE(e): 2.273e-04, MSE(pi1): 9.721e-02, MSE(pi2): 1.066e-04, MSE(pi3): 8.181e-03\n",
      "Epoch 65900, Train loss: 1.918e+03, Test loss: 2.951e+03, MSE(e): 8.668e-05, MSE(pi1): 2.555e-02, MSE(pi2): 4.431e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 66000, Train loss: 2.352e+03, Test loss: 4.187e+03, MSE(e): 1.216e-04, MSE(pi1): 3.378e-02, MSE(pi2): 5.962e-05, MSE(pi3): 7.976e-03\n",
      "Epoch 66100, Train loss: 1.955e+03, Test loss: 3.151e+03, MSE(e): 7.218e-05, MSE(pi1): 4.339e-02, MSE(pi2): 3.704e-05, MSE(pi3): 7.996e-03\n",
      "Epoch 66200, Train loss: 2.174e+03, Test loss: 3.443e+03, MSE(e): 8.001e-05, MSE(pi1): 5.728e-02, MSE(pi2): 3.897e-05, MSE(pi3): 8.006e-03\n",
      "Epoch 66300, Train loss: 2.446e+03, Test loss: 4.929e+03, MSE(e): 1.381e-04, MSE(pi1): 2.666e-02, MSE(pi2): 6.703e-05, MSE(pi3): 7.978e-03\n",
      "Epoch 66400, Train loss: 1.993e+03, Test loss: 3.950e+03, MSE(e): 7.909e-05, MSE(pi1): 4.036e-02, MSE(pi2): 4.213e-05, MSE(pi3): 7.980e-03\n",
      "Epoch 66500, Train loss: 1.772e+03, Test loss: 3.273e+03, MSE(e): 7.450e-05, MSE(pi1): 2.301e-02, MSE(pi2): 3.920e-05, MSE(pi3): 7.971e-03\n",
      "Epoch 66600, Train loss: 1.909e+03, Test loss: 3.607e+03, MSE(e): 7.812e-05, MSE(pi1): 3.321e-02, MSE(pi2): 3.923e-05, MSE(pi3): 7.962e-03\n",
      "Epoch 66700, Train loss: 1.814e+03, Test loss: 3.434e+03, MSE(e): 6.024e-05, MSE(pi1): 4.143e-02, MSE(pi2): 3.179e-05, MSE(pi3): 7.975e-03\n",
      "Epoch 66800, Train loss: 1.806e+03, Test loss: 3.373e+03, MSE(e): 6.191e-05, MSE(pi1): 3.899e-02, MSE(pi2): 3.115e-05, MSE(pi3): 7.974e-03\n",
      "Epoch 66900, Train loss: 1.245e+03, Test loss: 2.266e+03, MSE(e): 3.293e-05, MSE(pi1): 1.257e-02, MSE(pi2): 1.971e-05, MSE(pi3): 7.897e-03\n",
      "Epoch 67000, Train loss: 2.363e+03, Test loss: 3.858e+03, MSE(e): 8.810e-05, MSE(pi1): 6.755e-02, MSE(pi2): 4.277e-05, MSE(pi3): 8.065e-03\n",
      "Epoch 67100, Train loss: 1.971e+03, Test loss: 3.375e+03, MSE(e): 5.064e-05, MSE(pi1): 6.621e-02, MSE(pi2): 2.662e-05, MSE(pi3): 8.023e-03\n",
      "Epoch 67200, Train loss: 2.747e+03, Test loss: 3.343e+03, MSE(e): 1.513e-04, MSE(pi1): 4.292e-02, MSE(pi2): 7.574e-05, MSE(pi3): 8.046e-03\n",
      "Epoch 67300, Train loss: 1.576e+03, Test loss: 2.726e+03, MSE(e): 4.246e-05, MSE(pi1): 3.552e-02, MSE(pi2): 2.427e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 67400, Train loss: 1.670e+03, Test loss: 2.847e+03, MSE(e): 7.287e-05, MSE(pi1): 1.488e-02, MSE(pi2): 3.835e-05, MSE(pi3): 7.926e-03\n",
      "Epoch 67500, Train loss: 1.819e+03, Test loss: 2.985e+03, MSE(e): 6.569e-05, MSE(pi1): 3.649e-02, MSE(pi2): 3.667e-05, MSE(pi3): 7.974e-03\n",
      "Epoch 67600, Train loss: 1.554e+03, Test loss: 2.414e+03, MSE(e): 6.374e-05, MSE(pi1): 1.254e-02, MSE(pi2): 3.330e-05, MSE(pi3): 7.913e-03\n",
      "Epoch 67700, Train loss: 1.336e+03, Test loss: 2.371e+03, MSE(e): 3.412e-05, MSE(pi1): 2.023e-02, MSE(pi2): 2.020e-05, MSE(pi3): 7.924e-03\n",
      "Epoch 67800, Train loss: 2.090e+03, Test loss: 3.668e+03, MSE(e): 8.043e-05, MSE(pi1): 4.838e-02, MSE(pi2): 4.378e-05, MSE(pi3): 8.020e-03\n",
      "Epoch 67900, Train loss: 3.238e+03, Test loss: 3.849e+03, MSE(e): 2.184e-04, MSE(pi1): 2.535e-02, MSE(pi2): 1.045e-04, MSE(pi3): 7.999e-03\n",
      "Epoch 68000, Train loss: 1.386e+03, Test loss: 2.459e+03, MSE(e): 4.179e-05, MSE(pi1): 1.756e-02, MSE(pi2): 2.455e-05, MSE(pi3): 7.921e-03\n",
      "Epoch 68100, Train loss: 1.362e+03, Test loss: 2.678e+03, MSE(e): 4.135e-05, MSE(pi1): 1.571e-02, MSE(pi2): 2.365e-05, MSE(pi3): 7.911e-03\n",
      "Epoch 68200, Train loss: 2.144e+03, Test loss: 4.483e+03, MSE(e): 1.190e-04, MSE(pi1): 1.577e-02, MSE(pi2): 5.821e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 68300, Train loss: 1.587e+03, Test loss: 2.895e+03, MSE(e): 5.248e-05, MSE(pi1): 2.676e-02, MSE(pi2): 3.059e-05, MSE(pi3): 7.949e-03\n",
      "Epoch 68400, Train loss: 1.907e+03, Test loss: 3.451e+03, MSE(e): 5.682e-05, MSE(pi1): 5.379e-02, MSE(pi2): 2.823e-05, MSE(pi3): 8.010e-03\n",
      "Epoch 68500, Train loss: 1.438e+03, Test loss: 2.595e+03, MSE(e): 3.591e-05, MSE(pi1): 2.857e-02, MSE(pi2): 2.073e-05, MSE(pi3): 7.929e-03\n",
      "Epoch 68600, Train loss: 2.108e+03, Test loss: 4.223e+03, MSE(e): 1.055e-04, MSE(pi1): 2.551e-02, MSE(pi2): 5.243e-05, MSE(pi3): 7.971e-03\n",
      "Epoch 68700, Train loss: 1.867e+03, Test loss: 2.939e+03, MSE(e): 8.439e-05, MSE(pi1): 2.286e-02, MSE(pi2): 4.312e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 68800, Train loss: 1.424e+03, Test loss: 2.634e+03, MSE(e): 4.758e-05, MSE(pi1): 1.557e-02, MSE(pi2): 2.797e-05, MSE(pi3): 7.921e-03\n",
      "Epoch 68900, Train loss: 1.835e+03, Test loss: 3.395e+03, MSE(e): 5.094e-05, MSE(pi1): 5.275e-02, MSE(pi2): 2.673e-05, MSE(pi3): 7.977e-03\n",
      "Epoch 69000, Train loss: 2.521e+03, Test loss: 2.892e+03, MSE(e): 1.388e-04, MSE(pi1): 3.314e-02, MSE(pi2): 7.068e-05, MSE(pi3): 8.018e-03\n",
      "Epoch 69100, Train loss: 2.071e+03, Test loss: 3.753e+03, MSE(e): 4.573e-05, MSE(pi1): 8.086e-02, MSE(pi2): 2.363e-05, MSE(pi3): 8.054e-03\n",
      "Epoch 69200, Train loss: 2.102e+03, Test loss: 2.793e+03, MSE(e): 9.508e-05, MSE(pi1): 3.570e-02, MSE(pi2): 4.781e-05, MSE(pi3): 7.943e-03\n",
      "Epoch 69300, Train loss: 2.282e+03, Test loss: 5.331e+03, MSE(e): 1.254e-04, MSE(pi1): 2.327e-02, MSE(pi2): 6.328e-05, MSE(pi3): 7.951e-03\n",
      "Epoch 69400, Train loss: 2.011e+03, Test loss: 4.040e+03, MSE(e): 9.919e-05, MSE(pi1): 2.237e-02, MSE(pi2): 5.070e-05, MSE(pi3): 7.950e-03\n",
      "Epoch 69500, Train loss: 2.875e+03, Test loss: 4.098e+03, MSE(e): 1.721e-04, MSE(pi1): 3.532e-02, MSE(pi2): 8.314e-05, MSE(pi3): 8.007e-03\n",
      "Epoch 69600, Train loss: 2.437e+03, Test loss: 3.927e+03, MSE(e): 1.215e-04, MSE(pi1): 4.213e-02, MSE(pi2): 5.989e-05, MSE(pi3): 8.001e-03\n",
      "Epoch 69700, Train loss: 2.116e+03, Test loss: 3.334e+03, MSE(e): 1.159e-04, MSE(pi1): 1.596e-02, MSE(pi2): 5.722e-05, MSE(pi3): 7.975e-03\n",
      "Epoch 69800, Train loss: 1.894e+03, Test loss: 2.872e+03, MSE(e): 7.617e-05, MSE(pi1): 3.355e-02, MSE(pi2): 3.999e-05, MSE(pi3): 7.968e-03\n",
      "Epoch 69900, Train loss: 2.020e+03, Test loss: 3.465e+03, MSE(e): 6.731e-05, MSE(pi1): 5.473e-02, MSE(pi2): 3.551e-05, MSE(pi3): 7.993e-03\n",
      "Epoch 70000, Train loss: 2.707e+03, Test loss: 4.207e+03, MSE(e): 1.497e-04, MSE(pi1): 4.080e-02, MSE(pi2): 7.556e-05, MSE(pi3): 8.028e-03\n",
      "Epoch 70100, Train loss: 1.844e+03, Test loss: 2.724e+03, MSE(e): 7.630e-05, MSE(pi1): 2.868e-02, MSE(pi2): 3.889e-05, MSE(pi3): 7.946e-03\n",
      "Epoch 70200, Train loss: 2.209e+03, Test loss: 3.614e+03, MSE(e): 6.670e-05, MSE(pi1): 7.359e-02, MSE(pi2): 3.355e-05, MSE(pi3): 8.063e-03\n",
      "Epoch 70300, Train loss: 2.442e+03, Test loss: 5.155e+03, MSE(e): 1.355e-04, MSE(pi1): 2.906e-02, MSE(pi2): 6.588e-05, MSE(pi3): 7.963e-03\n",
      "Epoch 70400, Train loss: 1.891e+03, Test loss: 3.671e+03, MSE(e): 8.408e-05, MSE(pi1): 2.549e-02, MSE(pi2): 4.065e-05, MSE(pi3): 7.953e-03\n",
      "Epoch 70500, Train loss: 1.469e+03, Test loss: 2.635e+03, MSE(e): 4.754e-05, MSE(pi1): 2.017e-02, MSE(pi2): 2.650e-05, MSE(pi3): 7.917e-03\n",
      "Epoch 70600, Train loss: 1.366e+03, Test loss: 2.653e+03, MSE(e): 4.293e-05, MSE(pi1): 1.462e-02, MSE(pi2): 2.391e-05, MSE(pi3): 7.909e-03\n",
      "Epoch 70700, Train loss: 2.056e+03, Test loss: 3.242e+03, MSE(e): 9.894e-05, MSE(pi1): 2.710e-02, MSE(pi2): 4.909e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 70800, Train loss: 1.785e+03, Test loss: 3.303e+03, MSE(e): 7.182e-05, MSE(pi1): 2.684e-02, MSE(pi2): 3.998e-05, MSE(pi3): 7.982e-03\n",
      "Epoch 70900, Train loss: 1.736e+03, Test loss: 3.020e+03, MSE(e): 4.878e-05, MSE(pi1): 4.496e-02, MSE(pi2): 2.745e-05, MSE(pi3): 7.983e-03\n",
      "Epoch 71000, Train loss: 1.676e+03, Test loss: 3.923e+03, MSE(e): 7.569e-05, MSE(pi1): 1.275e-02, MSE(pi2): 4.012e-05, MSE(pi3): 7.915e-03\n",
      "Epoch 71100, Train loss: 1.617e+03, Test loss: 2.768e+03, MSE(e): 4.768e-05, MSE(pi1): 3.441e-02, MSE(pi2): 2.780e-05, MSE(pi3): 7.961e-03\n",
      "Epoch 71200, Train loss: 1.733e+03, Test loss: 3.223e+03, MSE(e): 5.994e-05, MSE(pi1): 3.361e-02, MSE(pi2): 3.093e-05, MSE(pi3): 7.971e-03\n",
      "Epoch 71300, Train loss: 1.504e+03, Test loss: 2.582e+03, MSE(e): 5.996e-05, MSE(pi1): 1.133e-02, MSE(pi2): 3.294e-05, MSE(pi3): 7.914e-03\n",
      "Epoch 71400, Train loss: 2.266e+03, Test loss: 3.261e+03, MSE(e): 1.181e-04, MSE(pi1): 2.849e-02, MSE(pi2): 5.967e-05, MSE(pi3): 8.007e-03\n",
      "Epoch 71500, Train loss: 1.384e+03, Test loss: 2.468e+03, MSE(e): 3.871e-05, MSE(pi1): 2.038e-02, MSE(pi2): 2.303e-05, MSE(pi3): 7.927e-03\n",
      "Epoch 71600, Train loss: 2.465e+03, Test loss: 2.614e+03, MSE(e): 1.417e-04, MSE(pi1): 2.466e-02, MSE(pi2): 7.139e-05, MSE(pi3): 8.005e-03\n",
      "Epoch 71700, Train loss: 2.364e+03, Test loss: 3.362e+03, MSE(e): 9.464e-05, MSE(pi1): 6.121e-02, MSE(pi2): 4.827e-05, MSE(pi3): 8.053e-03\n",
      "Epoch 71800, Train loss: 1.851e+03, Test loss: 3.490e+03, MSE(e): 6.554e-05, MSE(pi1): 3.969e-02, MSE(pi2): 3.636e-05, MSE(pi3): 7.982e-03\n",
      "Epoch 71900, Train loss: 1.763e+03, Test loss: 2.708e+03, MSE(e): 6.717e-05, MSE(pi1): 2.969e-02, MSE(pi2): 3.447e-05, MSE(pi3): 7.946e-03\n",
      "Epoch 72000, Train loss: 1.824e+03, Test loss: 3.894e+03, MSE(e): 8.389e-05, MSE(pi1): 1.913e-02, MSE(pi2): 4.122e-05, MSE(pi3): 7.936e-03\n",
      "Epoch 72100, Train loss: 2.103e+03, Test loss: 3.624e+03, MSE(e): 1.150e-04, MSE(pi1): 1.587e-02, MSE(pi2): 5.942e-05, MSE(pi3): 7.945e-03\n",
      "Epoch 72200, Train loss: 2.138e+03, Test loss: 5.138e+03, MSE(e): 1.178e-04, MSE(pi1): 1.672e-02, MSE(pi2): 5.787e-05, MSE(pi3): 7.925e-03\n",
      "Epoch 72300, Train loss: 2.759e+03, Test loss: 5.071e+03, MSE(e): 1.554e-04, MSE(pi1): 4.029e-02, MSE(pi2): 7.639e-05, MSE(pi3): 8.017e-03\n",
      "Epoch 72400, Train loss: 1.416e+03, Test loss: 2.798e+03, MSE(e): 4.264e-05, MSE(pi1): 1.979e-02, MSE(pi2): 2.445e-05, MSE(pi3): 7.918e-03\n",
      "Epoch 72500, Train loss: 1.658e+03, Test loss: 2.785e+03, MSE(e): 7.316e-05, MSE(pi1): 1.354e-02, MSE(pi2): 3.843e-05, MSE(pi3): 7.914e-03\n",
      "Epoch 72600, Train loss: 1.963e+03, Test loss: 2.909e+03, MSE(e): 9.115e-05, MSE(pi1): 2.569e-02, MSE(pi2): 4.645e-05, MSE(pi3): 7.949e-03\n",
      "Epoch 72700, Train loss: 2.784e+03, Test loss: 2.918e+03, MSE(e): 1.696e-04, MSE(pi1): 2.885e-02, MSE(pi2): 8.065e-05, MSE(pi3): 7.996e-03\n",
      "Epoch 72800, Train loss: 1.729e+03, Test loss: 4.036e+03, MSE(e): 7.993e-05, MSE(pi1): 1.388e-02, MSE(pi2): 4.105e-05, MSE(pi3): 7.911e-03\n",
      "Epoch 72900, Train loss: 1.545e+03, Test loss: 2.618e+03, MSE(e): 5.265e-05, MSE(pi1): 2.248e-02, MSE(pi2): 3.085e-05, MSE(pi3): 7.936e-03\n",
      "Epoch 73000, Train loss: 1.798e+03, Test loss: 3.522e+03, MSE(e): 7.086e-05, MSE(pi1): 2.928e-02, MSE(pi2): 3.768e-05, MSE(pi3): 7.963e-03\n",
      "Epoch 73100, Train loss: 1.709e+03, Test loss: 3.043e+03, MSE(e): 5.899e-05, MSE(pi1): 3.236e-02, MSE(pi2): 3.188e-05, MSE(pi3): 7.951e-03\n",
      "Epoch 73200, Train loss: 1.939e+03, Test loss: 3.172e+03, MSE(e): 6.980e-05, MSE(pi1): 4.417e-02, MSE(pi2): 3.641e-05, MSE(pi3): 7.994e-03\n",
      "Epoch 73300, Train loss: 1.898e+03, Test loss: 2.867e+03, MSE(e): 9.304e-05, MSE(pi1): 1.705e-02, MSE(pi2): 4.915e-05, MSE(pi3): 7.973e-03\n",
      "Epoch 73400, Train loss: 1.693e+03, Test loss: 2.938e+03, MSE(e): 4.407e-05, MSE(pi1): 4.547e-02, MSE(pi2): 2.526e-05, MSE(pi3): 7.978e-03\n",
      "Epoch 73500, Train loss: 1.293e+03, Test loss: 2.363e+03, MSE(e): 3.759e-05, MSE(pi1): 1.264e-02, MSE(pi2): 2.271e-05, MSE(pi3): 7.906e-03\n",
      "Epoch 73600, Train loss: 1.577e+03, Test loss: 2.426e+03, MSE(e): 5.952e-05, MSE(pi1): 1.908e-02, MSE(pi2): 3.142e-05, MSE(pi3): 7.910e-03\n",
      "Epoch 73700, Train loss: 1.852e+03, Test loss: 2.608e+03, MSE(e): 8.318e-05, MSE(pi1): 2.244e-02, MSE(pi2): 4.342e-05, MSE(pi3): 7.959e-03\n",
      "Epoch 73800, Train loss: 1.937e+03, Test loss: 3.273e+03, MSE(e): 5.217e-05, MSE(pi1): 6.152e-02, MSE(pi2): 2.779e-05, MSE(pi3): 8.002e-03\n",
      "Epoch 73900, Train loss: 2.060e+03, Test loss: 2.606e+03, MSE(e): 1.029e-04, MSE(pi1): 2.370e-02, MSE(pi2): 5.047e-05, MSE(pi3): 7.936e-03\n",
      "Epoch 74000, Train loss: 1.419e+03, Test loss: 2.630e+03, MSE(e): 3.925e-05, MSE(pi1): 2.329e-02, MSE(pi2): 2.192e-05, MSE(pi3): 7.933e-03\n",
      "Epoch 74100, Train loss: 1.959e+03, Test loss: 3.205e+03, MSE(e): 6.791e-05, MSE(pi1): 4.814e-02, MSE(pi2): 3.386e-05, MSE(pi3): 7.981e-03\n",
      "Epoch 74200, Train loss: 1.377e+03, Test loss: 2.646e+03, MSE(e): 3.874e-05, MSE(pi1): 1.980e-02, MSE(pi2): 2.226e-05, MSE(pi3): 7.920e-03\n",
      "Epoch 74300, Train loss: 2.623e+03, Test loss: 5.482e+03, MSE(e): 1.379e-04, MSE(pi1): 4.459e-02, MSE(pi2): 7.077e-05, MSE(pi3): 7.983e-03\n",
      "Epoch 74400, Train loss: 1.829e+03, Test loss: 2.941e+03, MSE(e): 6.833e-05, MSE(pi1): 3.506e-02, MSE(pi2): 3.748e-05, MSE(pi3): 7.955e-03\n",
      "Epoch 74500, Train loss: 2.261e+03, Test loss: 4.612e+03, MSE(e): 1.283e-04, MSE(pi1): 1.816e-02, MSE(pi2): 6.175e-05, MSE(pi3): 7.969e-03\n",
      "Epoch 74600, Train loss: 3.630e+03, Test loss: 7.716e+03, MSE(e): 2.484e-04, MSE(pi1): 3.454e-02, MSE(pi2): 1.186e-04, MSE(pi3): 8.004e-03\n",
      "Epoch 74700, Train loss: 1.723e+03, Test loss: 3.005e+03, MSE(e): 4.547e-05, MSE(pi1): 4.696e-02, MSE(pi2): 2.588e-05, MSE(pi3): 7.989e-03\n",
      "Epoch 74800, Train loss: 1.463e+03, Test loss: 2.622e+03, MSE(e): 4.171e-05, MSE(pi1): 2.526e-02, MSE(pi2): 2.362e-05, MSE(pi3): 7.930e-03\n",
      "Epoch 74900, Train loss: 2.065e+03, Test loss: 4.056e+03, MSE(e): 6.576e-05, MSE(pi1): 6.088e-02, MSE(pi2): 3.383e-05, MSE(pi3): 7.990e-03\n",
      "Epoch 75000, Train loss: 1.485e+03, Test loss: 3.132e+03, MSE(e): 5.783e-05, MSE(pi1): 1.173e-02, MSE(pi2): 3.214e-05, MSE(pi3): 7.896e-03\n",
      "Epoch 75100, Train loss: 1.842e+03, Test loss: 2.563e+03, MSE(e): 8.676e-05, MSE(pi1): 1.818e-02, MSE(pi2): 4.513e-05, MSE(pi3): 7.928e-03\n",
      "Epoch 75200, Train loss: 2.585e+03, Test loss: 4.716e+03, MSE(e): 8.609e-05, MSE(pi1): 9.135e-02, MSE(pi2): 3.958e-05, MSE(pi3): 8.102e-03\n",
      "Epoch 75300, Train loss: 1.626e+03, Test loss: 3.097e+03, MSE(e): 7.029e-05, MSE(pi1): 1.304e-02, MSE(pi2): 3.602e-05, MSE(pi3): 7.924e-03\n",
      "Epoch 75400, Train loss: 2.207e+03, Test loss: 3.802e+03, MSE(e): 9.352e-05, MSE(pi1): 4.705e-02, MSE(pi2): 4.639e-05, MSE(pi3): 8.009e-03\n",
      "Epoch 75500, Train loss: 1.751e+03, Test loss: 3.237e+03, MSE(e): 7.726e-05, MSE(pi1): 1.856e-02, MSE(pi2): 3.904e-05, MSE(pi3): 7.930e-03\n",
      "Epoch 75600, Train loss: 1.840e+03, Test loss: 3.392e+03, MSE(e): 7.849e-05, MSE(pi1): 2.586e-02, MSE(pi2): 3.968e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 75700, Train loss: 1.912e+03, Test loss: 3.578e+03, MSE(e): 8.062e-05, MSE(pi1): 3.086e-02, MSE(pi2): 4.062e-05, MSE(pi3): 7.973e-03\n",
      "Epoch 75800, Train loss: 1.958e+03, Test loss: 3.522e+03, MSE(e): 8.431e-05, MSE(pi1): 3.195e-02, MSE(pi2): 4.298e-05, MSE(pi3): 7.957e-03\n",
      "Epoch 75900, Train loss: 2.634e+03, Test loss: 4.783e+03, MSE(e): 8.575e-05, MSE(pi1): 9.653e-02, MSE(pi2): 3.990e-05, MSE(pi3): 8.110e-03\n",
      "Epoch 76000, Train loss: 1.965e+03, Test loss: 3.470e+03, MSE(e): 8.018e-05, MSE(pi1): 3.645e-02, MSE(pi2): 4.025e-05, MSE(pi3): 7.988e-03\n",
      "Epoch 76100, Train loss: 1.886e+03, Test loss: 2.614e+03, MSE(e): 9.110e-05, MSE(pi1): 1.794e-02, MSE(pi2): 4.574e-05, MSE(pi3): 7.952e-03\n",
      "Epoch 76200, Train loss: 1.903e+03, Test loss: 2.603e+03, MSE(e): 9.272e-05, MSE(pi1): 1.799e-02, MSE(pi2): 4.672e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 76300, Train loss: 1.853e+03, Test loss: 2.859e+03, MSE(e): 8.577e-05, MSE(pi1): 1.998e-02, MSE(pi2): 4.263e-05, MSE(pi3): 7.950e-03\n",
      "Epoch 76400, Train loss: 1.739e+03, Test loss: 3.243e+03, MSE(e): 7.288e-05, MSE(pi1): 2.156e-02, MSE(pi2): 3.712e-05, MSE(pi3): 7.950e-03\n",
      "Epoch 76500, Train loss: 1.791e+03, Test loss: 3.344e+03, MSE(e): 7.435e-05, MSE(pi1): 2.514e-02, MSE(pi2): 3.829e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 76600, Train loss: 1.792e+03, Test loss: 2.941e+03, MSE(e): 5.632e-05, MSE(pi1): 4.289e-02, MSE(pi2): 3.224e-05, MSE(pi3): 7.997e-03\n",
      "Epoch 76700, Train loss: 1.722e+03, Test loss: 2.879e+03, MSE(e): 6.326e-05, MSE(pi1): 2.932e-02, MSE(pi2): 3.263e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 76800, Train loss: 1.536e+03, Test loss: 2.816e+03, MSE(e): 4.062e-05, MSE(pi1): 3.350e-02, MSE(pi2): 2.382e-05, MSE(pi3): 7.952e-03\n",
      "Epoch 76900, Train loss: 1.789e+03, Test loss: 3.314e+03, MSE(e): 5.070e-05, MSE(pi1): 4.841e-02, MSE(pi2): 2.724e-05, MSE(pi3): 7.973e-03\n",
      "Epoch 77000, Train loss: 1.778e+03, Test loss: 3.447e+03, MSE(e): 5.712e-05, MSE(pi1): 4.087e-02, MSE(pi2): 3.152e-05, MSE(pi3): 7.982e-03\n",
      "Epoch 77100, Train loss: 2.828e+03, Test loss: 4.633e+03, MSE(e): 1.902e-04, MSE(pi1): 1.310e-02, MSE(pi2): 9.290e-05, MSE(pi3): 7.953e-03\n",
      "Epoch 77200, Train loss: 1.882e+03, Test loss: 2.922e+03, MSE(e): 7.335e-05, MSE(pi1): 3.518e-02, MSE(pi2): 3.746e-05, MSE(pi3): 7.963e-03\n",
      "Epoch 77300, Train loss: 1.766e+03, Test loss: 2.646e+03, MSE(e): 7.073e-05, MSE(pi1): 2.625e-02, MSE(pi2): 3.807e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 77400, Train loss: 3.600e+03, Test loss: 3.260e+03, MSE(e): 2.630e-04, MSE(pi1): 1.701e-02, MSE(pi2): 1.246e-04, MSE(pi3): 8.004e-03\n",
      "Epoch 77500, Train loss: 2.549e+03, Test loss: 5.746e+03, MSE(e): 1.210e-04, MSE(pi1): 5.365e-02, MSE(pi2): 6.087e-05, MSE(pi3): 8.026e-03\n",
      "Epoch 77600, Train loss: 1.444e+03, Test loss: 2.839e+03, MSE(e): 5.138e-05, MSE(pi1): 1.393e-02, MSE(pi2): 2.956e-05, MSE(pi3): 7.912e-03\n",
      "Epoch 77700, Train loss: 2.195e+03, Test loss: 3.798e+03, MSE(e): 9.233e-05, MSE(pi1): 4.707e-02, MSE(pi2): 4.549e-05, MSE(pi3): 8.011e-03\n",
      "Epoch 77800, Train loss: 2.143e+03, Test loss: 3.473e+03, MSE(e): 1.048e-04, MSE(pi1): 2.955e-02, MSE(pi2): 5.099e-05, MSE(pi3): 7.985e-03\n",
      "Epoch 77900, Train loss: 1.973e+03, Test loss: 3.225e+03, MSE(e): 6.112e-05, MSE(pi1): 5.610e-02, MSE(pi2): 3.272e-05, MSE(pi3): 8.004e-03\n",
      "Epoch 78000, Train loss: 1.960e+03, Test loss: 3.723e+03, MSE(e): 7.659e-05, MSE(pi1): 3.952e-02, MSE(pi2): 3.765e-05, MSE(pi3): 7.989e-03\n",
      "Epoch 78100, Train loss: 1.920e+03, Test loss: 2.784e+03, MSE(e): 8.118e-05, MSE(pi1): 3.136e-02, MSE(pi2): 4.103e-05, MSE(pi3): 7.945e-03\n",
      "Epoch 78200, Train loss: 1.673e+03, Test loss: 3.559e+03, MSE(e): 6.101e-05, MSE(pi1): 2.692e-02, MSE(pi2): 3.336e-05, MSE(pi3): 7.935e-03\n",
      "Epoch 78300, Train loss: 1.745e+03, Test loss: 2.696e+03, MSE(e): 8.496e-05, MSE(pi1): 1.014e-02, MSE(pi2): 4.337e-05, MSE(pi3): 7.936e-03\n",
      "Epoch 78400, Train loss: 1.944e+03, Test loss: 3.203e+03, MSE(e): 8.094e-05, MSE(pi1): 3.371e-02, MSE(pi2): 4.095e-05, MSE(pi3): 7.969e-03\n",
      "Epoch 78500, Train loss: 2.254e+03, Test loss: 4.573e+03, MSE(e): 6.515e-05, MSE(pi1): 7.970e-02, MSE(pi2): 3.286e-05, MSE(pi3): 8.051e-03\n",
      "Epoch 78600, Train loss: 1.972e+03, Test loss: 3.115e+03, MSE(e): 8.367e-05, MSE(pi1): 3.371e-02, MSE(pi2): 4.098e-05, MSE(pi3): 7.980e-03\n",
      "Epoch 78700, Train loss: 1.753e+03, Test loss: 2.462e+03, MSE(e): 7.902e-05, MSE(pi1): 1.705e-02, MSE(pi2): 4.106e-05, MSE(pi3): 7.920e-03\n",
      "Epoch 78800, Train loss: 1.773e+03, Test loss: 2.797e+03, MSE(e): 8.441e-05, MSE(pi1): 1.355e-02, MSE(pi2): 4.380e-05, MSE(pi3): 7.938e-03\n",
      "Epoch 78900, Train loss: 1.902e+03, Test loss: 3.529e+03, MSE(e): 7.835e-05, MSE(pi1): 3.227e-02, MSE(pi2): 3.857e-05, MSE(pi3): 7.962e-03\n",
      "Epoch 79000, Train loss: 1.666e+03, Test loss: 3.541e+03, MSE(e): 6.103e-05, MSE(pi1): 2.624e-02, MSE(pi2): 3.273e-05, MSE(pi3): 7.931e-03\n",
      "Epoch 79100, Train loss: 2.049e+03, Test loss: 3.768e+03, MSE(e): 7.759e-05, MSE(pi1): 4.730e-02, MSE(pi2): 3.786e-05, MSE(pi3): 7.999e-03\n",
      "Epoch 79200, Train loss: 1.970e+03, Test loss: 3.856e+03, MSE(e): 6.093e-05, MSE(pi1): 5.626e-02, MSE(pi2): 3.154e-05, MSE(pi3): 7.985e-03\n",
      "Epoch 79300, Train loss: 2.022e+03, Test loss: 2.733e+03, MSE(e): 9.484e-05, MSE(pi1): 2.763e-02, MSE(pi2): 4.805e-05, MSE(pi3): 7.975e-03\n",
      "Epoch 79400, Train loss: 2.154e+03, Test loss: 3.425e+03, MSE(e): 8.398e-05, MSE(pi1): 5.148e-02, MSE(pi2): 4.102e-05, MSE(pi3): 7.990e-03\n",
      "Epoch 79500, Train loss: 2.153e+03, Test loss: 3.364e+03, MSE(e): 8.959e-05, MSE(pi1): 4.562e-02, MSE(pi2): 4.543e-05, MSE(pi3): 8.011e-03\n",
      "Epoch 79600, Train loss: 2.241e+03, Test loss: 3.954e+03, MSE(e): 8.123e-05, MSE(pi1): 6.264e-02, MSE(pi2): 3.882e-05, MSE(pi3): 8.024e-03\n",
      "Epoch 79700, Train loss: 1.854e+03, Test loss: 3.110e+03, MSE(e): 7.745e-05, MSE(pi1): 2.839e-02, MSE(pi2): 4.005e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 79800, Train loss: 1.907e+03, Test loss: 3.409e+03, MSE(e): 7.588e-05, MSE(pi1): 3.515e-02, MSE(pi2): 3.784e-05, MSE(pi3): 7.967e-03\n",
      "Epoch 79900, Train loss: 2.100e+03, Test loss: 3.322e+03, MSE(e): 8.920e-05, MSE(pi1): 4.089e-02, MSE(pi2): 4.537e-05, MSE(pi3): 7.991e-03\n",
      "Epoch 80000, Train loss: 1.716e+03, Test loss: 2.541e+03, MSE(e): 7.790e-05, MSE(pi1): 1.443e-02, MSE(pi2): 4.042e-05, MSE(pi3): 7.924e-03\n",
      "Epoch 80100, Train loss: 1.876e+03, Test loss: 2.483e+03, MSE(e): 9.266e-05, MSE(pi1): 1.542e-02, MSE(pi2): 4.702e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 80200, Train loss: 1.663e+03, Test loss: 3.037e+03, MSE(e): 5.961e-05, MSE(pi1): 2.739e-02, MSE(pi2): 3.192e-05, MSE(pi3): 7.929e-03\n",
      "Epoch 80300, Train loss: 1.709e+03, Test loss: 3.029e+03, MSE(e): 7.568e-05, MSE(pi1): 1.578e-02, MSE(pi2): 3.818e-05, MSE(pi3): 7.941e-03\n",
      "Epoch 80400, Train loss: 1.593e+03, Test loss: 3.402e+03, MSE(e): 6.249e-05, MSE(pi1): 1.757e-02, MSE(pi2): 3.418e-05, MSE(pi3): 7.920e-03\n",
      "Epoch 80500, Train loss: 2.011e+03, Test loss: 3.355e+03, MSE(e): 7.829e-05, MSE(pi1): 4.291e-02, MSE(pi2): 3.861e-05, MSE(pi3): 7.986e-03\n",
      "Epoch 80600, Train loss: 2.182e+03, Test loss: 2.980e+03, MSE(e): 1.012e-04, MSE(pi1): 3.720e-02, MSE(pi2): 5.063e-05, MSE(pi3): 7.977e-03\n",
      "Epoch 80700, Train loss: 1.662e+03, Test loss: 2.589e+03, MSE(e): 7.354e-05, MSE(pi1): 1.369e-02, MSE(pi2): 3.967e-05, MSE(pi3): 7.900e-03\n",
      "Epoch 80800, Train loss: 1.882e+03, Test loss: 3.569e+03, MSE(e): 7.502e-05, MSE(pi1): 3.342e-02, MSE(pi2): 3.715e-05, MSE(pi3): 7.972e-03\n",
      "Epoch 80900, Train loss: 1.973e+03, Test loss: 3.694e+03, MSE(e): 8.102e-05, MSE(pi1): 3.662e-02, MSE(pi2): 4.209e-05, MSE(pi3): 7.970e-03\n",
      "Epoch 81000, Train loss: 1.909e+03, Test loss: 2.743e+03, MSE(e): 8.338e-05, MSE(pi1): 2.818e-02, MSE(pi2): 4.364e-05, MSE(pi3): 7.935e-03\n",
      "Epoch 81100, Train loss: 1.884e+03, Test loss: 2.699e+03, MSE(e): 8.921e-05, MSE(pi1): 1.967e-02, MSE(pi2): 4.566e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 81200, Train loss: 1.819e+03, Test loss: 3.765e+03, MSE(e): 6.325e-05, MSE(pi1): 3.898e-02, MSE(pi2): 3.365e-05, MSE(pi3): 7.970e-03\n",
      "Epoch 81300, Train loss: 2.173e+03, Test loss: 3.501e+03, MSE(e): 8.361e-05, MSE(pi1): 5.383e-02, MSE(pi2): 4.103e-05, MSE(pi3): 7.990e-03\n",
      "Epoch 81400, Train loss: 2.090e+03, Test loss: 3.267e+03, MSE(e): 8.482e-05, MSE(pi1): 4.411e-02, MSE(pi2): 4.089e-05, MSE(pi3): 8.004e-03\n",
      "Epoch 81500, Train loss: 1.733e+03, Test loss: 3.402e+03, MSE(e): 6.696e-05, MSE(pi1): 2.692e-02, MSE(pi2): 3.616e-05, MSE(pi3): 7.945e-03\n",
      "Epoch 81600, Train loss: 1.788e+03, Test loss: 2.738e+03, MSE(e): 7.300e-05, MSE(pi1): 2.650e-02, MSE(pi2): 3.791e-05, MSE(pi3): 7.926e-03\n",
      "Epoch 81700, Train loss: 1.914e+03, Test loss: 3.621e+03, MSE(e): 7.578e-05, MSE(pi1): 3.589e-02, MSE(pi2): 3.716e-05, MSE(pi3): 7.973e-03\n",
      "Epoch 81800, Train loss: 2.210e+03, Test loss: 2.967e+03, MSE(e): 1.025e-04, MSE(pi1): 3.846e-02, MSE(pi2): 5.134e-05, MSE(pi3): 8.002e-03\n",
      "Epoch 81900, Train loss: 1.716e+03, Test loss: 3.525e+03, MSE(e): 6.093e-05, MSE(pi1): 3.129e-02, MSE(pi2): 3.332e-05, MSE(pi3): 7.940e-03\n",
      "Epoch 82000, Train loss: 1.933e+03, Test loss: 2.892e+03, MSE(e): 7.924e-05, MSE(pi1): 3.454e-02, MSE(pi2): 4.053e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 82100, Train loss: 1.691e+03, Test loss: 3.050e+03, MSE(e): 7.333e-05, MSE(pi1): 1.633e-02, MSE(pi2): 3.718e-05, MSE(pi3): 7.946e-03\n",
      "Epoch 82200, Train loss: 2.257e+03, Test loss: 3.462e+03, MSE(e): 9.476e-05, MSE(pi1): 5.068e-02, MSE(pi2): 4.673e-05, MSE(pi3): 8.023e-03\n",
      "Epoch 82300, Train loss: 1.635e+03, Test loss: 3.491e+03, MSE(e): 5.811e-05, MSE(pi1): 2.609e-02, MSE(pi2): 3.187e-05, MSE(pi3): 7.932e-03\n",
      "Epoch 82400, Train loss: 2.272e+03, Test loss: 3.522e+03, MSE(e): 8.080e-05, MSE(pi1): 6.615e-02, MSE(pi2): 3.941e-05, MSE(pi3): 8.021e-03\n",
      "Epoch 82500, Train loss: 1.740e+03, Test loss: 3.346e+03, MSE(e): 7.292e-05, MSE(pi1): 2.163e-02, MSE(pi2): 3.689e-05, MSE(pi3): 7.944e-03\n",
      "Epoch 82600, Train loss: 1.805e+03, Test loss: 2.457e+03, MSE(e): 9.037e-05, MSE(pi1): 1.066e-02, MSE(pi2): 4.599e-05, MSE(pi3): 7.946e-03\n",
      "Epoch 82700, Train loss: 2.098e+03, Test loss: 4.064e+03, MSE(e): 7.656e-05, MSE(pi1): 5.312e-02, MSE(pi2): 4.004e-05, MSE(pi3): 8.009e-03\n",
      "Epoch 82800, Train loss: 2.059e+03, Test loss: 4.061e+03, MSE(e): 6.110e-05, MSE(pi1): 6.470e-02, MSE(pi2): 3.257e-05, MSE(pi3): 8.006e-03\n",
      "Epoch 82900, Train loss: 1.897e+03, Test loss: 2.813e+03, MSE(e): 7.659e-05, MSE(pi1): 3.359e-02, MSE(pi2): 3.939e-05, MSE(pi3): 7.953e-03\n",
      "Epoch 83000, Train loss: 1.722e+03, Test loss: 3.299e+03, MSE(e): 7.496e-05, MSE(pi1): 1.790e-02, MSE(pi2): 3.851e-05, MSE(pi3): 7.938e-03\n",
      "Epoch 83100, Train loss: 2.039e+03, Test loss: 2.960e+03, MSE(e): 9.261e-05, MSE(pi1): 3.146e-02, MSE(pi2): 4.611e-05, MSE(pi3): 7.984e-03\n",
      "Epoch 83200, Train loss: 2.011e+03, Test loss: 3.224e+03, MSE(e): 9.408e-05, MSE(pi1): 2.745e-02, MSE(pi2): 4.880e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 83300, Train loss: 2.065e+03, Test loss: 4.372e+03, MSE(e): 6.419e-05, MSE(pi1): 6.216e-02, MSE(pi2): 3.262e-05, MSE(pi3): 8.019e-03\n",
      "Epoch 83400, Train loss: 1.927e+03, Test loss: 3.459e+03, MSE(e): 6.457e-05, MSE(pi1): 4.853e-02, MSE(pi2): 3.469e-05, MSE(pi3): 7.962e-03\n",
      "Epoch 83500, Train loss: 1.830e+03, Test loss: 2.711e+03, MSE(e): 7.494e-05, MSE(pi1): 2.848e-02, MSE(pi2): 3.821e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 83600, Train loss: 1.643e+03, Test loss: 2.919e+03, MSE(e): 6.885e-05, MSE(pi1): 1.615e-02, MSE(pi2): 3.499e-05, MSE(pi3): 7.933e-03\n",
      "Epoch 83700, Train loss: 1.878e+03, Test loss: 3.379e+03, MSE(e): 7.860e-05, MSE(pi1): 2.950e-02, MSE(pi2): 3.849e-05, MSE(pi3): 7.973e-03\n",
      "Epoch 83800, Train loss: 1.943e+03, Test loss: 2.910e+03, MSE(e): 8.865e-05, MSE(pi1): 2.592e-02, MSE(pi2): 4.421e-05, MSE(pi3): 7.972e-03\n",
      "Epoch 83900, Train loss: 1.843e+03, Test loss: 2.448e+03, MSE(e): 9.176e-05, MSE(pi1): 1.297e-02, MSE(pi2): 4.700e-05, MSE(pi3): 7.953e-03\n",
      "Epoch 84000, Train loss: 1.920e+03, Test loss: 2.935e+03, MSE(e): 8.649e-05, MSE(pi1): 2.596e-02, MSE(pi2): 4.490e-05, MSE(pi3): 7.959e-03\n",
      "Epoch 84100, Train loss: 1.865e+03, Test loss: 3.613e+03, MSE(e): 7.320e-05, MSE(pi1): 3.368e-02, MSE(pi2): 3.874e-05, MSE(pi3): 7.958e-03\n",
      "Epoch 84200, Train loss: 1.562e+03, Test loss: 3.401e+03, MSE(e): 5.839e-05, MSE(pi1): 1.870e-02, MSE(pi2): 3.171e-05, MSE(pi3): 7.912e-03\n",
      "Epoch 84300, Train loss: 1.618e+03, Test loss: 3.260e+03, MSE(e): 5.991e-05, MSE(pi1): 2.277e-02, MSE(pi2): 3.342e-05, MSE(pi3): 7.909e-03\n",
      "Epoch 84400, Train loss: 1.614e+03, Test loss: 2.717e+03, MSE(e): 6.583e-05, MSE(pi1): 1.647e-02, MSE(pi2): 3.514e-05, MSE(pi3): 7.910e-03\n",
      "Epoch 84500, Train loss: 2.072e+03, Test loss: 3.092e+03, MSE(e): 7.973e-05, MSE(pi1): 4.753e-02, MSE(pi2): 4.021e-05, MSE(pi3): 7.996e-03\n",
      "Epoch 84600, Train loss: 1.769e+03, Test loss: 2.624e+03, MSE(e): 7.185e-05, MSE(pi1): 2.569e-02, MSE(pi2): 3.698e-05, MSE(pi3): 7.932e-03\n",
      "Epoch 84700, Train loss: 1.630e+03, Test loss: 2.738e+03, MSE(e): 7.171e-05, MSE(pi1): 1.216e-02, MSE(pi2): 3.670e-05, MSE(pi3): 7.911e-03\n",
      "Epoch 84800, Train loss: 1.875e+03, Test loss: 3.307e+03, MSE(e): 7.276e-05, MSE(pi1): 3.506e-02, MSE(pi2): 3.639e-05, MSE(pi3): 7.966e-03\n",
      "Epoch 84900, Train loss: 1.817e+03, Test loss: 3.368e+03, MSE(e): 6.966e-05, MSE(pi1): 3.248e-02, MSE(pi2): 3.499e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 85000, Train loss: 1.937e+03, Test loss: 3.050e+03, MSE(e): 8.378e-05, MSE(pi1): 3.006e-02, MSE(pi2): 4.164e-05, MSE(pi3): 7.981e-03\n",
      "Epoch 85100, Train loss: 1.781e+03, Test loss: 2.690e+03, MSE(e): 8.729e-05, MSE(pi1): 1.143e-02, MSE(pi2): 4.359e-05, MSE(pi3): 7.936e-03\n",
      "Epoch 85200, Train loss: 1.977e+03, Test loss: 2.832e+03, MSE(e): 9.416e-05, MSE(pi1): 2.394e-02, MSE(pi2): 4.793e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 85300, Train loss: 1.872e+03, Test loss: 2.639e+03, MSE(e): 8.781e-05, MSE(pi1): 1.983e-02, MSE(pi2): 4.464e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 85400, Train loss: 2.036e+03, Test loss: 3.218e+03, MSE(e): 9.027e-05, MSE(pi1): 3.359e-02, MSE(pi2): 4.643e-05, MSE(pi3): 7.970e-03\n",
      "Epoch 85500, Train loss: 1.918e+03, Test loss: 2.709e+03, MSE(e): 9.149e-05, MSE(pi1): 2.071e-02, MSE(pi2): 4.707e-05, MSE(pi3): 7.958e-03\n",
      "Epoch 85600, Train loss: 1.865e+03, Test loss: 2.600e+03, MSE(e): 9.089e-05, MSE(pi1): 1.618e-02, MSE(pi2): 4.650e-05, MSE(pi3): 7.944e-03\n",
      "Epoch 85700, Train loss: 1.968e+03, Test loss: 2.740e+03, MSE(e): 9.136e-05, MSE(pi1): 2.571e-02, MSE(pi2): 4.730e-05, MSE(pi3): 7.969e-03\n",
      "Epoch 85800, Train loss: 1.924e+03, Test loss: 2.661e+03, MSE(e): 9.151e-05, MSE(pi1): 2.118e-02, MSE(pi2): 4.689e-05, MSE(pi3): 7.967e-03\n",
      "Epoch 85900, Train loss: 2.598e+03, Test loss: 3.707e+03, MSE(e): 1.011e-04, MSE(pi1): 7.784e-02, MSE(pi2): 4.914e-05, MSE(pi3): 8.087e-03\n",
      "Epoch 86000, Train loss: 2.214e+03, Test loss: 3.339e+03, MSE(e): 8.953e-05, MSE(pi1): 5.161e-02, MSE(pi2): 4.398e-05, MSE(pi3): 8.025e-03\n",
      "Epoch 86100, Train loss: 2.020e+03, Test loss: 2.712e+03, MSE(e): 9.507e-05, MSE(pi1): 2.712e-02, MSE(pi2): 4.778e-05, MSE(pi3): 7.982e-03\n",
      "Epoch 86200, Train loss: 1.953e+03, Test loss: 2.649e+03, MSE(e): 9.469e-05, MSE(pi1): 2.104e-02, MSE(pi2): 4.791e-05, MSE(pi3): 7.959e-03\n",
      "Epoch 86300, Train loss: 2.356e+03, Test loss: 3.467e+03, MSE(e): 9.458e-05, MSE(pi1): 6.041e-02, MSE(pi2): 4.650e-05, MSE(pi3): 8.061e-03\n",
      "Epoch 86400, Train loss: 1.971e+03, Test loss: 3.561e+03, MSE(e): 7.736e-05, MSE(pi1): 3.988e-02, MSE(pi2): 3.791e-05, MSE(pi3): 7.989e-03\n",
      "Epoch 86500, Train loss: 1.999e+03, Test loss: 3.457e+03, MSE(e): 8.552e-05, MSE(pi1): 3.448e-02, MSE(pi2): 4.269e-05, MSE(pi3): 7.993e-03\n",
      "Epoch 86600, Train loss: 1.654e+03, Test loss: 3.126e+03, MSE(e): 7.169e-05, MSE(pi1): 1.418e-02, MSE(pi2): 3.696e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 86700, Train loss: 1.746e+03, Test loss: 3.189e+03, MSE(e): 6.976e-05, MSE(pi1): 2.542e-02, MSE(pi2): 3.582e-05, MSE(pi3): 7.942e-03\n",
      "Epoch 86800, Train loss: 2.349e+03, Test loss: 3.619e+03, MSE(e): 7.786e-05, MSE(pi1): 7.641e-02, MSE(pi2): 3.770e-05, MSE(pi3): 8.058e-03\n",
      "Epoch 86900, Train loss: 1.883e+03, Test loss: 3.026e+03, MSE(e): 7.157e-05, MSE(pi1): 3.725e-02, MSE(pi2): 3.704e-05, MSE(pi3): 7.943e-03\n",
      "Epoch 87000, Train loss: 1.848e+03, Test loss: 3.917e+03, MSE(e): 5.921e-05, MSE(pi1): 4.594e-02, MSE(pi2): 3.132e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 87100, Train loss: 1.711e+03, Test loss: 3.662e+03, MSE(e): 6.374e-05, MSE(pi1): 2.790e-02, MSE(pi2): 3.364e-05, MSE(pi3): 7.945e-03\n",
      "Epoch 87200, Train loss: 2.112e+03, Test loss: 3.073e+03, MSE(e): 9.127e-05, MSE(pi1): 4.005e-02, MSE(pi2): 4.578e-05, MSE(pi3): 7.989e-03\n",
      "Epoch 87300, Train loss: 1.798e+03, Test loss: 2.702e+03, MSE(e): 8.503e-05, MSE(pi1): 1.528e-02, MSE(pi2): 4.327e-05, MSE(pi3): 7.944e-03\n",
      "Epoch 87400, Train loss: 1.759e+03, Test loss: 3.063e+03, MSE(e): 7.969e-05, MSE(pi1): 1.678e-02, MSE(pi2): 4.058e-05, MSE(pi3): 7.945e-03\n",
      "Epoch 87500, Train loss: 1.971e+03, Test loss: 3.500e+03, MSE(e): 7.221e-05, MSE(pi1): 4.505e-02, MSE(pi2): 3.521e-05, MSE(pi3): 7.988e-03\n",
      "Epoch 87600, Train loss: 1.669e+03, Test loss: 2.552e+03, MSE(e): 6.855e-05, MSE(pi1): 1.913e-02, MSE(pi2): 3.571e-05, MSE(pi3): 7.917e-03\n",
      "Epoch 87700, Train loss: 1.713e+03, Test loss: 3.363e+03, MSE(e): 5.783e-05, MSE(pi1): 3.400e-02, MSE(pi2): 3.088e-05, MSE(pi3): 7.951e-03\n",
      "Epoch 87800, Train loss: 1.976e+03, Test loss: 4.074e+03, MSE(e): 6.847e-05, MSE(pi1): 4.917e-02, MSE(pi2): 3.585e-05, MSE(pi3): 7.998e-03\n",
      "Epoch 87900, Train loss: 2.002e+03, Test loss: 3.008e+03, MSE(e): 8.975e-05, MSE(pi1): 3.069e-02, MSE(pi2): 4.558e-05, MSE(pi3): 7.977e-03\n",
      "Epoch 88000, Train loss: 1.786e+03, Test loss: 2.735e+03, MSE(e): 8.251e-05, MSE(pi1): 1.666e-02, MSE(pi2): 4.136e-05, MSE(pi3): 7.940e-03\n",
      "Epoch 88100, Train loss: 1.952e+03, Test loss: 3.564e+03, MSE(e): 7.577e-05, MSE(pi1): 3.946e-02, MSE(pi2): 3.801e-05, MSE(pi3): 7.993e-03\n",
      "Epoch 88200, Train loss: 1.795e+03, Test loss: 2.953e+03, MSE(e): 7.404e-05, MSE(pi1): 2.592e-02, MSE(pi2): 3.786e-05, MSE(pi3): 7.949e-03\n",
      "Epoch 88300, Train loss: 1.838e+03, Test loss: 2.838e+03, MSE(e): 6.905e-05, MSE(pi1): 3.516e-02, MSE(pi2): 3.612e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 88400, Train loss: 1.768e+03, Test loss: 3.800e+03, MSE(e): 5.775e-05, MSE(pi1): 3.949e-02, MSE(pi2): 3.149e-05, MSE(pi3): 7.953e-03\n",
      "Epoch 88500, Train loss: 2.356e+03, Test loss: 3.721e+03, MSE(e): 9.608e-05, MSE(pi1): 5.921e-02, MSE(pi2): 4.772e-05, MSE(pi3): 8.031e-03\n",
      "Epoch 88600, Train loss: 1.910e+03, Test loss: 2.700e+03, MSE(e): 9.083e-05, MSE(pi1): 2.052e-02, MSE(pi2): 4.521e-05, MSE(pi3): 7.962e-03\n",
      "Epoch 88700, Train loss: 1.564e+03, Test loss: 2.981e+03, MSE(e): 6.371e-05, MSE(pi1): 1.344e-02, MSE(pi2): 3.234e-05, MSE(pi3): 7.929e-03\n",
      "Epoch 88800, Train loss: 1.807e+03, Test loss: 2.725e+03, MSE(e): 7.346e-05, MSE(pi1): 2.778e-02, MSE(pi2): 3.773e-05, MSE(pi3): 7.941e-03\n",
      "Epoch 88900, Train loss: 1.502e+03, Test loss: 3.074e+03, MSE(e): 5.387e-05, MSE(pi1): 1.715e-02, MSE(pi2): 2.988e-05, MSE(pi3): 7.913e-03\n",
      "Epoch 89000, Train loss: 1.556e+03, Test loss: 3.082e+03, MSE(e): 6.471e-05, MSE(pi1): 1.177e-02, MSE(pi2): 3.502e-05, MSE(pi3): 7.915e-03\n",
      "Epoch 89100, Train loss: 1.785e+03, Test loss: 2.624e+03, MSE(e): 8.797e-05, MSE(pi1): 1.109e-02, MSE(pi2): 4.566e-05, MSE(pi3): 7.943e-03\n",
      "Epoch 89200, Train loss: 2.557e+03, Test loss: 4.256e+03, MSE(e): 9.818e-05, MSE(pi1): 7.675e-02, MSE(pi2): 4.639e-05, MSE(pi3): 8.075e-03\n",
      "Epoch 89300, Train loss: 1.930e+03, Test loss: 3.398e+03, MSE(e): 6.970e-05, MSE(pi1): 4.345e-02, MSE(pi2): 3.436e-05, MSE(pi3): 7.987e-03\n",
      "Epoch 89400, Train loss: 1.909e+03, Test loss: 3.146e+03, MSE(e): 7.243e-05, MSE(pi1): 3.873e-02, MSE(pi2): 3.574e-05, MSE(pi3): 7.976e-03\n",
      "Epoch 89500, Train loss: 1.528e+03, Test loss: 3.162e+03, MSE(e): 5.465e-05, MSE(pi1): 1.911e-02, MSE(pi2): 3.029e-05, MSE(pi3): 7.902e-03\n",
      "Epoch 89600, Train loss: 2.059e+03, Test loss: 4.110e+03, MSE(e): 7.460e-05, MSE(pi1): 5.137e-02, MSE(pi2): 3.949e-05, MSE(pi3): 7.993e-03\n",
      "Epoch 89700, Train loss: 2.099e+03, Test loss: 3.172e+03, MSE(e): 9.089e-05, MSE(pi1): 3.914e-02, MSE(pi2): 4.524e-05, MSE(pi3): 7.987e-03\n",
      "Epoch 89800, Train loss: 2.421e+03, Test loss: 4.080e+03, MSE(e): 8.185e-05, MSE(pi1): 7.950e-02, MSE(pi2): 3.945e-05, MSE(pi3): 8.074e-03\n",
      "Epoch 89900, Train loss: 1.702e+03, Test loss: 3.067e+03, MSE(e): 5.584e-05, MSE(pi1): 3.482e-02, MSE(pi2): 3.052e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 90000, Train loss: 2.240e+03, Test loss: 4.418e+03, MSE(e): 7.788e-05, MSE(pi1): 6.578e-02, MSE(pi2): 3.858e-05, MSE(pi3): 8.032e-03\n",
      "Epoch 90100, Train loss: 1.681e+03, Test loss: 2.660e+03, MSE(e): 7.932e-05, MSE(pi1): 9.428e-03, MSE(pi2): 4.029e-05, MSE(pi3): 7.935e-03\n",
      "Epoch 90200, Train loss: 2.061e+03, Test loss: 3.703e+03, MSE(e): 7.564e-05, MSE(pi1): 5.040e-02, MSE(pi2): 3.672e-05, MSE(pi3): 8.006e-03\n",
      "Epoch 90300, Train loss: 1.608e+03, Test loss: 2.453e+03, MSE(e): 6.538e-05, MSE(pi1): 1.623e-02, MSE(pi2): 3.459e-05, MSE(pi3): 7.918e-03\n",
      "Epoch 90400, Train loss: 1.566e+03, Test loss: 3.386e+03, MSE(e): 5.900e-05, MSE(pi1): 1.827e-02, MSE(pi2): 3.266e-05, MSE(pi3): 7.929e-03\n",
      "Epoch 90500, Train loss: 2.207e+03, Test loss: 3.116e+03, MSE(e): 9.481e-05, MSE(pi1): 4.572e-02, MSE(pi2): 4.669e-05, MSE(pi3): 8.012e-03\n",
      "Epoch 90600, Train loss: 1.857e+03, Test loss: 3.463e+03, MSE(e): 7.106e-05, MSE(pi1): 3.503e-02, MSE(pi2): 3.503e-05, MSE(pi3): 7.963e-03\n",
      "Epoch 90700, Train loss: 1.594e+03, Test loss: 3.277e+03, MSE(e): 5.468e-05, MSE(pi1): 2.540e-02, MSE(pi2): 2.936e-05, MSE(pi3): 7.927e-03\n",
      "Epoch 90800, Train loss: 2.108e+03, Test loss: 3.068e+03, MSE(e): 8.815e-05, MSE(pi1): 4.260e-02, MSE(pi2): 4.441e-05, MSE(pi3): 8.005e-03\n",
      "Epoch 90900, Train loss: 1.954e+03, Test loss: 3.785e+03, MSE(e): 7.240e-05, MSE(pi1): 4.304e-02, MSE(pi2): 3.541e-05, MSE(pi3): 7.994e-03\n",
      "Epoch 91000, Train loss: 1.875e+03, Test loss: 2.787e+03, MSE(e): 7.415e-05, MSE(pi1): 3.376e-02, MSE(pi2): 3.799e-05, MSE(pi3): 7.959e-03\n",
      "Epoch 91100, Train loss: 2.197e+03, Test loss: 4.393e+03, MSE(e): 6.791e-05, MSE(pi1): 7.138e-02, MSE(pi2): 3.581e-05, MSE(pi3): 8.040e-03\n",
      "Epoch 91200, Train loss: 2.023e+03, Test loss: 2.991e+03, MSE(e): 9.108e-05, MSE(pi1): 3.141e-02, MSE(pi2): 4.532e-05, MSE(pi3): 7.985e-03\n",
      "Epoch 91300, Train loss: 2.355e+03, Test loss: 3.987e+03, MSE(e): 7.836e-05, MSE(pi1): 7.681e-02, MSE(pi2): 3.684e-05, MSE(pi3): 8.037e-03\n",
      "Epoch 91400, Train loss: 1.958e+03, Test loss: 3.954e+03, MSE(e): 6.109e-05, MSE(pi1): 5.474e-02, MSE(pi2): 3.177e-05, MSE(pi3): 7.999e-03\n",
      "Epoch 91500, Train loss: 1.964e+03, Test loss: 2.772e+03, MSE(e): 9.225e-05, MSE(pi1): 2.454e-02, MSE(pi2): 4.652e-05, MSE(pi3): 7.964e-03\n",
      "Epoch 91600, Train loss: 1.781e+03, Test loss: 3.238e+03, MSE(e): 7.336e-05, MSE(pi1): 2.513e-02, MSE(pi2): 3.684e-05, MSE(pi3): 7.958e-03\n",
      "Epoch 91700, Train loss: 1.542e+03, Test loss: 2.558e+03, MSE(e): 6.102e-05, MSE(pi1): 1.408e-02, MSE(pi2): 3.295e-05, MSE(pi3): 7.906e-03\n",
      "Epoch 91800, Train loss: 1.504e+03, Test loss: 3.431e+03, MSE(e): 5.837e-05, MSE(pi1): 1.291e-02, MSE(pi2): 3.219e-05, MSE(pi3): 7.910e-03\n",
      "Epoch 91900, Train loss: 2.099e+03, Test loss: 3.120e+03, MSE(e): 8.546e-05, MSE(pi1): 4.425e-02, MSE(pi2): 4.300e-05, MSE(pi3): 8.017e-03\n",
      "Epoch 92000, Train loss: 1.588e+03, Test loss: 3.001e+03, MSE(e): 6.201e-05, MSE(pi1): 1.750e-02, MSE(pi2): 3.151e-05, MSE(pi3): 7.929e-03\n",
      "Epoch 92100, Train loss: 2.041e+03, Test loss: 3.936e+03, MSE(e): 6.631e-05, MSE(pi1): 5.796e-02, MSE(pi2): 3.344e-05, MSE(pi3): 7.988e-03\n",
      "Epoch 92200, Train loss: 2.417e+03, Test loss: 3.978e+03, MSE(e): 8.840e-05, MSE(pi1): 7.264e-02, MSE(pi2): 4.379e-05, MSE(pi3): 8.067e-03\n",
      "Epoch 92300, Train loss: 2.354e+03, Test loss: 4.355e+03, MSE(e): 7.722e-05, MSE(pi1): 7.746e-02, MSE(pi2): 3.629e-05, MSE(pi3): 8.073e-03\n",
      "Epoch 92400, Train loss: 1.993e+03, Test loss: 3.601e+03, MSE(e): 6.739e-05, MSE(pi1): 5.223e-02, MSE(pi2): 3.452e-05, MSE(pi3): 7.969e-03\n",
      "Epoch 92500, Train loss: 1.830e+03, Test loss: 2.874e+03, MSE(e): 8.491e-05, MSE(pi1): 1.857e-02, MSE(pi2): 4.399e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 92600, Train loss: 1.641e+03, Test loss: 3.091e+03, MSE(e): 6.676e-05, MSE(pi1): 1.793e-02, MSE(pi2): 3.478e-05, MSE(pi3): 7.937e-03\n",
      "Epoch 92700, Train loss: 1.533e+03, Test loss: 3.103e+03, MSE(e): 5.134e-05, MSE(pi1): 2.277e-02, MSE(pi2): 2.846e-05, MSE(pi3): 7.915e-03\n",
      "Epoch 92800, Train loss: 1.830e+03, Test loss: 2.576e+03, MSE(e): 8.758e-05, MSE(pi1): 1.602e-02, MSE(pi2): 4.501e-05, MSE(pi3): 7.936e-03\n",
      "Epoch 92900, Train loss: 1.578e+03, Test loss: 2.896e+03, MSE(e): 6.511e-05, MSE(pi1): 1.347e-02, MSE(pi2): 3.395e-05, MSE(pi3): 7.920e-03\n",
      "Epoch 93000, Train loss: 2.335e+03, Test loss: 4.436e+03, MSE(e): 6.277e-05, MSE(pi1): 9.010e-02, MSE(pi2): 3.170e-05, MSE(pi3): 8.066e-03\n",
      "Epoch 93100, Train loss: 2.586e+03, Test loss: 3.684e+03, MSE(e): 9.665e-05, MSE(pi1): 8.083e-02, MSE(pi2): 4.636e-05, MSE(pi3): 8.113e-03\n",
      "Epoch 93200, Train loss: 1.603e+03, Test loss: 3.125e+03, MSE(e): 6.677e-05, MSE(pi1): 1.429e-02, MSE(pi2): 3.403e-05, MSE(pi3): 7.925e-03\n",
      "Epoch 93300, Train loss: 1.518e+03, Test loss: 3.147e+03, MSE(e): 5.461e-05, MSE(pi1): 1.804e-02, MSE(pi2): 2.985e-05, MSE(pi3): 7.914e-03\n",
      "Epoch 93400, Train loss: 1.899e+03, Test loss: 2.702e+03, MSE(e): 8.772e-05, MSE(pi1): 2.259e-02, MSE(pi2): 4.475e-05, MSE(pi3): 7.954e-03\n",
      "Epoch 93500, Train loss: 1.787e+03, Test loss: 3.085e+03, MSE(e): 7.207e-05, MSE(pi1): 2.714e-02, MSE(pi2): 3.620e-05, MSE(pi3): 7.943e-03\n",
      "Epoch 93600, Train loss: 1.672e+03, Test loss: 3.608e+03, MSE(e): 5.573e-05, MSE(pi1): 3.203e-02, MSE(pi2): 3.018e-05, MSE(pi3): 7.945e-03\n",
      "Epoch 93700, Train loss: 1.830e+03, Test loss: 2.612e+03, MSE(e): 8.884e-05, MSE(pi1): 1.455e-02, MSE(pi2): 4.533e-05, MSE(pi3): 7.958e-03\n",
      "Epoch 93800, Train loss: 1.746e+03, Test loss: 2.628e+03, MSE(e): 7.031e-05, MSE(pi1): 2.484e-02, MSE(pi2): 3.623e-05, MSE(pi3): 7.945e-03\n",
      "Epoch 93900, Train loss: 1.679e+03, Test loss: 3.499e+03, MSE(e): 5.851e-05, MSE(pi1): 2.981e-02, MSE(pi2): 3.217e-05, MSE(pi3): 7.956e-03\n",
      "Epoch 94000, Train loss: 2.418e+03, Test loss: 3.541e+03, MSE(e): 1.020e-04, MSE(pi1): 5.940e-02, MSE(pi2): 4.931e-05, MSE(pi3): 8.040e-03\n",
      "Epoch 94100, Train loss: 1.847e+03, Test loss: 2.951e+03, MSE(e): 7.061e-05, MSE(pi1): 3.470e-02, MSE(pi2): 3.596e-05, MSE(pi3): 7.943e-03\n",
      "Epoch 94200, Train loss: 1.569e+03, Test loss: 3.348e+03, MSE(e): 6.495e-05, MSE(pi1): 1.278e-02, MSE(pi2): 3.577e-05, MSE(pi3): 7.920e-03\n",
      "Epoch 94300, Train loss: 1.761e+03, Test loss: 2.522e+03, MSE(e): 8.135e-05, MSE(pi1): 1.526e-02, MSE(pi2): 4.153e-05, MSE(pi3): 7.948e-03\n",
      "Epoch 94400, Train loss: 1.856e+03, Test loss: 3.472e+03, MSE(e): 7.007e-05, MSE(pi1): 3.584e-02, MSE(pi2): 3.521e-05, MSE(pi3): 7.969e-03\n",
      "Epoch 94500, Train loss: 1.453e+03, Test loss: 3.329e+03, MSE(e): 5.352e-05, MSE(pi1): 1.267e-02, MSE(pi2): 3.006e-05, MSE(pi3): 7.908e-03\n",
      "Epoch 94600, Train loss: 1.916e+03, Test loss: 3.061e+03, MSE(e): 8.206e-05, MSE(pi1): 2.973e-02, MSE(pi2): 4.146e-05, MSE(pi3): 7.984e-03\n",
      "Epoch 94700, Train loss: 2.678e+03, Test loss: 4.559e+03, MSE(e): 8.383e-05, MSE(pi1): 1.029e-01, MSE(pi2): 3.852e-05, MSE(pi3): 8.108e-03\n",
      "Epoch 94800, Train loss: 1.688e+03, Test loss: 3.829e+03, MSE(e): 5.895e-05, MSE(pi1): 3.047e-02, MSE(pi2): 3.208e-05, MSE(pi3): 7.940e-03\n",
      "Epoch 94900, Train loss: 2.069e+03, Test loss: 3.260e+03, MSE(e): 8.851e-05, MSE(pi1): 3.841e-02, MSE(pi2): 4.389e-05, MSE(pi3): 8.000e-03\n",
      "Epoch 95000, Train loss: 1.696e+03, Test loss: 2.794e+03, MSE(e): 6.369e-05, MSE(pi1): 2.670e-02, MSE(pi2): 3.319e-05, MSE(pi3): 7.926e-03\n",
      "Epoch 95100, Train loss: 1.916e+03, Test loss: 3.307e+03, MSE(e): 8.059e-05, MSE(pi1): 3.115e-02, MSE(pi2): 4.294e-05, MSE(pi3): 7.987e-03\n",
      "Epoch 95200, Train loss: 1.617e+03, Test loss: 3.072e+03, MSE(e): 6.528e-05, MSE(pi1): 1.703e-02, MSE(pi2): 3.336e-05, MSE(pi3): 7.939e-03\n",
      "Epoch 95300, Train loss: 2.015e+03, Test loss: 4.067e+03, MSE(e): 6.095e-05, MSE(pi1): 6.059e-02, MSE(pi2): 3.121e-05, MSE(pi3): 7.996e-03\n",
      "Epoch 95400, Train loss: 1.759e+03, Test loss: 2.403e+03, MSE(e): 8.285e-05, MSE(pi1): 1.357e-02, MSE(pi2): 4.331e-05, MSE(pi3): 7.947e-03\n",
      "Epoch 95500, Train loss: 1.741e+03, Test loss: 2.968e+03, MSE(e): 7.162e-05, MSE(pi1): 2.308e-02, MSE(pi2): 3.653e-05, MSE(pi3): 7.940e-03\n",
      "Epoch 95600, Train loss: 1.576e+03, Test loss: 3.472e+03, MSE(e): 5.711e-05, MSE(pi1): 2.121e-02, MSE(pi2): 3.155e-05, MSE(pi3): 7.929e-03\n",
      "Epoch 95700, Train loss: 1.841e+03, Test loss: 2.982e+03, MSE(e): 7.810e-05, MSE(pi1): 2.642e-02, MSE(pi2): 3.878e-05, MSE(pi3): 7.959e-03\n",
      "Epoch 95800, Train loss: 1.812e+03, Test loss: 2.913e+03, MSE(e): 6.913e-05, MSE(pi1): 3.256e-02, MSE(pi2): 3.593e-05, MSE(pi3): 7.952e-03\n",
      "Epoch 95900, Train loss: 1.971e+03, Test loss: 3.750e+03, MSE(e): 8.551e-05, MSE(pi1): 3.172e-02, MSE(pi2): 4.409e-05, MSE(pi3): 7.982e-03\n",
      "Epoch 96000, Train loss: 1.810e+03, Test loss: 3.990e+03, MSE(e): 6.995e-05, MSE(pi1): 3.154e-02, MSE(pi2): 3.543e-05, MSE(pi3): 7.947e-03\n",
      "Epoch 96100, Train loss: 1.586e+03, Test loss: 5.686e+03, MSE(e): 5.128e-05, MSE(pi1): 2.792e-02, MSE(pi2): 2.869e-05, MSE(pi3): 7.941e-03\n",
      "Epoch 96200, Train loss: 2.636e+03, Test loss: 6.721e+03, MSE(e): 9.231e-05, MSE(pi1): 9.007e-02, MSE(pi2): 4.377e-05, MSE(pi3): 8.119e-03\n",
      "Epoch 96300, Train loss: 1.638e+03, Test loss: 6.658e+03, MSE(e): 6.881e-05, MSE(pi1): 1.577e-02, MSE(pi2): 3.562e-05, MSE(pi3): 7.920e-03\n",
      "Epoch 96400, Train loss: 1.676e+03, Test loss: 9.332e+03, MSE(e): 7.099e-05, MSE(pi1): 1.717e-02, MSE(pi2): 3.815e-05, MSE(pi3): 7.942e-03\n",
      "Epoch 96500, Train loss: 1.950e+03, Test loss: 1.036e+04, MSE(e): 6.951e-05, MSE(pi1): 4.557e-02, MSE(pi2): 3.426e-05, MSE(pi3): 7.992e-03\n",
      "Epoch 96600, Train loss: 1.946e+03, Test loss: 1.331e+04, MSE(e): 6.577e-05, MSE(pi1): 4.902e-02, MSE(pi2): 3.416e-05, MSE(pi3): 7.978e-03\n",
      "Epoch 96700, Train loss: 2.117e+03, Test loss: 1.306e+04, MSE(e): 9.021e-05, MSE(pi1): 4.134e-02, MSE(pi2): 4.572e-05, MSE(pi3): 8.018e-03\n",
      "Epoch 96800, Train loss: 1.728e+03, Test loss: 1.483e+04, MSE(e): 6.734e-05, MSE(pi1): 2.614e-02, MSE(pi2): 3.450e-05, MSE(pi3): 7.931e-03\n",
      "Epoch 96900, Train loss: 1.941e+03, Test loss: 1.734e+04, MSE(e): 7.685e-05, MSE(pi1): 3.735e-02, MSE(pi2): 4.048e-05, MSE(pi3): 7.986e-03\n",
      "Epoch 97000, Train loss: 1.783e+03, Test loss: 1.724e+04, MSE(e): 7.029e-05, MSE(pi1): 2.838e-02, MSE(pi2): 3.522e-05, MSE(pi3): 7.960e-03\n",
      "Epoch 97100, Train loss: 1.995e+03, Test loss: 2.025e+04, MSE(e): 6.374e-05, MSE(pi1): 5.602e-02, MSE(pi2): 3.294e-05, MSE(pi3): 7.978e-03\n",
      "Epoch 97200, Train loss: 2.205e+03, Test loss: 2.018e+04, MSE(e): 9.319e-05, MSE(pi1): 4.709e-02, MSE(pi2): 4.635e-05, MSE(pi3): 8.018e-03\n",
      "Epoch 97300, Train loss: 2.160e+03, Test loss: 2.118e+04, MSE(e): 7.616e-05, MSE(pi1): 5.972e-02, MSE(pi2): 3.710e-05, MSE(pi3): 8.011e-03\n",
      "Epoch 97400, Train loss: 1.938e+03, Test loss: 2.357e+04, MSE(e): 7.125e-05, MSE(pi1): 4.284e-02, MSE(pi2): 3.771e-05, MSE(pi3): 7.972e-03\n",
      "Epoch 97500, Train loss: 1.961e+03, Test loss: 2.262e+04, MSE(e): 7.318e-05, MSE(pi1): 4.326e-02, MSE(pi2): 3.540e-05, MSE(pi3): 7.970e-03\n",
      "Epoch 97600, Train loss: 1.461e+03, Test loss: 2.590e+04, MSE(e): 5.014e-05, MSE(pi1): 1.672e-02, MSE(pi2): 2.761e-05, MSE(pi3): 7.919e-03\n",
      "Epoch 97700, Train loss: 2.050e+03, Test loss: 2.446e+04, MSE(e): 8.968e-05, MSE(pi1): 3.557e-02, MSE(pi2): 4.406e-05, MSE(pi3): 7.976e-03\n",
      "Epoch 97800, Train loss: 2.009e+03, Test loss: 2.621e+04, MSE(e): 7.043e-05, MSE(pi1): 5.066e-02, MSE(pi2): 3.576e-05, MSE(pi3): 7.983e-03\n",
      "Epoch 97900, Train loss: 1.699e+03, Test loss: 2.837e+04, MSE(e): 6.969e-05, MSE(pi1): 2.084e-02, MSE(pi2): 3.769e-05, MSE(pi3): 7.939e-03\n",
      "Epoch 98000, Train loss: 1.665e+03, Test loss: 2.655e+04, MSE(e): 6.529e-05, MSE(pi1): 2.180e-02, MSE(pi2): 3.392e-05, MSE(pi3): 7.940e-03\n",
      "Epoch 98100, Train loss: 1.564e+03, Test loss: 2.947e+04, MSE(e): 5.474e-05, MSE(pi1): 2.252e-02, MSE(pi2): 2.948e-05, MSE(pi3): 7.918e-03\n",
      "Epoch 98200, Train loss: 1.563e+03, Test loss: 2.721e+04, MSE(e): 6.460e-05, MSE(pi1): 1.244e-02, MSE(pi2): 3.382e-05, MSE(pi3): 7.930e-03\n",
      "Epoch 98300, Train loss: 1.601e+03, Test loss: 2.871e+04, MSE(e): 7.058e-05, MSE(pi1): 1.043e-02, MSE(pi2): 3.664e-05, MSE(pi3): 7.907e-03\n",
      "Epoch 98400, Train loss: 1.533e+03, Test loss: 3.122e+04, MSE(e): 5.905e-05, MSE(pi1): 1.501e-02, MSE(pi2): 3.239e-05, MSE(pi3): 7.927e-03\n",
      "Epoch 98500, Train loss: 2.014e+03, Test loss: 3.040e+04, MSE(e): 7.050e-05, MSE(pi1): 5.093e-02, MSE(pi2): 3.455e-05, MSE(pi3): 8.001e-03\n",
      "Epoch 98600, Train loss: 1.665e+03, Test loss: 3.263e+04, MSE(e): 5.497e-05, MSE(pi1): 3.217e-02, MSE(pi2): 2.996e-05, MSE(pi3): 7.938e-03\n",
      "Epoch 98700, Train loss: 2.232e+03, Test loss: 3.142e+04, MSE(e): 8.738e-05, MSE(pi1): 5.550e-02, MSE(pi2): 4.218e-05, MSE(pi3): 8.033e-03\n",
      "Epoch 98800, Train loss: 1.567e+03, Test loss: 3.253e+04, MSE(e): 5.745e-05, MSE(pi1): 2.011e-02, MSE(pi2): 3.032e-05, MSE(pi3): 7.914e-03\n",
      "Epoch 98900, Train loss: 1.918e+03, Test loss: 3.234e+04, MSE(e): 8.962e-05, MSE(pi1): 2.256e-02, MSE(pi2): 4.594e-05, MSE(pi3): 7.964e-03\n",
      "Epoch 99000, Train loss: 1.876e+03, Test loss: 3.264e+04, MSE(e): 6.825e-05, MSE(pi1): 3.977e-02, MSE(pi2): 3.416e-05, MSE(pi3): 7.959e-03\n",
      "Epoch 99100, Train loss: 1.641e+03, Test loss: 3.415e+04, MSE(e): 6.931e-05, MSE(pi1): 1.531e-02, MSE(pi2): 3.701e-05, MSE(pi3): 7.942e-03\n",
      "Epoch 99200, Train loss: 2.563e+03, Test loss: 3.403e+04, MSE(e): 7.827e-05, MSE(pi1): 9.729e-02, MSE(pi2): 3.706e-05, MSE(pi3): 8.074e-03\n",
      "Epoch 99300, Train loss: 1.801e+03, Test loss: 3.660e+04, MSE(e): 6.119e-05, MSE(pi1): 3.904e-02, MSE(pi2): 3.303e-05, MSE(pi3): 7.984e-03\n",
      "Epoch 99400, Train loss: 1.818e+03, Test loss: 3.319e+04, MSE(e): 7.239e-05, MSE(pi1): 2.987e-02, MSE(pi2): 3.565e-05, MSE(pi3): 7.955e-03\n",
      "Epoch 99500, Train loss: 1.424e+03, Test loss: 3.633e+04, MSE(e): 5.027e-05, MSE(pi1): 1.303e-02, MSE(pi2): 2.813e-05, MSE(pi3): 7.905e-03\n",
      "Epoch 99600, Train loss: 2.006e+03, Test loss: 3.419e+04, MSE(e): 7.773e-05, MSE(pi1): 4.280e-02, MSE(pi2): 3.853e-05, MSE(pi3): 8.005e-03\n",
      "Epoch 99700, Train loss: 1.689e+03, Test loss: 3.645e+04, MSE(e): 6.141e-05, MSE(pi1): 2.816e-02, MSE(pi2): 3.286e-05, MSE(pi3): 7.935e-03\n",
      "Epoch 99800, Train loss: 1.808e+03, Test loss: 3.432e+04, MSE(e): 7.690e-05, MSE(pi1): 2.420e-02, MSE(pi2): 3.863e-05, MSE(pi3): 7.966e-03\n",
      "Epoch 99900, Train loss: 1.758e+03, Test loss: 3.670e+04, MSE(e): 6.836e-05, MSE(pi1): 2.808e-02, MSE(pi2): 3.525e-05, MSE(pi3): 7.934e-03\n",
      "\n",
      "Training process finished after 100000 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model and the optimizer\n",
    "model = PGNNIVBaseline(input_shape, predictive_layers, predictive_output, explanatory_input, explanatory_layers, explanatory_output, n_filters_explanatory).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 100000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 5\n",
    "\n",
    "train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "           D,  n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# start_epoch = n_epochs-1\n",
    "# n_epochs = 20000\n",
    "\n",
    "# batch_size = 64 \n",
    "# n_checkpoints = 5\n",
    "\n",
    "# second_lr = 3e-4\n",
    "\n",
    "# train_loop(model, optimizer, X_train, y_train, f_train, X_test, y_test, f_test,\n",
    "#            D, n_checkpoints, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "#            model_results_path=MODEL_RESULTS_TRANSFERLEARNING_PATH, device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
