{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# Imports de la libreria propia\n",
    "from vecopsciml.kernels.derivative import DerivativeKernels\n",
    "from vecopsciml.utils import TensOps\n",
    "\n",
    "# Imports de las funciones creadas para este programa\n",
    "from utils.folders import create_folder\n",
    "from utils.load_data import load_data\n",
    "from trainers.train import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear\n",
      "Folder already exists at: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/results/non_linear/model_POD\n"
     ]
    }
   ],
   "source": [
    "# Creamos los paths para las distintas carpetas\n",
    "ROOT_PATH = r'/home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning'\n",
    "DATA_PATH = os.path.join(ROOT_PATH, r'data/non_linear/non_linear_decomposition.pkl')\n",
    "RESULTS_FOLDER_PATH = os.path.join(ROOT_PATH, r'results/non_linear')\n",
    "MODEL_RESULTS_PGNNIV_PATH = os.path.join(ROOT_PATH, r'results/non_linear/model_POD')\n",
    "\n",
    "\n",
    "# Creamos las carpetas que sean necesarias (si ya están creadas se avisará de ello)\n",
    "create_folder(RESULTS_FOLDER_PATH)\n",
    "create_folder(MODEL_RESULTS_PGNNIV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: /home/rmunoz/Escritorio/rmunozTMELab/Physically-Guided-Machine-Learning/data/non_linear/non_linear_decomposition.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional filters to derivate\n",
    "dx = dataset['x_step_size']\n",
    "dy = dataset['y_step_size']\n",
    "D = DerivativeKernels(dx, dy, 0).grad_kernels_two_dimensions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 8000\n",
      "Validation dataset length: 2000\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.Tensor(dataset['X_train']).unsqueeze(1).to(DEVICE)\n",
    "y_train = TensOps(torch.Tensor(dataset['y_train']).unsqueeze(1).requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_train = TensOps(torch.tensor(dataset['k_train']).unsqueeze(1).requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_train = TensOps(torch.tensor(dataset['f_train']).unsqueeze(1).to(torch.float32).requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "X_val = torch.Tensor(dataset['X_val']).unsqueeze(1).to(DEVICE)\n",
    "y_val = TensOps(torch.Tensor(dataset['y_val']).unsqueeze(1).requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "K_val = TensOps(torch.tensor(dataset['k_val']).unsqueeze(1).requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "f_val = TensOps(torch.tensor(dataset['f_val']).to(torch.float32).unsqueeze(1).requires_grad_(True).to(DEVICE), space_dimension=2, contravariance=0, covariance=0)\n",
    "\n",
    "print(\"Train dataset length:\", len(X_train))\n",
    "print(\"Validation dataset length:\", len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> 1.0\n",
      "1 --> 0.0983155369758606\n",
      "2 --> 0.05151933431625366\n",
      "3 --> 0.00887155532836914\n",
      "4 --> 0.005898416042327881\n",
      "5 --> 0.0036424994468688965\n",
      "6 --> 0.0016180872917175293\n",
      "7 --> 0.0011507868766784668\n",
      "8 --> 0.000786125659942627\n",
      "9 --> 0.0005230903625488281\n",
      "10 --> 0.0003058314323425293\n",
      "11 --> 0.00022345781326293945\n",
      "12 --> 0.0001596212387084961\n",
      "13 --> 0.00011056661605834961\n",
      "14 --> 8.106231689453125e-05\n",
      "15 --> 5.6684017181396484e-05\n",
      "16 --> 4.3272972106933594e-05\n",
      "17 --> 3.129243850708008e-05\n",
      "18 --> 2.372264862060547e-05\n",
      "19 --> 1.7762184143066406e-05\n"
     ]
    }
   ],
   "source": [
    "U_train, S_train, Vt_train = torch.linalg.svd(y_train.values.detach().squeeze().to('cpu').view(y_train.values.detach().shape[0], -1).T, full_matrices=False)\n",
    "\n",
    "error = []\n",
    "for mode_i in range(len(S_train)):\n",
    "    error.append(1-(sum(S_train[:mode_i])/sum(S_train)).numpy())\n",
    "    if mode_i < 20:\n",
    "        print(mode_i, '-->', error[mode_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_modes = 14\n",
    "\n",
    "U_reduced_train = U_train[:, :num_modes]\n",
    "S_reduced_train = S_train[:num_modes]\n",
    "Vt_reduced_train = Vt_train[:num_modes, :]\n",
    "\n",
    "modes_base_train = torch.mm(U_reduced_train, torch.diag(S_reduced_train))\n",
    "# y_train = Vt_reduced_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_val, S_val, Vt_val = torch.linalg.svd(y_val.values.squeeze().view(y_val.values.shape[0], -1).T, full_matrices=False)\n",
    "\n",
    "num_modes = 14\n",
    "\n",
    "U_reduced_val = U_val[:, :num_modes]\n",
    "S_reduced_val = S_val[:num_modes]\n",
    "Vt_reduced_val = Vt_val[:num_modes, :]\n",
    "\n",
    "# data_reconstructed = torch.mm(torch.mm(U_reduced_val, torch.diag(S_reduced_val)), Vt_reduced_val)\n",
    "\n",
    "# y_val = Vt_reduced_val.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train[0].shape\n",
    "POD_shape = num_modes\n",
    "output_shape = y_train.values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from vecopsciml.utils import TensOps\n",
    "from vecopsciml.operators.zero_order import Mx, My\n",
    "\n",
    "class POD_PGNNIV(nn.Module):\n",
    "    def __init__(self, input_size, POD_output, explanatory_output_size, POD_base, device, **kwargs):\n",
    "        super(POD_PGNNIV, self).__init__()\n",
    "\n",
    "        self.input = input_size\n",
    "        self.POD_output = POD_output\n",
    "        self.output_expl = explanatory_output_size\n",
    "\n",
    "        self.hidden_units_pred = 10\n",
    "        self.hidden_units_exp = 15\n",
    "        self.filters_exp = 10\n",
    "\n",
    "        self.base = POD_base.to(device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # # Predictive network\n",
    "        self.flatten_layer_pred = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "        self.hidden1_layer_pred = nn.Linear(torch.prod(torch.tensor(self.input, device=self.device)), self.hidden_units_pred).to(self.device)\n",
    "        self.hidden2_layer_pred = nn.Linear(self.hidden_units_pred, self.hidden_units_pred).to(self.device)\n",
    "        self.output_layer_pred = nn.Linear(self.hidden_units_pred, self.POD_output).to(self.device)\n",
    "\n",
    "        # Explanatory network (commented out since they are not used in forward method)\n",
    "        self.conv1_exp = nn.Conv2d(in_channels=1, out_channels=self.filters_exp, kernel_size=1).to(self.device)\n",
    "        self.flatten_layer_exp = nn.Flatten().to(self.device)\n",
    "        self.hidden1_layer_exp = nn.LazyLinear(self.hidden_units_exp).to(self.device)\n",
    "        self.hidden2_layer_exp = nn.Linear(self.hidden_units_exp, self.hidden_units_exp).to(self.device)\n",
    "        self.output_layer_exp = nn.Linear(self.hidden_units_exp, self.filters_exp * (self.output_expl[1] - 1) * (self.output_expl[2] - 1)).to(self.device)\n",
    "        self.conv2_exp = nn.Conv2d(in_channels=self.filters_exp, out_channels=1, kernel_size=1).to(self.device)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        X = X.to(self.device)\n",
    "\n",
    "        # Predictive network\n",
    "        X = self.flatten_layer_pred(X)\n",
    "        X = torch.sigmoid(self.hidden1_layer_pred(X))\n",
    "        X = torch.sigmoid(self.hidden2_layer_pred(X))\n",
    "        output_predictive_net = self.output_layer_pred(X)\n",
    "\n",
    "        u_pred = torch.mm(self.base, output_predictive_net.T).T.reshape(output_predictive_net.shape[0], self.output_expl[0], self.output_expl[1], self.output_expl[2])\n",
    "        um_pred = My(Mx(TensOps(u_pred, space_dimension=2, contravariance=0, covariance=0))).values\n",
    "\n",
    "        x = torch.sigmoid(self.conv1_exp(um_pred))\n",
    "        x = self.flatten_layer_exp(x)\n",
    "        x = torch.sigmoid(self.hidden1_layer_exp(x))\n",
    "        x = torch.sigmoid(self.hidden2_layer_exp(x))\n",
    "        x = self.output_layer_exp(x)\n",
    "        x = x.view(x.size(0), self.filters_exp, self.output_expl[1] - 1, self.output_expl[2] - 1)\n",
    "        K_pred = self.conv2_exp(x)\n",
    "\n",
    "        return u_pred, K_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch 0, Train loss: 1.327e+10, Test loss: 1.299e+10, MSE(e): 1.326e+03, MSE(pi1): 4.988e+02, MSE(pi2): 5.896e+02, MSE(pi3): 1.179e+01\n",
      "Epoch 10, Train loss: 1.300e+07, Test loss: 1.124e+07, MSE(e): 1.292e+00, MSE(pi1): 5.147e+00, MSE(pi2): 8.534e-01, MSE(pi3): 2.504e-01\n",
      "Epoch 20, Train loss: 7.235e+06, Test loss: 6.275e+06, MSE(e): 7.185e-01, MSE(pi1): 2.926e+00, MSE(pi2): 4.624e-01, MSE(pi3): 2.074e-01\n",
      "Epoch 30, Train loss: 5.804e+06, Test loss: 5.143e+06, MSE(e): 5.766e-01, MSE(pi1): 1.936e+00, MSE(pi2): 3.976e-01, MSE(pi3): 1.851e-01\n",
      "Epoch 40, Train loss: 5.058e+06, Test loss: 4.566e+06, MSE(e): 5.028e-01, MSE(pi1): 1.261e+00, MSE(pi2): 3.585e-01, MSE(pi3): 1.681e-01\n",
      "Epoch 50, Train loss: 4.595e+06, Test loss: 4.173e+06, MSE(e): 4.571e-01, MSE(pi1): 7.897e-01, MSE(pi2): 3.283e-01, MSE(pi3): 1.521e-01\n",
      "Epoch 60, Train loss: 4.004e+06, Test loss: 3.642e+06, MSE(e): 3.984e-01, MSE(pi1): 5.431e-01, MSE(pi2): 2.859e-01, MSE(pi3): 1.395e-01\n",
      "Epoch 70, Train loss: 3.139e+06, Test loss: 2.860e+06, MSE(e): 3.122e-01, MSE(pi1): 4.097e-01, MSE(pi2): 2.223e-01, MSE(pi3): 1.280e-01\n",
      "Epoch 80, Train loss: 2.103e+06, Test loss: 1.901e+06, MSE(e): 2.088e-01, MSE(pi1): 3.042e-01, MSE(pi2): 1.471e-01, MSE(pi3): 1.172e-01\n",
      "Epoch 90, Train loss: 1.043e+06, Test loss: 9.208e+05, MSE(e): 1.030e-01, MSE(pi1): 2.188e-01, MSE(pi2): 7.174e-02, MSE(pi3): 1.074e-01\n",
      "Epoch 100, Train loss: 3.521e+05, Test loss: 3.004e+05, MSE(e): 3.403e-02, MSE(pi1): 1.683e-01, MSE(pi2): 2.385e-02, MSE(pi3): 1.010e-01\n",
      "Epoch 110, Train loss: 2.212e+05, Test loss: 1.692e+05, MSE(e): 2.098e-02, MSE(pi1): 1.534e-01, MSE(pi2): 1.422e-02, MSE(pi3): 9.845e-02\n",
      "Epoch 120, Train loss: 2.079e+05, Test loss: 1.537e+05, MSE(e): 1.969e-02, MSE(pi1): 1.557e-01, MSE(pi2): 1.308e-02, MSE(pi3): 9.468e-02\n",
      "Epoch 130, Train loss: 1.941e+05, Test loss: 1.434e+05, MSE(e): 1.856e-02, MSE(pi1): 1.770e-01, MSE(pi2): 1.232e-02, MSE(pi3): 6.735e-02\n",
      "Epoch 140, Train loss: 1.805e+05, Test loss: 1.347e+05, MSE(e): 1.773e-02, MSE(pi1): 1.155e-01, MSE(pi2): 1.170e-02, MSE(pi3): 2.049e-02\n",
      "Epoch 150, Train loss: 1.654e+05, Test loss: 1.386e+05, MSE(e): 1.627e-02, MSE(pi1): 1.044e-01, MSE(pi2): 1.084e-02, MSE(pi3): 1.598e-02\n",
      "Epoch 160, Train loss: 1.107e+05, Test loss: 1.293e+05, MSE(e): 1.083e-02, MSE(pi1): 9.653e-02, MSE(pi2): 8.329e-03, MSE(pi3): 1.489e-02\n",
      "Epoch 170, Train loss: 1.088e+05, Test loss: 1.131e+05, MSE(e): 1.065e-02, MSE(pi1): 8.998e-02, MSE(pi2): 8.076e-03, MSE(pi3): 1.429e-02\n",
      "Epoch 180, Train loss: 9.948e+04, Test loss: 1.106e+05, MSE(e): 9.733e-03, MSE(pi1): 8.042e-02, MSE(pi2): 7.507e-03, MSE(pi3): 1.334e-02\n",
      "Epoch 190, Train loss: 9.301e+04, Test loss: 9.246e+04, MSE(e): 9.110e-03, MSE(pi1): 6.920e-02, MSE(pi2): 7.044e-03, MSE(pi3): 1.207e-02\n",
      "Epoch 200, Train loss: 8.758e+04, Test loss: 8.782e+04, MSE(e): 8.597e-03, MSE(pi1): 5.908e-02, MSE(pi2): 6.707e-03, MSE(pi3): 1.016e-02\n",
      "Epoch 210, Train loss: 8.363e+04, Test loss: 8.493e+04, MSE(e): 8.247e-03, MSE(pi1): 4.422e-02, MSE(pi2): 6.432e-03, MSE(pi3): 7.086e-03\n",
      "Epoch 220, Train loss: 7.933e+04, Test loss: 8.257e+04, MSE(e): 7.862e-03, MSE(pi1): 2.789e-02, MSE(pi2): 6.148e-03, MSE(pi3): 4.286e-03\n",
      "Epoch 230, Train loss: 7.484e+04, Test loss: 7.958e+04, MSE(e): 7.434e-03, MSE(pi1): 2.038e-02, MSE(pi2): 5.852e-03, MSE(pi3): 2.962e-03\n",
      "Epoch 240, Train loss: 7.062e+04, Test loss: 7.625e+04, MSE(e): 7.020e-03, MSE(pi1): 1.725e-02, MSE(pi2): 5.569e-03, MSE(pi3): 2.400e-03\n",
      "Epoch 250, Train loss: 6.675e+04, Test loss: 7.248e+04, MSE(e): 6.638e-03, MSE(pi1): 1.543e-02, MSE(pi2): 5.300e-03, MSE(pi3): 2.112e-03\n",
      "Epoch 260, Train loss: 6.389e+04, Test loss: 6.804e+04, MSE(e): 6.355e-03, MSE(pi1): 1.410e-02, MSE(pi2): 5.071e-03, MSE(pi3): 1.948e-03\n",
      "Epoch 270, Train loss: 6.316e+04, Test loss: 6.310e+04, MSE(e): 6.284e-03, MSE(pi1): 1.297e-02, MSE(pi2): 4.929e-03, MSE(pi3): 1.861e-03\n",
      "Epoch 280, Train loss: 6.333e+04, Test loss: 5.932e+04, MSE(e): 6.302e-03, MSE(pi1): 1.214e-02, MSE(pi2): 4.835e-03, MSE(pi3): 1.801e-03\n",
      "Epoch 290, Train loss: 6.311e+04, Test loss: 5.660e+04, MSE(e): 6.281e-03, MSE(pi1): 1.154e-02, MSE(pi2): 4.738e-03, MSE(pi3): 1.750e-03\n",
      "Epoch 300, Train loss: 6.309e+04, Test loss: 5.447e+04, MSE(e): 6.280e-03, MSE(pi1): 1.104e-02, MSE(pi2): 4.657e-03, MSE(pi3): 1.710e-03\n",
      "Epoch 310, Train loss: 6.292e+04, Test loss: 5.280e+04, MSE(e): 6.264e-03, MSE(pi1): 1.061e-02, MSE(pi2): 4.577e-03, MSE(pi3): 1.675e-03\n",
      "Epoch 320, Train loss: 6.220e+04, Test loss: 5.130e+04, MSE(e): 6.193e-03, MSE(pi1): 1.024e-02, MSE(pi2): 4.483e-03, MSE(pi3): 1.639e-03\n"
     ]
    }
   ],
   "source": [
    "# Se carga el modelo y el optimizador\n",
    "POD_model = POD_PGNNIV(input_size=input_shape, POD_output=POD_shape, explanatory_output_size=output_shape, POD_base=modes_base_train, device=DEVICE)\n",
    "optimizer = torch.optim.Adam(POD_model.parameters(), lr=1e-4)\n",
    "\n",
    "# Parametros de entrenamiento\n",
    "start_epoch = 0\n",
    "n_epochs = 1000\n",
    "\n",
    "batch_size = 64\n",
    "n_checkpoints = 10\n",
    "\n",
    "train_loop(POD_model, optimizer, n_checkpoints,\n",
    "           X_train.to(DEVICE), y_train, X_val, y_val, f_train, f_val,\n",
    "           D=D, start_epoch=start_epoch, n_epochs=n_epochs, batch_size=batch_size, \n",
    "           model_results_path=MODEL_RESULTS_PGNNIV_PATH, device=DEVICE,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
